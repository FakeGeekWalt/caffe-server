./build/tools/caffe: /home/zkx/anaconda2/lib/libtiff.so.5: no version information available (required by /home/zkx/env/opencv/lib/libopencv_highgui.so.2.4)
I0523 21:53:37.520953 11654 upgrade_proto.cpp:1084] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': models/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/solver.prototxt
I0523 21:53:37.521270 11654 upgrade_proto.cpp:1091] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0523 21:53:37.521284 11654 upgrade_proto.cpp:1093] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0523 21:53:37.521435 11654 caffe.cpp:204] Using GPUs 0, 1, 2, 3
I0523 21:53:37.546175 11654 caffe.cpp:209] GPU 0: TITAN Xp
I0523 21:53:37.546861 11654 caffe.cpp:209] GPU 1: TITAN Xp
I0523 21:53:37.547466 11654 caffe.cpp:209] GPU 2: TITAN Xp
I0523 21:53:37.548066 11654 caffe.cpp:209] GPU 3: TITAN Xp
I0523 21:53:38.259901 11654 solver.cpp:45] Initializing solver from parameters: 
base_lr: 0.1
display: 10
max_iter: 160000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx"
solver_mode: GPU
device_id: 0
net: "models/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/train.prototxt"
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
stepvalue: 80000
stepvalue: 120000
stepvalue: 140000
iter_size: 1
type: "SGD"
weights: "/home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel"
I0523 21:53:38.260100 11654 solver.cpp:102] Creating training net from net file: models/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/train.prototxt
I0523 21:53:38.264808 11654 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: models/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/train.prototxt
I0523 21:53:38.264828 11654 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:38.267014 11654 net.cpp:51] Initializing net from parameters: 
name: "2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  image_data_param {
    source: "/home/zkx/Data_sdb/TrainData/Data_sdc/Patches/MultiPatches/image_list/train_list/Combine_base_Cmul-Asia-beid-cap10-ZheD_list.txt_label.txt"
    batch_size: 64
    shuffle: true
    root_folder: "/home/zkx/Data_sdb/TrainData/Data_sdc/Patches/MultiPatches/fc_0.35_112x96/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_dw"
  type: "DepthwiseConvolution"
  bottom: "conv1"
  top: "conv1_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_dw/bn"
  type: "BatchNorm"
  bottom: "conv1_dw"
  top: "conv1_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_dw/scale"
  type: "Scale"
  bottom: "conv1_dw"
  top: "conv1_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_dw"
  type: "PReLU"
  bottom: "conv1_dw"
  top: "conv1_dw"
}
layer {
  name: "conv2_ex"
  type: "Convolution"
  bottom: "conv1_dw"
  top: "conv2_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_ex"
  top: "conv2_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_ex/scale"
  type: "Scale"
  bottom: "conv2_ex"
  top: "conv2_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_ex"
  type: "PReLU"
  bottom: "conv2_ex"
  top: "conv2_ex"
}
layer {
  name: "conv2_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_ex"
  top: "conv2_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_dw"
  top: "conv2_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_dw/scale"
  type: "Scale"
  bottom: "conv2_dw"
  top: "conv2_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_dw"
  type: "PReLU"
  bottom: "conv2_dw"
  top: "conv2_dw"
}
layer {
  name: "conv2_em"
  type: "Convolution"
  bottom: "conv2_dw"
  top: "conv2_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_em/bn"
  type: "BatchNorm"
  bottom: "conv2_em"
  top: "conv2_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_em/scale"
  type: "Scale"
  bottom: "conv2_em"
  top: "conv2_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ex"
  type: "Convolution"
  bottom: "conv2_em"
  top: "conv2_1_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_1_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_1_ex"
  top: "conv2_1_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_ex/scale"
  type: "Scale"
  bottom: "conv2_1_ex"
  top: "conv2_1_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_ex"
  type: "PReLU"
  bottom: "conv2_1_ex"
  top: "conv2_1_ex"
}
layer {
  name: "conv2_1_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_1_ex"
  top: "conv2_1_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1_dw"
  top: "conv2_1_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_dw/scale"
  type: "Scale"
  bottom: "conv2_1_dw"
  top: "conv2_1_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_dw"
  type: "PReLU"
  bottom: "conv2_1_dw"
  top: "conv2_1_dw"
}
layer {
  name: "conv2_1_em"
  type: "Convolution"
  bottom: "conv2_1_dw"
  top: "conv2_1_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_1_em/bn"
  type: "BatchNorm"
  bottom: "conv2_1_em"
  top: "conv2_1_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_em/scale"
  type: "Scale"
  bottom: "conv2_1_em"
  top: "conv2_1_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_1"
  type: "Eltwise"
  bottom: "conv2_em"
  bottom: "conv2_1_em"
  top: "res2_1"
}
layer {
  name: "conv2_2_ex"
  type: "Convolution"
  bottom: "res2_1"
  top: "conv2_2_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_2_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_2_ex"
  top: "conv2_2_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_ex/scale"
  type: "Scale"
  bottom: "conv2_2_ex"
  top: "conv2_2_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_ex"
  type: "PReLU"
  bottom: "conv2_2_ex"
  top: "conv2_2_ex"
}
layer {
  name: "conv2_2_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_2_ex"
  top: "conv2_2_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2_dw"
  top: "conv2_2_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_dw/scale"
  type: "Scale"
  bottom: "conv2_2_dw"
  top: "conv2_2_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_dw"
  type: "PReLU"
  bottom: "conv2_2_dw"
  top: "conv2_2_dw"
}
layer {
  name: "conv2_2_em"
  type: "Convolution"
  bottom: "conv2_2_dw"
  top: "conv2_2_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_2_em/bn"
  type: "BatchNorm"
  bottom: "conv2_2_em"
  top: "conv2_2_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_em/scale"
  type: "Scale"
  bottom: "conv2_2_em"
  top: "conv2_2_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_2"
  type: "Eltwise"
  bottom: "res2_1"
  bottom: "conv2_2_em"
  top: "res2_2"
}
layer {
  name: "conv2_3_ex"
  type: "Convolution"
  bottom: "res2_2"
  top: "conv2_3_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_3_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_3_ex"
  top: "conv2_3_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_ex/scale"
  type: "Scale"
  bottom: "conv2_3_ex"
  top: "conv2_3_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_3_ex"
  type: "PReLU"
  bottom: "conv2_3_ex"
  top: "conv2_3_ex"
}
layer {
  name: "conv2_3_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_3_ex"
  top: "conv2_3_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_3_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_3_dw"
  top: "conv2_3_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_dw/scale"
  type: "Scale"
  bottom: "conv2_3_dw"
  top: "conv2_3_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_3_dw"
  type: "PReLU"
  bottom: "conv2_3_dw"
  top: "conv2_3_dw"
}
layer {
  name: "conv2_3_em"
  type: "Convolution"
  bottom: "conv2_3_dw"
  top: "conv2_3_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_3_em/bn"
  type: "BatchNorm"
  bottom: "conv2_3_em"
  top: "conv2_3_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_em/scale"
  type: "Scale"
  bottom: "conv2_3_em"
  top: "conv2_3_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_3"
  type: "Eltwise"
  bottom: "res2_2"
  bottom: "conv2_3_em"
  top: "res2_3"
}
layer {
  name: "conv2_4_ex"
  type: "Convolution"
  bottom: "res2_3"
  top: "conv2_4_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_4_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_4_ex"
  top: "conv2_4_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_ex/scale"
  type: "Scale"
  bottom: "conv2_4_ex"
  top: "conv2_4_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_4_ex"
  type: "PReLU"
  bottom: "conv2_4_ex"
  top: "conv2_4_ex"
}
layer {
  name: "conv2_4_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_4_ex"
  top: "conv2_4_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_4_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_4_dw"
  top: "conv2_4_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_dw/scale"
  type: "Scale"
  bottom: "conv2_4_dw"
  top: "conv2_4_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_4_dw"
  type: "PReLU"
  bottom: "conv2_4_dw"
  top: "conv2_4_dw"
}
layer {
  name: "conv2_4_em"
  type: "Convolution"
  bottom: "conv2_4_dw"
  top: "conv2_4_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_4_em/bn"
  type: "BatchNorm"
  bottom: "conv2_4_em"
  top: "conv2_4_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_em/scale"
  type: "Scale"
  bottom: "conv2_4_em"
  top: "conv2_4_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_4"
  type: "Eltwise"
  bottom: "res2_3"
  bottom: "conv2_4_em"
  top: "res2_4"
}
layer {
  name: "conv3_ex"
  type: "Convolution"
  bottom: "res2_4"
  top: "conv3_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_ex"
  top: "conv3_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_ex/scale"
  type: "Scale"
  bottom: "conv3_ex"
  top: "conv3_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_ex"
  type: "PReLU"
  bottom: "conv3_ex"
  top: "conv3_ex"
}
layer {
  name: "conv3_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_ex"
  top: "conv3_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_dw"
  top: "conv3_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_dw/scale"
  type: "Scale"
  bottom: "conv3_dw"
  top: "conv3_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_dw"
  type: "PReLU"
  bottom: "conv3_dw"
  top: "conv3_dw"
}
layer {
  name: "conv3_em"
  type: "Convolution"
  bottom: "conv3_dw"
  top: "conv3_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_em/bn"
  type: "BatchNorm"
  bottom: "conv3_em"
  top: "conv3_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_em/scale"
  type: "Scale"
  bottom: "conv3_em"
  top: "conv3_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ex"
  type: "Convolution"
  bottom: "conv3_em"
  top: "conv3_1_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_1_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_1_ex"
  top: "conv3_1_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_ex/scale"
  type: "Scale"
  bottom: "conv3_1_ex"
  top: "conv3_1_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_ex"
  type: "PReLU"
  bottom: "conv3_1_ex"
  top: "conv3_1_ex"
}
layer {
  name: "conv3_1_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_1_ex"
  top: "conv3_1_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1_dw"
  top: "conv3_1_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_dw/scale"
  type: "Scale"
  bottom: "conv3_1_dw"
  top: "conv3_1_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_dw"
  type: "PReLU"
  bottom: "conv3_1_dw"
  top: "conv3_1_dw"
}
layer {
  name: "conv3_1_em"
  type: "Convolution"
  bottom: "conv3_1_dw"
  top: "conv3_1_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_1_em/bn"
  type: "BatchNorm"
  bottom: "conv3_1_em"
  top: "conv3_1_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_em/scale"
  type: "Scale"
  bottom: "conv3_1_em"
  top: "conv3_1_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_1"
  type: "Eltwise"
  bottom: "conv3_em"
  bottom: "conv3_1_em"
  top: "res3_1"
}
layer {
  name: "conv3_2_ex"
  type: "Convolution"
  bottom: "res3_1"
  top: "conv3_2_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_2_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_2_ex"
  top: "conv3_2_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_ex/scale"
  type: "Scale"
  bottom: "conv3_2_ex"
  top: "conv3_2_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_ex"
  type: "PReLU"
  bottom: "conv3_2_ex"
  top: "conv3_2_ex"
}
layer {
  name: "conv3_2_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_2_ex"
  top: "conv3_2_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2_dw"
  top: "conv3_2_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_dw/scale"
  type: "Scale"
  bottom: "conv3_2_dw"
  top: "conv3_2_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_dw"
  type: "PReLU"
  bottom: "conv3_2_dw"
  top: "conv3_2_dw"
}
layer {
  name: "conv3_2_em"
  type: "Convolution"
  bottom: "conv3_2_dw"
  top: "conv3_2_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_2_em/bn"
  type: "BatchNorm"
  bottom: "conv3_2_em"
  top: "conv3_2_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_em/scale"
  type: "Scale"
  bottom: "conv3_2_em"
  top: "conv3_2_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_2"
  type: "Eltwise"
  bottom: "res3_1"
  bottom: "conv3_2_em"
  top: "res3_2"
}
layer {
  name: "conv3_3_ex"
  type: "Convolution"
  bottom: "res3_2"
  top: "conv3_3_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_3_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_3_ex"
  top: "conv3_3_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_ex/scale"
  type: "Scale"
  bottom: "conv3_3_ex"
  top: "conv3_3_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_ex"
  type: "PReLU"
  bottom: "conv3_3_ex"
  top: "conv3_3_ex"
}
layer {
  name: "conv3_3_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_3_ex"
  top: "conv3_3_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_3_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_3_dw"
  top: "conv3_3_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_dw/scale"
  type: "Scale"
  bottom: "conv3_3_dw"
  top: "conv3_3_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_dw"
  type: "PReLU"
  bottom: "conv3_3_dw"
  top: "conv3_3_dw"
}
layer {
  name: "conv3_3_em"
  type: "Convolution"
  bottom: "conv3_3_dw"
  top: "conv3_3_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_3_em/bn"
  type: "BatchNorm"
  bottom: "conv3_3_em"
  top: "conv3_3_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_em/scale"
  type: "Scale"
  bottom: "conv3_3_em"
  top: "conv3_3_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_3"
  type: "Eltwise"
  bottom: "res3_2"
  bottom: "conv3_3_em"
  top: "res3_3"
}
layer {
  name: "conv3_4_ex"
  type: "Convolution"
  bottom: "res3_3"
  top: "conv3_4_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_4_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_4_ex"
  top: "conv3_4_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_ex/scale"
  type: "Scale"
  bottom: "conv3_4_ex"
  top: "conv3_4_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_4_ex"
  type: "PReLU"
  bottom: "conv3_4_ex"
  top: "conv3_4_ex"
}
layer {
  name: "conv3_4_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_4_ex"
  top: "conv3_4_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_4_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_4_dw"
  top: "conv3_4_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_dw/scale"
  type: "Scale"
  bottom: "conv3_4_dw"
  top: "conv3_4_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_4_dw"
  type: "PReLU"
  bottom: "conv3_4_dw"
  top: "conv3_4_dw"
}
layer {
  name: "conv3_4_em"
  type: "Convolution"
  bottom: "conv3_4_dw"
  top: "conv3_4_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_4_em/bn"
  type: "BatchNorm"
  bottom: "conv3_4_em"
  top: "conv3_4_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_em/scale"
  type: "Scale"
  bottom: "conv3_4_em"
  top: "conv3_4_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_4"
  type: "Eltwise"
  bottom: "res3_3"
  bottom: "conv3_4_em"
  top: "res3_4"
}
layer {
  name: "conv3_5_ex"
  type: "Convolution"
  bottom: "res3_4"
  top: "conv3_5_ex"
  param {
  
I0523 21:53:38.267935 11654 layer_factory.hpp:77] Creating layer data
I0523 21:53:38.267997 11654 net.cpp:84] Creating Layer data
I0523 21:53:38.268005 11654 net.cpp:380] data -> data
I0523 21:53:38.268028 11654 net.cpp:380] data -> label
I0523 21:53:38.268040 11654 image_data_layer.cpp:38] Opening file /home/zkx/Data_sdb/TrainData/Data_sdc/Patches/MultiPatches/image_list/train_list/Combine_base_Cmul-Asia-beid-cap10-ZheD_list.txt_label.txt
I0523 21:53:39.161262 11654 image_data_layer.cpp:53] Shuffling data
I0523 21:53:39.588524 11654 image_data_layer.cpp:63] A total of 2075438 images.
I0523 21:53:39.591207 11654 image_data_layer.cpp:90] output data size: 64,3,112,96
I0523 21:53:39.615473 11654 net.cpp:122] Setting up data
I0523 21:53:39.615507 11654 net.cpp:129] Top shape: 64 3 112 96 (2064384)
I0523 21:53:39.615514 11654 net.cpp:129] Top shape: 64 (64)
I0523 21:53:39.615556 11654 net.cpp:137] Memory required for data: 8257792
I0523 21:53:39.615586 11654 layer_factory.hpp:77] Creating layer label_data_1_split
I0523 21:53:39.615645 11654 net.cpp:84] Creating Layer label_data_1_split
I0523 21:53:39.615654 11654 net.cpp:406] label_data_1_split <- label
I0523 21:53:39.615670 11654 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0523 21:53:39.615685 11654 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0523 21:53:39.615774 11654 net.cpp:122] Setting up label_data_1_split
I0523 21:53:39.615784 11654 net.cpp:129] Top shape: 64 (64)
I0523 21:53:39.615788 11654 net.cpp:129] Top shape: 64 (64)
I0523 21:53:39.615792 11654 net.cpp:137] Memory required for data: 8258304
I0523 21:53:39.615794 11654 layer_factory.hpp:77] Creating layer conv1
I0523 21:53:39.615829 11654 net.cpp:84] Creating Layer conv1
I0523 21:53:39.615835 11654 net.cpp:406] conv1 <- data
I0523 21:53:39.615844 11654 net.cpp:380] conv1 -> conv1
I0523 21:53:40.129374 11654 net.cpp:122] Setting up conv1
I0523 21:53:40.129426 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.129431 11654 net.cpp:137] Memory required for data: 52298496
I0523 21:53:40.129456 11654 layer_factory.hpp:77] Creating layer conv1/bn
I0523 21:53:40.129496 11654 net.cpp:84] Creating Layer conv1/bn
I0523 21:53:40.129503 11654 net.cpp:406] conv1/bn <- conv1
I0523 21:53:40.129513 11654 net.cpp:367] conv1/bn -> conv1 (in-place)
I0523 21:53:40.129693 11654 net.cpp:122] Setting up conv1/bn
I0523 21:53:40.129701 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.129705 11654 net.cpp:137] Memory required for data: 96338688
I0523 21:53:40.129717 11654 layer_factory.hpp:77] Creating layer conv1/scale
I0523 21:53:40.129734 11654 net.cpp:84] Creating Layer conv1/scale
I0523 21:53:40.129739 11654 net.cpp:406] conv1/scale <- conv1
I0523 21:53:40.129745 11654 net.cpp:367] conv1/scale -> conv1 (in-place)
I0523 21:53:40.129787 11654 layer_factory.hpp:77] Creating layer conv1/scale
I0523 21:53:40.129895 11654 net.cpp:122] Setting up conv1/scale
I0523 21:53:40.129904 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.129906 11654 net.cpp:137] Memory required for data: 140378880
I0523 21:53:40.129915 11654 layer_factory.hpp:77] Creating layer relu1
I0523 21:53:40.129926 11654 net.cpp:84] Creating Layer relu1
I0523 21:53:40.129931 11654 net.cpp:406] relu1 <- conv1
I0523 21:53:40.129945 11654 net.cpp:367] relu1 -> conv1 (in-place)
I0523 21:53:40.131722 11654 net.cpp:122] Setting up relu1
I0523 21:53:40.131738 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.131743 11654 net.cpp:137] Memory required for data: 184419072
I0523 21:53:40.131749 11654 layer_factory.hpp:77] Creating layer conv1_dw
I0523 21:53:40.131770 11654 net.cpp:84] Creating Layer conv1_dw
I0523 21:53:40.131775 11654 net.cpp:406] conv1_dw <- conv1
I0523 21:53:40.131783 11654 net.cpp:380] conv1_dw -> conv1_dw
I0523 21:53:40.133514 11654 net.cpp:122] Setting up conv1_dw
I0523 21:53:40.133528 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.133532 11654 net.cpp:137] Memory required for data: 228459264
I0523 21:53:40.133553 11654 layer_factory.hpp:77] Creating layer conv1_dw/bn
I0523 21:53:40.133561 11654 net.cpp:84] Creating Layer conv1_dw/bn
I0523 21:53:40.133568 11654 net.cpp:406] conv1_dw/bn <- conv1_dw
I0523 21:53:40.133574 11654 net.cpp:367] conv1_dw/bn -> conv1_dw (in-place)
I0523 21:53:40.133776 11654 net.cpp:122] Setting up conv1_dw/bn
I0523 21:53:40.133783 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.133787 11654 net.cpp:137] Memory required for data: 272499456
I0523 21:53:40.133800 11654 layer_factory.hpp:77] Creating layer conv1_dw/scale
I0523 21:53:40.133810 11654 net.cpp:84] Creating Layer conv1_dw/scale
I0523 21:53:40.133814 11654 net.cpp:406] conv1_dw/scale <- conv1_dw
I0523 21:53:40.133821 11654 net.cpp:367] conv1_dw/scale -> conv1_dw (in-place)
I0523 21:53:40.133857 11654 layer_factory.hpp:77] Creating layer conv1_dw/scale
I0523 21:53:40.133958 11654 net.cpp:122] Setting up conv1_dw/scale
I0523 21:53:40.133987 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.133991 11654 net.cpp:137] Memory required for data: 316539648
I0523 21:53:40.133998 11654 layer_factory.hpp:77] Creating layer relu1_dw
I0523 21:53:40.134006 11654 net.cpp:84] Creating Layer relu1_dw
I0523 21:53:40.134009 11654 net.cpp:406] relu1_dw <- conv1_dw
I0523 21:53:40.134014 11654 net.cpp:367] relu1_dw -> conv1_dw (in-place)
I0523 21:53:40.134220 11654 net.cpp:122] Setting up relu1_dw
I0523 21:53:40.134228 11654 net.cpp:129] Top shape: 64 64 56 48 (11010048)
I0523 21:53:40.134232 11654 net.cpp:137] Memory required for data: 360579840
I0523 21:53:40.134236 11654 layer_factory.hpp:77] Creating layer conv2_ex
I0523 21:53:40.134246 11654 net.cpp:84] Creating Layer conv2_ex
I0523 21:53:40.134250 11654 net.cpp:406] conv2_ex <- conv1_dw
I0523 21:53:40.134256 11654 net.cpp:380] conv2_ex -> conv2_ex
I0523 21:53:40.136838 11654 net.cpp:122] Setting up conv2_ex
I0523 21:53:40.136853 11654 net.cpp:129] Top shape: 64 128 56 48 (22020096)
I0523 21:53:40.136857 11654 net.cpp:137] Memory required for data: 448660224
I0523 21:53:40.136862 11654 layer_factory.hpp:77] Creating layer conv2_ex/bn
I0523 21:53:40.136868 11654 net.cpp:84] Creating Layer conv2_ex/bn
I0523 21:53:40.136873 11654 net.cpp:406] conv2_ex/bn <- conv2_ex
I0523 21:53:40.136878 11654 net.cpp:367] conv2_ex/bn -> conv2_ex (in-place)
I0523 21:53:40.137064 11654 net.cpp:122] Setting up conv2_ex/bn
I0523 21:53:40.137073 11654 net.cpp:129] Top shape: 64 128 56 48 (22020096)
I0523 21:53:40.137076 11654 net.cpp:137] Memory required for data: 536740608
I0523 21:53:40.137089 11654 layer_factory.hpp:77] Creating layer conv2_ex/scale
I0523 21:53:40.137097 11654 net.cpp:84] Creating Layer conv2_ex/scale
I0523 21:53:40.137101 11654 net.cpp:406] conv2_ex/scale <- conv2_ex
I0523 21:53:40.137106 11654 net.cpp:367] conv2_ex/scale -> conv2_ex (in-place)
I0523 21:53:40.137141 11654 layer_factory.hpp:77] Creating layer conv2_ex/scale
I0523 21:53:40.137235 11654 net.cpp:122] Setting up conv2_ex/scale
I0523 21:53:40.137243 11654 net.cpp:129] Top shape: 64 128 56 48 (22020096)
I0523 21:53:40.137246 11654 net.cpp:137] Memory required for data: 624820992
I0523 21:53:40.137251 11654 layer_factory.hpp:77] Creating layer relu2_ex
I0523 21:53:40.137256 11654 net.cpp:84] Creating Layer relu2_ex
I0523 21:53:40.137259 11654 net.cpp:406] relu2_ex <- conv2_ex
I0523 21:53:40.137264 11654 net.cpp:367] relu2_ex -> conv2_ex (in-place)
I0523 21:53:40.139058 11654 net.cpp:122] Setting up relu2_ex
I0523 21:53:40.139075 11654 net.cpp:129] Top shape: 64 128 56 48 (22020096)
I0523 21:53:40.139078 11654 net.cpp:137] Memory required for data: 712901376
I0523 21:53:40.139083 11654 layer_factory.hpp:77] Creating layer conv2_dw
I0523 21:53:40.139096 11654 net.cpp:84] Creating Layer conv2_dw
I0523 21:53:40.139101 11654 net.cpp:406] conv2_dw <- conv2_ex
I0523 21:53:40.139108 11654 net.cpp:380] conv2_dw -> conv2_dw
I0523 21:53:40.139288 11654 net.cpp:122] Setting up conv2_dw
I0523 21:53:40.139302 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.139304 11654 net.cpp:137] Memory required for data: 734921472
I0523 21:53:40.139309 11654 layer_factory.hpp:77] Creating layer conv2_dw/bn
I0523 21:53:40.139317 11654 net.cpp:84] Creating Layer conv2_dw/bn
I0523 21:53:40.139322 11654 net.cpp:406] conv2_dw/bn <- conv2_dw
I0523 21:53:40.139327 11654 net.cpp:367] conv2_dw/bn -> conv2_dw (in-place)
I0523 21:53:40.139489 11654 net.cpp:122] Setting up conv2_dw/bn
I0523 21:53:40.139497 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.139500 11654 net.cpp:137] Memory required for data: 756941568
I0523 21:53:40.139508 11654 layer_factory.hpp:77] Creating layer conv2_dw/scale
I0523 21:53:40.139515 11654 net.cpp:84] Creating Layer conv2_dw/scale
I0523 21:53:40.139518 11654 net.cpp:406] conv2_dw/scale <- conv2_dw
I0523 21:53:40.139523 11654 net.cpp:367] conv2_dw/scale -> conv2_dw (in-place)
I0523 21:53:40.139557 11654 layer_factory.hpp:77] Creating layer conv2_dw/scale
I0523 21:53:40.139668 11654 net.cpp:122] Setting up conv2_dw/scale
I0523 21:53:40.139689 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.139693 11654 net.cpp:137] Memory required for data: 778961664
I0523 21:53:40.139698 11654 layer_factory.hpp:77] Creating layer relu2_dw
I0523 21:53:40.139703 11654 net.cpp:84] Creating Layer relu2_dw
I0523 21:53:40.139708 11654 net.cpp:406] relu2_dw <- conv2_dw
I0523 21:53:40.139711 11654 net.cpp:367] relu2_dw -> conv2_dw (in-place)
I0523 21:53:40.139840 11654 net.cpp:122] Setting up relu2_dw
I0523 21:53:40.139848 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.139852 11654 net.cpp:137] Memory required for data: 800981760
I0523 21:53:40.139855 11654 layer_factory.hpp:77] Creating layer conv2_em
I0523 21:53:40.139866 11654 net.cpp:84] Creating Layer conv2_em
I0523 21:53:40.139873 11654 net.cpp:406] conv2_em <- conv2_dw
I0523 21:53:40.139879 11654 net.cpp:380] conv2_em -> conv2_em
I0523 21:53:40.140923 11654 net.cpp:122] Setting up conv2_em
I0523 21:53:40.140938 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.140957 11654 net.cpp:137] Memory required for data: 811991808
I0523 21:53:40.140965 11654 layer_factory.hpp:77] Creating layer conv2_em/bn
I0523 21:53:40.140974 11654 net.cpp:84] Creating Layer conv2_em/bn
I0523 21:53:40.140992 11654 net.cpp:406] conv2_em/bn <- conv2_em
I0523 21:53:40.140998 11654 net.cpp:367] conv2_em/bn -> conv2_em (in-place)
I0523 21:53:40.141175 11654 net.cpp:122] Setting up conv2_em/bn
I0523 21:53:40.141185 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.141187 11654 net.cpp:137] Memory required for data: 823001856
I0523 21:53:40.141194 11654 layer_factory.hpp:77] Creating layer conv2_em/scale
I0523 21:53:40.141201 11654 net.cpp:84] Creating Layer conv2_em/scale
I0523 21:53:40.141206 11654 net.cpp:406] conv2_em/scale <- conv2_em
I0523 21:53:40.141212 11654 net.cpp:367] conv2_em/scale -> conv2_em (in-place)
I0523 21:53:40.141265 11654 layer_factory.hpp:77] Creating layer conv2_em/scale
I0523 21:53:40.141381 11654 net.cpp:122] Setting up conv2_em/scale
I0523 21:53:40.141388 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.141391 11654 net.cpp:137] Memory required for data: 834011904
I0523 21:53:40.141402 11654 layer_factory.hpp:77] Creating layer conv2_em_conv2_em/scale_0_split
I0523 21:53:40.141418 11654 net.cpp:84] Creating Layer conv2_em_conv2_em/scale_0_split
I0523 21:53:40.141422 11654 net.cpp:406] conv2_em_conv2_em/scale_0_split <- conv2_em
I0523 21:53:40.141427 11654 net.cpp:380] conv2_em_conv2_em/scale_0_split -> conv2_em_conv2_em/scale_0_split_0
I0523 21:53:40.141433 11654 net.cpp:380] conv2_em_conv2_em/scale_0_split -> conv2_em_conv2_em/scale_0_split_1
I0523 21:53:40.141469 11654 net.cpp:122] Setting up conv2_em_conv2_em/scale_0_split
I0523 21:53:40.141475 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.141479 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.141482 11654 net.cpp:137] Memory required for data: 856032000
I0523 21:53:40.141485 11654 layer_factory.hpp:77] Creating layer conv2_1_ex
I0523 21:53:40.141495 11654 net.cpp:84] Creating Layer conv2_1_ex
I0523 21:53:40.141501 11654 net.cpp:406] conv2_1_ex <- conv2_em_conv2_em/scale_0_split_0
I0523 21:53:40.141507 11654 net.cpp:380] conv2_1_ex -> conv2_1_ex
I0523 21:53:40.142558 11654 net.cpp:122] Setting up conv2_1_ex
I0523 21:53:40.142573 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.142593 11654 net.cpp:137] Memory required for data: 878052096
I0523 21:53:40.142601 11654 layer_factory.hpp:77] Creating layer conv2_1_ex/bn
I0523 21:53:40.142608 11654 net.cpp:84] Creating Layer conv2_1_ex/bn
I0523 21:53:40.142614 11654 net.cpp:406] conv2_1_ex/bn <- conv2_1_ex
I0523 21:53:40.142621 11654 net.cpp:367] conv2_1_ex/bn -> conv2_1_ex (in-place)
I0523 21:53:40.142818 11654 net.cpp:122] Setting up conv2_1_ex/bn
I0523 21:53:40.142827 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.142830 11654 net.cpp:137] Memory required for data: 900072192
I0523 21:53:40.142838 11654 layer_factory.hpp:77] Creating layer conv2_1_ex/scale
I0523 21:53:40.142858 11654 net.cpp:84] Creating Layer conv2_1_ex/scale
I0523 21:53:40.142863 11654 net.cpp:406] conv2_1_ex/scale <- conv2_1_ex
I0523 21:53:40.142870 11654 net.cpp:367] conv2_1_ex/scale -> conv2_1_ex (in-place)
I0523 21:53:40.142911 11654 layer_factory.hpp:77] Creating layer conv2_1_ex/scale
I0523 21:53:40.143013 11654 net.cpp:122] Setting up conv2_1_ex/scale
I0523 21:53:40.143026 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.143030 11654 net.cpp:137] Memory required for data: 922092288
I0523 21:53:40.143035 11654 layer_factory.hpp:77] Creating layer relu2_1_ex
I0523 21:53:40.143043 11654 net.cpp:84] Creating Layer relu2_1_ex
I0523 21:53:40.143048 11654 net.cpp:406] relu2_1_ex <- conv2_1_ex
I0523 21:53:40.143051 11654 net.cpp:367] relu2_1_ex -> conv2_1_ex (in-place)
I0523 21:53:40.143185 11654 net.cpp:122] Setting up relu2_1_ex
I0523 21:53:40.143194 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.143198 11654 net.cpp:137] Memory required for data: 944112384
I0523 21:53:40.143201 11654 layer_factory.hpp:77] Creating layer conv2_1_dw
I0523 21:53:40.143211 11654 net.cpp:84] Creating Layer conv2_1_dw
I0523 21:53:40.143218 11654 net.cpp:406] conv2_1_dw <- conv2_1_ex
I0523 21:53:40.143223 11654 net.cpp:380] conv2_1_dw -> conv2_1_dw
I0523 21:53:40.143404 11654 net.cpp:122] Setting up conv2_1_dw
I0523 21:53:40.143412 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.143415 11654 net.cpp:137] Memory required for data: 966132480
I0523 21:53:40.143420 11654 layer_factory.hpp:77] Creating layer conv2_1_dw/bn
I0523 21:53:40.143427 11654 net.cpp:84] Creating Layer conv2_1_dw/bn
I0523 21:53:40.143430 11654 net.cpp:406] conv2_1_dw/bn <- conv2_1_dw
I0523 21:53:40.143435 11654 net.cpp:367] conv2_1_dw/bn -> conv2_1_dw (in-place)
I0523 21:53:40.143617 11654 net.cpp:122] Setting up conv2_1_dw/bn
I0523 21:53:40.143625 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.143628 11654 net.cpp:137] Memory required for data: 988152576
I0523 21:53:40.143635 11654 layer_factory.hpp:77] Creating layer conv2_1_dw/scale
I0523 21:53:40.143641 11654 net.cpp:84] Creating Layer conv2_1_dw/scale
I0523 21:53:40.143646 11654 net.cpp:406] conv2_1_dw/scale <- conv2_1_dw
I0523 21:53:40.143651 11654 net.cpp:367] conv2_1_dw/scale -> conv2_1_dw (in-place)
I0523 21:53:40.143683 11654 layer_factory.hpp:77] Creating layer conv2_1_dw/scale
I0523 21:53:40.143780 11654 net.cpp:122] Setting up conv2_1_dw/scale
I0523 21:53:40.143788 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.143791 11654 net.cpp:137] Memory required for data: 1010172672
I0523 21:53:40.143796 11654 layer_factory.hpp:77] Creating layer relu2_1_dw
I0523 21:53:40.143801 11654 net.cpp:84] Creating Layer relu2_1_dw
I0523 21:53:40.143805 11654 net.cpp:406] relu2_1_dw <- conv2_1_dw
I0523 21:53:40.143810 11654 net.cpp:367] relu2_1_dw -> conv2_1_dw (in-place)
I0523 21:53:40.143945 11654 net.cpp:122] Setting up relu2_1_dw
I0523 21:53:40.143954 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.143956 11654 net.cpp:137] Memory required for data: 1032192768
I0523 21:53:40.143961 11654 layer_factory.hpp:77] Creating layer conv2_1_em
I0523 21:53:40.143970 11654 net.cpp:84] Creating Layer conv2_1_em
I0523 21:53:40.143973 11654 net.cpp:406] conv2_1_em <- conv2_1_dw
I0523 21:53:40.143980 11654 net.cpp:380] conv2_1_em -> conv2_1_em
I0523 21:53:40.145051 11654 net.cpp:122] Setting up conv2_1_em
I0523 21:53:40.145066 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.145087 11654 net.cpp:137] Memory required for data: 1043202816
I0523 21:53:40.145092 11654 layer_factory.hpp:77] Creating layer conv2_1_em/bn
I0523 21:53:40.145102 11654 net.cpp:84] Creating Layer conv2_1_em/bn
I0523 21:53:40.145107 11654 net.cpp:406] conv2_1_em/bn <- conv2_1_em
I0523 21:53:40.145112 11654 net.cpp:367] conv2_1_em/bn -> conv2_1_em (in-place)
I0523 21:53:40.145296 11654 net.cpp:122] Setting up conv2_1_em/bn
I0523 21:53:40.145304 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.145320 11654 net.cpp:137] Memory required for data: 1054212864
I0523 21:53:40.145344 11654 layer_factory.hpp:77] Creating layer conv2_1_em/scale
I0523 21:53:40.145354 11654 net.cpp:84] Creating Layer conv2_1_em/scale
I0523 21:53:40.145359 11654 net.cpp:406] conv2_1_em/scale <- conv2_1_em
I0523 21:53:40.145364 11654 net.cpp:367] conv2_1_em/scale -> conv2_1_em (in-place)
I0523 21:53:40.145402 11654 layer_factory.hpp:77] Creating layer conv2_1_em/scale
I0523 21:53:40.145509 11654 net.cpp:122] Setting up conv2_1_em/scale
I0523 21:53:40.145515 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.145519 11654 net.cpp:137] Memory required for data: 1065222912
I0523 21:53:40.145524 11654 layer_factory.hpp:77] Creating layer res2_1
I0523 21:53:40.145529 11654 net.cpp:84] Creating Layer res2_1
I0523 21:53:40.145534 11654 net.cpp:406] res2_1 <- conv2_em_conv2_em/scale_0_split_1
I0523 21:53:40.145539 11654 net.cpp:406] res2_1 <- conv2_1_em
I0523 21:53:40.145543 11654 net.cpp:380] res2_1 -> res2_1
I0523 21:53:40.145566 11654 net.cpp:122] Setting up res2_1
I0523 21:53:40.145572 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.145576 11654 net.cpp:137] Memory required for data: 1076232960
I0523 21:53:40.145581 11654 layer_factory.hpp:77] Creating layer res2_1_res2_1_0_split
I0523 21:53:40.145586 11654 net.cpp:84] Creating Layer res2_1_res2_1_0_split
I0523 21:53:40.145588 11654 net.cpp:406] res2_1_res2_1_0_split <- res2_1
I0523 21:53:40.145593 11654 net.cpp:380] res2_1_res2_1_0_split -> res2_1_res2_1_0_split_0
I0523 21:53:40.145598 11654 net.cpp:380] res2_1_res2_1_0_split -> res2_1_res2_1_0_split_1
I0523 21:53:40.145629 11654 net.cpp:122] Setting up res2_1_res2_1_0_split
I0523 21:53:40.145635 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.145640 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.145642 11654 net.cpp:137] Memory required for data: 1098253056
I0523 21:53:40.145645 11654 layer_factory.hpp:77] Creating layer conv2_2_ex
I0523 21:53:40.145655 11654 net.cpp:84] Creating Layer conv2_2_ex
I0523 21:53:40.145660 11654 net.cpp:406] conv2_2_ex <- res2_1_res2_1_0_split_0
I0523 21:53:40.145666 11654 net.cpp:380] conv2_2_ex -> conv2_2_ex
I0523 21:53:40.146764 11654 net.cpp:122] Setting up conv2_2_ex
I0523 21:53:40.146780 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.146783 11654 net.cpp:137] Memory required for data: 1120273152
I0523 21:53:40.146790 11654 layer_factory.hpp:77] Creating layer conv2_2_ex/bn
I0523 21:53:40.146797 11654 net.cpp:84] Creating Layer conv2_2_ex/bn
I0523 21:53:40.146801 11654 net.cpp:406] conv2_2_ex/bn <- conv2_2_ex
I0523 21:53:40.146807 11654 net.cpp:367] conv2_2_ex/bn -> conv2_2_ex (in-place)
I0523 21:53:40.146986 11654 net.cpp:122] Setting up conv2_2_ex/bn
I0523 21:53:40.146994 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.146998 11654 net.cpp:137] Memory required for data: 1142293248
I0523 21:53:40.147006 11654 layer_factory.hpp:77] Creating layer conv2_2_ex/scale
I0523 21:53:40.147017 11654 net.cpp:84] Creating Layer conv2_2_ex/scale
I0523 21:53:40.147019 11654 net.cpp:406] conv2_2_ex/scale <- conv2_2_ex
I0523 21:53:40.147025 11654 net.cpp:367] conv2_2_ex/scale -> conv2_2_ex (in-place)
I0523 21:53:40.147063 11654 layer_factory.hpp:77] Creating layer conv2_2_ex/scale
I0523 21:53:40.147163 11654 net.cpp:122] Setting up conv2_2_ex/scale
I0523 21:53:40.147171 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.147174 11654 net.cpp:137] Memory required for data: 1164313344
I0523 21:53:40.147181 11654 layer_factory.hpp:77] Creating layer relu2_2_ex
I0523 21:53:40.147187 11654 net.cpp:84] Creating Layer relu2_2_ex
I0523 21:53:40.147192 11654 net.cpp:406] relu2_2_ex <- conv2_2_ex
I0523 21:53:40.147197 11654 net.cpp:367] relu2_2_ex -> conv2_2_ex (in-place)
I0523 21:53:40.147341 11654 net.cpp:122] Setting up relu2_2_ex
I0523 21:53:40.147348 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.147351 11654 net.cpp:137] Memory required for data: 1186333440
I0523 21:53:40.147369 11654 layer_factory.hpp:77] Creating layer conv2_2_dw
I0523 21:53:40.147378 11654 net.cpp:84] Creating Layer conv2_2_dw
I0523 21:53:40.147382 11654 net.cpp:406] conv2_2_dw <- conv2_2_ex
I0523 21:53:40.147387 11654 net.cpp:380] conv2_2_dw -> conv2_2_dw
I0523 21:53:40.147581 11654 net.cpp:122] Setting up conv2_2_dw
I0523 21:53:40.147589 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.147593 11654 net.cpp:137] Memory required for data: 1208353536
I0523 21:53:40.147598 11654 layer_factory.hpp:77] Creating layer conv2_2_dw/bn
I0523 21:53:40.147603 11654 net.cpp:84] Creating Layer conv2_2_dw/bn
I0523 21:53:40.147606 11654 net.cpp:406] conv2_2_dw/bn <- conv2_2_dw
I0523 21:53:40.147613 11654 net.cpp:367] conv2_2_dw/bn -> conv2_2_dw (in-place)
I0523 21:53:40.147775 11654 net.cpp:122] Setting up conv2_2_dw/bn
I0523 21:53:40.147783 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.147785 11654 net.cpp:137] Memory required for data: 1230373632
I0523 21:53:40.147800 11654 layer_factory.hpp:77] Creating layer conv2_2_dw/scale
I0523 21:53:40.147809 11654 net.cpp:84] Creating Layer conv2_2_dw/scale
I0523 21:53:40.147814 11654 net.cpp:406] conv2_2_dw/scale <- conv2_2_dw
I0523 21:53:40.147819 11654 net.cpp:367] conv2_2_dw/scale -> conv2_2_dw (in-place)
I0523 21:53:40.147853 11654 layer_factory.hpp:77] Creating layer conv2_2_dw/scale
I0523 21:53:40.147950 11654 net.cpp:122] Setting up conv2_2_dw/scale
I0523 21:53:40.147958 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.147961 11654 net.cpp:137] Memory required for data: 1252393728
I0523 21:53:40.147966 11654 layer_factory.hpp:77] Creating layer relu2_2_dw
I0523 21:53:40.147972 11654 net.cpp:84] Creating Layer relu2_2_dw
I0523 21:53:40.147975 11654 net.cpp:406] relu2_2_dw <- conv2_2_dw
I0523 21:53:40.147980 11654 net.cpp:367] relu2_2_dw -> conv2_2_dw (in-place)
I0523 21:53:40.149590 11654 net.cpp:122] Setting up relu2_2_dw
I0523 21:53:40.149605 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.149608 11654 net.cpp:137] Memory required for data: 1274413824
I0523 21:53:40.149615 11654 layer_factory.hpp:77] Creating layer conv2_2_em
I0523 21:53:40.149626 11654 net.cpp:84] Creating Layer conv2_2_em
I0523 21:53:40.149631 11654 net.cpp:406] conv2_2_em <- conv2_2_dw
I0523 21:53:40.149637 11654 net.cpp:380] conv2_2_em -> conv2_2_em
I0523 21:53:40.150750 11654 net.cpp:122] Setting up conv2_2_em
I0523 21:53:40.150765 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.150770 11654 net.cpp:137] Memory required for data: 1285423872
I0523 21:53:40.150775 11654 layer_factory.hpp:77] Creating layer conv2_2_em/bn
I0523 21:53:40.150786 11654 net.cpp:84] Creating Layer conv2_2_em/bn
I0523 21:53:40.150790 11654 net.cpp:406] conv2_2_em/bn <- conv2_2_em
I0523 21:53:40.150797 11654 net.cpp:367] conv2_2_em/bn -> conv2_2_em (in-place)
I0523 21:53:40.150990 11654 net.cpp:122] Setting up conv2_2_em/bn
I0523 21:53:40.150998 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.151002 11654 net.cpp:137] Memory required for data: 1296433920
I0523 21:53:40.151010 11654 layer_factory.hpp:77] Creating layer conv2_2_em/scale
I0523 21:53:40.151020 11654 net.cpp:84] Creating Layer conv2_2_em/scale
I0523 21:53:40.151026 11654 net.cpp:406] conv2_2_em/scale <- conv2_2_em
I0523 21:53:40.151031 11654 net.cpp:367] conv2_2_em/scale -> conv2_2_em (in-place)
I0523 21:53:40.151069 11654 layer_factory.hpp:77] Creating layer conv2_2_em/scale
I0523 21:53:40.151182 11654 net.cpp:122] Setting up conv2_2_em/scale
I0523 21:53:40.151190 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.151193 11654 net.cpp:137] Memory required for data: 1307443968
I0523 21:53:40.151198 11654 layer_factory.hpp:77] Creating layer res2_2
I0523 21:53:40.151204 11654 net.cpp:84] Creating Layer res2_2
I0523 21:53:40.151208 11654 net.cpp:406] res2_2 <- res2_1_res2_1_0_split_1
I0523 21:53:40.151213 11654 net.cpp:406] res2_2 <- conv2_2_em
I0523 21:53:40.151218 11654 net.cpp:380] res2_2 -> res2_2
I0523 21:53:40.151257 11654 net.cpp:122] Setting up res2_2
I0523 21:53:40.151264 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.151268 11654 net.cpp:137] Memory required for data: 1318454016
I0523 21:53:40.151270 11654 layer_factory.hpp:77] Creating layer res2_2_res2_2_0_split
I0523 21:53:40.151276 11654 net.cpp:84] Creating Layer res2_2_res2_2_0_split
I0523 21:53:40.151279 11654 net.cpp:406] res2_2_res2_2_0_split <- res2_2
I0523 21:53:40.151284 11654 net.cpp:380] res2_2_res2_2_0_split -> res2_2_res2_2_0_split_0
I0523 21:53:40.151290 11654 net.cpp:380] res2_2_res2_2_0_split -> res2_2_res2_2_0_split_1
I0523 21:53:40.151322 11654 net.cpp:122] Setting up res2_2_res2_2_0_split
I0523 21:53:40.151329 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.151334 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.151336 11654 net.cpp:137] Memory required for data: 1340474112
I0523 21:53:40.151340 11654 layer_factory.hpp:77] Creating layer conv2_3_ex
I0523 21:53:40.151350 11654 net.cpp:84] Creating Layer conv2_3_ex
I0523 21:53:40.151355 11654 net.cpp:406] conv2_3_ex <- res2_2_res2_2_0_split_0
I0523 21:53:40.151361 11654 net.cpp:380] conv2_3_ex -> conv2_3_ex
I0523 21:53:40.152478 11654 net.cpp:122] Setting up conv2_3_ex
I0523 21:53:40.152493 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.152498 11654 net.cpp:137] Memory required for data: 1362494208
I0523 21:53:40.152503 11654 layer_factory.hpp:77] Creating layer conv2_3_ex/bn
I0523 21:53:40.152513 11654 net.cpp:84] Creating Layer conv2_3_ex/bn
I0523 21:53:40.152515 11654 net.cpp:406] conv2_3_ex/bn <- conv2_3_ex
I0523 21:53:40.152521 11654 net.cpp:367] conv2_3_ex/bn -> conv2_3_ex (in-place)
I0523 21:53:40.152700 11654 net.cpp:122] Setting up conv2_3_ex/bn
I0523 21:53:40.152709 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.152711 11654 net.cpp:137] Memory required for data: 1384514304
I0523 21:53:40.152719 11654 layer_factory.hpp:77] Creating layer conv2_3_ex/scale
I0523 21:53:40.152725 11654 net.cpp:84] Creating Layer conv2_3_ex/scale
I0523 21:53:40.152729 11654 net.cpp:406] conv2_3_ex/scale <- conv2_3_ex
I0523 21:53:40.152734 11654 net.cpp:367] conv2_3_ex/scale -> conv2_3_ex (in-place)
I0523 21:53:40.152770 11654 layer_factory.hpp:77] Creating layer conv2_3_ex/scale
I0523 21:53:40.152874 11654 net.cpp:122] Setting up conv2_3_ex/scale
I0523 21:53:40.152882 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.152885 11654 net.cpp:137] Memory required for data: 1406534400
I0523 21:53:40.152890 11654 layer_factory.hpp:77] Creating layer relu2_3_ex
I0523 21:53:40.152896 11654 net.cpp:84] Creating Layer relu2_3_ex
I0523 21:53:40.152899 11654 net.cpp:406] relu2_3_ex <- conv2_3_ex
I0523 21:53:40.152904 11654 net.cpp:367] relu2_3_ex -> conv2_3_ex (in-place)
I0523 21:53:40.153035 11654 net.cpp:122] Setting up relu2_3_ex
I0523 21:53:40.153043 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.153045 11654 net.cpp:137] Memory required for data: 1428554496
I0523 21:53:40.153053 11654 layer_factory.hpp:77] Creating layer conv2_3_dw
I0523 21:53:40.153061 11654 net.cpp:84] Creating Layer conv2_3_dw
I0523 21:53:40.153066 11654 net.cpp:406] conv2_3_dw <- conv2_3_ex
I0523 21:53:40.153072 11654 net.cpp:380] conv2_3_dw -> conv2_3_dw
I0523 21:53:40.153273 11654 net.cpp:122] Setting up conv2_3_dw
I0523 21:53:40.153281 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.153285 11654 net.cpp:137] Memory required for data: 1450574592
I0523 21:53:40.153288 11654 layer_factory.hpp:77] Creating layer conv2_3_dw/bn
I0523 21:53:40.153295 11654 net.cpp:84] Creating Layer conv2_3_dw/bn
I0523 21:53:40.153298 11654 net.cpp:406] conv2_3_dw/bn <- conv2_3_dw
I0523 21:53:40.153304 11654 net.cpp:367] conv2_3_dw/bn -> conv2_3_dw (in-place)
I0523 21:53:40.153481 11654 net.cpp:122] Setting up conv2_3_dw/bn
I0523 21:53:40.153502 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.153506 11654 net.cpp:137] Memory required for data: 1472594688
I0523 21:53:40.153512 11654 layer_factory.hpp:77] Creating layer conv2_3_dw/scale
I0523 21:53:40.153530 11654 net.cpp:84] Creating Layer conv2_3_dw/scale
I0523 21:53:40.153534 11654 net.cpp:406] conv2_3_dw/scale <- conv2_3_dw
I0523 21:53:40.153539 11654 net.cpp:367] conv2_3_dw/scale -> conv2_3_dw (in-place)
I0523 21:53:40.153576 11654 layer_factory.hpp:77] Creating layer conv2_3_dw/scale
I0523 21:53:40.153676 11654 net.cpp:122] Setting up conv2_3_dw/scale
I0523 21:53:40.153684 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.153687 11654 net.cpp:137] Memory required for data: 1494614784
I0523 21:53:40.153692 11654 layer_factory.hpp:77] Creating layer relu2_3_dw
I0523 21:53:40.153699 11654 net.cpp:84] Creating Layer relu2_3_dw
I0523 21:53:40.153703 11654 net.cpp:406] relu2_3_dw <- conv2_3_dw
I0523 21:53:40.153707 11654 net.cpp:367] relu2_3_dw -> conv2_3_dw (in-place)
I0523 21:53:40.153841 11654 net.cpp:122] Setting up relu2_3_dw
I0523 21:53:40.153848 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.153851 11654 net.cpp:137] Memory required for data: 1516634880
I0523 21:53:40.153857 11654 layer_factory.hpp:77] Creating layer conv2_3_em
I0523 21:53:40.153865 11654 net.cpp:84] Creating Layer conv2_3_em
I0523 21:53:40.153872 11654 net.cpp:406] conv2_3_em <- conv2_3_dw
I0523 21:53:40.153877 11654 net.cpp:380] conv2_3_em -> conv2_3_em
I0523 21:53:40.155004 11654 net.cpp:122] Setting up conv2_3_em
I0523 21:53:40.155035 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.155040 11654 net.cpp:137] Memory required for data: 1527644928
I0523 21:53:40.155059 11654 layer_factory.hpp:77] Creating layer conv2_3_em/bn
I0523 21:53:40.155068 11654 net.cpp:84] Creating Layer conv2_3_em/bn
I0523 21:53:40.155072 11654 net.cpp:406] conv2_3_em/bn <- conv2_3_em
I0523 21:53:40.155079 11654 net.cpp:367] conv2_3_em/bn -> conv2_3_em (in-place)
I0523 21:53:40.155277 11654 net.cpp:122] Setting up conv2_3_em/bn
I0523 21:53:40.155284 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.155288 11654 net.cpp:137] Memory required for data: 1538654976
I0523 21:53:40.155295 11654 layer_factory.hpp:77] Creating layer conv2_3_em/scale
I0523 21:53:40.155306 11654 net.cpp:84] Creating Layer conv2_3_em/scale
I0523 21:53:40.155313 11654 net.cpp:406] conv2_3_em/scale <- conv2_3_em
I0523 21:53:40.155318 11654 net.cpp:367] conv2_3_em/scale -> conv2_3_em (in-place)
I0523 21:53:40.155359 11654 layer_factory.hpp:77] Creating layer conv2_3_em/scale
I0523 21:53:40.155472 11654 net.cpp:122] Setting up conv2_3_em/scale
I0523 21:53:40.155479 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.155483 11654 net.cpp:137] Memory required for data: 1549665024
I0523 21:53:40.155488 11654 layer_factory.hpp:77] Creating layer res2_3
I0523 21:53:40.155496 11654 net.cpp:84] Creating Layer res2_3
I0523 21:53:40.155500 11654 net.cpp:406] res2_3 <- res2_2_res2_2_0_split_1
I0523 21:53:40.155505 11654 net.cpp:406] res2_3 <- conv2_3_em
I0523 21:53:40.155510 11654 net.cpp:380] res2_3 -> res2_3
I0523 21:53:40.155534 11654 net.cpp:122] Setting up res2_3
I0523 21:53:40.155540 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.155544 11654 net.cpp:137] Memory required for data: 1560675072
I0523 21:53:40.155546 11654 layer_factory.hpp:77] Creating layer res2_3_res2_3_0_split
I0523 21:53:40.155552 11654 net.cpp:84] Creating Layer res2_3_res2_3_0_split
I0523 21:53:40.155555 11654 net.cpp:406] res2_3_res2_3_0_split <- res2_3
I0523 21:53:40.155560 11654 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_0
I0523 21:53:40.155566 11654 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_1
I0523 21:53:40.155622 11654 net.cpp:122] Setting up res2_3_res2_3_0_split
I0523 21:53:40.155628 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.155632 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.155635 11654 net.cpp:137] Memory required for data: 1582695168
I0523 21:53:40.155638 11654 layer_factory.hpp:77] Creating layer conv2_4_ex
I0523 21:53:40.155648 11654 net.cpp:84] Creating Layer conv2_4_ex
I0523 21:53:40.155680 11654 net.cpp:406] conv2_4_ex <- res2_3_res2_3_0_split_0
I0523 21:53:40.155688 11654 net.cpp:380] conv2_4_ex -> conv2_4_ex
I0523 21:53:40.156791 11654 net.cpp:122] Setting up conv2_4_ex
I0523 21:53:40.156807 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.156811 11654 net.cpp:137] Memory required for data: 1604715264
I0523 21:53:40.156817 11654 layer_factory.hpp:77] Creating layer conv2_4_ex/bn
I0523 21:53:40.156826 11654 net.cpp:84] Creating Layer conv2_4_ex/bn
I0523 21:53:40.156831 11654 net.cpp:406] conv2_4_ex/bn <- conv2_4_ex
I0523 21:53:40.156836 11654 net.cpp:367] conv2_4_ex/bn -> conv2_4_ex (in-place)
I0523 21:53:40.157027 11654 net.cpp:122] Setting up conv2_4_ex/bn
I0523 21:53:40.157035 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.157038 11654 net.cpp:137] Memory required for data: 1626735360
I0523 21:53:40.157048 11654 layer_factory.hpp:77] Creating layer conv2_4_ex/scale
I0523 21:53:40.157057 11654 net.cpp:84] Creating Layer conv2_4_ex/scale
I0523 21:53:40.157060 11654 net.cpp:406] conv2_4_ex/scale <- conv2_4_ex
I0523 21:53:40.157065 11654 net.cpp:367] conv2_4_ex/scale -> conv2_4_ex (in-place)
I0523 21:53:40.157104 11654 layer_factory.hpp:77] Creating layer conv2_4_ex/scale
I0523 21:53:40.157212 11654 net.cpp:122] Setting up conv2_4_ex/scale
I0523 21:53:40.157219 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.157223 11654 net.cpp:137] Memory required for data: 1648755456
I0523 21:53:40.157228 11654 layer_factory.hpp:77] Creating layer relu2_4_ex
I0523 21:53:40.157239 11654 net.cpp:84] Creating Layer relu2_4_ex
I0523 21:53:40.157244 11654 net.cpp:406] relu2_4_ex <- conv2_4_ex
I0523 21:53:40.157249 11654 net.cpp:367] relu2_4_ex -> conv2_4_ex (in-place)
I0523 21:53:40.157387 11654 net.cpp:122] Setting up relu2_4_ex
I0523 21:53:40.157395 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.157398 11654 net.cpp:137] Memory required for data: 1670775552
I0523 21:53:40.157404 11654 layer_factory.hpp:77] Creating layer conv2_4_dw
I0523 21:53:40.157414 11654 net.cpp:84] Creating Layer conv2_4_dw
I0523 21:53:40.157419 11654 net.cpp:406] conv2_4_dw <- conv2_4_ex
I0523 21:53:40.157425 11654 net.cpp:380] conv2_4_dw -> conv2_4_dw
I0523 21:53:40.157619 11654 net.cpp:122] Setting up conv2_4_dw
I0523 21:53:40.157627 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.157630 11654 net.cpp:137] Memory required for data: 1692795648
I0523 21:53:40.157634 11654 layer_factory.hpp:77] Creating layer conv2_4_dw/bn
I0523 21:53:40.157641 11654 net.cpp:84] Creating Layer conv2_4_dw/bn
I0523 21:53:40.157644 11654 net.cpp:406] conv2_4_dw/bn <- conv2_4_dw
I0523 21:53:40.157650 11654 net.cpp:367] conv2_4_dw/bn -> conv2_4_dw (in-place)
I0523 21:53:40.157830 11654 net.cpp:122] Setting up conv2_4_dw/bn
I0523 21:53:40.157837 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.157841 11654 net.cpp:137] Memory required for data: 1714815744
I0523 21:53:40.157850 11654 layer_factory.hpp:77] Creating layer conv2_4_dw/scale
I0523 21:53:40.157857 11654 net.cpp:84] Creating Layer conv2_4_dw/scale
I0523 21:53:40.157860 11654 net.cpp:406] conv2_4_dw/scale <- conv2_4_dw
I0523 21:53:40.157866 11654 net.cpp:367] conv2_4_dw/scale -> conv2_4_dw (in-place)
I0523 21:53:40.157903 11654 layer_factory.hpp:77] Creating layer conv2_4_dw/scale
I0523 21:53:40.158010 11654 net.cpp:122] Setting up conv2_4_dw/scale
I0523 21:53:40.158016 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.158020 11654 net.cpp:137] Memory required for data: 1736835840
I0523 21:53:40.158025 11654 layer_factory.hpp:77] Creating layer relu2_4_dw
I0523 21:53:40.158032 11654 net.cpp:84] Creating Layer relu2_4_dw
I0523 21:53:40.158035 11654 net.cpp:406] relu2_4_dw <- conv2_4_dw
I0523 21:53:40.158041 11654 net.cpp:367] relu2_4_dw -> conv2_4_dw (in-place)
I0523 21:53:40.158179 11654 net.cpp:122] Setting up relu2_4_dw
I0523 21:53:40.158185 11654 net.cpp:129] Top shape: 64 128 28 24 (5505024)
I0523 21:53:40.158190 11654 net.cpp:137] Memory required for data: 1758855936
I0523 21:53:40.158206 11654 layer_factory.hpp:77] Creating layer conv2_4_em
I0523 21:53:40.158216 11654 net.cpp:84] Creating Layer conv2_4_em
I0523 21:53:40.158222 11654 net.cpp:406] conv2_4_em <- conv2_4_dw
I0523 21:53:40.158227 11654 net.cpp:380] conv2_4_em -> conv2_4_em
I0523 21:53:40.159368 11654 net.cpp:122] Setting up conv2_4_em
I0523 21:53:40.159384 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.159389 11654 net.cpp:137] Memory required for data: 1769865984
I0523 21:53:40.159394 11654 layer_factory.hpp:77] Creating layer conv2_4_em/bn
I0523 21:53:40.159404 11654 net.cpp:84] Creating Layer conv2_4_em/bn
I0523 21:53:40.159407 11654 net.cpp:406] conv2_4_em/bn <- conv2_4_em
I0523 21:53:40.159415 11654 net.cpp:367] conv2_4_em/bn -> conv2_4_em (in-place)
I0523 21:53:40.159607 11654 net.cpp:122] Setting up conv2_4_em/bn
I0523 21:53:40.159615 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.159620 11654 net.cpp:137] Memory required for data: 1780876032
I0523 21:53:40.159626 11654 layer_factory.hpp:77] Creating layer conv2_4_em/scale
I0523 21:53:40.159634 11654 net.cpp:84] Creating Layer conv2_4_em/scale
I0523 21:53:40.159637 11654 net.cpp:406] conv2_4_em/scale <- conv2_4_em
I0523 21:53:40.159643 11654 net.cpp:367] conv2_4_em/scale -> conv2_4_em (in-place)
I0523 21:53:40.159682 11654 layer_factory.hpp:77] Creating layer conv2_4_em/scale
I0523 21:53:40.159795 11654 net.cpp:122] Setting up conv2_4_em/scale
I0523 21:53:40.159803 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.159806 11654 net.cpp:137] Memory required for data: 1791886080
I0523 21:53:40.159811 11654 layer_factory.hpp:77] Creating layer res2_4
I0523 21:53:40.159817 11654 net.cpp:84] Creating Layer res2_4
I0523 21:53:40.159821 11654 net.cpp:406] res2_4 <- res2_3_res2_3_0_split_1
I0523 21:53:40.159826 11654 net.cpp:406] res2_4 <- conv2_4_em
I0523 21:53:40.159832 11654 net.cpp:380] res2_4 -> res2_4
I0523 21:53:40.159857 11654 net.cpp:122] Setting up res2_4
I0523 21:53:40.159863 11654 net.cpp:129] Top shape: 64 64 28 24 (2752512)
I0523 21:53:40.159868 11654 net.cpp:137] Memory required for data: 1802896128
I0523 21:53:40.159869 11654 layer_factory.hpp:77] Creating layer conv3_ex
I0523 21:53:40.159880 11654 net.cpp:84] Creating Layer conv3_ex
I0523 21:53:40.159886 11654 net.cpp:406] conv3_ex <- res2_4
I0523 21:53:40.159893 11654 net.cpp:380] conv3_ex -> conv3_ex
I0523 21:53:40.161043 11654 net.cpp:122] Setting up conv3_ex
I0523 21:53:40.161058 11654 net.cpp:129] Top shape: 64 256 28 24 (11010048)
I0523 21:53:40.161062 11654 net.cpp:137] Memory required for data: 1846936320
I0523 21:53:40.161070 11654 layer_factory.hpp:77] Creating layer conv3_ex/bn
I0523 21:53:40.161078 11654 net.cpp:84] Creating Layer conv3_ex/bn
I0523 21:53:40.161082 11654 net.cpp:406] conv3_ex/bn <- conv3_ex
I0523 21:53:40.161089 11654 net.cpp:367] conv3_ex/bn -> conv3_ex (in-place)
I0523 21:53:40.161280 11654 net.cpp:122] Setting up conv3_ex/bn
I0523 21:53:40.161288 11654 net.cpp:129] Top shape: 64 256 28 24 (11010048)
I0523 21:53:40.161291 11654 net.cpp:137] Memory required for data: 1890976512
I0523 21:53:40.161299 11654 layer_factory.hpp:77] Creating layer conv3_ex/scale
I0523 21:53:40.161306 11654 net.cpp:84] Creating Layer conv3_ex/scale
I0523 21:53:40.161311 11654 net.cpp:406] conv3_ex/scale <- conv3_ex
I0523 21:53:40.161316 11654 net.cpp:367] conv3_ex/scale -> conv3_ex (in-place)
I0523 21:53:40.161356 11654 layer_factory.hpp:77] Creating layer conv3_ex/scale
I0523 21:53:40.161464 11654 net.cpp:122] Setting up conv3_ex/scale
I0523 21:53:40.161471 11654 net.cpp:129] Top shape: 64 256 28 24 (11010048)
I0523 21:53:40.161474 11654 net.cpp:137] Memory required for data: 1935016704
I0523 21:53:40.161480 11654 layer_factory.hpp:77] Creating layer relu3_ex
I0523 21:53:40.161486 11654 net.cpp:84] Creating Layer relu3_ex
I0523 21:53:40.161489 11654 net.cpp:406] relu3_ex <- conv3_ex
I0523 21:53:40.161494 11654 net.cpp:367] relu3_ex -> conv3_ex (in-place)
I0523 21:53:40.163229 11654 net.cpp:122] Setting up relu3_ex
I0523 21:53:40.163255 11654 net.cpp:129] Top shape: 64 256 28 24 (11010048)
I0523 21:53:40.163259 11654 net.cpp:137] Memory required for data: 1979056896
I0523 21:53:40.163280 11654 layer_factory.hpp:77] Creating layer conv3_dw
I0523 21:53:40.163295 11654 net.cpp:84] Creating Layer conv3_dw
I0523 21:53:40.163300 11654 net.cpp:406] conv3_dw <- conv3_ex
I0523 21:53:40.163306 11654 net.cpp:380] conv3_dw -> conv3_dw
I0523 21:53:40.163537 11654 net.cpp:122] Setting up conv3_dw
I0523 21:53:40.163547 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.163549 11654 net.cpp:137] Memory required for data: 1990066944
I0523 21:53:40.163554 11654 layer_factory.hpp:77] Creating layer conv3_dw/bn
I0523 21:53:40.163561 11654 net.cpp:84] Creating Layer conv3_dw/bn
I0523 21:53:40.163564 11654 net.cpp:406] conv3_dw/bn <- conv3_dw
I0523 21:53:40.163569 11654 net.cpp:367] conv3_dw/bn -> conv3_dw (in-place)
I0523 21:53:40.163748 11654 net.cpp:122] Setting up conv3_dw/bn
I0523 21:53:40.163755 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.163758 11654 net.cpp:137] Memory required for data: 2001076992
I0523 21:53:40.163766 11654 layer_factory.hpp:77] Creating layer conv3_dw/scale
I0523 21:53:40.163774 11654 net.cpp:84] Creating Layer conv3_dw/scale
I0523 21:53:40.163776 11654 net.cpp:406] conv3_dw/scale <- conv3_dw
I0523 21:53:40.163781 11654 net.cpp:367] conv3_dw/scale -> conv3_dw (in-place)
I0523 21:53:40.163820 11654 layer_factory.hpp:77] Creating layer conv3_dw/scale
I0523 21:53:40.163923 11654 net.cpp:122] Setting up conv3_dw/scale
I0523 21:53:40.163930 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.163933 11654 net.cpp:137] Memory required for data: 2012087040
I0523 21:53:40.163939 11654 layer_factory.hpp:77] Creating layer relu3_dw
I0523 21:53:40.163946 11654 net.cpp:84] Creating Layer relu3_dw
I0523 21:53:40.163950 11654 net.cpp:406] relu3_dw <- conv3_dw
I0523 21:53:40.163954 11654 net.cpp:367] relu3_dw -> conv3_dw (in-place)
I0523 21:53:40.165637 11654 net.cpp:122] Setting up relu3_dw
I0523 21:53:40.165652 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.165670 11654 net.cpp:137] Memory required for data: 2023097088
I0523 21:53:40.165678 11654 layer_factory.hpp:77] Creating layer conv3_em
I0523 21:53:40.165704 11654 net.cpp:84] Creating Layer conv3_em
I0523 21:53:40.165710 11654 net.cpp:406] conv3_em <- conv3_dw
I0523 21:53:40.165716 11654 net.cpp:380] conv3_em -> conv3_em
I0523 21:53:40.166764 11654 net.cpp:122] Setting up conv3_em
I0523 21:53:40.166776 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.166796 11654 net.cpp:137] Memory required for data: 2028602112
I0523 21:53:40.166827 11654 layer_factory.hpp:77] Creating layer conv3_em/bn
I0523 21:53:40.166836 11654 net.cpp:84] Creating Layer conv3_em/bn
I0523 21:53:40.166842 11654 net.cpp:406] conv3_em/bn <- conv3_em
I0523 21:53:40.166848 11654 net.cpp:367] conv3_em/bn -> conv3_em (in-place)
I0523 21:53:40.167039 11654 net.cpp:122] Setting up conv3_em/bn
I0523 21:53:40.167047 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.167050 11654 net.cpp:137] Memory required for data: 2034107136
I0523 21:53:40.167058 11654 layer_factory.hpp:77] Creating layer conv3_em/scale
I0523 21:53:40.167068 11654 net.cpp:84] Creating Layer conv3_em/scale
I0523 21:53:40.167083 11654 net.cpp:406] conv3_em/scale <- conv3_em
I0523 21:53:40.167088 11654 net.cpp:367] conv3_em/scale -> conv3_em (in-place)
I0523 21:53:40.167143 11654 layer_factory.hpp:77] Creating layer conv3_em/scale
I0523 21:53:40.167248 11654 net.cpp:122] Setting up conv3_em/scale
I0523 21:53:40.167254 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.167258 11654 net.cpp:137] Memory required for data: 2039612160
I0523 21:53:40.167263 11654 layer_factory.hpp:77] Creating layer conv3_em_conv3_em/scale_0_split
I0523 21:53:40.167268 11654 net.cpp:84] Creating Layer conv3_em_conv3_em/scale_0_split
I0523 21:53:40.167271 11654 net.cpp:406] conv3_em_conv3_em/scale_0_split <- conv3_em
I0523 21:53:40.167276 11654 net.cpp:380] conv3_em_conv3_em/scale_0_split -> conv3_em_conv3_em/scale_0_split_0
I0523 21:53:40.167297 11654 net.cpp:380] conv3_em_conv3_em/scale_0_split -> conv3_em_conv3_em/scale_0_split_1
I0523 21:53:40.167333 11654 net.cpp:122] Setting up conv3_em_conv3_em/scale_0_split
I0523 21:53:40.167340 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.167346 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.167348 11654 net.cpp:137] Memory required for data: 2050622208
I0523 21:53:40.167353 11654 layer_factory.hpp:77] Creating layer conv3_1_ex
I0523 21:53:40.167361 11654 net.cpp:84] Creating Layer conv3_1_ex
I0523 21:53:40.167382 11654 net.cpp:406] conv3_1_ex <- conv3_em_conv3_em/scale_0_split_0
I0523 21:53:40.167388 11654 net.cpp:380] conv3_1_ex -> conv3_1_ex
I0523 21:53:40.168638 11654 net.cpp:122] Setting up conv3_1_ex
I0523 21:53:40.168653 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.168658 11654 net.cpp:137] Memory required for data: 2061632256
I0523 21:53:40.168663 11654 layer_factory.hpp:77] Creating layer conv3_1_ex/bn
I0523 21:53:40.168670 11654 net.cpp:84] Creating Layer conv3_1_ex/bn
I0523 21:53:40.168674 11654 net.cpp:406] conv3_1_ex/bn <- conv3_1_ex
I0523 21:53:40.168680 11654 net.cpp:367] conv3_1_ex/bn -> conv3_1_ex (in-place)
I0523 21:53:40.168884 11654 net.cpp:122] Setting up conv3_1_ex/bn
I0523 21:53:40.168892 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.168895 11654 net.cpp:137] Memory required for data: 2072642304
I0523 21:53:40.168902 11654 layer_factory.hpp:77] Creating layer conv3_1_ex/scale
I0523 21:53:40.168912 11654 net.cpp:84] Creating Layer conv3_1_ex/scale
I0523 21:53:40.168916 11654 net.cpp:406] conv3_1_ex/scale <- conv3_1_ex
I0523 21:53:40.168922 11654 net.cpp:367] conv3_1_ex/scale -> conv3_1_ex (in-place)
I0523 21:53:40.168962 11654 layer_factory.hpp:77] Creating layer conv3_1_ex/scale
I0523 21:53:40.169073 11654 net.cpp:122] Setting up conv3_1_ex/scale
I0523 21:53:40.169081 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.169085 11654 net.cpp:137] Memory required for data: 2083652352
I0523 21:53:40.169090 11654 layer_factory.hpp:77] Creating layer relu3_1_ex
I0523 21:53:40.169097 11654 net.cpp:84] Creating Layer relu3_1_ex
I0523 21:53:40.169101 11654 net.cpp:406] relu3_1_ex <- conv3_1_ex
I0523 21:53:40.169107 11654 net.cpp:367] relu3_1_ex -> conv3_1_ex (in-place)
I0523 21:53:40.169219 11654 net.cpp:122] Setting up relu3_1_ex
I0523 21:53:40.169227 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.169230 11654 net.cpp:137] Memory required for data: 2094662400
I0523 21:53:40.169234 11654 layer_factory.hpp:77] Creating layer conv3_1_dw
I0523 21:53:40.169245 11654 net.cpp:84] Creating Layer conv3_1_dw
I0523 21:53:40.169250 11654 net.cpp:406] conv3_1_dw <- conv3_1_ex
I0523 21:53:40.169257 11654 net.cpp:380] conv3_1_dw -> conv3_1_dw
I0523 21:53:40.169462 11654 net.cpp:122] Setting up conv3_1_dw
I0523 21:53:40.169471 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.169473 11654 net.cpp:137] Memory required for data: 2105672448
I0523 21:53:40.169477 11654 layer_factory.hpp:77] Creating layer conv3_1_dw/bn
I0523 21:53:40.169484 11654 net.cpp:84] Creating Layer conv3_1_dw/bn
I0523 21:53:40.169487 11654 net.cpp:406] conv3_1_dw/bn <- conv3_1_dw
I0523 21:53:40.169493 11654 net.cpp:367] conv3_1_dw/bn -> conv3_1_dw (in-place)
I0523 21:53:40.169687 11654 net.cpp:122] Setting up conv3_1_dw/bn
I0523 21:53:40.169693 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.169697 11654 net.cpp:137] Memory required for data: 2116682496
I0523 21:53:40.169713 11654 layer_factory.hpp:77] Creating layer conv3_1_dw/scale
I0523 21:53:40.169721 11654 net.cpp:84] Creating Layer conv3_1_dw/scale
I0523 21:53:40.169725 11654 net.cpp:406] conv3_1_dw/scale <- conv3_1_dw
I0523 21:53:40.169731 11654 net.cpp:367] conv3_1_dw/scale -> conv3_1_dw (in-place)
I0523 21:53:40.169770 11654 layer_factory.hpp:77] Creating layer conv3_1_dw/scale
I0523 21:53:40.169876 11654 net.cpp:122] Setting up conv3_1_dw/scale
I0523 21:53:40.169894 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.169898 11654 net.cpp:137] Memory required for data: 2127692544
I0523 21:53:40.169905 11654 layer_factory.hpp:77] Creating layer relu3_1_dw
I0523 21:53:40.169911 11654 net.cpp:84] Creating Layer relu3_1_dw
I0523 21:53:40.169914 11654 net.cpp:406] relu3_1_dw <- conv3_1_dw
I0523 21:53:40.169920 11654 net.cpp:367] relu3_1_dw -> conv3_1_dw (in-place)
I0523 21:53:40.170030 11654 net.cpp:122] Setting up relu3_1_dw
I0523 21:53:40.170038 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.170042 11654 net.cpp:137] Memory required for data: 2138702592
I0523 21:53:40.170045 11654 layer_factory.hpp:77] Creating layer conv3_1_em
I0523 21:53:40.170055 11654 net.cpp:84] Creating Layer conv3_1_em
I0523 21:53:40.170061 11654 net.cpp:406] conv3_1_em <- conv3_1_dw
I0523 21:53:40.170068 11654 net.cpp:380] conv3_1_em -> conv3_1_em
I0523 21:53:40.171378 11654 net.cpp:122] Setting up conv3_1_em
I0523 21:53:40.171394 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.171398 11654 net.cpp:137] Memory required for data: 2144207616
I0523 21:53:40.171403 11654 layer_factory.hpp:77] Creating layer conv3_1_em/bn
I0523 21:53:40.171411 11654 net.cpp:84] Creating Layer conv3_1_em/bn
I0523 21:53:40.171416 11654 net.cpp:406] conv3_1_em/bn <- conv3_1_em
I0523 21:53:40.171422 11654 net.cpp:367] conv3_1_em/bn -> conv3_1_em (in-place)
I0523 21:53:40.171614 11654 net.cpp:122] Setting up conv3_1_em/bn
I0523 21:53:40.171622 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.171625 11654 net.cpp:137] Memory required for data: 2149712640
I0523 21:53:40.171633 11654 layer_factory.hpp:77] Creating layer conv3_1_em/scale
I0523 21:53:40.171638 11654 net.cpp:84] Creating Layer conv3_1_em/scale
I0523 21:53:40.171643 11654 net.cpp:406] conv3_1_em/scale <- conv3_1_em
I0523 21:53:40.171648 11654 net.cpp:367] conv3_1_em/scale -> conv3_1_em (in-place)
I0523 21:53:40.171686 11654 layer_factory.hpp:77] Creating layer conv3_1_em/scale
I0523 21:53:40.171795 11654 net.cpp:122] Setting up conv3_1_em/scale
I0523 21:53:40.171803 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.171806 11654 net.cpp:137] Memory required for data: 2155217664
I0523 21:53:40.171814 11654 layer_factory.hpp:77] Creating layer res3_1
I0523 21:53:40.171823 11654 net.cpp:84] Creating Layer res3_1
I0523 21:53:40.171828 11654 net.cpp:406] res3_1 <- conv3_em_conv3_em/scale_0_split_1
I0523 21:53:40.171833 11654 net.cpp:406] res3_1 <- conv3_1_em
I0523 21:53:40.171838 11654 net.cpp:380] res3_1 -> res3_1
I0523 21:53:40.171864 11654 net.cpp:122] Setting up res3_1
I0523 21:53:40.171870 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.171875 11654 net.cpp:137] Memory required for data: 2160722688
I0523 21:53:40.171876 11654 layer_factory.hpp:77] Creating layer res3_1_res3_1_0_split
I0523 21:53:40.171882 11654 net.cpp:84] Creating Layer res3_1_res3_1_0_split
I0523 21:53:40.171886 11654 net.cpp:406] res3_1_res3_1_0_split <- res3_1
I0523 21:53:40.171891 11654 net.cpp:380] res3_1_res3_1_0_split -> res3_1_res3_1_0_split_0
I0523 21:53:40.171896 11654 net.cpp:380] res3_1_res3_1_0_split -> res3_1_res3_1_0_split_1
I0523 21:53:40.171931 11654 net.cpp:122] Setting up res3_1_res3_1_0_split
I0523 21:53:40.171937 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.171941 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.171943 11654 net.cpp:137] Memory required for data: 2171732736
I0523 21:53:40.171947 11654 layer_factory.hpp:77] Creating layer conv3_2_ex
I0523 21:53:40.171955 11654 net.cpp:84] Creating Layer conv3_2_ex
I0523 21:53:40.171962 11654 net.cpp:406] conv3_2_ex <- res3_1_res3_1_0_split_0
I0523 21:53:40.171967 11654 net.cpp:380] conv3_2_ex -> conv3_2_ex
I0523 21:53:40.173250 11654 net.cpp:122] Setting up conv3_2_ex
I0523 21:53:40.173265 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.173285 11654 net.cpp:137] Memory required for data: 2182742784
I0523 21:53:40.173290 11654 layer_factory.hpp:77] Creating layer conv3_2_ex/bn
I0523 21:53:40.173311 11654 net.cpp:84] Creating Layer conv3_2_ex/bn
I0523 21:53:40.173316 11654 net.cpp:406] conv3_2_ex/bn <- conv3_2_ex
I0523 21:53:40.173323 11654 net.cpp:367] conv3_2_ex/bn -> conv3_2_ex (in-place)
I0523 21:53:40.173516 11654 net.cpp:122] Setting up conv3_2_ex/bn
I0523 21:53:40.173523 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.173527 11654 net.cpp:137] Memory required for data: 2193752832
I0523 21:53:40.173535 11654 layer_factory.hpp:77] Creating layer conv3_2_ex/scale
I0523 21:53:40.173545 11654 net.cpp:84] Creating Layer conv3_2_ex/scale
I0523 21:53:40.173550 11654 net.cpp:406] conv3_2_ex/scale <- conv3_2_ex
I0523 21:53:40.173555 11654 net.cpp:367] conv3_2_ex/scale -> conv3_2_ex (in-place)
I0523 21:53:40.173595 11654 layer_factory.hpp:77] Creating layer conv3_2_ex/scale
I0523 21:53:40.173704 11654 net.cpp:122] Setting up conv3_2_ex/scale
I0523 21:53:40.173712 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.173715 11654 net.cpp:137] Memory required for data: 2204762880
I0523 21:53:40.173720 11654 layer_factory.hpp:77] Creating layer relu3_2_ex
I0523 21:53:40.173727 11654 net.cpp:84] Creating Layer relu3_2_ex
I0523 21:53:40.173729 11654 net.cpp:406] relu3_2_ex <- conv3_2_ex
I0523 21:53:40.173734 11654 net.cpp:367] relu3_2_ex -> conv3_2_ex (in-place)
I0523 21:53:40.173844 11654 net.cpp:122] Setting up relu3_2_ex
I0523 21:53:40.173852 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.173856 11654 net.cpp:137] Memory required for data: 2215772928
I0523 21:53:40.173861 11654 layer_factory.hpp:77] Creating layer conv3_2_dw
I0523 21:53:40.173868 11654 net.cpp:84] Creating Layer conv3_2_dw
I0523 21:53:40.173871 11654 net.cpp:406] conv3_2_dw <- conv3_2_ex
I0523 21:53:40.173877 11654 net.cpp:380] conv3_2_dw -> conv3_2_dw
I0523 21:53:40.174082 11654 net.cpp:122] Setting up conv3_2_dw
I0523 21:53:40.174090 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.174093 11654 net.cpp:137] Memory required for data: 2226782976
I0523 21:53:40.174098 11654 layer_factory.hpp:77] Creating layer conv3_2_dw/bn
I0523 21:53:40.174106 11654 net.cpp:84] Creating Layer conv3_2_dw/bn
I0523 21:53:40.174109 11654 net.cpp:406] conv3_2_dw/bn <- conv3_2_dw
I0523 21:53:40.174115 11654 net.cpp:367] conv3_2_dw/bn -> conv3_2_dw (in-place)
I0523 21:53:40.174300 11654 net.cpp:122] Setting up conv3_2_dw/bn
I0523 21:53:40.174307 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.174310 11654 net.cpp:137] Memory required for data: 2237793024
I0523 21:53:40.174317 11654 layer_factory.hpp:77] Creating layer conv3_2_dw/scale
I0523 21:53:40.174325 11654 net.cpp:84] Creating Layer conv3_2_dw/scale
I0523 21:53:40.174330 11654 net.cpp:406] conv3_2_dw/scale <- conv3_2_dw
I0523 21:53:40.174335 11654 net.cpp:367] conv3_2_dw/scale -> conv3_2_dw (in-place)
I0523 21:53:40.174372 11654 layer_factory.hpp:77] Creating layer conv3_2_dw/scale
I0523 21:53:40.174479 11654 net.cpp:122] Setting up conv3_2_dw/scale
I0523 21:53:40.174485 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.174489 11654 net.cpp:137] Memory required for data: 2248803072
I0523 21:53:40.174494 11654 layer_factory.hpp:77] Creating layer relu3_2_dw
I0523 21:53:40.174499 11654 net.cpp:84] Creating Layer relu3_2_dw
I0523 21:53:40.174502 11654 net.cpp:406] relu3_2_dw <- conv3_2_dw
I0523 21:53:40.174507 11654 net.cpp:367] relu3_2_dw -> conv3_2_dw (in-place)
I0523 21:53:40.174614 11654 net.cpp:122] Setting up relu3_2_dw
I0523 21:53:40.174623 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.174625 11654 net.cpp:137] Memory required for data: 2259813120
I0523 21:53:40.174629 11654 layer_factory.hpp:77] Creating layer conv3_2_em
I0523 21:53:40.174639 11654 net.cpp:84] Creating Layer conv3_2_em
I0523 21:53:40.174643 11654 net.cpp:406] conv3_2_em <- conv3_2_dw
I0523 21:53:40.174649 11654 net.cpp:380] conv3_2_em -> conv3_2_em
I0523 21:53:40.175928 11654 net.cpp:122] Setting up conv3_2_em
I0523 21:53:40.175943 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.175973 11654 net.cpp:137] Memory required for data: 2265318144
I0523 21:53:40.175981 11654 layer_factory.hpp:77] Creating layer conv3_2_em/bn
I0523 21:53:40.175992 11654 net.cpp:84] Creating Layer conv3_2_em/bn
I0523 21:53:40.175997 11654 net.cpp:406] conv3_2_em/bn <- conv3_2_em
I0523 21:53:40.176002 11654 net.cpp:367] conv3_2_em/bn -> conv3_2_em (in-place)
I0523 21:53:40.176203 11654 net.cpp:122] Setting up conv3_2_em/bn
I0523 21:53:40.176211 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.176214 11654 net.cpp:137] Memory required for data: 2270823168
I0523 21:53:40.176223 11654 layer_factory.hpp:77] Creating layer conv3_2_em/scale
I0523 21:53:40.176229 11654 net.cpp:84] Creating Layer conv3_2_em/scale
I0523 21:53:40.176234 11654 net.cpp:406] conv3_2_em/scale <- conv3_2_em
I0523 21:53:40.176239 11654 net.cpp:367] conv3_2_em/scale -> conv3_2_em (in-place)
I0523 21:53:40.176278 11654 layer_factory.hpp:77] Creating layer conv3_2_em/scale
I0523 21:53:40.176389 11654 net.cpp:122] Setting up conv3_2_em/scale
I0523 21:53:40.176396 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.176399 11654 net.cpp:137] Memory required for data: 2276328192
I0523 21:53:40.176405 11654 layer_factory.hpp:77] Creating layer res3_2
I0523 21:53:40.176412 11654 net.cpp:84] Creating Layer res3_2
I0523 21:53:40.176416 11654 net.cpp:406] res3_2 <- res3_1_res3_1_0_split_1
I0523 21:53:40.176430 11654 net.cpp:406] res3_2 <- conv3_2_em
I0523 21:53:40.176436 11654 net.cpp:380] res3_2 -> res3_2
I0523 21:53:40.176460 11654 net.cpp:122] Setting up res3_2
I0523 21:53:40.176466 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.176470 11654 net.cpp:137] Memory required for data: 2281833216
I0523 21:53:40.176472 11654 layer_factory.hpp:77] Creating layer res3_2_res3_2_0_split
I0523 21:53:40.176479 11654 net.cpp:84] Creating Layer res3_2_res3_2_0_split
I0523 21:53:40.176483 11654 net.cpp:406] res3_2_res3_2_0_split <- res3_2
I0523 21:53:40.176488 11654 net.cpp:380] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_0
I0523 21:53:40.176494 11654 net.cpp:380] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_1
I0523 21:53:40.176543 11654 net.cpp:122] Setting up res3_2_res3_2_0_split
I0523 21:53:40.176550 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.176554 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.176556 11654 net.cpp:137] Memory required for data: 2292843264
I0523 21:53:40.176559 11654 layer_factory.hpp:77] Creating layer conv3_3_ex
I0523 21:53:40.176568 11654 net.cpp:84] Creating Layer conv3_3_ex
I0523 21:53:40.176571 11654 net.cpp:406] conv3_3_ex <- res3_2_res3_2_0_split_0
I0523 21:53:40.176578 11654 net.cpp:380] conv3_3_ex -> conv3_3_ex
I0523 21:53:40.177893 11654 net.cpp:122] Setting up conv3_3_ex
I0523 21:53:40.177908 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.177928 11654 net.cpp:137] Memory required for data: 2303853312
I0523 21:53:40.177933 11654 layer_factory.hpp:77] Creating layer conv3_3_ex/bn
I0523 21:53:40.177942 11654 net.cpp:84] Creating Layer conv3_3_ex/bn
I0523 21:53:40.177948 11654 net.cpp:406] conv3_3_ex/bn <- conv3_3_ex
I0523 21:53:40.177955 11654 net.cpp:367] conv3_3_ex/bn -> conv3_3_ex (in-place)
I0523 21:53:40.178151 11654 net.cpp:122] Setting up conv3_3_ex/bn
I0523 21:53:40.178159 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.178162 11654 net.cpp:137] Memory required for data: 2314863360
I0523 21:53:40.178169 11654 layer_factory.hpp:77] Creating layer conv3_3_ex/scale
I0523 21:53:40.178180 11654 net.cpp:84] Creating Layer conv3_3_ex/scale
I0523 21:53:40.178184 11654 net.cpp:406] conv3_3_ex/scale <- conv3_3_ex
I0523 21:53:40.178190 11654 net.cpp:367] conv3_3_ex/scale -> conv3_3_ex (in-place)
I0523 21:53:40.178231 11654 layer_factory.hpp:77] Creating layer conv3_3_ex/scale
I0523 21:53:40.178345 11654 net.cpp:122] Setting up conv3_3_ex/scale
I0523 21:53:40.178354 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.178356 11654 net.cpp:137] Memory required for data: 2325873408
I0523 21:53:40.178375 11654 layer_factory.hpp:77] Creating layer relu3_3_ex
I0523 21:53:40.178382 11654 net.cpp:84] Creating Layer relu3_3_ex
I0523 21:53:40.178386 11654 net.cpp:406] relu3_3_ex <- conv3_3_ex
I0523 21:53:40.178391 11654 net.cpp:367] relu3_3_ex -> conv3_3_ex (in-place)
I0523 21:53:40.178508 11654 net.cpp:122] Setting up relu3_3_ex
I0523 21:53:40.178515 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.178519 11654 net.cpp:137] Memory required for data: 2336883456
I0523 21:53:40.178522 11654 layer_factory.hpp:77] Creating layer conv3_3_dw
I0523 21:53:40.178530 11654 net.cpp:84] Creating Layer conv3_3_dw
I0523 21:53:40.178534 11654 net.cpp:406] conv3_3_dw <- conv3_3_ex
I0523 21:53:40.178540 11654 net.cpp:380] conv3_3_dw -> conv3_3_dw
I0523 21:53:40.178761 11654 net.cpp:122] Setting up conv3_3_dw
I0523 21:53:40.178769 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.178772 11654 net.cpp:137] Memory required for data: 2347893504
I0523 21:53:40.178777 11654 layer_factory.hpp:77] Creating layer conv3_3_dw/bn
I0523 21:53:40.178786 11654 net.cpp:84] Creating Layer conv3_3_dw/bn
I0523 21:53:40.178788 11654 net.cpp:406] conv3_3_dw/bn <- conv3_3_dw
I0523 21:53:40.178794 11654 net.cpp:367] conv3_3_dw/bn -> conv3_3_dw (in-place)
I0523 21:53:40.178982 11654 net.cpp:122] Setting up conv3_3_dw/bn
I0523 21:53:40.178989 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.178992 11654 net.cpp:137] Memory required for data: 2358903552
I0523 21:53:40.178999 11654 layer_factory.hpp:77] Creating layer conv3_3_dw/scale
I0523 21:53:40.179008 11654 net.cpp:84] Creating Layer conv3_3_dw/scale
I0523 21:53:40.179013 11654 net.cpp:406] conv3_3_dw/scale <- conv3_3_dw
I0523 21:53:40.179018 11654 net.cpp:367] conv3_3_dw/scale -> conv3_3_dw (in-place)
I0523 21:53:40.179057 11654 layer_factory.hpp:77] Creating layer conv3_3_dw/scale
I0523 21:53:40.179168 11654 net.cpp:122] Setting up conv3_3_dw/scale
I0523 21:53:40.179175 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.179179 11654 net.cpp:137] Memory required for data: 2369913600
I0523 21:53:40.179185 11654 layer_factory.hpp:77] Creating layer relu3_3_dw
I0523 21:53:40.179193 11654 net.cpp:84] Creating Layer relu3_3_dw
I0523 21:53:40.179195 11654 net.cpp:406] relu3_3_dw <- conv3_3_dw
I0523 21:53:40.179200 11654 net.cpp:367] relu3_3_dw -> conv3_3_dw (in-place)
I0523 21:53:40.179311 11654 net.cpp:122] Setting up relu3_3_dw
I0523 21:53:40.179319 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.179322 11654 net.cpp:137] Memory required for data: 2380923648
I0523 21:53:40.179327 11654 layer_factory.hpp:77] Creating layer conv3_3_em
I0523 21:53:40.179337 11654 net.cpp:84] Creating Layer conv3_3_em
I0523 21:53:40.179340 11654 net.cpp:406] conv3_3_em <- conv3_3_dw
I0523 21:53:40.179347 11654 net.cpp:380] conv3_3_em -> conv3_3_em
I0523 21:53:40.182134 11654 net.cpp:122] Setting up conv3_3_em
I0523 21:53:40.182149 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.182169 11654 net.cpp:137] Memory required for data: 2386428672
I0523 21:53:40.182174 11654 layer_factory.hpp:77] Creating layer conv3_3_em/bn
I0523 21:53:40.182184 11654 net.cpp:84] Creating Layer conv3_3_em/bn
I0523 21:53:40.182190 11654 net.cpp:406] conv3_3_em/bn <- conv3_3_em
I0523 21:53:40.182196 11654 net.cpp:367] conv3_3_em/bn -> conv3_3_em (in-place)
I0523 21:53:40.182404 11654 net.cpp:122] Setting up conv3_3_em/bn
I0523 21:53:40.182411 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.182415 11654 net.cpp:137] Memory required for data: 2391933696
I0523 21:53:40.182421 11654 layer_factory.hpp:77] Creating layer conv3_3_em/scale
I0523 21:53:40.182431 11654 net.cpp:84] Creating Layer conv3_3_em/scale
I0523 21:53:40.182435 11654 net.cpp:406] conv3_3_em/scale <- conv3_3_em
I0523 21:53:40.182440 11654 net.cpp:367] conv3_3_em/scale -> conv3_3_em (in-place)
I0523 21:53:40.182485 11654 layer_factory.hpp:77] Creating layer conv3_3_em/scale
I0523 21:53:40.182601 11654 net.cpp:122] Setting up conv3_3_em/scale
I0523 21:53:40.182622 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.182626 11654 net.cpp:137] Memory required for data: 2397438720
I0523 21:53:40.182631 11654 layer_factory.hpp:77] Creating layer res3_3
I0523 21:53:40.182641 11654 net.cpp:84] Creating Layer res3_3
I0523 21:53:40.182646 11654 net.cpp:406] res3_3 <- res3_2_res3_2_0_split_1
I0523 21:53:40.182651 11654 net.cpp:406] res3_3 <- conv3_3_em
I0523 21:53:40.182656 11654 net.cpp:380] res3_3 -> res3_3
I0523 21:53:40.182703 11654 net.cpp:122] Setting up res3_3
I0523 21:53:40.182713 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.182715 11654 net.cpp:137] Memory required for data: 2402943744
I0523 21:53:40.182718 11654 layer_factory.hpp:77] Creating layer res3_3_res3_3_0_split
I0523 21:53:40.182724 11654 net.cpp:84] Creating Layer res3_3_res3_3_0_split
I0523 21:53:40.182727 11654 net.cpp:406] res3_3_res3_3_0_split <- res3_3
I0523 21:53:40.182735 11654 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_0
I0523 21:53:40.182741 11654 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_1
I0523 21:53:40.182780 11654 net.cpp:122] Setting up res3_3_res3_3_0_split
I0523 21:53:40.182786 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.182790 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.182793 11654 net.cpp:137] Memory required for data: 2413953792
I0523 21:53:40.182796 11654 layer_factory.hpp:77] Creating layer conv3_4_ex
I0523 21:53:40.182804 11654 net.cpp:84] Creating Layer conv3_4_ex
I0523 21:53:40.182808 11654 net.cpp:406] conv3_4_ex <- res3_3_res3_3_0_split_0
I0523 21:53:40.182816 11654 net.cpp:380] conv3_4_ex -> conv3_4_ex
I0523 21:53:40.184198 11654 net.cpp:122] Setting up conv3_4_ex
I0523 21:53:40.184214 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.184218 11654 net.cpp:137] Memory required for data: 2424963840
I0523 21:53:40.184226 11654 layer_factory.hpp:77] Creating layer conv3_4_ex/bn
I0523 21:53:40.184236 11654 net.cpp:84] Creating Layer conv3_4_ex/bn
I0523 21:53:40.184248 11654 net.cpp:406] conv3_4_ex/bn <- conv3_4_ex
I0523 21:53:40.184254 11654 net.cpp:367] conv3_4_ex/bn -> conv3_4_ex (in-place)
I0523 21:53:40.184466 11654 net.cpp:122] Setting up conv3_4_ex/bn
I0523 21:53:40.184474 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.184478 11654 net.cpp:137] Memory required for data: 2435973888
I0523 21:53:40.184484 11654 layer_factory.hpp:77] Creating layer conv3_4_ex/scale
I0523 21:53:40.184494 11654 net.cpp:84] Creating Layer conv3_4_ex/scale
I0523 21:53:40.184499 11654 net.cpp:406] conv3_4_ex/scale <- conv3_4_ex
I0523 21:53:40.184504 11654 net.cpp:367] conv3_4_ex/scale -> conv3_4_ex (in-place)
I0523 21:53:40.184546 11654 layer_factory.hpp:77] Creating layer conv3_4_ex/scale
I0523 21:53:40.184667 11654 net.cpp:122] Setting up conv3_4_ex/scale
I0523 21:53:40.184674 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.184679 11654 net.cpp:137] Memory required for data: 2446983936
I0523 21:53:40.184684 11654 layer_factory.hpp:77] Creating layer relu3_4_ex
I0523 21:53:40.184692 11654 net.cpp:84] Creating Layer relu3_4_ex
I0523 21:53:40.184697 11654 net.cpp:406] relu3_4_ex <- conv3_4_ex
I0523 21:53:40.184715 11654 net.cpp:367] relu3_4_ex -> conv3_4_ex (in-place)
I0523 21:53:40.184829 11654 net.cpp:122] Setting up relu3_4_ex
I0523 21:53:40.184837 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.184841 11654 net.cpp:137] Memory required for data: 2457993984
I0523 21:53:40.184845 11654 layer_factory.hpp:77] Creating layer conv3_4_dw
I0523 21:53:40.184864 11654 net.cpp:84] Creating Layer conv3_4_dw
I0523 21:53:40.184870 11654 net.cpp:406] conv3_4_dw <- conv3_4_ex
I0523 21:53:40.184876 11654 net.cpp:380] conv3_4_dw -> conv3_4_dw
I0523 21:53:40.185099 11654 net.cpp:122] Setting up conv3_4_dw
I0523 21:53:40.185108 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.185111 11654 net.cpp:137] Memory required for data: 2469004032
I0523 21:53:40.185117 11654 layer_factory.hpp:77] Creating layer conv3_4_dw/bn
I0523 21:53:40.185140 11654 net.cpp:84] Creating Layer conv3_4_dw/bn
I0523 21:53:40.185147 11654 net.cpp:406] conv3_4_dw/bn <- conv3_4_dw
I0523 21:53:40.185151 11654 net.cpp:367] conv3_4_dw/bn -> conv3_4_dw (in-place)
I0523 21:53:40.185353 11654 net.cpp:122] Setting up conv3_4_dw/bn
I0523 21:53:40.185361 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.185364 11654 net.cpp:137] Memory required for data: 2480014080
I0523 21:53:40.185371 11654 layer_factory.hpp:77] Creating layer conv3_4_dw/scale
I0523 21:53:40.185384 11654 net.cpp:84] Creating Layer conv3_4_dw/scale
I0523 21:53:40.185386 11654 net.cpp:406] conv3_4_dw/scale <- conv3_4_dw
I0523 21:53:40.185391 11654 net.cpp:367] conv3_4_dw/scale -> conv3_4_dw (in-place)
I0523 21:53:40.185441 11654 layer_factory.hpp:77] Creating layer conv3_4_dw/scale
I0523 21:53:40.185564 11654 net.cpp:122] Setting up conv3_4_dw/scale
I0523 21:53:40.185571 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.185575 11654 net.cpp:137] Memory required for data: 2491024128
I0523 21:53:40.185580 11654 layer_factory.hpp:77] Creating layer relu3_4_dw
I0523 21:53:40.185586 11654 net.cpp:84] Creating Layer relu3_4_dw
I0523 21:53:40.185590 11654 net.cpp:406] relu3_4_dw <- conv3_4_dw
I0523 21:53:40.185596 11654 net.cpp:367] relu3_4_dw -> conv3_4_dw (in-place)
I0523 21:53:40.185709 11654 net.cpp:122] Setting up relu3_4_dw
I0523 21:53:40.185717 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.185720 11654 net.cpp:137] Memory required for data: 2502034176
I0523 21:53:40.185725 11654 layer_factory.hpp:77] Creating layer conv3_4_em
I0523 21:53:40.185736 11654 net.cpp:84] Creating Layer conv3_4_em
I0523 21:53:40.185741 11654 net.cpp:406] conv3_4_em <- conv3_4_dw
I0523 21:53:40.185746 11654 net.cpp:380] conv3_4_em -> conv3_4_em
I0523 21:53:40.187427 11654 net.cpp:122] Setting up conv3_4_em
I0523 21:53:40.187444 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.187448 11654 net.cpp:137] Memory required for data: 2507539200
I0523 21:53:40.187453 11654 layer_factory.hpp:77] Creating layer conv3_4_em/bn
I0523 21:53:40.187465 11654 net.cpp:84] Creating Layer conv3_4_em/bn
I0523 21:53:40.187471 11654 net.cpp:406] conv3_4_em/bn <- conv3_4_em
I0523 21:53:40.187480 11654 net.cpp:367] conv3_4_em/bn -> conv3_4_em (in-place)
I0523 21:53:40.187695 11654 net.cpp:122] Setting up conv3_4_em/bn
I0523 21:53:40.187703 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.187707 11654 net.cpp:137] Memory required for data: 2513044224
I0523 21:53:40.187714 11654 layer_factory.hpp:77] Creating layer conv3_4_em/scale
I0523 21:53:40.187723 11654 net.cpp:84] Creating Layer conv3_4_em/scale
I0523 21:53:40.187728 11654 net.cpp:406] conv3_4_em/scale <- conv3_4_em
I0523 21:53:40.187733 11654 net.cpp:367] conv3_4_em/scale -> conv3_4_em (in-place)
I0523 21:53:40.187777 11654 layer_factory.hpp:77] Creating layer conv3_4_em/scale
I0523 21:53:40.187901 11654 net.cpp:122] Setting up conv3_4_em/scale
I0523 21:53:40.187911 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.187913 11654 net.cpp:137] Memory required for data: 2518549248
I0523 21:53:40.187919 11654 layer_factory.hpp:77] Creating layer res3_4
I0523 21:53:40.187927 11654 net.cpp:84] Creating Layer res3_4
I0523 21:53:40.187933 11654 net.cpp:406] res3_4 <- res3_3_res3_3_0_split_1
I0523 21:53:40.187938 11654 net.cpp:406] res3_4 <- conv3_4_em
I0523 21:53:40.187942 11654 net.cpp:380] res3_4 -> res3_4
I0523 21:53:40.187970 11654 net.cpp:122] Setting up res3_4
I0523 21:53:40.187978 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.187980 11654 net.cpp:137] Memory required for data: 2524054272
I0523 21:53:40.187984 11654 layer_factory.hpp:77] Creating layer res3_4_res3_4_0_split
I0523 21:53:40.187989 11654 net.cpp:84] Creating Layer res3_4_res3_4_0_split
I0523 21:53:40.187994 11654 net.cpp:406] res3_4_res3_4_0_split <- res3_4
I0523 21:53:40.188001 11654 net.cpp:380] res3_4_res3_4_0_split -> res3_4_res3_4_0_split_0
I0523 21:53:40.188007 11654 net.cpp:380] res3_4_res3_4_0_split -> res3_4_res3_4_0_split_1
I0523 21:53:40.188060 11654 net.cpp:122] Setting up res3_4_res3_4_0_split
I0523 21:53:40.188066 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.188071 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.188074 11654 net.cpp:137] Memory required for data: 2535064320
I0523 21:53:40.188077 11654 layer_factory.hpp:77] Creating layer conv3_5_ex
I0523 21:53:40.188093 11654 net.cpp:84] Creating Layer conv3_5_ex
I0523 21:53:40.188099 11654 net.cpp:406] conv3_5_ex <- res3_4_res3_4_0_split_0
I0523 21:53:40.188105 11654 net.cpp:380] conv3_5_ex -> conv3_5_ex
I0523 21:53:40.189473 11654 net.cpp:122] Setting up conv3_5_ex
I0523 21:53:40.189489 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.189493 11654 net.cpp:137] Memory required for data: 2546074368
I0523 21:53:40.189498 11654 layer_factory.hpp:77] Creating layer conv3_5_ex/bn
I0523 21:53:40.189507 11654 net.cpp:84] Creating Layer conv3_5_ex/bn
I0523 21:53:40.189510 11654 net.cpp:406] conv3_5_ex/bn <- conv3_5_ex
I0523 21:53:40.189518 11654 net.cpp:367] conv3_5_ex/bn -> conv3_5_ex (in-place)
I0523 21:53:40.189751 11654 net.cpp:122] Setting up conv3_5_ex/bn
I0523 21:53:40.189759 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.189762 11654 net.cpp:137] Memory required for data: 2557084416
I0523 21:53:40.189769 11654 layer_factory.hpp:77] Creating layer conv3_5_ex/scale
I0523 21:53:40.189791 11654 net.cpp:84] Creating Layer conv3_5_ex/scale
I0523 21:53:40.189796 11654 net.cpp:406] conv3_5_ex/scale <- conv3_5_ex
I0523 21:53:40.189803 11654 net.cpp:367] conv3_5_ex/scale -> conv3_5_ex (in-place)
I0523 21:53:40.189846 11654 layer_factory.hpp:77] Creating layer conv3_5_ex/scale
I0523 21:53:40.189970 11654 net.cpp:122] Setting up conv3_5_ex/scale
I0523 21:53:40.189978 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.189981 11654 net.cpp:137] Memory required for data: 2568094464
I0523 21:53:40.189988 11654 layer_factory.hpp:77] Creating layer relu3_5_ex
I0523 21:53:40.189997 11654 net.cpp:84] Creating Layer relu3_5_ex
I0523 21:53:40.190001 11654 net.cpp:406] relu3_5_ex <- conv3_5_ex
I0523 21:53:40.190006 11654 net.cpp:367] relu3_5_ex -> conv3_5_ex (in-place)
I0523 21:53:40.190124 11654 net.cpp:122] Setting up relu3_5_ex
I0523 21:53:40.190132 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.190135 11654 net.cpp:137] Memory required for data: 2579104512
I0523 21:53:40.190140 11654 layer_factory.hpp:77] Creating layer conv3_5_dw
I0523 21:53:40.190147 11654 net.cpp:84] Creating Layer conv3_5_dw
I0523 21:53:40.190150 11654 net.cpp:406] conv3_5_dw <- conv3_5_ex
I0523 21:53:40.190158 11654 net.cpp:380] conv3_5_dw -> conv3_5_dw
I0523 21:53:40.190392 11654 net.cpp:122] Setting up conv3_5_dw
I0523 21:53:40.190399 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.190403 11654 net.cpp:137] Memory required for data: 2590114560
I0523 21:53:40.190407 11654 layer_factory.hpp:77] Creating layer conv3_5_dw/bn
I0523 21:53:40.190415 11654 net.cpp:84] Creating Layer conv3_5_dw/bn
I0523 21:53:40.190419 11654 net.cpp:406] conv3_5_dw/bn <- conv3_5_dw
I0523 21:53:40.190424 11654 net.cpp:367] conv3_5_dw/bn -> conv3_5_dw (in-place)
I0523 21:53:40.190634 11654 net.cpp:122] Setting up conv3_5_dw/bn
I0523 21:53:40.190641 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.190644 11654 net.cpp:137] Memory required for data: 2601124608
I0523 21:53:40.190651 11654 layer_factory.hpp:77] Creating layer conv3_5_dw/scale
I0523 21:53:40.190661 11654 net.cpp:84] Creating Layer conv3_5_dw/scale
I0523 21:53:40.190665 11654 net.cpp:406] conv3_5_dw/scale <- conv3_5_dw
I0523 21:53:40.190670 11654 net.cpp:367] conv3_5_dw/scale -> conv3_5_dw (in-place)
I0523 21:53:40.190721 11654 layer_factory.hpp:77] Creating layer conv3_5_dw/scale
I0523 21:53:40.190845 11654 net.cpp:122] Setting up conv3_5_dw/scale
I0523 21:53:40.190852 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.190855 11654 net.cpp:137] Memory required for data: 2612134656
I0523 21:53:40.190876 11654 layer_factory.hpp:77] Creating layer relu3_5_dw
I0523 21:53:40.190884 11654 net.cpp:84] Creating Layer relu3_5_dw
I0523 21:53:40.190889 11654 net.cpp:406] relu3_5_dw <- conv3_5_dw
I0523 21:53:40.190894 11654 net.cpp:367] relu3_5_dw -> conv3_5_dw (in-place)
I0523 21:53:40.191011 11654 net.cpp:122] Setting up relu3_5_dw
I0523 21:53:40.191020 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.191023 11654 net.cpp:137] Memory required for data: 2623144704
I0523 21:53:40.191027 11654 layer_factory.hpp:77] Creating layer conv3_5_em
I0523 21:53:40.191040 11654 net.cpp:84] Creating Layer conv3_5_em
I0523 21:53:40.191045 11654 net.cpp:406] conv3_5_em <- conv3_5_dw
I0523 21:53:40.191049 11654 net.cpp:380] conv3_5_em -> conv3_5_em
I0523 21:53:40.192078 11654 net.cpp:122] Setting up conv3_5_em
I0523 21:53:40.192093 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.192096 11654 net.cpp:137] Memory required for data: 2628649728
I0523 21:53:40.192102 11654 layer_factory.hpp:77] Creating layer conv3_5_em/bn
I0523 21:53:40.192111 11654 net.cpp:84] Creating Layer conv3_5_em/bn
I0523 21:53:40.192116 11654 net.cpp:406] conv3_5_em/bn <- conv3_5_em
I0523 21:53:40.192121 11654 net.cpp:367] conv3_5_em/bn -> conv3_5_em (in-place)
I0523 21:53:40.192335 11654 net.cpp:122] Setting up conv3_5_em/bn
I0523 21:53:40.192343 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.192347 11654 net.cpp:137] Memory required for data: 2634154752
I0523 21:53:40.192354 11654 layer_factory.hpp:77] Creating layer conv3_5_em/scale
I0523 21:53:40.192363 11654 net.cpp:84] Creating Layer conv3_5_em/scale
I0523 21:53:40.192368 11654 net.cpp:406] conv3_5_em/scale <- conv3_5_em
I0523 21:53:40.192373 11654 net.cpp:367] conv3_5_em/scale -> conv3_5_em (in-place)
I0523 21:53:40.192427 11654 layer_factory.hpp:77] Creating layer conv3_5_em/scale
I0523 21:53:40.192545 11654 net.cpp:122] Setting up conv3_5_em/scale
I0523 21:53:40.192553 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.192556 11654 net.cpp:137] Memory required for data: 2639659776
I0523 21:53:40.192561 11654 layer_factory.hpp:77] Creating layer res3_5
I0523 21:53:40.192567 11654 net.cpp:84] Creating Layer res3_5
I0523 21:53:40.192571 11654 net.cpp:406] res3_5 <- res3_4_res3_4_0_split_1
I0523 21:53:40.192575 11654 net.cpp:406] res3_5 <- conv3_5_em
I0523 21:53:40.192582 11654 net.cpp:380] res3_5 -> res3_5
I0523 21:53:40.192605 11654 net.cpp:122] Setting up res3_5
I0523 21:53:40.192611 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.192615 11654 net.cpp:137] Memory required for data: 2645164800
I0523 21:53:40.192617 11654 layer_factory.hpp:77] Creating layer res3_5_res3_5_0_split
I0523 21:53:40.192631 11654 net.cpp:84] Creating Layer res3_5_res3_5_0_split
I0523 21:53:40.192636 11654 net.cpp:406] res3_5_res3_5_0_split <- res3_5
I0523 21:53:40.192641 11654 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_0
I0523 21:53:40.192646 11654 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_1
I0523 21:53:40.192682 11654 net.cpp:122] Setting up res3_5_res3_5_0_split
I0523 21:53:40.192688 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.192693 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.192695 11654 net.cpp:137] Memory required for data: 2656174848
I0523 21:53:40.192698 11654 layer_factory.hpp:77] Creating layer conv3_6_ex
I0523 21:53:40.192705 11654 net.cpp:84] Creating Layer conv3_6_ex
I0523 21:53:40.192709 11654 net.cpp:406] conv3_6_ex <- res3_5_res3_5_0_split_0
I0523 21:53:40.192716 11654 net.cpp:380] conv3_6_ex -> conv3_6_ex
I0523 21:53:40.194046 11654 net.cpp:122] Setting up conv3_6_ex
I0523 21:53:40.194061 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.194080 11654 net.cpp:137] Memory required for data: 2667184896
I0523 21:53:40.194087 11654 layer_factory.hpp:77] Creating layer conv3_6_ex/bn
I0523 21:53:40.194097 11654 net.cpp:84] Creating Layer conv3_6_ex/bn
I0523 21:53:40.194102 11654 net.cpp:406] conv3_6_ex/bn <- conv3_6_ex
I0523 21:53:40.194121 11654 net.cpp:367] conv3_6_ex/bn -> conv3_6_ex (in-place)
I0523 21:53:40.194360 11654 net.cpp:122] Setting up conv3_6_ex/bn
I0523 21:53:40.194368 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.194371 11654 net.cpp:137] Memory required for data: 2678194944
I0523 21:53:40.194378 11654 layer_factory.hpp:77] Creating layer conv3_6_ex/scale
I0523 21:53:40.194387 11654 net.cpp:84] Creating Layer conv3_6_ex/scale
I0523 21:53:40.194392 11654 net.cpp:406] conv3_6_ex/scale <- conv3_6_ex
I0523 21:53:40.194397 11654 net.cpp:367] conv3_6_ex/scale -> conv3_6_ex (in-place)
I0523 21:53:40.194442 11654 layer_factory.hpp:77] Creating layer conv3_6_ex/scale
I0523 21:53:40.194576 11654 net.cpp:122] Setting up conv3_6_ex/scale
I0523 21:53:40.194598 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.194602 11654 net.cpp:137] Memory required for data: 2689204992
I0523 21:53:40.194607 11654 layer_factory.hpp:77] Creating layer relu3_6_ex
I0523 21:53:40.194614 11654 net.cpp:84] Creating Layer relu3_6_ex
I0523 21:53:40.194617 11654 net.cpp:406] relu3_6_ex <- conv3_6_ex
I0523 21:53:40.194624 11654 net.cpp:367] relu3_6_ex -> conv3_6_ex (in-place)
I0523 21:53:40.194752 11654 net.cpp:122] Setting up relu3_6_ex
I0523 21:53:40.194770 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.194773 11654 net.cpp:137] Memory required for data: 2700215040
I0523 21:53:40.194778 11654 layer_factory.hpp:77] Creating layer conv3_6_dw
I0523 21:53:40.194787 11654 net.cpp:84] Creating Layer conv3_6_dw
I0523 21:53:40.194790 11654 net.cpp:406] conv3_6_dw <- conv3_6_ex
I0523 21:53:40.194799 11654 net.cpp:380] conv3_6_dw -> conv3_6_dw
I0523 21:53:40.195024 11654 net.cpp:122] Setting up conv3_6_dw
I0523 21:53:40.195032 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.195035 11654 net.cpp:137] Memory required for data: 2711225088
I0523 21:53:40.195040 11654 layer_factory.hpp:77] Creating layer conv3_6_dw/bn
I0523 21:53:40.195045 11654 net.cpp:84] Creating Layer conv3_6_dw/bn
I0523 21:53:40.195050 11654 net.cpp:406] conv3_6_dw/bn <- conv3_6_dw
I0523 21:53:40.195053 11654 net.cpp:367] conv3_6_dw/bn -> conv3_6_dw (in-place)
I0523 21:53:40.195263 11654 net.cpp:122] Setting up conv3_6_dw/bn
I0523 21:53:40.195271 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.195274 11654 net.cpp:137] Memory required for data: 2722235136
I0523 21:53:40.195282 11654 layer_factory.hpp:77] Creating layer conv3_6_dw/scale
I0523 21:53:40.195291 11654 net.cpp:84] Creating Layer conv3_6_dw/scale
I0523 21:53:40.195296 11654 net.cpp:406] conv3_6_dw/scale <- conv3_6_dw
I0523 21:53:40.195299 11654 net.cpp:367] conv3_6_dw/scale -> conv3_6_dw (in-place)
I0523 21:53:40.195343 11654 layer_factory.hpp:77] Creating layer conv3_6_dw/scale
I0523 21:53:40.195464 11654 net.cpp:122] Setting up conv3_6_dw/scale
I0523 21:53:40.195472 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.195475 11654 net.cpp:137] Memory required for data: 2733245184
I0523 21:53:40.195480 11654 layer_factory.hpp:77] Creating layer relu3_6_dw
I0523 21:53:40.195485 11654 net.cpp:84] Creating Layer relu3_6_dw
I0523 21:53:40.195489 11654 net.cpp:406] relu3_6_dw <- conv3_6_dw
I0523 21:53:40.195495 11654 net.cpp:367] relu3_6_dw -> conv3_6_dw (in-place)
I0523 21:53:40.195608 11654 net.cpp:122] Setting up relu3_6_dw
I0523 21:53:40.195616 11654 net.cpp:129] Top shape: 64 256 14 12 (2752512)
I0523 21:53:40.195619 11654 net.cpp:137] Memory required for data: 2744255232
I0523 21:53:40.195626 11654 layer_factory.hpp:77] Creating layer conv3_6_em
I0523 21:53:40.195636 11654 net.cpp:84] Creating Layer conv3_6_em
I0523 21:53:40.195641 11654 net.cpp:406] conv3_6_em <- conv3_6_dw
I0523 21:53:40.195647 11654 net.cpp:380] conv3_6_em -> conv3_6_em
I0523 21:53:40.196995 11654 net.cpp:122] Setting up conv3_6_em
I0523 21:53:40.197029 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.197033 11654 net.cpp:137] Memory required for data: 2749760256
I0523 21:53:40.197054 11654 layer_factory.hpp:77] Creating layer conv3_6_em/bn
I0523 21:53:40.197074 11654 net.cpp:84] Creating Layer conv3_6_em/bn
I0523 21:53:40.197080 11654 net.cpp:406] conv3_6_em/bn <- conv3_6_em
I0523 21:53:40.197089 11654 net.cpp:367] conv3_6_em/bn -> conv3_6_em (in-place)
I0523 21:53:40.197309 11654 net.cpp:122] Setting up conv3_6_em/bn
I0523 21:53:40.197317 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.197321 11654 net.cpp:137] Memory required for data: 2755265280
I0523 21:53:40.197329 11654 layer_factory.hpp:77] Creating layer conv3_6_em/scale
I0523 21:53:40.197335 11654 net.cpp:84] Creating Layer conv3_6_em/scale
I0523 21:53:40.197340 11654 net.cpp:406] conv3_6_em/scale <- conv3_6_em
I0523 21:53:40.197345 11654 net.cpp:367] conv3_6_em/scale -> conv3_6_em (in-place)
I0523 21:53:40.197387 11654 layer_factory.hpp:77] Creating layer conv3_6_em/scale
I0523 21:53:40.197510 11654 net.cpp:122] Setting up conv3_6_em/scale
I0523 21:53:40.197520 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.197525 11654 net.cpp:137] Memory required for data: 2760770304
I0523 21:53:40.197531 11654 layer_factory.hpp:77] Creating layer res3_6
I0523 21:53:40.197538 11654 net.cpp:84] Creating Layer res3_6
I0523 21:53:40.197544 11654 net.cpp:406] res3_6 <- res3_5_res3_5_0_split_1
I0523 21:53:40.197548 11654 net.cpp:406] res3_6 <- conv3_6_em
I0523 21:53:40.197553 11654 net.cpp:380] res3_6 -> res3_6
I0523 21:53:40.197607 11654 net.cpp:122] Setting up res3_6
I0523 21:53:40.197614 11654 net.cpp:129] Top shape: 64 128 14 12 (1376256)
I0523 21:53:40.197618 11654 net.cpp:137] Memory required for data: 2766275328
I0523 21:53:40.197621 11654 layer_factory.hpp:77] Creating layer conv4_ex
I0523 21:53:40.197631 11654 net.cpp:84] Creating Layer conv4_ex
I0523 21:53:40.197635 11654 net.cpp:406] conv4_ex <- res3_6
I0523 21:53:40.197643 11654 net.cpp:380] conv4_ex -> conv4_ex
I0523 21:53:40.200716 11654 net.cpp:122] Setting up conv4_ex
I0523 21:53:40.200752 11654 net.cpp:129] Top shape: 64 512 14 12 (5505024)
I0523 21:53:40.200755 11654 net.cpp:137] Memory required for data: 2788295424
I0523 21:53:40.200762 11654 layer_factory.hpp:77] Creating layer conv4_ex/bn
I0523 21:53:40.200770 11654 net.cpp:84] Creating Layer conv4_ex/bn
I0523 21:53:40.200774 11654 net.cpp:406] conv4_ex/bn <- conv4_ex
I0523 21:53:40.200783 11654 net.cpp:367] conv4_ex/bn -> conv4_ex (in-place)
I0523 21:53:40.201027 11654 net.cpp:122] Setting up conv4_ex/bn
I0523 21:53:40.201036 11654 net.cpp:129] Top shape: 64 512 14 12 (5505024)
I0523 21:53:40.201040 11654 net.cpp:137] Memory required for data: 2810315520
I0523 21:53:40.201081 11654 layer_factory.hpp:77] Creating layer conv4_ex/scale
I0523 21:53:40.201090 11654 net.cpp:84] Creating Layer conv4_ex/scale
I0523 21:53:40.201094 11654 net.cpp:406] conv4_ex/scale <- conv4_ex
I0523 21:53:40.201099 11654 net.cpp:367] conv4_ex/scale -> conv4_ex (in-place)
I0523 21:53:40.201143 11654 layer_factory.hpp:77] Creating layer conv4_ex/scale
I0523 21:53:40.201268 11654 net.cpp:122] Setting up conv4_ex/scale
I0523 21:53:40.201277 11654 net.cpp:129] Top shape: 64 512 14 12 (5505024)
I0523 21:53:40.201279 11654 net.cpp:137] Memory required for data: 2832335616
I0523 21:53:40.201287 11654 layer_factory.hpp:77] Creating layer relu4_ex
I0523 21:53:40.201292 11654 net.cpp:84] Creating Layer relu4_ex
I0523 21:53:40.201297 11654 net.cpp:406] relu4_ex <- conv4_ex
I0523 21:53:40.201303 11654 net.cpp:367] relu4_ex -> conv4_ex (in-place)
I0523 21:53:40.201467 11654 net.cpp:122] Setting up relu4_ex
I0523 21:53:40.201475 11654 net.cpp:129] Top shape: 64 512 14 12 (5505024)
I0523 21:53:40.201478 11654 net.cpp:137] Memory required for data: 2854355712
I0523 21:53:40.201483 11654 layer_factory.hpp:77] Creating layer conv4_dw
I0523 21:53:40.201493 11654 net.cpp:84] Creating Layer conv4_dw
I0523 21:53:40.201496 11654 net.cpp:406] conv4_dw <- conv4_ex
I0523 21:53:40.201501 11654 net.cpp:380] conv4_dw -> conv4_dw
I0523 21:53:40.201756 11654 net.cpp:122] Setting up conv4_dw
I0523 21:53:40.201763 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.201767 11654 net.cpp:137] Memory required for data: 2859860736
I0523 21:53:40.201786 11654 layer_factory.hpp:77] Creating layer conv4_dw/bn
I0523 21:53:40.201792 11654 net.cpp:84] Creating Layer conv4_dw/bn
I0523 21:53:40.201797 11654 net.cpp:406] conv4_dw/bn <- conv4_dw
I0523 21:53:40.201803 11654 net.cpp:367] conv4_dw/bn -> conv4_dw (in-place)
I0523 21:53:40.202044 11654 net.cpp:122] Setting up conv4_dw/bn
I0523 21:53:40.202051 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.202055 11654 net.cpp:137] Memory required for data: 2865365760
I0523 21:53:40.202061 11654 layer_factory.hpp:77] Creating layer conv4_dw/scale
I0523 21:53:40.202069 11654 net.cpp:84] Creating Layer conv4_dw/scale
I0523 21:53:40.202072 11654 net.cpp:406] conv4_dw/scale <- conv4_dw
I0523 21:53:40.202076 11654 net.cpp:367] conv4_dw/scale -> conv4_dw (in-place)
I0523 21:53:40.202116 11654 layer_factory.hpp:77] Creating layer conv4_dw/scale
I0523 21:53:40.202258 11654 net.cpp:122] Setting up conv4_dw/scale
I0523 21:53:40.202270 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.202272 11654 net.cpp:137] Memory required for data: 2870870784
I0523 21:53:40.202280 11654 layer_factory.hpp:77] Creating layer relu4_dw
I0523 21:53:40.202284 11654 net.cpp:84] Creating Layer relu4_dw
I0523 21:53:40.202288 11654 net.cpp:406] relu4_dw <- conv4_dw
I0523 21:53:40.202292 11654 net.cpp:367] relu4_dw -> conv4_dw (in-place)
I0523 21:53:40.202400 11654 net.cpp:122] Setting up relu4_dw
I0523 21:53:40.202409 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.202412 11654 net.cpp:137] Memory required for data: 2876375808
I0523 21:53:40.202416 11654 layer_factory.hpp:77] Creating layer conv4_em
I0523 21:53:40.202425 11654 net.cpp:84] Creating Layer conv4_em
I0523 21:53:40.202427 11654 net.cpp:406] conv4_em <- conv4_dw
I0523 21:53:40.202432 11654 net.cpp:380] conv4_em -> conv4_em
I0523 21:53:40.204352 11654 net.cpp:122] Setting up conv4_em
I0523 21:53:40.204366 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.204386 11654 net.cpp:137] Memory required for data: 2877752064
I0523 21:53:40.204391 11654 layer_factory.hpp:77] Creating layer conv4_em/bn
I0523 21:53:40.204402 11654 net.cpp:84] Creating Layer conv4_em/bn
I0523 21:53:40.204424 11654 net.cpp:406] conv4_em/bn <- conv4_em
I0523 21:53:40.204430 11654 net.cpp:367] conv4_em/bn -> conv4_em (in-place)
I0523 21:53:40.204646 11654 net.cpp:122] Setting up conv4_em/bn
I0523 21:53:40.204655 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.204658 11654 net.cpp:137] Memory required for data: 2879128320
I0523 21:53:40.204665 11654 layer_factory.hpp:77] Creating layer conv4_em/scale
I0523 21:53:40.204672 11654 net.cpp:84] Creating Layer conv4_em/scale
I0523 21:53:40.204677 11654 net.cpp:406] conv4_em/scale <- conv4_em
I0523 21:53:40.204682 11654 net.cpp:367] conv4_em/scale -> conv4_em (in-place)
I0523 21:53:40.204726 11654 layer_factory.hpp:77] Creating layer conv4_em/scale
I0523 21:53:40.204849 11654 net.cpp:122] Setting up conv4_em/scale
I0523 21:53:40.204856 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.204859 11654 net.cpp:137] Memory required for data: 2880504576
I0523 21:53:40.204864 11654 layer_factory.hpp:77] Creating layer conv4_em_conv4_em/scale_0_split
I0523 21:53:40.204871 11654 net.cpp:84] Creating Layer conv4_em_conv4_em/scale_0_split
I0523 21:53:40.204895 11654 net.cpp:406] conv4_em_conv4_em/scale_0_split <- conv4_em
I0523 21:53:40.204900 11654 net.cpp:380] conv4_em_conv4_em/scale_0_split -> conv4_em_conv4_em/scale_0_split_0
I0523 21:53:40.204907 11654 net.cpp:380] conv4_em_conv4_em/scale_0_split -> conv4_em_conv4_em/scale_0_split_1
I0523 21:53:40.204949 11654 net.cpp:122] Setting up conv4_em_conv4_em/scale_0_split
I0523 21:53:40.204957 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.204962 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.204963 11654 net.cpp:137] Memory required for data: 2883257088
I0523 21:53:40.204967 11654 layer_factory.hpp:77] Creating layer conv4_1_ex
I0523 21:53:40.204977 11654 net.cpp:84] Creating Layer conv4_1_ex
I0523 21:53:40.204994 11654 net.cpp:406] conv4_1_ex <- conv4_em_conv4_em/scale_0_split_0
I0523 21:53:40.205001 11654 net.cpp:380] conv4_1_ex -> conv4_1_ex
I0523 21:53:40.206414 11654 net.cpp:122] Setting up conv4_1_ex
I0523 21:53:40.206455 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.206459 11654 net.cpp:137] Memory required for data: 2886009600
I0523 21:53:40.206480 11654 layer_factory.hpp:77] Creating layer conv4_1_ex/bn
I0523 21:53:40.206504 11654 net.cpp:84] Creating Layer conv4_1_ex/bn
I0523 21:53:40.206511 11654 net.cpp:406] conv4_1_ex/bn <- conv4_1_ex
I0523 21:53:40.206531 11654 net.cpp:367] conv4_1_ex/bn -> conv4_1_ex (in-place)
I0523 21:53:40.206796 11654 net.cpp:122] Setting up conv4_1_ex/bn
I0523 21:53:40.206805 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.206809 11654 net.cpp:137] Memory required for data: 2888762112
I0523 21:53:40.206816 11654 layer_factory.hpp:77] Creating layer conv4_1_ex/scale
I0523 21:53:40.206827 11654 net.cpp:84] Creating Layer conv4_1_ex/scale
I0523 21:53:40.206832 11654 net.cpp:406] conv4_1_ex/scale <- conv4_1_ex
I0523 21:53:40.206837 11654 net.cpp:367] conv4_1_ex/scale -> conv4_1_ex (in-place)
I0523 21:53:40.206881 11654 layer_factory.hpp:77] Creating layer conv4_1_ex/scale
I0523 21:53:40.207018 11654 net.cpp:122] Setting up conv4_1_ex/scale
I0523 21:53:40.207026 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.207029 11654 net.cpp:137] Memory required for data: 2891514624
I0523 21:53:40.207036 11654 layer_factory.hpp:77] Creating layer relu4_1_ex
I0523 21:53:40.207042 11654 net.cpp:84] Creating Layer relu4_1_ex
I0523 21:53:40.207049 11654 net.cpp:406] relu4_1_ex <- conv4_1_ex
I0523 21:53:40.207053 11654 net.cpp:367] relu4_1_ex -> conv4_1_ex (in-place)
I0523 21:53:40.207156 11654 net.cpp:122] Setting up relu4_1_ex
I0523 21:53:40.207165 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.207167 11654 net.cpp:137] Memory required for data: 2894267136
I0523 21:53:40.207171 11654 layer_factory.hpp:77] Creating layer conv4_1_dw
I0523 21:53:40.207182 11654 net.cpp:84] Creating Layer conv4_1_dw
I0523 21:53:40.207187 11654 net.cpp:406] conv4_1_dw <- conv4_1_ex
I0523 21:53:40.207192 11654 net.cpp:380] conv4_1_dw -> conv4_1_dw
I0523 21:53:40.207418 11654 net.cpp:122] Setting up conv4_1_dw
I0523 21:53:40.207427 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.207429 11654 net.cpp:137] Memory required for data: 2897019648
I0523 21:53:40.207434 11654 layer_factory.hpp:77] Creating layer conv4_1_dw/bn
I0523 21:53:40.207440 11654 net.cpp:84] Creating Layer conv4_1_dw/bn
I0523 21:53:40.207443 11654 net.cpp:406] conv4_1_dw/bn <- conv4_1_dw
I0523 21:53:40.207448 11654 net.cpp:367] conv4_1_dw/bn -> conv4_1_dw (in-place)
I0523 21:53:40.207684 11654 net.cpp:122] Setting up conv4_1_dw/bn
I0523 21:53:40.207691 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.207695 11654 net.cpp:137] Memory required for data: 2899772160
I0523 21:53:40.207702 11654 layer_factory.hpp:77] Creating layer conv4_1_dw/scale
I0523 21:53:40.207710 11654 net.cpp:84] Creating Layer conv4_1_dw/scale
I0523 21:53:40.207712 11654 net.cpp:406] conv4_1_dw/scale <- conv4_1_dw
I0523 21:53:40.207717 11654 net.cpp:367] conv4_1_dw/scale -> conv4_1_dw (in-place)
I0523 21:53:40.207762 11654 layer_factory.hpp:77] Creating layer conv4_1_dw/scale
I0523 21:53:40.207901 11654 net.cpp:122] Setting up conv4_1_dw/scale
I0523 21:53:40.207908 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.207911 11654 net.cpp:137] Memory required for data: 2902524672
I0523 21:53:40.207916 11654 layer_factory.hpp:77] Creating layer relu4_1_dw
I0523 21:53:40.207924 11654 net.cpp:84] Creating Layer relu4_1_dw
I0523 21:53:40.207927 11654 net.cpp:406] relu4_1_dw <- conv4_1_dw
I0523 21:53:40.207931 11654 net.cpp:367] relu4_1_dw -> conv4_1_dw (in-place)
I0523 21:53:40.208032 11654 net.cpp:122] Setting up relu4_1_dw
I0523 21:53:40.208040 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.208043 11654 net.cpp:137] Memory required for data: 2905277184
I0523 21:53:40.208061 11654 layer_factory.hpp:77] Creating layer conv4_1_em
I0523 21:53:40.208072 11654 net.cpp:84] Creating Layer conv4_1_em
I0523 21:53:40.208077 11654 net.cpp:406] conv4_1_em <- conv4_1_dw
I0523 21:53:40.208082 11654 net.cpp:380] conv4_1_em -> conv4_1_em
I0523 21:53:40.209455 11654 net.cpp:122] Setting up conv4_1_em
I0523 21:53:40.209470 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.209488 11654 net.cpp:137] Memory required for data: 2906653440
I0523 21:53:40.209493 11654 layer_factory.hpp:77] Creating layer conv4_1_em/bn
I0523 21:53:40.209502 11654 net.cpp:84] Creating Layer conv4_1_em/bn
I0523 21:53:40.209524 11654 net.cpp:406] conv4_1_em/bn <- conv4_1_em
I0523 21:53:40.209532 11654 net.cpp:367] conv4_1_em/bn -> conv4_1_em (in-place)
I0523 21:53:40.209746 11654 net.cpp:122] Setting up conv4_1_em/bn
I0523 21:53:40.209754 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.209758 11654 net.cpp:137] Memory required for data: 2908029696
I0523 21:53:40.209764 11654 layer_factory.hpp:77] Creating layer conv4_1_em/scale
I0523 21:53:40.209771 11654 net.cpp:84] Creating Layer conv4_1_em/scale
I0523 21:53:40.209775 11654 net.cpp:406] conv4_1_em/scale <- conv4_1_em
I0523 21:53:40.209782 11654 net.cpp:367] conv4_1_em/scale -> conv4_1_em (in-place)
I0523 21:53:40.209823 11654 layer_factory.hpp:77] Creating layer conv4_1_em/scale
I0523 21:53:40.209946 11654 net.cpp:122] Setting up conv4_1_em/scale
I0523 21:53:40.209954 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.209957 11654 net.cpp:137] Memory required for data: 2909405952
I0523 21:53:40.209964 11654 layer_factory.hpp:77] Creating layer res4_1
I0523 21:53:40.209969 11654 net.cpp:84] Creating Layer res4_1
I0523 21:53:40.209972 11654 net.cpp:406] res4_1 <- conv4_em_conv4_em/scale_0_split_1
I0523 21:53:40.209976 11654 net.cpp:406] res4_1 <- conv4_1_em
I0523 21:53:40.209981 11654 net.cpp:380] res4_1 -> res4_1
I0523 21:53:40.210006 11654 net.cpp:122] Setting up res4_1
I0523 21:53:40.210013 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.210016 11654 net.cpp:137] Memory required for data: 2910782208
I0523 21:53:40.210019 11654 layer_factory.hpp:77] Creating layer res4_1_res4_1_0_split
I0523 21:53:40.210027 11654 net.cpp:84] Creating Layer res4_1_res4_1_0_split
I0523 21:53:40.210031 11654 net.cpp:406] res4_1_res4_1_0_split <- res4_1
I0523 21:53:40.210036 11654 net.cpp:380] res4_1_res4_1_0_split -> res4_1_res4_1_0_split_0
I0523 21:53:40.210041 11654 net.cpp:380] res4_1_res4_1_0_split -> res4_1_res4_1_0_split_1
I0523 21:53:40.210078 11654 net.cpp:122] Setting up res4_1_res4_1_0_split
I0523 21:53:40.210084 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.210088 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.210091 11654 net.cpp:137] Memory required for data: 2913534720
I0523 21:53:40.210095 11654 layer_factory.hpp:77] Creating layer conv4_2_ex
I0523 21:53:40.210105 11654 net.cpp:84] Creating Layer conv4_2_ex
I0523 21:53:40.210110 11654 net.cpp:406] conv4_2_ex <- res4_1_res4_1_0_split_0
I0523 21:53:40.210116 11654 net.cpp:380] conv4_2_ex -> conv4_2_ex
I0523 21:53:40.211477 11654 net.cpp:122] Setting up conv4_2_ex
I0523 21:53:40.211493 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.211498 11654 net.cpp:137] Memory required for data: 2916287232
I0523 21:53:40.211503 11654 layer_factory.hpp:77] Creating layer conv4_2_ex/bn
I0523 21:53:40.211516 11654 net.cpp:84] Creating Layer conv4_2_ex/bn
I0523 21:53:40.211524 11654 net.cpp:406] conv4_2_ex/bn <- conv4_2_ex
I0523 21:53:40.211529 11654 net.cpp:367] conv4_2_ex/bn -> conv4_2_ex (in-place)
I0523 21:53:40.211767 11654 net.cpp:122] Setting up conv4_2_ex/bn
I0523 21:53:40.211776 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.211778 11654 net.cpp:137] Memory required for data: 2919039744
I0523 21:53:40.211786 11654 layer_factory.hpp:77] Creating layer conv4_2_ex/scale
I0523 21:53:40.211793 11654 net.cpp:84] Creating Layer conv4_2_ex/scale
I0523 21:53:40.211812 11654 net.cpp:406] conv4_2_ex/scale <- conv4_2_ex
I0523 21:53:40.211817 11654 net.cpp:367] conv4_2_ex/scale -> conv4_2_ex (in-place)
I0523 21:53:40.211863 11654 layer_factory.hpp:77] Creating layer conv4_2_ex/scale
I0523 21:53:40.211989 11654 net.cpp:122] Setting up conv4_2_ex/scale
I0523 21:53:40.211998 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.212002 11654 net.cpp:137] Memory required for data: 2921792256
I0523 21:53:40.212007 11654 layer_factory.hpp:77] Creating layer relu4_2_ex
I0523 21:53:40.212015 11654 net.cpp:84] Creating Layer relu4_2_ex
I0523 21:53:40.212020 11654 net.cpp:406] relu4_2_ex <- conv4_2_ex
I0523 21:53:40.212026 11654 net.cpp:367] relu4_2_ex -> conv4_2_ex (in-place)
I0523 21:53:40.212142 11654 net.cpp:122] Setting up relu4_2_ex
I0523 21:53:40.212150 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.212153 11654 net.cpp:137] Memory required for data: 2924544768
I0523 21:53:40.212159 11654 layer_factory.hpp:77] Creating layer conv4_2_dw
I0523 21:53:40.212169 11654 net.cpp:84] Creating Layer conv4_2_dw
I0523 21:53:40.212175 11654 net.cpp:406] conv4_2_dw <- conv4_2_ex
I0523 21:53:40.212182 11654 net.cpp:380] conv4_2_dw -> conv4_2_dw
I0523 21:53:40.212425 11654 net.cpp:122] Setting up conv4_2_dw
I0523 21:53:40.212433 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.212436 11654 net.cpp:137] Memory required for data: 2927297280
I0523 21:53:40.212440 11654 layer_factory.hpp:77] Creating layer conv4_2_dw/bn
I0523 21:53:40.212446 11654 net.cpp:84] Creating Layer conv4_2_dw/bn
I0523 21:53:40.212450 11654 net.cpp:406] conv4_2_dw/bn <- conv4_2_dw
I0523 21:53:40.212456 11654 net.cpp:367] conv4_2_dw/bn -> conv4_2_dw (in-place)
I0523 21:53:40.212685 11654 net.cpp:122] Setting up conv4_2_dw/bn
I0523 21:53:40.212693 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.212697 11654 net.cpp:137] Memory required for data: 2930049792
I0523 21:53:40.212703 11654 layer_factory.hpp:77] Creating layer conv4_2_dw/scale
I0523 21:53:40.212709 11654 net.cpp:84] Creating Layer conv4_2_dw/scale
I0523 21:53:40.212713 11654 net.cpp:406] conv4_2_dw/scale <- conv4_2_dw
I0523 21:53:40.212718 11654 net.cpp:367] conv4_2_dw/scale -> conv4_2_dw (in-place)
I0523 21:53:40.212759 11654 layer_factory.hpp:77] Creating layer conv4_2_dw/scale
I0523 21:53:40.212906 11654 net.cpp:122] Setting up conv4_2_dw/scale
I0523 21:53:40.212914 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.212918 11654 net.cpp:137] Memory required for data: 2932802304
I0523 21:53:40.212923 11654 layer_factory.hpp:77] Creating layer relu4_2_dw
I0523 21:53:40.212930 11654 net.cpp:84] Creating Layer relu4_2_dw
I0523 21:53:40.212934 11654 net.cpp:406] relu4_2_dw <- conv4_2_dw
I0523 21:53:40.212939 11654 net.cpp:367] relu4_2_dw -> conv4_2_dw (in-place)
I0523 21:53:40.213037 11654 net.cpp:122] Setting up relu4_2_dw
I0523 21:53:40.213044 11654 net.cpp:129] Top shape: 64 256 7 6 (688128)
I0523 21:53:40.213047 11654 net.cpp:137] Memory required for data: 2935554816
I0523 21:53:40.213052 11654 layer_factory.hpp:77] Creating layer conv4_2_em
I0523 21:53:40.213063 11654 net.cpp:84] Creating Layer conv4_2_em
I0523 21:53:40.213068 11654 net.cpp:406] conv4_2_em <- conv4_2_dw
I0523 21:53:40.213073 11654 net.cpp:380] conv4_2_em -> conv4_2_em
I0523 21:53:40.214445 11654 net.cpp:122] Setting up conv4_2_em
I0523 21:53:40.214460 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.214479 11654 net.cpp:137] Memory required for data: 2936931072
I0523 21:53:40.214486 11654 layer_factory.hpp:77] Creating layer conv4_2_em/bn
I0523 21:53:40.214511 11654 net.cpp:84] Creating Layer conv4_2_em/bn
I0523 21:53:40.214517 11654 net.cpp:406] conv4_2_em/bn <- conv4_2_em
I0523 21:53:40.214524 11654 net.cpp:367] conv4_2_em/bn -> conv4_2_em (in-place)
I0523 21:53:40.214769 11654 net.cpp:122] Setting up conv4_2_em/bn
I0523 21:53:40.214778 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.214782 11654 net.cpp:137] Memory required for data: 2938307328
I0523 21:53:40.214789 11654 layer_factory.hpp:77] Creating layer conv4_2_em/scale
I0523 21:53:40.214818 11654 net.cpp:84] Creating Layer conv4_2_em/scale
I0523 21:53:40.214823 11654 net.cpp:406] conv4_2_em/scale <- conv4_2_em
I0523 21:53:40.214829 11654 net.cpp:367] conv4_2_em/scale -> conv4_2_em (in-place)
I0523 21:53:40.214877 11654 layer_factory.hpp:77] Creating layer conv4_2_em/scale
I0523 21:53:40.215006 11654 net.cpp:122] Setting up conv4_2_em/scale
I0523 21:53:40.215015 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.215018 11654 net.cpp:137] Memory required for data: 2939683584
I0523 21:53:40.215024 11654 layer_factory.hpp:77] Creating layer res4_2
I0523 21:53:40.215032 11654 net.cpp:84] Creating Layer res4_2
I0523 21:53:40.215036 11654 net.cpp:406] res4_2 <- res4_1_res4_1_0_split_1
I0523 21:53:40.215041 11654 net.cpp:406] res4_2 <- conv4_2_em
I0523 21:53:40.215049 11654 net.cpp:380] res4_2 -> res4_2
I0523 21:53:40.215073 11654 net.cpp:122] Setting up res4_2
I0523 21:53:40.215083 11654 net.cpp:129] Top shape: 64 128 7 6 (344064)
I0523 21:53:40.215087 11654 net.cpp:137] Memory required for data: 2941059840
I0523 21:53:40.215090 11654 layer_factory.hpp:77] Creating layer conv5_ex
I0523 21:53:40.215098 11654 net.cpp:84] Creating Layer conv5_ex
I0523 21:53:40.215102 11654 net.cpp:406] conv5_ex <- res4_2
I0523 21:53:40.215111 11654 net.cpp:380] conv5_ex -> conv5_ex
I0523 21:53:40.216667 11654 net.cpp:122] Setting up conv5_ex
I0523 21:53:40.216681 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.216684 11654 net.cpp:137] Memory required for data: 2946564864
I0523 21:53:40.216691 11654 layer_factory.hpp:77] Creating layer conv5_ex/bn
I0523 21:53:40.216701 11654 net.cpp:84] Creating Layer conv5_ex/bn
I0523 21:53:40.216706 11654 net.cpp:406] conv5_ex/bn <- conv5_ex
I0523 21:53:40.216722 11654 net.cpp:367] conv5_ex/bn -> conv5_ex (in-place)
I0523 21:53:40.216961 11654 net.cpp:122] Setting up conv5_ex/bn
I0523 21:53:40.216969 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.216974 11654 net.cpp:137] Memory required for data: 2952069888
I0523 21:53:40.216979 11654 layer_factory.hpp:77] Creating layer conv5_ex/scale
I0523 21:53:40.216989 11654 net.cpp:84] Creating Layer conv5_ex/scale
I0523 21:53:40.216995 11654 net.cpp:406] conv5_ex/scale <- conv5_ex
I0523 21:53:40.217000 11654 net.cpp:367] conv5_ex/scale -> conv5_ex (in-place)
I0523 21:53:40.217041 11654 layer_factory.hpp:77] Creating layer conv5_ex/scale
I0523 21:53:40.217171 11654 net.cpp:122] Setting up conv5_ex/scale
I0523 21:53:40.217180 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.217182 11654 net.cpp:137] Memory required for data: 2957574912
I0523 21:53:40.217187 11654 layer_factory.hpp:77] Creating layer relu5_ex
I0523 21:53:40.217195 11654 net.cpp:84] Creating Layer relu5_ex
I0523 21:53:40.217198 11654 net.cpp:406] relu5_ex <- conv5_ex
I0523 21:53:40.217206 11654 net.cpp:367] relu5_ex -> conv5_ex (in-place)
I0523 21:53:40.217305 11654 net.cpp:122] Setting up relu5_ex
I0523 21:53:40.217312 11654 net.cpp:129] Top shape: 64 512 7 6 (1376256)
I0523 21:53:40.217315 11654 net.cpp:137] Memory required for data: 2963079936
I0523 21:53:40.217320 11654 layer_factory.hpp:77] Creating layer conv5_dw
I0523 21:53:40.217330 11654 net.cpp:84] Creating Layer conv5_dw
I0523 21:53:40.217335 11654 net.cpp:406] conv5_dw <- conv5_ex
I0523 21:53:40.217340 11654 net.cpp:380] conv5_dw -> conv5_dw
I0523 21:53:40.217701 11654 net.cpp:122] Setting up conv5_dw
I0523 21:53:40.217708 11654 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0523 21:53:40.217711 11654 net.cpp:137] Memory required for data: 2963211008
I0523 21:53:40.217727 11654 layer_factory.hpp:77] Creating layer conv5_dw/bn
I0523 21:53:40.217734 11654 net.cpp:84] Creating Layer conv5_dw/bn
I0523 21:53:40.217737 11654 net.cpp:406] conv5_dw/bn <- conv5_dw
I0523 21:53:40.217744 11654 net.cpp:367] conv5_dw/bn -> conv5_dw (in-place)
I0523 21:53:40.217958 11654 net.cpp:122] Setting up conv5_dw/bn
I0523 21:53:40.217965 11654 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0523 21:53:40.217968 11654 net.cpp:137] Memory required for data: 2963342080
I0523 21:53:40.217988 11654 layer_factory.hpp:77] Creating layer conv5_dw/scale
I0523 21:53:40.217995 11654 net.cpp:84] Creating Layer conv5_dw/scale
I0523 21:53:40.217998 11654 net.cpp:406] conv5_dw/scale <- conv5_dw
I0523 21:53:40.218003 11654 net.cpp:367] conv5_dw/scale -> conv5_dw (in-place)
I0523 21:53:40.218046 11654 layer_factory.hpp:77] Creating layer conv5_dw/scale
I0523 21:53:40.218196 11654 net.cpp:122] Setting up conv5_dw/scale
I0523 21:53:40.218204 11654 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0523 21:53:40.218207 11654 net.cpp:137] Memory required for data: 2963473152
I0523 21:53:40.218214 11654 layer_factory.hpp:77] Creating layer fc5
I0523 21:53:40.218225 11654 net.cpp:84] Creating Layer fc5
I0523 21:53:40.218230 11654 net.cpp:406] fc5 <- conv5_dw
I0523 21:53:40.218235 11654 net.cpp:380] fc5 -> fc5
I0523 21:53:40.218690 11654 net.cpp:122] Setting up fc5
I0523 21:53:40.218704 11654 net.cpp:129] Top shape: 64 128 (8192)
I0523 21:53:40.218722 11654 net.cpp:137] Memory required for data: 2963505920
I0523 21:53:40.218726 11654 layer_factory.hpp:77] Creating layer fc5_bn
I0523 21:53:40.218750 11654 net.cpp:84] Creating Layer fc5_bn
I0523 21:53:40.218755 11654 net.cpp:406] fc5_bn <- fc5
I0523 21:53:40.218776 11654 net.cpp:367] fc5_bn -> fc5 (in-place)
I0523 21:53:40.218984 11654 net.cpp:122] Setting up fc5_bn
I0523 21:53:40.218991 11654 net.cpp:129] Top shape: 64 128 (8192)
I0523 21:53:40.218994 11654 net.cpp:137] Memory required for data: 2963538688
I0523 21:53:40.219002 11654 layer_factory.hpp:77] Creating layer norm1
I0523 21:53:40.219017 11654 net.cpp:84] Creating Layer norm1
I0523 21:53:40.219022 11654 net.cpp:406] norm1 <- fc5
I0523 21:53:40.219027 11654 net.cpp:380] norm1 -> norm1
I0523 21:53:40.219084 11654 net.cpp:122] Setting up norm1
I0523 21:53:40.219090 11654 net.cpp:129] Top shape: 64 128 1 1 (8192)
I0523 21:53:40.219094 11654 net.cpp:137] Memory required for data: 2963571456
I0523 21:53:40.219096 11654 layer_factory.hpp:77] Creating layer fc-6_l2
I0523 21:53:40.219105 11654 net.cpp:84] Creating Layer fc-6_l2
I0523 21:53:40.219110 11654 net.cpp:406] fc-6_l2 <- norm1
I0523 21:53:40.219115 11654 net.cpp:380] fc-6_l2 -> fc-6_l2
I0523 21:53:40.276199 11654 net.cpp:122] Setting up fc-6_l2
I0523 21:53:40.276253 11654 net.cpp:129] Top shape: 64 54547 (3491008)
I0523 21:53:40.276258 11654 net.cpp:137] Memory required for data: 2977535488
I0523 21:53:40.276268 11654 layer_factory.hpp:77] Creating layer fc-6_margin
I0523 21:53:40.276283 11654 net.cpp:84] Creating Layer fc-6_margin
I0523 21:53:40.276305 11654 net.cpp:406] fc-6_margin <- fc-6_l2
I0523 21:53:40.276314 11654 net.cpp:406] fc-6_margin <- label_data_1_split_0
I0523 21:53:40.276322 11654 net.cpp:380] fc-6_margin -> fc-6_margin
I0523 21:53:40.276367 11654 net.cpp:122] Setting up fc-6_margin
I0523 21:53:40.276374 11654 net.cpp:129] Top shape: 64 54547 (3491008)
I0523 21:53:40.276377 11654 net.cpp:137] Memory required for data: 2991499520
I0523 21:53:40.276381 11654 layer_factory.hpp:77] Creating layer fc-6_margin_scale
I0523 21:53:40.276389 11654 net.cpp:84] Creating Layer fc-6_margin_scale
I0523 21:53:40.276394 11654 net.cpp:406] fc-6_margin_scale <- fc-6_margin
I0523 21:53:40.276402 11654 net.cpp:380] fc-6_margin_scale -> fc-6_margin_scale
I0523 21:53:40.278301 11654 net.cpp:122] Setting up fc-6_margin_scale
I0523 21:53:40.278314 11654 net.cpp:129] Top shape: 64 54547 (3491008)
I0523 21:53:40.278334 11654 net.cpp:137] Memory required for data: 3005463552
I0523 21:53:40.278340 11654 layer_factory.hpp:77] Creating layer softmax_loss
I0523 21:53:40.278348 11654 net.cpp:84] Creating Layer softmax_loss
I0523 21:53:40.278353 11654 net.cpp:406] softmax_loss <- fc-6_margin_scale
I0523 21:53:40.278357 11654 net.cpp:406] softmax_loss <- label_data_1_split_1
I0523 21:53:40.278380 11654 net.cpp:380] softmax_loss -> softmax_loss
I0523 21:53:40.278391 11654 layer_factory.hpp:77] Creating layer softmax_loss
I0523 21:53:40.289075 11654 net.cpp:122] Setting up softmax_loss
I0523 21:53:40.289093 11654 net.cpp:129] Top shape: (1)
I0523 21:53:40.289129 11654 net.cpp:132]     with loss weight 1
I0523 21:53:40.289167 11654 net.cpp:137] Memory required for data: 3005463556
I0523 21:53:40.289172 11654 net.cpp:198] softmax_loss needs backward computation.
I0523 21:53:40.289176 11654 net.cpp:198] fc-6_margin_scale needs backward computation.
I0523 21:53:40.289180 11654 net.cpp:198] fc-6_margin needs backward computation.
I0523 21:53:40.289185 11654 net.cpp:198] fc-6_l2 needs backward computation.
I0523 21:53:40.289199 11654 net.cpp:198] norm1 needs backward computation.
I0523 21:53:40.289203 11654 net.cpp:198] fc5_bn needs backward computation.
I0523 21:53:40.289207 11654 net.cpp:198] fc5 needs backward computation.
I0523 21:53:40.289211 11654 net.cpp:198] conv5_dw/scale needs backward computation.
I0523 21:53:40.289216 11654 net.cpp:198] conv5_dw/bn needs backward computation.
I0523 21:53:40.289219 11654 net.cpp:198] conv5_dw needs backward computation.
I0523 21:53:40.289222 11654 net.cpp:198] relu5_ex needs backward computation.
I0523 21:53:40.289227 11654 net.cpp:198] conv5_ex/scale needs backward computation.
I0523 21:53:40.289229 11654 net.cpp:198] conv5_ex/bn needs backward computation.
I0523 21:53:40.289232 11654 net.cpp:198] conv5_ex needs backward computation.
I0523 21:53:40.289237 11654 net.cpp:198] res4_2 needs backward computation.
I0523 21:53:40.289240 11654 net.cpp:198] conv4_2_em/scale needs backward computation.
I0523 21:53:40.289244 11654 net.cpp:198] conv4_2_em/bn needs backward computation.
I0523 21:53:40.289247 11654 net.cpp:198] conv4_2_em needs backward computation.
I0523 21:53:40.289250 11654 net.cpp:198] relu4_2_dw needs backward computation.
I0523 21:53:40.289253 11654 net.cpp:198] conv4_2_dw/scale needs backward computation.
I0523 21:53:40.289258 11654 net.cpp:198] conv4_2_dw/bn needs backward computation.
I0523 21:53:40.289260 11654 net.cpp:198] conv4_2_dw needs backward computation.
I0523 21:53:40.289264 11654 net.cpp:198] relu4_2_ex needs backward computation.
I0523 21:53:40.289268 11654 net.cpp:198] conv4_2_ex/scale needs backward computation.
I0523 21:53:40.289270 11654 net.cpp:198] conv4_2_ex/bn needs backward computation.
I0523 21:53:40.289274 11654 net.cpp:198] conv4_2_ex needs backward computation.
I0523 21:53:40.289278 11654 net.cpp:198] res4_1_res4_1_0_split needs backward computation.
I0523 21:53:40.289281 11654 net.cpp:198] res4_1 needs backward computation.
I0523 21:53:40.289285 11654 net.cpp:198] conv4_1_em/scale needs backward computation.
I0523 21:53:40.289289 11654 net.cpp:198] conv4_1_em/bn needs backward computation.
I0523 21:53:40.289292 11654 net.cpp:198] conv4_1_em needs backward computation.
I0523 21:53:40.289296 11654 net.cpp:198] relu4_1_dw needs backward computation.
I0523 21:53:40.289299 11654 net.cpp:198] conv4_1_dw/scale needs backward computation.
I0523 21:53:40.289302 11654 net.cpp:198] conv4_1_dw/bn needs backward computation.
I0523 21:53:40.289306 11654 net.cpp:198] conv4_1_dw needs backward computation.
I0523 21:53:40.289309 11654 net.cpp:198] relu4_1_ex needs backward computation.
I0523 21:53:40.289314 11654 net.cpp:198] conv4_1_ex/scale needs backward computation.
I0523 21:53:40.289316 11654 net.cpp:198] conv4_1_ex/bn needs backward computation.
I0523 21:53:40.289319 11654 net.cpp:198] conv4_1_ex needs backward computation.
I0523 21:53:40.289324 11654 net.cpp:198] conv4_em_conv4_em/scale_0_split needs backward computation.
I0523 21:53:40.289327 11654 net.cpp:198] conv4_em/scale needs backward computation.
I0523 21:53:40.289330 11654 net.cpp:198] conv4_em/bn needs backward computation.
I0523 21:53:40.289333 11654 net.cpp:198] conv4_em needs backward computation.
I0523 21:53:40.289337 11654 net.cpp:198] relu4_dw needs backward computation.
I0523 21:53:40.289340 11654 net.cpp:198] conv4_dw/scale needs backward computation.
I0523 21:53:40.289345 11654 net.cpp:198] conv4_dw/bn needs backward computation.
I0523 21:53:40.289347 11654 net.cpp:198] conv4_dw needs backward computation.
I0523 21:53:40.289350 11654 net.cpp:198] relu4_ex needs backward computation.
I0523 21:53:40.289355 11654 net.cpp:198] conv4_ex/scale needs backward computation.
I0523 21:53:40.289367 11654 net.cpp:198] conv4_ex/bn needs backward computation.
I0523 21:53:40.289371 11654 net.cpp:198] conv4_ex needs backward computation.
I0523 21:53:40.289376 11654 net.cpp:198] res3_6 needs backward computation.
I0523 21:53:40.289379 11654 net.cpp:198] conv3_6_em/scale needs backward computation.
I0523 21:53:40.289383 11654 net.cpp:198] conv3_6_em/bn needs backward computation.
I0523 21:53:40.289386 11654 net.cpp:198] conv3_6_em needs backward computation.
I0523 21:53:40.289389 11654 net.cpp:198] relu3_6_dw needs backward computation.
I0523 21:53:40.289393 11654 net.cpp:198] conv3_6_dw/scale needs backward computation.
I0523 21:53:40.289397 11654 net.cpp:198] conv3_6_dw/bn needs backward computation.
I0523 21:53:40.289399 11654 net.cpp:198] conv3_6_dw needs backward computation.
I0523 21:53:40.289403 11654 net.cpp:198] relu3_6_ex needs backward computation.
I0523 21:53:40.289407 11654 net.cpp:198] conv3_6_ex/scale needs backward computation.
I0523 21:53:40.289410 11654 net.cpp:198] conv3_6_ex/bn needs backward computation.
I0523 21:53:40.289413 11654 net.cpp:198] conv3_6_ex needs backward computation.
I0523 21:53:40.289417 11654 net.cpp:198] res3_5_res3_5_0_split needs backward computation.
I0523 21:53:40.289420 11654 net.cpp:198] res3_5 needs backward computation.
I0523 21:53:40.289425 11654 net.cpp:198] conv3_5_em/scale needs backward computation.
I0523 21:53:40.289428 11654 net.cpp:198] conv3_5_em/bn needs backward computation.
I0523 21:53:40.289433 11654 net.cpp:198] conv3_5_em needs backward computation.
I0523 21:53:40.289435 11654 net.cpp:198] relu3_5_dw needs backward computation.
I0523 21:53:40.289438 11654 net.cpp:198] conv3_5_dw/scale needs backward computation.
I0523 21:53:40.289443 11654 net.cpp:198] conv3_5_dw/bn needs backward computation.
I0523 21:53:40.289445 11654 net.cpp:198] conv3_5_dw needs backward computation.
I0523 21:53:40.289449 11654 net.cpp:198] relu3_5_ex needs backward computation.
I0523 21:53:40.289453 11654 net.cpp:198] conv3_5_ex/scale needs backward computation.
I0523 21:53:40.289455 11654 net.cpp:198] conv3_5_ex/bn needs backward computation.
I0523 21:53:40.289458 11654 net.cpp:198] conv3_5_ex needs backward computation.
I0523 21:53:40.289463 11654 net.cpp:198] res3_4_res3_4_0_split needs backward computation.
I0523 21:53:40.289466 11654 net.cpp:198] res3_4 needs backward computation.
I0523 21:53:40.289470 11654 net.cpp:198] conv3_4_em/scale needs backward computation.
I0523 21:53:40.289474 11654 net.cpp:198] conv3_4_em/bn needs backward computation.
I0523 21:53:40.289476 11654 net.cpp:198] conv3_4_em needs backward computation.
I0523 21:53:40.289479 11654 net.cpp:198] relu3_4_dw needs backward computation.
I0523 21:53:40.289484 11654 net.cpp:198] conv3_4_dw/scale needs backward computation.
I0523 21:53:40.289486 11654 net.cpp:198] conv3_4_dw/bn needs backward computation.
I0523 21:53:40.289489 11654 net.cpp:198] conv3_4_dw needs backward computation.
I0523 21:53:40.289494 11654 net.cpp:198] relu3_4_ex needs backward computation.
I0523 21:53:40.289496 11654 net.cpp:198] conv3_4_ex/scale needs backward computation.
I0523 21:53:40.289500 11654 net.cpp:198] conv3_4_ex/bn needs backward computation.
I0523 21:53:40.289503 11654 net.cpp:198] conv3_4_ex needs backward computation.
I0523 21:53:40.289507 11654 net.cpp:198] res3_3_res3_3_0_split needs backward computation.
I0523 21:53:40.289510 11654 net.cpp:198] res3_3 needs backward computation.
I0523 21:53:40.289515 11654 net.cpp:198] conv3_3_em/scale needs backward computation.
I0523 21:53:40.289518 11654 net.cpp:198] conv3_3_em/bn needs backward computation.
I0523 21:53:40.289521 11654 net.cpp:198] conv3_3_em needs backward computation.
I0523 21:53:40.289525 11654 net.cpp:198] relu3_3_dw needs backward computation.
I0523 21:53:40.289527 11654 net.cpp:198] conv3_3_dw/scale needs backward computation.
I0523 21:53:40.289531 11654 net.cpp:198] conv3_3_dw/bn needs backward computation.
I0523 21:53:40.289535 11654 net.cpp:198] conv3_3_dw needs backward computation.
I0523 21:53:40.289537 11654 net.cpp:198] relu3_3_ex needs backward computation.
I0523 21:53:40.289546 11654 net.cpp:198] conv3_3_ex/scale needs backward computation.
I0523 21:53:40.289551 11654 net.cpp:198] conv3_3_ex/bn needs backward computation.
I0523 21:53:40.289553 11654 net.cpp:198] conv3_3_ex needs backward computation.
I0523 21:53:40.289557 11654 net.cpp:198] res3_2_res3_2_0_split needs backward computation.
I0523 21:53:40.289561 11654 net.cpp:198] res3_2 needs backward computation.
I0523 21:53:40.289566 11654 net.cpp:198] conv3_2_em/scale needs backward computation.
I0523 21:53:40.289568 11654 net.cpp:198] conv3_2_em/bn needs backward computation.
I0523 21:53:40.289572 11654 net.cpp:198] conv3_2_em needs backward computation.
I0523 21:53:40.289575 11654 net.cpp:198] relu3_2_dw needs backward computation.
I0523 21:53:40.289579 11654 net.cpp:198] conv3_2_dw/scale needs backward computation.
I0523 21:53:40.289582 11654 net.cpp:198] conv3_2_dw/bn needs backward computation.
I0523 21:53:40.289585 11654 net.cpp:198] conv3_2_dw needs backward computation.
I0523 21:53:40.289589 11654 net.cpp:198] relu3_2_ex needs backward computation.
I0523 21:53:40.289592 11654 net.cpp:198] conv3_2_ex/scale needs backward computation.
I0523 21:53:40.289597 11654 net.cpp:198] conv3_2_ex/bn needs backward computation.
I0523 21:53:40.289599 11654 net.cpp:198] conv3_2_ex needs backward computation.
I0523 21:53:40.289603 11654 net.cpp:198] res3_1_res3_1_0_split needs backward computation.
I0523 21:53:40.289607 11654 net.cpp:198] res3_1 needs backward computation.
I0523 21:53:40.289610 11654 net.cpp:198] conv3_1_em/scale needs backward computation.
I0523 21:53:40.289614 11654 net.cpp:198] conv3_1_em/bn needs backward computation.
I0523 21:53:40.289618 11654 net.cpp:198] conv3_1_em needs backward computation.
I0523 21:53:40.289621 11654 net.cpp:198] relu3_1_dw needs backward computation.
I0523 21:53:40.289624 11654 net.cpp:198] conv3_1_dw/scale needs backward computation.
I0523 21:53:40.289628 11654 net.cpp:198] conv3_1_dw/bn needs backward computation.
I0523 21:53:40.289631 11654 net.cpp:198] conv3_1_dw needs backward computation.
I0523 21:53:40.289634 11654 net.cpp:198] relu3_1_ex needs backward computation.
I0523 21:53:40.289638 11654 net.cpp:198] conv3_1_ex/scale needs backward computation.
I0523 21:53:40.289641 11654 net.cpp:198] conv3_1_ex/bn needs backward computation.
I0523 21:53:40.289645 11654 net.cpp:198] conv3_1_ex needs backward computation.
I0523 21:53:40.289649 11654 net.cpp:198] conv3_em_conv3_em/scale_0_split needs backward computation.
I0523 21:53:40.289654 11654 net.cpp:198] conv3_em/scale needs backward computation.
I0523 21:53:40.289656 11654 net.cpp:198] conv3_em/bn needs backward computation.
I0523 21:53:40.289659 11654 net.cpp:198] conv3_em needs backward computation.
I0523 21:53:40.289664 11654 net.cpp:198] relu3_dw needs backward computation.
I0523 21:53:40.289666 11654 net.cpp:198] conv3_dw/scale needs backward computation.
I0523 21:53:40.289669 11654 net.cpp:198] conv3_dw/bn needs backward computation.
I0523 21:53:40.289674 11654 net.cpp:198] conv3_dw needs backward computation.
I0523 21:53:40.289677 11654 net.cpp:198] relu3_ex needs backward computation.
I0523 21:53:40.289680 11654 net.cpp:198] conv3_ex/scale needs backward computation.
I0523 21:53:40.289683 11654 net.cpp:198] conv3_ex/bn needs backward computation.
I0523 21:53:40.289686 11654 net.cpp:198] conv3_ex needs backward computation.
I0523 21:53:40.289690 11654 net.cpp:198] res2_4 needs backward computation.
I0523 21:53:40.289695 11654 net.cpp:198] conv2_4_em/scale needs backward computation.
I0523 21:53:40.289698 11654 net.cpp:198] conv2_4_em/bn needs backward computation.
I0523 21:53:40.289701 11654 net.cpp:198] conv2_4_em needs backward computation.
I0523 21:53:40.289705 11654 net.cpp:198] relu2_4_dw needs backward computation.
I0523 21:53:40.289708 11654 net.cpp:198] conv2_4_dw/scale needs backward computation.
I0523 21:53:40.289712 11654 net.cpp:198] conv2_4_dw/bn needs backward computation.
I0523 21:53:40.289716 11654 net.cpp:198] conv2_4_dw needs backward computation.
I0523 21:53:40.289726 11654 net.cpp:198] relu2_4_ex needs backward computation.
I0523 21:53:40.289729 11654 net.cpp:198] conv2_4_ex/scale needs backward computation.
I0523 21:53:40.289732 11654 net.cpp:198] conv2_4_ex/bn needs backward computation.
I0523 21:53:40.289736 11654 net.cpp:198] conv2_4_ex needs backward computation.
I0523 21:53:40.289741 11654 net.cpp:198] res2_3_res2_3_0_split needs backward computation.
I0523 21:53:40.289744 11654 net.cpp:198] res2_3 needs backward computation.
I0523 21:53:40.289748 11654 net.cpp:198] conv2_3_em/scale needs backward computation.
I0523 21:53:40.289752 11654 net.cpp:198] conv2_3_em/bn needs backward computation.
I0523 21:53:40.289755 11654 net.cpp:198] conv2_3_em needs backward computation.
I0523 21:53:40.289758 11654 net.cpp:198] relu2_3_dw needs backward computation.
I0523 21:53:40.289762 11654 net.cpp:198] conv2_3_dw/scale needs backward computation.
I0523 21:53:40.289765 11654 net.cpp:198] conv2_3_dw/bn needs backward computation.
I0523 21:53:40.289768 11654 net.cpp:198] conv2_3_dw needs backward computation.
I0523 21:53:40.289772 11654 net.cpp:198] relu2_3_ex needs backward computation.
I0523 21:53:40.289775 11654 net.cpp:198] conv2_3_ex/scale needs backward computation.
I0523 21:53:40.289778 11654 net.cpp:198] conv2_3_ex/bn needs backward computation.
I0523 21:53:40.289782 11654 net.cpp:198] conv2_3_ex needs backward computation.
I0523 21:53:40.289785 11654 net.cpp:198] res2_2_res2_2_0_split needs backward computation.
I0523 21:53:40.289791 11654 net.cpp:198] res2_2 needs backward computation.
I0523 21:53:40.289796 11654 net.cpp:198] conv2_2_em/scale needs backward computation.
I0523 21:53:40.289799 11654 net.cpp:198] conv2_2_em/bn needs backward computation.
I0523 21:53:40.289803 11654 net.cpp:198] conv2_2_em needs backward computation.
I0523 21:53:40.289806 11654 net.cpp:198] relu2_2_dw needs backward computation.
I0523 21:53:40.289810 11654 net.cpp:198] conv2_2_dw/scale needs backward computation.
I0523 21:53:40.289813 11654 net.cpp:198] conv2_2_dw/bn needs backward computation.
I0523 21:53:40.289816 11654 net.cpp:198] conv2_2_dw needs backward computation.
I0523 21:53:40.289820 11654 net.cpp:198] relu2_2_ex needs backward computation.
I0523 21:53:40.289824 11654 net.cpp:198] conv2_2_ex/scale needs backward computation.
I0523 21:53:40.289827 11654 net.cpp:198] conv2_2_ex/bn needs backward computation.
I0523 21:53:40.289831 11654 net.cpp:198] conv2_2_ex needs backward computation.
I0523 21:53:40.289834 11654 net.cpp:198] res2_1_res2_1_0_split needs backward computation.
I0523 21:53:40.289839 11654 net.cpp:198] res2_1 needs backward computation.
I0523 21:53:40.289841 11654 net.cpp:198] conv2_1_em/scale needs backward computation.
I0523 21:53:40.289845 11654 net.cpp:198] conv2_1_em/bn needs backward computation.
I0523 21:53:40.289849 11654 net.cpp:198] conv2_1_em needs backward computation.
I0523 21:53:40.289852 11654 net.cpp:198] relu2_1_dw needs backward computation.
I0523 21:53:40.289855 11654 net.cpp:198] conv2_1_dw/scale needs backward computation.
I0523 21:53:40.289858 11654 net.cpp:198] conv2_1_dw/bn needs backward computation.
I0523 21:53:40.289862 11654 net.cpp:198] conv2_1_dw needs backward computation.
I0523 21:53:40.289865 11654 net.cpp:198] relu2_1_ex needs backward computation.
I0523 21:53:40.289868 11654 net.cpp:198] conv2_1_ex/scale needs backward computation.
I0523 21:53:40.289872 11654 net.cpp:198] conv2_1_ex/bn needs backward computation.
I0523 21:53:40.289875 11654 net.cpp:198] conv2_1_ex needs backward computation.
I0523 21:53:40.289880 11654 net.cpp:198] conv2_em_conv2_em/scale_0_split needs backward computation.
I0523 21:53:40.289883 11654 net.cpp:198] conv2_em/scale needs backward computation.
I0523 21:53:40.289886 11654 net.cpp:198] conv2_em/bn needs backward computation.
I0523 21:53:40.289891 11654 net.cpp:198] conv2_em needs backward computation.
I0523 21:53:40.289893 11654 net.cpp:198] relu2_dw needs backward computation.
I0523 21:53:40.289897 11654 net.cpp:198] conv2_dw/scale needs backward computation.
I0523 21:53:40.289901 11654 net.cpp:198] conv2_dw/bn needs backward computation.
I0523 21:53:40.289909 11654 net.cpp:198] conv2_dw needs backward computation.
I0523 21:53:40.289913 11654 net.cpp:198] relu2_ex needs backward computation.
I0523 21:53:40.289917 11654 net.cpp:198] conv2_ex/scale needs backward computation.
I0523 21:53:40.289921 11654 net.cpp:198] conv2_ex/bn needs backward computation.
I0523 21:53:40.289924 11654 net.cpp:198] conv2_ex needs backward computation.
I0523 21:53:40.289927 11654 net.cpp:198] relu1_dw needs backward computation.
I0523 21:53:40.289932 11654 net.cpp:198] conv1_dw/scale needs backward computation.
I0523 21:53:40.289934 11654 net.cpp:198] conv1_dw/bn needs backward computation.
I0523 21:53:40.289937 11654 net.cpp:198] conv1_dw needs backward computation.
I0523 21:53:40.289942 11654 net.cpp:198] relu1 needs backward computation.
I0523 21:53:40.289945 11654 net.cpp:198] conv1/scale needs backward computation.
I0523 21:53:40.289948 11654 net.cpp:198] conv1/bn needs backward computation.
I0523 21:53:40.289952 11654 net.cpp:198] conv1 needs backward computation.
I0523 21:53:40.289955 11654 net.cpp:200] label_data_1_split does not need backward computation.
I0523 21:53:40.289960 11654 net.cpp:200] data does not need backward computation.
I0523 21:53:40.289964 11654 net.cpp:242] This network produces output softmax_loss
I0523 21:53:40.290084 11654 net.cpp:255] Network initialization done.
I0523 21:53:40.290565 11654 solver.cpp:72] Finetuning from /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:40.296319 11654 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:40.296356 11654 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:40.296363 11654 net.cpp:744] Ignoring source layer input
I0523 21:53:40.297947 11654 solver.cpp:57] Solver scaffolding done.
I0523 21:53:40.309473 11654 caffe.cpp:239] Starting Optimization
I0523 21:53:42.364032 11730 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: models/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/train.prototxt
I0523 21:53:42.364070 11730 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:42.365888 11730 image_data_layer.cpp:38] Opening file /home/zkx/Data_sdb/TrainData/Data_sdc/Patches/MultiPatches/image_list/train_list/Combine_base_Cmul-Asia-beid-cap10-ZheD_list.txt_label.txt
I0523 21:53:42.419144 11729 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: models/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/train.prototxt
I0523 21:53:42.419190 11729 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:42.420758 11729 image_data_layer.cpp:38] Opening file /home/zkx/Data_sdb/TrainData/Data_sdc/Patches/MultiPatches/image_list/train_list/Combine_base_Cmul-Asia-beid-cap10-ZheD_list.txt_label.txt
I0523 21:53:42.433064 11731 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: models/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/train.prototxt
I0523 21:53:42.433096 11731 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:42.434664 11731 image_data_layer.cpp:38] Opening file /home/zkx/Data_sdb/TrainData/Data_sdc/Patches/MultiPatches/image_list/train_list/Combine_base_Cmul-Asia-beid-cap10-ZheD_list.txt_label.txt
I0523 21:53:43.279928 11730 image_data_layer.cpp:53] Shuffling data
I0523 21:53:43.313623 11729 image_data_layer.cpp:53] Shuffling data
I0523 21:53:43.367812 11731 image_data_layer.cpp:53] Shuffling data
I0523 21:53:43.737653 11730 image_data_layer.cpp:63] A total of 2075438 images.
I0523 21:53:43.741019 11730 image_data_layer.cpp:90] output data size: 64,3,112,96
I0523 21:53:43.777351 11729 image_data_layer.cpp:63] A total of 2075438 images.
I0523 21:53:43.802150 11729 image_data_layer.cpp:90] output data size: 64,3,112,96
I0523 21:53:43.854948 11731 image_data_layer.cpp:63] A total of 2075438 images.
I0523 21:53:43.946679 11731 image_data_layer.cpp:90] output data size: 64,3,112,96
I0523 21:53:46.750355 11729 solver.cpp:72] Finetuning from /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:46.754752 11730 solver.cpp:72] Finetuning from /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:46.755492 11729 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:46.755522 11729 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:46.755528 11729 net.cpp:744] Ignoring source layer input
I0523 21:53:46.759446 11730 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:46.759471 11730 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:46.759477 11730 net.cpp:744] Ignoring source layer input
I0523 21:53:46.779156 11731 solver.cpp:72] Finetuning from /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:46.784173 11731 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /home/zkx/Project/O2N/DepthwiseConvolution-master/MobileFaceNet-master/face_snapshot/MobileFaceNet.caffemodel
I0523 21:53:46.784198 11731 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0523 21:53:46.784204 11731 net.cpp:744] Ignoring source layer input
I0523 21:53:47.212092 11654 solver.cpp:293] Solving 2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_train
I0523 21:53:47.212131 11654 solver.cpp:294] Learning Rate Policy: multistep
I0523 21:53:49.473532 11654 solver.cpp:239] Iteration 0 (2.38488e+37 iter/s, 2.25773s/10 iters), loss = 14.1379
I0523 21:53:49.473584 11654 solver.cpp:258]     Train net output #0: softmax_loss = 14.1379 (* 1 = 14.1379 loss)
I0523 21:53:49.473606 11654 sgd_solver.cpp:112] Iteration 0, lr = 0.1
I0523 21:53:52.632917 11654 solver.cpp:239] Iteration 10 (3.16534 iter/s, 3.15922s/10 iters), loss = 14.2544
I0523 21:53:52.632977 11654 solver.cpp:258]     Train net output #0: softmax_loss = 14.2544 (* 1 = 14.2544 loss)
I0523 21:53:52.632988 11654 sgd_solver.cpp:112] Iteration 10, lr = 0.1
I0523 21:53:55.567812 11654 solver.cpp:239] Iteration 20 (3.40746 iter/s, 2.93474s/10 iters), loss = 13.5874
I0523 21:53:55.567858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 13.5874 (* 1 = 13.5874 loss)
I0523 21:53:55.567873 11654 sgd_solver.cpp:112] Iteration 20, lr = 0.1
I0523 21:54:00.265234 11654 solver.cpp:239] Iteration 30 (2.12893 iter/s, 4.69719s/10 iters), loss = 13.3192
I0523 21:54:00.265300 11654 solver.cpp:258]     Train net output #0: softmax_loss = 13.3192 (* 1 = 13.3192 loss)
I0523 21:54:00.265581 11654 sgd_solver.cpp:112] Iteration 30, lr = 0.1
I0523 21:54:07.885083 11654 solver.cpp:239] Iteration 40 (1.31242 iter/s, 7.61953s/10 iters), loss = 13.1727
I0523 21:54:07.885262 11654 solver.cpp:258]     Train net output #0: softmax_loss = 13.1727 (* 1 = 13.1727 loss)
I0523 21:54:07.885275 11654 sgd_solver.cpp:112] Iteration 40, lr = 0.1
I0523 21:54:13.960444 11654 solver.cpp:239] Iteration 50 (1.6461 iter/s, 6.07498s/10 iters), loss = 13.0616
I0523 21:54:13.960486 11654 solver.cpp:258]     Train net output #0: softmax_loss = 13.0616 (* 1 = 13.0616 loss)
I0523 21:54:13.960500 11654 sgd_solver.cpp:112] Iteration 50, lr = 0.1
I0523 21:54:21.180191 11654 solver.cpp:239] Iteration 60 (1.38516 iter/s, 7.21939s/10 iters), loss = 13.225
I0523 21:54:21.180225 11654 solver.cpp:258]     Train net output #0: softmax_loss = 13.225 (* 1 = 13.225 loss)
I0523 21:54:21.180236 11654 sgd_solver.cpp:112] Iteration 60, lr = 0.1
I0523 21:54:27.538110 11654 solver.cpp:239] Iteration 70 (1.57346 iter/s, 6.35542s/10 iters), loss = 13.2476
I0523 21:54:27.538153 11654 solver.cpp:258]     Train net output #0: softmax_loss = 13.2476 (* 1 = 13.2476 loss)
I0523 21:54:27.538288 11654 sgd_solver.cpp:112] Iteration 70, lr = 0.1
I0523 21:54:33.457237 11654 solver.cpp:239] Iteration 80 (1.68951 iter/s, 5.91886s/10 iters), loss = 12.213
I0523 21:54:33.457288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 12.213 (* 1 = 12.213 loss)
I0523 21:54:33.457432 11654 sgd_solver.cpp:112] Iteration 80, lr = 0.1
I0523 21:54:41.609670 11654 solver.cpp:239] Iteration 90 (1.22668 iter/s, 8.15209s/10 iters), loss = 12.5959
I0523 21:54:41.609908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 12.5959 (* 1 = 12.5959 loss)
I0523 21:54:41.609951 11654 sgd_solver.cpp:112] Iteration 90, lr = 0.1
I0523 21:54:52.176914 11654 solver.cpp:239] Iteration 100 (0.946377 iter/s, 10.5666s/10 iters), loss = 12.2517
I0523 21:54:52.176966 11654 solver.cpp:258]     Train net output #0: softmax_loss = 12.2517 (* 1 = 12.2517 loss)
I0523 21:54:52.176977 11654 sgd_solver.cpp:112] Iteration 100, lr = 0.1
I0523 21:54:58.361920 11654 solver.cpp:239] Iteration 110 (1.61691 iter/s, 6.18465s/10 iters), loss = 12.8646
I0523 21:54:58.361974 11654 solver.cpp:258]     Train net output #0: softmax_loss = 12.8646 (* 1 = 12.8646 loss)
I0523 21:54:58.361986 11654 sgd_solver.cpp:112] Iteration 110, lr = 0.1
I0523 21:55:05.444425 11654 solver.cpp:239] Iteration 120 (1.41199 iter/s, 7.08219s/10 iters), loss = 11.9837
I0523 21:55:05.444463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.9837 (* 1 = 11.9837 loss)
I0523 21:55:05.444527 11654 sgd_solver.cpp:112] Iteration 120, lr = 0.1
I0523 21:55:13.916091 11654 solver.cpp:239] Iteration 130 (1.18046 iter/s, 8.47131s/10 iters), loss = 12.0277
I0523 21:55:13.916323 11654 solver.cpp:258]     Train net output #0: softmax_loss = 12.0277 (* 1 = 12.0277 loss)
I0523 21:55:13.916435 11654 sgd_solver.cpp:112] Iteration 130, lr = 0.1
I0523 21:55:19.957913 11654 solver.cpp:239] Iteration 140 (1.65525 iter/s, 6.04138s/10 iters), loss = 11.9656
I0523 21:55:19.957965 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.9656 (* 1 = 11.9656 loss)
I0523 21:55:19.958338 11654 sgd_solver.cpp:112] Iteration 140, lr = 0.1
I0523 21:55:26.169245 11654 solver.cpp:239] Iteration 150 (1.61004 iter/s, 6.21104s/10 iters), loss = 11.7375
I0523 21:55:26.169289 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.7375 (* 1 = 11.7375 loss)
I0523 21:55:26.169447 11654 sgd_solver.cpp:112] Iteration 150, lr = 0.1
I0523 21:55:34.015616 11654 solver.cpp:239] Iteration 160 (1.27453 iter/s, 7.84603s/10 iters), loss = 11.8461
I0523 21:55:34.015658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.8461 (* 1 = 11.8461 loss)
I0523 21:55:34.016047 11654 sgd_solver.cpp:112] Iteration 160, lr = 0.1
I0523 21:55:40.291311 11654 solver.cpp:239] Iteration 170 (1.59352 iter/s, 6.2754s/10 iters), loss = 12.2218
I0523 21:55:40.291353 11654 solver.cpp:258]     Train net output #0: softmax_loss = 12.2218 (* 1 = 12.2218 loss)
I0523 21:55:40.291365 11654 sgd_solver.cpp:112] Iteration 170, lr = 0.1
I0523 21:55:46.709285 11654 solver.cpp:239] Iteration 180 (1.55825 iter/s, 6.41746s/10 iters), loss = 11.5112
I0523 21:55:46.709517 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5112 (* 1 = 11.5112 loss)
I0523 21:55:46.987599 11654 sgd_solver.cpp:112] Iteration 180, lr = 0.1
I0523 21:55:53.478271 11654 solver.cpp:239] Iteration 190 (1.47743 iter/s, 6.76851s/10 iters), loss = 11.8837
I0523 21:55:53.478319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.8837 (* 1 = 11.8837 loss)
I0523 21:55:53.478595 11654 sgd_solver.cpp:112] Iteration 190, lr = 0.1
I0523 21:56:00.308423 11654 solver.cpp:239] Iteration 200 (1.46416 iter/s, 6.82984s/10 iters), loss = 11.5511
I0523 21:56:00.308470 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5511 (* 1 = 11.5511 loss)
I0523 21:56:00.308631 11654 sgd_solver.cpp:112] Iteration 200, lr = 0.1
I0523 21:56:06.613916 11654 solver.cpp:239] Iteration 210 (1.58599 iter/s, 6.3052s/10 iters), loss = 11.4772
I0523 21:56:06.613955 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4772 (* 1 = 11.4772 loss)
I0523 21:56:06.614300 11654 sgd_solver.cpp:112] Iteration 210, lr = 0.1
I0523 21:56:15.873740 11654 solver.cpp:239] Iteration 220 (1.07998 iter/s, 9.25942s/10 iters), loss = 11.4847
I0523 21:56:15.873781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4847 (* 1 = 11.4847 loss)
I0523 21:56:15.873792 11654 sgd_solver.cpp:112] Iteration 220, lr = 0.1
I0523 21:56:22.808622 11654 solver.cpp:239] Iteration 230 (1.44205 iter/s, 6.93457s/10 iters), loss = 11.8855
I0523 21:56:22.808914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.8855 (* 1 = 11.8855 loss)
I0523 21:56:22.808960 11654 sgd_solver.cpp:112] Iteration 230, lr = 0.1
I0523 21:56:29.210975 11654 solver.cpp:239] Iteration 240 (1.56206 iter/s, 6.40181s/10 iters), loss = 11.0712
I0523 21:56:29.211015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0712 (* 1 = 11.0712 loss)
I0523 21:56:29.223137 11654 sgd_solver.cpp:112] Iteration 240, lr = 0.1
I0523 21:56:40.380539 11654 solver.cpp:239] Iteration 250 (0.895328 iter/s, 11.1691s/10 iters), loss = 11.5519
I0523 21:56:40.380576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5519 (* 1 = 11.5519 loss)
I0523 21:56:40.380589 11654 sgd_solver.cpp:112] Iteration 250, lr = 0.1
I0523 21:56:46.783219 11654 solver.cpp:239] Iteration 260 (1.56246 iter/s, 6.40015s/10 iters), loss = 11.5049
I0523 21:56:46.783268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5049 (* 1 = 11.5049 loss)
I0523 21:56:47.301380 11654 sgd_solver.cpp:112] Iteration 260, lr = 0.1
I0523 21:56:54.658881 11654 solver.cpp:239] Iteration 270 (1.26979 iter/s, 7.87531s/10 iters), loss = 11.3473
I0523 21:56:54.659107 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3473 (* 1 = 11.3473 loss)
I0523 21:56:54.659497 11654 sgd_solver.cpp:112] Iteration 270, lr = 0.1
I0523 21:57:01.868774 11654 solver.cpp:239] Iteration 280 (1.38708 iter/s, 7.20942s/10 iters), loss = 11.0757
I0523 21:57:01.868818 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0757 (* 1 = 11.0757 loss)
I0523 21:57:01.875188 11654 sgd_solver.cpp:112] Iteration 280, lr = 0.1
I0523 21:57:07.828593 11654 solver.cpp:239] Iteration 290 (1.67798 iter/s, 5.95953s/10 iters), loss = 10.9122
I0523 21:57:07.828644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9122 (* 1 = 10.9122 loss)
I0523 21:57:07.829202 11654 sgd_solver.cpp:112] Iteration 290, lr = 0.1
I0523 21:57:14.060379 11654 solver.cpp:239] Iteration 300 (1.60475 iter/s, 6.23149s/10 iters), loss = 11.7923
I0523 21:57:14.060418 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.7923 (* 1 = 11.7923 loss)
I0523 21:57:14.060430 11654 sgd_solver.cpp:112] Iteration 300, lr = 0.1
I0523 21:57:22.047325 11654 solver.cpp:239] Iteration 310 (1.25213 iter/s, 7.9864s/10 iters), loss = 10.8247
I0523 21:57:22.047371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8247 (* 1 = 10.8247 loss)
I0523 21:57:22.257184 11654 sgd_solver.cpp:112] Iteration 310, lr = 0.1
I0523 21:57:29.388676 11654 solver.cpp:239] Iteration 320 (1.36221 iter/s, 7.34102s/10 iters), loss = 10.7958
I0523 21:57:29.388907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7958 (* 1 = 10.7958 loss)
I0523 21:57:29.388957 11654 sgd_solver.cpp:112] Iteration 320, lr = 0.1
I0523 21:57:36.775264 11654 solver.cpp:239] Iteration 330 (1.3539 iter/s, 7.3861s/10 iters), loss = 11.252
I0523 21:57:36.775319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.252 (* 1 = 11.252 loss)
I0523 21:57:36.775337 11654 sgd_solver.cpp:112] Iteration 330, lr = 0.1
I0523 21:57:42.895668 11654 solver.cpp:239] Iteration 340 (1.63454 iter/s, 6.11791s/10 iters), loss = 10.5309
I0523 21:57:42.895714 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5309 (* 1 = 10.5309 loss)
I0523 21:57:42.969264 11654 sgd_solver.cpp:112] Iteration 340, lr = 0.1
I0523 21:57:48.959069 11654 solver.cpp:239] Iteration 350 (1.64932 iter/s, 6.06311s/10 iters), loss = 11.1596
I0523 21:57:48.959116 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1596 (* 1 = 11.1596 loss)
I0523 21:57:48.959275 11654 sgd_solver.cpp:112] Iteration 350, lr = 0.1
I0523 21:57:55.824626 11654 solver.cpp:239] Iteration 360 (1.45661 iter/s, 6.86524s/10 iters), loss = 11.2833
I0523 21:57:55.824676 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2833 (* 1 = 11.2833 loss)
I0523 21:57:55.824736 11654 sgd_solver.cpp:112] Iteration 360, lr = 0.1
I0523 21:58:02.797699 11654 solver.cpp:239] Iteration 370 (1.43415 iter/s, 6.97276s/10 iters), loss = 11.0312
I0523 21:58:02.797933 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0312 (* 1 = 11.0312 loss)
I0523 21:58:02.797971 11654 sgd_solver.cpp:112] Iteration 370, lr = 0.1
I0523 21:58:09.193581 11654 solver.cpp:239] Iteration 380 (1.56414 iter/s, 6.39331s/10 iters), loss = 10.8479
I0523 21:58:09.193642 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8479 (* 1 = 10.8479 loss)
I0523 21:58:09.193722 11654 sgd_solver.cpp:112] Iteration 380, lr = 0.1
I0523 21:58:15.459343 11654 solver.cpp:239] Iteration 390 (1.59605 iter/s, 6.26546s/10 iters), loss = 11.3076
I0523 21:58:15.459388 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3076 (* 1 = 11.3076 loss)
I0523 21:58:15.459401 11654 sgd_solver.cpp:112] Iteration 390, lr = 0.1
I0523 21:58:21.878738 11654 solver.cpp:239] Iteration 400 (1.55791 iter/s, 6.41884s/10 iters), loss = 10.9977
I0523 21:58:21.878779 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9977 (* 1 = 10.9977 loss)
I0523 21:58:21.878798 11654 sgd_solver.cpp:112] Iteration 400, lr = 0.1
I0523 21:58:31.991274 11654 solver.cpp:239] Iteration 410 (0.988914 iter/s, 10.1121s/10 iters), loss = 10.829
I0523 21:58:31.991319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.829 (* 1 = 10.829 loss)
I0523 21:58:31.991338 11654 sgd_solver.cpp:112] Iteration 410, lr = 0.1
I0523 21:58:39.709236 11654 solver.cpp:239] Iteration 420 (1.29574 iter/s, 7.71762s/10 iters), loss = 10.6407
I0523 21:58:39.709481 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6407 (* 1 = 10.6407 loss)
I0523 21:58:40.084118 11654 sgd_solver.cpp:112] Iteration 420, lr = 0.1
I0523 21:58:47.280145 11654 solver.cpp:239] Iteration 430 (1.32093 iter/s, 7.5704s/10 iters), loss = 11.1009
I0523 21:58:47.280196 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1009 (* 1 = 11.1009 loss)
I0523 21:58:47.280238 11654 sgd_solver.cpp:112] Iteration 430, lr = 0.1
I0523 21:58:53.901376 11654 solver.cpp:239] Iteration 440 (1.51037 iter/s, 6.62091s/10 iters), loss = 10.7276
I0523 21:58:53.901428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7276 (* 1 = 10.7276 loss)
I0523 21:58:53.901846 11654 sgd_solver.cpp:112] Iteration 440, lr = 0.1
I0523 21:59:00.854758 11654 solver.cpp:239] Iteration 450 (1.43821 iter/s, 6.95307s/10 iters), loss = 10.6441
I0523 21:59:00.854792 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6441 (* 1 = 10.6441 loss)
I0523 21:59:01.073675 11654 sgd_solver.cpp:112] Iteration 450, lr = 0.1
I0523 21:59:07.682111 11654 solver.cpp:239] Iteration 460 (1.46476 iter/s, 6.82705s/10 iters), loss = 10.7276
I0523 21:59:07.682152 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7276 (* 1 = 10.7276 loss)
I0523 21:59:07.682164 11654 sgd_solver.cpp:112] Iteration 460, lr = 0.1
I0523 21:59:15.797287 11654 solver.cpp:239] Iteration 470 (1.23264 iter/s, 8.11266s/10 iters), loss = 11.0683
I0523 21:59:15.797437 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0683 (* 1 = 11.0683 loss)
I0523 21:59:15.799113 11654 sgd_solver.cpp:112] Iteration 470, lr = 0.1
I0523 21:59:22.021983 11654 solver.cpp:239] Iteration 480 (1.6066 iter/s, 6.22431s/10 iters), loss = 11.0761
I0523 21:59:22.022029 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0761 (* 1 = 11.0761 loss)
I0523 21:59:22.287499 11654 sgd_solver.cpp:112] Iteration 480, lr = 0.1
I0523 21:59:28.938570 11654 solver.cpp:239] Iteration 490 (1.44587 iter/s, 6.91626s/10 iters), loss = 10.7413
I0523 21:59:28.938619 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7413 (* 1 = 10.7413 loss)
I0523 21:59:28.939033 11654 sgd_solver.cpp:112] Iteration 490, lr = 0.1
I0523 21:59:37.121206 11654 solver.cpp:239] Iteration 500 (1.22215 iter/s, 8.18227s/10 iters), loss = 11.2053
I0523 21:59:37.121259 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2053 (* 1 = 11.2053 loss)
I0523 21:59:37.121274 11654 sgd_solver.cpp:112] Iteration 500, lr = 0.1
I0523 21:59:44.466128 11654 solver.cpp:239] Iteration 510 (1.36156 iter/s, 7.34453s/10 iters), loss = 10.4967
I0523 21:59:44.466181 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4967 (* 1 = 10.4967 loss)
I0523 21:59:44.466590 11654 sgd_solver.cpp:112] Iteration 510, lr = 0.1
I0523 21:59:52.780491 11654 solver.cpp:239] Iteration 520 (1.20279 iter/s, 8.314s/10 iters), loss = 11.0859
I0523 21:59:52.780704 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0859 (* 1 = 11.0859 loss)
I0523 21:59:52.780755 11654 sgd_solver.cpp:112] Iteration 520, lr = 0.1
I0523 21:59:59.067654 11654 solver.cpp:239] Iteration 530 (1.59066 iter/s, 6.28671s/10 iters), loss = 11.0417
I0523 21:59:59.067695 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0417 (* 1 = 11.0417 loss)
I0523 21:59:59.095610 11654 sgd_solver.cpp:112] Iteration 530, lr = 0.1
I0523 22:00:05.377962 11654 solver.cpp:239] Iteration 540 (1.58478 iter/s, 6.31002s/10 iters), loss = 10.9003
I0523 22:00:05.378005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9003 (* 1 = 10.9003 loss)
I0523 22:00:05.378016 11654 sgd_solver.cpp:112] Iteration 540, lr = 0.1
I0523 22:00:13.206097 11654 solver.cpp:239] Iteration 550 (1.27752 iter/s, 7.82766s/10 iters), loss = 10.6351
I0523 22:00:13.206147 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6351 (* 1 = 10.6351 loss)
I0523 22:00:13.207751 11654 sgd_solver.cpp:112] Iteration 550, lr = 0.1
I0523 22:00:19.638348 11654 solver.cpp:239] Iteration 560 (1.55474 iter/s, 6.43196s/10 iters), loss = 11.1053
I0523 22:00:19.638391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1053 (* 1 = 11.1053 loss)
I0523 22:00:19.638401 11654 sgd_solver.cpp:112] Iteration 560, lr = 0.1
I0523 22:00:26.009157 11654 solver.cpp:239] Iteration 570 (1.57025 iter/s, 6.36841s/10 iters), loss = 11.1427
I0523 22:00:26.009281 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1427 (* 1 = 11.1427 loss)
I0523 22:00:26.009296 11654 sgd_solver.cpp:112] Iteration 570, lr = 0.1
I0523 22:00:33.072940 11654 solver.cpp:239] Iteration 580 (1.41575 iter/s, 7.06339s/10 iters), loss = 10.7407
I0523 22:00:33.072983 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7407 (* 1 = 10.7407 loss)
I0523 22:00:33.073043 11654 sgd_solver.cpp:112] Iteration 580, lr = 0.1
I0523 22:00:39.421260 11654 solver.cpp:239] Iteration 590 (1.57529 iter/s, 6.34802s/10 iters), loss = 10.3481
I0523 22:00:39.421310 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3481 (* 1 = 10.3481 loss)
I0523 22:00:39.421638 11654 sgd_solver.cpp:112] Iteration 590, lr = 0.1
I0523 22:00:47.032275 11654 solver.cpp:239] Iteration 600 (1.31394 iter/s, 7.61068s/10 iters), loss = 10.4031
I0523 22:00:47.032320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4031 (* 1 = 10.4031 loss)
I0523 22:00:48.293383 11654 sgd_solver.cpp:112] Iteration 600, lr = 0.1
I0523 22:00:54.601925 11654 solver.cpp:239] Iteration 610 (1.32112 iter/s, 7.56932s/10 iters), loss = 10.5324
I0523 22:00:54.601971 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5324 (* 1 = 10.5324 loss)
I0523 22:00:54.602248 11654 sgd_solver.cpp:112] Iteration 610, lr = 0.1
I0523 22:01:03.226806 11654 solver.cpp:239] Iteration 620 (1.15949 iter/s, 8.6245s/10 iters), loss = 10.731
I0523 22:01:03.227047 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.731 (* 1 = 10.731 loss)
I0523 22:01:03.235568 11654 sgd_solver.cpp:112] Iteration 620, lr = 0.1
I0523 22:01:10.454454 11654 solver.cpp:239] Iteration 630 (1.38367 iter/s, 7.22716s/10 iters), loss = 10.5358
I0523 22:01:10.454495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5358 (* 1 = 10.5358 loss)
I0523 22:01:10.585667 11654 sgd_solver.cpp:112] Iteration 630, lr = 0.1
I0523 22:01:17.513134 11654 solver.cpp:239] Iteration 640 (1.41676 iter/s, 7.05837s/10 iters), loss = 10.4128
I0523 22:01:17.513175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4128 (* 1 = 10.4128 loss)
I0523 22:01:17.513310 11654 sgd_solver.cpp:112] Iteration 640, lr = 0.1
I0523 22:01:23.757755 11654 solver.cpp:239] Iteration 650 (1.60145 iter/s, 6.24434s/10 iters), loss = 11.0684
I0523 22:01:23.757799 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0684 (* 1 = 11.0684 loss)
I0523 22:01:23.758021 11654 sgd_solver.cpp:112] Iteration 650, lr = 0.1
I0523 22:01:29.970222 11654 solver.cpp:239] Iteration 660 (1.60974 iter/s, 6.21218s/10 iters), loss = 10.4723
I0523 22:01:29.970270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4723 (* 1 = 10.4723 loss)
I0523 22:01:29.970386 11654 sgd_solver.cpp:112] Iteration 660, lr = 0.1
I0523 22:01:39.254681 11654 solver.cpp:239] Iteration 670 (1.07712 iter/s, 9.28406s/10 iters), loss = 10.2687
I0523 22:01:39.254827 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2687 (* 1 = 10.2687 loss)
I0523 22:01:39.254848 11654 sgd_solver.cpp:112] Iteration 670, lr = 0.1
I0523 22:01:45.662163 11654 solver.cpp:239] Iteration 680 (1.56078 iter/s, 6.40707s/10 iters), loss = 10.5883
I0523 22:01:45.662204 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5883 (* 1 = 10.5883 loss)
I0523 22:01:45.662328 11654 sgd_solver.cpp:112] Iteration 680, lr = 0.1
I0523 22:01:52.317816 11654 solver.cpp:239] Iteration 690 (1.50255 iter/s, 6.65535s/10 iters), loss = 10.3958
I0523 22:01:52.317878 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3958 (* 1 = 10.3958 loss)
I0523 22:01:52.318011 11654 sgd_solver.cpp:112] Iteration 690, lr = 0.1
I0523 22:01:59.160303 11654 solver.cpp:239] Iteration 700 (1.46153 iter/s, 6.84216s/10 iters), loss = 10.7061
I0523 22:01:59.160356 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7061 (* 1 = 10.7061 loss)
I0523 22:01:59.160707 11654 sgd_solver.cpp:112] Iteration 700, lr = 0.1
I0523 22:02:05.705548 11654 solver.cpp:239] Iteration 710 (1.5279 iter/s, 6.54493s/10 iters), loss = 10.5406
I0523 22:02:05.705605 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5406 (* 1 = 10.5406 loss)
I0523 22:02:05.705901 11654 sgd_solver.cpp:112] Iteration 710, lr = 0.1
I0523 22:02:12.271042 11654 solver.cpp:239] Iteration 720 (1.52319 iter/s, 6.56518s/10 iters), loss = 10.6148
I0523 22:02:12.271275 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6148 (* 1 = 10.6148 loss)
I0523 22:02:13.333577 11654 sgd_solver.cpp:112] Iteration 720, lr = 0.1
I0523 22:02:22.658713 11654 solver.cpp:239] Iteration 730 (0.962735 iter/s, 10.3871s/10 iters), loss = 10.7033
I0523 22:02:22.658761 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7033 (* 1 = 10.7033 loss)
I0523 22:02:22.658968 11654 sgd_solver.cpp:112] Iteration 730, lr = 0.1
I0523 22:02:29.516855 11654 solver.cpp:239] Iteration 740 (1.45819 iter/s, 6.85783s/10 iters), loss = 10.4672
I0523 22:02:29.516896 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4672 (* 1 = 10.4672 loss)
I0523 22:02:29.516937 11654 sgd_solver.cpp:112] Iteration 740, lr = 0.1
I0523 22:02:37.398633 11654 solver.cpp:239] Iteration 750 (1.2688 iter/s, 7.88143s/10 iters), loss = 10.4454
I0523 22:02:37.398679 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4454 (* 1 = 10.4454 loss)
I0523 22:02:37.398690 11654 sgd_solver.cpp:112] Iteration 750, lr = 0.1
I0523 22:02:45.294682 11654 solver.cpp:239] Iteration 760 (1.26687 iter/s, 7.89349s/10 iters), loss = 10.8538
I0523 22:02:45.294836 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8538 (* 1 = 10.8538 loss)
I0523 22:02:45.294863 11654 sgd_solver.cpp:112] Iteration 760, lr = 0.1
I0523 22:02:53.615516 11654 solver.cpp:239] Iteration 770 (1.20192 iter/s, 8.32006s/10 iters), loss = 10.6773
I0523 22:02:53.615571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6773 (* 1 = 10.6773 loss)
I0523 22:02:53.616103 11654 sgd_solver.cpp:112] Iteration 770, lr = 0.1
I0523 22:03:00.990869 11654 solver.cpp:239] Iteration 780 (1.35593 iter/s, 7.37502s/10 iters), loss = 10.212
I0523 22:03:00.990908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.212 (* 1 = 10.212 loss)
I0523 22:03:00.990926 11654 sgd_solver.cpp:112] Iteration 780, lr = 0.1
I0523 22:03:08.083652 11654 solver.cpp:239] Iteration 790 (1.40995 iter/s, 7.09246s/10 iters), loss = 9.68337
I0523 22:03:08.083695 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.68337 (* 1 = 9.68337 loss)
I0523 22:03:08.083706 11654 sgd_solver.cpp:112] Iteration 790, lr = 0.1
I0523 22:03:14.460522 11654 solver.cpp:239] Iteration 800 (1.56824 iter/s, 6.37658s/10 iters), loss = 10.7641
I0523 22:03:14.460582 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7641 (* 1 = 10.7641 loss)
I0523 22:03:14.546294 11654 sgd_solver.cpp:112] Iteration 800, lr = 0.1
I0523 22:03:22.380380 11654 solver.cpp:239] Iteration 810 (1.26271 iter/s, 7.9195s/10 iters), loss = 9.87938
I0523 22:03:22.380528 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.87938 (* 1 = 9.87938 loss)
I0523 22:03:23.221683 11654 sgd_solver.cpp:112] Iteration 810, lr = 0.1
I0523 22:03:30.277743 11654 solver.cpp:239] Iteration 820 (1.26632 iter/s, 7.89691s/10 iters), loss = 10.7839
I0523 22:03:30.277796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7839 (* 1 = 10.7839 loss)
I0523 22:03:30.277915 11654 sgd_solver.cpp:112] Iteration 820, lr = 0.1
I0523 22:03:38.256520 11654 solver.cpp:239] Iteration 830 (1.25338 iter/s, 7.97843s/10 iters), loss = 10.2443
I0523 22:03:38.256556 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2443 (* 1 = 10.2443 loss)
I0523 22:03:38.256738 11654 sgd_solver.cpp:112] Iteration 830, lr = 0.1
I0523 22:03:44.887717 11654 solver.cpp:239] Iteration 840 (1.50809 iter/s, 6.6309s/10 iters), loss = 10.8688
I0523 22:03:44.887758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8688 (* 1 = 10.8688 loss)
I0523 22:03:44.887769 11654 sgd_solver.cpp:112] Iteration 840, lr = 0.1
I0523 22:03:52.037641 11654 solver.cpp:239] Iteration 850 (1.39868 iter/s, 7.1496s/10 iters), loss = 10.1531
I0523 22:03:52.037685 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1531 (* 1 = 10.1531 loss)
I0523 22:03:52.037992 11654 sgd_solver.cpp:112] Iteration 850, lr = 0.1
I0523 22:04:00.137933 11654 solver.cpp:239] Iteration 860 (1.23458 iter/s, 8.09994s/10 iters), loss = 10.363
I0523 22:04:00.138198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.363 (* 1 = 10.363 loss)
I0523 22:04:00.725528 11654 sgd_solver.cpp:112] Iteration 860, lr = 0.1
I0523 22:04:08.101058 11654 solver.cpp:239] Iteration 870 (1.25587 iter/s, 7.9626s/10 iters), loss = 10.3268
I0523 22:04:08.101094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3268 (* 1 = 10.3268 loss)
I0523 22:04:08.101135 11654 sgd_solver.cpp:112] Iteration 870, lr = 0.1
I0523 22:04:15.040422 11654 solver.cpp:239] Iteration 880 (1.44112 iter/s, 6.93906s/10 iters), loss = 10.7165
I0523 22:04:15.040463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7165 (* 1 = 10.7165 loss)
I0523 22:04:16.231993 11654 sgd_solver.cpp:112] Iteration 880, lr = 0.1
I0523 22:04:23.204260 11654 solver.cpp:239] Iteration 890 (1.22497 iter/s, 8.16348s/10 iters), loss = 10.0528
I0523 22:04:23.204303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0528 (* 1 = 10.0528 loss)
I0523 22:04:23.366773 11654 sgd_solver.cpp:112] Iteration 890, lr = 0.1
I0523 22:04:30.670398 11654 solver.cpp:239] Iteration 900 (1.33944 iter/s, 7.46581s/10 iters), loss = 10.4113
I0523 22:04:30.670544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4113 (* 1 = 10.4113 loss)
I0523 22:04:30.670737 11654 sgd_solver.cpp:112] Iteration 900, lr = 0.1
I0523 22:04:38.417572 11654 solver.cpp:239] Iteration 910 (1.29087 iter/s, 7.74674s/10 iters), loss = 10.3446
I0523 22:04:38.417623 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3446 (* 1 = 10.3446 loss)
I0523 22:04:38.418079 11654 sgd_solver.cpp:112] Iteration 910, lr = 0.1
I0523 22:04:46.944947 11654 solver.cpp:239] Iteration 920 (1.17275 iter/s, 8.52699s/10 iters), loss = 10.7038
I0523 22:04:46.945005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7038 (* 1 = 10.7038 loss)
I0523 22:04:46.945190 11654 sgd_solver.cpp:112] Iteration 920, lr = 0.1
I0523 22:04:53.248792 11654 solver.cpp:239] Iteration 930 (1.58641 iter/s, 6.30355s/10 iters), loss = 10.3193
I0523 22:04:53.248829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3193 (* 1 = 10.3193 loss)
I0523 22:04:53.249174 11654 sgd_solver.cpp:112] Iteration 930, lr = 0.1
I0523 22:04:59.782902 11654 solver.cpp:239] Iteration 940 (1.5305 iter/s, 6.53381s/10 iters), loss = 10.8343
I0523 22:04:59.782951 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8343 (* 1 = 10.8343 loss)
I0523 22:04:59.783239 11654 sgd_solver.cpp:112] Iteration 940, lr = 0.1
I0523 22:05:08.453510 11654 solver.cpp:239] Iteration 950 (1.15337 iter/s, 8.67022s/10 iters), loss = 9.7631
I0523 22:05:08.453714 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.7631 (* 1 = 9.7631 loss)
I0523 22:05:08.455447 11654 sgd_solver.cpp:112] Iteration 950, lr = 0.1
I0523 22:05:15.045457 11654 solver.cpp:239] Iteration 960 (1.5171 iter/s, 6.59152s/10 iters), loss = 10.1608
I0523 22:05:15.045500 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1608 (* 1 = 10.1608 loss)
I0523 22:05:15.078752 11654 sgd_solver.cpp:112] Iteration 960, lr = 0.1
I0523 22:05:23.598958 11654 solver.cpp:239] Iteration 970 (1.16916 iter/s, 8.55314s/10 iters), loss = 10.1209
I0523 22:05:23.598994 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1209 (* 1 = 10.1209 loss)
I0523 22:05:24.667034 11654 sgd_solver.cpp:112] Iteration 970, lr = 0.1
I0523 22:05:33.650277 11654 solver.cpp:239] Iteration 980 (0.994936 iter/s, 10.0509s/10 iters), loss = 10.1772
I0523 22:05:33.650318 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1772 (* 1 = 10.1772 loss)
I0523 22:05:33.650331 11654 sgd_solver.cpp:112] Iteration 980, lr = 0.1
I0523 22:05:40.200738 11654 solver.cpp:239] Iteration 990 (1.5272 iter/s, 6.54794s/10 iters), loss = 9.91903
I0523 22:05:40.200872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.91903 (* 1 = 9.91903 loss)
I0523 22:05:40.200887 11654 sgd_solver.cpp:112] Iteration 990, lr = 0.1
I0523 22:05:49.487457 11654 solver.cpp:239] Iteration 1000 (1.07686 iter/s, 9.28623s/10 iters), loss = 10.6758
I0523 22:05:49.487498 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6758 (* 1 = 10.6758 loss)
I0523 22:05:49.597131 11654 sgd_solver.cpp:112] Iteration 1000, lr = 0.1
I0523 22:05:56.162247 11654 solver.cpp:239] Iteration 1010 (1.49824 iter/s, 6.67448s/10 iters), loss = 10.5628
I0523 22:05:56.162291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5628 (* 1 = 10.5628 loss)
I0523 22:05:56.162302 11654 sgd_solver.cpp:112] Iteration 1010, lr = 0.1
I0523 22:06:03.395473 11654 solver.cpp:239] Iteration 1020 (1.38257 iter/s, 7.2329s/10 iters), loss = 9.61088
I0523 22:06:03.395515 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.61088 (* 1 = 9.61088 loss)
I0523 22:06:03.395642 11654 sgd_solver.cpp:112] Iteration 1020, lr = 0.1
I0523 22:06:09.783870 11654 solver.cpp:239] Iteration 1030 (1.56541 iter/s, 6.38811s/10 iters), loss = 10.1622
I0523 22:06:09.783915 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1622 (* 1 = 10.1622 loss)
I0523 22:06:09.783974 11654 sgd_solver.cpp:112] Iteration 1030, lr = 0.1
I0523 22:06:16.074714 11654 solver.cpp:239] Iteration 1040 (1.58969 iter/s, 6.29054s/10 iters), loss = 10.6064
I0523 22:06:16.075016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6064 (* 1 = 10.6064 loss)
I0523 22:06:16.075073 11654 sgd_solver.cpp:112] Iteration 1040, lr = 0.1
I0523 22:06:22.600284 11654 solver.cpp:239] Iteration 1050 (1.53256 iter/s, 6.52503s/10 iters), loss = 10.1976
I0523 22:06:22.600327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1976 (* 1 = 10.1976 loss)
I0523 22:06:22.601022 11654 sgd_solver.cpp:112] Iteration 1050, lr = 0.1
I0523 22:06:28.794950 11654 solver.cpp:239] Iteration 1060 (1.61437 iter/s, 6.19438s/10 iters), loss = 10.1964
I0523 22:06:28.794993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1964 (* 1 = 10.1964 loss)
I0523 22:06:28.795006 11654 sgd_solver.cpp:112] Iteration 1060, lr = 0.1
I0523 22:06:35.987074 11654 solver.cpp:239] Iteration 1070 (1.39089 iter/s, 7.18964s/10 iters), loss = 10.4266
I0523 22:06:35.987119 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4266 (* 1 = 10.4266 loss)
I0523 22:06:35.987282 11654 sgd_solver.cpp:112] Iteration 1070, lr = 0.1
I0523 22:06:41.960988 11654 solver.cpp:239] Iteration 1080 (1.67402 iter/s, 5.97364s/10 iters), loss = 10.332
I0523 22:06:41.961036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.332 (* 1 = 10.332 loss)
I0523 22:06:41.961052 11654 sgd_solver.cpp:112] Iteration 1080, lr = 0.1
I0523 22:06:49.526616 11654 solver.cpp:239] Iteration 1090 (1.32184 iter/s, 7.56523s/10 iters), loss = 10.5687
I0523 22:06:49.526813 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5687 (* 1 = 10.5687 loss)
I0523 22:06:49.566835 11654 sgd_solver.cpp:112] Iteration 1090, lr = 0.1
I0523 22:06:55.720470 11654 solver.cpp:239] Iteration 1100 (1.61461 iter/s, 6.19343s/10 iters), loss = 10.3557
I0523 22:06:55.720506 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3557 (* 1 = 10.3557 loss)
I0523 22:06:55.720757 11654 sgd_solver.cpp:112] Iteration 1100, lr = 0.1
I0523 22:07:02.492128 11654 solver.cpp:239] Iteration 1110 (1.47681 iter/s, 6.77135s/10 iters), loss = 10.2278
I0523 22:07:02.492180 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2278 (* 1 = 10.2278 loss)
I0523 22:07:02.492588 11654 sgd_solver.cpp:112] Iteration 1110, lr = 0.1
I0523 22:07:10.398033 11654 solver.cpp:239] Iteration 1120 (1.26493 iter/s, 7.90555s/10 iters), loss = 10.707
I0523 22:07:10.398070 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.707 (* 1 = 10.707 loss)
I0523 22:07:10.398542 11654 sgd_solver.cpp:112] Iteration 1120, lr = 0.1
I0523 22:07:17.097529 11654 solver.cpp:239] Iteration 1130 (1.49271 iter/s, 6.69921s/10 iters), loss = 10.3262
I0523 22:07:17.097568 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3262 (* 1 = 10.3262 loss)
I0523 22:07:17.338348 11654 sgd_solver.cpp:112] Iteration 1130, lr = 0.1
I0523 22:07:25.883322 11654 solver.cpp:239] Iteration 1140 (1.13825 iter/s, 8.78542s/10 iters), loss = 10.4086
I0523 22:07:25.883424 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4086 (* 1 = 10.4086 loss)
I0523 22:07:25.883437 11654 sgd_solver.cpp:112] Iteration 1140, lr = 0.1
I0523 22:07:32.481459 11654 solver.cpp:239] Iteration 1150 (1.51617 iter/s, 6.59558s/10 iters), loss = 10.413
I0523 22:07:32.481503 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.413 (* 1 = 10.413 loss)
I0523 22:07:32.484414 11654 sgd_solver.cpp:112] Iteration 1150, lr = 0.1
I0523 22:07:39.901190 11654 solver.cpp:239] Iteration 1160 (1.34782 iter/s, 7.4194s/10 iters), loss = 10.0527
I0523 22:07:39.901232 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0527 (* 1 = 10.0527 loss)
I0523 22:07:39.901245 11654 sgd_solver.cpp:112] Iteration 1160, lr = 0.1
I0523 22:07:48.403326 11654 solver.cpp:239] Iteration 1170 (1.17623 iter/s, 8.50176s/10 iters), loss = 10.2119
I0523 22:07:48.403373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2119 (* 1 = 10.2119 loss)
I0523 22:07:48.847653 11654 sgd_solver.cpp:112] Iteration 1170, lr = 0.1
I0523 22:07:56.911839 11654 solver.cpp:239] Iteration 1180 (1.17534 iter/s, 8.50814s/10 iters), loss = 10.5441
I0523 22:07:56.911989 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5441 (* 1 = 10.5441 loss)
I0523 22:07:56.912423 11654 sgd_solver.cpp:112] Iteration 1180, lr = 0.1
I0523 22:08:03.102982 11654 solver.cpp:239] Iteration 1190 (1.61531 iter/s, 6.19076s/10 iters), loss = 10.1892
I0523 22:08:03.103032 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1892 (* 1 = 10.1892 loss)
I0523 22:08:03.103458 11654 sgd_solver.cpp:112] Iteration 1190, lr = 0.1
I0523 22:08:09.360406 11654 solver.cpp:239] Iteration 1200 (1.59818 iter/s, 6.25713s/10 iters), loss = 10.4007
I0523 22:08:09.360446 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4007 (* 1 = 10.4007 loss)
I0523 22:08:09.360472 11654 sgd_solver.cpp:112] Iteration 1200, lr = 0.1
I0523 22:08:16.123756 11654 solver.cpp:239] Iteration 1210 (1.47862 iter/s, 6.76305s/10 iters), loss = 10.8284
I0523 22:08:16.123795 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8284 (* 1 = 10.8284 loss)
I0523 22:08:16.123988 11654 sgd_solver.cpp:112] Iteration 1210, lr = 0.1
I0523 22:08:22.418859 11654 solver.cpp:239] Iteration 1220 (1.58861 iter/s, 6.29481s/10 iters), loss = 10.7212
I0523 22:08:22.418923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7212 (* 1 = 10.7212 loss)
I0523 22:08:22.419389 11654 sgd_solver.cpp:112] Iteration 1220, lr = 0.1
I0523 22:08:29.617650 11654 solver.cpp:239] Iteration 1230 (1.38919 iter/s, 7.19844s/10 iters), loss = 10.6972
I0523 22:08:29.617805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6972 (* 1 = 10.6972 loss)
I0523 22:08:29.617825 11654 sgd_solver.cpp:112] Iteration 1230, lr = 0.1
I0523 22:08:36.296614 11654 solver.cpp:239] Iteration 1240 (1.49733 iter/s, 6.67857s/10 iters), loss = 10.9031
I0523 22:08:36.296658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9031 (* 1 = 10.9031 loss)
I0523 22:08:36.296922 11654 sgd_solver.cpp:112] Iteration 1240, lr = 0.1
I0523 22:08:42.238057 11654 solver.cpp:239] Iteration 1250 (1.68317 iter/s, 5.94117s/10 iters), loss = 10.1756
I0523 22:08:42.238102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1756 (* 1 = 10.1756 loss)
I0523 22:08:42.238114 11654 sgd_solver.cpp:112] Iteration 1250, lr = 0.1
I0523 22:08:49.269600 11654 solver.cpp:239] Iteration 1260 (1.42266 iter/s, 7.02907s/10 iters), loss = 11.0869
I0523 22:08:49.269651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0869 (* 1 = 11.0869 loss)
I0523 22:08:49.269966 11654 sgd_solver.cpp:112] Iteration 1260, lr = 0.1
I0523 22:08:55.938769 11654 solver.cpp:239] Iteration 1270 (1.4995 iter/s, 6.66887s/10 iters), loss = 10.3543
I0523 22:08:55.938807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3543 (* 1 = 10.3543 loss)
I0523 22:08:55.938912 11654 sgd_solver.cpp:112] Iteration 1270, lr = 0.1
I0523 22:09:02.890425 11654 solver.cpp:239] Iteration 1280 (1.43857 iter/s, 6.95135s/10 iters), loss = 9.89092
I0523 22:09:02.890628 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.89092 (* 1 = 9.89092 loss)
I0523 22:09:02.896524 11654 sgd_solver.cpp:112] Iteration 1280, lr = 0.1
I0523 22:09:11.436408 11654 solver.cpp:239] Iteration 1290 (1.17021 iter/s, 8.54549s/10 iters), loss = 10.5035
I0523 22:09:11.436460 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5035 (* 1 = 10.5035 loss)
I0523 22:09:11.436939 11654 sgd_solver.cpp:112] Iteration 1290, lr = 0.1
I0523 22:09:19.248970 11654 solver.cpp:239] Iteration 1300 (1.28005 iter/s, 7.81221s/10 iters), loss = 10.1384
I0523 22:09:19.249018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1384 (* 1 = 10.1384 loss)
I0523 22:09:19.249189 11654 sgd_solver.cpp:112] Iteration 1300, lr = 0.1
I0523 22:09:27.089200 11654 solver.cpp:239] Iteration 1310 (1.27553 iter/s, 7.83989s/10 iters), loss = 10.7857
I0523 22:09:27.089248 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7857 (* 1 = 10.7857 loss)
I0523 22:09:27.089262 11654 sgd_solver.cpp:112] Iteration 1310, lr = 0.1
I0523 22:09:35.369439 11654 solver.cpp:239] Iteration 1320 (1.20776 iter/s, 8.27981s/10 iters), loss = 10.7339
I0523 22:09:35.369731 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7339 (* 1 = 10.7339 loss)
I0523 22:09:35.369776 11654 sgd_solver.cpp:112] Iteration 1320, lr = 0.1
I0523 22:09:44.424948 11654 solver.cpp:239] Iteration 1330 (1.10463 iter/s, 9.05281s/10 iters), loss = 10.0556
I0523 22:09:44.425001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0556 (* 1 = 10.0556 loss)
I0523 22:09:44.425387 11654 sgd_solver.cpp:112] Iteration 1330, lr = 0.1
I0523 22:09:50.801254 11654 solver.cpp:239] Iteration 1340 (1.56838 iter/s, 6.376s/10 iters), loss = 10.2729
I0523 22:09:50.801296 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2729 (* 1 = 10.2729 loss)
I0523 22:09:50.801532 11654 sgd_solver.cpp:112] Iteration 1340, lr = 0.1
I0523 22:09:57.107426 11654 solver.cpp:239] Iteration 1350 (1.58582 iter/s, 6.30589s/10 iters), loss = 10.547
I0523 22:09:57.107480 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.547 (* 1 = 10.547 loss)
I0523 22:09:57.107551 11654 sgd_solver.cpp:112] Iteration 1350, lr = 0.1
I0523 22:10:05.067770 11654 solver.cpp:239] Iteration 1360 (1.25628 iter/s, 7.95999s/10 iters), loss = 10.1286
I0523 22:10:05.067817 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1286 (* 1 = 10.1286 loss)
I0523 22:10:05.828832 11654 sgd_solver.cpp:112] Iteration 1360, lr = 0.1
I0523 22:10:11.949280 11654 solver.cpp:239] Iteration 1370 (1.45324 iter/s, 6.8812s/10 iters), loss = 10.3326
I0523 22:10:11.949322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3326 (* 1 = 10.3326 loss)
I0523 22:10:11.949348 11654 sgd_solver.cpp:112] Iteration 1370, lr = 0.1
I0523 22:10:19.307883 11654 solver.cpp:239] Iteration 1380 (1.35901 iter/s, 7.35828s/10 iters), loss = 10.2254
I0523 22:10:19.307919 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2254 (* 1 = 10.2254 loss)
I0523 22:10:19.307929 11654 sgd_solver.cpp:112] Iteration 1380, lr = 0.1
I0523 22:10:26.957613 11654 solver.cpp:239] Iteration 1390 (1.30729 iter/s, 7.6494s/10 iters), loss = 10.036
I0523 22:10:26.957656 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.036 (* 1 = 10.036 loss)
I0523 22:10:27.342825 11654 sgd_solver.cpp:112] Iteration 1390, lr = 0.1
I0523 22:10:35.537340 11654 solver.cpp:239] Iteration 1400 (1.16559 iter/s, 8.57934s/10 iters), loss = 10.6985
I0523 22:10:35.537397 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6985 (* 1 = 10.6985 loss)
I0523 22:10:36.071609 11654 sgd_solver.cpp:112] Iteration 1400, lr = 0.1
I0523 22:10:42.927230 11654 solver.cpp:239] Iteration 1410 (1.35326 iter/s, 7.38956s/10 iters), loss = 10.6542
I0523 22:10:42.927266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6542 (* 1 = 10.6542 loss)
I0523 22:10:42.927384 11654 sgd_solver.cpp:112] Iteration 1410, lr = 0.1
I0523 22:10:50.843430 11654 solver.cpp:239] Iteration 1420 (1.26329 iter/s, 7.91586s/10 iters), loss = 10.3742
I0523 22:10:50.843475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3742 (* 1 = 10.3742 loss)
I0523 22:10:50.843489 11654 sgd_solver.cpp:112] Iteration 1420, lr = 0.1
I0523 22:11:01.083282 11654 solver.cpp:239] Iteration 1430 (0.976625 iter/s, 10.2393s/10 iters), loss = 11.2687
I0523 22:11:01.083328 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2687 (* 1 = 11.2687 loss)
I0523 22:11:01.487243 11654 sgd_solver.cpp:112] Iteration 1430, lr = 0.1
I0523 22:11:08.696030 11654 solver.cpp:239] Iteration 1440 (1.31364 iter/s, 7.61241s/10 iters), loss = 10.1878
I0523 22:11:08.696302 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1878 (* 1 = 10.1878 loss)
I0523 22:11:08.696350 11654 sgd_solver.cpp:112] Iteration 1440, lr = 0.1
I0523 22:11:15.446059 11654 solver.cpp:239] Iteration 1450 (1.48169 iter/s, 6.74907s/10 iters), loss = 10.1497
I0523 22:11:15.446101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1497 (* 1 = 10.1497 loss)
I0523 22:11:15.446139 11654 sgd_solver.cpp:112] Iteration 1450, lr = 0.1
I0523 22:11:21.595492 11654 solver.cpp:239] Iteration 1460 (1.62624 iter/s, 6.14915s/10 iters), loss = 10.7133
I0523 22:11:21.595542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7133 (* 1 = 10.7133 loss)
I0523 22:11:21.595652 11654 sgd_solver.cpp:112] Iteration 1460, lr = 0.1
I0523 22:11:28.543006 11654 solver.cpp:239] Iteration 1470 (1.43943 iter/s, 6.94721s/10 iters), loss = 10.7635
I0523 22:11:28.543041 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7635 (* 1 = 10.7635 loss)
I0523 22:11:28.621040 11654 sgd_solver.cpp:112] Iteration 1470, lr = 0.1
I0523 22:11:35.582176 11654 solver.cpp:239] Iteration 1480 (1.42069 iter/s, 7.03885s/10 iters), loss = 10.5779
I0523 22:11:35.582219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5779 (* 1 = 10.5779 loss)
I0523 22:11:35.747381 11654 sgd_solver.cpp:112] Iteration 1480, lr = 0.1
I0523 22:11:41.733721 11654 solver.cpp:239] Iteration 1490 (1.62568 iter/s, 6.15127s/10 iters), loss = 10.548
I0523 22:11:41.733849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.548 (* 1 = 10.548 loss)
I0523 22:11:42.066697 11654 sgd_solver.cpp:112] Iteration 1490, lr = 0.1
I0523 22:11:49.917240 11654 solver.cpp:239] Iteration 1500 (1.22203 iter/s, 8.18308s/10 iters), loss = 10.4748
I0523 22:11:49.917284 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4748 (* 1 = 10.4748 loss)
I0523 22:11:49.917295 11654 sgd_solver.cpp:112] Iteration 1500, lr = 0.1
I0523 22:11:56.127429 11654 solver.cpp:239] Iteration 1510 (1.6109 iter/s, 6.20771s/10 iters), loss = 10.2278
I0523 22:11:56.127471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2278 (* 1 = 10.2278 loss)
I0523 22:11:56.226500 11654 sgd_solver.cpp:112] Iteration 1510, lr = 0.1
I0523 22:12:03.092622 11654 solver.cpp:239] Iteration 1520 (1.43578 iter/s, 6.96488s/10 iters), loss = 10.8516
I0523 22:12:03.092671 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8516 (* 1 = 10.8516 loss)
I0523 22:12:03.093272 11654 sgd_solver.cpp:112] Iteration 1520, lr = 0.1
I0523 22:12:09.226591 11654 solver.cpp:239] Iteration 1530 (1.63034 iter/s, 6.13368s/10 iters), loss = 10.0473
I0523 22:12:09.226640 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0473 (* 1 = 10.0473 loss)
I0523 22:12:09.516381 11654 sgd_solver.cpp:112] Iteration 1530, lr = 0.1
I0523 22:12:15.835925 11654 solver.cpp:239] Iteration 1540 (1.51308 iter/s, 6.60903s/10 iters), loss = 10.8281
I0523 22:12:15.836014 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8281 (* 1 = 10.8281 loss)
I0523 22:12:15.836086 11654 sgd_solver.cpp:112] Iteration 1540, lr = 0.1
I0523 22:12:23.871840 11654 solver.cpp:239] Iteration 1550 (1.24447 iter/s, 8.03552s/10 iters), loss = 10.7997
I0523 22:12:23.871888 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7997 (* 1 = 10.7997 loss)
I0523 22:12:23.871903 11654 sgd_solver.cpp:112] Iteration 1550, lr = 0.1
I0523 22:12:31.402855 11654 solver.cpp:239] Iteration 1560 (1.32791 iter/s, 7.53062s/10 iters), loss = 10.5313
I0523 22:12:31.402899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5313 (* 1 = 10.5313 loss)
I0523 22:12:31.402915 11654 sgd_solver.cpp:112] Iteration 1560, lr = 0.1
I0523 22:12:38.125658 11654 solver.cpp:239] Iteration 1570 (1.48756 iter/s, 6.72243s/10 iters), loss = 11.2642
I0523 22:12:38.125699 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2642 (* 1 = 11.2642 loss)
I0523 22:12:38.125710 11654 sgd_solver.cpp:112] Iteration 1570, lr = 0.1
I0523 22:12:46.048151 11654 solver.cpp:239] Iteration 1580 (1.2623 iter/s, 7.92207s/10 iters), loss = 10.711
I0523 22:12:46.048424 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.711 (* 1 = 10.711 loss)
I0523 22:12:46.048468 11654 sgd_solver.cpp:112] Iteration 1580, lr = 0.1
I0523 22:12:52.902045 11654 solver.cpp:239] Iteration 1590 (1.45914 iter/s, 6.85336s/10 iters), loss = 10.7595
I0523 22:12:52.902088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7595 (* 1 = 10.7595 loss)
I0523 22:12:52.902590 11654 sgd_solver.cpp:112] Iteration 1590, lr = 0.1
I0523 22:12:59.343514 11654 solver.cpp:239] Iteration 1600 (1.55251 iter/s, 6.44117s/10 iters), loss = 11.3229
I0523 22:12:59.343559 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3229 (* 1 = 11.3229 loss)
I0523 22:12:59.343570 11654 sgd_solver.cpp:112] Iteration 1600, lr = 0.1
I0523 22:13:08.378031 11654 solver.cpp:239] Iteration 1610 (1.10691 iter/s, 9.03413s/10 iters), loss = 10.5192
I0523 22:13:08.378075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5192 (* 1 = 10.5192 loss)
I0523 22:13:08.378213 11654 sgd_solver.cpp:112] Iteration 1610, lr = 0.1
I0523 22:13:16.851923 11654 solver.cpp:239] Iteration 1620 (1.18015 iter/s, 8.47353s/10 iters), loss = 11.1858
I0523 22:13:16.852109 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1858 (* 1 = 11.1858 loss)
I0523 22:13:17.718834 11654 sgd_solver.cpp:112] Iteration 1620, lr = 0.1
I0523 22:13:26.057345 11654 solver.cpp:239] Iteration 1630 (1.08638 iter/s, 9.20491s/10 iters), loss = 10.7978
I0523 22:13:26.057389 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7978 (* 1 = 10.7978 loss)
I0523 22:13:26.066526 11654 sgd_solver.cpp:112] Iteration 1630, lr = 0.1
I0523 22:13:34.013536 11654 solver.cpp:239] Iteration 1640 (1.25694 iter/s, 7.95583s/10 iters), loss = 10.4193
I0523 22:13:34.013597 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4193 (* 1 = 10.4193 loss)
I0523 22:13:34.053988 11654 sgd_solver.cpp:112] Iteration 1640, lr = 0.1
I0523 22:13:41.821838 11654 solver.cpp:239] Iteration 1650 (1.28075 iter/s, 7.80795s/10 iters), loss = 11.5165
I0523 22:13:41.821883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5165 (* 1 = 11.5165 loss)
I0523 22:13:43.014395 11654 sgd_solver.cpp:112] Iteration 1650, lr = 0.1
I0523 22:13:50.153141 11654 solver.cpp:239] Iteration 1660 (1.20035 iter/s, 8.33093s/10 iters), loss = 10.8224
I0523 22:13:50.153344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8224 (* 1 = 10.8224 loss)
I0523 22:13:50.153493 11654 sgd_solver.cpp:112] Iteration 1660, lr = 0.1
I0523 22:13:57.479758 11654 solver.cpp:239] Iteration 1670 (1.36497 iter/s, 7.32616s/10 iters), loss = 10.7866
I0523 22:13:57.479802 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7866 (* 1 = 10.7866 loss)
I0523 22:13:57.951084 11654 sgd_solver.cpp:112] Iteration 1670, lr = 0.1
I0523 22:14:06.998033 11654 solver.cpp:239] Iteration 1680 (1.05066 iter/s, 9.51787s/10 iters), loss = 10.5571
I0523 22:14:06.998078 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5571 (* 1 = 10.5571 loss)
I0523 22:14:06.998091 11654 sgd_solver.cpp:112] Iteration 1680, lr = 0.1
I0523 22:14:13.660625 11654 solver.cpp:239] Iteration 1690 (1.501 iter/s, 6.66222s/10 iters), loss = 11.3218
I0523 22:14:13.660666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3218 (* 1 = 11.3218 loss)
I0523 22:14:13.660677 11654 sgd_solver.cpp:112] Iteration 1690, lr = 0.1
I0523 22:14:21.601328 11654 solver.cpp:239] Iteration 1700 (1.2594 iter/s, 7.94029s/10 iters), loss = 10.9162
I0523 22:14:21.601544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9162 (* 1 = 10.9162 loss)
I0523 22:14:21.601590 11654 sgd_solver.cpp:112] Iteration 1700, lr = 0.1
I0523 22:14:28.493405 11654 solver.cpp:239] Iteration 1710 (1.45104 iter/s, 6.89159s/10 iters), loss = 10.5306
I0523 22:14:28.493444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5306 (* 1 = 10.5306 loss)
I0523 22:14:28.493455 11654 sgd_solver.cpp:112] Iteration 1710, lr = 0.1
I0523 22:14:35.205142 11654 solver.cpp:239] Iteration 1720 (1.48999 iter/s, 6.71143s/10 iters), loss = 11.0687
I0523 22:14:35.205190 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0687 (* 1 = 11.0687 loss)
I0523 22:14:35.260766 11654 sgd_solver.cpp:112] Iteration 1720, lr = 0.1
I0523 22:14:42.912859 11654 solver.cpp:239] Iteration 1730 (1.29746 iter/s, 7.70738s/10 iters), loss = 10.5661
I0523 22:14:42.912896 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5661 (* 1 = 10.5661 loss)
I0523 22:14:42.912909 11654 sgd_solver.cpp:112] Iteration 1730, lr = 0.1
I0523 22:14:49.212599 11654 solver.cpp:239] Iteration 1740 (1.5876 iter/s, 6.2988s/10 iters), loss = 10.7886
I0523 22:14:49.212651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7886 (* 1 = 10.7886 loss)
I0523 22:14:49.213006 11654 sgd_solver.cpp:112] Iteration 1740, lr = 0.1
I0523 22:14:57.876504 11654 solver.cpp:239] Iteration 1750 (1.15426 iter/s, 8.66353s/10 iters), loss = 11.1486
I0523 22:14:57.876670 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1486 (* 1 = 11.1486 loss)
I0523 22:14:57.876685 11654 sgd_solver.cpp:112] Iteration 1750, lr = 0.1
I0523 22:15:04.646688 11654 solver.cpp:239] Iteration 1760 (1.47716 iter/s, 6.76973s/10 iters), loss = 10.9718
I0523 22:15:04.646755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9718 (* 1 = 10.9718 loss)
I0523 22:15:04.646939 11654 sgd_solver.cpp:112] Iteration 1760, lr = 0.1
I0523 22:15:11.629943 11654 solver.cpp:239] Iteration 1770 (1.43207 iter/s, 6.98292s/10 iters), loss = 10.7456
I0523 22:15:11.629987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7456 (* 1 = 10.7456 loss)
I0523 22:15:11.630223 11654 sgd_solver.cpp:112] Iteration 1770, lr = 0.1
I0523 22:15:19.644963 11654 solver.cpp:239] Iteration 1780 (1.24771 iter/s, 8.01467s/10 iters), loss = 11.0727
I0523 22:15:19.645005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0727 (* 1 = 11.0727 loss)
I0523 22:15:19.736037 11654 sgd_solver.cpp:112] Iteration 1780, lr = 0.1
I0523 22:15:27.360101 11654 solver.cpp:239] Iteration 1790 (1.29621 iter/s, 7.71479s/10 iters), loss = 10.5002
I0523 22:15:27.360157 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5002 (* 1 = 10.5002 loss)
I0523 22:15:27.361052 11654 sgd_solver.cpp:112] Iteration 1790, lr = 0.1
I0523 22:15:33.685130 11654 solver.cpp:239] Iteration 1800 (1.5811 iter/s, 6.32472s/10 iters), loss = 11.2418
I0523 22:15:33.685365 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2418 (* 1 = 11.2418 loss)
I0523 22:15:33.688936 11654 sgd_solver.cpp:112] Iteration 1800, lr = 0.1
I0523 22:15:41.000290 11654 solver.cpp:239] Iteration 1810 (1.36711 iter/s, 7.31468s/10 iters), loss = 10.6888
I0523 22:15:41.000334 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6888 (* 1 = 10.6888 loss)
I0523 22:15:41.000414 11654 sgd_solver.cpp:112] Iteration 1810, lr = 0.1
I0523 22:15:47.192226 11654 solver.cpp:239] Iteration 1820 (1.61508 iter/s, 6.19166s/10 iters), loss = 11.1394
I0523 22:15:47.192270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1394 (* 1 = 11.1394 loss)
I0523 22:15:47.208906 11654 sgd_solver.cpp:112] Iteration 1820, lr = 0.1
I0523 22:15:55.247978 11654 solver.cpp:239] Iteration 1830 (1.2414 iter/s, 8.0554s/10 iters), loss = 11.1632
I0523 22:15:55.248018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1632 (* 1 = 11.1632 loss)
I0523 22:15:55.248028 11654 sgd_solver.cpp:112] Iteration 1830, lr = 0.1
I0523 22:16:05.139611 11654 solver.cpp:239] Iteration 1840 (1.011 iter/s, 9.89122s/10 iters), loss = 10.0032
I0523 22:16:05.139878 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0032 (* 1 = 10.0032 loss)
I0523 22:16:05.482439 11654 sgd_solver.cpp:112] Iteration 1840, lr = 0.1
I0523 22:16:12.750828 11654 solver.cpp:239] Iteration 1850 (1.31394 iter/s, 7.6107s/10 iters), loss = 10.8586
I0523 22:16:12.750872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8586 (* 1 = 10.8586 loss)
I0523 22:16:12.750995 11654 sgd_solver.cpp:112] Iteration 1850, lr = 0.1
I0523 22:16:20.459532 11654 solver.cpp:239] Iteration 1860 (1.29729 iter/s, 7.70836s/10 iters), loss = 10.2599
I0523 22:16:20.459581 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2599 (* 1 = 10.2599 loss)
I0523 22:16:20.459782 11654 sgd_solver.cpp:112] Iteration 1860, lr = 0.1
I0523 22:16:26.752300 11654 solver.cpp:239] Iteration 1870 (1.5892 iter/s, 6.29248s/10 iters), loss = 10.6245
I0523 22:16:26.752341 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6245 (* 1 = 10.6245 loss)
I0523 22:16:26.752353 11654 sgd_solver.cpp:112] Iteration 1870, lr = 0.1
I0523 22:16:34.829028 11654 solver.cpp:239] Iteration 1880 (1.23819 iter/s, 8.07629s/10 iters), loss = 11.1717
I0523 22:16:34.829080 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1717 (* 1 = 11.1717 loss)
I0523 22:16:34.829613 11654 sgd_solver.cpp:112] Iteration 1880, lr = 0.1
I0523 22:16:42.101758 11654 solver.cpp:239] Iteration 1890 (1.37506 iter/s, 7.2724s/10 iters), loss = 10.9503
I0523 22:16:42.102012 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9503 (* 1 = 10.9503 loss)
I0523 22:16:42.102056 11654 sgd_solver.cpp:112] Iteration 1890, lr = 0.1
I0523 22:16:49.709353 11654 solver.cpp:239] Iteration 1900 (1.31492 iter/s, 7.60504s/10 iters), loss = 11.3771
I0523 22:16:49.709393 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3771 (* 1 = 11.3771 loss)
I0523 22:16:50.248339 11654 sgd_solver.cpp:112] Iteration 1900, lr = 0.1
I0523 22:16:57.216735 11654 solver.cpp:239] Iteration 1910 (1.33208 iter/s, 7.50705s/10 iters), loss = 11.5048
I0523 22:16:57.216785 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5048 (* 1 = 11.5048 loss)
I0523 22:16:57.217012 11654 sgd_solver.cpp:112] Iteration 1910, lr = 0.1
I0523 22:17:05.488451 11654 solver.cpp:239] Iteration 1920 (1.20899 iter/s, 8.27135s/10 iters), loss = 11.1207
I0523 22:17:05.488495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1207 (* 1 = 11.1207 loss)
I0523 22:17:05.489073 11654 sgd_solver.cpp:112] Iteration 1920, lr = 0.1
I0523 22:17:13.155721 11654 solver.cpp:239] Iteration 1930 (1.3043 iter/s, 7.66693s/10 iters), loss = 11.2158
I0523 22:17:13.155962 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2158 (* 1 = 11.2158 loss)
I0523 22:17:13.156008 11654 sgd_solver.cpp:112] Iteration 1930, lr = 0.1
I0523 22:17:19.397295 11654 solver.cpp:239] Iteration 1940 (1.60228 iter/s, 6.24109s/10 iters), loss = 10.6247
I0523 22:17:19.397347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6247 (* 1 = 10.6247 loss)
I0523 22:17:19.397711 11654 sgd_solver.cpp:112] Iteration 1940, lr = 0.1
I0523 22:17:25.987251 11654 solver.cpp:239] Iteration 1950 (1.51753 iter/s, 6.58966s/10 iters), loss = 11.1607
I0523 22:17:25.987293 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1607 (* 1 = 11.1607 loss)
I0523 22:17:25.987709 11654 sgd_solver.cpp:112] Iteration 1950, lr = 0.1
I0523 22:17:35.231322 11654 solver.cpp:239] Iteration 1960 (1.08182 iter/s, 9.24368s/10 iters), loss = 11.2029
I0523 22:17:35.231362 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2029 (* 1 = 11.2029 loss)
I0523 22:17:35.231384 11654 sgd_solver.cpp:112] Iteration 1960, lr = 0.1
I0523 22:17:42.254976 11654 solver.cpp:239] Iteration 1970 (1.42382 iter/s, 7.02334s/10 iters), loss = 10.7013
I0523 22:17:42.255024 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7013 (* 1 = 10.7013 loss)
I0523 22:17:42.255439 11654 sgd_solver.cpp:112] Iteration 1970, lr = 0.1
I0523 22:17:48.795472 11654 solver.cpp:239] Iteration 1980 (1.52901 iter/s, 6.54018s/10 iters), loss = 10.4957
I0523 22:17:48.795727 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4957 (* 1 = 10.4957 loss)
I0523 22:17:48.795773 11654 sgd_solver.cpp:112] Iteration 1980, lr = 0.1
I0523 22:17:55.819206 11654 solver.cpp:239] Iteration 1990 (1.42428 iter/s, 7.02109s/10 iters), loss = 11.3736
I0523 22:17:55.819243 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3736 (* 1 = 11.3736 loss)
I0523 22:17:55.819293 11654 sgd_solver.cpp:112] Iteration 1990, lr = 0.1
I0523 22:18:06.164942 11654 solver.cpp:239] Iteration 2000 (0.966622 iter/s, 10.3453s/10 iters), loss = 11.2014
I0523 22:18:06.164983 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2014 (* 1 = 11.2014 loss)
I0523 22:18:07.376065 11654 sgd_solver.cpp:112] Iteration 2000, lr = 0.1
I0523 22:18:14.561866 11654 solver.cpp:239] Iteration 2010 (1.19096 iter/s, 8.39657s/10 iters), loss = 10.7921
I0523 22:18:14.561903 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7921 (* 1 = 10.7921 loss)
I0523 22:18:14.715212 11654 sgd_solver.cpp:112] Iteration 2010, lr = 0.1
I0523 22:18:22.838382 11654 solver.cpp:239] Iteration 2020 (1.20829 iter/s, 8.27615s/10 iters), loss = 11.27
I0523 22:18:22.838562 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.27 (* 1 = 11.27 loss)
I0523 22:18:22.838589 11654 sgd_solver.cpp:112] Iteration 2020, lr = 0.1
I0523 22:18:30.457659 11654 solver.cpp:239] Iteration 2030 (1.31254 iter/s, 7.61881s/10 iters), loss = 10.7493
I0523 22:18:30.457700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7493 (* 1 = 10.7493 loss)
I0523 22:18:30.457710 11654 sgd_solver.cpp:112] Iteration 2030, lr = 0.1
I0523 22:18:37.527128 11654 solver.cpp:239] Iteration 2040 (1.4146 iter/s, 7.06916s/10 iters), loss = 11.5577
I0523 22:18:37.527170 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5577 (* 1 = 11.5577 loss)
I0523 22:18:37.527420 11654 sgd_solver.cpp:112] Iteration 2040, lr = 0.1
I0523 22:18:43.914842 11654 solver.cpp:239] Iteration 2050 (1.56558 iter/s, 6.3874s/10 iters), loss = 10.9557
I0523 22:18:43.914932 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9557 (* 1 = 10.9557 loss)
I0523 22:18:44.020961 11654 sgd_solver.cpp:112] Iteration 2050, lr = 0.1
I0523 22:18:51.458901 11654 solver.cpp:239] Iteration 2060 (1.32561 iter/s, 7.54368s/10 iters), loss = 10.8166
I0523 22:18:51.458945 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8166 (* 1 = 10.8166 loss)
I0523 22:18:51.458968 11654 sgd_solver.cpp:112] Iteration 2060, lr = 0.1
I0523 22:18:58.521883 11654 solver.cpp:239] Iteration 2070 (1.4159 iter/s, 7.06266s/10 iters), loss = 10.6458
I0523 22:18:58.522116 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6458 (* 1 = 10.6458 loss)
I0523 22:18:58.522167 11654 sgd_solver.cpp:112] Iteration 2070, lr = 0.1
I0523 22:19:06.828761 11654 solver.cpp:239] Iteration 2080 (1.2039 iter/s, 8.30633s/10 iters), loss = 10.8282
I0523 22:19:06.828809 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8282 (* 1 = 10.8282 loss)
I0523 22:19:07.886687 11654 sgd_solver.cpp:112] Iteration 2080, lr = 0.1
I0523 22:19:15.883152 11654 solver.cpp:239] Iteration 2090 (1.10448 iter/s, 9.054s/10 iters), loss = 11.0353
I0523 22:19:15.883194 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0353 (* 1 = 11.0353 loss)
I0523 22:19:15.883594 11654 sgd_solver.cpp:112] Iteration 2090, lr = 0.1
I0523 22:19:22.669520 11654 solver.cpp:239] Iteration 2100 (1.47361 iter/s, 6.78605s/10 iters), loss = 11.5179
I0523 22:19:22.669570 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5179 (* 1 = 11.5179 loss)
I0523 22:19:23.191089 11654 sgd_solver.cpp:112] Iteration 2100, lr = 0.1
I0523 22:19:30.071010 11654 solver.cpp:239] Iteration 2110 (1.35114 iter/s, 7.40116s/10 iters), loss = 10.6195
I0523 22:19:30.071271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6195 (* 1 = 10.6195 loss)
I0523 22:19:30.071317 11654 sgd_solver.cpp:112] Iteration 2110, lr = 0.1
I0523 22:19:37.995795 11654 solver.cpp:239] Iteration 2120 (1.26195 iter/s, 7.92425s/10 iters), loss = 10.7332
I0523 22:19:37.995846 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7332 (* 1 = 10.7332 loss)
I0523 22:19:37.996286 11654 sgd_solver.cpp:112] Iteration 2120, lr = 0.1
I0523 22:19:46.080150 11654 solver.cpp:239] Iteration 2130 (1.23701 iter/s, 8.084s/10 iters), loss = 11.5426
I0523 22:19:46.080184 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5426 (* 1 = 11.5426 loss)
I0523 22:19:46.080206 11654 sgd_solver.cpp:112] Iteration 2130, lr = 0.1
I0523 22:19:53.565189 11654 solver.cpp:239] Iteration 2140 (1.33606 iter/s, 7.4847s/10 iters), loss = 10.6567
I0523 22:19:53.565233 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6567 (* 1 = 10.6567 loss)
I0523 22:19:53.565665 11654 sgd_solver.cpp:112] Iteration 2140, lr = 0.1
I0523 22:20:00.842893 11654 solver.cpp:239] Iteration 2150 (1.37412 iter/s, 7.27737s/10 iters), loss = 11.1341
I0523 22:20:00.843189 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1341 (* 1 = 11.1341 loss)
I0523 22:20:00.843240 11654 sgd_solver.cpp:112] Iteration 2150, lr = 0.1
I0523 22:20:08.101138 11654 solver.cpp:239] Iteration 2160 (1.37789 iter/s, 7.25749s/10 iters), loss = 11.1024
I0523 22:20:08.101183 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1024 (* 1 = 11.1024 loss)
I0523 22:20:08.101294 11654 sgd_solver.cpp:112] Iteration 2160, lr = 0.1
I0523 22:20:16.012473 11654 solver.cpp:239] Iteration 2170 (1.26407 iter/s, 7.91098s/10 iters), loss = 10.8841
I0523 22:20:16.012526 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8841 (* 1 = 10.8841 loss)
I0523 22:20:16.036909 11654 sgd_solver.cpp:112] Iteration 2170, lr = 0.1
I0523 22:20:22.785665 11654 solver.cpp:239] Iteration 2180 (1.47648 iter/s, 6.77288s/10 iters), loss = 10.7479
I0523 22:20:22.785707 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7479 (* 1 = 10.7479 loss)
I0523 22:20:22.911692 11654 sgd_solver.cpp:112] Iteration 2180, lr = 0.1
I0523 22:20:29.214370 11654 solver.cpp:239] Iteration 2190 (1.55559 iter/s, 6.42842s/10 iters), loss = 10.4484
I0523 22:20:29.214414 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4484 (* 1 = 10.4484 loss)
I0523 22:20:29.214879 11654 sgd_solver.cpp:112] Iteration 2190, lr = 0.1
I0523 22:20:36.966452 11654 solver.cpp:239] Iteration 2200 (1.29003 iter/s, 7.75174s/10 iters), loss = 10.3101
I0523 22:20:36.966684 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3101 (* 1 = 10.3101 loss)
I0523 22:20:36.966747 11654 sgd_solver.cpp:112] Iteration 2200, lr = 0.1
I0523 22:20:43.620767 11654 solver.cpp:239] Iteration 2210 (1.5029 iter/s, 6.65382s/10 iters), loss = 10.9164
I0523 22:20:43.620806 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9164 (* 1 = 10.9164 loss)
I0523 22:20:43.620818 11654 sgd_solver.cpp:112] Iteration 2210, lr = 0.1
I0523 22:20:50.764978 11654 solver.cpp:239] Iteration 2220 (1.3998 iter/s, 7.1439s/10 iters), loss = 10.8131
I0523 22:20:50.765022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8131 (* 1 = 10.8131 loss)
I0523 22:20:50.765033 11654 sgd_solver.cpp:112] Iteration 2220, lr = 0.1
I0523 22:20:57.955271 11654 solver.cpp:239] Iteration 2230 (1.39084 iter/s, 7.18989s/10 iters), loss = 10.5155
I0523 22:20:57.955312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5155 (* 1 = 10.5155 loss)
I0523 22:20:57.955324 11654 sgd_solver.cpp:112] Iteration 2230, lr = 0.1
I0523 22:21:06.724128 11654 solver.cpp:239] Iteration 2240 (1.14045 iter/s, 8.76848s/10 iters), loss = 10.9289
I0523 22:21:06.724171 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9289 (* 1 = 10.9289 loss)
I0523 22:21:06.724184 11654 sgd_solver.cpp:112] Iteration 2240, lr = 0.1
I0523 22:21:14.742830 11654 solver.cpp:239] Iteration 2250 (1.24715 iter/s, 8.01829s/10 iters), loss = 10.9199
I0523 22:21:14.743014 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9199 (* 1 = 10.9199 loss)
I0523 22:21:14.743062 11654 sgd_solver.cpp:112] Iteration 2250, lr = 0.1
I0523 22:21:23.552047 11654 solver.cpp:239] Iteration 2260 (1.13551 iter/s, 8.80661s/10 iters), loss = 10.691
I0523 22:21:23.552093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.691 (* 1 = 10.691 loss)
I0523 22:21:23.833232 11654 sgd_solver.cpp:112] Iteration 2260, lr = 0.1
I0523 22:21:31.388716 11654 solver.cpp:239] Iteration 2270 (1.27611 iter/s, 7.83632s/10 iters), loss = 11.1766
I0523 22:21:31.388765 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1766 (* 1 = 11.1766 loss)
I0523 22:21:31.388779 11654 sgd_solver.cpp:112] Iteration 2270, lr = 0.1
I0523 22:21:38.209086 11654 solver.cpp:239] Iteration 2280 (1.46628 iter/s, 6.81998s/10 iters), loss = 10.0605
I0523 22:21:38.209130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0605 (* 1 = 10.0605 loss)
I0523 22:21:38.209216 11654 sgd_solver.cpp:112] Iteration 2280, lr = 0.1
I0523 22:21:44.977077 11654 solver.cpp:239] Iteration 2290 (1.47761 iter/s, 6.76769s/10 iters), loss = 10.958
I0523 22:21:44.977203 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.958 (* 1 = 10.958 loss)
I0523 22:21:44.977217 11654 sgd_solver.cpp:112] Iteration 2290, lr = 0.1
I0523 22:21:51.409598 11654 solver.cpp:239] Iteration 2300 (1.55523 iter/s, 6.4299s/10 iters), loss = 10.5246
I0523 22:21:51.409642 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5246 (* 1 = 10.5246 loss)
I0523 22:21:51.509270 11654 sgd_solver.cpp:112] Iteration 2300, lr = 0.1
I0523 22:21:58.195407 11654 solver.cpp:239] Iteration 2310 (1.47373 iter/s, 6.7855s/10 iters), loss = 11.2397
I0523 22:21:58.195454 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2397 (* 1 = 11.2397 loss)
I0523 22:21:58.195472 11654 sgd_solver.cpp:112] Iteration 2310, lr = 0.1
I0523 22:22:04.435600 11654 solver.cpp:239] Iteration 2320 (1.60259 iter/s, 6.2399s/10 iters), loss = 10.5897
I0523 22:22:04.435648 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5897 (* 1 = 10.5897 loss)
I0523 22:22:04.436051 11654 sgd_solver.cpp:112] Iteration 2320, lr = 0.1
I0523 22:22:10.424278 11654 solver.cpp:239] Iteration 2330 (1.6699 iter/s, 5.9884s/10 iters), loss = 10.2851
I0523 22:22:10.424321 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2851 (* 1 = 10.2851 loss)
I0523 22:22:10.424466 11654 sgd_solver.cpp:112] Iteration 2330, lr = 0.1
I0523 22:22:17.141314 11654 solver.cpp:239] Iteration 2340 (1.48882 iter/s, 6.71674s/10 iters), loss = 10.6334
I0523 22:22:17.141435 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6334 (* 1 = 10.6334 loss)
I0523 22:22:17.170176 11654 sgd_solver.cpp:112] Iteration 2340, lr = 0.1
I0523 22:22:25.342609 11654 solver.cpp:239] Iteration 2350 (1.21938 iter/s, 8.20086s/10 iters), loss = 10.9436
I0523 22:22:25.342654 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9436 (* 1 = 10.9436 loss)
I0523 22:22:25.342669 11654 sgd_solver.cpp:112] Iteration 2350, lr = 0.1
I0523 22:22:34.895428 11654 solver.cpp:239] Iteration 2360 (1.04686 iter/s, 9.55235s/10 iters), loss = 10.4786
I0523 22:22:34.895463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4786 (* 1 = 10.4786 loss)
I0523 22:22:35.680428 11654 sgd_solver.cpp:112] Iteration 2360, lr = 0.1
I0523 22:22:41.902974 11654 solver.cpp:239] Iteration 2370 (1.4271 iter/s, 7.00723s/10 iters), loss = 11.4061
I0523 22:22:41.903028 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4061 (* 1 = 11.4061 loss)
I0523 22:22:41.903393 11654 sgd_solver.cpp:112] Iteration 2370, lr = 0.1
I0523 22:22:48.776795 11654 solver.cpp:239] Iteration 2380 (1.45486 iter/s, 6.8735s/10 iters), loss = 10.5103
I0523 22:22:48.777070 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5103 (* 1 = 10.5103 loss)
I0523 22:22:48.777130 11654 sgd_solver.cpp:112] Iteration 2380, lr = 0.1
I0523 22:22:55.235985 11654 solver.cpp:239] Iteration 2390 (1.54842 iter/s, 6.45818s/10 iters), loss = 10.7832
I0523 22:22:55.236022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7832 (* 1 = 10.7832 loss)
I0523 22:22:55.236064 11654 sgd_solver.cpp:112] Iteration 2390, lr = 0.1
I0523 22:23:01.999393 11654 solver.cpp:239] Iteration 2400 (1.47861 iter/s, 6.76311s/10 iters), loss = 10.823
I0523 22:23:01.999438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.823 (* 1 = 10.823 loss)
I0523 22:23:01.999449 11654 sgd_solver.cpp:112] Iteration 2400, lr = 0.1
I0523 22:23:08.356535 11654 solver.cpp:239] Iteration 2410 (1.57363 iter/s, 6.35475s/10 iters), loss = 10.5898
I0523 22:23:08.356572 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5898 (* 1 = 10.5898 loss)
I0523 22:23:08.356586 11654 sgd_solver.cpp:112] Iteration 2410, lr = 0.1
I0523 22:23:15.089319 11654 solver.cpp:239] Iteration 2420 (1.48551 iter/s, 6.7317s/10 iters), loss = 10.7161
I0523 22:23:15.089352 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7161 (* 1 = 10.7161 loss)
I0523 22:23:15.682497 11654 sgd_solver.cpp:112] Iteration 2420, lr = 0.1
I0523 22:23:23.913573 11654 solver.cpp:239] Iteration 2430 (1.13329 iter/s, 8.82387s/10 iters), loss = 10.6025
I0523 22:23:23.913758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6025 (* 1 = 10.6025 loss)
I0523 22:23:23.913774 11654 sgd_solver.cpp:112] Iteration 2430, lr = 0.1
I0523 22:23:31.246069 11654 solver.cpp:239] Iteration 2440 (1.36398 iter/s, 7.33151s/10 iters), loss = 11.3691
I0523 22:23:31.246103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3691 (* 1 = 11.3691 loss)
I0523 22:23:31.250993 11654 sgd_solver.cpp:112] Iteration 2440, lr = 0.1
I0523 22:23:37.999864 11654 solver.cpp:239] Iteration 2450 (1.48071 iter/s, 6.7535s/10 iters), loss = 9.9092
I0523 22:23:37.999907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.9092 (* 1 = 9.9092 loss)
I0523 22:23:37.999919 11654 sgd_solver.cpp:112] Iteration 2450, lr = 0.1
I0523 22:23:45.524479 11654 solver.cpp:239] Iteration 2460 (1.32903 iter/s, 7.52429s/10 iters), loss = 10.1748
I0523 22:23:45.524520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1748 (* 1 = 10.1748 loss)
I0523 22:23:45.631199 11654 sgd_solver.cpp:112] Iteration 2460, lr = 0.1
I0523 22:23:52.264343 11654 solver.cpp:239] Iteration 2470 (1.48378 iter/s, 6.73956s/10 iters), loss = 10.3064
I0523 22:23:52.264379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3064 (* 1 = 10.3064 loss)
I0523 22:23:52.264529 11654 sgd_solver.cpp:112] Iteration 2470, lr = 0.1
I0523 22:23:58.551336 11654 solver.cpp:239] Iteration 2480 (1.59066 iter/s, 6.28671s/10 iters), loss = 10.8884
I0523 22:23:58.551631 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8884 (* 1 = 10.8884 loss)
I0523 22:23:58.551692 11654 sgd_solver.cpp:112] Iteration 2480, lr = 0.1
I0523 22:24:06.749439 11654 solver.cpp:239] Iteration 2490 (1.2199 iter/s, 8.19738s/10 iters), loss = 11.4111
I0523 22:24:06.749471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4111 (* 1 = 11.4111 loss)
I0523 22:24:06.749544 11654 sgd_solver.cpp:112] Iteration 2490, lr = 0.1
I0523 22:24:13.346048 11654 solver.cpp:239] Iteration 2500 (1.516 iter/s, 6.59632s/10 iters), loss = 9.75043
I0523 22:24:13.346091 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.75043 (* 1 = 9.75043 loss)
I0523 22:24:13.346102 11654 sgd_solver.cpp:112] Iteration 2500, lr = 0.1
I0523 22:24:20.799279 11654 solver.cpp:239] Iteration 2510 (1.34216 iter/s, 7.45069s/10 iters), loss = 10.7492
I0523 22:24:20.799319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7492 (* 1 = 10.7492 loss)
I0523 22:24:20.927105 11654 sgd_solver.cpp:112] Iteration 2510, lr = 0.1
I0523 22:24:29.474020 11654 solver.cpp:239] Iteration 2520 (1.15282 iter/s, 8.67437s/10 iters), loss = 11.0949
I0523 22:24:29.474269 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0949 (* 1 = 11.0949 loss)
I0523 22:24:29.474314 11654 sgd_solver.cpp:112] Iteration 2520, lr = 0.1
I0523 22:24:36.702800 11654 solver.cpp:239] Iteration 2530 (1.38346 iter/s, 7.22827s/10 iters), loss = 10.9674
I0523 22:24:36.702838 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9674 (* 1 = 10.9674 loss)
I0523 22:24:36.702849 11654 sgd_solver.cpp:112] Iteration 2530, lr = 0.1
I0523 22:24:45.661224 11654 solver.cpp:239] Iteration 2540 (1.11632 iter/s, 8.95797s/10 iters), loss = 10.5169
I0523 22:24:45.661267 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5169 (* 1 = 10.5169 loss)
I0523 22:24:45.661761 11654 sgd_solver.cpp:112] Iteration 2540, lr = 0.1
I0523 22:24:53.508599 11654 solver.cpp:239] Iteration 2550 (1.27437 iter/s, 7.84702s/10 iters), loss = 10.7583
I0523 22:24:53.508643 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7583 (* 1 = 10.7583 loss)
I0523 22:24:53.508657 11654 sgd_solver.cpp:112] Iteration 2550, lr = 0.1
I0523 22:25:01.726066 11654 solver.cpp:239] Iteration 2560 (1.21697 iter/s, 8.21711s/10 iters), loss = 9.97839
I0523 22:25:01.726254 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.97839 (* 1 = 9.97839 loss)
I0523 22:25:01.726413 11654 sgd_solver.cpp:112] Iteration 2560, lr = 0.1
I0523 22:25:09.181279 11654 solver.cpp:239] Iteration 2570 (1.34143 iter/s, 7.45475s/10 iters), loss = 10.5624
I0523 22:25:09.181330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5624 (* 1 = 10.5624 loss)
I0523 22:25:09.181344 11654 sgd_solver.cpp:112] Iteration 2570, lr = 0.1
I0523 22:25:18.186444 11654 solver.cpp:239] Iteration 2580 (1.11053 iter/s, 9.00471s/10 iters), loss = 10.8039
I0523 22:25:18.186488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8039 (* 1 = 10.8039 loss)
I0523 22:25:18.186501 11654 sgd_solver.cpp:112] Iteration 2580, lr = 0.1
I0523 22:25:26.649833 11654 solver.cpp:239] Iteration 2590 (1.18192 iter/s, 8.46079s/10 iters), loss = 10.8099
I0523 22:25:26.649883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8099 (* 1 = 10.8099 loss)
I0523 22:25:26.988781 11654 sgd_solver.cpp:112] Iteration 2590, lr = 0.1
I0523 22:25:33.291555 11654 solver.cpp:239] Iteration 2600 (1.50571 iter/s, 6.64141s/10 iters), loss = 11.2913
I0523 22:25:33.291693 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2913 (* 1 = 11.2913 loss)
I0523 22:25:33.291707 11654 sgd_solver.cpp:112] Iteration 2600, lr = 0.1
I0523 22:25:39.653795 11654 solver.cpp:239] Iteration 2610 (1.57202 iter/s, 6.36123s/10 iters), loss = 10.4667
I0523 22:25:39.653836 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4667 (* 1 = 10.4667 loss)
I0523 22:25:39.654247 11654 sgd_solver.cpp:112] Iteration 2610, lr = 0.1
I0523 22:25:46.161507 11654 solver.cpp:239] Iteration 2620 (1.53671 iter/s, 6.50742s/10 iters), loss = 11.15
I0523 22:25:46.161551 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.15 (* 1 = 11.15 loss)
I0523 22:25:46.161686 11654 sgd_solver.cpp:112] Iteration 2620, lr = 0.1
I0523 22:25:55.201764 11654 solver.cpp:239] Iteration 2630 (1.10621 iter/s, 9.03987s/10 iters), loss = 10.3691
I0523 22:25:55.201812 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3691 (* 1 = 10.3691 loss)
I0523 22:25:55.928676 11654 sgd_solver.cpp:112] Iteration 2630, lr = 0.1
I0523 22:26:02.492933 11654 solver.cpp:239] Iteration 2640 (1.37158 iter/s, 7.29084s/10 iters), loss = 11.2561
I0523 22:26:02.492976 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2561 (* 1 = 11.2561 loss)
I0523 22:26:03.491645 11654 sgd_solver.cpp:112] Iteration 2640, lr = 0.1
I0523 22:26:10.646924 11654 solver.cpp:239] Iteration 2650 (1.22645 iter/s, 8.15362s/10 iters), loss = 10.6616
I0523 22:26:10.646991 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6616 (* 1 = 10.6616 loss)
I0523 22:26:10.647164 11654 sgd_solver.cpp:112] Iteration 2650, lr = 0.1
I0523 22:26:16.976008 11654 solver.cpp:239] Iteration 2660 (1.58008 iter/s, 6.32878s/10 iters), loss = 10.6721
I0523 22:26:16.976052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6721 (* 1 = 10.6721 loss)
I0523 22:26:16.976279 11654 sgd_solver.cpp:112] Iteration 2660, lr = 0.1
I0523 22:26:25.289844 11654 solver.cpp:239] Iteration 2670 (1.20287 iter/s, 8.31347s/10 iters), loss = 11.0714
I0523 22:26:25.289889 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0714 (* 1 = 11.0714 loss)
I0523 22:26:26.014068 11654 sgd_solver.cpp:112] Iteration 2670, lr = 0.1
I0523 22:26:33.650621 11654 solver.cpp:239] Iteration 2680 (1.19611 iter/s, 8.3604s/10 iters), loss = 10.7006
I0523 22:26:33.650804 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7006 (* 1 = 10.7006 loss)
I0523 22:26:33.651217 11654 sgd_solver.cpp:112] Iteration 2680, lr = 0.1
I0523 22:26:40.129377 11654 solver.cpp:239] Iteration 2690 (1.5436 iter/s, 6.47834s/10 iters), loss = 11.1805
I0523 22:26:40.129431 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1805 (* 1 = 11.1805 loss)
I0523 22:26:40.129858 11654 sgd_solver.cpp:112] Iteration 2690, lr = 0.1
I0523 22:26:47.178725 11654 solver.cpp:239] Iteration 2700 (1.41864 iter/s, 7.04901s/10 iters), loss = 10.6498
I0523 22:26:47.178767 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6498 (* 1 = 10.6498 loss)
I0523 22:26:47.178947 11654 sgd_solver.cpp:112] Iteration 2700, lr = 0.1
I0523 22:26:53.578586 11654 solver.cpp:239] Iteration 2710 (1.5626 iter/s, 6.39958s/10 iters), loss = 11.2843
I0523 22:26:53.578620 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2843 (* 1 = 11.2843 loss)
I0523 22:26:53.578676 11654 sgd_solver.cpp:112] Iteration 2710, lr = 0.1
I0523 22:27:01.188706 11654 solver.cpp:239] Iteration 2720 (1.3141 iter/s, 7.60978s/10 iters), loss = 11.2444
I0523 22:27:01.188751 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2444 (* 1 = 11.2444 loss)
I0523 22:27:01.189316 11654 sgd_solver.cpp:112] Iteration 2720, lr = 0.1
I0523 22:27:07.879012 11654 solver.cpp:239] Iteration 2730 (1.49477 iter/s, 6.69s/10 iters), loss = 10.8512
I0523 22:27:07.879274 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8512 (* 1 = 10.8512 loss)
I0523 22:27:07.879331 11654 sgd_solver.cpp:112] Iteration 2730, lr = 0.1
I0523 22:27:15.055814 11654 solver.cpp:239] Iteration 2740 (1.39348 iter/s, 7.1763s/10 iters), loss = 11.1005
I0523 22:27:15.055857 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1005 (* 1 = 11.1005 loss)
I0523 22:27:15.055871 11654 sgd_solver.cpp:112] Iteration 2740, lr = 0.1
I0523 22:27:22.784271 11654 solver.cpp:239] Iteration 2750 (1.29435 iter/s, 7.72589s/10 iters), loss = 10.9492
I0523 22:27:22.784322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9492 (* 1 = 10.9492 loss)
I0523 22:27:22.784765 11654 sgd_solver.cpp:112] Iteration 2750, lr = 0.1
I0523 22:27:29.401232 11654 solver.cpp:239] Iteration 2760 (1.51134 iter/s, 6.61664s/10 iters), loss = 10.4901
I0523 22:27:29.401288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4901 (* 1 = 10.4901 loss)
I0523 22:27:29.401607 11654 sgd_solver.cpp:112] Iteration 2760, lr = 0.1
I0523 22:27:37.075099 11654 solver.cpp:239] Iteration 2770 (1.30318 iter/s, 7.67352s/10 iters), loss = 10.948
I0523 22:27:37.075155 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.948 (* 1 = 10.948 loss)
I0523 22:27:37.075183 11654 sgd_solver.cpp:112] Iteration 2770, lr = 0.1
I0523 22:27:45.493934 11654 solver.cpp:239] Iteration 2780 (1.18787 iter/s, 8.41846s/10 iters), loss = 10.8335
I0523 22:27:45.494016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8335 (* 1 = 10.8335 loss)
I0523 22:27:45.494031 11654 sgd_solver.cpp:112] Iteration 2780, lr = 0.1
I0523 22:27:51.669251 11654 solver.cpp:239] Iteration 2790 (1.61944 iter/s, 6.17499s/10 iters), loss = 10.6285
I0523 22:27:51.669294 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6285 (* 1 = 10.6285 loss)
I0523 22:27:51.669404 11654 sgd_solver.cpp:112] Iteration 2790, lr = 0.1
I0523 22:27:57.923456 11654 solver.cpp:239] Iteration 2800 (1.599 iter/s, 6.25392s/10 iters), loss = 10.6936
I0523 22:27:57.923501 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6936 (* 1 = 10.6936 loss)
I0523 22:27:57.923743 11654 sgd_solver.cpp:112] Iteration 2800, lr = 0.1
I0523 22:28:04.482029 11654 solver.cpp:239] Iteration 2810 (1.52479 iter/s, 6.55828s/10 iters), loss = 10.8239
I0523 22:28:04.482064 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8239 (* 1 = 10.8239 loss)
I0523 22:28:04.482252 11654 sgd_solver.cpp:112] Iteration 2810, lr = 0.1
I0523 22:28:12.613221 11654 solver.cpp:239] Iteration 2820 (1.22988 iter/s, 8.13085s/10 iters), loss = 10.7482
I0523 22:28:12.613261 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7482 (* 1 = 10.7482 loss)
I0523 22:28:12.613273 11654 sgd_solver.cpp:112] Iteration 2820, lr = 0.1
I0523 22:28:20.608773 11654 solver.cpp:239] Iteration 2830 (1.2511 iter/s, 7.99297s/10 iters), loss = 10.5231
I0523 22:28:20.608929 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5231 (* 1 = 10.5231 loss)
I0523 22:28:20.608958 11654 sgd_solver.cpp:112] Iteration 2830, lr = 0.1
I0523 22:28:27.337476 11654 solver.cpp:239] Iteration 2840 (1.48627 iter/s, 6.72826s/10 iters), loss = 10.7566
I0523 22:28:27.337517 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7566 (* 1 = 10.7566 loss)
I0523 22:28:27.337529 11654 sgd_solver.cpp:112] Iteration 2840, lr = 0.1
I0523 22:28:34.351307 11654 solver.cpp:239] Iteration 2850 (1.42584 iter/s, 7.01341s/10 iters), loss = 11.1219
I0523 22:28:34.351352 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1219 (* 1 = 11.1219 loss)
I0523 22:28:34.351482 11654 sgd_solver.cpp:112] Iteration 2850, lr = 0.1
I0523 22:28:40.956300 11654 solver.cpp:239] Iteration 2860 (1.51408 iter/s, 6.60469s/10 iters), loss = 10.6311
I0523 22:28:40.956344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6311 (* 1 = 10.6311 loss)
I0523 22:28:40.956729 11654 sgd_solver.cpp:112] Iteration 2860, lr = 0.1
I0523 22:28:48.033764 11654 solver.cpp:239] Iteration 2870 (1.413 iter/s, 7.07715s/10 iters), loss = 10.9126
I0523 22:28:48.033807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9126 (* 1 = 10.9126 loss)
I0523 22:28:48.034010 11654 sgd_solver.cpp:112] Iteration 2870, lr = 0.1
I0523 22:28:54.396679 11654 solver.cpp:239] Iteration 2880 (1.57168 iter/s, 6.36263s/10 iters), loss = 11.3791
I0523 22:28:54.396883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3791 (* 1 = 11.3791 loss)
I0523 22:28:54.396924 11654 sgd_solver.cpp:112] Iteration 2880, lr = 0.1
I0523 22:29:02.070822 11654 solver.cpp:239] Iteration 2890 (1.30316 iter/s, 7.67363s/10 iters), loss = 10.961
I0523 22:29:02.070884 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.961 (* 1 = 10.961 loss)
I0523 22:29:02.075721 11654 sgd_solver.cpp:112] Iteration 2890, lr = 0.1
I0523 22:29:10.045506 11654 solver.cpp:239] Iteration 2900 (1.25403 iter/s, 7.97431s/10 iters), loss = 11.1742
I0523 22:29:10.045559 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1742 (* 1 = 11.1742 loss)
I0523 22:29:10.045619 11654 sgd_solver.cpp:112] Iteration 2900, lr = 0.1
I0523 22:29:16.252723 11654 solver.cpp:239] Iteration 2910 (1.6111 iter/s, 6.20693s/10 iters), loss = 10.8014
I0523 22:29:16.252768 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8014 (* 1 = 10.8014 loss)
I0523 22:29:16.253152 11654 sgd_solver.cpp:112] Iteration 2910, lr = 0.1
I0523 22:29:23.163247 11654 solver.cpp:239] Iteration 2920 (1.44713 iter/s, 6.91022s/10 iters), loss = 10.5314
I0523 22:29:23.163293 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5314 (* 1 = 10.5314 loss)
I0523 22:29:23.392462 11654 sgd_solver.cpp:112] Iteration 2920, lr = 0.1
I0523 22:29:30.311198 11654 solver.cpp:239] Iteration 2930 (1.39906 iter/s, 7.14763s/10 iters), loss = 10.7139
I0523 22:29:30.311400 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7139 (* 1 = 10.7139 loss)
I0523 22:29:30.311812 11654 sgd_solver.cpp:112] Iteration 2930, lr = 0.1
I0523 22:29:39.119202 11654 solver.cpp:239] Iteration 2940 (1.1354 iter/s, 8.8075s/10 iters), loss = 10.5776
I0523 22:29:39.119247 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5776 (* 1 = 10.5776 loss)
I0523 22:29:39.124048 11654 sgd_solver.cpp:112] Iteration 2940, lr = 0.1
I0523 22:29:45.717118 11654 solver.cpp:239] Iteration 2950 (1.5157 iter/s, 6.59762s/10 iters), loss = 10.1504
I0523 22:29:45.717154 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1504 (* 1 = 10.1504 loss)
I0523 22:29:46.152794 11654 sgd_solver.cpp:112] Iteration 2950, lr = 0.1
I0523 22:29:53.001288 11654 solver.cpp:239] Iteration 2960 (1.3729 iter/s, 7.28385s/10 iters), loss = 11.5382
I0523 22:29:53.001338 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5382 (* 1 = 11.5382 loss)
I0523 22:29:53.001579 11654 sgd_solver.cpp:112] Iteration 2960, lr = 0.1
I0523 22:30:01.547799 11654 solver.cpp:239] Iteration 2970 (1.17012 iter/s, 8.54614s/10 iters), loss = 10.8456
I0523 22:30:01.548076 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8456 (* 1 = 10.8456 loss)
I0523 22:30:01.548126 11654 sgd_solver.cpp:112] Iteration 2970, lr = 0.1
I0523 22:30:09.699652 11654 solver.cpp:239] Iteration 2980 (1.2268 iter/s, 8.15127s/10 iters), loss = 10.5376
I0523 22:30:09.699698 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5376 (* 1 = 10.5376 loss)
I0523 22:30:10.613636 11654 sgd_solver.cpp:112] Iteration 2980, lr = 0.1
I0523 22:30:19.947582 11654 solver.cpp:239] Iteration 2990 (0.975848 iter/s, 10.2475s/10 iters), loss = 10.6603
I0523 22:30:19.947625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6603 (* 1 = 10.6603 loss)
I0523 22:30:20.973800 11654 sgd_solver.cpp:112] Iteration 2990, lr = 0.1
I0523 22:30:28.093968 11654 solver.cpp:239] Iteration 3000 (1.22759 iter/s, 8.14602s/10 iters), loss = 10.9379
I0523 22:30:28.094018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9379 (* 1 = 10.9379 loss)
I0523 22:30:28.094379 11654 sgd_solver.cpp:112] Iteration 3000, lr = 0.1
I0523 22:30:34.882825 11654 solver.cpp:239] Iteration 3010 (1.47307 iter/s, 6.78855s/10 iters), loss = 10.4103
I0523 22:30:34.883056 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4103 (* 1 = 10.4103 loss)
I0523 22:30:34.883098 11654 sgd_solver.cpp:112] Iteration 3010, lr = 0.1
I0523 22:30:42.882228 11654 solver.cpp:239] Iteration 3020 (1.25018 iter/s, 7.99887s/10 iters), loss = 10.9338
I0523 22:30:42.882263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9338 (* 1 = 10.9338 loss)
I0523 22:30:42.882284 11654 sgd_solver.cpp:112] Iteration 3020, lr = 0.1
I0523 22:30:50.576733 11654 solver.cpp:239] Iteration 3030 (1.29969 iter/s, 7.69417s/10 iters), loss = 10.13
I0523 22:30:50.576781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.13 (* 1 = 10.13 loss)
I0523 22:30:51.350869 11654 sgd_solver.cpp:112] Iteration 3030, lr = 0.1
I0523 22:30:58.815546 11654 solver.cpp:239] Iteration 3040 (1.21382 iter/s, 8.23845s/10 iters), loss = 10.4812
I0523 22:30:58.815583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4812 (* 1 = 10.4812 loss)
I0523 22:30:58.815599 11654 sgd_solver.cpp:112] Iteration 3040, lr = 0.1
I0523 22:31:07.183645 11654 solver.cpp:239] Iteration 3050 (1.19507 iter/s, 8.36774s/10 iters), loss = 10.1637
I0523 22:31:07.183773 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1637 (* 1 = 10.1637 loss)
I0523 22:31:07.937110 11654 sgd_solver.cpp:112] Iteration 3050, lr = 0.1
I0523 22:31:15.493521 11654 solver.cpp:239] Iteration 3060 (1.20345 iter/s, 8.30943s/10 iters), loss = 10.6635
I0523 22:31:15.493569 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6635 (* 1 = 10.6635 loss)
I0523 22:31:15.493585 11654 sgd_solver.cpp:112] Iteration 3060, lr = 0.1
I0523 22:31:24.450829 11654 solver.cpp:239] Iteration 3070 (1.11673 iter/s, 8.95473s/10 iters), loss = 10.8662
I0523 22:31:24.450881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8662 (* 1 = 10.8662 loss)
I0523 22:31:25.276270 11654 sgd_solver.cpp:112] Iteration 3070, lr = 0.1
I0523 22:31:33.654147 11654 solver.cpp:239] Iteration 3080 (1.08661 iter/s, 9.20292s/10 iters), loss = 10.9815
I0523 22:31:33.654187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9815 (* 1 = 10.9815 loss)
I0523 22:31:33.718581 11654 sgd_solver.cpp:112] Iteration 3080, lr = 0.1
I0523 22:31:40.655858 11654 solver.cpp:239] Iteration 3090 (1.42829 iter/s, 7.00139s/10 iters), loss = 11.0064
I0523 22:31:40.656046 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0064 (* 1 = 11.0064 loss)
I0523 22:31:40.656399 11654 sgd_solver.cpp:112] Iteration 3090, lr = 0.1
I0523 22:31:49.443686 11654 solver.cpp:239] Iteration 3100 (1.138 iter/s, 8.78734s/10 iters), loss = 11.1198
I0523 22:31:49.443737 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1198 (* 1 = 11.1198 loss)
I0523 22:31:50.140637 11654 sgd_solver.cpp:112] Iteration 3100, lr = 0.1
I0523 22:31:57.708767 11654 solver.cpp:239] Iteration 3110 (1.20996 iter/s, 8.26472s/10 iters), loss = 10.8849
I0523 22:31:57.708811 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8849 (* 1 = 10.8849 loss)
I0523 22:31:57.708822 11654 sgd_solver.cpp:112] Iteration 3110, lr = 0.1
I0523 22:32:05.059854 11654 solver.cpp:239] Iteration 3120 (1.36061 iter/s, 7.34966s/10 iters), loss = 10.7517
I0523 22:32:05.059890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7517 (* 1 = 10.7517 loss)
I0523 22:32:05.059903 11654 sgd_solver.cpp:112] Iteration 3120, lr = 0.1
I0523 22:32:13.097611 11654 solver.cpp:239] Iteration 3130 (1.24418 iter/s, 8.03741s/10 iters), loss = 10.7107
I0523 22:32:13.097882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7107 (* 1 = 10.7107 loss)
I0523 22:32:13.454793 11654 sgd_solver.cpp:112] Iteration 3130, lr = 0.1
I0523 22:32:19.843595 11654 solver.cpp:239] Iteration 3140 (1.48247 iter/s, 6.74549s/10 iters), loss = 11.2056
I0523 22:32:19.843639 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2056 (* 1 = 11.2056 loss)
I0523 22:32:19.843816 11654 sgd_solver.cpp:112] Iteration 3140, lr = 0.1
I0523 22:32:25.983286 11654 solver.cpp:239] Iteration 3150 (1.62882 iter/s, 6.13941s/10 iters), loss = 11.458
I0523 22:32:25.983332 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.458 (* 1 = 11.458 loss)
I0523 22:32:25.983355 11654 sgd_solver.cpp:112] Iteration 3150, lr = 0.1
I0523 22:32:33.442265 11654 solver.cpp:239] Iteration 3160 (1.34073 iter/s, 7.45864s/10 iters), loss = 10.4207
I0523 22:32:33.442311 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4207 (* 1 = 10.4207 loss)
I0523 22:32:33.442322 11654 sgd_solver.cpp:112] Iteration 3160, lr = 0.1
I0523 22:32:40.271934 11654 solver.cpp:239] Iteration 3170 (1.46473 iter/s, 6.8272s/10 iters), loss = 10.9895
I0523 22:32:40.271984 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9895 (* 1 = 10.9895 loss)
I0523 22:32:40.273859 11654 sgd_solver.cpp:112] Iteration 3170, lr = 0.1
I0523 22:32:48.489797 11654 solver.cpp:239] Iteration 3180 (1.21692 iter/s, 8.21748s/10 iters), loss = 11.1055
I0523 22:32:48.489890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1055 (* 1 = 11.1055 loss)
I0523 22:32:48.642573 11654 sgd_solver.cpp:112] Iteration 3180, lr = 0.1
I0523 22:32:56.377367 11654 solver.cpp:239] Iteration 3190 (1.26788 iter/s, 7.88717s/10 iters), loss = 10.9906
I0523 22:32:56.377409 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9906 (* 1 = 10.9906 loss)
I0523 22:32:56.377420 11654 sgd_solver.cpp:112] Iteration 3190, lr = 0.1
I0523 22:33:02.694206 11654 solver.cpp:239] Iteration 3200 (1.58314 iter/s, 6.31655s/10 iters), loss = 11.7003
I0523 22:33:02.694250 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.7003 (* 1 = 11.7003 loss)
I0523 22:33:02.696215 11654 sgd_solver.cpp:112] Iteration 3200, lr = 0.1
I0523 22:33:10.023186 11654 solver.cpp:239] Iteration 3210 (1.36451 iter/s, 7.32865s/10 iters), loss = 10.6674
I0523 22:33:10.023234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6674 (* 1 = 10.6674 loss)
I0523 22:33:10.023250 11654 sgd_solver.cpp:112] Iteration 3210, lr = 0.1
I0523 22:33:18.383299 11654 solver.cpp:239] Iteration 3220 (1.19653 iter/s, 8.35752s/10 iters), loss = 11.4157
I0523 22:33:18.383339 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4157 (* 1 = 11.4157 loss)
I0523 22:33:18.386809 11654 sgd_solver.cpp:112] Iteration 3220, lr = 0.1
I0523 22:33:24.787690 11654 solver.cpp:239] Iteration 3230 (1.5615 iter/s, 6.4041s/10 iters), loss = 10.3891
I0523 22:33:24.787961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3891 (* 1 = 10.3891 loss)
I0523 22:33:24.788017 11654 sgd_solver.cpp:112] Iteration 3230, lr = 0.1
I0523 22:33:30.828774 11654 solver.cpp:239] Iteration 3240 (1.65546 iter/s, 6.04061s/10 iters), loss = 10.0817
I0523 22:33:30.828840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0817 (* 1 = 10.0817 loss)
I0523 22:33:30.828867 11654 sgd_solver.cpp:112] Iteration 3240, lr = 0.1
I0523 22:33:38.327055 11654 solver.cpp:239] Iteration 3250 (1.33409 iter/s, 7.49572s/10 iters), loss = 10.8696
I0523 22:33:38.327105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8696 (* 1 = 10.8696 loss)
I0523 22:33:38.327178 11654 sgd_solver.cpp:112] Iteration 3250, lr = 0.1
I0523 22:33:45.823911 11654 solver.cpp:239] Iteration 3260 (1.33395 iter/s, 7.49652s/10 iters), loss = 11.0796
I0523 22:33:45.823949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0796 (* 1 = 11.0796 loss)
I0523 22:33:45.823961 11654 sgd_solver.cpp:112] Iteration 3260, lr = 0.1
I0523 22:33:53.181911 11654 solver.cpp:239] Iteration 3270 (1.35954 iter/s, 7.35545s/10 iters), loss = 10.7564
I0523 22:33:53.181957 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7564 (* 1 = 10.7564 loss)
I0523 22:33:53.592929 11654 sgd_solver.cpp:112] Iteration 3270, lr = 0.1
I0523 22:34:02.929767 11654 solver.cpp:239] Iteration 3280 (1.02591 iter/s, 9.74744s/10 iters), loss = 11.3228
I0523 22:34:02.930008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3228 (* 1 = 11.3228 loss)
I0523 22:34:02.930048 11654 sgd_solver.cpp:112] Iteration 3280, lr = 0.1
I0523 22:34:10.268699 11654 solver.cpp:239] Iteration 3290 (1.36306 iter/s, 7.33644s/10 iters), loss = 11.6029
I0523 22:34:10.268762 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.6029 (* 1 = 11.6029 loss)
I0523 22:34:10.268939 11654 sgd_solver.cpp:112] Iteration 3290, lr = 0.1
I0523 22:34:16.968432 11654 solver.cpp:239] Iteration 3300 (1.49267 iter/s, 6.69941s/10 iters), loss = 10.2678
I0523 22:34:16.968480 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2678 (* 1 = 10.2678 loss)
I0523 22:34:16.968725 11654 sgd_solver.cpp:112] Iteration 3300, lr = 0.1
I0523 22:34:26.265746 11654 solver.cpp:239] Iteration 3310 (1.07563 iter/s, 9.29691s/10 iters), loss = 10.1747
I0523 22:34:26.265786 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1747 (* 1 = 10.1747 loss)
I0523 22:34:26.267215 11654 sgd_solver.cpp:112] Iteration 3310, lr = 0.1
I0523 22:34:32.667093 11654 solver.cpp:239] Iteration 3320 (1.56224 iter/s, 6.40106s/10 iters), loss = 10.8348
I0523 22:34:32.667142 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8348 (* 1 = 10.8348 loss)
I0523 22:34:32.680085 11654 sgd_solver.cpp:112] Iteration 3320, lr = 0.1
I0523 22:34:38.805598 11654 solver.cpp:239] Iteration 3330 (1.62913 iter/s, 6.13823s/10 iters), loss = 10.4513
I0523 22:34:38.805737 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4513 (* 1 = 10.4513 loss)
I0523 22:34:38.805749 11654 sgd_solver.cpp:112] Iteration 3330, lr = 0.1
I0523 22:34:47.759299 11654 solver.cpp:239] Iteration 3340 (1.11692 iter/s, 8.95319s/10 iters), loss = 10.305
I0523 22:34:47.759343 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.305 (* 1 = 10.305 loss)
I0523 22:34:47.759356 11654 sgd_solver.cpp:112] Iteration 3340, lr = 0.1
I0523 22:34:53.995570 11654 solver.cpp:239] Iteration 3350 (1.60416 iter/s, 6.23378s/10 iters), loss = 10.9491
I0523 22:34:53.995606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9491 (* 1 = 10.9491 loss)
I0523 22:34:54.784842 11654 sgd_solver.cpp:112] Iteration 3350, lr = 0.1
I0523 22:35:01.788302 11654 solver.cpp:239] Iteration 3360 (1.2833 iter/s, 7.79239s/10 iters), loss = 10.7292
I0523 22:35:01.788348 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7292 (* 1 = 10.7292 loss)
I0523 22:35:01.788547 11654 sgd_solver.cpp:112] Iteration 3360, lr = 0.1
I0523 22:35:08.353446 11654 solver.cpp:239] Iteration 3370 (1.52327 iter/s, 6.56484s/10 iters), loss = 10.9065
I0523 22:35:08.353492 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9065 (* 1 = 10.9065 loss)
I0523 22:35:08.353649 11654 sgd_solver.cpp:112] Iteration 3370, lr = 0.1
I0523 22:35:15.254060 11654 solver.cpp:239] Iteration 3380 (1.45 iter/s, 6.89657s/10 iters), loss = 10.5399
I0523 22:35:15.254371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5399 (* 1 = 10.5399 loss)
I0523 22:35:15.254421 11654 sgd_solver.cpp:112] Iteration 3380, lr = 0.1
I0523 22:35:21.469862 11654 solver.cpp:239] Iteration 3390 (1.60931 iter/s, 6.21384s/10 iters), loss = 11.2437
I0523 22:35:21.469902 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2437 (* 1 = 11.2437 loss)
I0523 22:35:21.469915 11654 sgd_solver.cpp:112] Iteration 3390, lr = 0.1
I0523 22:35:28.701251 11654 solver.cpp:239] Iteration 3400 (1.38294 iter/s, 7.23097s/10 iters), loss = 10.4214
I0523 22:35:28.701292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4214 (* 1 = 10.4214 loss)
I0523 22:35:28.702776 11654 sgd_solver.cpp:112] Iteration 3400, lr = 0.1
I0523 22:35:37.197824 11654 solver.cpp:239] Iteration 3410 (1.177 iter/s, 8.49621s/10 iters), loss = 10.3079
I0523 22:35:37.197862 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3079 (* 1 = 10.3079 loss)
I0523 22:35:37.197875 11654 sgd_solver.cpp:112] Iteration 3410, lr = 0.1
I0523 22:35:44.302999 11654 solver.cpp:239] Iteration 3420 (1.40793 iter/s, 7.10261s/10 iters), loss = 11.2999
I0523 22:35:44.303032 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2999 (* 1 = 11.2999 loss)
I0523 22:35:44.373255 11654 sgd_solver.cpp:112] Iteration 3420, lr = 0.1
I0523 22:35:52.049209 11654 solver.cpp:239] Iteration 3430 (1.29101 iter/s, 7.74587s/10 iters), loss = 11.4419
I0523 22:35:52.049477 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4419 (* 1 = 11.4419 loss)
I0523 22:35:52.848662 11654 sgd_solver.cpp:112] Iteration 3430, lr = 0.1
I0523 22:36:01.954926 11654 solver.cpp:239] Iteration 3440 (1.00958 iter/s, 9.90511s/10 iters), loss = 10.1339
I0523 22:36:01.954970 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1339 (* 1 = 10.1339 loss)
I0523 22:36:01.955329 11654 sgd_solver.cpp:112] Iteration 3440, lr = 0.1
I0523 22:36:08.466786 11654 solver.cpp:239] Iteration 3450 (1.53573 iter/s, 6.51156s/10 iters), loss = 11.4112
I0523 22:36:08.466831 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4112 (* 1 = 11.4112 loss)
I0523 22:36:08.748198 11654 sgd_solver.cpp:112] Iteration 3450, lr = 0.1
I0523 22:36:16.467083 11654 solver.cpp:239] Iteration 3460 (1.25001 iter/s, 7.99994s/10 iters), loss = 11.3293
I0523 22:36:16.467133 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3293 (* 1 = 11.3293 loss)
I0523 22:36:16.484014 11654 sgd_solver.cpp:112] Iteration 3460, lr = 0.1
I0523 22:36:22.900405 11654 solver.cpp:239] Iteration 3470 (1.55448 iter/s, 6.43303s/10 iters), loss = 10.9697
I0523 22:36:22.900638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9697 (* 1 = 10.9697 loss)
I0523 22:36:22.900687 11654 sgd_solver.cpp:112] Iteration 3470, lr = 0.1
I0523 22:36:29.068141 11654 solver.cpp:239] Iteration 3480 (1.62147 iter/s, 6.16726s/10 iters), loss = 10.8522
I0523 22:36:29.068192 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8522 (* 1 = 10.8522 loss)
I0523 22:36:29.468585 11654 sgd_solver.cpp:112] Iteration 3480, lr = 0.1
I0523 22:36:36.161360 11654 solver.cpp:239] Iteration 3490 (1.40986 iter/s, 7.09289s/10 iters), loss = 10.2806
I0523 22:36:36.161401 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2806 (* 1 = 10.2806 loss)
I0523 22:36:36.161413 11654 sgd_solver.cpp:112] Iteration 3490, lr = 0.1
I0523 22:36:44.021370 11654 solver.cpp:239] Iteration 3500 (1.27246 iter/s, 7.8588s/10 iters), loss = 11.2121
I0523 22:36:44.021414 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2121 (* 1 = 11.2121 loss)
I0523 22:36:44.625782 11654 sgd_solver.cpp:112] Iteration 3500, lr = 0.1
I0523 22:36:50.871887 11654 solver.cpp:239] Iteration 3510 (1.45981 iter/s, 6.85021s/10 iters), loss = 9.97458
I0523 22:36:50.871922 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.97458 (* 1 = 9.97458 loss)
I0523 22:36:50.872056 11654 sgd_solver.cpp:112] Iteration 3510, lr = 0.1
I0523 22:36:58.423125 11654 solver.cpp:239] Iteration 3520 (1.32434 iter/s, 7.5509s/10 iters), loss = 10.8697
I0523 22:36:58.423264 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8697 (* 1 = 10.8697 loss)
I0523 22:36:58.444114 11654 sgd_solver.cpp:112] Iteration 3520, lr = 0.1
I0523 22:37:05.960983 11654 solver.cpp:239] Iteration 3530 (1.32671 iter/s, 7.53743s/10 iters), loss = 10.8311
I0523 22:37:05.961026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8311 (* 1 = 10.8311 loss)
I0523 22:37:06.436980 11654 sgd_solver.cpp:112] Iteration 3530, lr = 0.1
I0523 22:37:12.769346 11654 solver.cpp:239] Iteration 3540 (1.46885 iter/s, 6.80805s/10 iters), loss = 10.7467
I0523 22:37:12.769390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7467 (* 1 = 10.7467 loss)
I0523 22:37:13.093894 11654 sgd_solver.cpp:112] Iteration 3540, lr = 0.1
I0523 22:37:20.001943 11654 solver.cpp:239] Iteration 3550 (1.38269 iter/s, 7.23226s/10 iters), loss = 11.1214
I0523 22:37:20.002022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1214 (* 1 = 11.1214 loss)
I0523 22:37:20.002187 11654 sgd_solver.cpp:112] Iteration 3550, lr = 0.1
I0523 22:37:26.421461 11654 solver.cpp:239] Iteration 3560 (1.55783 iter/s, 6.4192s/10 iters), loss = 11.0279
I0523 22:37:26.421509 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0279 (* 1 = 11.0279 loss)
I0523 22:37:26.421839 11654 sgd_solver.cpp:112] Iteration 3560, lr = 0.1
I0523 22:37:33.332468 11654 solver.cpp:239] Iteration 3570 (1.44703 iter/s, 6.91069s/10 iters), loss = 10.8901
I0523 22:37:33.332737 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8901 (* 1 = 10.8901 loss)
I0523 22:37:33.332792 11654 sgd_solver.cpp:112] Iteration 3570, lr = 0.1
I0523 22:37:40.668542 11654 solver.cpp:239] Iteration 3580 (1.36333 iter/s, 7.33496s/10 iters), loss = 10.3929
I0523 22:37:40.668587 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3929 (* 1 = 10.3929 loss)
I0523 22:37:40.668620 11654 sgd_solver.cpp:112] Iteration 3580, lr = 0.1
I0523 22:37:49.409454 11654 solver.cpp:239] Iteration 3590 (1.14409 iter/s, 8.74054s/10 iters), loss = 10.8008
I0523 22:37:49.409513 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8008 (* 1 = 10.8008 loss)
I0523 22:37:49.409526 11654 sgd_solver.cpp:112] Iteration 3590, lr = 0.1
I0523 22:37:57.716733 11654 solver.cpp:239] Iteration 3600 (1.20381 iter/s, 8.30692s/10 iters), loss = 11.1657
I0523 22:37:57.716773 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1657 (* 1 = 11.1657 loss)
I0523 22:37:57.716786 11654 sgd_solver.cpp:112] Iteration 3600, lr = 0.1
I0523 22:38:05.500077 11654 solver.cpp:239] Iteration 3610 (1.28522 iter/s, 7.78078s/10 iters), loss = 10.374
I0523 22:38:05.500200 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.374 (* 1 = 10.374 loss)
I0523 22:38:05.715687 11654 sgd_solver.cpp:112] Iteration 3610, lr = 0.1
I0523 22:38:12.935829 11654 solver.cpp:239] Iteration 3620 (1.34493 iter/s, 7.43535s/10 iters), loss = 10.8572
I0523 22:38:12.935871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8572 (* 1 = 10.8572 loss)
I0523 22:38:12.935884 11654 sgd_solver.cpp:112] Iteration 3620, lr = 0.1
I0523 22:38:19.942006 11654 solver.cpp:239] Iteration 3630 (1.42783 iter/s, 7.00362s/10 iters), loss = 10.9467
I0523 22:38:19.942051 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9467 (* 1 = 10.9467 loss)
I0523 22:38:19.942150 11654 sgd_solver.cpp:112] Iteration 3630, lr = 0.1
I0523 22:38:27.111531 11654 solver.cpp:239] Iteration 3640 (1.39486 iter/s, 7.1692s/10 iters), loss = 11.2036
I0523 22:38:27.111572 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2036 (* 1 = 11.2036 loss)
I0523 22:38:27.124091 11654 sgd_solver.cpp:112] Iteration 3640, lr = 0.1
I0523 22:38:35.990983 11654 solver.cpp:239] Iteration 3650 (1.12624 iter/s, 8.87907s/10 iters), loss = 11.0815
I0523 22:38:35.991255 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0815 (* 1 = 11.0815 loss)
I0523 22:38:35.991303 11654 sgd_solver.cpp:112] Iteration 3650, lr = 0.1
I0523 22:38:42.611706 11654 solver.cpp:239] Iteration 3660 (1.51053 iter/s, 6.62019s/10 iters), loss = 10.6461
I0523 22:38:42.611755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6461 (* 1 = 10.6461 loss)
I0523 22:38:42.611832 11654 sgd_solver.cpp:112] Iteration 3660, lr = 0.1
I0523 22:38:48.950976 11654 solver.cpp:239] Iteration 3670 (1.57754 iter/s, 6.33898s/10 iters), loss = 11.7478
I0523 22:38:48.951022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.7478 (* 1 = 11.7478 loss)
I0523 22:38:48.951037 11654 sgd_solver.cpp:112] Iteration 3670, lr = 0.1
I0523 22:38:56.931247 11654 solver.cpp:239] Iteration 3680 (1.2535 iter/s, 7.97769s/10 iters), loss = 11.4866
I0523 22:38:56.931282 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4866 (* 1 = 11.4866 loss)
I0523 22:38:56.941882 11654 sgd_solver.cpp:112] Iteration 3680, lr = 0.1
I0523 22:39:05.333099 11654 solver.cpp:239] Iteration 3690 (1.19027 iter/s, 8.40149s/10 iters), loss = 11.8369
I0523 22:39:05.333142 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.8369 (* 1 = 11.8369 loss)
I0523 22:39:06.262554 11654 sgd_solver.cpp:112] Iteration 3690, lr = 0.1
I0523 22:39:12.498775 11654 solver.cpp:239] Iteration 3700 (1.3956 iter/s, 7.16536s/10 iters), loss = 10.6814
I0523 22:39:12.498819 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6814 (* 1 = 10.6814 loss)
I0523 22:39:12.499372 11654 sgd_solver.cpp:112] Iteration 3700, lr = 0.1
I0523 22:39:19.571976 11654 solver.cpp:239] Iteration 3710 (1.41385 iter/s, 7.07288s/10 iters), loss = 10.6912
I0523 22:39:19.572018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6912 (* 1 = 10.6912 loss)
I0523 22:39:19.572556 11654 sgd_solver.cpp:112] Iteration 3710, lr = 0.1
I0523 22:39:27.661356 11654 solver.cpp:239] Iteration 3720 (1.23624 iter/s, 8.08903s/10 iters), loss = 11.068
I0523 22:39:27.661396 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.068 (* 1 = 11.068 loss)
I0523 22:39:28.777254 11654 sgd_solver.cpp:112] Iteration 3720, lr = 0.1
I0523 22:39:37.378247 11654 solver.cpp:239] Iteration 3730 (1.02918 iter/s, 9.71647s/10 iters), loss = 10.6541
I0523 22:39:37.378376 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6541 (* 1 = 10.6541 loss)
I0523 22:39:37.378448 11654 sgd_solver.cpp:112] Iteration 3730, lr = 0.1
I0523 22:39:44.415665 11654 solver.cpp:239] Iteration 3740 (1.42105 iter/s, 7.03703s/10 iters), loss = 11.2658
I0523 22:39:44.415704 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2658 (* 1 = 11.2658 loss)
I0523 22:39:44.611421 11654 sgd_solver.cpp:112] Iteration 3740, lr = 0.1
I0523 22:39:52.617944 11654 solver.cpp:239] Iteration 3750 (1.21923 iter/s, 8.20193s/10 iters), loss = 10.7552
I0523 22:39:52.617988 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7552 (* 1 = 10.7552 loss)
I0523 22:39:52.649004 11654 sgd_solver.cpp:112] Iteration 3750, lr = 0.1
I0523 22:39:59.021317 11654 solver.cpp:239] Iteration 3760 (1.56175 iter/s, 6.40308s/10 iters), loss = 10.7131
I0523 22:39:59.021360 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7131 (* 1 = 10.7131 loss)
I0523 22:39:59.526343 11654 sgd_solver.cpp:112] Iteration 3760, lr = 0.1
I0523 22:40:06.297950 11654 solver.cpp:239] Iteration 3770 (1.37432 iter/s, 7.27631s/10 iters), loss = 10.1734
I0523 22:40:06.297987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1734 (* 1 = 10.1734 loss)
I0523 22:40:06.698283 11654 sgd_solver.cpp:112] Iteration 3770, lr = 0.1
I0523 22:40:13.406919 11654 solver.cpp:239] Iteration 3780 (1.40674 iter/s, 7.10866s/10 iters), loss = 11.715
I0523 22:40:13.407017 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.715 (* 1 = 11.715 loss)
I0523 22:40:13.407032 11654 sgd_solver.cpp:112] Iteration 3780, lr = 0.1
I0523 22:40:20.208091 11654 solver.cpp:239] Iteration 3790 (1.47041 iter/s, 6.8008s/10 iters), loss = 10.7431
I0523 22:40:20.208142 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7431 (* 1 = 10.7431 loss)
I0523 22:40:20.486841 11654 sgd_solver.cpp:112] Iteration 3790, lr = 0.1
I0523 22:40:28.355161 11654 solver.cpp:239] Iteration 3800 (1.22749 iter/s, 8.1467s/10 iters), loss = 11.2476
I0523 22:40:28.355213 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2476 (* 1 = 11.2476 loss)
I0523 22:40:28.355363 11654 sgd_solver.cpp:112] Iteration 3800, lr = 0.1
I0523 22:40:34.845638 11654 solver.cpp:239] Iteration 3810 (1.54079 iter/s, 6.49017s/10 iters), loss = 11.1999
I0523 22:40:34.845690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1999 (* 1 = 11.1999 loss)
I0523 22:40:34.845731 11654 sgd_solver.cpp:112] Iteration 3810, lr = 0.1
I0523 22:40:41.585816 11654 solver.cpp:239] Iteration 3820 (1.48371 iter/s, 6.73988s/10 iters), loss = 10.4202
I0523 22:40:41.585852 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4202 (* 1 = 10.4202 loss)
I0523 22:40:41.585914 11654 sgd_solver.cpp:112] Iteration 3820, lr = 0.1
I0523 22:40:48.196549 11654 solver.cpp:239] Iteration 3830 (1.51281 iter/s, 6.6102s/10 iters), loss = 11.0623
I0523 22:40:48.198575 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0623 (* 1 = 11.0623 loss)
I0523 22:40:48.473800 11654 sgd_solver.cpp:112] Iteration 3830, lr = 0.1
I0523 22:40:54.762084 11654 solver.cpp:239] Iteration 3840 (1.5236 iter/s, 6.56342s/10 iters), loss = 9.99248
I0523 22:40:54.762136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.99248 (* 1 = 9.99248 loss)
I0523 22:40:54.764088 11654 sgd_solver.cpp:112] Iteration 3840, lr = 0.1
I0523 22:41:02.884748 11654 solver.cpp:239] Iteration 3850 (1.23118 iter/s, 8.12231s/10 iters), loss = 10.2832
I0523 22:41:02.884783 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2832 (* 1 = 10.2832 loss)
I0523 22:41:03.077090 11654 sgd_solver.cpp:112] Iteration 3850, lr = 0.1
I0523 22:41:11.069046 11654 solver.cpp:239] Iteration 3860 (1.22191 iter/s, 8.18394s/10 iters), loss = 10.9781
I0523 22:41:11.069093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9781 (* 1 = 10.9781 loss)
I0523 22:41:12.318663 11654 sgd_solver.cpp:112] Iteration 3860, lr = 0.1
I0523 22:41:20.645352 11654 solver.cpp:239] Iteration 3870 (1.04429 iter/s, 9.57589s/10 iters), loss = 10.0844
I0523 22:41:20.645576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0844 (* 1 = 10.0844 loss)
I0523 22:41:20.645622 11654 sgd_solver.cpp:112] Iteration 3870, lr = 0.1
I0523 22:41:28.028522 11654 solver.cpp:239] Iteration 3880 (1.35452 iter/s, 7.38266s/10 iters), loss = 11.1629
I0523 22:41:28.028568 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1629 (* 1 = 11.1629 loss)
I0523 22:41:28.028579 11654 sgd_solver.cpp:112] Iteration 3880, lr = 0.1
I0523 22:41:36.630746 11654 solver.cpp:239] Iteration 3890 (1.16283 iter/s, 8.5997s/10 iters), loss = 10.5671
I0523 22:41:36.630784 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5671 (* 1 = 10.5671 loss)
I0523 22:41:36.630795 11654 sgd_solver.cpp:112] Iteration 3890, lr = 0.1
I0523 22:41:44.657300 11654 solver.cpp:239] Iteration 3900 (1.24592 iter/s, 8.02621s/10 iters), loss = 9.92487
I0523 22:41:44.657341 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.92487 (* 1 = 9.92487 loss)
I0523 22:41:44.657352 11654 sgd_solver.cpp:112] Iteration 3900, lr = 0.1
I0523 22:41:51.456970 11654 solver.cpp:239] Iteration 3910 (1.47073 iter/s, 6.79936s/10 iters), loss = 10.6353
I0523 22:41:51.457074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6353 (* 1 = 10.6353 loss)
I0523 22:41:51.457090 11654 sgd_solver.cpp:112] Iteration 3910, lr = 0.1
I0523 22:41:59.048471 11654 solver.cpp:239] Iteration 3920 (1.31733 iter/s, 7.59111s/10 iters), loss = 10.6402
I0523 22:41:59.048516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6402 (* 1 = 10.6402 loss)
I0523 22:41:59.048569 11654 sgd_solver.cpp:112] Iteration 3920, lr = 0.1
I0523 22:42:06.689831 11654 solver.cpp:239] Iteration 3930 (1.30873 iter/s, 7.64102s/10 iters), loss = 10.8482
I0523 22:42:06.689870 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8482 (* 1 = 10.8482 loss)
I0523 22:42:06.786130 11654 sgd_solver.cpp:112] Iteration 3930, lr = 0.1
I0523 22:42:13.139737 11654 solver.cpp:239] Iteration 3940 (1.55048 iter/s, 6.44962s/10 iters), loss = 10.9245
I0523 22:42:13.139781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9245 (* 1 = 10.9245 loss)
I0523 22:42:13.139914 11654 sgd_solver.cpp:112] Iteration 3940, lr = 0.1
I0523 22:42:21.240612 11654 solver.cpp:239] Iteration 3950 (1.23449 iter/s, 8.10052s/10 iters), loss = 10.0611
I0523 22:42:21.240653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0611 (* 1 = 10.0611 loss)
I0523 22:42:21.360756 11654 sgd_solver.cpp:112] Iteration 3950, lr = 0.1
I0523 22:42:27.616479 11654 solver.cpp:239] Iteration 3960 (1.56849 iter/s, 6.37557s/10 iters), loss = 10.9405
I0523 22:42:27.616739 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9405 (* 1 = 10.9405 loss)
I0523 22:42:27.617115 11654 sgd_solver.cpp:112] Iteration 3960, lr = 0.1
I0523 22:42:34.701297 11654 solver.cpp:239] Iteration 3970 (1.41157 iter/s, 7.08432s/10 iters), loss = 9.73987
I0523 22:42:34.701344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.73987 (* 1 = 9.73987 loss)
I0523 22:42:34.701359 11654 sgd_solver.cpp:112] Iteration 3970, lr = 0.1
I0523 22:42:41.242321 11654 solver.cpp:239] Iteration 3980 (1.52941 iter/s, 6.53849s/10 iters), loss = 10.8864
I0523 22:42:41.242369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8864 (* 1 = 10.8864 loss)
I0523 22:42:41.265251 11654 sgd_solver.cpp:112] Iteration 3980, lr = 0.1
I0523 22:42:48.818644 11654 solver.cpp:239] Iteration 3990 (1.31997 iter/s, 7.57595s/10 iters), loss = 11.2122
I0523 22:42:48.818778 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2122 (* 1 = 11.2122 loss)
I0523 22:42:48.819010 11654 sgd_solver.cpp:112] Iteration 3990, lr = 0.1
I0523 22:42:57.494500 11654 solver.cpp:239] Iteration 4000 (1.15268 iter/s, 8.6754s/10 iters), loss = 10.9452
I0523 22:42:57.494550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9452 (* 1 = 10.9452 loss)
I0523 22:42:57.494814 11654 sgd_solver.cpp:112] Iteration 4000, lr = 0.1
I0523 22:43:05.249195 11654 solver.cpp:239] Iteration 4010 (1.2896 iter/s, 7.75435s/10 iters), loss = 11.4422
I0523 22:43:05.249310 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4422 (* 1 = 11.4422 loss)
I0523 22:43:05.324864 11654 sgd_solver.cpp:112] Iteration 4010, lr = 0.1
I0523 22:43:11.377173 11654 solver.cpp:239] Iteration 4020 (1.63197 iter/s, 6.12757s/10 iters), loss = 9.39889
I0523 22:43:11.377228 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.39889 (* 1 = 9.39889 loss)
I0523 22:43:11.377248 11654 sgd_solver.cpp:112] Iteration 4020, lr = 0.1
I0523 22:43:19.003309 11654 solver.cpp:239] Iteration 4030 (1.31171 iter/s, 7.62364s/10 iters), loss = 10.4156
I0523 22:43:19.003342 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4156 (* 1 = 10.4156 loss)
I0523 22:43:19.003353 11654 sgd_solver.cpp:112] Iteration 4030, lr = 0.1
I0523 22:43:25.403827 11654 solver.cpp:239] Iteration 4040 (1.56244 iter/s, 6.40024s/10 iters), loss = 10.5536
I0523 22:43:25.403868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5536 (* 1 = 10.5536 loss)
I0523 22:43:25.403879 11654 sgd_solver.cpp:112] Iteration 4040, lr = 0.1
I0523 22:43:33.406858 11654 solver.cpp:239] Iteration 4050 (1.24958 iter/s, 8.00269s/10 iters), loss = 10.761
I0523 22:43:33.406895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.761 (* 1 = 10.761 loss)
I0523 22:43:33.521535 11654 sgd_solver.cpp:112] Iteration 4050, lr = 0.1
I0523 22:43:40.784127 11654 solver.cpp:239] Iteration 4060 (1.35558 iter/s, 7.37694s/10 iters), loss = 11.7482
I0523 22:43:40.784402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.7482 (* 1 = 11.7482 loss)
I0523 22:43:40.784451 11654 sgd_solver.cpp:112] Iteration 4060, lr = 0.1
I0523 22:43:47.463080 11654 solver.cpp:239] Iteration 4070 (1.49736 iter/s, 6.67843s/10 iters), loss = 10.5509
I0523 22:43:47.463127 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5509 (* 1 = 10.5509 loss)
I0523 22:43:47.463410 11654 sgd_solver.cpp:112] Iteration 4070, lr = 0.1
I0523 22:43:55.206260 11654 solver.cpp:239] Iteration 4080 (1.29152 iter/s, 7.74283s/10 iters), loss = 10.6089
I0523 22:43:55.206312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6089 (* 1 = 10.6089 loss)
I0523 22:43:55.206708 11654 sgd_solver.cpp:112] Iteration 4080, lr = 0.1
I0523 22:44:02.403887 11654 solver.cpp:239] Iteration 4090 (1.38941 iter/s, 7.1973s/10 iters), loss = 10.7465
I0523 22:44:02.403923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7465 (* 1 = 10.7465 loss)
I0523 22:44:02.794450 11654 sgd_solver.cpp:112] Iteration 4090, lr = 0.1
I0523 22:44:11.616125 11654 solver.cpp:239] Iteration 4100 (1.08556 iter/s, 9.21185s/10 iters), loss = 11.3069
I0523 22:44:11.616253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3069 (* 1 = 11.3069 loss)
I0523 22:44:11.616266 11654 sgd_solver.cpp:112] Iteration 4100, lr = 0.1
I0523 22:44:18.426936 11654 solver.cpp:239] Iteration 4110 (1.46835 iter/s, 6.81038s/10 iters), loss = 10.9407
I0523 22:44:18.426987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9407 (* 1 = 10.9407 loss)
I0523 22:44:18.427237 11654 sgd_solver.cpp:112] Iteration 4110, lr = 0.1
I0523 22:44:26.121803 11654 solver.cpp:239] Iteration 4120 (1.29963 iter/s, 7.69452s/10 iters), loss = 11.279
I0523 22:44:26.121868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.279 (* 1 = 11.279 loss)
I0523 22:44:26.121891 11654 sgd_solver.cpp:112] Iteration 4120, lr = 0.1
I0523 22:44:33.318778 11654 solver.cpp:239] Iteration 4130 (1.38955 iter/s, 7.19655s/10 iters), loss = 11.0189
I0523 22:44:33.318820 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0189 (* 1 = 11.0189 loss)
I0523 22:44:33.390677 11654 sgd_solver.cpp:112] Iteration 4130, lr = 0.1
I0523 22:44:39.815590 11654 solver.cpp:239] Iteration 4140 (1.53929 iter/s, 6.49651s/10 iters), loss = 10.8609
I0523 22:44:39.815634 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8609 (* 1 = 10.8609 loss)
I0523 22:44:39.815646 11654 sgd_solver.cpp:112] Iteration 4140, lr = 0.1
I0523 22:44:48.408524 11654 solver.cpp:239] Iteration 4150 (1.1638 iter/s, 8.59256s/10 iters), loss = 10.8143
I0523 22:44:48.408656 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8143 (* 1 = 10.8143 loss)
I0523 22:44:48.409018 11654 sgd_solver.cpp:112] Iteration 4150, lr = 0.1
I0523 22:44:56.459321 11654 solver.cpp:239] Iteration 4160 (1.24218 iter/s, 8.05036s/10 iters), loss = 10.4358
I0523 22:44:56.459367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4358 (* 1 = 10.4358 loss)
I0523 22:44:56.459379 11654 sgd_solver.cpp:112] Iteration 4160, lr = 0.1
I0523 22:45:03.760710 11654 solver.cpp:239] Iteration 4170 (1.36968 iter/s, 7.30098s/10 iters), loss = 10.1088
I0523 22:45:03.760752 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1088 (* 1 = 10.1088 loss)
I0523 22:45:03.791085 11654 sgd_solver.cpp:112] Iteration 4170, lr = 0.1
I0523 22:45:12.044714 11654 solver.cpp:239] Iteration 4180 (1.2072 iter/s, 8.28365s/10 iters), loss = 10.1984
I0523 22:45:12.044759 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1984 (* 1 = 10.1984 loss)
I0523 22:45:12.044770 11654 sgd_solver.cpp:112] Iteration 4180, lr = 0.1
I0523 22:45:20.214468 11654 solver.cpp:239] Iteration 4190 (1.22442 iter/s, 8.16716s/10 iters), loss = 10.8627
I0523 22:45:20.214555 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8627 (* 1 = 10.8627 loss)
I0523 22:45:20.214568 11654 sgd_solver.cpp:112] Iteration 4190, lr = 0.1
I0523 22:45:27.118454 11654 solver.cpp:239] Iteration 4200 (1.44852 iter/s, 6.90359s/10 iters), loss = 10.5765
I0523 22:45:27.118494 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5765 (* 1 = 10.5765 loss)
I0523 22:45:27.264746 11654 sgd_solver.cpp:112] Iteration 4200, lr = 0.1
I0523 22:45:36.110070 11654 solver.cpp:239] Iteration 4210 (1.1122 iter/s, 8.99122s/10 iters), loss = 10.6336
I0523 22:45:36.110119 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6336 (* 1 = 10.6336 loss)
I0523 22:45:36.110170 11654 sgd_solver.cpp:112] Iteration 4210, lr = 0.1
I0523 22:45:43.031847 11654 solver.cpp:239] Iteration 4220 (1.44478 iter/s, 6.92146s/10 iters), loss = 10.4205
I0523 22:45:43.031891 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4205 (* 1 = 10.4205 loss)
I0523 22:45:43.031903 11654 sgd_solver.cpp:112] Iteration 4220, lr = 0.1
I0523 22:45:49.892374 11654 solver.cpp:239] Iteration 4230 (1.45768 iter/s, 6.86022s/10 iters), loss = 10.8848
I0523 22:45:49.892415 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8848 (* 1 = 10.8848 loss)
I0523 22:45:50.030982 11654 sgd_solver.cpp:112] Iteration 4230, lr = 0.1
I0523 22:45:56.405578 11654 solver.cpp:239] Iteration 4240 (1.53541 iter/s, 6.51291s/10 iters), loss = 11.0032
I0523 22:45:56.405827 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0032 (* 1 = 11.0032 loss)
I0523 22:45:56.405874 11654 sgd_solver.cpp:112] Iteration 4240, lr = 0.1
I0523 22:46:04.305011 11654 solver.cpp:239] Iteration 4250 (1.26617 iter/s, 7.89785s/10 iters), loss = 10.9189
I0523 22:46:04.305058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9189 (* 1 = 10.9189 loss)
I0523 22:46:04.469725 11654 sgd_solver.cpp:112] Iteration 4250, lr = 0.1
I0523 22:46:11.273051 11654 solver.cpp:239] Iteration 4260 (1.43519 iter/s, 6.96773s/10 iters), loss = 10.7393
I0523 22:46:11.273093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7393 (* 1 = 10.7393 loss)
I0523 22:46:11.273141 11654 sgd_solver.cpp:112] Iteration 4260, lr = 0.1
I0523 22:46:18.415879 11654 solver.cpp:239] Iteration 4270 (1.40007 iter/s, 7.14251s/10 iters), loss = 10.4841
I0523 22:46:18.415933 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4841 (* 1 = 10.4841 loss)
I0523 22:46:18.415954 11654 sgd_solver.cpp:112] Iteration 4270, lr = 0.1
I0523 22:46:26.572386 11654 solver.cpp:239] Iteration 4280 (1.2264 iter/s, 8.15393s/10 iters), loss = 10.6024
I0523 22:46:26.573740 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6024 (* 1 = 10.6024 loss)
I0523 22:46:26.573786 11654 sgd_solver.cpp:112] Iteration 4280, lr = 0.1
I0523 22:46:33.656965 11654 solver.cpp:239] Iteration 4290 (1.41184 iter/s, 7.08296s/10 iters), loss = 10.1452
I0523 22:46:33.657006 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1452 (* 1 = 10.1452 loss)
I0523 22:46:33.657177 11654 sgd_solver.cpp:112] Iteration 4290, lr = 0.1
I0523 22:46:39.917490 11654 solver.cpp:239] Iteration 4300 (1.59738 iter/s, 6.26024s/10 iters), loss = 10.9706
I0523 22:46:39.917549 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9706 (* 1 = 10.9706 loss)
I0523 22:46:39.918051 11654 sgd_solver.cpp:112] Iteration 4300, lr = 0.1
I0523 22:46:46.765149 11654 solver.cpp:239] Iteration 4310 (1.46042 iter/s, 6.84735s/10 iters), loss = 10.4492
I0523 22:46:46.765187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4492 (* 1 = 10.4492 loss)
I0523 22:46:46.765199 11654 sgd_solver.cpp:112] Iteration 4310, lr = 0.1
I0523 22:46:53.301038 11654 solver.cpp:239] Iteration 4320 (1.53019 iter/s, 6.53516s/10 iters), loss = 10.7404
I0523 22:46:53.301081 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7404 (* 1 = 10.7404 loss)
I0523 22:46:53.301092 11654 sgd_solver.cpp:112] Iteration 4320, lr = 0.1
I0523 22:47:03.195698 11654 solver.cpp:239] Iteration 4330 (1.01069 iter/s, 9.89423s/10 iters), loss = 10.4181
I0523 22:47:03.195991 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4181 (* 1 = 10.4181 loss)
I0523 22:47:03.197118 11654 sgd_solver.cpp:112] Iteration 4330, lr = 0.1
I0523 22:47:09.726042 11654 solver.cpp:239] Iteration 4340 (1.53143 iter/s, 6.52983s/10 iters), loss = 11.2862
I0523 22:47:09.726091 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2862 (* 1 = 11.2862 loss)
I0523 22:47:09.726622 11654 sgd_solver.cpp:112] Iteration 4340, lr = 0.1
I0523 22:47:17.692109 11654 solver.cpp:239] Iteration 4350 (1.25538 iter/s, 7.9657s/10 iters), loss = 11.0333
I0523 22:47:17.692160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0333 (* 1 = 11.0333 loss)
I0523 22:47:17.692483 11654 sgd_solver.cpp:112] Iteration 4350, lr = 0.1
I0523 22:47:24.209451 11654 solver.cpp:239] Iteration 4360 (1.53444 iter/s, 6.51704s/10 iters), loss = 10.3493
I0523 22:47:24.209497 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3493 (* 1 = 10.3493 loss)
I0523 22:47:24.869593 11654 sgd_solver.cpp:112] Iteration 4360, lr = 0.1
I0523 22:47:31.693104 11654 solver.cpp:239] Iteration 4370 (1.33631 iter/s, 7.48332s/10 iters), loss = 10.8846
I0523 22:47:31.693145 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8846 (* 1 = 10.8846 loss)
I0523 22:47:31.693157 11654 sgd_solver.cpp:112] Iteration 4370, lr = 0.1
I0523 22:47:39.473827 11654 solver.cpp:239] Iteration 4380 (1.28529 iter/s, 7.78032s/10 iters), loss = 11.285
I0523 22:47:39.474087 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.285 (* 1 = 11.285 loss)
I0523 22:47:39.474120 11654 sgd_solver.cpp:112] Iteration 4380, lr = 0.1
I0523 22:47:46.692513 11654 solver.cpp:239] Iteration 4390 (1.3854 iter/s, 7.21814s/10 iters), loss = 9.60437
I0523 22:47:46.692548 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.60437 (* 1 = 9.60437 loss)
I0523 22:47:47.135380 11654 sgd_solver.cpp:112] Iteration 4390, lr = 0.1
I0523 22:47:54.874864 11654 solver.cpp:239] Iteration 4400 (1.2222 iter/s, 8.182s/10 iters), loss = 11.8204
I0523 22:47:54.874908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.8204 (* 1 = 11.8204 loss)
I0523 22:47:54.874928 11654 sgd_solver.cpp:112] Iteration 4400, lr = 0.1
I0523 22:48:01.687626 11654 solver.cpp:239] Iteration 4410 (1.4679 iter/s, 6.81246s/10 iters), loss = 11.5285
I0523 22:48:01.687665 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5285 (* 1 = 11.5285 loss)
I0523 22:48:01.687883 11654 sgd_solver.cpp:112] Iteration 4410, lr = 0.1
I0523 22:48:10.894907 11654 solver.cpp:239] Iteration 4420 (1.08614 iter/s, 9.20689s/10 iters), loss = 10.9001
I0523 22:48:10.895156 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9001 (* 1 = 10.9001 loss)
I0523 22:48:10.911916 11654 sgd_solver.cpp:112] Iteration 4420, lr = 0.1
I0523 22:48:17.802526 11654 solver.cpp:239] Iteration 4430 (1.44778 iter/s, 6.90715s/10 iters), loss = 10.8709
I0523 22:48:17.802564 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8709 (* 1 = 10.8709 loss)
I0523 22:48:17.999378 11654 sgd_solver.cpp:112] Iteration 4430, lr = 0.1
I0523 22:48:25.351321 11654 solver.cpp:239] Iteration 4440 (1.32477 iter/s, 7.54847s/10 iters), loss = 10.5169
I0523 22:48:25.351358 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5169 (* 1 = 10.5169 loss)
I0523 22:48:25.351369 11654 sgd_solver.cpp:112] Iteration 4440, lr = 0.1
I0523 22:48:31.530380 11654 solver.cpp:239] Iteration 4450 (1.61844 iter/s, 6.17877s/10 iters), loss = 10.5688
I0523 22:48:31.530431 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5688 (* 1 = 10.5688 loss)
I0523 22:48:31.530609 11654 sgd_solver.cpp:112] Iteration 4450, lr = 0.1
I0523 22:48:38.359100 11654 solver.cpp:239] Iteration 4460 (1.46447 iter/s, 6.82841s/10 iters), loss = 10.2998
I0523 22:48:38.359146 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2998 (* 1 = 10.2998 loss)
I0523 22:48:38.359158 11654 sgd_solver.cpp:112] Iteration 4460, lr = 0.1
I0523 22:48:46.480095 11654 solver.cpp:239] Iteration 4470 (1.23177 iter/s, 8.11842s/10 iters), loss = 11.5646
I0523 22:48:46.480203 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5646 (* 1 = 11.5646 loss)
I0523 22:48:46.480228 11654 sgd_solver.cpp:112] Iteration 4470, lr = 0.1
I0523 22:48:53.334453 11654 solver.cpp:239] Iteration 4480 (1.45947 iter/s, 6.85182s/10 iters), loss = 10.9331
I0523 22:48:53.334492 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9331 (* 1 = 10.9331 loss)
I0523 22:48:53.334508 11654 sgd_solver.cpp:112] Iteration 4480, lr = 0.1
I0523 22:49:00.589779 11654 solver.cpp:239] Iteration 4490 (1.37836 iter/s, 7.25501s/10 iters), loss = 10.1948
I0523 22:49:00.589820 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1948 (* 1 = 10.1948 loss)
I0523 22:49:00.589831 11654 sgd_solver.cpp:112] Iteration 4490, lr = 0.1
I0523 22:49:06.914356 11654 solver.cpp:239] Iteration 4500 (1.5812 iter/s, 6.32429s/10 iters), loss = 10.9689
I0523 22:49:06.914404 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9689 (* 1 = 10.9689 loss)
I0523 22:49:06.914422 11654 sgd_solver.cpp:112] Iteration 4500, lr = 0.1
I0523 22:49:13.795768 11654 solver.cpp:239] Iteration 4510 (1.45349 iter/s, 6.88s/10 iters), loss = 10.5431
I0523 22:49:13.795805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5431 (* 1 = 10.5431 loss)
I0523 22:49:13.795817 11654 sgd_solver.cpp:112] Iteration 4510, lr = 0.1
I0523 22:49:21.613004 11654 solver.cpp:239] Iteration 4520 (1.27937 iter/s, 7.81635s/10 iters), loss = 11.2518
I0523 22:49:21.613314 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2518 (* 1 = 11.2518 loss)
I0523 22:49:21.613418 11654 sgd_solver.cpp:112] Iteration 4520, lr = 0.1
I0523 22:49:28.591881 11654 solver.cpp:239] Iteration 4530 (1.433 iter/s, 6.97834s/10 iters), loss = 10.9521
I0523 22:49:28.591924 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9521 (* 1 = 10.9521 loss)
I0523 22:49:29.667373 11654 sgd_solver.cpp:112] Iteration 4530, lr = 0.1
I0523 22:49:36.843098 11654 solver.cpp:239] Iteration 4540 (1.21199 iter/s, 8.25086s/10 iters), loss = 11.4543
I0523 22:49:36.843144 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4543 (* 1 = 11.4543 loss)
I0523 22:49:37.481474 11654 sgd_solver.cpp:112] Iteration 4540, lr = 0.1
I0523 22:49:45.275260 11654 solver.cpp:239] Iteration 4550 (1.18599 iter/s, 8.43179s/10 iters), loss = 10.69
I0523 22:49:45.275303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.69 (* 1 = 10.69 loss)
I0523 22:49:46.916102 11654 sgd_solver.cpp:112] Iteration 4550, lr = 0.1
I0523 22:49:55.121017 11654 solver.cpp:239] Iteration 4560 (1.01571 iter/s, 9.84533s/10 iters), loss = 10.7826
I0523 22:49:55.121153 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7826 (* 1 = 10.7826 loss)
I0523 22:49:55.121496 11654 sgd_solver.cpp:112] Iteration 4560, lr = 0.1
I0523 22:50:02.434049 11654 solver.cpp:239] Iteration 4570 (1.3675 iter/s, 7.31262s/10 iters), loss = 10.1622
I0523 22:50:02.434089 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1622 (* 1 = 10.1622 loss)
I0523 22:50:03.650022 11654 sgd_solver.cpp:112] Iteration 4570, lr = 0.1
I0523 22:50:12.290746 11654 solver.cpp:239] Iteration 4580 (1.01458 iter/s, 9.85628s/10 iters), loss = 10.3702
I0523 22:50:12.290786 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3702 (* 1 = 10.3702 loss)
I0523 22:50:12.588963 11654 sgd_solver.cpp:112] Iteration 4580, lr = 0.1
I0523 22:50:19.251310 11654 solver.cpp:239] Iteration 4590 (1.43673 iter/s, 6.96025s/10 iters), loss = 10.7364
I0523 22:50:19.251363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7364 (* 1 = 10.7364 loss)
I0523 22:50:19.251454 11654 sgd_solver.cpp:112] Iteration 4590, lr = 0.1
I0523 22:50:26.346715 11654 solver.cpp:239] Iteration 4600 (1.40943 iter/s, 7.09508s/10 iters), loss = 10.7956
I0523 22:50:26.346949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7956 (* 1 = 10.7956 loss)
I0523 22:50:26.351097 11654 sgd_solver.cpp:112] Iteration 4600, lr = 0.1
I0523 22:50:33.476001 11654 solver.cpp:239] Iteration 4610 (1.40276 iter/s, 7.12882s/10 iters), loss = 10.0476
I0523 22:50:33.476040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0476 (* 1 = 10.0476 loss)
I0523 22:50:34.222604 11654 sgd_solver.cpp:112] Iteration 4610, lr = 0.1
I0523 22:50:42.531669 11654 solver.cpp:239] Iteration 4620 (1.10433 iter/s, 9.05528s/10 iters), loss = 11.5535
I0523 22:50:42.531711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.5535 (* 1 = 11.5535 loss)
I0523 22:50:42.531765 11654 sgd_solver.cpp:112] Iteration 4620, lr = 0.1
I0523 22:50:50.058950 11654 solver.cpp:239] Iteration 4630 (1.32856 iter/s, 7.52695s/10 iters), loss = 10.9571
I0523 22:50:50.059000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9571 (* 1 = 10.9571 loss)
I0523 22:50:50.529202 11654 sgd_solver.cpp:112] Iteration 4630, lr = 0.1
I0523 22:50:57.568639 11654 solver.cpp:239] Iteration 4640 (1.33167 iter/s, 7.50935s/10 iters), loss = 10.9913
I0523 22:50:57.568938 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9913 (* 1 = 10.9913 loss)
I0523 22:50:57.568991 11654 sgd_solver.cpp:112] Iteration 4640, lr = 0.1
I0523 22:51:06.323690 11654 solver.cpp:239] Iteration 4650 (1.14239 iter/s, 8.7536s/10 iters), loss = 11.3836
I0523 22:51:06.323747 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3836 (* 1 = 11.3836 loss)
I0523 22:51:06.751688 11654 sgd_solver.cpp:112] Iteration 4650, lr = 0.1
I0523 22:51:13.166509 11654 solver.cpp:239] Iteration 4660 (1.46145 iter/s, 6.84251s/10 iters), loss = 10.8661
I0523 22:51:13.166551 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8661 (* 1 = 10.8661 loss)
I0523 22:51:13.831996 11654 sgd_solver.cpp:112] Iteration 4660, lr = 0.1
I0523 22:51:22.419097 11654 solver.cpp:239] Iteration 4670 (1.08083 iter/s, 9.25219s/10 iters), loss = 10.6481
I0523 22:51:22.419136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6481 (* 1 = 10.6481 loss)
I0523 22:51:22.421350 11654 sgd_solver.cpp:112] Iteration 4670, lr = 0.1
I0523 22:51:32.289557 11654 solver.cpp:239] Iteration 4680 (1.01317 iter/s, 9.87005s/10 iters), loss = 9.96357
I0523 22:51:32.289796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.96357 (* 1 = 9.96357 loss)
I0523 22:51:32.289836 11654 sgd_solver.cpp:112] Iteration 4680, lr = 0.1
I0523 22:51:41.349159 11654 solver.cpp:239] Iteration 4690 (1.10387 iter/s, 9.05903s/10 iters), loss = 10.2519
I0523 22:51:41.349201 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2519 (* 1 = 10.2519 loss)
I0523 22:51:41.349304 11654 sgd_solver.cpp:112] Iteration 4690, lr = 0.1
I0523 22:51:49.796821 11654 solver.cpp:239] Iteration 4700 (1.18381 iter/s, 8.4473s/10 iters), loss = 10.3249
I0523 22:51:49.796862 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3249 (* 1 = 10.3249 loss)
I0523 22:51:50.124676 11654 sgd_solver.cpp:112] Iteration 4700, lr = 0.1
I0523 22:51:57.998217 11654 solver.cpp:239] Iteration 4710 (1.21936 iter/s, 8.20104s/10 iters), loss = 11.2303
I0523 22:51:57.998262 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2303 (* 1 = 11.2303 loss)
I0523 22:51:57.998275 11654 sgd_solver.cpp:112] Iteration 4710, lr = 0.1
I0523 22:52:05.363090 11654 solver.cpp:239] Iteration 4720 (1.35787 iter/s, 7.36446s/10 iters), loss = 11.7432
I0523 22:52:05.363332 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.7432 (* 1 = 11.7432 loss)
I0523 22:52:05.363387 11654 sgd_solver.cpp:112] Iteration 4720, lr = 0.1
I0523 22:52:13.468369 11654 solver.cpp:239] Iteration 4730 (1.23385 iter/s, 8.10472s/10 iters), loss = 11.0365
I0523 22:52:13.468422 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0365 (* 1 = 11.0365 loss)
I0523 22:52:13.468528 11654 sgd_solver.cpp:112] Iteration 4730, lr = 0.1
I0523 22:52:20.716748 11654 solver.cpp:239] Iteration 4740 (1.37968 iter/s, 7.24805s/10 iters), loss = 10.5064
I0523 22:52:20.716794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5064 (* 1 = 10.5064 loss)
I0523 22:52:20.716806 11654 sgd_solver.cpp:112] Iteration 4740, lr = 0.1
I0523 22:52:29.712227 11654 solver.cpp:239] Iteration 4750 (1.11172 iter/s, 8.99509s/10 iters), loss = 10.7751
I0523 22:52:29.712270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7751 (* 1 = 10.7751 loss)
I0523 22:52:29.712282 11654 sgd_solver.cpp:112] Iteration 4750, lr = 0.1
I0523 22:52:36.007582 11654 solver.cpp:239] Iteration 4760 (1.58854 iter/s, 6.29508s/10 iters), loss = 10.1696
I0523 22:52:36.007781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1696 (* 1 = 10.1696 loss)
I0523 22:52:36.007798 11654 sgd_solver.cpp:112] Iteration 4760, lr = 0.1
I0523 22:52:42.526516 11654 solver.cpp:239] Iteration 4770 (1.53411 iter/s, 6.51845s/10 iters), loss = 10.7783
I0523 22:52:42.526559 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7783 (* 1 = 10.7783 loss)
I0523 22:52:42.526571 11654 sgd_solver.cpp:112] Iteration 4770, lr = 0.1
I0523 22:52:50.425174 11654 solver.cpp:239] Iteration 4780 (1.26609 iter/s, 7.89831s/10 iters), loss = 10.6111
I0523 22:52:50.425217 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6111 (* 1 = 10.6111 loss)
I0523 22:52:50.651868 11654 sgd_solver.cpp:112] Iteration 4780, lr = 0.1
I0523 22:52:58.318176 11654 solver.cpp:239] Iteration 4790 (1.267 iter/s, 7.89266s/10 iters), loss = 11.0099
I0523 22:52:58.318212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0099 (* 1 = 11.0099 loss)
I0523 22:52:58.318240 11654 sgd_solver.cpp:112] Iteration 4790, lr = 0.1
I0523 22:53:05.853510 11654 solver.cpp:239] Iteration 4800 (1.32715 iter/s, 7.53492s/10 iters), loss = 11.1586
I0523 22:53:05.853600 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1586 (* 1 = 11.1586 loss)
I0523 22:53:05.853742 11654 sgd_solver.cpp:112] Iteration 4800, lr = 0.1
I0523 22:53:13.220510 11654 solver.cpp:239] Iteration 4810 (1.35747 iter/s, 7.36663s/10 iters), loss = 11.3203
I0523 22:53:13.220652 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3203 (* 1 = 11.3203 loss)
I0523 22:53:13.221036 11654 sgd_solver.cpp:112] Iteration 4810, lr = 0.1
I0523 22:53:20.290127 11654 solver.cpp:239] Iteration 4820 (1.41458 iter/s, 7.06922s/10 iters), loss = 10.3895
I0523 22:53:20.290169 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3895 (* 1 = 10.3895 loss)
I0523 22:53:20.290236 11654 sgd_solver.cpp:112] Iteration 4820, lr = 0.1
I0523 22:53:26.418895 11654 solver.cpp:239] Iteration 4830 (1.63173 iter/s, 6.12848s/10 iters), loss = 10.3975
I0523 22:53:26.418941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3975 (* 1 = 10.3975 loss)
I0523 22:53:26.419106 11654 sgd_solver.cpp:112] Iteration 4830, lr = 0.1
I0523 22:53:34.251453 11654 solver.cpp:239] Iteration 4840 (1.27678 iter/s, 7.8322s/10 iters), loss = 10.1857
I0523 22:53:34.251507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1857 (* 1 = 10.1857 loss)
I0523 22:53:34.251659 11654 sgd_solver.cpp:112] Iteration 4840, lr = 0.1
I0523 22:53:40.599901 11654 solver.cpp:239] Iteration 4850 (1.57526 iter/s, 6.34816s/10 iters), loss = 10.7087
I0523 22:53:40.599941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7087 (* 1 = 10.7087 loss)
I0523 22:53:40.599968 11654 sgd_solver.cpp:112] Iteration 4850, lr = 0.1
I0523 22:53:47.308262 11654 solver.cpp:239] Iteration 4860 (1.49074 iter/s, 6.70806s/10 iters), loss = 9.73783
I0523 22:53:47.308501 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.73783 (* 1 = 9.73783 loss)
I0523 22:53:47.330016 11654 sgd_solver.cpp:112] Iteration 4860, lr = 0.1
I0523 22:53:55.136605 11654 solver.cpp:239] Iteration 4870 (1.27749 iter/s, 7.82784s/10 iters), loss = 10.6128
I0523 22:53:55.136651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6128 (* 1 = 10.6128 loss)
I0523 22:53:55.143888 11654 sgd_solver.cpp:112] Iteration 4870, lr = 0.1
I0523 22:54:01.350349 11654 solver.cpp:239] Iteration 4880 (1.60941 iter/s, 6.21346s/10 iters), loss = 10.0419
I0523 22:54:01.350396 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0419 (* 1 = 10.0419 loss)
I0523 22:54:01.356724 11654 sgd_solver.cpp:112] Iteration 4880, lr = 0.1
I0523 22:54:07.936146 11654 solver.cpp:239] Iteration 4890 (1.5185 iter/s, 6.58544s/10 iters), loss = 10.5841
I0523 22:54:07.936230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5841 (* 1 = 10.5841 loss)
I0523 22:54:07.936260 11654 sgd_solver.cpp:112] Iteration 4890, lr = 0.1
I0523 22:54:14.442106 11654 solver.cpp:239] Iteration 4900 (1.53713 iter/s, 6.50564s/10 iters), loss = 10.4254
I0523 22:54:14.442144 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4254 (* 1 = 10.4254 loss)
I0523 22:54:14.442374 11654 sgd_solver.cpp:112] Iteration 4900, lr = 0.1
I0523 22:54:21.013092 11654 solver.cpp:239] Iteration 4910 (1.52191 iter/s, 6.57069s/10 iters), loss = 10.1612
I0523 22:54:21.013387 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1612 (* 1 = 10.1612 loss)
I0523 22:54:21.013444 11654 sgd_solver.cpp:112] Iteration 4910, lr = 0.1
I0523 22:54:29.557484 11654 solver.cpp:239] Iteration 4920 (1.17044 iter/s, 8.54378s/10 iters), loss = 10.4445
I0523 22:54:29.557528 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4445 (* 1 = 10.4445 loss)
I0523 22:54:30.168355 11654 sgd_solver.cpp:112] Iteration 4920, lr = 0.1
I0523 22:54:37.820307 11654 solver.cpp:239] Iteration 4930 (1.21029 iter/s, 8.26246s/10 iters), loss = 10.5156
I0523 22:54:37.820353 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5156 (* 1 = 10.5156 loss)
I0523 22:54:37.820509 11654 sgd_solver.cpp:112] Iteration 4930, lr = 0.1
I0523 22:54:45.194614 11654 solver.cpp:239] Iteration 4940 (1.35612 iter/s, 7.37398s/10 iters), loss = 10.525
I0523 22:54:45.194655 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.525 (* 1 = 10.525 loss)
I0523 22:54:45.194876 11654 sgd_solver.cpp:112] Iteration 4940, lr = 0.1
I0523 22:54:53.743892 11654 solver.cpp:239] Iteration 4950 (1.16974 iter/s, 8.54892s/10 iters), loss = 10.858
I0523 22:54:53.744114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.858 (* 1 = 10.858 loss)
I0523 22:54:53.744164 11654 sgd_solver.cpp:112] Iteration 4950, lr = 0.1
I0523 22:55:00.153050 11654 solver.cpp:239] Iteration 4960 (1.56088 iter/s, 6.40663s/10 iters), loss = 9.99353
I0523 22:55:00.153095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.99353 (* 1 = 9.99353 loss)
I0523 22:55:00.153107 11654 sgd_solver.cpp:112] Iteration 4960, lr = 0.1
I0523 22:55:07.831465 11654 solver.cpp:239] Iteration 4970 (1.30241 iter/s, 7.67807s/10 iters), loss = 10.1147
I0523 22:55:07.831514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1147 (* 1 = 10.1147 loss)
I0523 22:55:08.010500 11654 sgd_solver.cpp:112] Iteration 4970, lr = 0.1
I0523 22:55:15.465909 11654 solver.cpp:239] Iteration 4980 (1.30991 iter/s, 7.6341s/10 iters), loss = 10.9836
I0523 22:55:15.465957 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9836 (* 1 = 10.9836 loss)
I0523 22:55:15.469084 11654 sgd_solver.cpp:112] Iteration 4980, lr = 0.1
I0523 22:55:22.204341 11654 solver.cpp:239] Iteration 4990 (1.48409 iter/s, 6.73813s/10 iters), loss = 9.92509
I0523 22:55:22.204385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.92509 (* 1 = 9.92509 loss)
I0523 22:55:22.204599 11654 sgd_solver.cpp:112] Iteration 4990, lr = 0.1
I0523 22:55:31.779857 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_5000.caffemodel
I0523 22:55:32.049844 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_5000.solverstate
I0523 22:55:32.795354 11654 solver.cpp:239] Iteration 5000 (0.944237 iter/s, 10.5906s/10 iters), loss = 10.9982
I0523 22:55:32.795405 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9982 (* 1 = 10.9982 loss)
I0523 22:55:32.795421 11654 sgd_solver.cpp:112] Iteration 5000, lr = 0.1
I0523 22:55:41.040747 11654 solver.cpp:239] Iteration 5010 (1.21285 iter/s, 8.24503s/10 iters), loss = 11.4745
I0523 22:55:41.040791 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4745 (* 1 = 11.4745 loss)
I0523 22:55:41.045279 11654 sgd_solver.cpp:112] Iteration 5010, lr = 0.1
I0523 22:55:48.553513 11654 solver.cpp:239] Iteration 5020 (1.33113 iter/s, 7.51243s/10 iters), loss = 10.6412
I0523 22:55:48.553570 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6412 (* 1 = 10.6412 loss)
I0523 22:55:48.553588 11654 sgd_solver.cpp:112] Iteration 5020, lr = 0.1
I0523 22:55:54.561648 11654 solver.cpp:239] Iteration 5030 (1.66466 iter/s, 6.00722s/10 iters), loss = 11.3516
I0523 22:55:54.561697 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3516 (* 1 = 11.3516 loss)
I0523 22:55:54.561815 11654 sgd_solver.cpp:112] Iteration 5030, lr = 0.1
I0523 22:56:01.410727 11654 solver.cpp:239] Iteration 5040 (1.46012 iter/s, 6.84874s/10 iters), loss = 10.1397
I0523 22:56:01.410794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1397 (* 1 = 10.1397 loss)
I0523 22:56:01.410959 11654 sgd_solver.cpp:112] Iteration 5040, lr = 0.1
I0523 22:56:11.136376 11654 solver.cpp:239] Iteration 5050 (1.02825 iter/s, 9.72523s/10 iters), loss = 10.7638
I0523 22:56:11.136685 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7638 (* 1 = 10.7638 loss)
I0523 22:56:11.213954 11654 sgd_solver.cpp:112] Iteration 5050, lr = 0.1
I0523 22:56:18.436262 11654 solver.cpp:239] Iteration 5060 (1.36998 iter/s, 7.29936s/10 iters), loss = 10.4908
I0523 22:56:18.436309 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4908 (* 1 = 10.4908 loss)
I0523 22:56:18.436424 11654 sgd_solver.cpp:112] Iteration 5060, lr = 0.1
I0523 22:56:25.144323 11654 solver.cpp:239] Iteration 5070 (1.49081 iter/s, 6.70775s/10 iters), loss = 11.1748
I0523 22:56:25.144388 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1748 (* 1 = 11.1748 loss)
I0523 22:56:25.144636 11654 sgd_solver.cpp:112] Iteration 5070, lr = 0.1
I0523 22:56:33.639266 11654 solver.cpp:239] Iteration 5080 (1.17722 iter/s, 8.49456s/10 iters), loss = 10.4298
I0523 22:56:33.639330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4298 (* 1 = 10.4298 loss)
I0523 22:56:33.639547 11654 sgd_solver.cpp:112] Iteration 5080, lr = 0.1
I0523 22:56:41.794080 11654 solver.cpp:239] Iteration 5090 (1.22632 iter/s, 8.15445s/10 iters), loss = 10.8666
I0523 22:56:41.794286 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8666 (* 1 = 10.8666 loss)
I0523 22:56:41.887148 11654 sgd_solver.cpp:112] Iteration 5090, lr = 0.1
I0523 22:56:49.702392 11654 solver.cpp:239] Iteration 5100 (1.26457 iter/s, 7.90784s/10 iters), loss = 10.3532
I0523 22:56:49.702445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3532 (* 1 = 10.3532 loss)
I0523 22:56:49.702461 11654 sgd_solver.cpp:112] Iteration 5100, lr = 0.1
I0523 22:56:57.380093 11654 solver.cpp:239] Iteration 5110 (1.30254 iter/s, 7.67729s/10 iters), loss = 10.5406
I0523 22:56:57.380133 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5406 (* 1 = 10.5406 loss)
I0523 22:56:58.030648 11654 sgd_solver.cpp:112] Iteration 5110, lr = 0.1
I0523 22:57:05.663398 11654 solver.cpp:239] Iteration 5120 (1.2073 iter/s, 8.28294s/10 iters), loss = 10.4004
I0523 22:57:05.663450 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4004 (* 1 = 10.4004 loss)
I0523 22:57:05.672042 11654 sgd_solver.cpp:112] Iteration 5120, lr = 0.1
I0523 22:57:12.316560 11654 solver.cpp:239] Iteration 5130 (1.50311 iter/s, 6.65285s/10 iters), loss = 11.0351
I0523 22:57:12.316658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0351 (* 1 = 11.0351 loss)
I0523 22:57:12.406406 11654 sgd_solver.cpp:112] Iteration 5130, lr = 0.1
I0523 22:57:20.008957 11654 solver.cpp:239] Iteration 5140 (1.30005 iter/s, 7.69201s/10 iters), loss = 10.3479
I0523 22:57:20.009011 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3479 (* 1 = 10.3479 loss)
I0523 22:57:21.322291 11654 sgd_solver.cpp:112] Iteration 5140, lr = 0.1
I0523 22:57:27.597847 11654 solver.cpp:239] Iteration 5150 (1.31778 iter/s, 7.58855s/10 iters), loss = 10.9995
I0523 22:57:27.597910 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9995 (* 1 = 10.9995 loss)
I0523 22:57:27.598151 11654 sgd_solver.cpp:112] Iteration 5150, lr = 0.1
I0523 22:57:35.690946 11654 solver.cpp:239] Iteration 5160 (1.23568 iter/s, 8.09273s/10 iters), loss = 10.882
I0523 22:57:35.690996 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.882 (* 1 = 10.882 loss)
I0523 22:57:36.262781 11654 sgd_solver.cpp:112] Iteration 5160, lr = 0.1
I0523 22:57:43.188829 11654 solver.cpp:239] Iteration 5170 (1.33377 iter/s, 7.49756s/10 iters), loss = 10.4141
I0523 22:57:43.188932 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4141 (* 1 = 10.4141 loss)
I0523 22:57:43.189153 11654 sgd_solver.cpp:112] Iteration 5170, lr = 0.1
I0523 22:57:50.100320 11654 solver.cpp:239] Iteration 5180 (1.44694 iter/s, 6.91112s/10 iters), loss = 10.543
I0523 22:57:50.100401 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.543 (* 1 = 10.543 loss)
I0523 22:57:50.101017 11654 sgd_solver.cpp:112] Iteration 5180, lr = 0.1
I0523 22:57:57.041012 11654 solver.cpp:239] Iteration 5190 (1.44085 iter/s, 6.94037s/10 iters), loss = 10.6721
I0523 22:57:57.041052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6721 (* 1 = 10.6721 loss)
I0523 22:57:57.041071 11654 sgd_solver.cpp:112] Iteration 5190, lr = 0.1
I0523 22:58:04.023736 11654 solver.cpp:239] Iteration 5200 (1.43217 iter/s, 6.98241s/10 iters), loss = 10.604
I0523 22:58:04.023797 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.604 (* 1 = 10.604 loss)
I0523 22:58:04.023932 11654 sgd_solver.cpp:112] Iteration 5200, lr = 0.1
I0523 22:58:11.203446 11654 solver.cpp:239] Iteration 5210 (1.39288 iter/s, 7.17938s/10 iters), loss = 9.32181
I0523 22:58:11.203498 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.32181 (* 1 = 9.32181 loss)
I0523 22:58:11.203517 11654 sgd_solver.cpp:112] Iteration 5210, lr = 0.1
I0523 22:58:18.124922 11654 solver.cpp:239] Iteration 5220 (1.4449 iter/s, 6.9209s/10 iters), loss = 10.1879
I0523 22:58:18.125195 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1879 (* 1 = 10.1879 loss)
I0523 22:58:18.125259 11654 sgd_solver.cpp:112] Iteration 5220, lr = 0.1
I0523 22:58:25.770120 11654 solver.cpp:239] Iteration 5230 (1.3081 iter/s, 7.64468s/10 iters), loss = 10.5121
I0523 22:58:25.770174 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5121 (* 1 = 10.5121 loss)
I0523 22:58:25.770190 11654 sgd_solver.cpp:112] Iteration 5230, lr = 0.1
I0523 22:58:32.353652 11654 solver.cpp:239] Iteration 5240 (1.51903 iter/s, 6.58316s/10 iters), loss = 10.1597
I0523 22:58:32.353699 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1597 (* 1 = 10.1597 loss)
I0523 22:58:32.354156 11654 sgd_solver.cpp:112] Iteration 5240, lr = 0.1
I0523 22:58:40.262740 11654 solver.cpp:239] Iteration 5250 (1.26443 iter/s, 7.90868s/10 iters), loss = 10.9097
I0523 22:58:40.262804 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9097 (* 1 = 10.9097 loss)
I0523 22:58:40.296133 11654 sgd_solver.cpp:112] Iteration 5250, lr = 0.1
I0523 22:58:46.941208 11654 solver.cpp:239] Iteration 5260 (1.49742 iter/s, 6.67816s/10 iters), loss = 11.169
I0523 22:58:46.941247 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.169 (* 1 = 11.169 loss)
I0523 22:58:46.941262 11654 sgd_solver.cpp:112] Iteration 5260, lr = 0.1
I0523 22:58:53.559707 11654 solver.cpp:239] Iteration 5270 (1.511 iter/s, 6.61812s/10 iters), loss = 10.7979
I0523 22:58:53.559973 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7979 (* 1 = 10.7979 loss)
I0523 22:58:53.560253 11654 sgd_solver.cpp:112] Iteration 5270, lr = 0.1
I0523 22:59:00.824779 11654 solver.cpp:239] Iteration 5280 (1.37654 iter/s, 7.26457s/10 iters), loss = 10.6471
I0523 22:59:00.824842 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6471 (* 1 = 10.6471 loss)
I0523 22:59:00.824892 11654 sgd_solver.cpp:112] Iteration 5280, lr = 0.1
I0523 22:59:08.494767 11654 solver.cpp:239] Iteration 5290 (1.30384 iter/s, 7.66964s/10 iters), loss = 10.3012
I0523 22:59:08.494828 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3012 (* 1 = 10.3012 loss)
I0523 22:59:08.494845 11654 sgd_solver.cpp:112] Iteration 5290, lr = 0.1
I0523 22:59:14.908020 11654 solver.cpp:239] Iteration 5300 (1.55987 iter/s, 6.4108s/10 iters), loss = 11.3497
I0523 22:59:14.908071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3497 (* 1 = 11.3497 loss)
I0523 22:59:14.908087 11654 sgd_solver.cpp:112] Iteration 5300, lr = 0.1
I0523 22:59:21.026489 11654 solver.cpp:239] Iteration 5310 (1.63449 iter/s, 6.11812s/10 iters), loss = 10.3437
I0523 22:59:21.026541 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3437 (* 1 = 10.3437 loss)
I0523 22:59:21.035187 11654 sgd_solver.cpp:112] Iteration 5310, lr = 0.1
I0523 22:59:27.515805 11654 solver.cpp:239] Iteration 5320 (1.54106 iter/s, 6.48902s/10 iters), loss = 11.2787
I0523 22:59:27.515986 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2787 (* 1 = 11.2787 loss)
I0523 22:59:27.687364 11654 sgd_solver.cpp:112] Iteration 5320, lr = 0.1
I0523 22:59:34.344146 11654 solver.cpp:239] Iteration 5330 (1.46458 iter/s, 6.82788s/10 iters), loss = 10.7608
I0523 22:59:34.344208 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7608 (* 1 = 10.7608 loss)
I0523 22:59:34.344579 11654 sgd_solver.cpp:112] Iteration 5330, lr = 0.1
I0523 22:59:41.182488 11654 solver.cpp:239] Iteration 5340 (1.46241 iter/s, 6.83803s/10 iters), loss = 10.2278
I0523 22:59:41.182544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2278 (* 1 = 10.2278 loss)
I0523 22:59:41.182564 11654 sgd_solver.cpp:112] Iteration 5340, lr = 0.1
I0523 22:59:47.881907 11654 solver.cpp:239] Iteration 5350 (1.49275 iter/s, 6.69906s/10 iters), loss = 10.7068
I0523 22:59:47.881963 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7068 (* 1 = 10.7068 loss)
I0523 22:59:47.882131 11654 sgd_solver.cpp:112] Iteration 5350, lr = 0.1
I0523 22:59:54.351114 11654 solver.cpp:239] Iteration 5360 (1.54585 iter/s, 6.46891s/10 iters), loss = 10.1189
I0523 22:59:54.351155 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1189 (* 1 = 10.1189 loss)
I0523 22:59:54.351303 11654 sgd_solver.cpp:112] Iteration 5360, lr = 0.1
I0523 23:00:00.914499 11654 solver.cpp:239] Iteration 5370 (1.52368 iter/s, 6.56308s/10 iters), loss = 11.593
I0523 23:00:00.914810 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.593 (* 1 = 11.593 loss)
I0523 23:00:00.914901 11654 sgd_solver.cpp:112] Iteration 5370, lr = 0.1
I0523 23:00:08.557822 11654 solver.cpp:239] Iteration 5380 (1.30843 iter/s, 7.64278s/10 iters), loss = 10.1961
I0523 23:00:08.557871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1961 (* 1 = 10.1961 loss)
I0523 23:00:08.558118 11654 sgd_solver.cpp:112] Iteration 5380, lr = 0.1
I0523 23:00:17.017421 11654 solver.cpp:239] Iteration 5390 (1.18214 iter/s, 8.45922s/10 iters), loss = 10.6312
I0523 23:00:17.017484 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6312 (* 1 = 10.6312 loss)
I0523 23:00:17.017738 11654 sgd_solver.cpp:112] Iteration 5390, lr = 0.1
I0523 23:00:23.522601 11654 solver.cpp:239] Iteration 5400 (1.53731 iter/s, 6.50488s/10 iters), loss = 10.0047
I0523 23:00:23.522655 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0047 (* 1 = 10.0047 loss)
I0523 23:00:23.522779 11654 sgd_solver.cpp:112] Iteration 5400, lr = 0.1
I0523 23:00:31.493436 11654 solver.cpp:239] Iteration 5410 (1.25463 iter/s, 7.97048s/10 iters), loss = 10.609
I0523 23:00:31.493652 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.609 (* 1 = 10.609 loss)
I0523 23:00:31.493892 11654 sgd_solver.cpp:112] Iteration 5410, lr = 0.1
I0523 23:00:37.959046 11654 solver.cpp:239] Iteration 5420 (1.54674 iter/s, 6.4652s/10 iters), loss = 11.0547
I0523 23:00:37.959095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0547 (* 1 = 11.0547 loss)
I0523 23:00:37.959343 11654 sgd_solver.cpp:112] Iteration 5420, lr = 0.1
I0523 23:00:45.108520 11654 solver.cpp:239] Iteration 5430 (1.39877 iter/s, 7.14916s/10 iters), loss = 9.7153
I0523 23:00:45.108572 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.7153 (* 1 = 9.7153 loss)
I0523 23:00:45.108942 11654 sgd_solver.cpp:112] Iteration 5430, lr = 0.1
I0523 23:00:51.383483 11654 solver.cpp:239] Iteration 5440 (1.59371 iter/s, 6.27467s/10 iters), loss = 11.2212
I0523 23:00:51.383535 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.2212 (* 1 = 11.2212 loss)
I0523 23:00:51.653429 11654 sgd_solver.cpp:112] Iteration 5440, lr = 0.1
I0523 23:00:59.398851 11654 solver.cpp:239] Iteration 5450 (1.24766 iter/s, 8.015s/10 iters), loss = 10.975
I0523 23:00:59.398924 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.975 (* 1 = 10.975 loss)
I0523 23:00:59.399291 11654 sgd_solver.cpp:112] Iteration 5450, lr = 0.1
I0523 23:01:06.243744 11654 solver.cpp:239] Iteration 5460 (1.46101 iter/s, 6.84458s/10 iters), loss = 10.8356
I0523 23:01:06.244030 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8356 (* 1 = 10.8356 loss)
I0523 23:01:06.773486 11654 sgd_solver.cpp:112] Iteration 5460, lr = 0.1
I0523 23:01:13.758522 11654 solver.cpp:239] Iteration 5470 (1.33081 iter/s, 7.51424s/10 iters), loss = 9.73253
I0523 23:01:13.758591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.73253 (* 1 = 9.73253 loss)
I0523 23:01:13.758740 11654 sgd_solver.cpp:112] Iteration 5470, lr = 0.1
I0523 23:01:20.099261 11654 solver.cpp:239] Iteration 5480 (1.57718 iter/s, 6.34044s/10 iters), loss = 10.1794
I0523 23:01:20.099320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1794 (* 1 = 10.1794 loss)
I0523 23:01:20.099656 11654 sgd_solver.cpp:112] Iteration 5480, lr = 0.1
I0523 23:01:26.925509 11654 solver.cpp:239] Iteration 5490 (1.465 iter/s, 6.82593s/10 iters), loss = 10.2797
I0523 23:01:26.925563 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2797 (* 1 = 10.2797 loss)
I0523 23:01:26.926112 11654 sgd_solver.cpp:112] Iteration 5490, lr = 0.1
I0523 23:01:33.782428 11654 solver.cpp:239] Iteration 5500 (1.45845 iter/s, 6.8566s/10 iters), loss = 9.93921
I0523 23:01:33.782485 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.93921 (* 1 = 9.93921 loss)
I0523 23:01:33.782502 11654 sgd_solver.cpp:112] Iteration 5500, lr = 0.1
I0523 23:01:40.364526 11654 solver.cpp:239] Iteration 5510 (1.51934 iter/s, 6.5818s/10 iters), loss = 10.6746
I0523 23:01:40.364799 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6746 (* 1 = 10.6746 loss)
I0523 23:01:40.364868 11654 sgd_solver.cpp:112] Iteration 5510, lr = 0.1
I0523 23:01:46.840135 11654 solver.cpp:239] Iteration 5520 (1.54484 iter/s, 6.47316s/10 iters), loss = 9.95754
I0523 23:01:46.840193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95754 (* 1 = 9.95754 loss)
I0523 23:01:46.840422 11654 sgd_solver.cpp:112] Iteration 5520, lr = 0.1
I0523 23:01:54.704285 11654 solver.cpp:239] Iteration 5530 (1.27165 iter/s, 7.86378s/10 iters), loss = 10.0184
I0523 23:01:54.704358 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0184 (* 1 = 10.0184 loss)
I0523 23:01:54.704385 11654 sgd_solver.cpp:112] Iteration 5530, lr = 0.1
I0523 23:02:02.956657 11654 solver.cpp:239] Iteration 5540 (1.21215 iter/s, 8.2498s/10 iters), loss = 10.3417
I0523 23:02:02.956709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3417 (* 1 = 10.3417 loss)
I0523 23:02:02.957208 11654 sgd_solver.cpp:112] Iteration 5540, lr = 0.1
I0523 23:02:10.239333 11654 solver.cpp:239] Iteration 5550 (1.37318 iter/s, 7.28234s/10 iters), loss = 10.7925
I0523 23:02:10.239387 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7925 (* 1 = 10.7925 loss)
I0523 23:02:10.378280 11654 sgd_solver.cpp:112] Iteration 5550, lr = 0.1
I0523 23:02:18.330231 11654 solver.cpp:239] Iteration 5560 (1.23601 iter/s, 8.09054s/10 iters), loss = 10.6704
I0523 23:02:18.330289 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6704 (* 1 = 10.6704 loss)
I0523 23:02:18.330576 11654 sgd_solver.cpp:112] Iteration 5560, lr = 0.1
I0523 23:02:24.783586 11654 solver.cpp:239] Iteration 5570 (1.54965 iter/s, 6.45306s/10 iters), loss = 10.0721
I0523 23:02:24.783638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0721 (* 1 = 10.0721 loss)
I0523 23:02:24.783654 11654 sgd_solver.cpp:112] Iteration 5570, lr = 0.1
I0523 23:02:32.191509 11654 solver.cpp:239] Iteration 5580 (1.35036 iter/s, 7.40544s/10 iters), loss = 10.3257
I0523 23:02:32.191555 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3257 (* 1 = 10.3257 loss)
I0523 23:02:32.191710 11654 sgd_solver.cpp:112] Iteration 5580, lr = 0.1
I0523 23:02:38.360910 11654 solver.cpp:239] Iteration 5590 (1.62098 iter/s, 6.16912s/10 iters), loss = 10.5152
I0523 23:02:38.360968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5152 (* 1 = 10.5152 loss)
I0523 23:02:38.360985 11654 sgd_solver.cpp:112] Iteration 5590, lr = 0.1
I0523 23:02:45.536458 11654 solver.cpp:239] Iteration 5600 (1.39369 iter/s, 7.17522s/10 iters), loss = 9.96334
I0523 23:02:45.536744 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.96334 (* 1 = 9.96334 loss)
I0523 23:02:45.536808 11654 sgd_solver.cpp:112] Iteration 5600, lr = 0.1
I0523 23:02:52.086396 11654 solver.cpp:239] Iteration 5610 (1.52694 iter/s, 6.54905s/10 iters), loss = 10.7082
I0523 23:02:52.086449 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7082 (* 1 = 10.7082 loss)
I0523 23:02:52.086465 11654 sgd_solver.cpp:112] Iteration 5610, lr = 0.1
I0523 23:02:58.656075 11654 solver.cpp:239] Iteration 5620 (1.52236 iter/s, 6.56875s/10 iters), loss = 10.0953
I0523 23:02:58.656121 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0953 (* 1 = 10.0953 loss)
I0523 23:02:58.656235 11654 sgd_solver.cpp:112] Iteration 5620, lr = 0.1
I0523 23:03:05.496781 11654 solver.cpp:239] Iteration 5630 (1.4619 iter/s, 6.84039s/10 iters), loss = 10.7026
I0523 23:03:05.496841 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7026 (* 1 = 10.7026 loss)
I0523 23:03:05.496906 11654 sgd_solver.cpp:112] Iteration 5630, lr = 0.1
I0523 23:03:12.222842 11654 solver.cpp:239] Iteration 5640 (1.48683 iter/s, 6.72573s/10 iters), loss = 10.4896
I0523 23:03:12.222926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4896 (* 1 = 10.4896 loss)
I0523 23:03:12.223151 11654 sgd_solver.cpp:112] Iteration 5640, lr = 0.1
I0523 23:03:18.732278 11654 solver.cpp:239] Iteration 5650 (1.53631 iter/s, 6.50911s/10 iters), loss = 8.57831
I0523 23:03:18.732529 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.57831 (* 1 = 8.57831 loss)
I0523 23:03:18.732708 11654 sgd_solver.cpp:112] Iteration 5650, lr = 0.1
I0523 23:03:25.113719 11654 solver.cpp:239] Iteration 5660 (1.56716 iter/s, 6.38098s/10 iters), loss = 10.5343
I0523 23:03:25.113776 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5343 (* 1 = 10.5343 loss)
I0523 23:03:25.129953 11654 sgd_solver.cpp:112] Iteration 5660, lr = 0.1
I0523 23:03:32.098531 11654 solver.cpp:239] Iteration 5670 (1.43174 iter/s, 6.9845s/10 iters), loss = 9.67674
I0523 23:03:32.098577 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.67674 (* 1 = 9.67674 loss)
I0523 23:03:32.558163 11654 sgd_solver.cpp:112] Iteration 5670, lr = 0.1
I0523 23:03:39.832542 11654 solver.cpp:239] Iteration 5680 (1.29305 iter/s, 7.73367s/10 iters), loss = 10.1564
I0523 23:03:39.832595 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1564 (* 1 = 10.1564 loss)
I0523 23:03:39.832665 11654 sgd_solver.cpp:112] Iteration 5680, lr = 0.1
I0523 23:03:47.202246 11654 solver.cpp:239] Iteration 5690 (1.35697 iter/s, 7.36938s/10 iters), loss = 10.212
I0523 23:03:47.202301 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.212 (* 1 = 10.212 loss)
I0523 23:03:47.202456 11654 sgd_solver.cpp:112] Iteration 5690, lr = 0.1
I0523 23:03:55.143268 11654 solver.cpp:239] Iteration 5700 (1.25934 iter/s, 7.94068s/10 iters), loss = 10.3005
I0523 23:03:55.143445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3005 (* 1 = 10.3005 loss)
I0523 23:03:55.143470 11654 sgd_solver.cpp:112] Iteration 5700, lr = 0.1
I0523 23:04:02.079685 11654 solver.cpp:239] Iteration 5710 (1.44176 iter/s, 6.93595s/10 iters), loss = 11.1484
I0523 23:04:02.079742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.1484 (* 1 = 11.1484 loss)
I0523 23:04:02.080018 11654 sgd_solver.cpp:112] Iteration 5710, lr = 0.1
I0523 23:04:10.786129 11654 solver.cpp:239] Iteration 5720 (1.14863 iter/s, 8.70606s/10 iters), loss = 9.82547
I0523 23:04:10.786197 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.82547 (* 1 = 9.82547 loss)
I0523 23:04:10.786218 11654 sgd_solver.cpp:112] Iteration 5720, lr = 0.1
I0523 23:04:18.813908 11654 solver.cpp:239] Iteration 5730 (1.24574 iter/s, 8.02737s/10 iters), loss = 10.3643
I0523 23:04:18.813951 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3643 (* 1 = 10.3643 loss)
I0523 23:04:18.814023 11654 sgd_solver.cpp:112] Iteration 5730, lr = 0.1
I0523 23:04:28.936492 11654 solver.cpp:239] Iteration 5740 (0.987932 iter/s, 10.1222s/10 iters), loss = 10.9946
I0523 23:04:28.936812 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9946 (* 1 = 10.9946 loss)
I0523 23:04:28.947674 11654 sgd_solver.cpp:112] Iteration 5740, lr = 0.1
I0523 23:04:37.574456 11654 solver.cpp:239] Iteration 5750 (1.15776 iter/s, 8.63737s/10 iters), loss = 10.3967
I0523 23:04:37.574523 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3967 (* 1 = 10.3967 loss)
I0523 23:04:37.574779 11654 sgd_solver.cpp:112] Iteration 5750, lr = 0.1
I0523 23:04:43.666226 11654 solver.cpp:239] Iteration 5760 (1.64164 iter/s, 6.09147s/10 iters), loss = 10.5444
I0523 23:04:43.666290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5444 (* 1 = 10.5444 loss)
I0523 23:04:43.667047 11654 sgd_solver.cpp:112] Iteration 5760, lr = 0.1
I0523 23:04:50.072281 11654 solver.cpp:239] Iteration 5770 (1.5611 iter/s, 6.40575s/10 iters), loss = 9.27474
I0523 23:04:50.072329 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.27474 (* 1 = 9.27474 loss)
I0523 23:04:50.072537 11654 sgd_solver.cpp:112] Iteration 5770, lr = 0.1
I0523 23:04:57.981932 11654 solver.cpp:239] Iteration 5780 (1.26433 iter/s, 7.9093s/10 iters), loss = 10.1155
I0523 23:04:57.981986 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1155 (* 1 = 10.1155 loss)
I0523 23:04:57.982002 11654 sgd_solver.cpp:112] Iteration 5780, lr = 0.1
I0523 23:05:05.219254 11654 solver.cpp:239] Iteration 5790 (1.38221 iter/s, 7.23478s/10 iters), loss = 11.0051
I0523 23:05:05.219347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0051 (* 1 = 11.0051 loss)
I0523 23:05:05.219497 11654 sgd_solver.cpp:112] Iteration 5790, lr = 0.1
I0523 23:05:11.422926 11654 solver.cpp:239] Iteration 5800 (1.61203 iter/s, 6.20335s/10 iters), loss = 10.4871
I0523 23:05:11.422969 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4871 (* 1 = 10.4871 loss)
I0523 23:05:11.422983 11654 sgd_solver.cpp:112] Iteration 5800, lr = 0.1
I0523 23:05:18.551285 11654 solver.cpp:239] Iteration 5810 (1.40304 iter/s, 7.1274s/10 iters), loss = 9.93707
I0523 23:05:18.551337 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.93707 (* 1 = 9.93707 loss)
I0523 23:05:18.551354 11654 sgd_solver.cpp:112] Iteration 5810, lr = 0.1
I0523 23:05:25.921187 11654 solver.cpp:239] Iteration 5820 (1.35734 iter/s, 7.36736s/10 iters), loss = 10.855
I0523 23:05:25.921241 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.855 (* 1 = 10.855 loss)
I0523 23:05:25.921257 11654 sgd_solver.cpp:112] Iteration 5820, lr = 0.1
I0523 23:05:33.810624 11654 solver.cpp:239] Iteration 5830 (1.26757 iter/s, 7.88908s/10 iters), loss = 10.8288
I0523 23:05:33.810683 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8288 (* 1 = 10.8288 loss)
I0523 23:05:33.811092 11654 sgd_solver.cpp:112] Iteration 5830, lr = 0.1
I0523 23:05:40.584543 11654 solver.cpp:239] Iteration 5840 (1.47632 iter/s, 6.7736s/10 iters), loss = 9.43589
I0523 23:05:40.584877 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.43589 (* 1 = 9.43589 loss)
I0523 23:05:40.584995 11654 sgd_solver.cpp:112] Iteration 5840, lr = 0.1
I0523 23:05:48.048799 11654 solver.cpp:239] Iteration 5850 (1.33982 iter/s, 7.46369s/10 iters), loss = 10.3278
I0523 23:05:48.048853 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3278 (* 1 = 10.3278 loss)
I0523 23:05:48.048954 11654 sgd_solver.cpp:112] Iteration 5850, lr = 0.1
I0523 23:05:55.798332 11654 solver.cpp:239] Iteration 5860 (1.29046 iter/s, 7.74919s/10 iters), loss = 10.0239
I0523 23:05:55.798385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0239 (* 1 = 10.0239 loss)
I0523 23:05:56.376631 11654 sgd_solver.cpp:112] Iteration 5860, lr = 0.1
I0523 23:06:04.437110 11654 solver.cpp:239] Iteration 5870 (1.15762 iter/s, 8.63839s/10 iters), loss = 11.3632
I0523 23:06:04.437170 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3632 (* 1 = 11.3632 loss)
I0523 23:06:04.468619 11654 sgd_solver.cpp:112] Iteration 5870, lr = 0.1
I0523 23:06:11.369961 11654 solver.cpp:239] Iteration 5880 (1.44247 iter/s, 6.93253s/10 iters), loss = 9.98911
I0523 23:06:11.370223 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.98911 (* 1 = 9.98911 loss)
I0523 23:06:11.637810 11654 sgd_solver.cpp:112] Iteration 5880, lr = 0.1
I0523 23:06:18.679344 11654 solver.cpp:239] Iteration 5890 (1.3682 iter/s, 7.3089s/10 iters), loss = 10.8206
I0523 23:06:18.679397 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8206 (* 1 = 10.8206 loss)
I0523 23:06:18.904589 11654 sgd_solver.cpp:112] Iteration 5890, lr = 0.1
I0523 23:06:26.314596 11654 solver.cpp:239] Iteration 5900 (1.30977 iter/s, 7.63491s/10 iters), loss = 10.6292
I0523 23:06:26.314642 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6292 (* 1 = 10.6292 loss)
I0523 23:06:26.314657 11654 sgd_solver.cpp:112] Iteration 5900, lr = 0.1
I0523 23:06:32.192009 11654 solver.cpp:239] Iteration 5910 (1.70151 iter/s, 5.87714s/10 iters), loss = 10.7519
I0523 23:06:32.192062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.7519 (* 1 = 10.7519 loss)
I0523 23:06:32.192189 11654 sgd_solver.cpp:112] Iteration 5910, lr = 0.1
I0523 23:06:39.875844 11654 solver.cpp:239] Iteration 5920 (1.30149 iter/s, 7.68349s/10 iters), loss = 9.72822
I0523 23:06:39.875890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.72822 (* 1 = 9.72822 loss)
I0523 23:06:39.875932 11654 sgd_solver.cpp:112] Iteration 5920, lr = 0.1
I0523 23:06:47.503031 11654 solver.cpp:239] Iteration 5930 (1.31116 iter/s, 7.62684s/10 iters), loss = 10.5561
I0523 23:06:47.503304 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5561 (* 1 = 10.5561 loss)
I0523 23:06:47.503358 11654 sgd_solver.cpp:112] Iteration 5930, lr = 0.1
I0523 23:06:53.483472 11654 solver.cpp:239] Iteration 5940 (1.6724 iter/s, 5.97943s/10 iters), loss = 10.74
I0523 23:06:53.483526 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.74 (* 1 = 10.74 loss)
I0523 23:06:53.483758 11654 sgd_solver.cpp:112] Iteration 5940, lr = 0.1
I0523 23:07:00.370626 11654 solver.cpp:239] Iteration 5950 (1.45204 iter/s, 6.88684s/10 iters), loss = 10.3783
I0523 23:07:00.370677 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3783 (* 1 = 10.3783 loss)
I0523 23:07:00.370707 11654 sgd_solver.cpp:112] Iteration 5950, lr = 0.1
I0523 23:07:07.757624 11654 solver.cpp:239] Iteration 5960 (1.35379 iter/s, 7.38667s/10 iters), loss = 9.95574
I0523 23:07:07.757670 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95574 (* 1 = 9.95574 loss)
I0523 23:07:07.757871 11654 sgd_solver.cpp:112] Iteration 5960, lr = 0.1
I0523 23:07:15.807704 11654 solver.cpp:239] Iteration 5970 (1.24228 iter/s, 8.04972s/10 iters), loss = 10.03
I0523 23:07:15.807765 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.03 (* 1 = 10.03 loss)
I0523 23:07:16.403187 11654 sgd_solver.cpp:112] Iteration 5970, lr = 0.1
I0523 23:07:23.965780 11654 solver.cpp:239] Iteration 5980 (1.22583 iter/s, 8.15772s/10 iters), loss = 10.6283
I0523 23:07:23.966058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6283 (* 1 = 10.6283 loss)
I0523 23:07:24.008147 11654 sgd_solver.cpp:112] Iteration 5980, lr = 0.1
I0523 23:07:30.785799 11654 solver.cpp:239] Iteration 5990 (1.46638 iter/s, 6.81953s/10 iters), loss = 9.93352
I0523 23:07:30.785859 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.93352 (* 1 = 9.93352 loss)
I0523 23:07:30.786077 11654 sgd_solver.cpp:112] Iteration 5990, lr = 0.1
I0523 23:07:36.874511 11654 solver.cpp:239] Iteration 6000 (1.64246 iter/s, 6.08843s/10 iters), loss = 10.6304
I0523 23:07:36.874545 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6304 (* 1 = 10.6304 loss)
I0523 23:07:36.874588 11654 sgd_solver.cpp:112] Iteration 6000, lr = 0.1
I0523 23:07:43.471199 11654 solver.cpp:239] Iteration 6010 (1.51598 iter/s, 6.5964s/10 iters), loss = 10.2428
I0523 23:07:43.471254 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2428 (* 1 = 10.2428 loss)
I0523 23:07:43.471483 11654 sgd_solver.cpp:112] Iteration 6010, lr = 0.1
I0523 23:07:50.793774 11654 solver.cpp:239] Iteration 6020 (1.3657 iter/s, 7.32225s/10 iters), loss = 10.5491
I0523 23:07:50.793818 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5491 (* 1 = 10.5491 loss)
I0523 23:07:50.793833 11654 sgd_solver.cpp:112] Iteration 6020, lr = 0.1
I0523 23:07:58.399672 11654 solver.cpp:239] Iteration 6030 (1.31484 iter/s, 7.60549s/10 iters), loss = 10.3847
I0523 23:07:58.399935 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3847 (* 1 = 10.3847 loss)
I0523 23:07:58.399994 11654 sgd_solver.cpp:112] Iteration 6030, lr = 0.1
I0523 23:08:06.028079 11654 solver.cpp:239] Iteration 6040 (1.31118 iter/s, 7.62669s/10 iters), loss = 9.21956
I0523 23:08:06.028132 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.21956 (* 1 = 9.21956 loss)
I0523 23:08:06.028149 11654 sgd_solver.cpp:112] Iteration 6040, lr = 0.1
I0523 23:08:12.105585 11654 solver.cpp:239] Iteration 6050 (1.64549 iter/s, 6.07722s/10 iters), loss = 9.95328
I0523 23:08:12.105638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95328 (* 1 = 9.95328 loss)
I0523 23:08:12.105813 11654 sgd_solver.cpp:112] Iteration 6050, lr = 0.1
I0523 23:08:19.218549 11654 solver.cpp:239] Iteration 6060 (1.40595 iter/s, 7.11263s/10 iters), loss = 10.2891
I0523 23:08:19.218611 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2891 (* 1 = 10.2891 loss)
I0523 23:08:19.237363 11654 sgd_solver.cpp:112] Iteration 6060, lr = 0.1
I0523 23:08:25.442559 11654 solver.cpp:239] Iteration 6070 (1.60676 iter/s, 6.22372s/10 iters), loss = 11.3715
I0523 23:08:25.442612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.3715 (* 1 = 11.3715 loss)
I0523 23:08:25.442672 11654 sgd_solver.cpp:112] Iteration 6070, lr = 0.1
I0523 23:08:31.400113 11654 solver.cpp:239] Iteration 6080 (1.67862 iter/s, 5.95727s/10 iters), loss = 10.0455
I0523 23:08:31.400377 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0455 (* 1 = 10.0455 loss)
I0523 23:08:31.428141 11654 sgd_solver.cpp:112] Iteration 6080, lr = 0.1
I0523 23:08:39.249462 11654 solver.cpp:239] Iteration 6090 (1.27407 iter/s, 7.84883s/10 iters), loss = 9.67068
I0523 23:08:39.249516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.67068 (* 1 = 9.67068 loss)
I0523 23:08:39.249531 11654 sgd_solver.cpp:112] Iteration 6090, lr = 0.1
I0523 23:08:48.849673 11654 solver.cpp:239] Iteration 6100 (1.04169 iter/s, 9.59981s/10 iters), loss = 9.98652
I0523 23:08:48.849725 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.98652 (* 1 = 9.98652 loss)
I0523 23:08:48.849741 11654 sgd_solver.cpp:112] Iteration 6100, lr = 0.1
I0523 23:08:55.232956 11654 solver.cpp:239] Iteration 6110 (1.56668 iter/s, 6.38292s/10 iters), loss = 9.94289
I0523 23:08:55.233007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.94289 (* 1 = 9.94289 loss)
I0523 23:08:55.971374 11654 sgd_solver.cpp:112] Iteration 6110, lr = 0.1
I0523 23:09:02.727144 11654 solver.cpp:239] Iteration 6120 (1.33443 iter/s, 7.49386s/10 iters), loss = 10.8181
I0523 23:09:02.727427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8181 (* 1 = 10.8181 loss)
I0523 23:09:03.006003 11654 sgd_solver.cpp:112] Iteration 6120, lr = 0.1
I0523 23:09:12.361111 11654 solver.cpp:239] Iteration 6130 (1.03806 iter/s, 9.63337s/10 iters), loss = 10.5121
I0523 23:09:12.361166 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5121 (* 1 = 10.5121 loss)
I0523 23:09:12.361460 11654 sgd_solver.cpp:112] Iteration 6130, lr = 0.1
I0523 23:09:20.213161 11654 solver.cpp:239] Iteration 6140 (1.27361 iter/s, 7.85169s/10 iters), loss = 9.32259
I0523 23:09:20.213217 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.32259 (* 1 = 9.32259 loss)
I0523 23:09:20.213233 11654 sgd_solver.cpp:112] Iteration 6140, lr = 0.1
I0523 23:09:28.040585 11654 solver.cpp:239] Iteration 6150 (1.27763 iter/s, 7.82701s/10 iters), loss = 9.32776
I0523 23:09:28.040627 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.32776 (* 1 = 9.32776 loss)
I0523 23:09:28.040685 11654 sgd_solver.cpp:112] Iteration 6150, lr = 0.1
I0523 23:09:35.037329 11654 solver.cpp:239] Iteration 6160 (1.4293 iter/s, 6.99642s/10 iters), loss = 10.3351
I0523 23:09:35.037587 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3351 (* 1 = 10.3351 loss)
I0523 23:09:35.037642 11654 sgd_solver.cpp:112] Iteration 6160, lr = 0.1
I0523 23:09:46.388541 11654 solver.cpp:239] Iteration 6170 (0.881076 iter/s, 11.3498s/10 iters), loss = 10.67
I0523 23:09:46.388594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.67 (* 1 = 10.67 loss)
I0523 23:09:47.525691 11654 sgd_solver.cpp:112] Iteration 6170, lr = 0.1
I0523 23:09:54.144106 11654 solver.cpp:239] Iteration 6180 (1.28946 iter/s, 7.75521s/10 iters), loss = 10.4304
I0523 23:09:54.144186 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4304 (* 1 = 10.4304 loss)
I0523 23:09:54.144606 11654 sgd_solver.cpp:112] Iteration 6180, lr = 0.1
I0523 23:10:02.202461 11654 solver.cpp:239] Iteration 6190 (1.241 iter/s, 8.05799s/10 iters), loss = 10.1363
I0523 23:10:02.202513 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1363 (* 1 = 10.1363 loss)
I0523 23:10:02.202530 11654 sgd_solver.cpp:112] Iteration 6190, lr = 0.1
I0523 23:10:11.177634 11654 solver.cpp:239] Iteration 6200 (1.11423 iter/s, 8.97478s/10 iters), loss = 10.2592
I0523 23:10:11.177738 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2592 (* 1 = 10.2592 loss)
I0523 23:10:11.177757 11654 sgd_solver.cpp:112] Iteration 6200, lr = 0.1
I0523 23:10:18.228968 11654 solver.cpp:239] Iteration 6210 (1.41825 iter/s, 7.05094s/10 iters), loss = 11.4281
I0523 23:10:18.229012 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.4281 (* 1 = 11.4281 loss)
I0523 23:10:18.291281 11654 sgd_solver.cpp:112] Iteration 6210, lr = 0.1
I0523 23:10:25.380103 11654 solver.cpp:239] Iteration 6220 (1.39844 iter/s, 7.15081s/10 iters), loss = 9.91187
I0523 23:10:25.380165 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.91187 (* 1 = 9.91187 loss)
I0523 23:10:25.380185 11654 sgd_solver.cpp:112] Iteration 6220, lr = 0.1
I0523 23:10:32.247970 11654 solver.cpp:239] Iteration 6230 (1.45659 iter/s, 6.86534s/10 iters), loss = 10.3098
I0523 23:10:32.248036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3098 (* 1 = 10.3098 loss)
I0523 23:10:32.250056 11654 sgd_solver.cpp:112] Iteration 6230, lr = 0.1
I0523 23:10:40.112807 11654 solver.cpp:239] Iteration 6240 (1.27154 iter/s, 7.86448s/10 iters), loss = 9.85187
I0523 23:10:40.112840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.85187 (* 1 = 9.85187 loss)
I0523 23:10:40.112854 11654 sgd_solver.cpp:112] Iteration 6240, lr = 0.1
I0523 23:10:48.064653 11654 solver.cpp:239] Iteration 6250 (1.25762 iter/s, 7.9515s/10 iters), loss = 9.96832
I0523 23:10:48.064913 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.96832 (* 1 = 9.96832 loss)
I0523 23:10:48.064972 11654 sgd_solver.cpp:112] Iteration 6250, lr = 0.1
I0523 23:10:55.542393 11654 solver.cpp:239] Iteration 6260 (1.3374 iter/s, 7.47722s/10 iters), loss = 10.0975
I0523 23:10:55.542446 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0975 (* 1 = 10.0975 loss)
I0523 23:10:56.999027 11654 sgd_solver.cpp:112] Iteration 6260, lr = 0.1
I0523 23:11:06.276809 11654 solver.cpp:239] Iteration 6270 (0.931623 iter/s, 10.734s/10 iters), loss = 11.0739
I0523 23:11:06.276875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 11.0739 (* 1 = 11.0739 loss)
I0523 23:11:06.277308 11654 sgd_solver.cpp:112] Iteration 6270, lr = 0.1
I0523 23:11:13.313792 11654 solver.cpp:239] Iteration 6280 (1.42113 iter/s, 7.03666s/10 iters), loss = 9.92301
I0523 23:11:13.313833 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.92301 (* 1 = 9.92301 loss)
I0523 23:11:13.313846 11654 sgd_solver.cpp:112] Iteration 6280, lr = 0.1
I0523 23:11:20.344671 11654 solver.cpp:239] Iteration 6290 (1.42238 iter/s, 7.03049s/10 iters), loss = 10.6722
I0523 23:11:20.344810 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6722 (* 1 = 10.6722 loss)
I0523 23:11:20.344825 11654 sgd_solver.cpp:112] Iteration 6290, lr = 0.1
I0523 23:11:29.726193 11654 solver.cpp:239] Iteration 6300 (1.06598 iter/s, 9.381s/10 iters), loss = 9.97353
I0523 23:11:29.726246 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.97353 (* 1 = 9.97353 loss)
I0523 23:11:30.287925 11654 sgd_solver.cpp:112] Iteration 6300, lr = 0.1
I0523 23:11:36.425902 11654 solver.cpp:239] Iteration 6310 (1.49267 iter/s, 6.69941s/10 iters), loss = 10.8104
I0523 23:11:36.425948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8104 (* 1 = 10.8104 loss)
I0523 23:11:36.426184 11654 sgd_solver.cpp:112] Iteration 6310, lr = 0.1
I0523 23:11:46.259481 11654 solver.cpp:239] Iteration 6320 (1.01697 iter/s, 9.83316s/10 iters), loss = 9.44418
I0523 23:11:46.259534 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.44418 (* 1 = 9.44418 loss)
I0523 23:11:46.259551 11654 sgd_solver.cpp:112] Iteration 6320, lr = 0.1
I0523 23:11:52.924540 11654 solver.cpp:239] Iteration 6330 (1.50074 iter/s, 6.6634s/10 iters), loss = 9.79001
I0523 23:11:52.924703 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.79001 (* 1 = 9.79001 loss)
I0523 23:11:52.925091 11654 sgd_solver.cpp:112] Iteration 6330, lr = 0.1
I0523 23:12:00.102439 11654 solver.cpp:239] Iteration 6340 (1.39325 iter/s, 7.17747s/10 iters), loss = 9.34541
I0523 23:12:00.102488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.34541 (* 1 = 9.34541 loss)
I0523 23:12:00.102507 11654 sgd_solver.cpp:112] Iteration 6340, lr = 0.1
I0523 23:12:08.168314 11654 solver.cpp:239] Iteration 6350 (1.24019 iter/s, 8.0633s/10 iters), loss = 10.5474
I0523 23:12:08.168366 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5474 (* 1 = 10.5474 loss)
I0523 23:12:08.645028 11654 sgd_solver.cpp:112] Iteration 6350, lr = 0.1
I0523 23:12:15.458712 11654 solver.cpp:239] Iteration 6360 (1.37173 iter/s, 7.29006s/10 iters), loss = 9.95542
I0523 23:12:15.458755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95542 (* 1 = 9.95542 loss)
I0523 23:12:15.458770 11654 sgd_solver.cpp:112] Iteration 6360, lr = 0.1
I0523 23:12:22.778741 11654 solver.cpp:239] Iteration 6370 (1.36618 iter/s, 7.31966s/10 iters), loss = 10.6184
I0523 23:12:22.778796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6184 (* 1 = 10.6184 loss)
I0523 23:12:22.778815 11654 sgd_solver.cpp:112] Iteration 6370, lr = 0.1
I0523 23:12:29.376107 11654 solver.cpp:239] Iteration 6380 (1.51634 iter/s, 6.59482s/10 iters), loss = 10.1306
I0523 23:12:29.376389 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1306 (* 1 = 10.1306 loss)
I0523 23:12:30.050572 11654 sgd_solver.cpp:112] Iteration 6380, lr = 0.1
I0523 23:12:37.056648 11654 solver.cpp:239] Iteration 6390 (1.30208 iter/s, 7.68003s/10 iters), loss = 10.0634
I0523 23:12:37.056691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0634 (* 1 = 10.0634 loss)
I0523 23:12:37.056706 11654 sgd_solver.cpp:112] Iteration 6390, lr = 0.1
I0523 23:12:43.498127 11654 solver.cpp:239] Iteration 6400 (1.55251 iter/s, 6.44118s/10 iters), loss = 9.80717
I0523 23:12:43.498184 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.80717 (* 1 = 9.80717 loss)
I0523 23:12:43.498314 11654 sgd_solver.cpp:112] Iteration 6400, lr = 0.1
I0523 23:12:50.105099 11654 solver.cpp:239] Iteration 6410 (1.51362 iter/s, 6.60666s/10 iters), loss = 10.4588
I0523 23:12:50.105136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4588 (* 1 = 10.4588 loss)
I0523 23:12:50.105166 11654 sgd_solver.cpp:112] Iteration 6410, lr = 0.1
I0523 23:12:56.193102 11654 solver.cpp:239] Iteration 6420 (1.64265 iter/s, 6.08773s/10 iters), loss = 10.6416
I0523 23:12:56.193159 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6416 (* 1 = 10.6416 loss)
I0523 23:12:56.482583 11654 sgd_solver.cpp:112] Iteration 6420, lr = 0.1
I0523 23:13:03.115145 11654 solver.cpp:239] Iteration 6430 (1.44472 iter/s, 6.92173s/10 iters), loss = 10.0113
I0523 23:13:03.115310 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0113 (* 1 = 10.0113 loss)
I0523 23:13:03.115326 11654 sgd_solver.cpp:112] Iteration 6430, lr = 0.1
I0523 23:13:09.324877 11654 solver.cpp:239] Iteration 6440 (1.61103 iter/s, 6.20722s/10 iters), loss = 9.9143
I0523 23:13:09.324928 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.9143 (* 1 = 9.9143 loss)
I0523 23:13:09.324941 11654 sgd_solver.cpp:112] Iteration 6440, lr = 0.1
I0523 23:13:16.128836 11654 solver.cpp:239] Iteration 6450 (1.4698 iter/s, 6.80365s/10 iters), loss = 9.76714
I0523 23:13:16.128875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.76714 (* 1 = 9.76714 loss)
I0523 23:13:16.737649 11654 sgd_solver.cpp:112] Iteration 6450, lr = 0.1
I0523 23:13:23.959662 11654 solver.cpp:239] Iteration 6460 (1.27706 iter/s, 7.83048s/10 iters), loss = 9.51819
I0523 23:13:23.959725 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.51819 (* 1 = 9.51819 loss)
I0523 23:13:23.960078 11654 sgd_solver.cpp:112] Iteration 6460, lr = 0.1
I0523 23:13:30.324657 11654 solver.cpp:239] Iteration 6470 (1.57117 iter/s, 6.36469s/10 iters), loss = 10.1279
I0523 23:13:30.324720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1279 (* 1 = 10.1279 loss)
I0523 23:13:30.324842 11654 sgd_solver.cpp:112] Iteration 6470, lr = 0.1
I0523 23:13:37.578310 11654 solver.cpp:239] Iteration 6480 (1.37868 iter/s, 7.25332s/10 iters), loss = 9.81075
I0523 23:13:37.578429 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.81075 (* 1 = 9.81075 loss)
I0523 23:13:37.578689 11654 sgd_solver.cpp:112] Iteration 6480, lr = 0.1
I0523 23:13:45.325636 11654 solver.cpp:239] Iteration 6490 (1.29084 iter/s, 7.74691s/10 iters), loss = 9.89234
I0523 23:13:45.325690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.89234 (* 1 = 9.89234 loss)
I0523 23:13:45.521262 11654 sgd_solver.cpp:112] Iteration 6490, lr = 0.1
I0523 23:13:53.882562 11654 solver.cpp:239] Iteration 6500 (1.1687 iter/s, 8.55655s/10 iters), loss = 10.1463
I0523 23:13:53.882624 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1463 (* 1 = 10.1463 loss)
I0523 23:13:53.882642 11654 sgd_solver.cpp:112] Iteration 6500, lr = 0.1
I0523 23:14:01.161579 11654 solver.cpp:239] Iteration 6510 (1.37387 iter/s, 7.27869s/10 iters), loss = 9.72007
I0523 23:14:01.161628 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.72007 (* 1 = 9.72007 loss)
I0523 23:14:01.161761 11654 sgd_solver.cpp:112] Iteration 6510, lr = 0.1
I0523 23:14:09.512236 11654 solver.cpp:239] Iteration 6520 (1.19756 iter/s, 8.35028s/10 iters), loss = 9.80809
I0523 23:14:09.512336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.80809 (* 1 = 9.80809 loss)
I0523 23:14:09.512353 11654 sgd_solver.cpp:112] Iteration 6520, lr = 0.1
I0523 23:14:16.931960 11654 solver.cpp:239] Iteration 6530 (1.34783 iter/s, 7.41932s/10 iters), loss = 9.85584
I0523 23:14:16.932014 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.85584 (* 1 = 9.85584 loss)
I0523 23:14:16.932265 11654 sgd_solver.cpp:112] Iteration 6530, lr = 0.1
I0523 23:14:23.451004 11654 solver.cpp:239] Iteration 6540 (1.53404 iter/s, 6.51874s/10 iters), loss = 9.82729
I0523 23:14:23.451064 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.82729 (* 1 = 9.82729 loss)
I0523 23:14:23.451270 11654 sgd_solver.cpp:112] Iteration 6540, lr = 0.1
I0523 23:14:29.818385 11654 solver.cpp:239] Iteration 6550 (1.57058 iter/s, 6.36709s/10 iters), loss = 9.53471
I0523 23:14:29.818436 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.53471 (* 1 = 9.53471 loss)
I0523 23:14:30.029675 11654 sgd_solver.cpp:112] Iteration 6550, lr = 0.1
I0523 23:14:37.043606 11654 solver.cpp:239] Iteration 6560 (1.3841 iter/s, 7.22489s/10 iters), loss = 9.9999
I0523 23:14:37.043669 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.9999 (* 1 = 9.9999 loss)
I0523 23:14:37.043689 11654 sgd_solver.cpp:112] Iteration 6560, lr = 0.1
I0523 23:14:43.761574 11654 solver.cpp:239] Iteration 6570 (1.48863 iter/s, 6.71757s/10 iters), loss = 10.4572
I0523 23:14:43.761888 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4572 (* 1 = 10.4572 loss)
I0523 23:14:43.762178 11654 sgd_solver.cpp:112] Iteration 6570, lr = 0.1
I0523 23:14:50.818842 11654 solver.cpp:239] Iteration 6580 (1.41708 iter/s, 7.05674s/10 iters), loss = 10.5642
I0523 23:14:50.818887 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5642 (* 1 = 10.5642 loss)
I0523 23:14:50.818902 11654 sgd_solver.cpp:112] Iteration 6580, lr = 0.1
I0523 23:14:56.928246 11654 solver.cpp:239] Iteration 6590 (1.6369 iter/s, 6.10912s/10 iters), loss = 10.9084
I0523 23:14:56.928297 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.9084 (* 1 = 10.9084 loss)
I0523 23:14:56.928534 11654 sgd_solver.cpp:112] Iteration 6590, lr = 0.1
I0523 23:15:02.983340 11654 solver.cpp:239] Iteration 6600 (1.65158 iter/s, 6.05481s/10 iters), loss = 8.99346
I0523 23:15:02.983398 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.99346 (* 1 = 8.99346 loss)
I0523 23:15:02.983768 11654 sgd_solver.cpp:112] Iteration 6600, lr = 0.1
I0523 23:15:09.652448 11654 solver.cpp:239] Iteration 6610 (1.49952 iter/s, 6.66879s/10 iters), loss = 9.82908
I0523 23:15:09.652508 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.82908 (* 1 = 9.82908 loss)
I0523 23:15:09.653091 11654 sgd_solver.cpp:112] Iteration 6610, lr = 0.1
I0523 23:15:16.788426 11654 solver.cpp:239] Iteration 6620 (1.40141 iter/s, 7.13566s/10 iters), loss = 10.2527
I0523 23:15:16.788518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2527 (* 1 = 10.2527 loss)
I0523 23:15:16.788533 11654 sgd_solver.cpp:112] Iteration 6620, lr = 0.1
I0523 23:15:24.077908 11654 solver.cpp:239] Iteration 6630 (1.37192 iter/s, 7.28907s/10 iters), loss = 9.68204
I0523 23:15:24.077973 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.68204 (* 1 = 9.68204 loss)
I0523 23:15:24.079905 11654 sgd_solver.cpp:112] Iteration 6630, lr = 0.1
I0523 23:15:31.316287 11654 solver.cpp:239] Iteration 6640 (1.38159 iter/s, 7.23805s/10 iters), loss = 10.5167
I0523 23:15:31.316337 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.5167 (* 1 = 10.5167 loss)
I0523 23:15:31.316632 11654 sgd_solver.cpp:112] Iteration 6640, lr = 0.1
I0523 23:15:37.667938 11654 solver.cpp:239] Iteration 6650 (1.57447 iter/s, 6.35135s/10 iters), loss = 8.93655
I0523 23:15:37.667991 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.93655 (* 1 = 8.93655 loss)
I0523 23:15:37.995118 11654 sgd_solver.cpp:112] Iteration 6650, lr = 0.1
I0523 23:15:44.852461 11654 solver.cpp:239] Iteration 6660 (1.39194 iter/s, 7.18421s/10 iters), loss = 9.93055
I0523 23:15:44.852501 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.93055 (* 1 = 9.93055 loss)
I0523 23:15:45.060439 11654 sgd_solver.cpp:112] Iteration 6660, lr = 0.1
I0523 23:15:52.633276 11654 solver.cpp:239] Iteration 6670 (1.28527 iter/s, 7.78046s/10 iters), loss = 9.72193
I0523 23:15:52.633539 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.72193 (* 1 = 9.72193 loss)
I0523 23:15:52.633682 11654 sgd_solver.cpp:112] Iteration 6670, lr = 0.1
I0523 23:15:58.848227 11654 solver.cpp:239] Iteration 6680 (1.60914 iter/s, 6.2145s/10 iters), loss = 10.1233
I0523 23:15:58.848268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1233 (* 1 = 10.1233 loss)
I0523 23:15:58.848294 11654 sgd_solver.cpp:112] Iteration 6680, lr = 0.1
I0523 23:16:07.323707 11654 solver.cpp:239] Iteration 6690 (1.17993 iter/s, 8.4751s/10 iters), loss = 10.0146
I0523 23:16:07.323776 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0146 (* 1 = 10.0146 loss)
I0523 23:16:07.323824 11654 sgd_solver.cpp:112] Iteration 6690, lr = 0.1
I0523 23:16:14.113579 11654 solver.cpp:239] Iteration 6700 (1.47285 iter/s, 6.78956s/10 iters), loss = 9.68249
I0523 23:16:14.113616 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.68249 (* 1 = 9.68249 loss)
I0523 23:16:14.113636 11654 sgd_solver.cpp:112] Iteration 6700, lr = 0.1
I0523 23:16:20.337600 11654 solver.cpp:239] Iteration 6710 (1.60675 iter/s, 6.22374s/10 iters), loss = 10.2276
I0523 23:16:20.337662 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2276 (* 1 = 10.2276 loss)
I0523 23:16:21.707672 11654 sgd_solver.cpp:112] Iteration 6710, lr = 0.1
I0523 23:16:31.609112 11654 solver.cpp:239] Iteration 6720 (0.88723 iter/s, 11.271s/10 iters), loss = 9.6426
I0523 23:16:31.609320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.6426 (* 1 = 9.6426 loss)
I0523 23:16:31.609501 11654 sgd_solver.cpp:112] Iteration 6720, lr = 0.1
I0523 23:16:39.648957 11654 solver.cpp:239] Iteration 6730 (1.24388 iter/s, 8.03937s/10 iters), loss = 9.75069
I0523 23:16:39.649004 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.75069 (* 1 = 9.75069 loss)
I0523 23:16:39.981822 11654 sgd_solver.cpp:112] Iteration 6730, lr = 0.1
I0523 23:16:46.627027 11654 solver.cpp:239] Iteration 6740 (1.43313 iter/s, 6.97775s/10 iters), loss = 9.7143
I0523 23:16:46.627086 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.7143 (* 1 = 9.7143 loss)
I0523 23:16:46.627485 11654 sgd_solver.cpp:112] Iteration 6740, lr = 0.1
I0523 23:16:53.854996 11654 solver.cpp:239] Iteration 6750 (1.38358 iter/s, 7.22763s/10 iters), loss = 10.0856
I0523 23:16:53.855067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0856 (* 1 = 10.0856 loss)
I0523 23:16:54.022091 11654 sgd_solver.cpp:112] Iteration 6750, lr = 0.1
I0523 23:17:01.636123 11654 solver.cpp:239] Iteration 6760 (1.28522 iter/s, 7.78077s/10 iters), loss = 9.9865
I0523 23:17:01.636391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.9865 (* 1 = 9.9865 loss)
I0523 23:17:01.636448 11654 sgd_solver.cpp:112] Iteration 6760, lr = 0.1
I0523 23:17:08.867738 11654 solver.cpp:239] Iteration 6770 (1.38292 iter/s, 7.23109s/10 iters), loss = 9.38175
I0523 23:17:08.867779 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.38175 (* 1 = 9.38175 loss)
I0523 23:17:08.870585 11654 sgd_solver.cpp:112] Iteration 6770, lr = 0.1
I0523 23:17:16.483950 11654 solver.cpp:239] Iteration 6780 (1.31305 iter/s, 7.61587s/10 iters), loss = 10.0802
I0523 23:17:16.484017 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0802 (* 1 = 10.0802 loss)
I0523 23:17:16.484040 11654 sgd_solver.cpp:112] Iteration 6780, lr = 0.1
I0523 23:17:22.704766 11654 solver.cpp:239] Iteration 6790 (1.60785 iter/s, 6.21949s/10 iters), loss = 9.7976
I0523 23:17:22.704813 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.7976 (* 1 = 9.7976 loss)
I0523 23:17:22.705018 11654 sgd_solver.cpp:112] Iteration 6790, lr = 0.1
I0523 23:17:29.166787 11654 solver.cpp:239] Iteration 6800 (1.54757 iter/s, 6.46173s/10 iters), loss = 10.1983
I0523 23:17:29.166854 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1983 (* 1 = 10.1983 loss)
I0523 23:17:29.166963 11654 sgd_solver.cpp:112] Iteration 6800, lr = 0.1
I0523 23:17:36.586156 11654 solver.cpp:239] Iteration 6810 (1.34789 iter/s, 7.41901s/10 iters), loss = 9.78331
I0523 23:17:36.586354 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.78331 (* 1 = 9.78331 loss)
I0523 23:17:36.586485 11654 sgd_solver.cpp:112] Iteration 6810, lr = 0.1
I0523 23:17:43.554653 11654 solver.cpp:239] Iteration 6820 (1.43512 iter/s, 6.96804s/10 iters), loss = 9.20117
I0523 23:17:43.554740 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.20117 (* 1 = 9.20117 loss)
I0523 23:17:43.556900 11654 sgd_solver.cpp:112] Iteration 6820, lr = 0.1
I0523 23:17:51.809087 11654 solver.cpp:239] Iteration 6830 (1.21152 iter/s, 8.25407s/10 iters), loss = 9.94556
I0523 23:17:51.809149 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.94556 (* 1 = 9.94556 loss)
I0523 23:17:52.494369 11654 sgd_solver.cpp:112] Iteration 6830, lr = 0.1
I0523 23:18:00.237517 11654 solver.cpp:239] Iteration 6840 (1.18651 iter/s, 8.42806s/10 iters), loss = 9.4932
I0523 23:18:00.237571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.4932 (* 1 = 9.4932 loss)
I0523 23:18:00.316366 11654 sgd_solver.cpp:112] Iteration 6840, lr = 0.1
I0523 23:18:07.166642 11654 solver.cpp:239] Iteration 6850 (1.44325 iter/s, 6.9288s/10 iters), loss = 9.73303
I0523 23:18:07.166822 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.73303 (* 1 = 9.73303 loss)
I0523 23:18:07.166843 11654 sgd_solver.cpp:112] Iteration 6850, lr = 0.1
I0523 23:18:14.524459 11654 solver.cpp:239] Iteration 6860 (1.35928 iter/s, 7.35681s/10 iters), loss = 9.77266
I0523 23:18:14.524516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.77266 (* 1 = 9.77266 loss)
I0523 23:18:14.524533 11654 sgd_solver.cpp:112] Iteration 6860, lr = 0.1
I0523 23:18:21.750126 11654 solver.cpp:239] Iteration 6870 (1.38444 iter/s, 7.22314s/10 iters), loss = 9.21189
I0523 23:18:21.750176 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.21189 (* 1 = 9.21189 loss)
I0523 23:18:21.750193 11654 sgd_solver.cpp:112] Iteration 6870, lr = 0.1
I0523 23:18:28.565184 11654 solver.cpp:239] Iteration 6880 (1.46741 iter/s, 6.81473s/10 iters), loss = 9.82562
I0523 23:18:28.565274 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.82562 (* 1 = 9.82562 loss)
I0523 23:18:28.571586 11654 sgd_solver.cpp:112] Iteration 6880, lr = 0.1
I0523 23:18:35.453449 11654 solver.cpp:239] Iteration 6890 (1.45182 iter/s, 6.88792s/10 iters), loss = 10.4257
I0523 23:18:35.453506 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4257 (* 1 = 10.4257 loss)
I0523 23:18:36.443509 11654 sgd_solver.cpp:112] Iteration 6890, lr = 0.1
I0523 23:18:45.485829 11654 solver.cpp:239] Iteration 6900 (0.996816 iter/s, 10.0319s/10 iters), loss = 9.00171
I0523 23:18:45.486093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.00171 (* 1 = 9.00171 loss)
I0523 23:18:46.202489 11654 sgd_solver.cpp:112] Iteration 6900, lr = 0.1
I0523 23:18:54.398046 11654 solver.cpp:239] Iteration 6910 (1.12212 iter/s, 8.91167s/10 iters), loss = 9.23017
I0523 23:18:54.398100 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.23017 (* 1 = 9.23017 loss)
I0523 23:18:54.398119 11654 sgd_solver.cpp:112] Iteration 6910, lr = 0.1
I0523 23:19:02.213896 11654 solver.cpp:239] Iteration 6920 (1.27952 iter/s, 7.81544s/10 iters), loss = 9.89042
I0523 23:19:02.213938 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.89042 (* 1 = 9.89042 loss)
I0523 23:19:03.228768 11654 sgd_solver.cpp:112] Iteration 6920, lr = 0.1
I0523 23:19:12.154328 11654 solver.cpp:239] Iteration 6930 (1.00604 iter/s, 9.94001s/10 iters), loss = 10.2142
I0523 23:19:12.154386 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2142 (* 1 = 10.2142 loss)
I0523 23:19:12.782363 11654 sgd_solver.cpp:112] Iteration 6930, lr = 0.1
I0523 23:19:19.144796 11654 solver.cpp:239] Iteration 6940 (1.43059 iter/s, 6.99014s/10 iters), loss = 9.30433
I0523 23:19:19.145089 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.30433 (* 1 = 9.30433 loss)
I0523 23:19:19.145150 11654 sgd_solver.cpp:112] Iteration 6940, lr = 0.1
I0523 23:19:26.609691 11654 solver.cpp:239] Iteration 6950 (1.33979 iter/s, 7.46383s/10 iters), loss = 10.0195
I0523 23:19:26.609745 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0195 (* 1 = 10.0195 loss)
I0523 23:19:26.668331 11654 sgd_solver.cpp:112] Iteration 6950, lr = 0.1
I0523 23:19:33.877848 11654 solver.cpp:239] Iteration 6960 (1.37593 iter/s, 7.26782s/10 iters), loss = 9.22583
I0523 23:19:33.877915 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.22583 (* 1 = 9.22583 loss)
I0523 23:19:33.878226 11654 sgd_solver.cpp:112] Iteration 6960, lr = 0.1
I0523 23:19:40.908985 11654 solver.cpp:239] Iteration 6970 (1.42231 iter/s, 7.03081s/10 iters), loss = 9.54559
I0523 23:19:40.909026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.54559 (* 1 = 9.54559 loss)
I0523 23:19:40.909039 11654 sgd_solver.cpp:112] Iteration 6970, lr = 0.1
I0523 23:19:48.376494 11654 solver.cpp:239] Iteration 6980 (1.33959 iter/s, 7.46495s/10 iters), loss = 9.35834
I0523 23:19:48.376549 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.35834 (* 1 = 9.35834 loss)
I0523 23:19:48.377655 11654 sgd_solver.cpp:112] Iteration 6980, lr = 0.1
I0523 23:19:54.865278 11654 solver.cpp:239] Iteration 6990 (1.54119 iter/s, 6.48848s/10 iters), loss = 9.95778
I0523 23:19:54.865469 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95778 (* 1 = 9.95778 loss)
I0523 23:19:54.865491 11654 sgd_solver.cpp:112] Iteration 6990, lr = 0.1
I0523 23:20:02.259070 11654 solver.cpp:239] Iteration 7000 (1.35259 iter/s, 7.39321s/10 iters), loss = 10.883
I0523 23:20:02.259111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.883 (* 1 = 10.883 loss)
I0523 23:20:02.267915 11654 sgd_solver.cpp:112] Iteration 7000, lr = 0.1
I0523 23:20:09.971143 11654 solver.cpp:239] Iteration 7010 (1.29673 iter/s, 7.71173s/10 iters), loss = 10.1044
I0523 23:20:09.971197 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1044 (* 1 = 10.1044 loss)
I0523 23:20:10.839416 11654 sgd_solver.cpp:112] Iteration 7010, lr = 0.1
I0523 23:20:19.676983 11654 solver.cpp:239] Iteration 7020 (1.03035 iter/s, 9.70542s/10 iters), loss = 9.98398
I0523 23:20:19.677037 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.98398 (* 1 = 9.98398 loss)
I0523 23:20:19.923174 11654 sgd_solver.cpp:112] Iteration 7020, lr = 0.1
I0523 23:20:28.291200 11654 solver.cpp:239] Iteration 7030 (1.16092 iter/s, 8.61383s/10 iters), loss = 9.88036
I0523 23:20:28.291366 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.88036 (* 1 = 9.88036 loss)
I0523 23:20:28.291616 11654 sgd_solver.cpp:112] Iteration 7030, lr = 0.1
I0523 23:20:35.589781 11654 solver.cpp:239] Iteration 7040 (1.37021 iter/s, 7.29815s/10 iters), loss = 10.0436
I0523 23:20:35.589836 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0436 (* 1 = 10.0436 loss)
I0523 23:20:36.338505 11654 sgd_solver.cpp:112] Iteration 7040, lr = 0.1
I0523 23:20:43.442131 11654 solver.cpp:239] Iteration 7050 (1.27356 iter/s, 7.852s/10 iters), loss = 9.40641
I0523 23:20:43.442173 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.40641 (* 1 = 9.40641 loss)
I0523 23:20:43.442186 11654 sgd_solver.cpp:112] Iteration 7050, lr = 0.1
I0523 23:20:50.373550 11654 solver.cpp:239] Iteration 7060 (1.44277 iter/s, 6.93111s/10 iters), loss = 8.92111
I0523 23:20:50.373601 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.92111 (* 1 = 8.92111 loss)
I0523 23:20:50.373616 11654 sgd_solver.cpp:112] Iteration 7060, lr = 0.1
I0523 23:20:57.079120 11654 solver.cpp:239] Iteration 7070 (1.49186 iter/s, 6.70306s/10 iters), loss = 9.61031
I0523 23:20:57.079160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.61031 (* 1 = 9.61031 loss)
I0523 23:20:57.093901 11654 sgd_solver.cpp:112] Iteration 7070, lr = 0.1
I0523 23:21:05.782644 11654 solver.cpp:239] Iteration 7080 (1.14901 iter/s, 8.70312s/10 iters), loss = 9.84452
I0523 23:21:05.783094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.84452 (* 1 = 9.84452 loss)
I0523 23:21:06.031034 11654 sgd_solver.cpp:112] Iteration 7080, lr = 0.1
I0523 23:21:13.296537 11654 solver.cpp:239] Iteration 7090 (1.33099 iter/s, 7.51321s/10 iters), loss = 9.45442
I0523 23:21:13.296591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.45442 (* 1 = 9.45442 loss)
I0523 23:21:13.296604 11654 sgd_solver.cpp:112] Iteration 7090, lr = 0.1
I0523 23:21:23.487299 11654 solver.cpp:239] Iteration 7100 (0.981382 iter/s, 10.1897s/10 iters), loss = 9.88349
I0523 23:21:23.487367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.88349 (* 1 = 9.88349 loss)
I0523 23:21:23.487617 11654 sgd_solver.cpp:112] Iteration 7100, lr = 0.1
I0523 23:21:30.284183 11654 solver.cpp:239] Iteration 7110 (1.47133 iter/s, 6.79657s/10 iters), loss = 10.246
I0523 23:21:30.284224 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.246 (* 1 = 10.246 loss)
I0523 23:21:30.284245 11654 sgd_solver.cpp:112] Iteration 7110, lr = 0.1
I0523 23:21:37.197348 11654 solver.cpp:239] Iteration 7120 (1.44658 iter/s, 6.91285s/10 iters), loss = 10.3064
I0523 23:21:37.197491 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3064 (* 1 = 10.3064 loss)
I0523 23:21:37.957000 11654 sgd_solver.cpp:112] Iteration 7120, lr = 0.1
I0523 23:21:44.748098 11654 solver.cpp:239] Iteration 7130 (1.32445 iter/s, 7.55033s/10 iters), loss = 9.44724
I0523 23:21:44.748152 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.44724 (* 1 = 9.44724 loss)
I0523 23:21:44.748244 11654 sgd_solver.cpp:112] Iteration 7130, lr = 0.1
I0523 23:21:51.834683 11654 solver.cpp:239] Iteration 7140 (1.41118 iter/s, 7.08627s/10 iters), loss = 9.72868
I0523 23:21:51.834738 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.72868 (* 1 = 9.72868 loss)
I0523 23:21:52.075208 11654 sgd_solver.cpp:112] Iteration 7140, lr = 0.1
I0523 23:21:59.066010 11654 solver.cpp:239] Iteration 7150 (1.38294 iter/s, 7.23099s/10 iters), loss = 9.99124
I0523 23:21:59.066064 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.99124 (* 1 = 9.99124 loss)
I0523 23:21:59.066215 11654 sgd_solver.cpp:112] Iteration 7150, lr = 0.1
I0523 23:22:06.004439 11654 solver.cpp:239] Iteration 7160 (1.44131 iter/s, 6.93812s/10 iters), loss = 9.41022
I0523 23:22:06.004482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.41022 (* 1 = 9.41022 loss)
I0523 23:22:06.004496 11654 sgd_solver.cpp:112] Iteration 7160, lr = 0.1
I0523 23:22:13.136382 11654 solver.cpp:239] Iteration 7170 (1.40233 iter/s, 7.13099s/10 iters), loss = 10.3959
I0523 23:22:13.136526 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3959 (* 1 = 10.3959 loss)
I0523 23:22:13.380242 11654 sgd_solver.cpp:112] Iteration 7170, lr = 0.1
I0523 23:22:19.728755 11654 solver.cpp:239] Iteration 7180 (1.51699 iter/s, 6.59198s/10 iters), loss = 9.89038
I0523 23:22:19.728802 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.89038 (* 1 = 9.89038 loss)
I0523 23:22:19.728868 11654 sgd_solver.cpp:112] Iteration 7180, lr = 0.1
I0523 23:22:26.047929 11654 solver.cpp:239] Iteration 7190 (1.58256 iter/s, 6.31887s/10 iters), loss = 9.26159
I0523 23:22:26.047993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.26159 (* 1 = 9.26159 loss)
I0523 23:22:26.048014 11654 sgd_solver.cpp:112] Iteration 7190, lr = 0.1
I0523 23:22:32.256184 11654 solver.cpp:239] Iteration 7200 (1.611 iter/s, 6.20733s/10 iters), loss = 9.51231
I0523 23:22:32.256232 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.51231 (* 1 = 9.51231 loss)
I0523 23:22:32.256248 11654 sgd_solver.cpp:112] Iteration 7200, lr = 0.1
I0523 23:22:39.135157 11654 solver.cpp:239] Iteration 7210 (1.45377 iter/s, 6.87867s/10 iters), loss = 8.96873
I0523 23:22:39.135198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.96873 (* 1 = 8.96873 loss)
I0523 23:22:39.953683 11654 sgd_solver.cpp:112] Iteration 7210, lr = 0.1
I0523 23:22:46.992383 11654 solver.cpp:239] Iteration 7220 (1.27277 iter/s, 7.85688s/10 iters), loss = 9.43516
I0523 23:22:46.992677 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.43516 (* 1 = 9.43516 loss)
I0523 23:22:46.992738 11654 sgd_solver.cpp:112] Iteration 7220, lr = 0.1
I0523 23:22:53.607764 11654 solver.cpp:239] Iteration 7230 (1.51224 iter/s, 6.61272s/10 iters), loss = 10.2226
I0523 23:22:53.607827 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2226 (* 1 = 10.2226 loss)
I0523 23:22:53.608319 11654 sgd_solver.cpp:112] Iteration 7230, lr = 0.1
I0523 23:23:00.145699 11654 solver.cpp:239] Iteration 7240 (1.52961 iter/s, 6.53763s/10 iters), loss = 9.5802
I0523 23:23:00.145748 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.5802 (* 1 = 9.5802 loss)
I0523 23:23:00.146015 11654 sgd_solver.cpp:112] Iteration 7240, lr = 0.1
I0523 23:23:06.562538 11654 solver.cpp:239] Iteration 7250 (1.55847 iter/s, 6.41654s/10 iters), loss = 9.60627
I0523 23:23:06.562592 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.60627 (* 1 = 9.60627 loss)
I0523 23:23:06.562955 11654 sgd_solver.cpp:112] Iteration 7250, lr = 0.1
I0523 23:23:12.714243 11654 solver.cpp:239] Iteration 7260 (1.62564 iter/s, 6.15142s/10 iters), loss = 9.37562
I0523 23:23:12.714292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.37562 (* 1 = 9.37562 loss)
I0523 23:23:12.714797 11654 sgd_solver.cpp:112] Iteration 7260, lr = 0.1
I0523 23:23:18.878038 11654 solver.cpp:239] Iteration 7270 (1.62245 iter/s, 6.16351s/10 iters), loss = 9.20203
I0523 23:23:18.878315 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.20203 (* 1 = 9.20203 loss)
I0523 23:23:19.150662 11654 sgd_solver.cpp:112] Iteration 7270, lr = 0.1
I0523 23:23:26.749446 11654 solver.cpp:239] Iteration 7280 (1.27051 iter/s, 7.87088s/10 iters), loss = 9.70128
I0523 23:23:26.749500 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.70128 (* 1 = 9.70128 loss)
I0523 23:23:26.749517 11654 sgd_solver.cpp:112] Iteration 7280, lr = 0.1
I0523 23:23:33.208170 11654 solver.cpp:239] Iteration 7290 (1.54861 iter/s, 6.45739s/10 iters), loss = 9.70466
I0523 23:23:33.208211 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.70466 (* 1 = 9.70466 loss)
I0523 23:23:33.208225 11654 sgd_solver.cpp:112] Iteration 7290, lr = 0.1
I0523 23:23:40.034934 11654 solver.cpp:239] Iteration 7300 (1.4649 iter/s, 6.82639s/10 iters), loss = 9.73095
I0523 23:23:40.034978 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.73095 (* 1 = 9.73095 loss)
I0523 23:23:40.035104 11654 sgd_solver.cpp:112] Iteration 7300, lr = 0.1
I0523 23:23:46.895587 11654 solver.cpp:239] Iteration 7310 (1.45765 iter/s, 6.86035s/10 iters), loss = 9.75795
I0523 23:23:46.895639 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.75795 (* 1 = 9.75795 loss)
I0523 23:23:46.895808 11654 sgd_solver.cpp:112] Iteration 7310, lr = 0.1
I0523 23:23:55.610549 11654 solver.cpp:239] Iteration 7320 (1.1475 iter/s, 8.71459s/10 iters), loss = 9.43264
I0523 23:23:55.610678 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.43264 (* 1 = 9.43264 loss)
I0523 23:23:55.610709 11654 sgd_solver.cpp:112] Iteration 7320, lr = 0.1
I0523 23:24:02.236127 11654 solver.cpp:239] Iteration 7330 (1.50939 iter/s, 6.62517s/10 iters), loss = 9.9085
I0523 23:24:02.236173 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.9085 (* 1 = 9.9085 loss)
I0523 23:24:02.236274 11654 sgd_solver.cpp:112] Iteration 7330, lr = 0.1
I0523 23:24:09.900496 11654 solver.cpp:239] Iteration 7340 (1.3048 iter/s, 7.66403s/10 iters), loss = 8.38865
I0523 23:24:09.900550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.38865 (* 1 = 8.38865 loss)
I0523 23:24:09.900564 11654 sgd_solver.cpp:112] Iteration 7340, lr = 0.1
I0523 23:24:16.262358 11654 solver.cpp:239] Iteration 7350 (1.57194 iter/s, 6.36157s/10 iters), loss = 10.2336
I0523 23:24:16.262423 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2336 (* 1 = 10.2336 loss)
I0523 23:24:16.262717 11654 sgd_solver.cpp:112] Iteration 7350, lr = 0.1
I0523 23:24:24.240712 11654 solver.cpp:239] Iteration 7360 (1.25345 iter/s, 7.978s/10 iters), loss = 9.95344
I0523 23:24:24.240752 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95344 (* 1 = 9.95344 loss)
I0523 23:24:24.240767 11654 sgd_solver.cpp:112] Iteration 7360, lr = 0.1
I0523 23:24:30.827944 11654 solver.cpp:239] Iteration 7370 (1.51866 iter/s, 6.58477s/10 iters), loss = 9.98747
I0523 23:24:30.828239 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.98747 (* 1 = 9.98747 loss)
I0523 23:24:30.828286 11654 sgd_solver.cpp:112] Iteration 7370, lr = 0.1
I0523 23:24:37.037894 11654 solver.cpp:239] Iteration 7380 (1.61048 iter/s, 6.20932s/10 iters), loss = 9.66171
I0523 23:24:37.037933 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.66171 (* 1 = 9.66171 loss)
I0523 23:24:37.037950 11654 sgd_solver.cpp:112] Iteration 7380, lr = 0.1
I0523 23:24:43.711652 11654 solver.cpp:239] Iteration 7390 (1.49847 iter/s, 6.67346s/10 iters), loss = 9.58497
I0523 23:24:43.711704 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.58497 (* 1 = 9.58497 loss)
I0523 23:24:43.711884 11654 sgd_solver.cpp:112] Iteration 7390, lr = 0.1
I0523 23:24:51.158892 11654 solver.cpp:239] Iteration 7400 (1.34284 iter/s, 7.44691s/10 iters), loss = 9.69414
I0523 23:24:51.158941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.69414 (* 1 = 9.69414 loss)
I0523 23:24:51.158963 11654 sgd_solver.cpp:112] Iteration 7400, lr = 0.1
I0523 23:24:57.773576 11654 solver.cpp:239] Iteration 7410 (1.51186 iter/s, 6.61438s/10 iters), loss = 9.43548
I0523 23:24:57.773630 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.43548 (* 1 = 9.43548 loss)
I0523 23:24:57.773797 11654 sgd_solver.cpp:112] Iteration 7410, lr = 0.1
I0523 23:25:04.323288 11654 solver.cpp:239] Iteration 7420 (1.52685 iter/s, 6.54942s/10 iters), loss = 9.63849
I0523 23:25:04.323446 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.63849 (* 1 = 9.63849 loss)
I0523 23:25:04.323472 11654 sgd_solver.cpp:112] Iteration 7420, lr = 0.1
I0523 23:25:11.456053 11654 solver.cpp:239] Iteration 7430 (1.40217 iter/s, 7.13181s/10 iters), loss = 9.33433
I0523 23:25:11.456115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.33433 (* 1 = 9.33433 loss)
I0523 23:25:11.456562 11654 sgd_solver.cpp:112] Iteration 7430, lr = 0.1
I0523 23:25:18.137899 11654 solver.cpp:239] Iteration 7440 (1.49666 iter/s, 6.68154s/10 iters), loss = 9.79626
I0523 23:25:18.137939 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.79626 (* 1 = 9.79626 loss)
I0523 23:25:18.137953 11654 sgd_solver.cpp:112] Iteration 7440, lr = 0.1
I0523 23:25:26.842439 11654 solver.cpp:239] Iteration 7450 (1.14887 iter/s, 8.70417s/10 iters), loss = 9.46775
I0523 23:25:26.842496 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.46775 (* 1 = 9.46775 loss)
I0523 23:25:26.847097 11654 sgd_solver.cpp:112] Iteration 7450, lr = 0.1
I0523 23:25:33.036406 11654 solver.cpp:239] Iteration 7460 (1.61455 iter/s, 6.19368s/10 iters), loss = 9.8198
I0523 23:25:33.036456 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.8198 (* 1 = 9.8198 loss)
I0523 23:25:33.036569 11654 sgd_solver.cpp:112] Iteration 7460, lr = 0.1
I0523 23:25:39.743643 11654 solver.cpp:239] Iteration 7470 (1.49099 iter/s, 6.70693s/10 iters), loss = 10.2667
I0523 23:25:39.743899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2667 (* 1 = 10.2667 loss)
I0523 23:25:39.743991 11654 sgd_solver.cpp:112] Iteration 7470, lr = 0.1
I0523 23:25:45.860766 11654 solver.cpp:239] Iteration 7480 (1.63488 iter/s, 6.11667s/10 iters), loss = 9.8503
I0523 23:25:45.860816 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.8503 (* 1 = 9.8503 loss)
I0523 23:25:45.861018 11654 sgd_solver.cpp:112] Iteration 7480, lr = 0.1
I0523 23:25:53.313989 11654 solver.cpp:239] Iteration 7490 (1.34176 iter/s, 7.4529s/10 iters), loss = 10.1879
I0523 23:25:53.314028 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1879 (* 1 = 10.1879 loss)
I0523 23:25:53.314043 11654 sgd_solver.cpp:112] Iteration 7490, lr = 0.1
I0523 23:25:59.919505 11654 solver.cpp:239] Iteration 7500 (1.51397 iter/s, 6.60515s/10 iters), loss = 10.698
I0523 23:25:59.919558 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.698 (* 1 = 10.698 loss)
I0523 23:25:59.988616 11654 sgd_solver.cpp:112] Iteration 7500, lr = 0.1
I0523 23:26:06.281435 11654 solver.cpp:239] Iteration 7510 (1.57192 iter/s, 6.36164s/10 iters), loss = 9.69375
I0523 23:26:06.281472 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.69375 (* 1 = 9.69375 loss)
I0523 23:26:06.281553 11654 sgd_solver.cpp:112] Iteration 7510, lr = 0.1
I0523 23:26:13.233471 11654 solver.cpp:239] Iteration 7520 (1.43849 iter/s, 6.95173s/10 iters), loss = 10.2455
I0523 23:26:13.233660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2455 (* 1 = 10.2455 loss)
I0523 23:26:13.233697 11654 sgd_solver.cpp:112] Iteration 7520, lr = 0.1
I0523 23:26:21.063333 11654 solver.cpp:239] Iteration 7530 (1.27757 iter/s, 7.82734s/10 iters), loss = 9.12634
I0523 23:26:21.063374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.12634 (* 1 = 9.12634 loss)
I0523 23:26:21.153033 11654 sgd_solver.cpp:112] Iteration 7530, lr = 0.1
I0523 23:26:27.505129 11654 solver.cpp:239] Iteration 7540 (1.55243 iter/s, 6.4415s/10 iters), loss = 8.80247
I0523 23:26:27.505182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.80247 (* 1 = 8.80247 loss)
I0523 23:26:27.505198 11654 sgd_solver.cpp:112] Iteration 7540, lr = 0.1
I0523 23:26:36.227653 11654 solver.cpp:239] Iteration 7550 (1.14651 iter/s, 8.72214s/10 iters), loss = 8.87319
I0523 23:26:36.227716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.87319 (* 1 = 8.87319 loss)
I0523 23:26:36.228093 11654 sgd_solver.cpp:112] Iteration 7550, lr = 0.1
I0523 23:26:43.120811 11654 solver.cpp:239] Iteration 7560 (1.45078 iter/s, 6.89285s/10 iters), loss = 10.2025
I0523 23:26:43.120851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.2025 (* 1 = 10.2025 loss)
I0523 23:26:43.601433 11654 sgd_solver.cpp:112] Iteration 7560, lr = 0.1
I0523 23:26:50.857525 11654 solver.cpp:239] Iteration 7570 (1.29259 iter/s, 7.73638s/10 iters), loss = 9.42561
I0523 23:26:50.857563 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.42561 (* 1 = 9.42561 loss)
I0523 23:26:50.857576 11654 sgd_solver.cpp:112] Iteration 7570, lr = 0.1
I0523 23:26:57.620934 11654 solver.cpp:239] Iteration 7580 (1.47861 iter/s, 6.7631s/10 iters), loss = 9.99996
I0523 23:26:57.620997 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.99996 (* 1 = 9.99996 loss)
I0523 23:26:57.895906 11654 sgd_solver.cpp:112] Iteration 7580, lr = 0.1
I0523 23:27:04.984676 11654 solver.cpp:239] Iteration 7590 (1.35807 iter/s, 7.3634s/10 iters), loss = 10.1867
I0523 23:27:04.984730 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1867 (* 1 = 10.1867 loss)
I0523 23:27:04.984935 11654 sgd_solver.cpp:112] Iteration 7590, lr = 0.1
I0523 23:27:11.194849 11654 solver.cpp:239] Iteration 7600 (1.61033 iter/s, 6.20989s/10 iters), loss = 10.0412
I0523 23:27:11.194901 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0412 (* 1 = 10.0412 loss)
I0523 23:27:11.194916 11654 sgd_solver.cpp:112] Iteration 7600, lr = 0.1
I0523 23:27:17.773201 11654 solver.cpp:239] Iteration 7610 (1.52024 iter/s, 6.5779s/10 iters), loss = 9.43556
I0523 23:27:17.773452 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.43556 (* 1 = 9.43556 loss)
I0523 23:27:17.773509 11654 sgd_solver.cpp:112] Iteration 7610, lr = 0.1
I0523 23:27:23.930968 11654 solver.cpp:239] Iteration 7620 (1.62408 iter/s, 6.15732s/10 iters), loss = 9.17497
I0523 23:27:23.931025 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.17497 (* 1 = 9.17497 loss)
I0523 23:27:23.931041 11654 sgd_solver.cpp:112] Iteration 7620, lr = 0.1
I0523 23:27:30.750097 11654 solver.cpp:239] Iteration 7630 (1.46653 iter/s, 6.81882s/10 iters), loss = 9.10548
I0523 23:27:30.750141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.10548 (* 1 = 9.10548 loss)
I0523 23:27:30.750306 11654 sgd_solver.cpp:112] Iteration 7630, lr = 0.1
I0523 23:27:37.530917 11654 solver.cpp:239] Iteration 7640 (1.47481 iter/s, 6.78051s/10 iters), loss = 9.73522
I0523 23:27:37.530967 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.73522 (* 1 = 9.73522 loss)
I0523 23:27:37.530982 11654 sgd_solver.cpp:112] Iteration 7640, lr = 0.1
I0523 23:27:45.431484 11654 solver.cpp:239] Iteration 7650 (1.2658 iter/s, 7.90015s/10 iters), loss = 9.23986
I0523 23:27:45.431541 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.23986 (* 1 = 9.23986 loss)
I0523 23:27:45.431560 11654 sgd_solver.cpp:112] Iteration 7650, lr = 0.1
I0523 23:27:51.768573 11654 solver.cpp:239] Iteration 7660 (1.57863 iter/s, 6.33459s/10 iters), loss = 9.95179
I0523 23:27:51.768836 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95179 (* 1 = 9.95179 loss)
I0523 23:27:51.768890 11654 sgd_solver.cpp:112] Iteration 7660, lr = 0.1
I0523 23:27:59.611320 11654 solver.cpp:239] Iteration 7670 (1.27548 iter/s, 7.84017s/10 iters), loss = 9.8826
I0523 23:27:59.611377 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.8826 (* 1 = 9.8826 loss)
I0523 23:27:59.938235 11654 sgd_solver.cpp:112] Iteration 7670, lr = 0.1
I0523 23:28:06.401182 11654 solver.cpp:239] Iteration 7680 (1.47285 iter/s, 6.78955s/10 iters), loss = 9.74593
I0523 23:28:06.401247 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.74593 (* 1 = 9.74593 loss)
I0523 23:28:06.401546 11654 sgd_solver.cpp:112] Iteration 7680, lr = 0.1
I0523 23:28:12.887303 11654 solver.cpp:239] Iteration 7690 (1.54182 iter/s, 6.48582s/10 iters), loss = 8.37369
I0523 23:28:12.887342 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.37369 (* 1 = 8.37369 loss)
I0523 23:28:12.887362 11654 sgd_solver.cpp:112] Iteration 7690, lr = 0.1
I0523 23:28:20.382295 11654 solver.cpp:239] Iteration 7700 (1.33428 iter/s, 7.49466s/10 iters), loss = 9.72445
I0523 23:28:20.382355 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.72445 (* 1 = 9.72445 loss)
I0523 23:28:20.390100 11654 sgd_solver.cpp:112] Iteration 7700, lr = 0.1
I0523 23:28:27.501302 11654 solver.cpp:239] Iteration 7710 (1.40475 iter/s, 7.11869s/10 iters), loss = 9.15597
I0523 23:28:27.501435 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.15597 (* 1 = 9.15597 loss)
I0523 23:28:28.092681 11654 sgd_solver.cpp:112] Iteration 7710, lr = 0.1
I0523 23:28:34.519740 11654 solver.cpp:239] Iteration 7720 (1.42491 iter/s, 7.01801s/10 iters), loss = 9.63083
I0523 23:28:34.519800 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.63083 (* 1 = 9.63083 loss)
I0523 23:28:34.519824 11654 sgd_solver.cpp:112] Iteration 7720, lr = 0.1
I0523 23:28:40.785405 11654 solver.cpp:239] Iteration 7730 (1.59609 iter/s, 6.26533s/10 iters), loss = 8.77656
I0523 23:28:40.785473 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.77656 (* 1 = 8.77656 loss)
I0523 23:28:40.785881 11654 sgd_solver.cpp:112] Iteration 7730, lr = 0.1
I0523 23:28:48.985601 11654 solver.cpp:239] Iteration 7740 (1.21954 iter/s, 8.19983s/10 iters), loss = 8.80487
I0523 23:28:48.985643 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.80487 (* 1 = 8.80487 loss)
I0523 23:28:48.985694 11654 sgd_solver.cpp:112] Iteration 7740, lr = 0.1
I0523 23:28:55.208304 11654 solver.cpp:239] Iteration 7750 (1.60709 iter/s, 6.22242s/10 iters), loss = 9.14768
I0523 23:28:55.208359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.14768 (* 1 = 9.14768 loss)
I0523 23:28:55.445745 11654 sgd_solver.cpp:112] Iteration 7750, lr = 0.1
I0523 23:29:01.360379 11654 solver.cpp:239] Iteration 7760 (1.62555 iter/s, 6.15178s/10 iters), loss = 9.28044
I0523 23:29:01.360641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.28044 (* 1 = 9.28044 loss)
I0523 23:29:01.360697 11654 sgd_solver.cpp:112] Iteration 7760, lr = 0.1
I0523 23:29:08.169128 11654 solver.cpp:239] Iteration 7770 (1.46901 iter/s, 6.80731s/10 iters), loss = 8.7836
I0523 23:29:08.169194 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.7836 (* 1 = 8.7836 loss)
I0523 23:29:08.169380 11654 sgd_solver.cpp:112] Iteration 7770, lr = 0.1
I0523 23:29:14.288745 11654 solver.cpp:239] Iteration 7780 (1.63417 iter/s, 6.11933s/10 iters), loss = 9.1847
I0523 23:29:14.288789 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.1847 (* 1 = 9.1847 loss)
I0523 23:29:14.289039 11654 sgd_solver.cpp:112] Iteration 7780, lr = 0.1
I0523 23:29:20.897516 11654 solver.cpp:239] Iteration 7790 (1.51321 iter/s, 6.60846s/10 iters), loss = 9.12963
I0523 23:29:20.897581 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.12963 (* 1 = 9.12963 loss)
I0523 23:29:20.897795 11654 sgd_solver.cpp:112] Iteration 7790, lr = 0.1
I0523 23:29:27.599424 11654 solver.cpp:239] Iteration 7800 (1.49218 iter/s, 6.7016s/10 iters), loss = 9.50332
I0523 23:29:27.599478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.50332 (* 1 = 9.50332 loss)
I0523 23:29:27.599494 11654 sgd_solver.cpp:112] Iteration 7800, lr = 0.1
I0523 23:29:35.698851 11654 solver.cpp:239] Iteration 7810 (1.23472 iter/s, 8.099s/10 iters), loss = 9.06476
I0523 23:29:35.699115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.06476 (* 1 = 9.06476 loss)
I0523 23:29:35.699501 11654 sgd_solver.cpp:112] Iteration 7810, lr = 0.1
I0523 23:29:42.066133 11654 solver.cpp:239] Iteration 7820 (1.57064 iter/s, 6.36682s/10 iters), loss = 9.24177
I0523 23:29:42.066175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.24177 (* 1 = 9.24177 loss)
I0523 23:29:42.066295 11654 sgd_solver.cpp:112] Iteration 7820, lr = 0.1
I0523 23:29:49.332245 11654 solver.cpp:239] Iteration 7830 (1.37631 iter/s, 7.26579s/10 iters), loss = 9.1177
I0523 23:29:49.332300 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.1177 (* 1 = 9.1177 loss)
I0523 23:29:49.332319 11654 sgd_solver.cpp:112] Iteration 7830, lr = 0.1
I0523 23:29:57.431696 11654 solver.cpp:239] Iteration 7840 (1.23471 iter/s, 8.09904s/10 iters), loss = 9.33947
I0523 23:29:57.431735 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.33947 (* 1 = 9.33947 loss)
I0523 23:29:57.431763 11654 sgd_solver.cpp:112] Iteration 7840, lr = 0.1
I0523 23:30:05.229473 11654 solver.cpp:239] Iteration 7850 (1.28247 iter/s, 7.79744s/10 iters), loss = 9.79314
I0523 23:30:05.229528 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.79314 (* 1 = 9.79314 loss)
I0523 23:30:05.230784 11654 sgd_solver.cpp:112] Iteration 7850, lr = 0.1
I0523 23:30:14.046510 11654 solver.cpp:239] Iteration 7860 (1.13422 iter/s, 8.81666s/10 iters), loss = 9.1401
I0523 23:30:14.046819 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.1401 (* 1 = 9.1401 loss)
I0523 23:30:14.046880 11654 sgd_solver.cpp:112] Iteration 7860, lr = 0.1
I0523 23:30:21.864104 11654 solver.cpp:239] Iteration 7870 (1.27926 iter/s, 7.81701s/10 iters), loss = 10.6444
I0523 23:30:21.864161 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.6444 (* 1 = 10.6444 loss)
I0523 23:30:22.191107 11654 sgd_solver.cpp:112] Iteration 7870, lr = 0.1
I0523 23:30:29.064162 11654 solver.cpp:239] Iteration 7880 (1.38894 iter/s, 7.19973s/10 iters), loss = 10.1554
I0523 23:30:29.064215 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1554 (* 1 = 10.1554 loss)
I0523 23:30:29.239555 11654 sgd_solver.cpp:112] Iteration 7880, lr = 0.1
I0523 23:30:35.976302 11654 solver.cpp:239] Iteration 7890 (1.4468 iter/s, 6.91182s/10 iters), loss = 10.0333
I0523 23:30:35.976364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0333 (* 1 = 10.0333 loss)
I0523 23:30:35.976714 11654 sgd_solver.cpp:112] Iteration 7890, lr = 0.1
I0523 23:30:43.977655 11654 solver.cpp:239] Iteration 7900 (1.24984 iter/s, 8.00099s/10 iters), loss = 9.58428
I0523 23:30:43.977695 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.58428 (* 1 = 9.58428 loss)
I0523 23:30:43.977741 11654 sgd_solver.cpp:112] Iteration 7900, lr = 0.1
I0523 23:30:50.362268 11654 solver.cpp:239] Iteration 7910 (1.56634 iter/s, 6.38432s/10 iters), loss = 9.23764
I0523 23:30:50.362581 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.23764 (* 1 = 9.23764 loss)
I0523 23:30:50.862722 11654 sgd_solver.cpp:112] Iteration 7910, lr = 0.1
I0523 23:30:59.126269 11654 solver.cpp:239] Iteration 7920 (1.14111 iter/s, 8.76342s/10 iters), loss = 8.80803
I0523 23:30:59.126317 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.80803 (* 1 = 8.80803 loss)
I0523 23:30:59.126583 11654 sgd_solver.cpp:112] Iteration 7920, lr = 0.1
I0523 23:31:05.345952 11654 solver.cpp:239] Iteration 7930 (1.60787 iter/s, 6.21939s/10 iters), loss = 9.06749
I0523 23:31:05.346007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.06749 (* 1 = 9.06749 loss)
I0523 23:31:05.783780 11654 sgd_solver.cpp:112] Iteration 7930, lr = 0.1
I0523 23:31:13.714877 11654 solver.cpp:239] Iteration 7940 (1.19495 iter/s, 8.36856s/10 iters), loss = 9.67048
I0523 23:31:13.714936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.67048 (* 1 = 9.67048 loss)
I0523 23:31:13.994069 11654 sgd_solver.cpp:112] Iteration 7940, lr = 0.1
I0523 23:31:21.821475 11654 solver.cpp:239] Iteration 7950 (1.23362 iter/s, 8.10623s/10 iters), loss = 9.44427
I0523 23:31:21.821758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.44427 (* 1 = 9.44427 loss)
I0523 23:31:21.822109 11654 sgd_solver.cpp:112] Iteration 7950, lr = 0.1
I0523 23:31:29.035683 11654 solver.cpp:239] Iteration 7960 (1.38625 iter/s, 7.2137s/10 iters), loss = 9.84751
I0523 23:31:29.035753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.84751 (* 1 = 9.84751 loss)
I0523 23:31:29.036103 11654 sgd_solver.cpp:112] Iteration 7960, lr = 0.1
I0523 23:31:36.148058 11654 solver.cpp:239] Iteration 7970 (1.40606 iter/s, 7.11205s/10 iters), loss = 10.044
I0523 23:31:36.148106 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.044 (* 1 = 10.044 loss)
I0523 23:31:36.148306 11654 sgd_solver.cpp:112] Iteration 7970, lr = 0.1
I0523 23:31:42.575605 11654 solver.cpp:239] Iteration 7980 (1.55588 iter/s, 6.42725s/10 iters), loss = 9.8299
I0523 23:31:42.575660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.8299 (* 1 = 9.8299 loss)
I0523 23:31:42.575723 11654 sgd_solver.cpp:112] Iteration 7980, lr = 0.1
I0523 23:31:49.060698 11654 solver.cpp:239] Iteration 7990 (1.54207 iter/s, 6.4848s/10 iters), loss = 8.83445
I0523 23:31:49.060747 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.83445 (* 1 = 8.83445 loss)
I0523 23:31:49.060763 11654 sgd_solver.cpp:112] Iteration 7990, lr = 0.1
I0523 23:31:58.708511 11654 solver.cpp:239] Iteration 8000 (1.03679 iter/s, 9.64518s/10 iters), loss = 9.22646
I0523 23:31:58.708734 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.22646 (* 1 = 9.22646 loss)
I0523 23:31:58.708797 11654 sgd_solver.cpp:112] Iteration 8000, lr = 0.1
I0523 23:32:06.505228 11654 solver.cpp:239] Iteration 8010 (1.28268 iter/s, 7.79619s/10 iters), loss = 8.49305
I0523 23:32:06.505285 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.49305 (* 1 = 8.49305 loss)
I0523 23:32:06.505312 11654 sgd_solver.cpp:112] Iteration 8010, lr = 0.1
I0523 23:32:12.568580 11654 solver.cpp:239] Iteration 8020 (1.64933 iter/s, 6.06307s/10 iters), loss = 9.17411
I0523 23:32:12.568619 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.17411 (* 1 = 9.17411 loss)
I0523 23:32:12.568894 11654 sgd_solver.cpp:112] Iteration 8020, lr = 0.1
I0523 23:32:18.987915 11654 solver.cpp:239] Iteration 8030 (1.55786 iter/s, 6.41905s/10 iters), loss = 9.12466
I0523 23:32:18.987967 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.12466 (* 1 = 9.12466 loss)
I0523 23:32:18.987994 11654 sgd_solver.cpp:112] Iteration 8030, lr = 0.1
I0523 23:32:26.799100 11654 solver.cpp:239] Iteration 8040 (1.28027 iter/s, 7.81083s/10 iters), loss = 9.55247
I0523 23:32:26.799162 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.55247 (* 1 = 9.55247 loss)
I0523 23:32:26.799294 11654 sgd_solver.cpp:112] Iteration 8040, lr = 0.1
I0523 23:32:34.490737 11654 solver.cpp:239] Iteration 8050 (1.30017 iter/s, 7.69129s/10 iters), loss = 9.05215
I0523 23:32:34.490989 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.05215 (* 1 = 9.05215 loss)
I0523 23:32:34.491030 11654 sgd_solver.cpp:112] Iteration 8050, lr = 0.1
I0523 23:32:43.955797 11654 solver.cpp:239] Iteration 8060 (1.05659 iter/s, 9.46445s/10 iters), loss = 9.54615
I0523 23:32:43.955865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.54615 (* 1 = 9.54615 loss)
I0523 23:32:43.956029 11654 sgd_solver.cpp:112] Iteration 8060, lr = 0.1
I0523 23:32:50.292819 11654 solver.cpp:239] Iteration 8070 (1.5781 iter/s, 6.33672s/10 iters), loss = 9.77436
I0523 23:32:50.292871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.77436 (* 1 = 9.77436 loss)
I0523 23:32:50.319291 11654 sgd_solver.cpp:112] Iteration 8070, lr = 0.1
I0523 23:32:56.532452 11654 solver.cpp:239] Iteration 8080 (1.60273 iter/s, 6.23935s/10 iters), loss = 9.20023
I0523 23:32:56.532497 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.20023 (* 1 = 9.20023 loss)
I0523 23:32:56.532665 11654 sgd_solver.cpp:112] Iteration 8080, lr = 0.1
I0523 23:33:03.041249 11654 solver.cpp:239] Iteration 8090 (1.53646 iter/s, 6.50849s/10 iters), loss = 10.1709
I0523 23:33:03.041309 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1709 (* 1 = 10.1709 loss)
I0523 23:33:03.041496 11654 sgd_solver.cpp:112] Iteration 8090, lr = 0.1
I0523 23:33:09.288501 11654 solver.cpp:239] Iteration 8100 (1.60078 iter/s, 6.24696s/10 iters), loss = 9.46028
I0523 23:33:09.288774 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.46028 (* 1 = 9.46028 loss)
I0523 23:33:09.349534 11654 sgd_solver.cpp:112] Iteration 8100, lr = 0.1
I0523 23:33:17.637104 11654 solver.cpp:239] Iteration 8110 (1.19788 iter/s, 8.34806s/10 iters), loss = 10.4833
I0523 23:33:17.637162 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.4833 (* 1 = 10.4833 loss)
I0523 23:33:17.637609 11654 sgd_solver.cpp:112] Iteration 8110, lr = 0.1
I0523 23:33:24.641147 11654 solver.cpp:239] Iteration 8120 (1.42781 iter/s, 7.00371s/10 iters), loss = 8.85734
I0523 23:33:24.641202 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.85734 (* 1 = 8.85734 loss)
I0523 23:33:24.641748 11654 sgd_solver.cpp:112] Iteration 8120, lr = 0.1
I0523 23:33:31.771116 11654 solver.cpp:239] Iteration 8130 (1.40259 iter/s, 7.12964s/10 iters), loss = 9.47146
I0523 23:33:31.771168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.47146 (* 1 = 9.47146 loss)
I0523 23:33:31.771333 11654 sgd_solver.cpp:112] Iteration 8130, lr = 0.1
I0523 23:33:38.742841 11654 solver.cpp:239] Iteration 8140 (1.43443 iter/s, 6.97141s/10 iters), loss = 8.83711
I0523 23:33:38.742905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.83711 (* 1 = 8.83711 loss)
I0523 23:33:38.742923 11654 sgd_solver.cpp:112] Iteration 8140, lr = 0.1
I0523 23:33:45.769479 11654 solver.cpp:239] Iteration 8150 (1.42322 iter/s, 7.02633s/10 iters), loss = 8.87584
I0523 23:33:45.769585 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.87584 (* 1 = 8.87584 loss)
I0523 23:33:45.769603 11654 sgd_solver.cpp:112] Iteration 8150, lr = 0.1
I0523 23:33:54.630662 11654 solver.cpp:239] Iteration 8160 (1.12858 iter/s, 8.86071s/10 iters), loss = 9.35171
I0523 23:33:54.630746 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.35171 (* 1 = 9.35171 loss)
I0523 23:33:54.987233 11654 sgd_solver.cpp:112] Iteration 8160, lr = 0.1
I0523 23:34:01.908417 11654 solver.cpp:239] Iteration 8170 (1.37412 iter/s, 7.27739s/10 iters), loss = 8.18118
I0523 23:34:01.908478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.18118 (* 1 = 8.18118 loss)
I0523 23:34:01.908604 11654 sgd_solver.cpp:112] Iteration 8170, lr = 0.1
I0523 23:34:11.804747 11654 solver.cpp:239] Iteration 8180 (1.01052 iter/s, 9.8959s/10 iters), loss = 8.29233
I0523 23:34:11.804801 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.29233 (* 1 = 8.29233 loss)
I0523 23:34:11.804817 11654 sgd_solver.cpp:112] Iteration 8180, lr = 0.1
I0523 23:34:18.190445 11654 solver.cpp:239] Iteration 8190 (1.56607 iter/s, 6.38541s/10 iters), loss = 9.02682
I0523 23:34:18.190770 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.02682 (* 1 = 9.02682 loss)
I0523 23:34:18.190829 11654 sgd_solver.cpp:112] Iteration 8190, lr = 0.1
I0523 23:34:26.164014 11654 solver.cpp:239] Iteration 8200 (1.25456 iter/s, 7.97094s/10 iters), loss = 8.93007
I0523 23:34:26.164063 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.93007 (* 1 = 8.93007 loss)
I0523 23:34:26.165843 11654 sgd_solver.cpp:112] Iteration 8200, lr = 0.1
I0523 23:34:33.399958 11654 solver.cpp:239] Iteration 8210 (1.38205 iter/s, 7.23561s/10 iters), loss = 10.8365
I0523 23:34:33.400019 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.8365 (* 1 = 10.8365 loss)
I0523 23:34:33.400192 11654 sgd_solver.cpp:112] Iteration 8210, lr = 0.1
I0523 23:34:40.262799 11654 solver.cpp:239] Iteration 8220 (1.45719 iter/s, 6.86253s/10 iters), loss = 9.88469
I0523 23:34:40.262856 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.88469 (* 1 = 9.88469 loss)
I0523 23:34:40.262874 11654 sgd_solver.cpp:112] Iteration 8220, lr = 0.1
I0523 23:34:47.123078 11654 solver.cpp:239] Iteration 8230 (1.45773 iter/s, 6.85997s/10 iters), loss = 8.90757
I0523 23:34:47.123121 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.90757 (* 1 = 8.90757 loss)
I0523 23:34:47.123216 11654 sgd_solver.cpp:112] Iteration 8230, lr = 0.1
I0523 23:34:54.681262 11654 solver.cpp:239] Iteration 8240 (1.32313 iter/s, 7.55785s/10 iters), loss = 9.25747
I0523 23:34:54.681411 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.25747 (* 1 = 9.25747 loss)
I0523 23:34:54.681427 11654 sgd_solver.cpp:112] Iteration 8240, lr = 0.1
I0523 23:35:02.009791 11654 solver.cpp:239] Iteration 8250 (1.36462 iter/s, 7.32807s/10 iters), loss = 9.54238
I0523 23:35:02.009855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.54238 (* 1 = 9.54238 loss)
I0523 23:35:02.009997 11654 sgd_solver.cpp:112] Iteration 8250, lr = 0.1
I0523 23:35:08.861804 11654 solver.cpp:239] Iteration 8260 (1.45949 iter/s, 6.85169s/10 iters), loss = 8.93785
I0523 23:35:08.861872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.93785 (* 1 = 8.93785 loss)
I0523 23:35:08.862161 11654 sgd_solver.cpp:112] Iteration 8260, lr = 0.1
I0523 23:35:15.062171 11654 solver.cpp:239] Iteration 8270 (1.61288 iter/s, 6.20008s/10 iters), loss = 9.32483
I0523 23:35:15.062223 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.32483 (* 1 = 9.32483 loss)
I0523 23:35:15.062757 11654 sgd_solver.cpp:112] Iteration 8270, lr = 0.1
I0523 23:35:21.316871 11654 solver.cpp:239] Iteration 8280 (1.59888 iter/s, 6.2544s/10 iters), loss = 8.53504
I0523 23:35:21.316936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.53504 (* 1 = 8.53504 loss)
I0523 23:35:21.317373 11654 sgd_solver.cpp:112] Iteration 8280, lr = 0.1
I0523 23:35:27.859762 11654 solver.cpp:239] Iteration 8290 (1.52845 iter/s, 6.54259s/10 iters), loss = 8.84277
I0523 23:35:27.859992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.84277 (* 1 = 8.84277 loss)
I0523 23:35:28.075992 11654 sgd_solver.cpp:112] Iteration 8290, lr = 0.1
I0523 23:35:36.403743 11654 solver.cpp:239] Iteration 8300 (1.17048 iter/s, 8.54348s/10 iters), loss = 9.54564
I0523 23:35:36.403789 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.54564 (* 1 = 9.54564 loss)
I0523 23:35:36.672544 11654 sgd_solver.cpp:112] Iteration 8300, lr = 0.1
I0523 23:35:44.194622 11654 solver.cpp:239] Iteration 8310 (1.28361 iter/s, 7.79053s/10 iters), loss = 9.23612
I0523 23:35:44.194674 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.23612 (* 1 = 9.23612 loss)
I0523 23:35:44.194875 11654 sgd_solver.cpp:112] Iteration 8310, lr = 0.1
I0523 23:35:50.566366 11654 solver.cpp:239] Iteration 8320 (1.5695 iter/s, 6.37146s/10 iters), loss = 9.19557
I0523 23:35:50.566414 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.19557 (* 1 = 9.19557 loss)
I0523 23:35:50.568380 11654 sgd_solver.cpp:112] Iteration 8320, lr = 0.1
I0523 23:35:58.571991 11654 solver.cpp:239] Iteration 8330 (1.24918 iter/s, 8.00527s/10 iters), loss = 9.21478
I0523 23:35:58.572319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.21478 (* 1 = 9.21478 loss)
I0523 23:35:58.574373 11654 sgd_solver.cpp:112] Iteration 8330, lr = 0.1
I0523 23:36:06.966861 11654 solver.cpp:239] Iteration 8340 (1.19129 iter/s, 8.39427s/10 iters), loss = 9.32125
I0523 23:36:06.966907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.32125 (* 1 = 9.32125 loss)
I0523 23:36:06.967106 11654 sgd_solver.cpp:112] Iteration 8340, lr = 0.1
I0523 23:36:15.700947 11654 solver.cpp:239] Iteration 8350 (1.14499 iter/s, 8.7337s/10 iters), loss = 9.32328
I0523 23:36:15.700999 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.32328 (* 1 = 9.32328 loss)
I0523 23:36:15.701094 11654 sgd_solver.cpp:112] Iteration 8350, lr = 0.1
I0523 23:36:22.363844 11654 solver.cpp:239] Iteration 8360 (1.50092 iter/s, 6.66259s/10 iters), loss = 8.81324
I0523 23:36:22.363920 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.81324 (* 1 = 8.81324 loss)
I0523 23:36:22.365501 11654 sgd_solver.cpp:112] Iteration 8360, lr = 0.1
I0523 23:36:29.887465 11654 solver.cpp:239] Iteration 8370 (1.32921 iter/s, 7.52327s/10 iters), loss = 9.98322
I0523 23:36:29.887619 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.98322 (* 1 = 9.98322 loss)
I0523 23:36:29.887641 11654 sgd_solver.cpp:112] Iteration 8370, lr = 0.1
I0523 23:36:37.811365 11654 solver.cpp:239] Iteration 8380 (1.26241 iter/s, 7.92133s/10 iters), loss = 9.1229
I0523 23:36:37.811414 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.1229 (* 1 = 9.1229 loss)
I0523 23:36:37.811944 11654 sgd_solver.cpp:112] Iteration 8380, lr = 0.1
I0523 23:36:44.553117 11654 solver.cpp:239] Iteration 8390 (1.48336 iter/s, 6.74144s/10 iters), loss = 8.70961
I0523 23:36:44.553172 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.70961 (* 1 = 8.70961 loss)
I0523 23:36:44.553545 11654 sgd_solver.cpp:112] Iteration 8390, lr = 0.1
I0523 23:36:51.377741 11654 solver.cpp:239] Iteration 8400 (1.46535 iter/s, 6.82432s/10 iters), loss = 9.2822
I0523 23:36:51.377794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.2822 (* 1 = 9.2822 loss)
I0523 23:36:51.377988 11654 sgd_solver.cpp:112] Iteration 8400, lr = 0.1
I0523 23:36:57.677081 11654 solver.cpp:239] Iteration 8410 (1.58754 iter/s, 6.29906s/10 iters), loss = 8.26566
I0523 23:36:57.677121 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.26566 (* 1 = 8.26566 loss)
I0523 23:36:57.677134 11654 sgd_solver.cpp:112] Iteration 8410, lr = 0.1
I0523 23:37:04.313990 11654 solver.cpp:239] Iteration 8420 (1.50681 iter/s, 6.63653s/10 iters), loss = 9.41695
I0523 23:37:04.314137 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.41695 (* 1 = 9.41695 loss)
I0523 23:37:04.314584 11654 sgd_solver.cpp:112] Iteration 8420, lr = 0.1
I0523 23:37:10.458075 11654 solver.cpp:239] Iteration 8430 (1.62768 iter/s, 6.14372s/10 iters), loss = 9.58138
I0523 23:37:10.458117 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.58138 (* 1 = 9.58138 loss)
I0523 23:37:10.458384 11654 sgd_solver.cpp:112] Iteration 8430, lr = 0.1
I0523 23:37:20.225122 11654 solver.cpp:239] Iteration 8440 (1.0239 iter/s, 9.76663s/10 iters), loss = 9.79188
I0523 23:37:20.225174 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.79188 (* 1 = 9.79188 loss)
I0523 23:37:21.186720 11654 sgd_solver.cpp:112] Iteration 8440, lr = 0.1
I0523 23:37:29.256244 11654 solver.cpp:239] Iteration 8450 (1.10733 iter/s, 9.03073s/10 iters), loss = 9.39888
I0523 23:37:29.256296 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.39888 (* 1 = 9.39888 loss)
I0523 23:37:29.256312 11654 sgd_solver.cpp:112] Iteration 8450, lr = 0.1
I0523 23:37:36.552181 11654 solver.cpp:239] Iteration 8460 (1.37069 iter/s, 7.29561s/10 iters), loss = 10.0416
I0523 23:37:36.552454 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0416 (* 1 = 10.0416 loss)
I0523 23:37:36.740540 11654 sgd_solver.cpp:112] Iteration 8460, lr = 0.1
I0523 23:37:42.881283 11654 solver.cpp:239] Iteration 8470 (1.58011 iter/s, 6.32866s/10 iters), loss = 9.19035
I0523 23:37:42.881327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.19035 (* 1 = 9.19035 loss)
I0523 23:37:43.117357 11654 sgd_solver.cpp:112] Iteration 8470, lr = 0.1
I0523 23:37:52.680238 11654 solver.cpp:239] Iteration 8480 (1.02056 iter/s, 9.79854s/10 iters), loss = 9.79661
I0523 23:37:52.680294 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.79661 (* 1 = 9.79661 loss)
I0523 23:37:52.680312 11654 sgd_solver.cpp:112] Iteration 8480, lr = 0.1
I0523 23:37:59.940366 11654 solver.cpp:239] Iteration 8490 (1.37746 iter/s, 7.25974s/10 iters), loss = 8.28925
I0523 23:37:59.940404 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.28925 (* 1 = 8.28925 loss)
I0523 23:37:59.940418 11654 sgd_solver.cpp:112] Iteration 8490, lr = 0.1
I0523 23:38:06.470060 11654 solver.cpp:239] Iteration 8500 (1.53167 iter/s, 6.52884s/10 iters), loss = 9.08989
I0523 23:38:06.470115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.08989 (* 1 = 9.08989 loss)
I0523 23:38:07.045373 11654 sgd_solver.cpp:112] Iteration 8500, lr = 0.1
I0523 23:38:14.379873 11654 solver.cpp:239] Iteration 8510 (1.26431 iter/s, 7.90947s/10 iters), loss = 9.47175
I0523 23:38:14.379915 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.47175 (* 1 = 9.47175 loss)
I0523 23:38:14.537753 11654 sgd_solver.cpp:112] Iteration 8510, lr = 0.1
I0523 23:38:21.591655 11654 solver.cpp:239] Iteration 8520 (1.38668 iter/s, 7.21146s/10 iters), loss = 9.58989
I0523 23:38:21.591707 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.58989 (* 1 = 9.58989 loss)
I0523 23:38:21.591722 11654 sgd_solver.cpp:112] Iteration 8520, lr = 0.1
I0523 23:38:27.952426 11654 solver.cpp:239] Iteration 8530 (1.57221 iter/s, 6.36047s/10 iters), loss = 8.87243
I0523 23:38:27.952489 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.87243 (* 1 = 8.87243 loss)
I0523 23:38:27.954416 11654 sgd_solver.cpp:112] Iteration 8530, lr = 0.1
I0523 23:38:35.444222 11654 solver.cpp:239] Iteration 8540 (1.33485 iter/s, 7.49146s/10 iters), loss = 10.3633
I0523 23:38:35.444268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.3633 (* 1 = 10.3633 loss)
I0523 23:38:35.444281 11654 sgd_solver.cpp:112] Iteration 8540, lr = 0.1
I0523 23:38:43.123432 11654 solver.cpp:239] Iteration 8550 (1.30229 iter/s, 7.6788s/10 iters), loss = 9.07515
I0523 23:38:43.123651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.07515 (* 1 = 9.07515 loss)
I0523 23:38:43.140947 11654 sgd_solver.cpp:112] Iteration 8550, lr = 0.1
I0523 23:38:50.969452 11654 solver.cpp:239] Iteration 8560 (1.27461 iter/s, 7.84555s/10 iters), loss = 9.44542
I0523 23:38:50.969504 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.44542 (* 1 = 9.44542 loss)
I0523 23:38:50.969521 11654 sgd_solver.cpp:112] Iteration 8560, lr = 0.1
I0523 23:38:57.484586 11654 solver.cpp:239] Iteration 8570 (1.53496 iter/s, 6.51483s/10 iters), loss = 9.51095
I0523 23:38:57.484630 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.51095 (* 1 = 9.51095 loss)
I0523 23:38:57.485028 11654 sgd_solver.cpp:112] Iteration 8570, lr = 0.1
I0523 23:39:03.802886 11654 solver.cpp:239] Iteration 8580 (1.58278 iter/s, 6.31801s/10 iters), loss = 9.81998
I0523 23:39:03.802951 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.81998 (* 1 = 9.81998 loss)
I0523 23:39:03.803161 11654 sgd_solver.cpp:112] Iteration 8580, lr = 0.1
I0523 23:39:10.102419 11654 solver.cpp:239] Iteration 8590 (1.58749 iter/s, 6.29925s/10 iters), loss = 9.06955
I0523 23:39:10.102458 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.06955 (* 1 = 9.06955 loss)
I0523 23:39:10.102588 11654 sgd_solver.cpp:112] Iteration 8590, lr = 0.1
I0523 23:39:17.992270 11654 solver.cpp:239] Iteration 8600 (1.26751 iter/s, 7.88949s/10 iters), loss = 10.1643
I0523 23:39:17.992619 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1643 (* 1 = 10.1643 loss)
I0523 23:39:17.992688 11654 sgd_solver.cpp:112] Iteration 8600, lr = 0.1
I0523 23:39:25.139936 11654 solver.cpp:239] Iteration 8610 (1.39917 iter/s, 7.1471s/10 iters), loss = 9.10267
I0523 23:39:25.139986 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.10267 (* 1 = 9.10267 loss)
I0523 23:39:25.140497 11654 sgd_solver.cpp:112] Iteration 8610, lr = 0.1
I0523 23:39:34.871012 11654 solver.cpp:239] Iteration 8620 (1.02768 iter/s, 9.73066s/10 iters), loss = 8.17108
I0523 23:39:34.871073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.17108 (* 1 = 8.17108 loss)
I0523 23:39:34.871350 11654 sgd_solver.cpp:112] Iteration 8620, lr = 0.1
I0523 23:39:40.992063 11654 solver.cpp:239] Iteration 8630 (1.63378 iter/s, 6.12076s/10 iters), loss = 10.1462
I0523 23:39:40.992123 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.1462 (* 1 = 10.1462 loss)
I0523 23:39:41.186789 11654 sgd_solver.cpp:112] Iteration 8630, lr = 0.1
I0523 23:39:49.184144 11654 solver.cpp:239] Iteration 8640 (1.22075 iter/s, 8.19171s/10 iters), loss = 8.59313
I0523 23:39:49.184268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.59313 (* 1 = 8.59313 loss)
I0523 23:39:49.184599 11654 sgd_solver.cpp:112] Iteration 8640, lr = 0.1
I0523 23:39:55.519063 11654 solver.cpp:239] Iteration 8650 (1.57864 iter/s, 6.33455s/10 iters), loss = 8.95918
I0523 23:39:55.519114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.95918 (* 1 = 8.95918 loss)
I0523 23:39:55.519760 11654 sgd_solver.cpp:112] Iteration 8650, lr = 0.1
I0523 23:40:01.867686 11654 solver.cpp:239] Iteration 8660 (1.57522 iter/s, 6.34832s/10 iters), loss = 9.21347
I0523 23:40:01.867754 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.21347 (* 1 = 9.21347 loss)
I0523 23:40:01.867776 11654 sgd_solver.cpp:112] Iteration 8660, lr = 0.1
I0523 23:40:09.591799 11654 solver.cpp:239] Iteration 8670 (1.29507 iter/s, 7.72158s/10 iters), loss = 9.56964
I0523 23:40:09.591863 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.56964 (* 1 = 9.56964 loss)
I0523 23:40:09.591900 11654 sgd_solver.cpp:112] Iteration 8670, lr = 0.1
I0523 23:40:16.029284 11654 solver.cpp:239] Iteration 8680 (1.55347 iter/s, 6.43718s/10 iters), loss = 8.9842
I0523 23:40:16.029338 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.9842 (* 1 = 8.9842 loss)
I0523 23:40:16.029476 11654 sgd_solver.cpp:112] Iteration 8680, lr = 0.1
I0523 23:40:22.280822 11654 solver.cpp:239] Iteration 8690 (1.59968 iter/s, 6.25125s/10 iters), loss = 8.35934
I0523 23:40:22.281075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.35934 (* 1 = 8.35934 loss)
I0523 23:40:22.281306 11654 sgd_solver.cpp:112] Iteration 8690, lr = 0.1
I0523 23:40:28.643002 11654 solver.cpp:239] Iteration 8700 (1.5719 iter/s, 6.36172s/10 iters), loss = 8.97068
I0523 23:40:28.643072 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.97068 (* 1 = 8.97068 loss)
I0523 23:40:28.643604 11654 sgd_solver.cpp:112] Iteration 8700, lr = 0.1
I0523 23:40:36.245963 11654 solver.cpp:239] Iteration 8710 (1.31534 iter/s, 7.60261s/10 iters), loss = 9.42127
I0523 23:40:36.246002 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.42127 (* 1 = 9.42127 loss)
I0523 23:40:36.246229 11654 sgd_solver.cpp:112] Iteration 8710, lr = 0.1
I0523 23:40:42.518049 11654 solver.cpp:239] Iteration 8720 (1.59444 iter/s, 6.2718s/10 iters), loss = 9.30975
I0523 23:40:42.518098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.30975 (* 1 = 9.30975 loss)
I0523 23:40:42.518115 11654 sgd_solver.cpp:112] Iteration 8720, lr = 0.1
I0523 23:40:49.172385 11654 solver.cpp:239] Iteration 8730 (1.50285 iter/s, 6.65404s/10 iters), loss = 9.47822
I0523 23:40:49.172425 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.47822 (* 1 = 9.47822 loss)
I0523 23:40:49.234889 11654 sgd_solver.cpp:112] Iteration 8730, lr = 0.1
I0523 23:40:56.327658 11654 solver.cpp:239] Iteration 8740 (1.39763 iter/s, 7.15495s/10 iters), loss = 8.9452
I0523 23:40:56.327941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.9452 (* 1 = 8.9452 loss)
I0523 23:40:56.328008 11654 sgd_solver.cpp:112] Iteration 8740, lr = 0.1
I0523 23:41:03.827520 11654 solver.cpp:239] Iteration 8750 (1.33345 iter/s, 7.49933s/10 iters), loss = 9.7849
I0523 23:41:03.827579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.7849 (* 1 = 9.7849 loss)
I0523 23:41:03.828505 11654 sgd_solver.cpp:112] Iteration 8750, lr = 0.1
I0523 23:41:11.440115 11654 solver.cpp:239] Iteration 8760 (1.31367 iter/s, 7.61226s/10 iters), loss = 9.2443
I0523 23:41:11.440158 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.2443 (* 1 = 9.2443 loss)
I0523 23:41:11.440177 11654 sgd_solver.cpp:112] Iteration 8760, lr = 0.1
I0523 23:41:17.947814 11654 solver.cpp:239] Iteration 8770 (1.53671 iter/s, 6.5074s/10 iters), loss = 9.22004
I0523 23:41:17.947867 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.22004 (* 1 = 9.22004 loss)
I0523 23:41:17.949383 11654 sgd_solver.cpp:112] Iteration 8770, lr = 0.1
I0523 23:41:24.600334 11654 solver.cpp:239] Iteration 8780 (1.50326 iter/s, 6.65222s/10 iters), loss = 10.0299
I0523 23:41:24.600391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 10.0299 (* 1 = 10.0299 loss)
I0523 23:41:24.600409 11654 sgd_solver.cpp:112] Iteration 8780, lr = 0.1
I0523 23:41:32.086203 11654 solver.cpp:239] Iteration 8790 (1.33591 iter/s, 7.48554s/10 iters), loss = 8.61258
I0523 23:41:32.086462 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.61258 (* 1 = 8.61258 loss)
I0523 23:41:32.086516 11654 sgd_solver.cpp:112] Iteration 8790, lr = 0.1
I0523 23:41:39.650454 11654 solver.cpp:239] Iteration 8800 (1.3221 iter/s, 7.56372s/10 iters), loss = 9.35576
I0523 23:41:39.650506 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.35576 (* 1 = 9.35576 loss)
I0523 23:41:39.650614 11654 sgd_solver.cpp:112] Iteration 8800, lr = 0.1
I0523 23:41:47.248623 11654 solver.cpp:239] Iteration 8810 (1.31617 iter/s, 7.59783s/10 iters), loss = 8.25071
I0523 23:41:47.248680 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.25071 (* 1 = 8.25071 loss)
I0523 23:41:47.248697 11654 sgd_solver.cpp:112] Iteration 8810, lr = 0.1
I0523 23:41:54.196933 11654 solver.cpp:239] Iteration 8820 (1.43926 iter/s, 6.94799s/10 iters), loss = 8.86899
I0523 23:41:54.196990 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.86899 (* 1 = 8.86899 loss)
I0523 23:41:54.198201 11654 sgd_solver.cpp:112] Iteration 8820, lr = 0.1
I0523 23:42:00.468822 11654 solver.cpp:239] Iteration 8830 (1.59449 iter/s, 6.2716s/10 iters), loss = 9.42009
I0523 23:42:00.468868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.42009 (* 1 = 9.42009 loss)
I0523 23:42:00.468885 11654 sgd_solver.cpp:112] Iteration 8830, lr = 0.1
I0523 23:42:06.816982 11654 solver.cpp:239] Iteration 8840 (1.57536 iter/s, 6.34777s/10 iters), loss = 8.61488
I0523 23:42:06.817270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.61488 (* 1 = 8.61488 loss)
I0523 23:42:06.819000 11654 sgd_solver.cpp:112] Iteration 8840, lr = 0.1
I0523 23:42:15.248603 11654 solver.cpp:239] Iteration 8850 (1.18609 iter/s, 8.43107s/10 iters), loss = 9.71987
I0523 23:42:15.248651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.71987 (* 1 = 9.71987 loss)
I0523 23:42:15.248664 11654 sgd_solver.cpp:112] Iteration 8850, lr = 0.1
I0523 23:42:22.126292 11654 solver.cpp:239] Iteration 8860 (1.45408 iter/s, 6.87718s/10 iters), loss = 8.75785
I0523 23:42:22.126353 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.75785 (* 1 = 8.75785 loss)
I0523 23:42:22.126372 11654 sgd_solver.cpp:112] Iteration 8860, lr = 0.1
I0523 23:42:29.108888 11654 solver.cpp:239] Iteration 8870 (1.43221 iter/s, 6.9822s/10 iters), loss = 9.76822
I0523 23:42:29.108968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.76822 (* 1 = 9.76822 loss)
I0523 23:42:29.114264 11654 sgd_solver.cpp:112] Iteration 8870, lr = 0.1
I0523 23:42:35.571367 11654 solver.cpp:239] Iteration 8880 (1.54747 iter/s, 6.46216s/10 iters), loss = 8.66556
I0523 23:42:35.571410 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.66556 (* 1 = 8.66556 loss)
I0523 23:42:35.579991 11654 sgd_solver.cpp:112] Iteration 8880, lr = 0.1
I0523 23:42:42.062270 11654 solver.cpp:239] Iteration 8890 (1.54069 iter/s, 6.4906s/10 iters), loss = 9.19774
I0523 23:42:42.062597 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.19774 (* 1 = 9.19774 loss)
I0523 23:42:42.062650 11654 sgd_solver.cpp:112] Iteration 8890, lr = 0.1
I0523 23:42:49.026324 11654 solver.cpp:239] Iteration 8900 (1.4361 iter/s, 6.96331s/10 iters), loss = 8.50464
I0523 23:42:49.026365 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.50464 (* 1 = 8.50464 loss)
I0523 23:42:49.026378 11654 sgd_solver.cpp:112] Iteration 8900, lr = 0.1
I0523 23:42:57.269443 11654 solver.cpp:239] Iteration 8910 (1.2135 iter/s, 8.2406s/10 iters), loss = 8.29837
I0523 23:42:57.269495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.29837 (* 1 = 8.29837 loss)
I0523 23:42:57.269814 11654 sgd_solver.cpp:112] Iteration 8910, lr = 0.1
I0523 23:43:06.026414 11654 solver.cpp:239] Iteration 8920 (1.142 iter/s, 8.75658s/10 iters), loss = 8.99551
I0523 23:43:06.026479 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.99551 (* 1 = 8.99551 loss)
I0523 23:43:06.027624 11654 sgd_solver.cpp:112] Iteration 8920, lr = 0.1
I0523 23:43:12.316076 11654 solver.cpp:239] Iteration 8930 (1.58999 iter/s, 6.28936s/10 iters), loss = 8.9826
I0523 23:43:12.316324 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.9826 (* 1 = 8.9826 loss)
I0523 23:43:12.919162 11654 sgd_solver.cpp:112] Iteration 8930, lr = 0.1
I0523 23:43:20.574834 11654 solver.cpp:239] Iteration 8940 (1.21091 iter/s, 8.25823s/10 iters), loss = 8.86265
I0523 23:43:20.574900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.86265 (* 1 = 8.86265 loss)
I0523 23:43:20.575527 11654 sgd_solver.cpp:112] Iteration 8940, lr = 0.1
I0523 23:43:27.927284 11654 solver.cpp:239] Iteration 8950 (1.36015 iter/s, 7.35212s/10 iters), loss = 9.57662
I0523 23:43:27.927326 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.57662 (* 1 = 9.57662 loss)
I0523 23:43:27.927340 11654 sgd_solver.cpp:112] Iteration 8950, lr = 0.1
I0523 23:43:34.542220 11654 solver.cpp:239] Iteration 8960 (1.51181 iter/s, 6.61459s/10 iters), loss = 8.51281
I0523 23:43:34.542289 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.51281 (* 1 = 8.51281 loss)
I0523 23:43:34.553498 11654 sgd_solver.cpp:112] Iteration 8960, lr = 0.1
I0523 23:43:41.184597 11654 solver.cpp:239] Iteration 8970 (1.50556 iter/s, 6.64207s/10 iters), loss = 9.73828
I0523 23:43:41.184641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.73828 (* 1 = 9.73828 loss)
I0523 23:43:41.189985 11654 sgd_solver.cpp:112] Iteration 8970, lr = 0.1
I0523 23:43:47.800753 11654 solver.cpp:239] Iteration 8980 (1.51152 iter/s, 6.61585s/10 iters), loss = 9.15042
I0523 23:43:47.801005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.15042 (* 1 = 9.15042 loss)
I0523 23:43:47.801240 11654 sgd_solver.cpp:112] Iteration 8980, lr = 0.1
I0523 23:43:55.393015 11654 solver.cpp:239] Iteration 8990 (1.31721 iter/s, 7.59178s/10 iters), loss = 8.76199
I0523 23:43:55.393079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.76199 (* 1 = 8.76199 loss)
I0523 23:43:55.393373 11654 sgd_solver.cpp:112] Iteration 8990, lr = 0.1
I0523 23:44:01.817225 11654 solver.cpp:239] Iteration 9000 (1.55669 iter/s, 6.42391s/10 iters), loss = 9.18465
I0523 23:44:01.817283 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.18465 (* 1 = 9.18465 loss)
I0523 23:44:01.817303 11654 sgd_solver.cpp:112] Iteration 9000, lr = 0.1
I0523 23:44:08.449177 11654 solver.cpp:239] Iteration 9010 (1.50794 iter/s, 6.63157s/10 iters), loss = 8.5608
I0523 23:44:08.449229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.5608 (* 1 = 8.5608 loss)
I0523 23:44:09.189054 11654 sgd_solver.cpp:112] Iteration 9010, lr = 0.1
I0523 23:44:17.177558 11654 solver.cpp:239] Iteration 9020 (1.14574 iter/s, 8.728s/10 iters), loss = 8.68962
I0523 23:44:17.177618 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.68962 (* 1 = 8.68962 loss)
I0523 23:44:17.177634 11654 sgd_solver.cpp:112] Iteration 9020, lr = 0.1
I0523 23:44:23.957881 11654 solver.cpp:239] Iteration 9030 (1.47492 iter/s, 6.78001s/10 iters), loss = 9.65471
I0523 23:44:23.958170 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.65471 (* 1 = 9.65471 loss)
I0523 23:44:23.958226 11654 sgd_solver.cpp:112] Iteration 9030, lr = 0.1
I0523 23:44:32.123152 11654 solver.cpp:239] Iteration 9040 (1.22485 iter/s, 8.16425s/10 iters), loss = 8.68628
I0523 23:44:32.123221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.68628 (* 1 = 8.68628 loss)
I0523 23:44:32.557267 11654 sgd_solver.cpp:112] Iteration 9040, lr = 0.1
I0523 23:44:40.913987 11654 solver.cpp:239] Iteration 9050 (1.1376 iter/s, 8.79043s/10 iters), loss = 9.97414
I0523 23:44:40.914043 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.97414 (* 1 = 9.97414 loss)
I0523 23:44:40.914062 11654 sgd_solver.cpp:112] Iteration 9050, lr = 0.1
I0523 23:44:47.997571 11654 solver.cpp:239] Iteration 9060 (1.41178 iter/s, 7.08327s/10 iters), loss = 8.33096
I0523 23:44:47.997620 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.33096 (* 1 = 8.33096 loss)
I0523 23:44:47.997635 11654 sgd_solver.cpp:112] Iteration 9060, lr = 0.1
I0523 23:44:54.822544 11654 solver.cpp:239] Iteration 9070 (1.46527 iter/s, 6.82467s/10 iters), loss = 9.1567
I0523 23:44:54.822852 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.1567 (* 1 = 9.1567 loss)
I0523 23:44:54.957348 11654 sgd_solver.cpp:112] Iteration 9070, lr = 0.1
I0523 23:45:01.527179 11654 solver.cpp:239] Iteration 9080 (1.49162 iter/s, 6.70412s/10 iters), loss = 9.64844
I0523 23:45:01.527242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.64844 (* 1 = 9.64844 loss)
I0523 23:45:01.527602 11654 sgd_solver.cpp:112] Iteration 9080, lr = 0.1
I0523 23:45:07.863126 11654 solver.cpp:239] Iteration 9090 (1.57837 iter/s, 6.33565s/10 iters), loss = 9.18336
I0523 23:45:07.863180 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.18336 (* 1 = 9.18336 loss)
I0523 23:45:07.863200 11654 sgd_solver.cpp:112] Iteration 9090, lr = 0.1
I0523 23:45:14.873746 11654 solver.cpp:239] Iteration 9100 (1.42648 iter/s, 7.01024s/10 iters), loss = 8.3087
I0523 23:45:14.873808 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.3087 (* 1 = 8.3087 loss)
I0523 23:45:14.873841 11654 sgd_solver.cpp:112] Iteration 9100, lr = 0.1
I0523 23:45:21.258354 11654 solver.cpp:239] Iteration 9110 (1.56634 iter/s, 6.38431s/10 iters), loss = 9.12489
I0523 23:45:21.258404 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.12489 (* 1 = 9.12489 loss)
I0523 23:45:21.258852 11654 sgd_solver.cpp:112] Iteration 9110, lr = 0.1
I0523 23:45:28.037597 11654 solver.cpp:239] Iteration 9120 (1.47516 iter/s, 6.77893s/10 iters), loss = 9.02105
I0523 23:45:28.037850 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.02105 (* 1 = 9.02105 loss)
I0523 23:45:28.037910 11654 sgd_solver.cpp:112] Iteration 9120, lr = 0.1
I0523 23:45:34.861508 11654 solver.cpp:239] Iteration 9130 (1.46554 iter/s, 6.82342s/10 iters), loss = 8.7004
I0523 23:45:34.861557 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.7004 (* 1 = 8.7004 loss)
I0523 23:45:34.942973 11654 sgd_solver.cpp:112] Iteration 9130, lr = 0.1
I0523 23:45:41.311195 11654 solver.cpp:239] Iteration 9140 (1.55053 iter/s, 6.4494s/10 iters), loss = 8.80876
I0523 23:45:41.311239 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.80876 (* 1 = 8.80876 loss)
I0523 23:45:41.311264 11654 sgd_solver.cpp:112] Iteration 9140, lr = 0.1
I0523 23:45:49.090137 11654 solver.cpp:239] Iteration 9150 (1.28558 iter/s, 7.7786s/10 iters), loss = 9.34683
I0523 23:45:49.090191 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.34683 (* 1 = 9.34683 loss)
I0523 23:45:49.090210 11654 sgd_solver.cpp:112] Iteration 9150, lr = 0.1
I0523 23:45:55.320462 11654 solver.cpp:239] Iteration 9160 (1.60515 iter/s, 6.22996s/10 iters), loss = 9.07104
I0523 23:45:55.320520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.07104 (* 1 = 9.07104 loss)
I0523 23:45:55.320539 11654 sgd_solver.cpp:112] Iteration 9160, lr = 0.1
I0523 23:46:03.417989 11654 solver.cpp:239] Iteration 9170 (1.235 iter/s, 8.09717s/10 iters), loss = 9.4662
I0523 23:46:03.418104 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.4662 (* 1 = 9.4662 loss)
I0523 23:46:03.418195 11654 sgd_solver.cpp:112] Iteration 9170, lr = 0.1
I0523 23:46:11.988855 11654 solver.cpp:239] Iteration 9180 (1.1668 iter/s, 8.57042s/10 iters), loss = 9.72141
I0523 23:46:11.988914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.72141 (* 1 = 9.72141 loss)
I0523 23:46:12.006342 11654 sgd_solver.cpp:112] Iteration 9180, lr = 0.1
I0523 23:46:19.763449 11654 solver.cpp:239] Iteration 9190 (1.2863 iter/s, 7.77425s/10 iters), loss = 8.43494
I0523 23:46:19.763491 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.43494 (* 1 = 8.43494 loss)
I0523 23:46:19.763506 11654 sgd_solver.cpp:112] Iteration 9190, lr = 0.1
I0523 23:46:27.045545 11654 solver.cpp:239] Iteration 9200 (1.37329 iter/s, 7.28177s/10 iters), loss = 8.92523
I0523 23:46:27.045601 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.92523 (* 1 = 8.92523 loss)
I0523 23:46:27.045619 11654 sgd_solver.cpp:112] Iteration 9200, lr = 0.1
I0523 23:46:35.713707 11654 solver.cpp:239] Iteration 9210 (1.15371 iter/s, 8.6677s/10 iters), loss = 9.2284
I0523 23:46:35.713850 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.2284 (* 1 = 9.2284 loss)
I0523 23:46:35.943853 11654 sgd_solver.cpp:112] Iteration 9210, lr = 0.1
I0523 23:46:44.167963 11654 solver.cpp:239] Iteration 9220 (1.1829 iter/s, 8.45378s/10 iters), loss = 9.13403
I0523 23:46:44.168015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.13403 (* 1 = 9.13403 loss)
I0523 23:46:44.168032 11654 sgd_solver.cpp:112] Iteration 9220, lr = 0.1
I0523 23:46:52.059804 11654 solver.cpp:239] Iteration 9230 (1.2672 iter/s, 7.89142s/10 iters), loss = 8.09061
I0523 23:46:52.059855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.09061 (* 1 = 8.09061 loss)
I0523 23:46:52.594691 11654 sgd_solver.cpp:112] Iteration 9230, lr = 0.1
I0523 23:46:59.796648 11654 solver.cpp:239] Iteration 9240 (1.29257 iter/s, 7.7365s/10 iters), loss = 9.46009
I0523 23:46:59.796700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.46009 (* 1 = 9.46009 loss)
I0523 23:46:59.796715 11654 sgd_solver.cpp:112] Iteration 9240, lr = 0.1
I0523 23:47:06.267385 11654 solver.cpp:239] Iteration 9250 (1.54602 iter/s, 6.46824s/10 iters), loss = 8.76328
I0523 23:47:06.267496 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.76328 (* 1 = 8.76328 loss)
I0523 23:47:06.796391 11654 sgd_solver.cpp:112] Iteration 9250, lr = 0.1
I0523 23:47:13.081825 11654 solver.cpp:239] Iteration 9260 (1.46755 iter/s, 6.81408s/10 iters), loss = 9.66553
I0523 23:47:13.081864 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.66553 (* 1 = 9.66553 loss)
I0523 23:47:13.081877 11654 sgd_solver.cpp:112] Iteration 9260, lr = 0.1
I0523 23:47:19.910737 11654 solver.cpp:239] Iteration 9270 (1.46492 iter/s, 6.82631s/10 iters), loss = 8.91321
I0523 23:47:19.910791 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.91321 (* 1 = 8.91321 loss)
I0523 23:47:19.910807 11654 sgd_solver.cpp:112] Iteration 9270, lr = 0.1
I0523 23:47:26.583715 11654 solver.cpp:239] Iteration 9280 (1.49865 iter/s, 6.67267s/10 iters), loss = 9.19101
I0523 23:47:26.583772 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.19101 (* 1 = 9.19101 loss)
I0523 23:47:26.584198 11654 sgd_solver.cpp:112] Iteration 9280, lr = 0.1
I0523 23:47:34.441741 11654 solver.cpp:239] Iteration 9290 (1.27264 iter/s, 7.85768s/10 iters), loss = 8.84008
I0523 23:47:34.441782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.84008 (* 1 = 8.84008 loss)
I0523 23:47:34.441954 11654 sgd_solver.cpp:112] Iteration 9290, lr = 0.1
I0523 23:47:40.895326 11654 solver.cpp:239] Iteration 9300 (1.5496 iter/s, 6.45329s/10 iters), loss = 8.37888
I0523 23:47:40.895505 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.37888 (* 1 = 8.37888 loss)
I0523 23:47:40.895720 11654 sgd_solver.cpp:112] Iteration 9300, lr = 0.1
I0523 23:47:48.179168 11654 solver.cpp:239] Iteration 9310 (1.37298 iter/s, 7.28342s/10 iters), loss = 8.61752
I0523 23:47:48.179213 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.61752 (* 1 = 8.61752 loss)
I0523 23:47:48.179270 11654 sgd_solver.cpp:112] Iteration 9310, lr = 0.1
I0523 23:47:55.140657 11654 solver.cpp:239] Iteration 9320 (1.43654 iter/s, 6.96118s/10 iters), loss = 8.82478
I0523 23:47:55.140710 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.82478 (* 1 = 8.82478 loss)
I0523 23:47:55.557309 11654 sgd_solver.cpp:112] Iteration 9320, lr = 0.1
I0523 23:48:02.656919 11654 solver.cpp:239] Iteration 9330 (1.33051 iter/s, 7.51593s/10 iters), loss = 9.18015
I0523 23:48:02.656960 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.18015 (* 1 = 9.18015 loss)
I0523 23:48:02.656971 11654 sgd_solver.cpp:112] Iteration 9330, lr = 0.1
I0523 23:48:08.798342 11654 solver.cpp:239] Iteration 9340 (1.62836 iter/s, 6.14114s/10 iters), loss = 8.71346
I0523 23:48:08.798403 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.71346 (* 1 = 8.71346 loss)
I0523 23:48:08.798620 11654 sgd_solver.cpp:112] Iteration 9340, lr = 0.1
I0523 23:48:16.144428 11654 solver.cpp:239] Iteration 9350 (1.36133 iter/s, 7.34575s/10 iters), loss = 9.23711
I0523 23:48:16.144599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.23711 (* 1 = 9.23711 loss)
I0523 23:48:16.144628 11654 sgd_solver.cpp:112] Iteration 9350, lr = 0.1
I0523 23:48:22.597882 11654 solver.cpp:239] Iteration 9360 (1.54965 iter/s, 6.45305s/10 iters), loss = 8.62564
I0523 23:48:22.597930 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.62564 (* 1 = 8.62564 loss)
I0523 23:48:22.598201 11654 sgd_solver.cpp:112] Iteration 9360, lr = 0.1
I0523 23:48:29.253890 11654 solver.cpp:239] Iteration 9370 (1.50247 iter/s, 6.65569s/10 iters), loss = 8.60269
I0523 23:48:29.253944 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.60269 (* 1 = 8.60269 loss)
I0523 23:48:29.254119 11654 sgd_solver.cpp:112] Iteration 9370, lr = 0.1
I0523 23:48:37.486506 11654 solver.cpp:239] Iteration 9380 (1.21473 iter/s, 8.23225s/10 iters), loss = 9.01936
I0523 23:48:37.486564 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.01936 (* 1 = 9.01936 loss)
I0523 23:48:37.486583 11654 sgd_solver.cpp:112] Iteration 9380, lr = 0.1
I0523 23:48:44.545202 11654 solver.cpp:239] Iteration 9390 (1.41677 iter/s, 7.05831s/10 iters), loss = 8.73261
I0523 23:48:44.545256 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.73261 (* 1 = 8.73261 loss)
I0523 23:48:44.545469 11654 sgd_solver.cpp:112] Iteration 9390, lr = 0.1
I0523 23:48:51.437841 11654 solver.cpp:239] Iteration 9400 (1.45089 iter/s, 6.89232s/10 iters), loss = 8.48757
I0523 23:48:51.437973 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.48757 (* 1 = 8.48757 loss)
I0523 23:48:51.438200 11654 sgd_solver.cpp:112] Iteration 9400, lr = 0.1
I0523 23:49:00.277180 11654 solver.cpp:239] Iteration 9410 (1.13137 iter/s, 8.83887s/10 iters), loss = 9.54374
I0523 23:49:00.277230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.54374 (* 1 = 9.54374 loss)
I0523 23:49:00.898046 11654 sgd_solver.cpp:112] Iteration 9410, lr = 0.1
I0523 23:49:07.356804 11654 solver.cpp:239] Iteration 9420 (1.41257 iter/s, 7.07931s/10 iters), loss = 7.85114
I0523 23:49:07.356843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85114 (* 1 = 7.85114 loss)
I0523 23:49:07.356873 11654 sgd_solver.cpp:112] Iteration 9420, lr = 0.1
I0523 23:49:15.306084 11654 solver.cpp:239] Iteration 9430 (1.25803 iter/s, 7.94893s/10 iters), loss = 8.03424
I0523 23:49:15.306139 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.03424 (* 1 = 8.03424 loss)
I0523 23:49:15.308079 11654 sgd_solver.cpp:112] Iteration 9430, lr = 0.1
I0523 23:49:21.891621 11654 solver.cpp:239] Iteration 9440 (1.51855 iter/s, 6.58524s/10 iters), loss = 8.39007
I0523 23:49:21.891909 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.39007 (* 1 = 8.39007 loss)
I0523 23:49:22.097206 11654 sgd_solver.cpp:112] Iteration 9440, lr = 0.1
I0523 23:49:28.590654 11654 solver.cpp:239] Iteration 9450 (1.49286 iter/s, 6.69853s/10 iters), loss = 9.04625
I0523 23:49:28.590711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.04625 (* 1 = 9.04625 loss)
I0523 23:49:28.590898 11654 sgd_solver.cpp:112] Iteration 9450, lr = 0.1
I0523 23:49:35.563009 11654 solver.cpp:239] Iteration 9460 (1.4343 iter/s, 6.97203s/10 iters), loss = 8.83301
I0523 23:49:35.563098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.83301 (* 1 = 8.83301 loss)
I0523 23:49:35.568305 11654 sgd_solver.cpp:112] Iteration 9460, lr = 0.1
I0523 23:49:44.282778 11654 solver.cpp:239] Iteration 9470 (1.14687 iter/s, 8.71937s/10 iters), loss = 8.6584
I0523 23:49:44.282829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.6584 (* 1 = 8.6584 loss)
I0523 23:49:44.282845 11654 sgd_solver.cpp:112] Iteration 9470, lr = 0.1
I0523 23:49:53.916290 11654 solver.cpp:239] Iteration 9480 (1.0381 iter/s, 9.63303s/10 iters), loss = 8.75043
I0523 23:49:53.916471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.75043 (* 1 = 8.75043 loss)
I0523 23:49:53.916496 11654 sgd_solver.cpp:112] Iteration 9480, lr = 0.1
I0523 23:50:01.139415 11654 solver.cpp:239] Iteration 9490 (1.38453 iter/s, 7.22265s/10 iters), loss = 8.24869
I0523 23:50:01.139473 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.24869 (* 1 = 8.24869 loss)
I0523 23:50:01.139488 11654 sgd_solver.cpp:112] Iteration 9490, lr = 0.1
I0523 23:50:10.338464 11654 solver.cpp:239] Iteration 9500 (1.08712 iter/s, 9.19864s/10 iters), loss = 8.92555
I0523 23:50:10.338537 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.92555 (* 1 = 8.92555 loss)
I0523 23:50:10.340337 11654 sgd_solver.cpp:112] Iteration 9500, lr = 0.1
I0523 23:50:19.301321 11654 solver.cpp:239] Iteration 9510 (1.11577 iter/s, 8.96246s/10 iters), loss = 9.95367
I0523 23:50:19.301370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.95367 (* 1 = 9.95367 loss)
I0523 23:50:19.301429 11654 sgd_solver.cpp:112] Iteration 9510, lr = 0.1
I0523 23:50:25.965162 11654 solver.cpp:239] Iteration 9520 (1.5007 iter/s, 6.66354s/10 iters), loss = 9.14019
I0523 23:50:25.965242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.14019 (* 1 = 9.14019 loss)
I0523 23:50:25.965260 11654 sgd_solver.cpp:112] Iteration 9520, lr = 0.1
I0523 23:50:32.262727 11654 solver.cpp:239] Iteration 9530 (1.58802 iter/s, 6.29716s/10 iters), loss = 8.93995
I0523 23:50:32.262784 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.93995 (* 1 = 8.93995 loss)
I0523 23:50:32.491808 11654 sgd_solver.cpp:112] Iteration 9530, lr = 0.1
I0523 23:50:40.148044 11654 solver.cpp:239] Iteration 9540 (1.26824 iter/s, 7.88495s/10 iters), loss = 8.19283
I0523 23:50:40.148111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.19283 (* 1 = 8.19283 loss)
I0523 23:50:40.149879 11654 sgd_solver.cpp:112] Iteration 9540, lr = 0.1
I0523 23:50:48.503916 11654 solver.cpp:239] Iteration 9550 (1.19682 iter/s, 8.3555s/10 iters), loss = 8.55913
I0523 23:50:48.503970 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.55913 (* 1 = 8.55913 loss)
I0523 23:50:48.504256 11654 sgd_solver.cpp:112] Iteration 9550, lr = 0.1
I0523 23:50:56.334096 11654 solver.cpp:239] Iteration 9560 (1.27717 iter/s, 7.82983s/10 iters), loss = 8.87682
I0523 23:50:56.334378 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.87682 (* 1 = 8.87682 loss)
I0523 23:50:56.983963 11654 sgd_solver.cpp:112] Iteration 9560, lr = 0.1
I0523 23:51:03.406515 11654 solver.cpp:239] Iteration 9570 (1.41404 iter/s, 7.07192s/10 iters), loss = 9.54571
I0523 23:51:03.406569 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.54571 (* 1 = 9.54571 loss)
I0523 23:51:03.601864 11654 sgd_solver.cpp:112] Iteration 9570, lr = 0.1
I0523 23:51:09.860384 11654 solver.cpp:239] Iteration 9580 (1.54953 iter/s, 6.45357s/10 iters), loss = 8.7051
I0523 23:51:09.860445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.7051 (* 1 = 8.7051 loss)
I0523 23:51:09.860465 11654 sgd_solver.cpp:112] Iteration 9580, lr = 0.1
I0523 23:51:18.045938 11654 solver.cpp:239] Iteration 9590 (1.22172 iter/s, 8.18519s/10 iters), loss = 8.61061
I0523 23:51:18.045998 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.61061 (* 1 = 8.61061 loss)
I0523 23:51:18.046020 11654 sgd_solver.cpp:112] Iteration 9590, lr = 0.1
I0523 23:51:22.833802 11654 solver.cpp:239] Iteration 9600 (2.08875 iter/s, 4.78755s/10 iters), loss = 7.75638
I0523 23:51:22.833889 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.75638 (* 1 = 7.75638 loss)
I0523 23:51:22.833923 11654 sgd_solver.cpp:112] Iteration 9600, lr = 0.1
I0523 23:51:30.795461 11654 solver.cpp:239] Iteration 9610 (1.25637 iter/s, 7.95946s/10 iters), loss = 8.7394
I0523 23:51:30.795742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.7394 (* 1 = 8.7394 loss)
I0523 23:51:30.795795 11654 sgd_solver.cpp:112] Iteration 9610, lr = 0.1
I0523 23:51:38.331315 11654 solver.cpp:239] Iteration 9620 (1.32746 iter/s, 7.53317s/10 iters), loss = 8.95571
I0523 23:51:38.331385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.95571 (* 1 = 8.95571 loss)
I0523 23:51:38.331408 11654 sgd_solver.cpp:112] Iteration 9620, lr = 0.1
I0523 23:51:44.770893 11654 solver.cpp:239] Iteration 9630 (1.55298 iter/s, 6.43922s/10 iters), loss = 9.21143
I0523 23:51:44.770958 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.21143 (* 1 = 9.21143 loss)
I0523 23:51:44.771062 11654 sgd_solver.cpp:112] Iteration 9630, lr = 0.1
I0523 23:51:51.235790 11654 solver.cpp:239] Iteration 9640 (1.54689 iter/s, 6.46459s/10 iters), loss = 8.97418
I0523 23:51:51.235842 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.97418 (* 1 = 8.97418 loss)
I0523 23:51:51.237792 11654 sgd_solver.cpp:112] Iteration 9640, lr = 0.1
I0523 23:51:58.910773 11654 solver.cpp:239] Iteration 9650 (1.30299 iter/s, 7.67464s/10 iters), loss = 8.45933
I0523 23:51:58.910830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.45933 (* 1 = 8.45933 loss)
I0523 23:51:58.911015 11654 sgd_solver.cpp:112] Iteration 9650, lr = 0.1
I0523 23:52:05.983952 11654 solver.cpp:239] Iteration 9660 (1.41385 iter/s, 7.07286s/10 iters), loss = 8.2647
I0523 23:52:05.984202 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.2647 (* 1 = 8.2647 loss)
I0523 23:52:05.984258 11654 sgd_solver.cpp:112] Iteration 9660, lr = 0.1
I0523 23:52:12.989091 11654 solver.cpp:239] Iteration 9670 (1.42804 iter/s, 7.0026s/10 iters), loss = 8.3202
I0523 23:52:12.989151 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.3202 (* 1 = 8.3202 loss)
I0523 23:52:12.989374 11654 sgd_solver.cpp:112] Iteration 9670, lr = 0.1
I0523 23:52:20.072852 11654 solver.cpp:239] Iteration 9680 (1.41175 iter/s, 7.0834s/10 iters), loss = 9.33275
I0523 23:52:20.072969 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.33275 (* 1 = 9.33275 loss)
I0523 23:52:20.073009 11654 sgd_solver.cpp:112] Iteration 9680, lr = 0.1
I0523 23:52:26.826952 11654 solver.cpp:239] Iteration 9690 (1.48113 iter/s, 6.7516s/10 iters), loss = 8.56392
I0523 23:52:26.826992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.56392 (* 1 = 8.56392 loss)
I0523 23:52:26.827234 11654 sgd_solver.cpp:112] Iteration 9690, lr = 0.1
I0523 23:52:34.508313 11654 solver.cpp:239] Iteration 9700 (1.30191 iter/s, 7.68102s/10 iters), loss = 8.55847
I0523 23:52:34.508369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.55847 (* 1 = 8.55847 loss)
I0523 23:52:34.508620 11654 sgd_solver.cpp:112] Iteration 9700, lr = 0.1
I0523 23:52:42.111590 11654 solver.cpp:239] Iteration 9710 (1.31528 iter/s, 7.60293s/10 iters), loss = 8.96928
I0523 23:52:42.111922 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.96928 (* 1 = 8.96928 loss)
I0523 23:52:42.111982 11654 sgd_solver.cpp:112] Iteration 9710, lr = 0.1
I0523 23:52:49.094126 11654 solver.cpp:239] Iteration 9720 (1.43226 iter/s, 6.98197s/10 iters), loss = 8.53901
I0523 23:52:49.094189 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.53901 (* 1 = 8.53901 loss)
I0523 23:52:49.095593 11654 sgd_solver.cpp:112] Iteration 9720, lr = 0.1
I0523 23:52:56.041800 11654 solver.cpp:239] Iteration 9730 (1.4394 iter/s, 6.94735s/10 iters), loss = 9.57286
I0523 23:52:56.041841 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.57286 (* 1 = 9.57286 loss)
I0523 23:52:56.041853 11654 sgd_solver.cpp:112] Iteration 9730, lr = 0.1
I0523 23:53:03.755388 11654 solver.cpp:239] Iteration 9740 (1.29648 iter/s, 7.71317s/10 iters), loss = 8.00371
I0523 23:53:03.755436 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.00371 (* 1 = 8.00371 loss)
I0523 23:53:03.786479 11654 sgd_solver.cpp:112] Iteration 9740, lr = 0.1
I0523 23:53:11.274137 11654 solver.cpp:239] Iteration 9750 (1.33007 iter/s, 7.51842s/10 iters), loss = 8.56328
I0523 23:53:11.274190 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.56328 (* 1 = 8.56328 loss)
I0523 23:53:11.274279 11654 sgd_solver.cpp:112] Iteration 9750, lr = 0.1
I0523 23:53:17.247906 11654 solver.cpp:239] Iteration 9760 (1.67407 iter/s, 5.97348s/10 iters), loss = 8.52396
I0523 23:53:17.248170 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.52396 (* 1 = 8.52396 loss)
I0523 23:53:17.248229 11654 sgd_solver.cpp:112] Iteration 9760, lr = 0.1
I0523 23:53:24.014155 11654 solver.cpp:239] Iteration 9770 (1.47803 iter/s, 6.76577s/10 iters), loss = 9.31225
I0523 23:53:24.014212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.31225 (* 1 = 9.31225 loss)
I0523 23:53:24.598335 11654 sgd_solver.cpp:112] Iteration 9770, lr = 0.1
I0523 23:53:33.005679 11654 solver.cpp:239] Iteration 9780 (1.11221 iter/s, 8.99112s/10 iters), loss = 9.18481
I0523 23:53:33.005740 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.18481 (* 1 = 9.18481 loss)
I0523 23:53:33.007377 11654 sgd_solver.cpp:112] Iteration 9780, lr = 0.1
I0523 23:53:40.984851 11654 solver.cpp:239] Iteration 9790 (1.25332 iter/s, 7.97882s/10 iters), loss = 8.14659
I0523 23:53:40.984894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.14659 (* 1 = 8.14659 loss)
I0523 23:53:41.150008 11654 sgd_solver.cpp:112] Iteration 9790, lr = 0.1
I0523 23:53:48.062088 11654 solver.cpp:239] Iteration 9800 (1.41304 iter/s, 7.07692s/10 iters), loss = 8.72912
I0523 23:53:48.062361 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.72912 (* 1 = 8.72912 loss)
I0523 23:53:48.436439 11654 sgd_solver.cpp:112] Iteration 9800, lr = 0.1
I0523 23:53:57.980861 11654 solver.cpp:239] Iteration 9810 (1.00825 iter/s, 9.91817s/10 iters), loss = 9.40706
I0523 23:53:57.980914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.40706 (* 1 = 9.40706 loss)
I0523 23:53:58.289680 11654 sgd_solver.cpp:112] Iteration 9810, lr = 0.1
I0523 23:54:05.546470 11654 solver.cpp:239] Iteration 9820 (1.32183 iter/s, 7.56527s/10 iters), loss = 8.47902
I0523 23:54:05.546519 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.47902 (* 1 = 8.47902 loss)
I0523 23:54:05.546536 11654 sgd_solver.cpp:112] Iteration 9820, lr = 0.1
I0523 23:54:12.132465 11654 solver.cpp:239] Iteration 9830 (1.51845 iter/s, 6.58567s/10 iters), loss = 8.75636
I0523 23:54:12.132525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.75636 (* 1 = 8.75636 loss)
I0523 23:54:12.132974 11654 sgd_solver.cpp:112] Iteration 9830, lr = 0.1
I0523 23:54:19.796705 11654 solver.cpp:239] Iteration 9840 (1.30482 iter/s, 7.66389s/10 iters), loss = 8.24274
I0523 23:54:19.796939 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.24274 (* 1 = 8.24274 loss)
I0523 23:54:19.932286 11654 sgd_solver.cpp:112] Iteration 9840, lr = 0.1
I0523 23:54:26.943893 11654 solver.cpp:239] Iteration 9850 (1.39924 iter/s, 7.14673s/10 iters), loss = 8.52949
I0523 23:54:26.943945 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.52949 (* 1 = 8.52949 loss)
I0523 23:54:26.961621 11654 sgd_solver.cpp:112] Iteration 9850, lr = 0.1
I0523 23:54:34.085177 11654 solver.cpp:239] Iteration 9860 (1.40037 iter/s, 7.14096s/10 iters), loss = 9.1207
I0523 23:54:34.085239 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.1207 (* 1 = 9.1207 loss)
I0523 23:54:34.085384 11654 sgd_solver.cpp:112] Iteration 9860, lr = 0.1
I0523 23:54:41.164954 11654 solver.cpp:239] Iteration 9870 (1.41254 iter/s, 7.07945s/10 iters), loss = 9.53868
I0523 23:54:41.165007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.53868 (* 1 = 9.53868 loss)
I0523 23:54:41.165024 11654 sgd_solver.cpp:112] Iteration 9870, lr = 0.1
I0523 23:54:48.569411 11654 solver.cpp:239] Iteration 9880 (1.351 iter/s, 7.4019s/10 iters), loss = 8.44425
I0523 23:54:48.569455 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.44425 (* 1 = 8.44425 loss)
I0523 23:54:48.569663 11654 sgd_solver.cpp:112] Iteration 9880, lr = 0.1
I0523 23:54:57.453802 11654 solver.cpp:239] Iteration 9890 (1.12562 iter/s, 8.884s/10 iters), loss = 7.98001
I0523 23:54:57.454077 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.98001 (* 1 = 7.98001 loss)
I0523 23:54:57.454118 11654 sgd_solver.cpp:112] Iteration 9890, lr = 0.1
I0523 23:55:05.627710 11654 solver.cpp:239] Iteration 9900 (1.2238 iter/s, 8.17127s/10 iters), loss = 7.86894
I0523 23:55:05.627776 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86894 (* 1 = 7.86894 loss)
I0523 23:55:05.627900 11654 sgd_solver.cpp:112] Iteration 9900, lr = 0.1
I0523 23:55:12.703948 11654 solver.cpp:239] Iteration 9910 (1.41325 iter/s, 7.07591s/10 iters), loss = 8.21028
I0523 23:55:12.704005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.21028 (* 1 = 8.21028 loss)
I0523 23:55:12.704025 11654 sgd_solver.cpp:112] Iteration 9910, lr = 0.1
I0523 23:55:20.017784 11654 solver.cpp:239] Iteration 9920 (1.36735 iter/s, 7.31344s/10 iters), loss = 8.76005
I0523 23:55:20.017838 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.76005 (* 1 = 8.76005 loss)
I0523 23:55:20.017853 11654 sgd_solver.cpp:112] Iteration 9920, lr = 0.1
I0523 23:55:27.963822 11654 solver.cpp:239] Iteration 9930 (1.25854 iter/s, 7.94569s/10 iters), loss = 8.72956
I0523 23:55:27.964079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.72956 (* 1 = 8.72956 loss)
I0523 23:55:27.964141 11654 sgd_solver.cpp:112] Iteration 9930, lr = 0.1
I0523 23:55:35.339936 11654 solver.cpp:239] Iteration 9940 (1.35582 iter/s, 7.37559s/10 iters), loss = 8.67807
I0523 23:55:35.339979 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.67807 (* 1 = 8.67807 loss)
I0523 23:55:35.487275 11654 sgd_solver.cpp:112] Iteration 9940, lr = 0.1
I0523 23:55:43.449539 11654 solver.cpp:239] Iteration 9950 (1.23316 iter/s, 8.10925s/10 iters), loss = 8.39399
I0523 23:55:43.449589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.39399 (* 1 = 8.39399 loss)
I0523 23:55:43.620685 11654 sgd_solver.cpp:112] Iteration 9950, lr = 0.1
I0523 23:55:52.802402 11654 solver.cpp:239] Iteration 9960 (1.06924 iter/s, 9.35245s/10 iters), loss = 8.63975
I0523 23:55:52.802474 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.63975 (* 1 = 8.63975 loss)
I0523 23:55:52.837261 11654 sgd_solver.cpp:112] Iteration 9960, lr = 0.1
I0523 23:56:01.672291 11654 solver.cpp:239] Iteration 9970 (1.12746 iter/s, 8.86949s/10 iters), loss = 9.31834
I0523 23:56:01.672561 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.31834 (* 1 = 9.31834 loss)
I0523 23:56:01.672616 11654 sgd_solver.cpp:112] Iteration 9970, lr = 0.1
I0523 23:56:07.892621 11654 solver.cpp:239] Iteration 9980 (1.60813 iter/s, 6.21841s/10 iters), loss = 8.29362
I0523 23:56:07.892671 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.29362 (* 1 = 8.29362 loss)
I0523 23:56:07.893189 11654 sgd_solver.cpp:112] Iteration 9980, lr = 0.1
I0523 23:56:14.054811 11654 solver.cpp:239] Iteration 9990 (1.62288 iter/s, 6.1619s/10 iters), loss = 9.02362
I0523 23:56:14.054865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.02362 (* 1 = 9.02362 loss)
I0523 23:56:14.054882 11654 sgd_solver.cpp:112] Iteration 9990, lr = 0.1
I0523 23:56:22.140782 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_10000.caffemodel
I0523 23:56:22.316750 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_10000.solverstate
I0523 23:56:22.937103 11654 solver.cpp:239] Iteration 10000 (1.12589 iter/s, 8.88184s/10 iters), loss = 7.9891
I0523 23:56:22.937145 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9891 (* 1 = 7.9891 loss)
I0523 23:56:22.937301 11654 sgd_solver.cpp:112] Iteration 10000, lr = 0.1
I0523 23:56:29.284952 11654 solver.cpp:239] Iteration 10010 (1.57541 iter/s, 6.34756s/10 iters), loss = 7.89712
I0523 23:56:29.285002 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89712 (* 1 = 7.89712 loss)
I0523 23:56:29.285020 11654 sgd_solver.cpp:112] Iteration 10010, lr = 0.1
I0523 23:56:36.042592 11654 solver.cpp:239] Iteration 10020 (1.47994 iter/s, 6.75701s/10 iters), loss = 8.16141
I0523 23:56:36.042971 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.16141 (* 1 = 8.16141 loss)
I0523 23:56:36.043012 11654 sgd_solver.cpp:112] Iteration 10020, lr = 0.1
I0523 23:56:42.456646 11654 solver.cpp:239] Iteration 10030 (1.55923 iter/s, 6.41344s/10 iters), loss = 9.3154
I0523 23:56:42.456691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.3154 (* 1 = 9.3154 loss)
I0523 23:56:42.456703 11654 sgd_solver.cpp:112] Iteration 10030, lr = 0.1
I0523 23:56:49.850327 11654 solver.cpp:239] Iteration 10040 (1.35296 iter/s, 7.3912s/10 iters), loss = 8.48961
I0523 23:56:49.850407 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.48961 (* 1 = 8.48961 loss)
I0523 23:56:49.850423 11654 sgd_solver.cpp:112] Iteration 10040, lr = 0.1
I0523 23:56:57.747679 11654 solver.cpp:239] Iteration 10050 (1.26632 iter/s, 7.89693s/10 iters), loss = 8.81196
I0523 23:56:57.747728 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.81196 (* 1 = 8.81196 loss)
I0523 23:56:57.748029 11654 sgd_solver.cpp:112] Iteration 10050, lr = 0.1
I0523 23:57:04.162634 11654 solver.cpp:239] Iteration 10060 (1.55893 iter/s, 6.41466s/10 iters), loss = 8.075
I0523 23:57:04.162686 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.075 (* 1 = 8.075 loss)
I0523 23:57:04.162717 11654 sgd_solver.cpp:112] Iteration 10060, lr = 0.1
I0523 23:57:11.922010 11654 solver.cpp:239] Iteration 10070 (1.28882 iter/s, 7.75904s/10 iters), loss = 8.45997
I0523 23:57:11.922250 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.45997 (* 1 = 8.45997 loss)
I0523 23:57:12.084879 11654 sgd_solver.cpp:112] Iteration 10070, lr = 0.1
I0523 23:57:20.905055 11654 solver.cpp:239] Iteration 10080 (1.11328 iter/s, 8.98248s/10 iters), loss = 8.46101
I0523 23:57:20.905120 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.46101 (* 1 = 8.46101 loss)
I0523 23:57:21.721287 11654 sgd_solver.cpp:112] Iteration 10080, lr = 0.1
I0523 23:57:28.210188 11654 solver.cpp:239] Iteration 10090 (1.36896 iter/s, 7.3048s/10 iters), loss = 8.03994
I0523 23:57:28.210234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.03994 (* 1 = 8.03994 loss)
I0523 23:57:28.210249 11654 sgd_solver.cpp:112] Iteration 10090, lr = 0.1
I0523 23:57:34.714905 11654 solver.cpp:239] Iteration 10100 (1.53742 iter/s, 6.50442s/10 iters), loss = 8.61327
I0523 23:57:34.714977 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.61327 (* 1 = 8.61327 loss)
I0523 23:57:34.715065 11654 sgd_solver.cpp:112] Iteration 10100, lr = 0.1
I0523 23:57:42.088979 11654 solver.cpp:239] Iteration 10110 (1.35617 iter/s, 7.37373s/10 iters), loss = 7.91891
I0523 23:57:42.089262 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91891 (* 1 = 7.91891 loss)
I0523 23:57:42.089306 11654 sgd_solver.cpp:112] Iteration 10110, lr = 0.1
I0523 23:57:50.854074 11654 solver.cpp:239] Iteration 10120 (1.14098 iter/s, 8.76439s/10 iters), loss = 8.27025
I0523 23:57:50.854125 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.27025 (* 1 = 8.27025 loss)
I0523 23:57:51.280418 11654 sgd_solver.cpp:112] Iteration 10120, lr = 0.1
I0523 23:57:57.668969 11654 solver.cpp:239] Iteration 10130 (1.46744 iter/s, 6.81459s/10 iters), loss = 7.29254
I0523 23:57:57.669018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29254 (* 1 = 7.29254 loss)
I0523 23:57:57.669034 11654 sgd_solver.cpp:112] Iteration 10130, lr = 0.1
I0523 23:58:05.523212 11654 solver.cpp:239] Iteration 10140 (1.27327 iter/s, 7.85382s/10 iters), loss = 9.0031
I0523 23:58:05.523267 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.0031 (* 1 = 9.0031 loss)
I0523 23:58:05.523586 11654 sgd_solver.cpp:112] Iteration 10140, lr = 0.1
I0523 23:58:14.018251 11654 solver.cpp:239] Iteration 10150 (1.17721 iter/s, 8.49466s/10 iters), loss = 8.25839
I0523 23:58:14.018514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.25839 (* 1 = 8.25839 loss)
I0523 23:58:14.649704 11654 sgd_solver.cpp:112] Iteration 10150, lr = 0.1
I0523 23:58:21.098876 11654 solver.cpp:239] Iteration 10160 (1.4124 iter/s, 7.08015s/10 iters), loss = 8.39248
I0523 23:58:21.098927 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.39248 (* 1 = 8.39248 loss)
I0523 23:58:21.099054 11654 sgd_solver.cpp:112] Iteration 10160, lr = 0.1
I0523 23:58:28.737567 11654 solver.cpp:239] Iteration 10170 (1.30919 iter/s, 7.63834s/10 iters), loss = 8.65688
I0523 23:58:28.737632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.65688 (* 1 = 8.65688 loss)
I0523 23:58:28.737861 11654 sgd_solver.cpp:112] Iteration 10170, lr = 0.1
I0523 23:58:36.551224 11654 solver.cpp:239] Iteration 10180 (1.27987 iter/s, 7.81331s/10 iters), loss = 8.20013
I0523 23:58:36.551280 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.20013 (* 1 = 8.20013 loss)
I0523 23:58:36.551815 11654 sgd_solver.cpp:112] Iteration 10180, lr = 0.1
I0523 23:58:42.957800 11654 solver.cpp:239] Iteration 10190 (1.56097 iter/s, 6.40628s/10 iters), loss = 8.9238
I0523 23:58:42.957864 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.9238 (* 1 = 8.9238 loss)
I0523 23:58:42.957942 11654 sgd_solver.cpp:112] Iteration 10190, lr = 0.1
I0523 23:58:50.832835 11654 solver.cpp:239] Iteration 10200 (1.26989 iter/s, 7.87468s/10 iters), loss = 7.93377
I0523 23:58:50.833084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.93377 (* 1 = 7.93377 loss)
I0523 23:58:50.851462 11654 sgd_solver.cpp:112] Iteration 10200, lr = 0.1
I0523 23:58:57.669919 11654 solver.cpp:239] Iteration 10210 (1.46272 iter/s, 6.8366s/10 iters), loss = 8.35264
I0523 23:58:57.669971 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.35264 (* 1 = 8.35264 loss)
I0523 23:58:58.279045 11654 sgd_solver.cpp:112] Iteration 10210, lr = 0.1
I0523 23:59:05.396227 11654 solver.cpp:239] Iteration 10220 (1.29434 iter/s, 7.72597s/10 iters), loss = 8.55856
I0523 23:59:05.396266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.55856 (* 1 = 8.55856 loss)
I0523 23:59:05.396279 11654 sgd_solver.cpp:112] Iteration 10220, lr = 0.1
I0523 23:59:12.074600 11654 solver.cpp:239] Iteration 10230 (1.49744 iter/s, 6.67807s/10 iters), loss = 8.11513
I0523 23:59:12.074651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11513 (* 1 = 8.11513 loss)
I0523 23:59:12.074806 11654 sgd_solver.cpp:112] Iteration 10230, lr = 0.1
I0523 23:59:19.350275 11654 solver.cpp:239] Iteration 10240 (1.3745 iter/s, 7.27535s/10 iters), loss = 8.81586
I0523 23:59:19.350327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.81586 (* 1 = 8.81586 loss)
I0523 23:59:19.350343 11654 sgd_solver.cpp:112] Iteration 10240, lr = 0.1
I0523 23:59:26.369750 11654 solver.cpp:239] Iteration 10250 (1.42469 iter/s, 7.01909s/10 iters), loss = 9.04766
I0523 23:59:26.370029 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.04766 (* 1 = 9.04766 loss)
I0523 23:59:26.370082 11654 sgd_solver.cpp:112] Iteration 10250, lr = 0.1
I0523 23:59:34.325923 11654 solver.cpp:239] Iteration 10260 (1.25731 iter/s, 7.95347s/10 iters), loss = 8.9852
I0523 23:59:34.325979 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.9852 (* 1 = 8.9852 loss)
I0523 23:59:34.332554 11654 sgd_solver.cpp:112] Iteration 10260, lr = 0.1
I0523 23:59:41.283057 11654 solver.cpp:239] Iteration 10270 (1.43744 iter/s, 6.95681s/10 iters), loss = 8.93784
I0523 23:59:41.283105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.93784 (* 1 = 8.93784 loss)
I0523 23:59:41.746080 11654 sgd_solver.cpp:112] Iteration 10270, lr = 0.1
I0523 23:59:49.243583 11654 solver.cpp:239] Iteration 10280 (1.25625 iter/s, 7.96018s/10 iters), loss = 7.71835
I0523 23:59:49.243623 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.71835 (* 1 = 7.71835 loss)
I0523 23:59:49.243638 11654 sgd_solver.cpp:112] Iteration 10280, lr = 0.1
I0523 23:59:56.387545 11654 solver.cpp:239] Iteration 10290 (1.39985 iter/s, 7.14364s/10 iters), loss = 8.63596
I0523 23:59:56.387666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.63596 (* 1 = 8.63596 loss)
I0523 23:59:56.751049 11654 sgd_solver.cpp:112] Iteration 10290, lr = 0.1
I0524 00:00:04.315479 11654 solver.cpp:239] Iteration 10300 (1.26143 iter/s, 7.9275s/10 iters), loss = 9.25753
I0524 00:00:04.315541 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.25753 (* 1 = 9.25753 loss)
I0524 00:00:04.315902 11654 sgd_solver.cpp:112] Iteration 10300, lr = 0.1
I0524 00:00:10.966222 11654 solver.cpp:239] Iteration 10310 (1.50366 iter/s, 6.65042s/10 iters), loss = 9.31538
I0524 00:00:10.966287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.31538 (* 1 = 9.31538 loss)
I0524 00:00:10.980231 11654 sgd_solver.cpp:112] Iteration 10310, lr = 0.1
I0524 00:00:19.446781 11654 solver.cpp:239] Iteration 10320 (1.17922 iter/s, 8.48018s/10 iters), loss = 9.31669
I0524 00:00:19.446841 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.31669 (* 1 = 9.31669 loss)
I0524 00:00:19.446964 11654 sgd_solver.cpp:112] Iteration 10320, lr = 0.1
I0524 00:00:26.358471 11654 solver.cpp:239] Iteration 10330 (1.44689 iter/s, 6.91137s/10 iters), loss = 8.31661
I0524 00:00:26.358527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.31661 (* 1 = 8.31661 loss)
I0524 00:00:26.359041 11654 sgd_solver.cpp:112] Iteration 10330, lr = 0.1
I0524 00:00:34.797910 11654 solver.cpp:239] Iteration 10340 (1.18497 iter/s, 8.43905s/10 iters), loss = 9.24965
I0524 00:00:34.798193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.24965 (* 1 = 9.24965 loss)
I0524 00:00:34.798328 11654 sgd_solver.cpp:112] Iteration 10340, lr = 0.1
I0524 00:00:41.686434 11654 solver.cpp:239] Iteration 10350 (1.45179 iter/s, 6.88803s/10 iters), loss = 8.42193
I0524 00:00:41.686475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.42193 (* 1 = 8.42193 loss)
I0524 00:00:41.688696 11654 sgd_solver.cpp:112] Iteration 10350, lr = 0.1
I0524 00:00:49.487363 11654 solver.cpp:239] Iteration 10360 (1.28196 iter/s, 7.80057s/10 iters), loss = 8.08634
I0524 00:00:49.487479 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.08634 (* 1 = 8.08634 loss)
I0524 00:00:49.653720 11654 sgd_solver.cpp:112] Iteration 10360, lr = 0.1
I0524 00:00:56.669688 11654 solver.cpp:239] Iteration 10370 (1.39238 iter/s, 7.18196s/10 iters), loss = 7.90795
I0524 00:00:56.669749 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90795 (* 1 = 7.90795 loss)
I0524 00:00:56.669905 11654 sgd_solver.cpp:112] Iteration 10370, lr = 0.1
I0524 00:01:03.169414 11654 solver.cpp:239] Iteration 10380 (1.5386 iter/s, 6.49942s/10 iters), loss = 8.19575
I0524 00:01:03.169472 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.19575 (* 1 = 8.19575 loss)
I0524 00:01:03.169591 11654 sgd_solver.cpp:112] Iteration 10380, lr = 0.1
I0524 00:01:10.005359 11654 solver.cpp:239] Iteration 10390 (1.46292 iter/s, 6.83563s/10 iters), loss = 7.62954
I0524 00:01:10.005524 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62954 (* 1 = 7.62954 loss)
I0524 00:01:10.005573 11654 sgd_solver.cpp:112] Iteration 10390, lr = 0.1
I0524 00:01:16.954790 11654 solver.cpp:239] Iteration 10400 (1.43906 iter/s, 6.94899s/10 iters), loss = 8.11164
I0524 00:01:16.954857 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11164 (* 1 = 8.11164 loss)
I0524 00:01:17.472044 11654 sgd_solver.cpp:112] Iteration 10400, lr = 0.1
I0524 00:01:23.806022 11654 solver.cpp:239] Iteration 10410 (1.45966 iter/s, 6.85091s/10 iters), loss = 8.67259
I0524 00:01:23.806071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.67259 (* 1 = 8.67259 loss)
I0524 00:01:23.806258 11654 sgd_solver.cpp:112] Iteration 10410, lr = 0.1
I0524 00:01:30.396553 11654 solver.cpp:239] Iteration 10420 (1.5174 iter/s, 6.59023s/10 iters), loss = 8.89011
I0524 00:01:30.396606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.89011 (* 1 = 8.89011 loss)
I0524 00:01:30.396621 11654 sgd_solver.cpp:112] Iteration 10420, lr = 0.1
I0524 00:01:37.168984 11654 solver.cpp:239] Iteration 10430 (1.47664 iter/s, 6.77212s/10 iters), loss = 7.93545
I0524 00:01:37.169047 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.93545 (* 1 = 7.93545 loss)
I0524 00:01:37.169180 11654 sgd_solver.cpp:112] Iteration 10430, lr = 0.1
I0524 00:01:43.355161 11654 solver.cpp:239] Iteration 10440 (1.61658 iter/s, 6.18589s/10 iters), loss = 9.14567
I0524 00:01:43.355394 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.14567 (* 1 = 9.14567 loss)
I0524 00:01:43.355451 11654 sgd_solver.cpp:112] Iteration 10440, lr = 0.1
I0524 00:01:49.688493 11654 solver.cpp:239] Iteration 10450 (1.57907 iter/s, 6.33285s/10 iters), loss = 7.77514
I0524 00:01:49.688552 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77514 (* 1 = 7.77514 loss)
I0524 00:01:49.688782 11654 sgd_solver.cpp:112] Iteration 10450, lr = 0.1
I0524 00:01:55.805825 11654 solver.cpp:239] Iteration 10460 (1.63477 iter/s, 6.11705s/10 iters), loss = 8.54268
I0524 00:01:55.805866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.54268 (* 1 = 8.54268 loss)
I0524 00:01:55.805877 11654 sgd_solver.cpp:112] Iteration 10460, lr = 0.1
I0524 00:02:02.947523 11654 solver.cpp:239] Iteration 10470 (1.40031 iter/s, 7.14126s/10 iters), loss = 7.82687
I0524 00:02:02.947579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.82687 (* 1 = 7.82687 loss)
I0524 00:02:02.968567 11654 sgd_solver.cpp:112] Iteration 10470, lr = 0.1
I0524 00:02:09.814138 11654 solver.cpp:239] Iteration 10480 (1.45639 iter/s, 6.86631s/10 iters), loss = 8.34059
I0524 00:02:09.814188 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.34059 (* 1 = 8.34059 loss)
I0524 00:02:09.814201 11654 sgd_solver.cpp:112] Iteration 10480, lr = 0.1
I0524 00:02:16.036823 11654 solver.cpp:239] Iteration 10490 (1.6071 iter/s, 6.2224s/10 iters), loss = 8.20993
I0524 00:02:16.037081 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.20993 (* 1 = 8.20993 loss)
I0524 00:02:16.037144 11654 sgd_solver.cpp:112] Iteration 10490, lr = 0.1
I0524 00:02:22.940137 11654 solver.cpp:239] Iteration 10500 (1.44869 iter/s, 6.9028s/10 iters), loss = 8.49681
I0524 00:02:22.940198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.49681 (* 1 = 8.49681 loss)
I0524 00:02:22.940709 11654 sgd_solver.cpp:112] Iteration 10500, lr = 0.1
I0524 00:02:30.181011 11654 solver.cpp:239] Iteration 10510 (1.38111 iter/s, 7.24054s/10 iters), loss = 9.08111
I0524 00:02:30.181058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.08111 (* 1 = 9.08111 loss)
I0524 00:02:30.181601 11654 sgd_solver.cpp:112] Iteration 10510, lr = 0.1
I0524 00:02:37.910576 11654 solver.cpp:239] Iteration 10520 (1.29379 iter/s, 7.72922s/10 iters), loss = 9.25682
I0524 00:02:37.910630 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.25682 (* 1 = 9.25682 loss)
I0524 00:02:37.910648 11654 sgd_solver.cpp:112] Iteration 10520, lr = 0.1
I0524 00:02:44.994539 11654 solver.cpp:239] Iteration 10530 (1.41172 iter/s, 7.08358s/10 iters), loss = 8.74597
I0524 00:02:44.994580 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.74597 (* 1 = 8.74597 loss)
I0524 00:02:44.994593 11654 sgd_solver.cpp:112] Iteration 10530, lr = 0.1
I0524 00:02:55.119555 11654 solver.cpp:239] Iteration 10540 (0.987913 iter/s, 10.1224s/10 iters), loss = 8.89911
I0524 00:02:55.119725 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.89911 (* 1 = 8.89911 loss)
I0524 00:02:55.119745 11654 sgd_solver.cpp:112] Iteration 10540, lr = 0.1
I0524 00:03:02.232395 11654 solver.cpp:239] Iteration 10550 (1.40641 iter/s, 7.11029s/10 iters), loss = 7.95433
I0524 00:03:02.232434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.95433 (* 1 = 7.95433 loss)
I0524 00:03:02.232475 11654 sgd_solver.cpp:112] Iteration 10550, lr = 0.1
I0524 00:03:08.711328 11654 solver.cpp:239] Iteration 10560 (1.54354 iter/s, 6.47863s/10 iters), loss = 8.11913
I0524 00:03:08.711393 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11913 (* 1 = 8.11913 loss)
I0524 00:03:08.711863 11654 sgd_solver.cpp:112] Iteration 10560, lr = 0.1
I0524 00:03:15.254236 11654 solver.cpp:239] Iteration 10570 (1.52844 iter/s, 6.54261s/10 iters), loss = 8.11968
I0524 00:03:15.254279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11968 (* 1 = 8.11968 loss)
I0524 00:03:15.254292 11654 sgd_solver.cpp:112] Iteration 10570, lr = 0.1
I0524 00:03:21.533617 11654 solver.cpp:239] Iteration 10580 (1.59315 iter/s, 6.27686s/10 iters), loss = 8.23003
I0524 00:03:21.533671 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.23003 (* 1 = 8.23003 loss)
I0524 00:03:21.578194 11654 sgd_solver.cpp:112] Iteration 10580, lr = 0.1
I0524 00:03:28.529098 11654 solver.cpp:239] Iteration 10590 (1.42956 iter/s, 6.99517s/10 iters), loss = 8.19793
I0524 00:03:28.529322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.19793 (* 1 = 8.19793 loss)
I0524 00:03:28.529386 11654 sgd_solver.cpp:112] Iteration 10590, lr = 0.1
I0524 00:03:38.893182 11654 solver.cpp:239] Iteration 10600 (0.965113 iter/s, 10.3615s/10 iters), loss = 8.56816
I0524 00:03:38.893247 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.56816 (* 1 = 8.56816 loss)
I0524 00:03:38.893571 11654 sgd_solver.cpp:112] Iteration 10600, lr = 0.1
I0524 00:03:46.418331 11654 solver.cpp:239] Iteration 10610 (1.32894 iter/s, 7.52478s/10 iters), loss = 8.65149
I0524 00:03:46.418442 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.65149 (* 1 = 8.65149 loss)
I0524 00:03:46.418921 11654 sgd_solver.cpp:112] Iteration 10610, lr = 0.1
I0524 00:03:53.060708 11654 solver.cpp:239] Iteration 10620 (1.50556 iter/s, 6.64205s/10 iters), loss = 8.45673
I0524 00:03:53.060761 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.45673 (* 1 = 8.45673 loss)
I0524 00:03:53.060868 11654 sgd_solver.cpp:112] Iteration 10620, lr = 0.1
I0524 00:03:59.509572 11654 solver.cpp:239] Iteration 10630 (1.55073 iter/s, 6.44857s/10 iters), loss = 8.67225
I0524 00:03:59.509835 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.67225 (* 1 = 8.67225 loss)
I0524 00:03:59.509905 11654 sgd_solver.cpp:112] Iteration 10630, lr = 0.1
I0524 00:04:06.861446 11654 solver.cpp:239] Iteration 10640 (1.3603 iter/s, 7.35133s/10 iters), loss = 8.55078
I0524 00:04:06.861500 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.55078 (* 1 = 8.55078 loss)
I0524 00:04:07.334398 11654 sgd_solver.cpp:112] Iteration 10640, lr = 0.1
I0524 00:04:13.876600 11654 solver.cpp:239] Iteration 10650 (1.42555 iter/s, 7.01484s/10 iters), loss = 9.05206
I0524 00:04:13.876652 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.05206 (* 1 = 9.05206 loss)
I0524 00:04:13.876677 11654 sgd_solver.cpp:112] Iteration 10650, lr = 0.1
I0524 00:04:20.461170 11654 solver.cpp:239] Iteration 10660 (1.51923 iter/s, 6.58227s/10 iters), loss = 8.16379
I0524 00:04:20.461230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.16379 (* 1 = 8.16379 loss)
I0524 00:04:20.628037 11654 sgd_solver.cpp:112] Iteration 10660, lr = 0.1
I0524 00:04:27.685967 11654 solver.cpp:239] Iteration 10670 (1.38418 iter/s, 7.22447s/10 iters), loss = 9.08107
I0524 00:04:27.686023 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.08107 (* 1 = 9.08107 loss)
I0524 00:04:27.696655 11654 sgd_solver.cpp:112] Iteration 10670, lr = 0.1
I0524 00:04:36.385062 11654 solver.cpp:239] Iteration 10680 (1.1496 iter/s, 8.69871s/10 iters), loss = 8.55329
I0524 00:04:36.385378 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.55329 (* 1 = 8.55329 loss)
I0524 00:04:36.385434 11654 sgd_solver.cpp:112] Iteration 10680, lr = 0.1
I0524 00:04:42.653874 11654 solver.cpp:239] Iteration 10690 (1.59532 iter/s, 6.26832s/10 iters), loss = 8.25717
I0524 00:04:42.653914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.25717 (* 1 = 8.25717 loss)
I0524 00:04:42.788328 11654 sgd_solver.cpp:112] Iteration 10690, lr = 0.1
I0524 00:04:49.720353 11654 solver.cpp:239] Iteration 10700 (1.4152 iter/s, 7.06616s/10 iters), loss = 7.90812
I0524 00:04:49.720405 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90812 (* 1 = 7.90812 loss)
I0524 00:04:49.720420 11654 sgd_solver.cpp:112] Iteration 10700, lr = 0.1
I0524 00:04:56.803195 11654 solver.cpp:239] Iteration 10710 (1.41193 iter/s, 7.08253s/10 iters), loss = 8.06911
I0524 00:04:56.803236 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.06911 (* 1 = 8.06911 loss)
I0524 00:04:56.803503 11654 sgd_solver.cpp:112] Iteration 10710, lr = 0.1
I0524 00:05:03.072093 11654 solver.cpp:239] Iteration 10720 (1.59525 iter/s, 6.26862s/10 iters), loss = 8.32991
I0524 00:05:03.072136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.32991 (* 1 = 8.32991 loss)
I0524 00:05:03.072150 11654 sgd_solver.cpp:112] Iteration 10720, lr = 0.1
I0524 00:05:09.352562 11654 solver.cpp:239] Iteration 10730 (1.59231 iter/s, 6.28019s/10 iters), loss = 7.28085
I0524 00:05:09.352843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28085 (* 1 = 7.28085 loss)
I0524 00:05:09.352913 11654 sgd_solver.cpp:112] Iteration 10730, lr = 0.1
I0524 00:05:16.629393 11654 solver.cpp:239] Iteration 10740 (1.37432 iter/s, 7.2763s/10 iters), loss = 8.24268
I0524 00:05:16.629478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.24268 (* 1 = 8.24268 loss)
I0524 00:05:16.631377 11654 sgd_solver.cpp:112] Iteration 10740, lr = 0.1
I0524 00:05:26.381680 11654 solver.cpp:239] Iteration 10750 (1.02545 iter/s, 9.75185s/10 iters), loss = 8.11016
I0524 00:05:26.381731 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11016 (* 1 = 8.11016 loss)
I0524 00:05:26.381860 11654 sgd_solver.cpp:112] Iteration 10750, lr = 0.1
I0524 00:05:33.754654 11654 solver.cpp:239] Iteration 10760 (1.35636 iter/s, 7.37266s/10 iters), loss = 8.40491
I0524 00:05:33.754710 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.40491 (* 1 = 8.40491 loss)
I0524 00:05:33.754727 11654 sgd_solver.cpp:112] Iteration 10760, lr = 0.1
I0524 00:05:40.256996 11654 solver.cpp:239] Iteration 10770 (1.53799 iter/s, 6.50198s/10 iters), loss = 9.25829
I0524 00:05:40.257113 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.25829 (* 1 = 9.25829 loss)
I0524 00:05:40.366680 11654 sgd_solver.cpp:112] Iteration 10770, lr = 0.1
I0524 00:05:48.151166 11654 solver.cpp:239] Iteration 10780 (1.26682 iter/s, 7.89376s/10 iters), loss = 7.85864
I0524 00:05:48.151212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85864 (* 1 = 7.85864 loss)
I0524 00:05:48.162931 11654 sgd_solver.cpp:112] Iteration 10780, lr = 0.1
I0524 00:05:55.570881 11654 solver.cpp:239] Iteration 10790 (1.34782 iter/s, 7.41938s/10 iters), loss = 8.47083
I0524 00:05:55.570931 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.47083 (* 1 = 8.47083 loss)
I0524 00:05:56.588495 11654 sgd_solver.cpp:112] Iteration 10790, lr = 0.1
I0524 00:06:03.056730 11654 solver.cpp:239] Iteration 10800 (1.33592 iter/s, 7.48546s/10 iters), loss = 8.12004
I0524 00:06:03.056805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.12004 (* 1 = 8.12004 loss)
I0524 00:06:03.057202 11654 sgd_solver.cpp:112] Iteration 10800, lr = 0.1
I0524 00:06:09.465173 11654 solver.cpp:239] Iteration 10810 (1.56052 iter/s, 6.40813s/10 iters), loss = 8.15035
I0524 00:06:09.465237 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.15035 (* 1 = 8.15035 loss)
I0524 00:06:09.465260 11654 sgd_solver.cpp:112] Iteration 10810, lr = 0.1
I0524 00:06:15.679570 11654 solver.cpp:239] Iteration 10820 (1.60924 iter/s, 6.21411s/10 iters), loss = 8.02616
I0524 00:06:15.679774 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.02616 (* 1 = 8.02616 loss)
I0524 00:06:15.679795 11654 sgd_solver.cpp:112] Iteration 10820, lr = 0.1
I0524 00:06:23.806548 11654 solver.cpp:239] Iteration 10830 (1.23055 iter/s, 8.12645s/10 iters), loss = 8.81786
I0524 00:06:23.806602 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.81786 (* 1 = 8.81786 loss)
I0524 00:06:23.806618 11654 sgd_solver.cpp:112] Iteration 10830, lr = 0.1
I0524 00:06:30.666746 11654 solver.cpp:239] Iteration 10840 (1.45776 iter/s, 6.85982s/10 iters), loss = 8.3016
I0524 00:06:30.666802 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.3016 (* 1 = 8.3016 loss)
I0524 00:06:30.729427 11654 sgd_solver.cpp:112] Iteration 10840, lr = 0.1
I0524 00:06:37.584046 11654 solver.cpp:239] Iteration 10850 (1.44572 iter/s, 6.91699s/10 iters), loss = 8.62446
I0524 00:06:37.584094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.62446 (* 1 = 8.62446 loss)
I0524 00:06:37.584214 11654 sgd_solver.cpp:112] Iteration 10850, lr = 0.1
I0524 00:06:44.804800 11654 solver.cpp:239] Iteration 10860 (1.38496 iter/s, 7.22043s/10 iters), loss = 8.0218
I0524 00:06:44.804852 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.0218 (* 1 = 8.0218 loss)
I0524 00:06:44.805768 11654 sgd_solver.cpp:112] Iteration 10860, lr = 0.1
I0524 00:06:51.574159 11654 solver.cpp:239] Iteration 10870 (1.47731 iter/s, 6.76906s/10 iters), loss = 8.00447
I0524 00:06:51.574417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.00447 (* 1 = 8.00447 loss)
I0524 00:06:51.574476 11654 sgd_solver.cpp:112] Iteration 10870, lr = 0.1
I0524 00:06:58.725234 11654 solver.cpp:239] Iteration 10880 (1.3985 iter/s, 7.15053s/10 iters), loss = 8.41305
I0524 00:06:58.725286 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.41305 (* 1 = 8.41305 loss)
I0524 00:06:58.743937 11654 sgd_solver.cpp:112] Iteration 10880, lr = 0.1
I0524 00:07:04.803439 11654 solver.cpp:239] Iteration 10890 (1.6453 iter/s, 6.07792s/10 iters), loss = 7.80062
I0524 00:07:04.803503 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.80062 (* 1 = 7.80062 loss)
I0524 00:07:04.803680 11654 sgd_solver.cpp:112] Iteration 10890, lr = 0.1
I0524 00:07:11.725136 11654 solver.cpp:239] Iteration 10900 (1.4448 iter/s, 6.92138s/10 iters), loss = 8.33037
I0524 00:07:11.725172 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.33037 (* 1 = 8.33037 loss)
I0524 00:07:11.725185 11654 sgd_solver.cpp:112] Iteration 10900, lr = 0.1
I0524 00:07:18.905036 11654 solver.cpp:239] Iteration 10910 (1.39284 iter/s, 7.17959s/10 iters), loss = 8.78496
I0524 00:07:18.905097 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.78496 (* 1 = 8.78496 loss)
I0524 00:07:18.905251 11654 sgd_solver.cpp:112] Iteration 10910, lr = 0.1
I0524 00:07:26.893661 11654 solver.cpp:239] Iteration 10920 (1.25183 iter/s, 7.98828s/10 iters), loss = 8.87906
I0524 00:07:26.893853 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.87906 (* 1 = 8.87906 loss)
I0524 00:07:26.893887 11654 sgd_solver.cpp:112] Iteration 10920, lr = 0.1
I0524 00:07:35.249889 11654 solver.cpp:239] Iteration 10930 (1.19679 iter/s, 8.35571s/10 iters), loss = 9.06017
I0524 00:07:35.249938 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.06017 (* 1 = 9.06017 loss)
I0524 00:07:35.249954 11654 sgd_solver.cpp:112] Iteration 10930, lr = 0.1
I0524 00:07:43.140401 11654 solver.cpp:239] Iteration 10940 (1.26741 iter/s, 7.8901s/10 iters), loss = 7.88928
I0524 00:07:43.140455 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.88928 (* 1 = 7.88928 loss)
I0524 00:07:43.655609 11654 sgd_solver.cpp:112] Iteration 10940, lr = 0.1
I0524 00:07:50.604550 11654 solver.cpp:239] Iteration 10950 (1.3398 iter/s, 7.46382s/10 iters), loss = 9.38408
I0524 00:07:50.604589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.38408 (* 1 = 9.38408 loss)
I0524 00:07:50.604604 11654 sgd_solver.cpp:112] Iteration 10950, lr = 0.1
I0524 00:07:59.151239 11654 solver.cpp:239] Iteration 10960 (1.17018 iter/s, 8.5457s/10 iters), loss = 7.96665
I0524 00:07:59.151551 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.96665 (* 1 = 7.96665 loss)
I0524 00:07:59.151767 11654 sgd_solver.cpp:112] Iteration 10960, lr = 0.1
I0524 00:08:05.698602 11654 solver.cpp:239] Iteration 10970 (1.52745 iter/s, 6.54686s/10 iters), loss = 8.31042
I0524 00:08:05.698652 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.31042 (* 1 = 8.31042 loss)
I0524 00:08:05.714311 11654 sgd_solver.cpp:112] Iteration 10970, lr = 0.1
I0524 00:08:13.029422 11654 solver.cpp:239] Iteration 10980 (1.36416 iter/s, 7.33049s/10 iters), loss = 7.36299
I0524 00:08:13.029467 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36299 (* 1 = 7.36299 loss)
I0524 00:08:13.029603 11654 sgd_solver.cpp:112] Iteration 10980, lr = 0.1
I0524 00:08:19.654392 11654 solver.cpp:239] Iteration 10990 (1.50951 iter/s, 6.62466s/10 iters), loss = 8.84875
I0524 00:08:19.654451 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.84875 (* 1 = 8.84875 loss)
I0524 00:08:19.654616 11654 sgd_solver.cpp:112] Iteration 10990, lr = 0.1
I0524 00:08:26.734974 11654 solver.cpp:239] Iteration 11000 (1.41238 iter/s, 7.08025s/10 iters), loss = 7.32232
I0524 00:08:26.735052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32232 (* 1 = 7.32232 loss)
I0524 00:08:26.735071 11654 sgd_solver.cpp:112] Iteration 11000, lr = 0.1
I0524 00:08:34.325628 11654 solver.cpp:239] Iteration 11010 (1.31748 iter/s, 7.59026s/10 iters), loss = 7.82806
I0524 00:08:34.325758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.82806 (* 1 = 7.82806 loss)
I0524 00:08:34.325778 11654 sgd_solver.cpp:112] Iteration 11010, lr = 0.1
I0524 00:08:40.484499 11654 solver.cpp:239] Iteration 11020 (1.62378 iter/s, 6.15848s/10 iters), loss = 7.82859
I0524 00:08:40.484546 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.82859 (* 1 = 7.82859 loss)
I0524 00:08:40.484952 11654 sgd_solver.cpp:112] Iteration 11020, lr = 0.1
I0524 00:08:47.268030 11654 solver.cpp:239] Iteration 11030 (1.47423 iter/s, 6.78322s/10 iters), loss = 7.86939
I0524 00:08:47.268084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86939 (* 1 = 7.86939 loss)
I0524 00:08:47.268316 11654 sgd_solver.cpp:112] Iteration 11030, lr = 0.1
I0524 00:08:53.845947 11654 solver.cpp:239] Iteration 11040 (1.52031 iter/s, 6.57762s/10 iters), loss = 7.90696
I0524 00:08:53.846000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90696 (* 1 = 7.90696 loss)
I0524 00:08:53.846019 11654 sgd_solver.cpp:112] Iteration 11040, lr = 0.1
I0524 00:09:01.752207 11654 solver.cpp:239] Iteration 11050 (1.26498 iter/s, 7.90529s/10 iters), loss = 7.48994
I0524 00:09:01.752246 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48994 (* 1 = 7.48994 loss)
I0524 00:09:01.752260 11654 sgd_solver.cpp:112] Iteration 11050, lr = 0.1
I0524 00:09:10.237733 11654 solver.cpp:239] Iteration 11060 (1.17884 iter/s, 8.48293s/10 iters), loss = 7.39793
I0524 00:09:10.237881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39793 (* 1 = 7.39793 loss)
I0524 00:09:10.237900 11654 sgd_solver.cpp:112] Iteration 11060, lr = 0.1
I0524 00:09:18.531198 11654 solver.cpp:239] Iteration 11070 (1.20584 iter/s, 8.29298s/10 iters), loss = 7.80976
I0524 00:09:18.531236 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.80976 (* 1 = 7.80976 loss)
I0524 00:09:18.564275 11654 sgd_solver.cpp:112] Iteration 11070, lr = 0.1
I0524 00:09:27.497469 11654 solver.cpp:239] Iteration 11080 (1.11534 iter/s, 8.96589s/10 iters), loss = 8.36978
I0524 00:09:27.497525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.36978 (* 1 = 8.36978 loss)
I0524 00:09:27.846779 11654 sgd_solver.cpp:112] Iteration 11080, lr = 0.1
I0524 00:09:34.828915 11654 solver.cpp:239] Iteration 11090 (1.36405 iter/s, 7.33112s/10 iters), loss = 7.56428
I0524 00:09:34.828972 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.56428 (* 1 = 7.56428 loss)
I0524 00:09:34.829264 11654 sgd_solver.cpp:112] Iteration 11090, lr = 0.1
I0524 00:09:42.267423 11654 solver.cpp:239] Iteration 11100 (1.34442 iter/s, 7.43817s/10 iters), loss = 8.03605
I0524 00:09:42.267715 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.03605 (* 1 = 8.03605 loss)
I0524 00:09:42.269281 11654 sgd_solver.cpp:112] Iteration 11100, lr = 0.1
I0524 00:09:50.636409 11654 solver.cpp:239] Iteration 11110 (1.19497 iter/s, 8.36844s/10 iters), loss = 8.13678
I0524 00:09:50.636451 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.13678 (* 1 = 8.13678 loss)
I0524 00:09:50.636467 11654 sgd_solver.cpp:112] Iteration 11110, lr = 0.1
I0524 00:09:57.274726 11654 solver.cpp:239] Iteration 11120 (1.50699 iter/s, 6.63576s/10 iters), loss = 8.24947
I0524 00:09:57.274782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.24947 (* 1 = 8.24947 loss)
I0524 00:09:57.274798 11654 sgd_solver.cpp:112] Iteration 11120, lr = 0.1
I0524 00:10:03.604765 11654 solver.cpp:239] Iteration 11130 (1.57999 iter/s, 6.32914s/10 iters), loss = 7.8138
I0524 00:10:03.604816 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8138 (* 1 = 7.8138 loss)
I0524 00:10:03.604831 11654 sgd_solver.cpp:112] Iteration 11130, lr = 0.1
I0524 00:10:11.095036 11654 solver.cpp:239] Iteration 11140 (1.33512 iter/s, 7.48994s/10 iters), loss = 8.37179
I0524 00:10:11.095108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.37179 (* 1 = 8.37179 loss)
I0524 00:10:11.095126 11654 sgd_solver.cpp:112] Iteration 11140, lr = 0.1
I0524 00:10:17.980087 11654 solver.cpp:239] Iteration 11150 (1.45249 iter/s, 6.88473s/10 iters), loss = 9.15814
I0524 00:10:17.980342 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.15814 (* 1 = 9.15814 loss)
I0524 00:10:17.980396 11654 sgd_solver.cpp:112] Iteration 11150, lr = 0.1
I0524 00:10:25.939260 11654 solver.cpp:239] Iteration 11160 (1.25649 iter/s, 7.95867s/10 iters), loss = 7.72829
I0524 00:10:25.939312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.72829 (* 1 = 7.72829 loss)
I0524 00:10:26.062201 11654 sgd_solver.cpp:112] Iteration 11160, lr = 0.1
I0524 00:10:33.963196 11654 solver.cpp:239] Iteration 11170 (1.24633 iter/s, 8.02358s/10 iters), loss = 8.2933
I0524 00:10:33.963258 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.2933 (* 1 = 8.2933 loss)
I0524 00:10:33.963277 11654 sgd_solver.cpp:112] Iteration 11170, lr = 0.1
I0524 00:10:42.506543 11654 solver.cpp:239] Iteration 11180 (1.17055 iter/s, 8.54298s/10 iters), loss = 8.44447
I0524 00:10:42.506592 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.44447 (* 1 = 8.44447 loss)
I0524 00:10:42.508471 11654 sgd_solver.cpp:112] Iteration 11180, lr = 0.1
I0524 00:10:49.196971 11654 solver.cpp:239] Iteration 11190 (1.49474 iter/s, 6.69012s/10 iters), loss = 8.30317
I0524 00:10:49.197211 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.30317 (* 1 = 8.30317 loss)
I0524 00:10:49.197295 11654 sgd_solver.cpp:112] Iteration 11190, lr = 0.1
I0524 00:10:57.493926 11654 solver.cpp:239] Iteration 11200 (1.20534 iter/s, 8.29643s/10 iters), loss = 8.30035
I0524 00:10:57.493975 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.30035 (* 1 = 8.30035 loss)
I0524 00:10:58.019654 11654 sgd_solver.cpp:112] Iteration 11200, lr = 0.1
I0524 00:11:04.330947 11654 solver.cpp:239] Iteration 11210 (1.46269 iter/s, 6.83672s/10 iters), loss = 7.57566
I0524 00:11:04.330994 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.57566 (* 1 = 7.57566 loss)
I0524 00:11:04.331346 11654 sgd_solver.cpp:112] Iteration 11210, lr = 0.1
I0524 00:11:11.738009 11654 solver.cpp:239] Iteration 11220 (1.35012 iter/s, 7.40674s/10 iters), loss = 7.52258
I0524 00:11:11.738046 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.52258 (* 1 = 7.52258 loss)
I0524 00:11:12.185545 11654 sgd_solver.cpp:112] Iteration 11220, lr = 0.1
I0524 00:11:18.819533 11654 solver.cpp:239] Iteration 11230 (1.41219 iter/s, 7.08122s/10 iters), loss = 8.49172
I0524 00:11:18.819573 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.49172 (* 1 = 8.49172 loss)
I0524 00:11:18.834101 11654 sgd_solver.cpp:112] Iteration 11230, lr = 0.1
I0524 00:11:25.990769 11654 solver.cpp:239] Iteration 11240 (1.39452 iter/s, 7.17093s/10 iters), loss = 8.72275
I0524 00:11:25.990985 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.72275 (* 1 = 8.72275 loss)
I0524 00:11:25.991029 11654 sgd_solver.cpp:112] Iteration 11240, lr = 0.1
I0524 00:11:33.012116 11654 solver.cpp:239] Iteration 11250 (1.42433 iter/s, 7.02086s/10 iters), loss = 8.69483
I0524 00:11:33.012171 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.69483 (* 1 = 8.69483 loss)
I0524 00:11:33.012189 11654 sgd_solver.cpp:112] Iteration 11250, lr = 0.1
I0524 00:11:40.224360 11654 solver.cpp:239] Iteration 11260 (1.38661 iter/s, 7.21184s/10 iters), loss = 7.94686
I0524 00:11:40.224422 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.94686 (* 1 = 7.94686 loss)
I0524 00:11:40.224645 11654 sgd_solver.cpp:112] Iteration 11260, lr = 0.1
I0524 00:11:48.741358 11654 solver.cpp:239] Iteration 11270 (1.17418 iter/s, 8.51661s/10 iters), loss = 8.95783
I0524 00:11:48.741415 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.95783 (* 1 = 8.95783 loss)
I0524 00:11:48.741767 11654 sgd_solver.cpp:112] Iteration 11270, lr = 0.1
I0524 00:11:55.105569 11654 solver.cpp:239] Iteration 11280 (1.57136 iter/s, 6.36392s/10 iters), loss = 8.59259
I0524 00:11:55.105615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.59259 (* 1 = 8.59259 loss)
I0524 00:11:55.105785 11654 sgd_solver.cpp:112] Iteration 11280, lr = 0.1
I0524 00:12:01.042189 11654 solver.cpp:239] Iteration 11290 (1.68454 iter/s, 5.93635s/10 iters), loss = 8.46166
I0524 00:12:01.042462 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.46166 (* 1 = 8.46166 loss)
I0524 00:12:01.042526 11654 sgd_solver.cpp:112] Iteration 11290, lr = 0.1
I0524 00:12:08.650115 11654 solver.cpp:239] Iteration 11300 (1.31451 iter/s, 7.60738s/10 iters), loss = 8.62827
I0524 00:12:08.650187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.62827 (* 1 = 8.62827 loss)
I0524 00:12:08.650596 11654 sgd_solver.cpp:112] Iteration 11300, lr = 0.1
I0524 00:12:16.196146 11654 solver.cpp:239] Iteration 11310 (1.32526 iter/s, 7.54568s/10 iters), loss = 8.43892
I0524 00:12:16.196213 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.43892 (* 1 = 8.43892 loss)
I0524 00:12:16.196561 11654 sgd_solver.cpp:112] Iteration 11310, lr = 0.1
I0524 00:12:22.659560 11654 solver.cpp:239] Iteration 11320 (1.54724 iter/s, 6.46312s/10 iters), loss = 7.91809
I0524 00:12:22.659600 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91809 (* 1 = 7.91809 loss)
I0524 00:12:22.659787 11654 sgd_solver.cpp:112] Iteration 11320, lr = 0.1
I0524 00:12:29.283514 11654 solver.cpp:239] Iteration 11330 (1.50974 iter/s, 6.62365s/10 iters), loss = 8.77024
I0524 00:12:29.283574 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.77024 (* 1 = 8.77024 loss)
I0524 00:12:29.283849 11654 sgd_solver.cpp:112] Iteration 11330, lr = 0.1
I0524 00:12:36.697134 11654 solver.cpp:239] Iteration 11340 (1.34893 iter/s, 7.41327s/10 iters), loss = 8.4893
I0524 00:12:36.697453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.4893 (* 1 = 8.4893 loss)
I0524 00:12:36.697504 11654 sgd_solver.cpp:112] Iteration 11340, lr = 0.1
I0524 00:12:42.919492 11654 solver.cpp:239] Iteration 11350 (1.60728 iter/s, 6.22168s/10 iters), loss = 7.9776
I0524 00:12:42.919538 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9776 (* 1 = 7.9776 loss)
I0524 00:12:42.919746 11654 sgd_solver.cpp:112] Iteration 11350, lr = 0.1
I0524 00:12:50.756201 11654 solver.cpp:239] Iteration 11360 (1.2761 iter/s, 7.83636s/10 iters), loss = 8.30012
I0524 00:12:50.756258 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.30012 (* 1 = 8.30012 loss)
I0524 00:12:50.762148 11654 sgd_solver.cpp:112] Iteration 11360, lr = 0.1
I0524 00:12:59.338021 11654 solver.cpp:239] Iteration 11370 (1.1653 iter/s, 8.58145s/10 iters), loss = 7.76752
I0524 00:12:59.338069 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76752 (* 1 = 7.76752 loss)
I0524 00:12:59.338086 11654 sgd_solver.cpp:112] Iteration 11370, lr = 0.1
I0524 00:13:06.004549 11654 solver.cpp:239] Iteration 11380 (1.50011 iter/s, 6.66616s/10 iters), loss = 8.91929
I0524 00:13:06.004603 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.91929 (* 1 = 8.91929 loss)
I0524 00:13:06.004619 11654 sgd_solver.cpp:112] Iteration 11380, lr = 0.1
I0524 00:13:13.337445 11654 solver.cpp:239] Iteration 11390 (1.36379 iter/s, 7.3325s/10 iters), loss = 8.22418
I0524 00:13:13.337716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.22418 (* 1 = 8.22418 loss)
I0524 00:13:13.337764 11654 sgd_solver.cpp:112] Iteration 11390, lr = 0.1
I0524 00:13:20.560299 11654 solver.cpp:239] Iteration 11400 (1.38468 iter/s, 7.22188s/10 iters), loss = 9.19618
I0524 00:13:20.560359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.19618 (* 1 = 9.19618 loss)
I0524 00:13:20.560545 11654 sgd_solver.cpp:112] Iteration 11400, lr = 0.1
I0524 00:13:27.443539 11654 solver.cpp:239] Iteration 11410 (1.45287 iter/s, 6.88292s/10 iters), loss = 7.9926
I0524 00:13:27.443598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9926 (* 1 = 7.9926 loss)
I0524 00:13:27.443619 11654 sgd_solver.cpp:112] Iteration 11410, lr = 0.1
I0524 00:13:35.308573 11654 solver.cpp:239] Iteration 11420 (1.27187 iter/s, 7.86244s/10 iters), loss = 8.26713
I0524 00:13:35.308646 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.26713 (* 1 = 8.26713 loss)
I0524 00:13:35.411439 11654 sgd_solver.cpp:112] Iteration 11420, lr = 0.1
I0524 00:13:42.943182 11654 solver.cpp:239] Iteration 11430 (1.30988 iter/s, 7.63426s/10 iters), loss = 8.85838
I0524 00:13:42.943229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.85838 (* 1 = 8.85838 loss)
I0524 00:13:42.943590 11654 sgd_solver.cpp:112] Iteration 11430, lr = 0.1
I0524 00:13:50.418494 11654 solver.cpp:239] Iteration 11440 (1.3378 iter/s, 7.47497s/10 iters), loss = 9.09939
I0524 00:13:50.418817 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.09939 (* 1 = 9.09939 loss)
I0524 00:13:50.457630 11654 sgd_solver.cpp:112] Iteration 11440, lr = 0.1
I0524 00:13:59.266559 11654 solver.cpp:239] Iteration 11450 (1.13026 iter/s, 8.84753s/10 iters), loss = 7.95283
I0524 00:13:59.266607 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.95283 (* 1 = 7.95283 loss)
I0524 00:13:59.266623 11654 sgd_solver.cpp:112] Iteration 11450, lr = 0.1
I0524 00:14:05.875187 11654 solver.cpp:239] Iteration 11460 (1.51334 iter/s, 6.60791s/10 iters), loss = 8.23429
I0524 00:14:05.875244 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.23429 (* 1 = 8.23429 loss)
I0524 00:14:06.104650 11654 sgd_solver.cpp:112] Iteration 11460, lr = 0.1
I0524 00:14:12.940361 11654 solver.cpp:239] Iteration 11470 (1.41546 iter/s, 7.06485s/10 iters), loss = 7.8279
I0524 00:14:12.940403 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8279 (* 1 = 7.8279 loss)
I0524 00:14:13.060958 11654 sgd_solver.cpp:112] Iteration 11470, lr = 0.1
I0524 00:14:19.315512 11654 solver.cpp:239] Iteration 11480 (1.56866 iter/s, 6.37486s/10 iters), loss = 7.78699
I0524 00:14:19.315577 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78699 (* 1 = 7.78699 loss)
I0524 00:14:19.315593 11654 sgd_solver.cpp:112] Iteration 11480, lr = 0.1
I0524 00:14:28.861308 11654 solver.cpp:239] Iteration 11490 (1.04763 iter/s, 9.54539s/10 iters), loss = 7.9406
I0524 00:14:28.861579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9406 (* 1 = 7.9406 loss)
I0524 00:14:28.861816 11654 sgd_solver.cpp:112] Iteration 11490, lr = 0.1
I0524 00:14:36.732282 11654 solver.cpp:239] Iteration 11500 (1.27058 iter/s, 7.87043s/10 iters), loss = 8.93004
I0524 00:14:36.732347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.93004 (* 1 = 8.93004 loss)
I0524 00:14:36.732729 11654 sgd_solver.cpp:112] Iteration 11500, lr = 0.1
I0524 00:14:42.956781 11654 solver.cpp:239] Iteration 11510 (1.60663 iter/s, 6.22421s/10 iters), loss = 8.6085
I0524 00:14:42.956820 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.6085 (* 1 = 8.6085 loss)
I0524 00:14:43.153812 11654 sgd_solver.cpp:112] Iteration 11510, lr = 0.1
I0524 00:14:50.559450 11654 solver.cpp:239] Iteration 11520 (1.31539 iter/s, 7.60233s/10 iters), loss = 8.81844
I0524 00:14:50.559504 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.81844 (* 1 = 8.81844 loss)
I0524 00:14:50.559520 11654 sgd_solver.cpp:112] Iteration 11520, lr = 0.1
I0524 00:14:57.267314 11654 solver.cpp:239] Iteration 11530 (1.49087 iter/s, 6.70749s/10 iters), loss = 9.18844
I0524 00:14:57.267366 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.18844 (* 1 = 9.18844 loss)
I0524 00:14:57.500581 11654 sgd_solver.cpp:112] Iteration 11530, lr = 0.1
I0524 00:15:04.605692 11654 solver.cpp:239] Iteration 11540 (1.36276 iter/s, 7.33804s/10 iters), loss = 8.92794
I0524 00:15:04.605990 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.92794 (* 1 = 8.92794 loss)
I0524 00:15:04.606063 11654 sgd_solver.cpp:112] Iteration 11540, lr = 0.1
I0524 00:15:11.679803 11654 solver.cpp:239] Iteration 11550 (1.41411 iter/s, 7.07157s/10 iters), loss = 7.51213
I0524 00:15:11.679852 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51213 (* 1 = 7.51213 loss)
I0524 00:15:11.681802 11654 sgd_solver.cpp:112] Iteration 11550, lr = 0.1
I0524 00:15:19.102538 11654 solver.cpp:239] Iteration 11560 (1.34727 iter/s, 7.4224s/10 iters), loss = 8.47573
I0524 00:15:19.102589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.47573 (* 1 = 8.47573 loss)
I0524 00:15:19.991777 11654 sgd_solver.cpp:112] Iteration 11560, lr = 0.1
I0524 00:15:27.155761 11654 solver.cpp:239] Iteration 11570 (1.24179 iter/s, 8.05286s/10 iters), loss = 8.83158
I0524 00:15:27.155824 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.83158 (* 1 = 8.83158 loss)
I0524 00:15:27.156276 11654 sgd_solver.cpp:112] Iteration 11570, lr = 0.1
I0524 00:15:34.755796 11654 solver.cpp:239] Iteration 11580 (1.31584 iter/s, 7.5997s/10 iters), loss = 8.53955
I0524 00:15:34.756001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.53955 (* 1 = 8.53955 loss)
I0524 00:15:34.756031 11654 sgd_solver.cpp:112] Iteration 11580, lr = 0.1
I0524 00:15:42.437850 11654 solver.cpp:239] Iteration 11590 (1.30182 iter/s, 7.68156s/10 iters), loss = 8.87379
I0524 00:15:42.437899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.87379 (* 1 = 8.87379 loss)
I0524 00:15:42.769227 11654 sgd_solver.cpp:112] Iteration 11590, lr = 0.1
I0524 00:15:49.841784 11654 solver.cpp:239] Iteration 11600 (1.35069 iter/s, 7.4036s/10 iters), loss = 8.3438
I0524 00:15:49.841831 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.3438 (* 1 = 8.3438 loss)
I0524 00:15:49.842300 11654 sgd_solver.cpp:112] Iteration 11600, lr = 0.1
I0524 00:15:56.079509 11654 solver.cpp:239] Iteration 11610 (1.60322 iter/s, 6.23744s/10 iters), loss = 8.8944
I0524 00:15:56.079561 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.8944 (* 1 = 8.8944 loss)
I0524 00:15:56.079768 11654 sgd_solver.cpp:112] Iteration 11610, lr = 0.1
I0524 00:16:02.902123 11654 solver.cpp:239] Iteration 11620 (1.46578 iter/s, 6.8223s/10 iters), loss = 8.18614
I0524 00:16:02.902176 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.18614 (* 1 = 8.18614 loss)
I0524 00:16:03.504204 11654 sgd_solver.cpp:112] Iteration 11620, lr = 0.1
I0524 00:16:10.360582 11654 solver.cpp:239] Iteration 11630 (1.34082 iter/s, 7.45813s/10 iters), loss = 8.54975
I0524 00:16:10.360755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.54975 (* 1 = 8.54975 loss)
I0524 00:16:10.394392 11654 sgd_solver.cpp:112] Iteration 11630, lr = 0.1
I0524 00:16:18.275303 11654 solver.cpp:239] Iteration 11640 (1.26355 iter/s, 7.91423s/10 iters), loss = 8.69518
I0524 00:16:18.275360 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.69518 (* 1 = 8.69518 loss)
I0524 00:16:18.275378 11654 sgd_solver.cpp:112] Iteration 11640, lr = 0.1
I0524 00:16:25.155354 11654 solver.cpp:239] Iteration 11650 (1.45368 iter/s, 6.8791s/10 iters), loss = 7.11037
I0524 00:16:25.155402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11037 (* 1 = 7.11037 loss)
I0524 00:16:25.436177 11654 sgd_solver.cpp:112] Iteration 11650, lr = 0.1
I0524 00:16:32.187268 11654 solver.cpp:239] Iteration 11660 (1.42215 iter/s, 7.03159s/10 iters), loss = 8.6781
I0524 00:16:32.187330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.6781 (* 1 = 8.6781 loss)
I0524 00:16:32.187618 11654 sgd_solver.cpp:112] Iteration 11660, lr = 0.1
I0524 00:16:38.939275 11654 solver.cpp:239] Iteration 11670 (1.48111 iter/s, 6.75169s/10 iters), loss = 7.24131
I0524 00:16:38.939332 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24131 (* 1 = 7.24131 loss)
I0524 00:16:39.080346 11654 sgd_solver.cpp:112] Iteration 11670, lr = 0.1
I0524 00:16:47.875566 11654 solver.cpp:239] Iteration 11680 (1.11908 iter/s, 8.9359s/10 iters), loss = 8.19191
I0524 00:16:47.875862 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.19191 (* 1 = 8.19191 loss)
I0524 00:16:47.875928 11654 sgd_solver.cpp:112] Iteration 11680, lr = 0.1
I0524 00:16:54.231894 11654 solver.cpp:239] Iteration 11690 (1.57336 iter/s, 6.35583s/10 iters), loss = 8.42269
I0524 00:16:54.231940 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.42269 (* 1 = 8.42269 loss)
I0524 00:16:54.232228 11654 sgd_solver.cpp:112] Iteration 11690, lr = 0.1
I0524 00:17:01.660305 11654 solver.cpp:239] Iteration 11700 (1.34624 iter/s, 7.42808s/10 iters), loss = 9.02442
I0524 00:17:01.660362 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.02442 (* 1 = 9.02442 loss)
I0524 00:17:01.663800 11654 sgd_solver.cpp:112] Iteration 11700, lr = 0.1
I0524 00:17:09.340512 11654 solver.cpp:239] Iteration 11710 (1.30211 iter/s, 7.67986s/10 iters), loss = 8.56189
I0524 00:17:09.340566 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.56189 (* 1 = 8.56189 loss)
I0524 00:17:09.340581 11654 sgd_solver.cpp:112] Iteration 11710, lr = 0.1
I0524 00:17:15.961872 11654 solver.cpp:239] Iteration 11720 (1.51035 iter/s, 6.62099s/10 iters), loss = 7.62076
I0524 00:17:15.961912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62076 (* 1 = 7.62076 loss)
I0524 00:17:15.962014 11654 sgd_solver.cpp:112] Iteration 11720, lr = 0.1
I0524 00:17:24.461544 11654 solver.cpp:239] Iteration 11730 (1.17657 iter/s, 8.4993s/10 iters), loss = 7.53506
I0524 00:17:24.461805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.53506 (* 1 = 7.53506 loss)
I0524 00:17:24.673435 11654 sgd_solver.cpp:112] Iteration 11730, lr = 0.1
I0524 00:17:32.732122 11654 solver.cpp:239] Iteration 11740 (1.20918 iter/s, 8.27005s/10 iters), loss = 8.77598
I0524 00:17:32.732177 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.77598 (* 1 = 8.77598 loss)
I0524 00:17:32.733618 11654 sgd_solver.cpp:112] Iteration 11740, lr = 0.1
I0524 00:17:39.764653 11654 solver.cpp:239] Iteration 11750 (1.42203 iter/s, 7.03221s/10 iters), loss = 8.27446
I0524 00:17:39.764700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.27446 (* 1 = 8.27446 loss)
I0524 00:17:39.764721 11654 sgd_solver.cpp:112] Iteration 11750, lr = 0.1
I0524 00:17:47.068948 11654 solver.cpp:239] Iteration 11760 (1.36912 iter/s, 7.30397s/10 iters), loss = 8.22354
I0524 00:17:47.069001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.22354 (* 1 = 8.22354 loss)
I0524 00:17:47.162094 11654 sgd_solver.cpp:112] Iteration 11760, lr = 0.1
I0524 00:17:53.912870 11654 solver.cpp:239] Iteration 11770 (1.46122 iter/s, 6.84362s/10 iters), loss = 9.03572
I0524 00:17:53.912911 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.03572 (* 1 = 9.03572 loss)
I0524 00:17:53.912925 11654 sgd_solver.cpp:112] Iteration 11770, lr = 0.1
I0524 00:18:01.155875 11654 solver.cpp:239] Iteration 11780 (1.38072 iter/s, 7.2426s/10 iters), loss = 7.63204
I0524 00:18:01.156046 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63204 (* 1 = 7.63204 loss)
I0524 00:18:01.156152 11654 sgd_solver.cpp:112] Iteration 11780, lr = 0.1
I0524 00:18:08.017814 11654 solver.cpp:239] Iteration 11790 (1.45741 iter/s, 6.8615s/10 iters), loss = 7.75777
I0524 00:18:08.017896 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.75777 (* 1 = 7.75777 loss)
I0524 00:18:08.389369 11654 sgd_solver.cpp:112] Iteration 11790, lr = 0.1
I0524 00:18:15.990653 11654 solver.cpp:239] Iteration 11800 (1.25432 iter/s, 7.97247s/10 iters), loss = 7.29295
I0524 00:18:15.990717 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29295 (* 1 = 7.29295 loss)
I0524 00:18:15.990773 11654 sgd_solver.cpp:112] Iteration 11800, lr = 0.1
I0524 00:18:22.354689 11654 solver.cpp:239] Iteration 11810 (1.5714 iter/s, 6.36374s/10 iters), loss = 8.58703
I0524 00:18:22.354763 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.58703 (* 1 = 8.58703 loss)
I0524 00:18:22.354833 11654 sgd_solver.cpp:112] Iteration 11810, lr = 0.1
I0524 00:18:30.281998 11654 solver.cpp:239] Iteration 11820 (1.26152 iter/s, 7.92695s/10 iters), loss = 7.85122
I0524 00:18:30.282045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85122 (* 1 = 7.85122 loss)
I0524 00:18:30.711938 11654 sgd_solver.cpp:112] Iteration 11820, lr = 0.1
I0524 00:18:40.888594 11654 solver.cpp:239] Iteration 11830 (0.942849 iter/s, 10.6062s/10 iters), loss = 8.4495
I0524 00:18:40.888674 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.4495 (* 1 = 8.4495 loss)
I0524 00:18:42.085533 11654 sgd_solver.cpp:112] Iteration 11830, lr = 0.1
I0524 00:18:48.780444 11654 solver.cpp:239] Iteration 11840 (1.26719 iter/s, 7.89148s/10 iters), loss = 7.17159
I0524 00:18:48.780500 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17159 (* 1 = 7.17159 loss)
I0524 00:18:48.780629 11654 sgd_solver.cpp:112] Iteration 11840, lr = 0.1
I0524 00:18:54.886822 11654 solver.cpp:239] Iteration 11850 (1.63771 iter/s, 6.10609s/10 iters), loss = 7.96194
I0524 00:18:54.886875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.96194 (* 1 = 7.96194 loss)
I0524 00:18:54.886891 11654 sgd_solver.cpp:112] Iteration 11850, lr = 0.1
I0524 00:19:01.358748 11654 solver.cpp:239] Iteration 11860 (1.54521 iter/s, 6.47163s/10 iters), loss = 9.45322
I0524 00:19:01.358798 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.45322 (* 1 = 9.45322 loss)
I0524 00:19:01.753718 11654 sgd_solver.cpp:112] Iteration 11860, lr = 0.1
I0524 00:19:08.907150 11654 solver.cpp:239] Iteration 11870 (1.32484 iter/s, 7.54806s/10 iters), loss = 8.06859
I0524 00:19:08.907207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.06859 (* 1 = 8.06859 loss)
I0524 00:19:08.907222 11654 sgd_solver.cpp:112] Iteration 11870, lr = 0.1
I0524 00:19:16.720788 11654 solver.cpp:239] Iteration 11880 (1.27988 iter/s, 7.81322s/10 iters), loss = 7.82187
I0524 00:19:16.721026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.82187 (* 1 = 7.82187 loss)
I0524 00:19:16.721077 11654 sgd_solver.cpp:112] Iteration 11880, lr = 0.1
I0524 00:19:23.219518 11654 solver.cpp:239] Iteration 11890 (1.53888 iter/s, 6.49825s/10 iters), loss = 8.13233
I0524 00:19:23.219576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.13233 (* 1 = 8.13233 loss)
I0524 00:19:23.219715 11654 sgd_solver.cpp:112] Iteration 11890, lr = 0.1
I0524 00:19:32.549201 11654 solver.cpp:239] Iteration 11900 (1.07189 iter/s, 9.32928s/10 iters), loss = 8.57229
I0524 00:19:32.549252 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.57229 (* 1 = 8.57229 loss)
I0524 00:19:32.549269 11654 sgd_solver.cpp:112] Iteration 11900, lr = 0.1
I0524 00:19:42.109009 11654 solver.cpp:239] Iteration 11910 (1.04609 iter/s, 9.5594s/10 iters), loss = 6.46439
I0524 00:19:42.109050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46439 (* 1 = 6.46439 loss)
I0524 00:19:42.109064 11654 sgd_solver.cpp:112] Iteration 11910, lr = 0.1
I0524 00:19:50.138183 11654 solver.cpp:239] Iteration 11920 (1.24551 iter/s, 8.02881s/10 iters), loss = 8.16191
I0524 00:19:50.138350 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.16191 (* 1 = 8.16191 loss)
I0524 00:19:50.138767 11654 sgd_solver.cpp:112] Iteration 11920, lr = 0.1
I0524 00:19:56.245829 11654 solver.cpp:239] Iteration 11930 (1.63739 iter/s, 6.10727s/10 iters), loss = 8.45412
I0524 00:19:56.245882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.45412 (* 1 = 8.45412 loss)
I0524 00:19:56.245915 11654 sgd_solver.cpp:112] Iteration 11930, lr = 0.1
I0524 00:20:02.559574 11654 solver.cpp:239] Iteration 11940 (1.58394 iter/s, 6.31337s/10 iters), loss = 8.55014
I0524 00:20:02.559630 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.55014 (* 1 = 8.55014 loss)
I0524 00:20:02.559954 11654 sgd_solver.cpp:112] Iteration 11940, lr = 0.1
I0524 00:20:11.084545 11654 solver.cpp:239] Iteration 11950 (1.17308 iter/s, 8.52458s/10 iters), loss = 7.83074
I0524 00:20:11.084604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.83074 (* 1 = 7.83074 loss)
I0524 00:20:11.084679 11654 sgd_solver.cpp:112] Iteration 11950, lr = 0.1
I0524 00:20:17.883957 11654 solver.cpp:239] Iteration 11960 (1.47078 iter/s, 6.7991s/10 iters), loss = 7.97328
I0524 00:20:17.884011 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.97328 (* 1 = 7.97328 loss)
I0524 00:20:17.884143 11654 sgd_solver.cpp:112] Iteration 11960, lr = 0.1
I0524 00:20:24.741688 11654 solver.cpp:239] Iteration 11970 (1.45828 iter/s, 6.85742s/10 iters), loss = 8.3265
I0524 00:20:24.741832 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.3265 (* 1 = 8.3265 loss)
I0524 00:20:24.741886 11654 sgd_solver.cpp:112] Iteration 11970, lr = 0.1
I0524 00:20:30.902062 11654 solver.cpp:239] Iteration 11980 (1.62337 iter/s, 6.16001s/10 iters), loss = 7.53004
I0524 00:20:30.902106 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.53004 (* 1 = 7.53004 loss)
I0524 00:20:30.902117 11654 sgd_solver.cpp:112] Iteration 11980, lr = 0.1
I0524 00:20:37.517863 11654 solver.cpp:239] Iteration 11990 (1.5116 iter/s, 6.6155s/10 iters), loss = 8.41346
I0524 00:20:37.517915 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.41346 (* 1 = 8.41346 loss)
I0524 00:20:37.518137 11654 sgd_solver.cpp:112] Iteration 11990, lr = 0.1
I0524 00:20:43.644580 11654 solver.cpp:239] Iteration 12000 (1.63227 iter/s, 6.12644s/10 iters), loss = 8.3948
I0524 00:20:43.644621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.3948 (* 1 = 8.3948 loss)
I0524 00:20:44.889909 11654 sgd_solver.cpp:112] Iteration 12000, lr = 0.1
I0524 00:20:51.471452 11654 solver.cpp:239] Iteration 12010 (1.27771 iter/s, 7.82653s/10 iters), loss = 8.72429
I0524 00:20:51.471498 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.72429 (* 1 = 8.72429 loss)
I0524 00:20:51.471513 11654 sgd_solver.cpp:112] Iteration 12010, lr = 0.1
I0524 00:21:00.665892 11654 solver.cpp:239] Iteration 12020 (1.08766 iter/s, 9.19405s/10 iters), loss = 8.67667
I0524 00:21:00.666074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.67667 (* 1 = 8.67667 loss)
I0524 00:21:00.666148 11654 sgd_solver.cpp:112] Iteration 12020, lr = 0.1
I0524 00:21:07.962505 11654 solver.cpp:239] Iteration 12030 (1.37058 iter/s, 7.29617s/10 iters), loss = 8.23011
I0524 00:21:07.962559 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.23011 (* 1 = 8.23011 loss)
I0524 00:21:07.962576 11654 sgd_solver.cpp:112] Iteration 12030, lr = 0.1
I0524 00:21:15.299793 11654 solver.cpp:239] Iteration 12040 (1.36297 iter/s, 7.3369s/10 iters), loss = 7.41831
I0524 00:21:15.299831 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.41831 (* 1 = 7.41831 loss)
I0524 00:21:15.299844 11654 sgd_solver.cpp:112] Iteration 12040, lr = 0.1
I0524 00:21:21.960739 11654 solver.cpp:239] Iteration 12050 (1.50186 iter/s, 6.65841s/10 iters), loss = 9.21011
I0524 00:21:21.960801 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.21011 (* 1 = 9.21011 loss)
I0524 00:21:21.961390 11654 sgd_solver.cpp:112] Iteration 12050, lr = 0.1
I0524 00:21:28.230404 11654 solver.cpp:239] Iteration 12060 (1.59506 iter/s, 6.26937s/10 iters), loss = 8.15887
I0524 00:21:28.230458 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.15887 (* 1 = 8.15887 loss)
I0524 00:21:28.230747 11654 sgd_solver.cpp:112] Iteration 12060, lr = 0.1
I0524 00:21:36.998383 11654 solver.cpp:239] Iteration 12070 (1.14056 iter/s, 8.7676s/10 iters), loss = 7.51777
I0524 00:21:36.998567 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51777 (* 1 = 7.51777 loss)
I0524 00:21:37.122148 11654 sgd_solver.cpp:112] Iteration 12070, lr = 0.1
I0524 00:21:44.053828 11654 solver.cpp:239] Iteration 12080 (1.41743 iter/s, 7.055s/10 iters), loss = 6.90609
I0524 00:21:44.053895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90609 (* 1 = 6.90609 loss)
I0524 00:21:44.053912 11654 sgd_solver.cpp:112] Iteration 12080, lr = 0.1
I0524 00:21:50.885933 11654 solver.cpp:239] Iteration 12090 (1.46376 iter/s, 6.83172s/10 iters), loss = 8.38826
I0524 00:21:50.885984 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.38826 (* 1 = 8.38826 loss)
I0524 00:21:50.886000 11654 sgd_solver.cpp:112] Iteration 12090, lr = 0.1
I0524 00:21:58.832676 11654 solver.cpp:239] Iteration 12100 (1.25843 iter/s, 7.94639s/10 iters), loss = 7.61429
I0524 00:21:58.832734 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61429 (* 1 = 7.61429 loss)
I0524 00:21:59.105900 11654 sgd_solver.cpp:112] Iteration 12100, lr = 0.1
I0524 00:22:05.554592 11654 solver.cpp:239] Iteration 12110 (1.48774 iter/s, 6.7216s/10 iters), loss = 8.66628
I0524 00:22:05.554646 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.66628 (* 1 = 8.66628 loss)
I0524 00:22:05.690472 11654 sgd_solver.cpp:112] Iteration 12110, lr = 0.1
I0524 00:22:12.207288 11654 solver.cpp:239] Iteration 12120 (1.50322 iter/s, 6.65238s/10 iters), loss = 6.9281
I0524 00:22:12.207445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9281 (* 1 = 6.9281 loss)
I0524 00:22:12.207578 11654 sgd_solver.cpp:112] Iteration 12120, lr = 0.1
I0524 00:22:18.818050 11654 solver.cpp:239] Iteration 12130 (1.51278 iter/s, 6.61036s/10 iters), loss = 7.89193
I0524 00:22:18.818102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89193 (* 1 = 7.89193 loss)
I0524 00:22:18.818119 11654 sgd_solver.cpp:112] Iteration 12130, lr = 0.1
I0524 00:22:25.314355 11654 solver.cpp:239] Iteration 12140 (1.53941 iter/s, 6.496s/10 iters), loss = 7.70248
I0524 00:22:25.314411 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70248 (* 1 = 7.70248 loss)
I0524 00:22:25.314426 11654 sgd_solver.cpp:112] Iteration 12140, lr = 0.1
I0524 00:22:31.589155 11654 solver.cpp:239] Iteration 12150 (1.59377 iter/s, 6.27443s/10 iters), loss = 8.16298
I0524 00:22:31.589202 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.16298 (* 1 = 8.16298 loss)
I0524 00:22:31.589439 11654 sgd_solver.cpp:112] Iteration 12150, lr = 0.1
I0524 00:22:38.077985 11654 solver.cpp:239] Iteration 12160 (1.54118 iter/s, 6.48853s/10 iters), loss = 8.28069
I0524 00:22:38.078037 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.28069 (* 1 = 8.28069 loss)
I0524 00:22:38.078053 11654 sgd_solver.cpp:112] Iteration 12160, lr = 0.1
I0524 00:22:45.228111 11654 solver.cpp:239] Iteration 12170 (1.39864 iter/s, 7.14981s/10 iters), loss = 8.10176
I0524 00:22:45.228271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.10176 (* 1 = 8.10176 loss)
I0524 00:22:45.279702 11654 sgd_solver.cpp:112] Iteration 12170, lr = 0.1
I0524 00:22:54.189164 11654 solver.cpp:239] Iteration 12180 (1.116 iter/s, 8.96056s/10 iters), loss = 7.66446
I0524 00:22:54.189216 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66446 (* 1 = 7.66446 loss)
I0524 00:22:54.189232 11654 sgd_solver.cpp:112] Iteration 12180, lr = 0.1
I0524 00:23:01.555802 11654 solver.cpp:239] Iteration 12190 (1.35753 iter/s, 7.3663s/10 iters), loss = 8.67978
I0524 00:23:01.555871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.67978 (* 1 = 8.67978 loss)
I0524 00:23:01.556301 11654 sgd_solver.cpp:112] Iteration 12190, lr = 0.1
I0524 00:23:09.605659 11654 solver.cpp:239] Iteration 12200 (1.24231 iter/s, 8.04949s/10 iters), loss = 9.19983
I0524 00:23:09.605710 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.19983 (* 1 = 9.19983 loss)
I0524 00:23:09.795665 11654 sgd_solver.cpp:112] Iteration 12200, lr = 0.1
I0524 00:23:17.687106 11654 solver.cpp:239] Iteration 12210 (1.23746 iter/s, 8.08109s/10 iters), loss = 8.40824
I0524 00:23:17.687371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.40824 (* 1 = 8.40824 loss)
I0524 00:23:17.687431 11654 sgd_solver.cpp:112] Iteration 12210, lr = 0.1
I0524 00:23:24.076515 11654 solver.cpp:239] Iteration 12220 (1.56521 iter/s, 6.38894s/10 iters), loss = 8.44889
I0524 00:23:24.076567 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.44889 (* 1 = 8.44889 loss)
I0524 00:23:24.076638 11654 sgd_solver.cpp:112] Iteration 12220, lr = 0.1
I0524 00:23:31.211870 11654 solver.cpp:239] Iteration 12230 (1.40154 iter/s, 7.13503s/10 iters), loss = 8.49275
I0524 00:23:31.211918 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.49275 (* 1 = 8.49275 loss)
I0524 00:23:31.212110 11654 sgd_solver.cpp:112] Iteration 12230, lr = 0.1
I0524 00:23:37.939445 11654 solver.cpp:239] Iteration 12240 (1.48649 iter/s, 6.72727s/10 iters), loss = 7.75165
I0524 00:23:37.939499 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.75165 (* 1 = 7.75165 loss)
I0524 00:23:37.939515 11654 sgd_solver.cpp:112] Iteration 12240, lr = 0.1
I0524 00:23:44.889458 11654 solver.cpp:239] Iteration 12250 (1.43891 iter/s, 6.9497s/10 iters), loss = 8.72346
I0524 00:23:44.889518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.72346 (* 1 = 8.72346 loss)
I0524 00:23:45.314364 11654 sgd_solver.cpp:112] Iteration 12250, lr = 0.1
I0524 00:23:53.169787 11654 solver.cpp:239] Iteration 12260 (1.20774 iter/s, 8.27996s/10 iters), loss = 7.82594
I0524 00:23:53.170032 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.82594 (* 1 = 7.82594 loss)
I0524 00:23:53.170459 11654 sgd_solver.cpp:112] Iteration 12260, lr = 0.1
I0524 00:23:59.657439 11654 solver.cpp:239] Iteration 12270 (1.54149 iter/s, 6.48722s/10 iters), loss = 7.65357
I0524 00:23:59.657492 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.65357 (* 1 = 7.65357 loss)
I0524 00:23:59.657595 11654 sgd_solver.cpp:112] Iteration 12270, lr = 0.1
I0524 00:24:07.071605 11654 solver.cpp:239] Iteration 12280 (1.34883 iter/s, 7.41384s/10 iters), loss = 7.979
I0524 00:24:07.071642 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.979 (* 1 = 7.979 loss)
I0524 00:24:07.071655 11654 sgd_solver.cpp:112] Iteration 12280, lr = 0.1
I0524 00:24:13.616498 11654 solver.cpp:239] Iteration 12290 (1.52798 iter/s, 6.54459s/10 iters), loss = 7.73033
I0524 00:24:13.616554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.73033 (* 1 = 7.73033 loss)
I0524 00:24:13.616719 11654 sgd_solver.cpp:112] Iteration 12290, lr = 0.1
I0524 00:24:20.606722 11654 solver.cpp:239] Iteration 12300 (1.43064 iter/s, 6.98989s/10 iters), loss = 7.39863
I0524 00:24:20.606765 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39863 (* 1 = 7.39863 loss)
I0524 00:24:20.607296 11654 sgd_solver.cpp:112] Iteration 12300, lr = 0.1
I0524 00:24:28.731716 11654 solver.cpp:239] Iteration 12310 (1.23083 iter/s, 8.12463s/10 iters), loss = 7.45965
I0524 00:24:28.732017 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.45965 (* 1 = 7.45965 loss)
I0524 00:24:28.732069 11654 sgd_solver.cpp:112] Iteration 12310, lr = 0.1
I0524 00:24:35.530539 11654 solver.cpp:239] Iteration 12320 (1.47107 iter/s, 6.79779s/10 iters), loss = 7.73448
I0524 00:24:35.530593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.73448 (* 1 = 7.73448 loss)
I0524 00:24:35.530609 11654 sgd_solver.cpp:112] Iteration 12320, lr = 0.1
I0524 00:24:43.035696 11654 solver.cpp:239] Iteration 12330 (1.33248 iter/s, 7.50483s/10 iters), loss = 7.82212
I0524 00:24:43.035735 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.82212 (* 1 = 7.82212 loss)
I0524 00:24:43.331569 11654 sgd_solver.cpp:112] Iteration 12330, lr = 0.1
I0524 00:24:53.756158 11654 solver.cpp:239] Iteration 12340 (0.932834 iter/s, 10.72s/10 iters), loss = 7.36214
I0524 00:24:53.756212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36214 (* 1 = 7.36214 loss)
I0524 00:24:53.756228 11654 sgd_solver.cpp:112] Iteration 12340, lr = 0.1
I0524 00:25:00.955044 11654 solver.cpp:239] Iteration 12350 (1.38917 iter/s, 7.19856s/10 iters), loss = 8.55765
I0524 00:25:00.955207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.55765 (* 1 = 8.55765 loss)
I0524 00:25:00.955230 11654 sgd_solver.cpp:112] Iteration 12350, lr = 0.1
I0524 00:25:10.179283 11654 solver.cpp:239] Iteration 12360 (1.08416 iter/s, 9.22371s/10 iters), loss = 7.45161
I0524 00:25:10.179327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.45161 (* 1 = 7.45161 loss)
I0524 00:25:10.397266 11654 sgd_solver.cpp:112] Iteration 12360, lr = 0.1
I0524 00:25:16.419450 11654 solver.cpp:239] Iteration 12370 (1.6026 iter/s, 6.23987s/10 iters), loss = 8.12075
I0524 00:25:16.419502 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.12075 (* 1 = 8.12075 loss)
I0524 00:25:16.419518 11654 sgd_solver.cpp:112] Iteration 12370, lr = 0.1
I0524 00:25:24.998584 11654 solver.cpp:239] Iteration 12380 (1.16574 iter/s, 8.57822s/10 iters), loss = 8.11344
I0524 00:25:24.998638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11344 (* 1 = 8.11344 loss)
I0524 00:25:24.998678 11654 sgd_solver.cpp:112] Iteration 12380, lr = 0.1
I0524 00:25:31.947167 11654 solver.cpp:239] Iteration 12390 (1.43921 iter/s, 6.94826s/10 iters), loss = 7.1106
I0524 00:25:31.947285 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1106 (* 1 = 7.1106 loss)
I0524 00:25:31.947428 11654 sgd_solver.cpp:112] Iteration 12390, lr = 0.1
I0524 00:25:38.825983 11654 solver.cpp:239] Iteration 12400 (1.45382 iter/s, 6.87844s/10 iters), loss = 9.51992
I0524 00:25:38.826036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.51992 (* 1 = 9.51992 loss)
I0524 00:25:38.826052 11654 sgd_solver.cpp:112] Iteration 12400, lr = 0.1
I0524 00:25:46.133736 11654 solver.cpp:239] Iteration 12410 (1.36848 iter/s, 7.30735s/10 iters), loss = 7.89807
I0524 00:25:46.133776 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89807 (* 1 = 7.89807 loss)
I0524 00:25:46.133790 11654 sgd_solver.cpp:112] Iteration 12410, lr = 0.1
I0524 00:25:52.194270 11654 solver.cpp:239] Iteration 12420 (1.65009 iter/s, 6.06026s/10 iters), loss = 7.66113
I0524 00:25:52.194324 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66113 (* 1 = 7.66113 loss)
I0524 00:25:52.194339 11654 sgd_solver.cpp:112] Iteration 12420, lr = 0.1
I0524 00:26:00.027020 11654 solver.cpp:239] Iteration 12430 (1.27711 iter/s, 7.83019s/10 iters), loss = 7.91826
I0524 00:26:00.027076 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91826 (* 1 = 7.91826 loss)
I0524 00:26:00.927942 11654 sgd_solver.cpp:112] Iteration 12430, lr = 0.1
I0524 00:26:08.670068 11654 solver.cpp:239] Iteration 12440 (1.15705 iter/s, 8.64267s/10 iters), loss = 8.03321
I0524 00:26:08.670333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.03321 (* 1 = 8.03321 loss)
I0524 00:26:08.670375 11654 sgd_solver.cpp:112] Iteration 12440, lr = 0.1
I0524 00:26:15.351680 11654 solver.cpp:239] Iteration 12450 (1.49676 iter/s, 6.6811s/10 iters), loss = 7.85809
I0524 00:26:15.351722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85809 (* 1 = 7.85809 loss)
I0524 00:26:15.527154 11654 sgd_solver.cpp:112] Iteration 12450, lr = 0.1
I0524 00:26:25.525787 11654 solver.cpp:239] Iteration 12460 (0.982929 iter/s, 10.1737s/10 iters), loss = 9.34508
I0524 00:26:25.525846 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.34508 (* 1 = 9.34508 loss)
I0524 00:26:25.526006 11654 sgd_solver.cpp:112] Iteration 12460, lr = 0.1
I0524 00:26:32.248169 11654 solver.cpp:239] Iteration 12470 (1.48764 iter/s, 6.72208s/10 iters), loss = 8.17088
I0524 00:26:32.248210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.17088 (* 1 = 8.17088 loss)
I0524 00:26:32.248224 11654 sgd_solver.cpp:112] Iteration 12470, lr = 0.1
I0524 00:26:39.274636 11654 solver.cpp:239] Iteration 12480 (1.42371 iter/s, 7.0239s/10 iters), loss = 7.68386
I0524 00:26:39.274946 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.68386 (* 1 = 7.68386 loss)
I0524 00:26:39.275009 11654 sgd_solver.cpp:112] Iteration 12480, lr = 0.1
I0524 00:26:47.750771 11654 solver.cpp:239] Iteration 12490 (1.17986 iter/s, 8.47556s/10 iters), loss = 8.63157
I0524 00:26:47.750820 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.63157 (* 1 = 8.63157 loss)
I0524 00:26:47.766338 11654 sgd_solver.cpp:112] Iteration 12490, lr = 0.1
I0524 00:26:55.489153 11654 solver.cpp:239] Iteration 12500 (1.29232 iter/s, 7.73805s/10 iters), loss = 7.21104
I0524 00:26:55.489190 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21104 (* 1 = 7.21104 loss)
I0524 00:26:55.489718 11654 sgd_solver.cpp:112] Iteration 12500, lr = 0.1
I0524 00:27:01.622084 11654 solver.cpp:239] Iteration 12510 (1.63062 iter/s, 6.13264s/10 iters), loss = 8.15896
I0524 00:27:01.622149 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.15896 (* 1 = 8.15896 loss)
I0524 00:27:01.622479 11654 sgd_solver.cpp:112] Iteration 12510, lr = 0.1
I0524 00:27:08.092000 11654 solver.cpp:239] Iteration 12520 (1.54569 iter/s, 6.46962s/10 iters), loss = 6.76378
I0524 00:27:08.092039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76378 (* 1 = 6.76378 loss)
I0524 00:27:08.158427 11654 sgd_solver.cpp:112] Iteration 12520, lr = 0.1
I0524 00:27:16.450626 11654 solver.cpp:239] Iteration 12530 (1.19642 iter/s, 8.35826s/10 iters), loss = 7.74314
I0524 00:27:16.450919 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.74314 (* 1 = 7.74314 loss)
I0524 00:27:16.493994 11654 sgd_solver.cpp:112] Iteration 12530, lr = 0.1
I0524 00:27:23.055109 11654 solver.cpp:239] Iteration 12540 (1.51424 iter/s, 6.60398s/10 iters), loss = 8.4498
I0524 00:27:23.055166 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.4498 (* 1 = 8.4498 loss)
I0524 00:27:23.055181 11654 sgd_solver.cpp:112] Iteration 12540, lr = 0.1
I0524 00:27:29.502105 11654 solver.cpp:239] Iteration 12550 (1.55118 iter/s, 6.4467s/10 iters), loss = 8.11434
I0524 00:27:29.502143 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11434 (* 1 = 8.11434 loss)
I0524 00:27:29.502362 11654 sgd_solver.cpp:112] Iteration 12550, lr = 0.1
I0524 00:27:36.889503 11654 solver.cpp:239] Iteration 12560 (1.35372 iter/s, 7.38707s/10 iters), loss = 7.78259
I0524 00:27:36.889560 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78259 (* 1 = 7.78259 loss)
I0524 00:27:36.996078 11654 sgd_solver.cpp:112] Iteration 12560, lr = 0.1
I0524 00:27:48.811738 11654 solver.cpp:239] Iteration 12570 (0.838804 iter/s, 11.9217s/10 iters), loss = 7.76837
I0524 00:27:48.812031 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76837 (* 1 = 7.76837 loss)
I0524 00:27:48.888772 11654 sgd_solver.cpp:112] Iteration 12570, lr = 0.1
I0524 00:27:57.892834 11654 solver.cpp:239] Iteration 12580 (1.10126 iter/s, 9.08051s/10 iters), loss = 7.36995
I0524 00:27:57.892889 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36995 (* 1 = 7.36995 loss)
I0524 00:27:57.892906 11654 sgd_solver.cpp:112] Iteration 12580, lr = 0.1
I0524 00:28:06.566741 11654 solver.cpp:239] Iteration 12590 (1.15294 iter/s, 8.67347s/10 iters), loss = 7.28653
I0524 00:28:06.566783 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28653 (* 1 = 7.28653 loss)
I0524 00:28:06.567327 11654 sgd_solver.cpp:112] Iteration 12590, lr = 0.1
I0524 00:28:12.992156 11654 solver.cpp:239] Iteration 12600 (1.55639 iter/s, 6.42513s/10 iters), loss = 7.2126
I0524 00:28:12.992194 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2126 (* 1 = 7.2126 loss)
I0524 00:28:13.083755 11654 sgd_solver.cpp:112] Iteration 12600, lr = 0.1
I0524 00:28:19.293841 11654 solver.cpp:239] Iteration 12610 (1.58695 iter/s, 6.3014s/10 iters), loss = 7.5761
I0524 00:28:19.293992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.5761 (* 1 = 7.5761 loss)
I0524 00:28:19.294011 11654 sgd_solver.cpp:112] Iteration 12610, lr = 0.1
I0524 00:28:25.709722 11654 solver.cpp:239] Iteration 12620 (1.55873 iter/s, 6.41549s/10 iters), loss = 8.91996
I0524 00:28:25.709786 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.91996 (* 1 = 8.91996 loss)
I0524 00:28:25.710198 11654 sgd_solver.cpp:112] Iteration 12620, lr = 0.1
I0524 00:28:33.277279 11654 solver.cpp:239] Iteration 12630 (1.32149 iter/s, 7.56722s/10 iters), loss = 7.473
I0524 00:28:33.277318 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.473 (* 1 = 7.473 loss)
I0524 00:28:33.285962 11654 sgd_solver.cpp:112] Iteration 12630, lr = 0.1
I0524 00:28:40.323454 11654 solver.cpp:239] Iteration 12640 (1.41927 iter/s, 7.04586s/10 iters), loss = 7.6402
I0524 00:28:40.323508 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.6402 (* 1 = 7.6402 loss)
I0524 00:28:40.323613 11654 sgd_solver.cpp:112] Iteration 12640, lr = 0.1
I0524 00:28:48.060544 11654 solver.cpp:239] Iteration 12650 (1.29253 iter/s, 7.73674s/10 iters), loss = 7.47855
I0524 00:28:48.060606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.47855 (* 1 = 7.47855 loss)
I0524 00:28:48.060848 11654 sgd_solver.cpp:112] Iteration 12650, lr = 0.1
I0524 00:28:57.937127 11654 solver.cpp:239] Iteration 12660 (1.01254 iter/s, 9.87615s/10 iters), loss = 7.3686
I0524 00:28:57.937330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3686 (* 1 = 7.3686 loss)
I0524 00:28:57.986785 11654 sgd_solver.cpp:112] Iteration 12660, lr = 0.1
I0524 00:29:05.215910 11654 solver.cpp:239] Iteration 12670 (1.37394 iter/s, 7.27835s/10 iters), loss = 7.40251
I0524 00:29:05.215952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40251 (* 1 = 7.40251 loss)
I0524 00:29:05.231376 11654 sgd_solver.cpp:112] Iteration 12670, lr = 0.1
I0524 00:29:11.807704 11654 solver.cpp:239] Iteration 12680 (1.51711 iter/s, 6.5915s/10 iters), loss = 7.01568
I0524 00:29:11.807768 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01568 (* 1 = 7.01568 loss)
I0524 00:29:11.807842 11654 sgd_solver.cpp:112] Iteration 12680, lr = 0.1
I0524 00:29:19.645089 11654 solver.cpp:239] Iteration 12690 (1.27599 iter/s, 7.83704s/10 iters), loss = 8.85719
I0524 00:29:19.645128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.85719 (* 1 = 8.85719 loss)
I0524 00:29:20.386615 11654 sgd_solver.cpp:112] Iteration 12690, lr = 0.1
I0524 00:29:29.269790 11654 solver.cpp:239] Iteration 12700 (1.03904 iter/s, 9.6243s/10 iters), loss = 8.41556
I0524 00:29:29.270033 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.41556 (* 1 = 8.41556 loss)
I0524 00:29:29.270268 11654 sgd_solver.cpp:112] Iteration 12700, lr = 0.1
I0524 00:29:35.666734 11654 solver.cpp:239] Iteration 12710 (1.56336 iter/s, 6.39648s/10 iters), loss = 8.54381
I0524 00:29:35.666796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.54381 (* 1 = 8.54381 loss)
I0524 00:29:35.666916 11654 sgd_solver.cpp:112] Iteration 12710, lr = 0.1
I0524 00:29:44.243652 11654 solver.cpp:239] Iteration 12720 (1.16597 iter/s, 8.57654s/10 iters), loss = 7.16482
I0524 00:29:44.243693 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16482 (* 1 = 7.16482 loss)
I0524 00:29:44.243957 11654 sgd_solver.cpp:112] Iteration 12720, lr = 0.1
I0524 00:29:51.098242 11654 solver.cpp:239] Iteration 12730 (1.45894 iter/s, 6.85428s/10 iters), loss = 8.27739
I0524 00:29:51.098297 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.27739 (* 1 = 8.27739 loss)
I0524 00:29:51.102636 11654 sgd_solver.cpp:112] Iteration 12730, lr = 0.1
I0524 00:29:58.260368 11654 solver.cpp:239] Iteration 12740 (1.3963 iter/s, 7.1618s/10 iters), loss = 7.81895
I0524 00:29:58.260416 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.81895 (* 1 = 7.81895 loss)
I0524 00:29:58.260771 11654 sgd_solver.cpp:112] Iteration 12740, lr = 0.1
I0524 00:30:05.143009 11654 solver.cpp:239] Iteration 12750 (1.453 iter/s, 6.88232s/10 iters), loss = 7.07412
I0524 00:30:05.143187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07412 (* 1 = 7.07412 loss)
I0524 00:30:05.143270 11654 sgd_solver.cpp:112] Iteration 12750, lr = 0.1
I0524 00:30:12.325381 11654 solver.cpp:239] Iteration 12760 (1.39238 iter/s, 7.18193s/10 iters), loss = 8.1194
I0524 00:30:12.325446 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.1194 (* 1 = 8.1194 loss)
I0524 00:30:12.325634 11654 sgd_solver.cpp:112] Iteration 12760, lr = 0.1
I0524 00:30:18.592315 11654 solver.cpp:239] Iteration 12770 (1.59575 iter/s, 6.26663s/10 iters), loss = 8.12803
I0524 00:30:18.592370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.12803 (* 1 = 8.12803 loss)
I0524 00:30:19.065999 11654 sgd_solver.cpp:112] Iteration 12770, lr = 0.1
I0524 00:30:27.068722 11654 solver.cpp:239] Iteration 12780 (1.1798 iter/s, 8.47604s/10 iters), loss = 7.77662
I0524 00:30:27.068775 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77662 (* 1 = 7.77662 loss)
I0524 00:30:27.068807 11654 sgd_solver.cpp:112] Iteration 12780, lr = 0.1
I0524 00:30:33.905899 11654 solver.cpp:239] Iteration 12790 (1.46266 iter/s, 6.83686s/10 iters), loss = 7.61701
I0524 00:30:33.905961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61701 (* 1 = 7.61701 loss)
I0524 00:30:33.906088 11654 sgd_solver.cpp:112] Iteration 12790, lr = 0.1
I0524 00:30:40.474982 11654 solver.cpp:239] Iteration 12800 (1.52235 iter/s, 6.56878s/10 iters), loss = 7.63886
I0524 00:30:40.475109 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63886 (* 1 = 7.63886 loss)
I0524 00:30:40.475126 11654 sgd_solver.cpp:112] Iteration 12800, lr = 0.1
I0524 00:30:46.710481 11654 solver.cpp:239] Iteration 12810 (1.60383 iter/s, 6.23509s/10 iters), loss = 8.51333
I0524 00:30:46.710530 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.51333 (* 1 = 8.51333 loss)
I0524 00:30:46.879571 11654 sgd_solver.cpp:112] Iteration 12810, lr = 0.1
I0524 00:30:53.554466 11654 solver.cpp:239] Iteration 12820 (1.4612 iter/s, 6.84368s/10 iters), loss = 7.26498
I0524 00:30:53.554509 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26498 (* 1 = 7.26498 loss)
I0524 00:30:53.593466 11654 sgd_solver.cpp:112] Iteration 12820, lr = 0.1
I0524 00:31:00.986251 11654 solver.cpp:239] Iteration 12830 (1.34563 iter/s, 7.43145s/10 iters), loss = 7.58273
I0524 00:31:00.986311 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58273 (* 1 = 7.58273 loss)
I0524 00:31:00.986330 11654 sgd_solver.cpp:112] Iteration 12830, lr = 0.1
I0524 00:31:07.291404 11654 solver.cpp:239] Iteration 12840 (1.58663 iter/s, 6.30266s/10 iters), loss = 7.62535
I0524 00:31:07.291461 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62535 (* 1 = 7.62535 loss)
I0524 00:31:07.292235 11654 sgd_solver.cpp:112] Iteration 12840, lr = 0.1
I0524 00:31:15.789263 11654 solver.cpp:239] Iteration 12850 (1.17682 iter/s, 8.49749s/10 iters), loss = 8.27837
I0524 00:31:15.789438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.27837 (* 1 = 8.27837 loss)
I0524 00:31:15.789472 11654 sgd_solver.cpp:112] Iteration 12850, lr = 0.1
I0524 00:31:23.261276 11654 solver.cpp:239] Iteration 12860 (1.33841 iter/s, 7.47157s/10 iters), loss = 7.90289
I0524 00:31:23.261323 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90289 (* 1 = 7.90289 loss)
I0524 00:31:23.261692 11654 sgd_solver.cpp:112] Iteration 12860, lr = 0.1
I0524 00:31:29.527779 11654 solver.cpp:239] Iteration 12870 (1.59586 iter/s, 6.26621s/10 iters), loss = 7.97739
I0524 00:31:29.527838 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.97739 (* 1 = 7.97739 loss)
I0524 00:31:29.527858 11654 sgd_solver.cpp:112] Iteration 12870, lr = 0.1
I0524 00:31:37.424142 11654 solver.cpp:239] Iteration 12880 (1.26647 iter/s, 7.89595s/10 iters), loss = 7.48786
I0524 00:31:37.424206 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48786 (* 1 = 7.48786 loss)
I0524 00:31:37.424227 11654 sgd_solver.cpp:112] Iteration 12880, lr = 0.1
I0524 00:31:47.634539 11654 solver.cpp:239] Iteration 12890 (0.979648 iter/s, 10.2078s/10 iters), loss = 9.54928
I0524 00:31:47.634843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 9.54928 (* 1 = 9.54928 loss)
I0524 00:31:47.634910 11654 sgd_solver.cpp:112] Iteration 12890, lr = 0.1
I0524 00:31:53.688414 11654 solver.cpp:239] Iteration 12900 (1.65257 iter/s, 6.05118s/10 iters), loss = 8.23192
I0524 00:31:53.688475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.23192 (* 1 = 8.23192 loss)
I0524 00:31:53.688696 11654 sgd_solver.cpp:112] Iteration 12900, lr = 0.1
I0524 00:32:00.077714 11654 solver.cpp:239] Iteration 12910 (1.56519 iter/s, 6.389s/10 iters), loss = 7.92207
I0524 00:32:00.077767 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.92207 (* 1 = 7.92207 loss)
I0524 00:32:00.077785 11654 sgd_solver.cpp:112] Iteration 12910, lr = 0.1
I0524 00:32:07.062377 11654 solver.cpp:239] Iteration 12920 (1.43177 iter/s, 6.98435s/10 iters), loss = 7.52798
I0524 00:32:07.062434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.52798 (* 1 = 7.52798 loss)
I0524 00:32:07.062451 11654 sgd_solver.cpp:112] Iteration 12920, lr = 0.1
I0524 00:32:13.626091 11654 solver.cpp:239] Iteration 12930 (1.52411 iter/s, 6.5612s/10 iters), loss = 7.41986
I0524 00:32:13.626149 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.41986 (* 1 = 7.41986 loss)
I0524 00:32:13.626466 11654 sgd_solver.cpp:112] Iteration 12930, lr = 0.1
I0524 00:32:20.562845 11654 solver.cpp:239] Iteration 12940 (1.44166 iter/s, 6.93644s/10 iters), loss = 7.69966
I0524 00:32:20.563113 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69966 (* 1 = 7.69966 loss)
I0524 00:32:20.563171 11654 sgd_solver.cpp:112] Iteration 12940, lr = 0.1
I0524 00:32:28.336468 11654 solver.cpp:239] Iteration 12950 (1.28685 iter/s, 7.77094s/10 iters), loss = 7.99618
I0524 00:32:28.336521 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.99618 (* 1 = 7.99618 loss)
I0524 00:32:28.592258 11654 sgd_solver.cpp:112] Iteration 12950, lr = 0.1
I0524 00:32:35.939205 11654 solver.cpp:239] Iteration 12960 (1.31538 iter/s, 7.60239s/10 iters), loss = 7.30784
I0524 00:32:35.939275 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30784 (* 1 = 7.30784 loss)
I0524 00:32:35.939713 11654 sgd_solver.cpp:112] Iteration 12960, lr = 0.1
I0524 00:32:44.956533 11654 solver.cpp:239] Iteration 12970 (1.10902 iter/s, 9.01693s/10 iters), loss = 8.23442
I0524 00:32:44.956585 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.23442 (* 1 = 8.23442 loss)
I0524 00:32:44.956601 11654 sgd_solver.cpp:112] Iteration 12970, lr = 0.1
I0524 00:32:52.225473 11654 solver.cpp:239] Iteration 12980 (1.37578 iter/s, 7.26862s/10 iters), loss = 6.94893
I0524 00:32:52.225580 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94893 (* 1 = 6.94893 loss)
I0524 00:32:52.225764 11654 sgd_solver.cpp:112] Iteration 12980, lr = 0.1
I0524 00:33:01.615741 11654 solver.cpp:239] Iteration 12990 (1.06498 iter/s, 9.38981s/10 iters), loss = 8.1619
I0524 00:33:01.615790 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.1619 (* 1 = 8.1619 loss)
I0524 00:33:01.816301 11654 sgd_solver.cpp:112] Iteration 12990, lr = 0.1
I0524 00:33:09.495522 11654 solver.cpp:239] Iteration 13000 (1.26913 iter/s, 7.87943s/10 iters), loss = 7.38524
I0524 00:33:09.495574 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.38524 (* 1 = 7.38524 loss)
I0524 00:33:09.496738 11654 sgd_solver.cpp:112] Iteration 13000, lr = 0.1
I0524 00:33:16.249832 11654 solver.cpp:239] Iteration 13010 (1.4806 iter/s, 6.75401s/10 iters), loss = 7.55503
I0524 00:33:16.249874 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.55503 (* 1 = 7.55503 loss)
I0524 00:33:17.789861 11654 sgd_solver.cpp:112] Iteration 13010, lr = 0.1
I0524 00:33:25.938727 11654 solver.cpp:239] Iteration 13020 (1.03216 iter/s, 9.68847s/10 iters), loss = 7.32339
I0524 00:33:25.939035 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32339 (* 1 = 7.32339 loss)
I0524 00:33:25.939090 11654 sgd_solver.cpp:112] Iteration 13020, lr = 0.1
I0524 00:33:33.466493 11654 solver.cpp:239] Iteration 13030 (1.32886 iter/s, 7.52524s/10 iters), loss = 7.41696
I0524 00:33:33.466553 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.41696 (* 1 = 7.41696 loss)
I0524 00:33:33.466572 11654 sgd_solver.cpp:112] Iteration 13030, lr = 0.1
I0524 00:33:42.142046 11654 solver.cpp:239] Iteration 13040 (1.153 iter/s, 8.67303s/10 iters), loss = 7.94015
I0524 00:33:42.142102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.94015 (* 1 = 7.94015 loss)
I0524 00:33:42.142118 11654 sgd_solver.cpp:112] Iteration 13040, lr = 0.1
I0524 00:33:48.372622 11654 solver.cpp:239] Iteration 13050 (1.60508 iter/s, 6.23021s/10 iters), loss = 8.84039
I0524 00:33:48.372671 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.84039 (* 1 = 8.84039 loss)
I0524 00:33:48.372956 11654 sgd_solver.cpp:112] Iteration 13050, lr = 0.1
I0524 00:33:55.575834 11654 solver.cpp:239] Iteration 13060 (1.38833 iter/s, 7.20288s/10 iters), loss = 8.43805
I0524 00:33:55.575896 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.43805 (* 1 = 8.43805 loss)
I0524 00:33:55.575917 11654 sgd_solver.cpp:112] Iteration 13060, lr = 0.1
I0524 00:34:01.938491 11654 solver.cpp:239] Iteration 13070 (1.57205 iter/s, 6.36112s/10 iters), loss = 8.98571
I0524 00:34:01.938796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.98571 (* 1 = 8.98571 loss)
I0524 00:34:01.939414 11654 sgd_solver.cpp:112] Iteration 13070, lr = 0.1
I0524 00:34:09.969032 11654 solver.cpp:239] Iteration 13080 (1.24534 iter/s, 8.02996s/10 iters), loss = 8.21404
I0524 00:34:09.969092 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.21404 (* 1 = 8.21404 loss)
I0524 00:34:09.969108 11654 sgd_solver.cpp:112] Iteration 13080, lr = 0.1
I0524 00:34:18.941459 11654 solver.cpp:239] Iteration 13090 (1.11485 iter/s, 8.96982s/10 iters), loss = 7.15462
I0524 00:34:18.941509 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15462 (* 1 = 7.15462 loss)
I0524 00:34:18.941526 11654 sgd_solver.cpp:112] Iteration 13090, lr = 0.1
I0524 00:34:27.108381 11654 solver.cpp:239] Iteration 13100 (1.22452 iter/s, 8.1665s/10 iters), loss = 8.54435
I0524 00:34:27.108425 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.54435 (* 1 = 8.54435 loss)
I0524 00:34:27.108578 11654 sgd_solver.cpp:112] Iteration 13100, lr = 0.1
I0524 00:34:33.975483 11654 solver.cpp:239] Iteration 13110 (1.45628 iter/s, 6.8668s/10 iters), loss = 7.87266
I0524 00:34:33.975674 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87266 (* 1 = 7.87266 loss)
I0524 00:34:33.975713 11654 sgd_solver.cpp:112] Iteration 13110, lr = 0.1
I0524 00:34:40.649021 11654 solver.cpp:239] Iteration 13120 (1.49856 iter/s, 6.67308s/10 iters), loss = 7.01348
I0524 00:34:40.649072 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01348 (* 1 = 7.01348 loss)
I0524 00:34:40.649168 11654 sgd_solver.cpp:112] Iteration 13120, lr = 0.1
I0524 00:34:47.312803 11654 solver.cpp:239] Iteration 13130 (1.50072 iter/s, 6.66348s/10 iters), loss = 7.22005
I0524 00:34:47.312855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22005 (* 1 = 7.22005 loss)
I0524 00:34:47.313072 11654 sgd_solver.cpp:112] Iteration 13130, lr = 0.1
I0524 00:34:53.645265 11654 solver.cpp:239] Iteration 13140 (1.57924 iter/s, 6.33217s/10 iters), loss = 7.603
I0524 00:34:53.645321 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.603 (* 1 = 7.603 loss)
I0524 00:34:53.645401 11654 sgd_solver.cpp:112] Iteration 13140, lr = 0.1
I0524 00:35:00.195574 11654 solver.cpp:239] Iteration 13150 (1.52672 iter/s, 6.55001s/10 iters), loss = 7.24569
I0524 00:35:00.195614 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24569 (* 1 = 7.24569 loss)
I0524 00:35:00.378839 11654 sgd_solver.cpp:112] Iteration 13150, lr = 0.1
I0524 00:35:07.536888 11654 solver.cpp:239] Iteration 13160 (1.36221 iter/s, 7.34099s/10 iters), loss = 7.93493
I0524 00:35:07.537209 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.93493 (* 1 = 7.93493 loss)
I0524 00:35:07.537263 11654 sgd_solver.cpp:112] Iteration 13160, lr = 0.1
I0524 00:35:15.021440 11654 solver.cpp:239] Iteration 13170 (1.33622 iter/s, 7.48378s/10 iters), loss = 6.5343
I0524 00:35:15.021499 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5343 (* 1 = 6.5343 loss)
I0524 00:35:15.021517 11654 sgd_solver.cpp:112] Iteration 13170, lr = 0.1
I0524 00:35:22.765782 11654 solver.cpp:239] Iteration 13180 (1.29133 iter/s, 7.74393s/10 iters), loss = 6.84177
I0524 00:35:22.765836 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84177 (* 1 = 6.84177 loss)
I0524 00:35:22.765851 11654 sgd_solver.cpp:112] Iteration 13180, lr = 0.1
I0524 00:35:30.787940 11654 solver.cpp:239] Iteration 13190 (1.2466 iter/s, 8.0218s/10 iters), loss = 8.00107
I0524 00:35:30.787997 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.00107 (* 1 = 8.00107 loss)
I0524 00:35:31.482774 11654 sgd_solver.cpp:112] Iteration 13190, lr = 0.1
I0524 00:35:40.021999 11654 solver.cpp:239] Iteration 13200 (1.083 iter/s, 9.23363s/10 iters), loss = 7.50072
I0524 00:35:40.022238 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50072 (* 1 = 7.50072 loss)
I0524 00:35:40.596362 11654 sgd_solver.cpp:112] Iteration 13200, lr = 0.1
I0524 00:35:47.367208 11654 solver.cpp:239] Iteration 13210 (1.36152 iter/s, 7.34473s/10 iters), loss = 7.40167
I0524 00:35:47.367249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40167 (* 1 = 7.40167 loss)
I0524 00:35:47.451493 11654 sgd_solver.cpp:112] Iteration 13210, lr = 0.1
I0524 00:35:53.903606 11654 solver.cpp:239] Iteration 13220 (1.52996 iter/s, 6.5361s/10 iters), loss = 7.86033
I0524 00:35:53.903659 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86033 (* 1 = 7.86033 loss)
I0524 00:35:54.085580 11654 sgd_solver.cpp:112] Iteration 13220, lr = 0.1
I0524 00:36:00.243525 11654 solver.cpp:239] Iteration 13230 (1.57738 iter/s, 6.33962s/10 iters), loss = 6.76239
I0524 00:36:00.243572 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76239 (* 1 = 6.76239 loss)
I0524 00:36:00.243827 11654 sgd_solver.cpp:112] Iteration 13230, lr = 0.1
I0524 00:36:06.879642 11654 solver.cpp:239] Iteration 13240 (1.50697 iter/s, 6.63582s/10 iters), loss = 7.87178
I0524 00:36:06.879698 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87178 (* 1 = 7.87178 loss)
I0524 00:36:06.879712 11654 sgd_solver.cpp:112] Iteration 13240, lr = 0.1
I0524 00:36:14.205818 11654 solver.cpp:239] Iteration 13250 (1.36503 iter/s, 7.32585s/10 iters), loss = 7.37035
I0524 00:36:14.205941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.37035 (* 1 = 7.37035 loss)
I0524 00:36:14.330412 11654 sgd_solver.cpp:112] Iteration 13250, lr = 0.1
I0524 00:36:22.009958 11654 solver.cpp:239] Iteration 13260 (1.28144 iter/s, 7.80371s/10 iters), loss = 7.29921
I0524 00:36:22.010015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29921 (* 1 = 7.29921 loss)
I0524 00:36:22.010030 11654 sgd_solver.cpp:112] Iteration 13260, lr = 0.1
I0524 00:36:29.173055 11654 solver.cpp:239] Iteration 13270 (1.39654 iter/s, 7.16056s/10 iters), loss = 7.86082
I0524 00:36:29.173111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86082 (* 1 = 7.86082 loss)
I0524 00:36:29.173208 11654 sgd_solver.cpp:112] Iteration 13270, lr = 0.1
I0524 00:36:36.848017 11654 solver.cpp:239] Iteration 13280 (1.303 iter/s, 7.67462s/10 iters), loss = 7.42029
I0524 00:36:36.848073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.42029 (* 1 = 7.42029 loss)
I0524 00:36:36.848127 11654 sgd_solver.cpp:112] Iteration 13280, lr = 0.1
I0524 00:36:44.539677 11654 solver.cpp:239] Iteration 13290 (1.30017 iter/s, 7.69132s/10 iters), loss = 8.15732
I0524 00:36:44.539923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.15732 (* 1 = 8.15732 loss)
I0524 00:36:44.539963 11654 sgd_solver.cpp:112] Iteration 13290, lr = 0.1
I0524 00:36:53.321769 11654 solver.cpp:239] Iteration 13300 (1.13902 iter/s, 8.77948s/10 iters), loss = 8.1838
I0524 00:36:53.321825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.1838 (* 1 = 8.1838 loss)
I0524 00:36:53.321841 11654 sgd_solver.cpp:112] Iteration 13300, lr = 0.1
I0524 00:36:59.794840 11654 solver.cpp:239] Iteration 13310 (1.54546 iter/s, 6.47056s/10 iters), loss = 7.34398
I0524 00:36:59.794898 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.34398 (* 1 = 7.34398 loss)
I0524 00:36:59.795262 11654 sgd_solver.cpp:112] Iteration 13310, lr = 0.1
I0524 00:37:09.118813 11654 solver.cpp:239] Iteration 13320 (1.07255 iter/s, 9.32357s/10 iters), loss = 8.77455
I0524 00:37:09.118866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.77455 (* 1 = 8.77455 loss)
I0524 00:37:09.118885 11654 sgd_solver.cpp:112] Iteration 13320, lr = 0.1
I0524 00:37:16.037623 11654 solver.cpp:239] Iteration 13330 (1.4454 iter/s, 6.9185s/10 iters), loss = 7.94208
I0524 00:37:16.037911 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.94208 (* 1 = 7.94208 loss)
I0524 00:37:16.037987 11654 sgd_solver.cpp:112] Iteration 13330, lr = 0.1
I0524 00:37:22.482827 11654 solver.cpp:239] Iteration 13340 (1.55215 iter/s, 6.44268s/10 iters), loss = 8.57865
I0524 00:37:22.482882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.57865 (* 1 = 8.57865 loss)
I0524 00:37:22.482898 11654 sgd_solver.cpp:112] Iteration 13340, lr = 0.1
I0524 00:37:30.651861 11654 solver.cpp:239] Iteration 13350 (1.2242 iter/s, 8.1686s/10 iters), loss = 7.5301
I0524 00:37:30.651906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.5301 (* 1 = 7.5301 loss)
I0524 00:37:30.652019 11654 sgd_solver.cpp:112] Iteration 13350, lr = 0.1
I0524 00:37:38.122669 11654 solver.cpp:239] Iteration 13360 (1.3386 iter/s, 7.47047s/10 iters), loss = 7.8078
I0524 00:37:38.122750 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8078 (* 1 = 7.8078 loss)
I0524 00:37:38.122766 11654 sgd_solver.cpp:112] Iteration 13360, lr = 0.1
I0524 00:37:45.042366 11654 solver.cpp:239] Iteration 13370 (1.44568 iter/s, 6.91716s/10 iters), loss = 8.22919
I0524 00:37:45.042419 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.22919 (* 1 = 8.22919 loss)
I0524 00:37:45.572613 11654 sgd_solver.cpp:112] Iteration 13370, lr = 0.1
I0524 00:37:52.450716 11654 solver.cpp:239] Iteration 13380 (1.34989 iter/s, 7.40801s/10 iters), loss = 7.53367
I0524 00:37:52.450995 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.53367 (* 1 = 7.53367 loss)
I0524 00:37:52.451050 11654 sgd_solver.cpp:112] Iteration 13380, lr = 0.1
I0524 00:37:58.683529 11654 solver.cpp:239] Iteration 13390 (1.60454 iter/s, 6.23232s/10 iters), loss = 7.62836
I0524 00:37:58.683563 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62836 (* 1 = 7.62836 loss)
I0524 00:37:58.683578 11654 sgd_solver.cpp:112] Iteration 13390, lr = 0.1
I0524 00:38:05.845926 11654 solver.cpp:239] Iteration 13400 (1.39626 iter/s, 7.16197s/10 iters), loss = 7.50172
I0524 00:38:05.845986 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50172 (* 1 = 7.50172 loss)
I0524 00:38:05.846177 11654 sgd_solver.cpp:112] Iteration 13400, lr = 0.1
I0524 00:38:12.593597 11654 solver.cpp:239] Iteration 13410 (1.48206 iter/s, 6.74735s/10 iters), loss = 7.90014
I0524 00:38:12.593683 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90014 (* 1 = 7.90014 loss)
I0524 00:38:12.593715 11654 sgd_solver.cpp:112] Iteration 13410, lr = 0.1
I0524 00:38:19.232601 11654 solver.cpp:239] Iteration 13420 (1.50635 iter/s, 6.63857s/10 iters), loss = 8.4553
I0524 00:38:19.232655 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.4553 (* 1 = 8.4553 loss)
I0524 00:38:19.232669 11654 sgd_solver.cpp:112] Iteration 13420, lr = 0.1
I0524 00:38:26.444288 11654 solver.cpp:239] Iteration 13430 (1.38672 iter/s, 7.21129s/10 iters), loss = 7.50268
I0524 00:38:26.444514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50268 (* 1 = 7.50268 loss)
I0524 00:38:26.444542 11654 sgd_solver.cpp:112] Iteration 13430, lr = 0.1
I0524 00:38:33.017982 11654 solver.cpp:239] Iteration 13440 (1.52181 iter/s, 6.57113s/10 iters), loss = 7.12364
I0524 00:38:33.018040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12364 (* 1 = 7.12364 loss)
I0524 00:38:34.067171 11654 sgd_solver.cpp:112] Iteration 13440, lr = 0.1
I0524 00:38:41.276330 11654 solver.cpp:239] Iteration 13450 (1.21095 iter/s, 8.25798s/10 iters), loss = 8.4708
I0524 00:38:41.276391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.4708 (* 1 = 8.4708 loss)
I0524 00:38:41.276564 11654 sgd_solver.cpp:112] Iteration 13450, lr = 0.1
I0524 00:38:47.486363 11654 solver.cpp:239] Iteration 13460 (1.61037 iter/s, 6.20974s/10 iters), loss = 8.06138
I0524 00:38:47.486405 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.06138 (* 1 = 8.06138 loss)
I0524 00:38:47.486419 11654 sgd_solver.cpp:112] Iteration 13460, lr = 0.1
I0524 00:38:53.852808 11654 solver.cpp:239] Iteration 13470 (1.57081 iter/s, 6.36615s/10 iters), loss = 8.17596
I0524 00:38:53.852869 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.17596 (* 1 = 8.17596 loss)
I0524 00:38:53.852890 11654 sgd_solver.cpp:112] Iteration 13470, lr = 0.1
I0524 00:39:00.471719 11654 solver.cpp:239] Iteration 13480 (1.51141 iter/s, 6.61633s/10 iters), loss = 7.4655
I0524 00:39:00.471843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4655 (* 1 = 7.4655 loss)
I0524 00:39:00.484678 11654 sgd_solver.cpp:112] Iteration 13480, lr = 0.1
I0524 00:39:07.634479 11654 solver.cpp:239] Iteration 13490 (1.39619 iter/s, 7.16236s/10 iters), loss = 8.65325
I0524 00:39:07.634546 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.65325 (* 1 = 8.65325 loss)
I0524 00:39:07.634747 11654 sgd_solver.cpp:112] Iteration 13490, lr = 0.1
I0524 00:39:14.774191 11654 solver.cpp:239] Iteration 13500 (1.40068 iter/s, 7.13938s/10 iters), loss = 6.5638
I0524 00:39:14.774246 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5638 (* 1 = 6.5638 loss)
I0524 00:39:14.774261 11654 sgd_solver.cpp:112] Iteration 13500, lr = 0.1
I0524 00:39:22.294842 11654 solver.cpp:239] Iteration 13510 (1.32973 iter/s, 7.52032s/10 iters), loss = 7.76721
I0524 00:39:22.294893 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76721 (* 1 = 7.76721 loss)
I0524 00:39:22.294910 11654 sgd_solver.cpp:112] Iteration 13510, lr = 0.1
I0524 00:39:30.718180 11654 solver.cpp:239] Iteration 13520 (1.18724 iter/s, 8.42291s/10 iters), loss = 8.31199
I0524 00:39:30.718391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.31199 (* 1 = 8.31199 loss)
I0524 00:39:30.718425 11654 sgd_solver.cpp:112] Iteration 13520, lr = 0.1
I0524 00:39:37.689644 11654 solver.cpp:239] Iteration 13530 (1.43452 iter/s, 6.97098s/10 iters), loss = 7.8009
I0524 00:39:37.689693 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8009 (* 1 = 7.8009 loss)
I0524 00:39:37.689708 11654 sgd_solver.cpp:112] Iteration 13530, lr = 0.1
I0524 00:39:45.521139 11654 solver.cpp:239] Iteration 13540 (1.27695 iter/s, 7.83113s/10 iters), loss = 7.62759
I0524 00:39:45.521203 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62759 (* 1 = 7.62759 loss)
I0524 00:39:45.521322 11654 sgd_solver.cpp:112] Iteration 13540, lr = 0.1
I0524 00:39:52.036949 11654 solver.cpp:239] Iteration 13550 (1.5348 iter/s, 6.51551s/10 iters), loss = 7.86426
I0524 00:39:52.036988 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86426 (* 1 = 7.86426 loss)
I0524 00:39:52.344890 11654 sgd_solver.cpp:112] Iteration 13550, lr = 0.1
I0524 00:39:59.487962 11654 solver.cpp:239] Iteration 13560 (1.34216 iter/s, 7.45069s/10 iters), loss = 7.542
I0524 00:39:59.488014 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.542 (* 1 = 7.542 loss)
I0524 00:40:00.544909 11654 sgd_solver.cpp:112] Iteration 13560, lr = 0.1
I0524 00:40:09.970377 11654 solver.cpp:239] Iteration 13570 (0.954019 iter/s, 10.482s/10 iters), loss = 8.41482
I0524 00:40:09.970675 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.41482 (* 1 = 8.41482 loss)
I0524 00:40:10.125993 11654 sgd_solver.cpp:112] Iteration 13570, lr = 0.1
I0524 00:40:19.964617 11654 solver.cpp:239] Iteration 13580 (1.00064 iter/s, 9.99361s/10 iters), loss = 7.79512
I0524 00:40:19.964668 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.79512 (* 1 = 7.79512 loss)
I0524 00:40:19.965102 11654 sgd_solver.cpp:112] Iteration 13580, lr = 0.1
I0524 00:40:26.653652 11654 solver.cpp:239] Iteration 13590 (1.49505 iter/s, 6.68872s/10 iters), loss = 7.51334
I0524 00:40:26.653717 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51334 (* 1 = 7.51334 loss)
I0524 00:40:27.351444 11654 sgd_solver.cpp:112] Iteration 13590, lr = 0.1
I0524 00:40:33.699906 11654 solver.cpp:239] Iteration 13600 (1.41926 iter/s, 7.04592s/10 iters), loss = 8.53551
I0524 00:40:33.699964 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.53551 (* 1 = 8.53551 loss)
I0524 00:40:33.700052 11654 sgd_solver.cpp:112] Iteration 13600, lr = 0.1
I0524 00:40:40.278733 11654 solver.cpp:239] Iteration 13610 (1.5201 iter/s, 6.5785s/10 iters), loss = 8.08199
I0524 00:40:40.278842 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.08199 (* 1 = 8.08199 loss)
I0524 00:40:40.278858 11654 sgd_solver.cpp:112] Iteration 13610, lr = 0.1
I0524 00:40:47.084450 11654 solver.cpp:239] Iteration 13620 (1.46944 iter/s, 6.80532s/10 iters), loss = 7.37144
I0524 00:40:47.084493 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.37144 (* 1 = 7.37144 loss)
I0524 00:40:47.372675 11654 sgd_solver.cpp:112] Iteration 13620, lr = 0.1
I0524 00:40:54.903911 11654 solver.cpp:239] Iteration 13630 (1.27892 iter/s, 7.81912s/10 iters), loss = 6.47918
I0524 00:40:54.903956 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47918 (* 1 = 6.47918 loss)
I0524 00:40:55.918915 11654 sgd_solver.cpp:112] Iteration 13630, lr = 0.1
I0524 00:41:02.388941 11654 solver.cpp:239] Iteration 13640 (1.33606 iter/s, 7.4847s/10 iters), loss = 7.15307
I0524 00:41:02.388993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15307 (* 1 = 7.15307 loss)
I0524 00:41:02.766193 11654 sgd_solver.cpp:112] Iteration 13640, lr = 0.1
I0524 00:41:11.344126 11654 solver.cpp:239] Iteration 13650 (1.11672 iter/s, 8.9548s/10 iters), loss = 8.20172
I0524 00:41:11.344363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.20172 (* 1 = 8.20172 loss)
I0524 00:41:11.344413 11654 sgd_solver.cpp:112] Iteration 13650, lr = 0.1
I0524 00:41:18.014829 11654 solver.cpp:239] Iteration 13660 (1.4992 iter/s, 6.67022s/10 iters), loss = 7.30644
I0524 00:41:18.014899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30644 (* 1 = 7.30644 loss)
I0524 00:41:18.015403 11654 sgd_solver.cpp:112] Iteration 13660, lr = 0.1
I0524 00:41:26.038625 11654 solver.cpp:239] Iteration 13670 (1.24635 iter/s, 8.02343s/10 iters), loss = 8.1918
I0524 00:41:26.038678 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.1918 (* 1 = 8.1918 loss)
I0524 00:41:26.051033 11654 sgd_solver.cpp:112] Iteration 13670, lr = 0.1
I0524 00:41:33.281016 11654 solver.cpp:239] Iteration 13680 (1.38082 iter/s, 7.24207s/10 iters), loss = 7.85106
I0524 00:41:33.281059 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85106 (* 1 = 7.85106 loss)
I0524 00:41:34.122421 11654 sgd_solver.cpp:112] Iteration 13680, lr = 0.1
I0524 00:41:42.927016 11654 solver.cpp:239] Iteration 13690 (1.03674 iter/s, 9.64559s/10 iters), loss = 6.34316
I0524 00:41:42.927220 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34316 (* 1 = 6.34316 loss)
I0524 00:41:42.927244 11654 sgd_solver.cpp:112] Iteration 13690, lr = 0.1
I0524 00:41:50.661936 11654 solver.cpp:239] Iteration 13700 (1.29293 iter/s, 7.7344s/10 iters), loss = 7.91606
I0524 00:41:50.661990 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91606 (* 1 = 7.91606 loss)
I0524 00:41:50.662009 11654 sgd_solver.cpp:112] Iteration 13700, lr = 0.1
I0524 00:41:57.508456 11654 solver.cpp:239] Iteration 13710 (1.46068 iter/s, 6.84613s/10 iters), loss = 6.98394
I0524 00:41:57.508513 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98394 (* 1 = 6.98394 loss)
I0524 00:41:57.538738 11654 sgd_solver.cpp:112] Iteration 13710, lr = 0.1
I0524 00:42:06.981717 11654 solver.cpp:239] Iteration 13720 (1.05565 iter/s, 9.47285s/10 iters), loss = 7.87651
I0524 00:42:06.981770 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87651 (* 1 = 7.87651 loss)
I0524 00:42:07.015735 11654 sgd_solver.cpp:112] Iteration 13720, lr = 0.1
I0524 00:42:13.270507 11654 solver.cpp:239] Iteration 13730 (1.59021 iter/s, 6.2885s/10 iters), loss = 7.14214
I0524 00:42:13.270614 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14214 (* 1 = 7.14214 loss)
I0524 00:42:13.270956 11654 sgd_solver.cpp:112] Iteration 13730, lr = 0.1
I0524 00:42:20.047271 11654 solver.cpp:239] Iteration 13740 (1.47571 iter/s, 6.77639s/10 iters), loss = 7.29802
I0524 00:42:20.047333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29802 (* 1 = 7.29802 loss)
I0524 00:42:20.133244 11654 sgd_solver.cpp:112] Iteration 13740, lr = 0.1
I0524 00:42:29.072662 11654 solver.cpp:239] Iteration 13750 (1.10804 iter/s, 9.02499s/10 iters), loss = 7.58264
I0524 00:42:29.072722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58264 (* 1 = 7.58264 loss)
I0524 00:42:29.072849 11654 sgd_solver.cpp:112] Iteration 13750, lr = 0.1
I0524 00:42:35.449249 11654 solver.cpp:239] Iteration 13760 (1.56831 iter/s, 6.37629s/10 iters), loss = 8.87124
I0524 00:42:35.449290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.87124 (* 1 = 8.87124 loss)
I0524 00:42:35.449302 11654 sgd_solver.cpp:112] Iteration 13760, lr = 0.1
I0524 00:42:42.490741 11654 solver.cpp:239] Iteration 13770 (1.42027 iter/s, 7.04093s/10 iters), loss = 7.13073
I0524 00:42:42.490789 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13073 (* 1 = 7.13073 loss)
I0524 00:42:42.490806 11654 sgd_solver.cpp:112] Iteration 13770, lr = 0.1
I0524 00:42:51.884191 11654 solver.cpp:239] Iteration 13780 (1.06487 iter/s, 9.39082s/10 iters), loss = 7.12953
I0524 00:42:51.884439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12953 (* 1 = 7.12953 loss)
I0524 00:42:51.884485 11654 sgd_solver.cpp:112] Iteration 13780, lr = 0.1
I0524 00:42:58.164687 11654 solver.cpp:239] Iteration 13790 (1.59237 iter/s, 6.27994s/10 iters), loss = 8.33134
I0524 00:42:58.164733 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.33134 (* 1 = 8.33134 loss)
I0524 00:42:58.165052 11654 sgd_solver.cpp:112] Iteration 13790, lr = 0.1
I0524 00:43:04.455860 11654 solver.cpp:239] Iteration 13800 (1.5896 iter/s, 6.29087s/10 iters), loss = 7.70477
I0524 00:43:04.455919 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70477 (* 1 = 7.70477 loss)
I0524 00:43:04.455946 11654 sgd_solver.cpp:112] Iteration 13800, lr = 0.1
I0524 00:43:11.129222 11654 solver.cpp:239] Iteration 13810 (1.49857 iter/s, 6.67305s/10 iters), loss = 7.70873
I0524 00:43:11.129281 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70873 (* 1 = 7.70873 loss)
I0524 00:43:11.129634 11654 sgd_solver.cpp:112] Iteration 13810, lr = 0.1
I0524 00:43:18.433032 11654 solver.cpp:239] Iteration 13820 (1.36921 iter/s, 7.30348s/10 iters), loss = 8.00306
I0524 00:43:18.433079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.00306 (* 1 = 8.00306 loss)
I0524 00:43:18.433264 11654 sgd_solver.cpp:112] Iteration 13820, lr = 0.1
I0524 00:43:25.983424 11654 solver.cpp:239] Iteration 13830 (1.32449 iter/s, 7.55006s/10 iters), loss = 7.85193
I0524 00:43:25.983592 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85193 (* 1 = 7.85193 loss)
I0524 00:43:25.983623 11654 sgd_solver.cpp:112] Iteration 13830, lr = 0.1
I0524 00:43:37.069046 11654 solver.cpp:239] Iteration 13840 (0.902294 iter/s, 11.0829s/10 iters), loss = 8.05102
I0524 00:43:37.069118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.05102 (* 1 = 8.05102 loss)
I0524 00:43:37.069140 11654 sgd_solver.cpp:112] Iteration 13840, lr = 0.1
I0524 00:43:44.854923 11654 solver.cpp:239] Iteration 13850 (1.2848 iter/s, 7.78332s/10 iters), loss = 7.48347
I0524 00:43:44.854982 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48347 (* 1 = 7.48347 loss)
I0524 00:43:45.531239 11654 sgd_solver.cpp:112] Iteration 13850, lr = 0.1
I0524 00:43:52.598722 11654 solver.cpp:239] Iteration 13860 (1.29142 iter/s, 7.74343s/10 iters), loss = 8.02945
I0524 00:43:52.598764 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.02945 (* 1 = 8.02945 loss)
I0524 00:43:53.073240 11654 sgd_solver.cpp:112] Iteration 13860, lr = 0.1
I0524 00:44:02.274618 11654 solver.cpp:239] Iteration 13870 (1.03354 iter/s, 9.67548s/10 iters), loss = 8.38826
I0524 00:44:02.274906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.38826 (* 1 = 8.38826 loss)
I0524 00:44:02.274966 11654 sgd_solver.cpp:112] Iteration 13870, lr = 0.1
I0524 00:44:09.934180 11654 solver.cpp:239] Iteration 13880 (1.30599 iter/s, 7.657s/10 iters), loss = 6.08005
I0524 00:44:09.934221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08005 (* 1 = 6.08005 loss)
I0524 00:44:09.934233 11654 sgd_solver.cpp:112] Iteration 13880, lr = 0.1
I0524 00:44:17.329310 11654 solver.cpp:239] Iteration 13890 (1.3523 iter/s, 7.39479s/10 iters), loss = 7.79257
I0524 00:44:17.329373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.79257 (* 1 = 7.79257 loss)
I0524 00:44:17.329649 11654 sgd_solver.cpp:112] Iteration 13890, lr = 0.1
I0524 00:44:23.865013 11654 solver.cpp:239] Iteration 13900 (1.53013 iter/s, 6.53539s/10 iters), loss = 7.87967
I0524 00:44:23.865074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87967 (* 1 = 7.87967 loss)
I0524 00:44:23.865195 11654 sgd_solver.cpp:112] Iteration 13900, lr = 0.1
I0524 00:44:30.849910 11654 solver.cpp:239] Iteration 13910 (1.43173 iter/s, 6.98458s/10 iters), loss = 7.0418
I0524 00:44:30.849961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0418 (* 1 = 7.0418 loss)
I0524 00:44:30.850118 11654 sgd_solver.cpp:112] Iteration 13910, lr = 0.1
I0524 00:44:38.586859 11654 solver.cpp:239] Iteration 13920 (1.29256 iter/s, 7.73661s/10 iters), loss = 8.00881
I0524 00:44:38.587054 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.00881 (* 1 = 8.00881 loss)
I0524 00:44:38.587097 11654 sgd_solver.cpp:112] Iteration 13920, lr = 0.1
I0524 00:44:45.582418 11654 solver.cpp:239] Iteration 13930 (1.42957 iter/s, 6.99509s/10 iters), loss = 7.60581
I0524 00:44:45.582484 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.60581 (* 1 = 7.60581 loss)
I0524 00:44:46.901511 11654 sgd_solver.cpp:112] Iteration 13930, lr = 0.1
I0524 00:44:55.046605 11654 solver.cpp:239] Iteration 13940 (1.05666 iter/s, 9.46376s/10 iters), loss = 7.89837
I0524 00:44:55.046676 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89837 (* 1 = 7.89837 loss)
I0524 00:44:55.047053 11654 sgd_solver.cpp:112] Iteration 13940, lr = 0.1
I0524 00:45:01.522948 11654 solver.cpp:239] Iteration 13950 (1.54415 iter/s, 6.47604s/10 iters), loss = 7.73011
I0524 00:45:01.522990 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.73011 (* 1 = 7.73011 loss)
I0524 00:45:01.523003 11654 sgd_solver.cpp:112] Iteration 13950, lr = 0.1
I0524 00:45:07.977262 11654 solver.cpp:239] Iteration 13960 (1.54942 iter/s, 6.45401s/10 iters), loss = 7.39366
I0524 00:45:07.977324 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39366 (* 1 = 7.39366 loss)
I0524 00:45:07.977587 11654 sgd_solver.cpp:112] Iteration 13960, lr = 0.1
I0524 00:45:14.899577 11654 solver.cpp:239] Iteration 13970 (1.44467 iter/s, 6.92199s/10 iters), loss = 6.94435
I0524 00:45:14.899849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94435 (* 1 = 6.94435 loss)
I0524 00:45:14.908502 11654 sgd_solver.cpp:112] Iteration 13970, lr = 0.1
I0524 00:45:21.724331 11654 solver.cpp:239] Iteration 13980 (1.46536 iter/s, 6.82428s/10 iters), loss = 7.3985
I0524 00:45:21.724378 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3985 (* 1 = 7.3985 loss)
I0524 00:45:21.724944 11654 sgd_solver.cpp:112] Iteration 13980, lr = 0.1
I0524 00:45:28.761764 11654 solver.cpp:239] Iteration 13990 (1.42104 iter/s, 7.03711s/10 iters), loss = 8.95554
I0524 00:45:28.761824 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.95554 (* 1 = 8.95554 loss)
I0524 00:45:28.761953 11654 sgd_solver.cpp:112] Iteration 13990, lr = 0.1
I0524 00:45:35.382789 11654 solver.cpp:239] Iteration 14000 (1.51041 iter/s, 6.62072s/10 iters), loss = 7.20703
I0524 00:45:35.382830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20703 (* 1 = 7.20703 loss)
I0524 00:45:35.382844 11654 sgd_solver.cpp:112] Iteration 14000, lr = 0.1
I0524 00:45:44.061131 11654 solver.cpp:239] Iteration 14010 (1.15234 iter/s, 8.67796s/10 iters), loss = 7.64108
I0524 00:45:44.061189 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.64108 (* 1 = 7.64108 loss)
I0524 00:45:44.061208 11654 sgd_solver.cpp:112] Iteration 14010, lr = 0.1
I0524 00:45:51.134140 11654 solver.cpp:239] Iteration 14020 (1.41432 iter/s, 7.07053s/10 iters), loss = 7.74624
I0524 00:45:51.134436 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.74624 (* 1 = 7.74624 loss)
I0524 00:45:51.134497 11654 sgd_solver.cpp:112] Iteration 14020, lr = 0.1
I0524 00:45:58.539073 11654 solver.cpp:239] Iteration 14030 (1.35054 iter/s, 7.40442s/10 iters), loss = 8.12491
I0524 00:45:58.539109 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.12491 (* 1 = 8.12491 loss)
I0524 00:45:58.539140 11654 sgd_solver.cpp:112] Iteration 14030, lr = 0.1
I0524 00:46:05.131001 11654 solver.cpp:239] Iteration 14040 (1.51709 iter/s, 6.59157s/10 iters), loss = 7.92685
I0524 00:46:05.131182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.92685 (* 1 = 7.92685 loss)
I0524 00:46:05.161468 11654 sgd_solver.cpp:112] Iteration 14040, lr = 0.1
I0524 00:46:12.617159 11654 solver.cpp:239] Iteration 14050 (1.33587 iter/s, 7.48577s/10 iters), loss = 7.30036
I0524 00:46:12.617233 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30036 (* 1 = 7.30036 loss)
I0524 00:46:12.617466 11654 sgd_solver.cpp:112] Iteration 14050, lr = 0.1
I0524 00:46:20.994657 11654 solver.cpp:239] Iteration 14060 (1.19373 iter/s, 8.37711s/10 iters), loss = 7.81493
I0524 00:46:20.994720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.81493 (* 1 = 7.81493 loss)
I0524 00:46:20.994909 11654 sgd_solver.cpp:112] Iteration 14060, lr = 0.1
I0524 00:46:28.134048 11654 solver.cpp:239] Iteration 14070 (1.40075 iter/s, 7.13905s/10 iters), loss = 8.19018
I0524 00:46:28.134301 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.19018 (* 1 = 8.19018 loss)
I0524 00:46:28.134351 11654 sgd_solver.cpp:112] Iteration 14070, lr = 0.1
I0524 00:46:37.484235 11654 solver.cpp:239] Iteration 14080 (1.06957 iter/s, 9.34957s/10 iters), loss = 7.52261
I0524 00:46:37.484292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.52261 (* 1 = 7.52261 loss)
I0524 00:46:37.484309 11654 sgd_solver.cpp:112] Iteration 14080, lr = 0.1
I0524 00:46:45.706806 11654 solver.cpp:239] Iteration 14090 (1.21624 iter/s, 8.22206s/10 iters), loss = 7.99071
I0524 00:46:45.706924 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.99071 (* 1 = 7.99071 loss)
I0524 00:46:45.707204 11654 sgd_solver.cpp:112] Iteration 14090, lr = 0.1
I0524 00:46:53.050441 11654 solver.cpp:239] Iteration 14100 (1.36179 iter/s, 7.3433s/10 iters), loss = 7.44029
I0524 00:46:53.050489 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44029 (* 1 = 7.44029 loss)
I0524 00:46:53.050515 11654 sgd_solver.cpp:112] Iteration 14100, lr = 0.1
I0524 00:46:59.566787 11654 solver.cpp:239] Iteration 14110 (1.535 iter/s, 6.51466s/10 iters), loss = 8.30317
I0524 00:46:59.566962 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.30317 (* 1 = 8.30317 loss)
I0524 00:46:59.571322 11654 sgd_solver.cpp:112] Iteration 14110, lr = 0.1
I0524 00:47:06.322844 11654 solver.cpp:239] Iteration 14120 (1.48025 iter/s, 6.75564s/10 iters), loss = 8.03979
I0524 00:47:06.322901 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.03979 (* 1 = 8.03979 loss)
I0524 00:47:06.322916 11654 sgd_solver.cpp:112] Iteration 14120, lr = 0.1
I0524 00:47:13.504595 11654 solver.cpp:239] Iteration 14130 (1.39248 iter/s, 7.18143s/10 iters), loss = 8.6121
I0524 00:47:13.504657 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.6121 (* 1 = 8.6121 loss)
I0524 00:47:13.504793 11654 sgd_solver.cpp:112] Iteration 14130, lr = 0.1
I0524 00:47:19.666759 11654 solver.cpp:239] Iteration 14140 (1.62289 iter/s, 6.16186s/10 iters), loss = 7.69849
I0524 00:47:19.666828 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69849 (* 1 = 7.69849 loss)
I0524 00:47:19.667568 11654 sgd_solver.cpp:112] Iteration 14140, lr = 0.1
I0524 00:47:26.362357 11654 solver.cpp:239] Iteration 14150 (1.49359 iter/s, 6.69527s/10 iters), loss = 7.69057
I0524 00:47:26.362412 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69057 (* 1 = 7.69057 loss)
I0524 00:47:26.362488 11654 sgd_solver.cpp:112] Iteration 14150, lr = 0.1
I0524 00:47:33.930323 11654 solver.cpp:239] Iteration 14160 (1.32142 iter/s, 7.56762s/10 iters), loss = 7.59017
I0524 00:47:33.930459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59017 (* 1 = 7.59017 loss)
I0524 00:47:33.930856 11654 sgd_solver.cpp:112] Iteration 14160, lr = 0.1
I0524 00:47:42.000974 11654 solver.cpp:239] Iteration 14170 (1.23913 iter/s, 8.07021s/10 iters), loss = 8.5766
I0524 00:47:42.001027 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.5766 (* 1 = 8.5766 loss)
I0524 00:47:42.001055 11654 sgd_solver.cpp:112] Iteration 14170, lr = 0.1
I0524 00:47:47.899654 11654 solver.cpp:239] Iteration 14180 (1.69537 iter/s, 5.8984s/10 iters), loss = 7.63973
I0524 00:47:47.899709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63973 (* 1 = 7.63973 loss)
I0524 00:47:47.899951 11654 sgd_solver.cpp:112] Iteration 14180, lr = 0.1
I0524 00:47:55.056509 11654 solver.cpp:239] Iteration 14190 (1.39733 iter/s, 7.15652s/10 iters), loss = 8.3964
I0524 00:47:55.056555 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.3964 (* 1 = 8.3964 loss)
I0524 00:47:55.056761 11654 sgd_solver.cpp:112] Iteration 14190, lr = 0.1
I0524 00:48:01.863729 11654 solver.cpp:239] Iteration 14200 (1.4691 iter/s, 6.8069s/10 iters), loss = 7.76135
I0524 00:48:01.863790 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76135 (* 1 = 7.76135 loss)
I0524 00:48:02.082852 11654 sgd_solver.cpp:112] Iteration 14200, lr = 0.1
I0524 00:48:09.425158 11654 solver.cpp:239] Iteration 14210 (1.32256 iter/s, 7.56109s/10 iters), loss = 7.73497
I0524 00:48:09.425402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.73497 (* 1 = 7.73497 loss)
I0524 00:48:09.427394 11654 sgd_solver.cpp:112] Iteration 14210, lr = 0.1
I0524 00:48:19.097563 11654 solver.cpp:239] Iteration 14220 (1.03393 iter/s, 9.67183s/10 iters), loss = 7.56185
I0524 00:48:19.097625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.56185 (* 1 = 7.56185 loss)
I0524 00:48:19.099478 11654 sgd_solver.cpp:112] Iteration 14220, lr = 0.1
I0524 00:48:25.182266 11654 solver.cpp:239] Iteration 14230 (1.64354 iter/s, 6.08441s/10 iters), loss = 8.06577
I0524 00:48:25.182312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.06577 (* 1 = 8.06577 loss)
I0524 00:48:25.182808 11654 sgd_solver.cpp:112] Iteration 14230, lr = 0.1
I0524 00:48:31.598980 11654 solver.cpp:239] Iteration 14240 (1.5585 iter/s, 6.41642s/10 iters), loss = 7.21832
I0524 00:48:31.599036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21832 (* 1 = 7.21832 loss)
I0524 00:48:31.625742 11654 sgd_solver.cpp:112] Iteration 14240, lr = 0.1
I0524 00:48:38.570107 11654 solver.cpp:239] Iteration 14250 (1.43455 iter/s, 6.97081s/10 iters), loss = 7.66311
I0524 00:48:38.570147 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66311 (* 1 = 7.66311 loss)
I0524 00:48:38.570160 11654 sgd_solver.cpp:112] Iteration 14250, lr = 0.1
I0524 00:48:46.399006 11654 solver.cpp:239] Iteration 14260 (1.27738 iter/s, 7.82855s/10 iters), loss = 7.2866
I0524 00:48:46.399274 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2866 (* 1 = 7.2866 loss)
I0524 00:48:46.399348 11654 sgd_solver.cpp:112] Iteration 14260, lr = 0.1
I0524 00:48:53.850299 11654 solver.cpp:239] Iteration 14270 (1.34214 iter/s, 7.45078s/10 iters), loss = 7.40949
I0524 00:48:53.850363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40949 (* 1 = 7.40949 loss)
I0524 00:48:53.850488 11654 sgd_solver.cpp:112] Iteration 14270, lr = 0.1
I0524 00:49:00.214268 11654 solver.cpp:239] Iteration 14280 (1.57142 iter/s, 6.36367s/10 iters), loss = 7.70474
I0524 00:49:00.214316 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70474 (* 1 = 7.70474 loss)
I0524 00:49:00.214675 11654 sgd_solver.cpp:112] Iteration 14280, lr = 0.1
I0524 00:49:07.388505 11654 solver.cpp:239] Iteration 14290 (1.39394 iter/s, 7.17391s/10 iters), loss = 7.93488
I0524 00:49:07.388555 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.93488 (* 1 = 7.93488 loss)
I0524 00:49:07.388571 11654 sgd_solver.cpp:112] Iteration 14290, lr = 0.1
I0524 00:49:15.473268 11654 solver.cpp:239] Iteration 14300 (1.23695 iter/s, 8.08441s/10 iters), loss = 6.95272
I0524 00:49:15.473312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95272 (* 1 = 6.95272 loss)
I0524 00:49:15.473333 11654 sgd_solver.cpp:112] Iteration 14300, lr = 0.1
I0524 00:49:21.618532 11654 solver.cpp:239] Iteration 14310 (1.62735 iter/s, 6.14497s/10 iters), loss = 7.13628
I0524 00:49:21.618732 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13628 (* 1 = 7.13628 loss)
I0524 00:49:21.618916 11654 sgd_solver.cpp:112] Iteration 14310, lr = 0.1
I0524 00:49:29.661979 11654 solver.cpp:239] Iteration 14320 (1.24332 iter/s, 8.04299s/10 iters), loss = 7.43179
I0524 00:49:29.662032 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43179 (* 1 = 7.43179 loss)
I0524 00:49:29.662690 11654 sgd_solver.cpp:112] Iteration 14320, lr = 0.1
I0524 00:49:35.888821 11654 solver.cpp:239] Iteration 14330 (1.60602 iter/s, 6.22656s/10 iters), loss = 8.17874
I0524 00:49:35.888871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.17874 (* 1 = 8.17874 loss)
I0524 00:49:35.889394 11654 sgd_solver.cpp:112] Iteration 14330, lr = 0.1
I0524 00:49:43.440158 11654 solver.cpp:239] Iteration 14340 (1.32433 iter/s, 7.55101s/10 iters), loss = 7.18238
I0524 00:49:43.440196 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18238 (* 1 = 7.18238 loss)
I0524 00:49:43.440213 11654 sgd_solver.cpp:112] Iteration 14340, lr = 0.1
I0524 00:49:51.462083 11654 solver.cpp:239] Iteration 14350 (1.24664 iter/s, 8.02157s/10 iters), loss = 7.91387
I0524 00:49:51.462136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91387 (* 1 = 7.91387 loss)
I0524 00:49:51.462152 11654 sgd_solver.cpp:112] Iteration 14350, lr = 0.1
I0524 00:49:58.316854 11654 solver.cpp:239] Iteration 14360 (1.45898 iter/s, 6.8541s/10 iters), loss = 7.87604
I0524 00:49:58.317018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87604 (* 1 = 7.87604 loss)
I0524 00:49:58.330775 11654 sgd_solver.cpp:112] Iteration 14360, lr = 0.1
I0524 00:50:03.008729 11654 solver.cpp:239] Iteration 14370 (2.13151 iter/s, 4.69152s/10 iters), loss = 7.8681
I0524 00:50:03.008800 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8681 (* 1 = 7.8681 loss)
I0524 00:50:03.008824 11654 sgd_solver.cpp:112] Iteration 14370, lr = 0.1
I0524 00:50:08.585780 11654 solver.cpp:239] Iteration 14380 (1.79315 iter/s, 5.57678s/10 iters), loss = 7.58125
I0524 00:50:08.585835 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58125 (* 1 = 7.58125 loss)
I0524 00:50:09.310540 11654 sgd_solver.cpp:112] Iteration 14380, lr = 0.1
I0524 00:50:15.567296 11654 solver.cpp:239] Iteration 14390 (1.43242 iter/s, 6.9812s/10 iters), loss = 7.78787
I0524 00:50:15.567348 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78787 (* 1 = 7.78787 loss)
I0524 00:50:15.567574 11654 sgd_solver.cpp:112] Iteration 14390, lr = 0.1
I0524 00:50:21.686421 11654 solver.cpp:239] Iteration 14400 (1.6343 iter/s, 6.11884s/10 iters), loss = 7.67196
I0524 00:50:21.686475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.67196 (* 1 = 7.67196 loss)
I0524 00:50:21.686720 11654 sgd_solver.cpp:112] Iteration 14400, lr = 0.1
I0524 00:50:28.371498 11654 solver.cpp:239] Iteration 14410 (1.49594 iter/s, 6.68476s/10 iters), loss = 7.84701
I0524 00:50:28.371755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.84701 (* 1 = 7.84701 loss)
I0524 00:50:28.373492 11654 sgd_solver.cpp:112] Iteration 14410, lr = 0.1
I0524 00:50:34.489325 11654 solver.cpp:239] Iteration 14420 (1.63469 iter/s, 6.11737s/10 iters), loss = 8.14374
I0524 00:50:34.489384 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.14374 (* 1 = 8.14374 loss)
I0524 00:50:34.489640 11654 sgd_solver.cpp:112] Iteration 14420, lr = 0.1
I0524 00:50:42.530786 11654 solver.cpp:239] Iteration 14430 (1.24361 iter/s, 8.0411s/10 iters), loss = 7.44802
I0524 00:50:42.530838 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44802 (* 1 = 7.44802 loss)
I0524 00:50:42.532761 11654 sgd_solver.cpp:112] Iteration 14430, lr = 0.1
I0524 00:50:49.228122 11654 solver.cpp:239] Iteration 14440 (1.4932 iter/s, 6.69704s/10 iters), loss = 7.22104
I0524 00:50:49.228173 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22104 (* 1 = 7.22104 loss)
I0524 00:50:49.228197 11654 sgd_solver.cpp:112] Iteration 14440, lr = 0.1
I0524 00:50:57.423517 11654 solver.cpp:239] Iteration 14450 (1.22025 iter/s, 8.19503s/10 iters), loss = 7.87123
I0524 00:50:57.423573 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87123 (* 1 = 7.87123 loss)
I0524 00:50:57.431279 11654 sgd_solver.cpp:112] Iteration 14450, lr = 0.1
I0524 00:51:06.801789 11654 solver.cpp:239] Iteration 14460 (1.06634 iter/s, 9.37786s/10 iters), loss = 8.14427
I0524 00:51:06.802036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.14427 (* 1 = 8.14427 loss)
I0524 00:51:06.802084 11654 sgd_solver.cpp:112] Iteration 14460, lr = 0.1
I0524 00:51:14.162765 11654 solver.cpp:239] Iteration 14470 (1.3587 iter/s, 7.35999s/10 iters), loss = 7.57655
I0524 00:51:14.162817 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.57655 (* 1 = 7.57655 loss)
I0524 00:51:14.835817 11654 sgd_solver.cpp:112] Iteration 14470, lr = 0.1
I0524 00:51:23.488274 11654 solver.cpp:239] Iteration 14480 (1.07237 iter/s, 9.32511s/10 iters), loss = 7.31412
I0524 00:51:23.488318 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31412 (* 1 = 7.31412 loss)
I0524 00:51:24.424602 11654 sgd_solver.cpp:112] Iteration 14480, lr = 0.1
I0524 00:51:33.167351 11654 solver.cpp:239] Iteration 14490 (1.0332 iter/s, 9.67866s/10 iters), loss = 7.89782
I0524 00:51:33.167407 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89782 (* 1 = 7.89782 loss)
I0524 00:51:33.167577 11654 sgd_solver.cpp:112] Iteration 14490, lr = 0.1
I0524 00:51:43.886085 11654 solver.cpp:239] Iteration 14500 (0.932986 iter/s, 10.7183s/10 iters), loss = 7.78345
I0524 00:51:43.886298 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78345 (* 1 = 7.78345 loss)
I0524 00:51:44.620535 11654 sgd_solver.cpp:112] Iteration 14500, lr = 0.1
I0524 00:51:50.989209 11654 solver.cpp:239] Iteration 14510 (1.40792 iter/s, 7.10267s/10 iters), loss = 7.7087
I0524 00:51:50.989253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.7087 (* 1 = 7.7087 loss)
I0524 00:51:50.989270 11654 sgd_solver.cpp:112] Iteration 14510, lr = 0.1
I0524 00:51:58.375401 11654 solver.cpp:239] Iteration 14520 (1.35394 iter/s, 7.38587s/10 iters), loss = 7.76842
I0524 00:51:58.375438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76842 (* 1 = 7.76842 loss)
I0524 00:51:58.375452 11654 sgd_solver.cpp:112] Iteration 14520, lr = 0.1
I0524 00:52:05.268368 11654 solver.cpp:239] Iteration 14530 (1.45082 iter/s, 6.89266s/10 iters), loss = 6.89129
I0524 00:52:05.268422 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89129 (* 1 = 6.89129 loss)
I0524 00:52:05.268440 11654 sgd_solver.cpp:112] Iteration 14530, lr = 0.1
I0524 00:52:11.771054 11654 solver.cpp:239] Iteration 14540 (1.53794 iter/s, 6.50221s/10 iters), loss = 8.13287
I0524 00:52:11.771103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.13287 (* 1 = 8.13287 loss)
I0524 00:52:11.771464 11654 sgd_solver.cpp:112] Iteration 14540, lr = 0.1
I0524 00:52:18.002759 11654 solver.cpp:239] Iteration 14550 (1.60477 iter/s, 6.23141s/10 iters), loss = 8.98967
I0524 00:52:18.003024 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.98967 (* 1 = 8.98967 loss)
I0524 00:52:18.308504 11654 sgd_solver.cpp:112] Iteration 14550, lr = 0.1
I0524 00:52:27.133337 11654 solver.cpp:239] Iteration 14560 (1.09529 iter/s, 9.13002s/10 iters), loss = 7.8311
I0524 00:52:27.133390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8311 (* 1 = 7.8311 loss)
I0524 00:52:27.133407 11654 sgd_solver.cpp:112] Iteration 14560, lr = 0.1
I0524 00:52:33.670387 11654 solver.cpp:239] Iteration 14570 (1.52983 iter/s, 6.53668s/10 iters), loss = 7.33694
I0524 00:52:33.670440 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33694 (* 1 = 7.33694 loss)
I0524 00:52:33.678733 11654 sgd_solver.cpp:112] Iteration 14570, lr = 0.1
I0524 00:52:40.884959 11654 solver.cpp:239] Iteration 14580 (1.38615 iter/s, 7.21424s/10 iters), loss = 7.91567
I0524 00:52:40.885012 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91567 (* 1 = 7.91567 loss)
I0524 00:52:40.885061 11654 sgd_solver.cpp:112] Iteration 14580, lr = 0.1
I0524 00:52:46.971016 11654 solver.cpp:239] Iteration 14590 (1.64318 iter/s, 6.08577s/10 iters), loss = 8.19876
I0524 00:52:46.971071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.19876 (* 1 = 8.19876 loss)
I0524 00:52:46.971119 11654 sgd_solver.cpp:112] Iteration 14590, lr = 0.1
I0524 00:52:53.217872 11654 solver.cpp:239] Iteration 14600 (1.60088 iter/s, 6.24656s/10 iters), loss = 6.91715
I0524 00:52:53.218034 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91715 (* 1 = 6.91715 loss)
I0524 00:52:53.218055 11654 sgd_solver.cpp:112] Iteration 14600, lr = 0.1
I0524 00:53:00.588383 11654 solver.cpp:239] Iteration 14610 (1.35684 iter/s, 7.37005s/10 iters), loss = 7.70407
I0524 00:53:00.588423 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70407 (* 1 = 7.70407 loss)
I0524 00:53:00.588436 11654 sgd_solver.cpp:112] Iteration 14610, lr = 0.1
I0524 00:53:07.724328 11654 solver.cpp:239] Iteration 14620 (1.40144 iter/s, 7.13554s/10 iters), loss = 7.59836
I0524 00:53:07.724422 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59836 (* 1 = 7.59836 loss)
I0524 00:53:07.724445 11654 sgd_solver.cpp:112] Iteration 14620, lr = 0.1
I0524 00:53:15.132200 11654 solver.cpp:239] Iteration 14630 (1.34999 iter/s, 7.40749s/10 iters), loss = 6.94802
I0524 00:53:15.132272 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94802 (* 1 = 6.94802 loss)
I0524 00:53:15.132295 11654 sgd_solver.cpp:112] Iteration 14630, lr = 0.1
I0524 00:53:22.947489 11654 solver.cpp:239] Iteration 14640 (1.27997 iter/s, 7.81271s/10 iters), loss = 7.47557
I0524 00:53:22.947542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.47557 (* 1 = 7.47557 loss)
I0524 00:53:22.956250 11654 sgd_solver.cpp:112] Iteration 14640, lr = 0.1
I0524 00:53:29.693117 11654 solver.cpp:239] Iteration 14650 (1.48251 iter/s, 6.74532s/10 iters), loss = 8.13323
I0524 00:53:29.693373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.13323 (* 1 = 8.13323 loss)
I0524 00:53:29.693409 11654 sgd_solver.cpp:112] Iteration 14650, lr = 0.1
I0524 00:53:36.365526 11654 solver.cpp:239] Iteration 14660 (1.499 iter/s, 6.67109s/10 iters), loss = 6.88105
I0524 00:53:36.365579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88105 (* 1 = 6.88105 loss)
I0524 00:53:36.365597 11654 sgd_solver.cpp:112] Iteration 14660, lr = 0.1
I0524 00:53:42.482411 11654 solver.cpp:239] Iteration 14670 (1.63512 iter/s, 6.11575s/10 iters), loss = 7.19824
I0524 00:53:42.482468 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19824 (* 1 = 7.19824 loss)
I0524 00:53:42.482532 11654 sgd_solver.cpp:112] Iteration 14670, lr = 0.1
I0524 00:53:48.950862 11654 solver.cpp:239] Iteration 14680 (1.54604 iter/s, 6.46815s/10 iters), loss = 6.99004
I0524 00:53:48.950922 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99004 (* 1 = 6.99004 loss)
I0524 00:53:48.950939 11654 sgd_solver.cpp:112] Iteration 14680, lr = 0.1
I0524 00:53:55.556860 11654 solver.cpp:239] Iteration 14690 (1.51386 iter/s, 6.60562s/10 iters), loss = 8.02295
I0524 00:53:55.556915 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.02295 (* 1 = 8.02295 loss)
I0524 00:53:55.911222 11654 sgd_solver.cpp:112] Iteration 14690, lr = 0.1
I0524 00:54:04.185387 11654 solver.cpp:239] Iteration 14700 (1.159 iter/s, 8.62816s/10 iters), loss = 6.70002
I0524 00:54:04.185626 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70002 (* 1 = 6.70002 loss)
I0524 00:54:04.644310 11654 sgd_solver.cpp:112] Iteration 14700, lr = 0.1
I0524 00:54:12.203789 11654 solver.cpp:239] Iteration 14710 (1.24721 iter/s, 8.01789s/10 iters), loss = 7.14946
I0524 00:54:12.203833 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14946 (* 1 = 7.14946 loss)
I0524 00:54:12.203848 11654 sgd_solver.cpp:112] Iteration 14710, lr = 0.1
I0524 00:54:21.303397 11654 solver.cpp:239] Iteration 14720 (1.099 iter/s, 9.09915s/10 iters), loss = 7.14956
I0524 00:54:21.303452 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14956 (* 1 = 7.14956 loss)
I0524 00:54:22.445163 11654 sgd_solver.cpp:112] Iteration 14720, lr = 0.1
I0524 00:54:31.235127 11654 solver.cpp:239] Iteration 14730 (1.00692 iter/s, 9.93131s/10 iters), loss = 7.47861
I0524 00:54:31.235178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.47861 (* 1 = 7.47861 loss)
I0524 00:54:31.235648 11654 sgd_solver.cpp:112] Iteration 14730, lr = 0.1
I0524 00:54:39.276988 11654 solver.cpp:239] Iteration 14740 (1.24355 iter/s, 8.04151s/10 iters), loss = 7.3701
I0524 00:54:39.277101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3701 (* 1 = 7.3701 loss)
I0524 00:54:39.278925 11654 sgd_solver.cpp:112] Iteration 14740, lr = 0.1
I0524 00:54:45.923197 11654 solver.cpp:239] Iteration 14750 (1.5047 iter/s, 6.64585s/10 iters), loss = 7.3185
I0524 00:54:45.923236 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3185 (* 1 = 7.3185 loss)
I0524 00:54:45.923266 11654 sgd_solver.cpp:112] Iteration 14750, lr = 0.1
I0524 00:54:52.712354 11654 solver.cpp:239] Iteration 14760 (1.47303 iter/s, 6.78874s/10 iters), loss = 8.47943
I0524 00:54:52.712411 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.47943 (* 1 = 8.47943 loss)
I0524 00:54:52.800927 11654 sgd_solver.cpp:112] Iteration 14760, lr = 0.1
I0524 00:54:59.388031 11654 solver.cpp:239] Iteration 14770 (1.49804 iter/s, 6.67538s/10 iters), loss = 8.16182
I0524 00:54:59.388074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.16182 (* 1 = 8.16182 loss)
I0524 00:54:59.390821 11654 sgd_solver.cpp:112] Iteration 14770, lr = 0.1
I0524 00:55:06.072080 11654 solver.cpp:239] Iteration 14780 (1.49617 iter/s, 6.68375s/10 iters), loss = 7.43598
I0524 00:55:06.072130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43598 (* 1 = 7.43598 loss)
I0524 00:55:06.072340 11654 sgd_solver.cpp:112] Iteration 14780, lr = 0.1
I0524 00:55:13.783077 11654 solver.cpp:239] Iteration 14790 (1.29691 iter/s, 7.71065s/10 iters), loss = 8.83656
I0524 00:55:13.783402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.83656 (* 1 = 8.83656 loss)
I0524 00:55:13.783550 11654 sgd_solver.cpp:112] Iteration 14790, lr = 0.1
I0524 00:55:21.533586 11654 solver.cpp:239] Iteration 14800 (1.29033 iter/s, 7.74996s/10 iters), loss = 7.88552
I0524 00:55:21.533641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.88552 (* 1 = 7.88552 loss)
I0524 00:55:21.534106 11654 sgd_solver.cpp:112] Iteration 14800, lr = 0.1
I0524 00:55:27.927680 11654 solver.cpp:239] Iteration 14810 (1.56401 iter/s, 6.3938s/10 iters), loss = 7.97824
I0524 00:55:27.927718 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.97824 (* 1 = 7.97824 loss)
I0524 00:55:27.927860 11654 sgd_solver.cpp:112] Iteration 14810, lr = 0.1
I0524 00:55:34.279806 11654 solver.cpp:239] Iteration 14820 (1.57435 iter/s, 6.35183s/10 iters), loss = 8.31582
I0524 00:55:34.279876 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.31582 (* 1 = 8.31582 loss)
I0524 00:55:34.279893 11654 sgd_solver.cpp:112] Iteration 14820, lr = 0.1
I0524 00:55:41.164487 11654 solver.cpp:239] Iteration 14830 (1.45258 iter/s, 6.88428s/10 iters), loss = 7.90758
I0524 00:55:41.164548 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90758 (* 1 = 7.90758 loss)
I0524 00:55:41.164860 11654 sgd_solver.cpp:112] Iteration 14830, lr = 0.1
I0524 00:55:47.206110 11654 solver.cpp:239] Iteration 14840 (1.65526 iter/s, 6.04133s/10 iters), loss = 7.8475
I0524 00:55:47.206347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8475 (* 1 = 7.8475 loss)
I0524 00:55:47.206404 11654 sgd_solver.cpp:112] Iteration 14840, lr = 0.1
I0524 00:55:56.353516 11654 solver.cpp:239] Iteration 14850 (1.09327 iter/s, 9.14684s/10 iters), loss = 7.24937
I0524 00:55:56.353574 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24937 (* 1 = 7.24937 loss)
I0524 00:55:56.353763 11654 sgd_solver.cpp:112] Iteration 14850, lr = 0.1
I0524 00:56:04.631218 11654 solver.cpp:239] Iteration 14860 (1.20812 iter/s, 8.27733s/10 iters), loss = 7.21616
I0524 00:56:04.631281 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21616 (* 1 = 7.21616 loss)
I0524 00:56:04.631438 11654 sgd_solver.cpp:112] Iteration 14860, lr = 0.1
I0524 00:56:12.596581 11654 solver.cpp:239] Iteration 14870 (1.25549 iter/s, 7.96501s/10 iters), loss = 7.40756
I0524 00:56:12.596622 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40756 (* 1 = 7.40756 loss)
I0524 00:56:14.487902 11654 sgd_solver.cpp:112] Iteration 14870, lr = 0.1
I0524 00:56:20.626037 11654 solver.cpp:239] Iteration 14880 (1.24547 iter/s, 8.02909s/10 iters), loss = 7.31319
I0524 00:56:20.626178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31319 (* 1 = 7.31319 loss)
I0524 00:56:20.626194 11654 sgd_solver.cpp:112] Iteration 14880, lr = 0.1
I0524 00:56:27.180284 11654 solver.cpp:239] Iteration 14890 (1.52583 iter/s, 6.55383s/10 iters), loss = 7.48435
I0524 00:56:27.180336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48435 (* 1 = 7.48435 loss)
I0524 00:56:27.180353 11654 sgd_solver.cpp:112] Iteration 14890, lr = 0.1
I0524 00:56:36.116665 11654 solver.cpp:239] Iteration 14900 (1.11907 iter/s, 8.93598s/10 iters), loss = 7.19904
I0524 00:56:36.116760 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19904 (* 1 = 7.19904 loss)
I0524 00:56:36.116796 11654 sgd_solver.cpp:112] Iteration 14900, lr = 0.1
I0524 00:56:42.794548 11654 solver.cpp:239] Iteration 14910 (1.49803 iter/s, 6.67543s/10 iters), loss = 8.00758
I0524 00:56:42.794600 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.00758 (* 1 = 8.00758 loss)
I0524 00:56:43.587676 11654 sgd_solver.cpp:112] Iteration 14910, lr = 0.1
I0524 00:56:51.177839 11654 solver.cpp:239] Iteration 14920 (1.1929 iter/s, 8.38293s/10 iters), loss = 8.40818
I0524 00:56:51.177989 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.40818 (* 1 = 8.40818 loss)
I0524 00:56:51.346369 11654 sgd_solver.cpp:112] Iteration 14920, lr = 0.1
I0524 00:56:59.005703 11654 solver.cpp:239] Iteration 14930 (1.27756 iter/s, 7.82742s/10 iters), loss = 7.48979
I0524 00:56:59.005759 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48979 (* 1 = 7.48979 loss)
I0524 00:56:59.312443 11654 sgd_solver.cpp:112] Iteration 14930, lr = 0.1
I0524 00:57:05.609318 11654 solver.cpp:239] Iteration 14940 (1.51439 iter/s, 6.60331s/10 iters), loss = 6.7422
I0524 00:57:05.609364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7422 (* 1 = 6.7422 loss)
I0524 00:57:05.609513 11654 sgd_solver.cpp:112] Iteration 14940, lr = 0.1
I0524 00:57:12.810359 11654 solver.cpp:239] Iteration 14950 (1.38875 iter/s, 7.20072s/10 iters), loss = 7.15612
I0524 00:57:12.810403 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15612 (* 1 = 7.15612 loss)
I0524 00:57:13.528053 11654 sgd_solver.cpp:112] Iteration 14950, lr = 0.1
I0524 00:57:19.861994 11654 solver.cpp:239] Iteration 14960 (1.41817 iter/s, 7.05132s/10 iters), loss = 6.72776
I0524 00:57:19.862048 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72776 (* 1 = 6.72776 loss)
I0524 00:57:19.862066 11654 sgd_solver.cpp:112] Iteration 14960, lr = 0.1
I0524 00:57:28.354848 11654 solver.cpp:239] Iteration 14970 (1.17757 iter/s, 8.4921s/10 iters), loss = 7.11578
I0524 00:57:28.355020 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11578 (* 1 = 7.11578 loss)
I0524 00:57:28.355065 11654 sgd_solver.cpp:112] Iteration 14970, lr = 0.1
I0524 00:57:35.700507 11654 solver.cpp:239] Iteration 14980 (1.36143 iter/s, 7.34521s/10 iters), loss = 7.03239
I0524 00:57:35.700563 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03239 (* 1 = 7.03239 loss)
I0524 00:57:35.700711 11654 sgd_solver.cpp:112] Iteration 14980, lr = 0.1
I0524 00:57:42.553756 11654 solver.cpp:239] Iteration 14990 (1.45923 iter/s, 6.85292s/10 iters), loss = 7.78031
I0524 00:57:42.553812 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78031 (* 1 = 7.78031 loss)
I0524 00:57:42.553858 11654 sgd_solver.cpp:112] Iteration 14990, lr = 0.1
I0524 00:57:48.531736 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_15000.caffemodel
I0524 00:57:49.890980 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_15000.solverstate
I0524 00:57:50.612360 11654 solver.cpp:239] Iteration 15000 (1.24096 iter/s, 8.05825s/10 iters), loss = 8.37617
I0524 00:57:50.612407 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.37617 (* 1 = 8.37617 loss)
I0524 00:57:50.612766 11654 sgd_solver.cpp:112] Iteration 15000, lr = 0.1
I0524 00:57:57.127267 11654 solver.cpp:239] Iteration 15010 (1.53501 iter/s, 6.51462s/10 iters), loss = 7.80095
I0524 00:57:57.127311 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.80095 (* 1 = 7.80095 loss)
I0524 00:57:58.055646 11654 sgd_solver.cpp:112] Iteration 15010, lr = 0.1
I0524 00:58:04.392403 11654 solver.cpp:239] Iteration 15020 (1.3765 iter/s, 7.2648s/10 iters), loss = 6.76702
I0524 00:58:04.392539 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76702 (* 1 = 6.76702 loss)
I0524 00:58:04.392717 11654 sgd_solver.cpp:112] Iteration 15020, lr = 0.1
I0524 00:58:12.581828 11654 solver.cpp:239] Iteration 15030 (1.22115 iter/s, 8.189s/10 iters), loss = 7.8254
I0524 00:58:12.581894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8254 (* 1 = 7.8254 loss)
I0524 00:58:12.582373 11654 sgd_solver.cpp:112] Iteration 15030, lr = 0.1
I0524 00:58:19.643929 11654 solver.cpp:239] Iteration 15040 (1.41607 iter/s, 7.06178s/10 iters), loss = 8.4088
I0524 00:58:19.643970 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.4088 (* 1 = 8.4088 loss)
I0524 00:58:20.180701 11654 sgd_solver.cpp:112] Iteration 15040, lr = 0.1
I0524 00:58:26.710382 11654 solver.cpp:239] Iteration 15050 (1.4152 iter/s, 7.06613s/10 iters), loss = 7.41575
I0524 00:58:26.710431 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.41575 (* 1 = 7.41575 loss)
I0524 00:58:27.366518 11654 sgd_solver.cpp:112] Iteration 15050, lr = 0.1
I0524 00:58:35.315239 11654 solver.cpp:239] Iteration 15060 (1.16218 iter/s, 8.60448s/10 iters), loss = 7.00531
I0524 00:58:35.315513 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00531 (* 1 = 7.00531 loss)
I0524 00:58:35.315573 11654 sgd_solver.cpp:112] Iteration 15060, lr = 0.1
I0524 00:58:42.023277 11654 solver.cpp:239] Iteration 15070 (1.49089 iter/s, 6.7074s/10 iters), loss = 7.18118
I0524 00:58:42.023336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18118 (* 1 = 7.18118 loss)
I0524 00:58:42.071305 11654 sgd_solver.cpp:112] Iteration 15070, lr = 0.1
I0524 00:58:48.790750 11654 solver.cpp:239] Iteration 15080 (1.47772 iter/s, 6.76717s/10 iters), loss = 7.65756
I0524 00:58:48.790791 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.65756 (* 1 = 7.65756 loss)
I0524 00:58:48.790808 11654 sgd_solver.cpp:112] Iteration 15080, lr = 0.1
I0524 00:58:56.995859 11654 solver.cpp:239] Iteration 15090 (1.21881 iter/s, 8.20475s/10 iters), loss = 8.22659
I0524 00:58:56.995908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.22659 (* 1 = 8.22659 loss)
I0524 00:58:57.494869 11654 sgd_solver.cpp:112] Iteration 15090, lr = 0.1
I0524 00:59:04.604429 11654 solver.cpp:239] Iteration 15100 (1.31437 iter/s, 7.60823s/10 iters), loss = 7.77024
I0524 00:59:04.604475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77024 (* 1 = 7.77024 loss)
I0524 00:59:04.604491 11654 sgd_solver.cpp:112] Iteration 15100, lr = 0.1
I0524 00:59:13.423755 11654 solver.cpp:239] Iteration 15110 (1.13392 iter/s, 8.81895s/10 iters), loss = 7.25368
I0524 00:59:13.423986 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25368 (* 1 = 7.25368 loss)
I0524 00:59:13.424037 11654 sgd_solver.cpp:112] Iteration 15110, lr = 0.1
I0524 00:59:21.041131 11654 solver.cpp:239] Iteration 15120 (1.31288 iter/s, 7.61686s/10 iters), loss = 8.28113
I0524 00:59:21.041182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.28113 (* 1 = 8.28113 loss)
I0524 00:59:21.746278 11654 sgd_solver.cpp:112] Iteration 15120, lr = 0.1
I0524 00:59:29.573575 11654 solver.cpp:239] Iteration 15130 (1.17205 iter/s, 8.53206s/10 iters), loss = 7.24283
I0524 00:59:29.573640 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24283 (* 1 = 7.24283 loss)
I0524 00:59:29.574084 11654 sgd_solver.cpp:112] Iteration 15130, lr = 0.1
I0524 00:59:36.498078 11654 solver.cpp:239] Iteration 15140 (1.44421 iter/s, 6.92418s/10 iters), loss = 8.03518
I0524 00:59:36.498128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.03518 (* 1 = 8.03518 loss)
I0524 00:59:36.498230 11654 sgd_solver.cpp:112] Iteration 15140, lr = 0.1
I0524 00:59:43.193277 11654 solver.cpp:239] Iteration 15150 (1.49368 iter/s, 6.69489s/10 iters), loss = 8.2011
I0524 00:59:43.193325 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.2011 (* 1 = 8.2011 loss)
I0524 00:59:43.193343 11654 sgd_solver.cpp:112] Iteration 15150, lr = 0.1
I0524 00:59:50.866674 11654 solver.cpp:239] Iteration 15160 (1.30326 iter/s, 7.67306s/10 iters), loss = 7.85763
I0524 00:59:50.867007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85763 (* 1 = 7.85763 loss)
I0524 00:59:50.867058 11654 sgd_solver.cpp:112] Iteration 15160, lr = 0.1
I0524 00:59:57.748272 11654 solver.cpp:239] Iteration 15170 (1.45367 iter/s, 6.87912s/10 iters), loss = 7.75385
I0524 00:59:57.748327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.75385 (* 1 = 7.75385 loss)
I0524 00:59:57.748533 11654 sgd_solver.cpp:112] Iteration 15170, lr = 0.1
I0524 01:00:04.503810 11654 solver.cpp:239] Iteration 15180 (1.48033 iter/s, 6.75523s/10 iters), loss = 8.12111
I0524 01:00:04.503865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.12111 (* 1 = 8.12111 loss)
I0524 01:00:04.503880 11654 sgd_solver.cpp:112] Iteration 15180, lr = 0.1
I0524 01:00:12.351918 11654 solver.cpp:239] Iteration 15190 (1.27426 iter/s, 7.8477s/10 iters), loss = 8.30374
I0524 01:00:12.351960 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.30374 (* 1 = 8.30374 loss)
I0524 01:00:12.648563 11654 sgd_solver.cpp:112] Iteration 15190, lr = 0.1
I0524 01:00:21.754303 11654 solver.cpp:239] Iteration 15200 (1.06361 iter/s, 9.40198s/10 iters), loss = 7.44367
I0524 01:00:21.754571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44367 (* 1 = 7.44367 loss)
I0524 01:00:21.754629 11654 sgd_solver.cpp:112] Iteration 15200, lr = 0.1
I0524 01:00:28.434324 11654 solver.cpp:239] Iteration 15210 (1.49712 iter/s, 6.67951s/10 iters), loss = 6.87966
I0524 01:00:28.434362 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87966 (* 1 = 6.87966 loss)
I0524 01:00:28.434381 11654 sgd_solver.cpp:112] Iteration 15210, lr = 0.1
I0524 01:00:34.989231 11654 solver.cpp:239] Iteration 15220 (1.52564 iter/s, 6.55461s/10 iters), loss = 8.02839
I0524 01:00:34.989287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.02839 (* 1 = 8.02839 loss)
I0524 01:00:35.019026 11654 sgd_solver.cpp:112] Iteration 15220, lr = 0.1
I0524 01:00:41.978211 11654 solver.cpp:239] Iteration 15230 (1.43089 iter/s, 6.98866s/10 iters), loss = 7.56859
I0524 01:00:41.978276 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.56859 (* 1 = 7.56859 loss)
I0524 01:00:41.978415 11654 sgd_solver.cpp:112] Iteration 15230, lr = 0.1
I0524 01:00:49.250063 11654 solver.cpp:239] Iteration 15240 (1.37523 iter/s, 7.27152s/10 iters), loss = 6.73331
I0524 01:00:49.250099 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73331 (* 1 = 6.73331 loss)
I0524 01:00:49.284032 11654 sgd_solver.cpp:112] Iteration 15240, lr = 0.1
I0524 01:00:58.065040 11654 solver.cpp:239] Iteration 15250 (1.13448 iter/s, 8.81459s/10 iters), loss = 6.6725
I0524 01:00:58.065315 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6725 (* 1 = 6.6725 loss)
I0524 01:00:58.065371 11654 sgd_solver.cpp:112] Iteration 15250, lr = 0.1
I0524 01:01:05.744643 11654 solver.cpp:239] Iteration 15260 (1.30258 iter/s, 7.67705s/10 iters), loss = 6.6238
I0524 01:01:05.744690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6238 (* 1 = 6.6238 loss)
I0524 01:01:06.151131 11654 sgd_solver.cpp:112] Iteration 15260, lr = 0.1
I0524 01:01:12.552811 11654 solver.cpp:239] Iteration 15270 (1.46889 iter/s, 6.80787s/10 iters), loss = 7.03268
I0524 01:01:12.552848 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03268 (* 1 = 7.03268 loss)
I0524 01:01:12.817399 11654 sgd_solver.cpp:112] Iteration 15270, lr = 0.1
I0524 01:01:20.242826 11654 solver.cpp:239] Iteration 15280 (1.30044 iter/s, 7.68968s/10 iters), loss = 7.24848
I0524 01:01:20.242877 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24848 (* 1 = 7.24848 loss)
I0524 01:01:20.242892 11654 sgd_solver.cpp:112] Iteration 15280, lr = 0.1
I0524 01:01:28.925463 11654 solver.cpp:239] Iteration 15290 (1.15207 iter/s, 8.68005s/10 iters), loss = 7.14151
I0524 01:01:28.925720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14151 (* 1 = 7.14151 loss)
I0524 01:01:28.925778 11654 sgd_solver.cpp:112] Iteration 15290, lr = 0.1
I0524 01:01:36.513322 11654 solver.cpp:239] Iteration 15300 (1.31835 iter/s, 7.58526s/10 iters), loss = 6.89083
I0524 01:01:36.513378 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89083 (* 1 = 6.89083 loss)
I0524 01:01:36.513440 11654 sgd_solver.cpp:112] Iteration 15300, lr = 0.1
I0524 01:01:43.288831 11654 solver.cpp:239] Iteration 15310 (1.47597 iter/s, 6.7752s/10 iters), loss = 7.59082
I0524 01:01:43.288874 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59082 (* 1 = 7.59082 loss)
I0524 01:01:43.932618 11654 sgd_solver.cpp:112] Iteration 15310, lr = 0.1
I0524 01:01:52.688470 11654 solver.cpp:239] Iteration 15320 (1.06392 iter/s, 9.39923s/10 iters), loss = 7.63318
I0524 01:01:52.688519 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63318 (* 1 = 7.63318 loss)
I0524 01:01:52.691489 11654 sgd_solver.cpp:112] Iteration 15320, lr = 0.1
I0524 01:01:59.779759 11654 solver.cpp:239] Iteration 15330 (1.41024 iter/s, 7.09097s/10 iters), loss = 7.59747
I0524 01:01:59.780053 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59747 (* 1 = 7.59747 loss)
I0524 01:01:59.780112 11654 sgd_solver.cpp:112] Iteration 15330, lr = 0.1
I0524 01:02:07.925158 11654 solver.cpp:239] Iteration 15340 (1.22777 iter/s, 8.14483s/10 iters), loss = 8.32896
I0524 01:02:07.925207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.32896 (* 1 = 8.32896 loss)
I0524 01:02:08.142249 11654 sgd_solver.cpp:112] Iteration 15340, lr = 0.1
I0524 01:02:15.334148 11654 solver.cpp:239] Iteration 15350 (1.34977 iter/s, 7.40866s/10 iters), loss = 7.15238
I0524 01:02:15.334195 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15238 (* 1 = 7.15238 loss)
I0524 01:02:15.334214 11654 sgd_solver.cpp:112] Iteration 15350, lr = 0.1
I0524 01:02:23.000032 11654 solver.cpp:239] Iteration 15360 (1.30492 iter/s, 7.66333s/10 iters), loss = 7.76814
I0524 01:02:23.000072 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76814 (* 1 = 7.76814 loss)
I0524 01:02:23.000087 11654 sgd_solver.cpp:112] Iteration 15360, lr = 0.1
I0524 01:02:30.548017 11654 solver.cpp:239] Iteration 15370 (1.32491 iter/s, 7.54766s/10 iters), loss = 7.39985
I0524 01:02:30.548154 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39985 (* 1 = 7.39985 loss)
I0524 01:02:30.745154 11654 sgd_solver.cpp:112] Iteration 15370, lr = 0.1
I0524 01:02:37.465627 11654 solver.cpp:239] Iteration 15380 (1.44567 iter/s, 6.91722s/10 iters), loss = 7.84782
I0524 01:02:37.465667 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.84782 (* 1 = 7.84782 loss)
I0524 01:02:37.465680 11654 sgd_solver.cpp:112] Iteration 15380, lr = 0.1
I0524 01:02:44.107462 11654 solver.cpp:239] Iteration 15390 (1.50568 iter/s, 6.64153s/10 iters), loss = 7.83306
I0524 01:02:44.107527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.83306 (* 1 = 7.83306 loss)
I0524 01:02:44.107550 11654 sgd_solver.cpp:112] Iteration 15390, lr = 0.1
I0524 01:02:53.593055 11654 solver.cpp:239] Iteration 15400 (1.05438 iter/s, 9.48423s/10 iters), loss = 8.67673
I0524 01:02:53.593107 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.67673 (* 1 = 8.67673 loss)
I0524 01:02:53.593123 11654 sgd_solver.cpp:112] Iteration 15400, lr = 0.1
I0524 01:03:01.729171 11654 solver.cpp:239] Iteration 15410 (1.22948 iter/s, 8.13353s/10 iters), loss = 7.04012
I0524 01:03:01.729437 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04012 (* 1 = 7.04012 loss)
I0524 01:03:01.729642 11654 sgd_solver.cpp:112] Iteration 15410, lr = 0.1
I0524 01:03:07.871901 11654 solver.cpp:239] Iteration 15420 (1.62807 iter/s, 6.14226s/10 iters), loss = 7.04108
I0524 01:03:07.871954 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04108 (* 1 = 7.04108 loss)
I0524 01:03:08.251251 11654 sgd_solver.cpp:112] Iteration 15420, lr = 0.1
I0524 01:03:15.709461 11654 solver.cpp:239] Iteration 15430 (1.27596 iter/s, 7.83721s/10 iters), loss = 7.3366
I0524 01:03:15.709522 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3366 (* 1 = 7.3366 loss)
I0524 01:03:15.709643 11654 sgd_solver.cpp:112] Iteration 15430, lr = 0.1
I0524 01:03:23.743572 11654 solver.cpp:239] Iteration 15440 (1.24475 iter/s, 8.03376s/10 iters), loss = 7.6803
I0524 01:03:23.743613 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.6803 (* 1 = 7.6803 loss)
I0524 01:03:23.743798 11654 sgd_solver.cpp:112] Iteration 15440, lr = 0.1
I0524 01:03:31.159812 11654 solver.cpp:239] Iteration 15450 (1.34845 iter/s, 7.41591s/10 iters), loss = 7.3044
I0524 01:03:31.159876 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3044 (* 1 = 7.3044 loss)
I0524 01:03:31.159894 11654 sgd_solver.cpp:112] Iteration 15450, lr = 0.1
I0524 01:03:37.797891 11654 solver.cpp:239] Iteration 15460 (1.50653 iter/s, 6.63777s/10 iters), loss = 7.3232
I0524 01:03:37.798112 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3232 (* 1 = 7.3232 loss)
I0524 01:03:38.194223 11654 sgd_solver.cpp:112] Iteration 15460, lr = 0.1
I0524 01:03:46.087641 11654 solver.cpp:239] Iteration 15470 (1.20638 iter/s, 8.28923s/10 iters), loss = 7.63153
I0524 01:03:46.087700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63153 (* 1 = 7.63153 loss)
I0524 01:03:46.087786 11654 sgd_solver.cpp:112] Iteration 15470, lr = 0.1
I0524 01:03:54.271920 11654 solver.cpp:239] Iteration 15480 (1.22191 iter/s, 8.18391s/10 iters), loss = 7.55868
I0524 01:03:54.271975 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.55868 (* 1 = 7.55868 loss)
I0524 01:03:54.492236 11654 sgd_solver.cpp:112] Iteration 15480, lr = 0.1
I0524 01:04:01.844378 11654 solver.cpp:239] Iteration 15490 (1.32063 iter/s, 7.57212s/10 iters), loss = 7.72975
I0524 01:04:01.844429 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.72975 (* 1 = 7.72975 loss)
I0524 01:04:01.844444 11654 sgd_solver.cpp:112] Iteration 15490, lr = 0.1
I0524 01:04:08.209188 11654 solver.cpp:239] Iteration 15500 (1.57121 iter/s, 6.36452s/10 iters), loss = 8.50552
I0524 01:04:08.209450 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.50552 (* 1 = 8.50552 loss)
I0524 01:04:08.232421 11654 sgd_solver.cpp:112] Iteration 15500, lr = 0.1
I0524 01:04:15.833840 11654 solver.cpp:239] Iteration 15510 (1.31162 iter/s, 7.62416s/10 iters), loss = 7.08173
I0524 01:04:15.833883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08173 (* 1 = 7.08173 loss)
I0524 01:04:15.992256 11654 sgd_solver.cpp:112] Iteration 15510, lr = 0.1
I0524 01:04:22.201926 11654 solver.cpp:239] Iteration 15520 (1.5704 iter/s, 6.36779s/10 iters), loss = 7.30677
I0524 01:04:22.201982 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30677 (* 1 = 7.30677 loss)
I0524 01:04:22.202107 11654 sgd_solver.cpp:112] Iteration 15520, lr = 0.1
I0524 01:04:31.632982 11654 solver.cpp:239] Iteration 15530 (1.06037 iter/s, 9.43065s/10 iters), loss = 8.25544
I0524 01:04:31.633033 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.25544 (* 1 = 8.25544 loss)
I0524 01:04:31.633050 11654 sgd_solver.cpp:112] Iteration 15530, lr = 0.1
I0524 01:04:39.365523 11654 solver.cpp:239] Iteration 15540 (1.29329 iter/s, 7.7322s/10 iters), loss = 8.23421
I0524 01:04:39.365603 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.23421 (* 1 = 8.23421 loss)
I0524 01:04:39.648960 11654 sgd_solver.cpp:112] Iteration 15540, lr = 0.1
I0524 01:04:46.109115 11654 solver.cpp:239] Iteration 15550 (1.48296 iter/s, 6.74325s/10 iters), loss = 6.18894
I0524 01:04:46.109175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18894 (* 1 = 6.18894 loss)
I0524 01:04:46.109195 11654 sgd_solver.cpp:112] Iteration 15550, lr = 0.1
I0524 01:04:53.182844 11654 solver.cpp:239] Iteration 15560 (1.41376 iter/s, 7.07335s/10 iters), loss = 7.87562
I0524 01:04:53.182883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87562 (* 1 = 7.87562 loss)
I0524 01:04:53.182898 11654 sgd_solver.cpp:112] Iteration 15560, lr = 0.1
I0524 01:05:01.458060 11654 solver.cpp:239] Iteration 15570 (1.20848 iter/s, 8.27485s/10 iters), loss = 6.6957
I0524 01:05:01.458113 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6957 (* 1 = 6.6957 loss)
I0524 01:05:01.459583 11654 sgd_solver.cpp:112] Iteration 15570, lr = 0.1
I0524 01:05:08.389204 11654 solver.cpp:239] Iteration 15580 (1.44283 iter/s, 6.93082s/10 iters), loss = 6.45605
I0524 01:05:08.389263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45605 (* 1 = 6.45605 loss)
I0524 01:05:08.389386 11654 sgd_solver.cpp:112] Iteration 15580, lr = 0.1
I0524 01:05:15.671561 11654 solver.cpp:239] Iteration 15590 (1.37324 iter/s, 7.28202s/10 iters), loss = 7.66377
I0524 01:05:15.671823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66377 (* 1 = 7.66377 loss)
I0524 01:05:15.671864 11654 sgd_solver.cpp:112] Iteration 15590, lr = 0.1
I0524 01:05:22.107661 11654 solver.cpp:239] Iteration 15600 (1.55386 iter/s, 6.43559s/10 iters), loss = 6.98316
I0524 01:05:22.107709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98316 (* 1 = 6.98316 loss)
I0524 01:05:22.107725 11654 sgd_solver.cpp:112] Iteration 15600, lr = 0.1
I0524 01:05:28.530858 11654 solver.cpp:239] Iteration 15610 (1.55693 iter/s, 6.4229s/10 iters), loss = 6.83936
I0524 01:05:28.530906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83936 (* 1 = 6.83936 loss)
I0524 01:05:28.531241 11654 sgd_solver.cpp:112] Iteration 15610, lr = 0.1
I0524 01:05:35.802497 11654 solver.cpp:239] Iteration 15620 (1.37527 iter/s, 7.27131s/10 iters), loss = 7.33872
I0524 01:05:35.802547 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33872 (* 1 = 7.33872 loss)
I0524 01:05:35.802563 11654 sgd_solver.cpp:112] Iteration 15620, lr = 0.1
I0524 01:05:42.875509 11654 solver.cpp:239] Iteration 15630 (1.41433 iter/s, 7.07048s/10 iters), loss = 6.45367
I0524 01:05:42.875548 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45367 (* 1 = 6.45367 loss)
I0524 01:05:42.877629 11654 sgd_solver.cpp:112] Iteration 15630, lr = 0.1
I0524 01:05:49.157778 11654 solver.cpp:239] Iteration 15640 (1.59186 iter/s, 6.28197s/10 iters), loss = 7.02692
I0524 01:05:49.157887 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02692 (* 1 = 7.02692 loss)
I0524 01:05:49.158164 11654 sgd_solver.cpp:112] Iteration 15640, lr = 0.1
I0524 01:05:55.156479 11654 solver.cpp:239] Iteration 15650 (1.66712 iter/s, 5.99837s/10 iters), loss = 6.64042
I0524 01:05:55.156524 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64042 (* 1 = 6.64042 loss)
I0524 01:05:55.186779 11654 sgd_solver.cpp:112] Iteration 15650, lr = 0.1
I0524 01:06:02.225046 11654 solver.cpp:239] Iteration 15660 (1.41478 iter/s, 7.06824s/10 iters), loss = 6.4424
I0524 01:06:02.225098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4424 (* 1 = 6.4424 loss)
I0524 01:06:02.618854 11654 sgd_solver.cpp:112] Iteration 15660, lr = 0.1
I0524 01:06:09.834682 11654 solver.cpp:239] Iteration 15670 (1.31418 iter/s, 7.60929s/10 iters), loss = 8.31823
I0524 01:06:09.834753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.31823 (* 1 = 8.31823 loss)
I0524 01:06:10.584892 11654 sgd_solver.cpp:112] Iteration 15670, lr = 0.1
I0524 01:06:17.552404 11654 solver.cpp:239] Iteration 15680 (1.29578 iter/s, 7.71736s/10 iters), loss = 6.73007
I0524 01:06:17.552453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73007 (* 1 = 6.73007 loss)
I0524 01:06:17.552485 11654 sgd_solver.cpp:112] Iteration 15680, lr = 0.1
I0524 01:06:24.106819 11654 solver.cpp:239] Iteration 15690 (1.52576 iter/s, 6.55411s/10 iters), loss = 8.97199
I0524 01:06:24.107039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.97199 (* 1 = 8.97199 loss)
I0524 01:06:24.107092 11654 sgd_solver.cpp:112] Iteration 15690, lr = 0.1
I0524 01:06:31.820988 11654 solver.cpp:239] Iteration 15700 (1.29644 iter/s, 7.71346s/10 iters), loss = 7.69164
I0524 01:06:31.821036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69164 (* 1 = 7.69164 loss)
I0524 01:06:31.838919 11654 sgd_solver.cpp:112] Iteration 15700, lr = 0.1
I0524 01:06:39.548980 11654 solver.cpp:239] Iteration 15710 (1.29406 iter/s, 7.72764s/10 iters), loss = 8.30014
I0524 01:06:39.549060 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.30014 (* 1 = 8.30014 loss)
I0524 01:06:39.549083 11654 sgd_solver.cpp:112] Iteration 15710, lr = 0.1
I0524 01:06:45.971885 11654 solver.cpp:239] Iteration 15720 (1.55701 iter/s, 6.42256s/10 iters), loss = 7.46444
I0524 01:06:45.971926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.46444 (* 1 = 7.46444 loss)
I0524 01:06:46.232210 11654 sgd_solver.cpp:112] Iteration 15720, lr = 0.1
I0524 01:06:54.932242 11654 solver.cpp:239] Iteration 15730 (1.11608 iter/s, 8.95997s/10 iters), loss = 6.99412
I0524 01:06:54.932535 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99412 (* 1 = 6.99412 loss)
I0524 01:06:54.949643 11654 sgd_solver.cpp:112] Iteration 15730, lr = 0.1
I0524 01:07:01.434567 11654 solver.cpp:239] Iteration 15740 (1.53802 iter/s, 6.50185s/10 iters), loss = 8.35371
I0524 01:07:01.434620 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.35371 (* 1 = 8.35371 loss)
I0524 01:07:01.434636 11654 sgd_solver.cpp:112] Iteration 15740, lr = 0.1
I0524 01:07:09.876503 11654 solver.cpp:239] Iteration 15750 (1.1847 iter/s, 8.44093s/10 iters), loss = 7.44854
I0524 01:07:09.876557 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44854 (* 1 = 7.44854 loss)
I0524 01:07:09.876588 11654 sgd_solver.cpp:112] Iteration 15750, lr = 0.1
I0524 01:07:16.385646 11654 solver.cpp:239] Iteration 15760 (1.53688 iter/s, 6.50669s/10 iters), loss = 6.8002
I0524 01:07:16.385695 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8002 (* 1 = 6.8002 loss)
I0524 01:07:16.386065 11654 sgd_solver.cpp:112] Iteration 15760, lr = 0.1
I0524 01:07:22.939982 11654 solver.cpp:239] Iteration 15770 (1.5258 iter/s, 6.55395s/10 iters), loss = 8.5133
I0524 01:07:22.940088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.5133 (* 1 = 8.5133 loss)
I0524 01:07:22.941913 11654 sgd_solver.cpp:112] Iteration 15770, lr = 0.1
I0524 01:07:29.922976 11654 solver.cpp:239] Iteration 15780 (1.43212 iter/s, 6.98264s/10 iters), loss = 8.25582
I0524 01:07:29.923283 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.25582 (* 1 = 8.25582 loss)
I0524 01:07:29.923365 11654 sgd_solver.cpp:112] Iteration 15780, lr = 0.1
I0524 01:07:36.971405 11654 solver.cpp:239] Iteration 15790 (1.41886 iter/s, 7.04791s/10 iters), loss = 6.85897
I0524 01:07:36.971477 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85897 (* 1 = 6.85897 loss)
I0524 01:07:36.971599 11654 sgd_solver.cpp:112] Iteration 15790, lr = 0.1
I0524 01:07:43.361125 11654 solver.cpp:239] Iteration 15800 (1.56509 iter/s, 6.38942s/10 iters), loss = 6.21442
I0524 01:07:43.361183 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21442 (* 1 = 6.21442 loss)
I0524 01:07:43.361397 11654 sgd_solver.cpp:112] Iteration 15800, lr = 0.1
I0524 01:07:51.627823 11654 solver.cpp:239] Iteration 15810 (1.20973 iter/s, 8.26633s/10 iters), loss = 7.39549
I0524 01:07:51.627879 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39549 (* 1 = 7.39549 loss)
I0524 01:07:51.627897 11654 sgd_solver.cpp:112] Iteration 15810, lr = 0.1
I0524 01:07:58.588136 11654 solver.cpp:239] Iteration 15820 (1.43679 iter/s, 6.95994s/10 iters), loss = 7.43545
I0524 01:07:58.588176 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43545 (* 1 = 7.43545 loss)
I0524 01:07:58.588745 11654 sgd_solver.cpp:112] Iteration 15820, lr = 0.1
I0524 01:08:05.489933 11654 solver.cpp:239] Iteration 15830 (1.44896 iter/s, 6.90149s/10 iters), loss = 7.40008
I0524 01:08:05.490075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40008 (* 1 = 7.40008 loss)
I0524 01:08:05.490095 11654 sgd_solver.cpp:112] Iteration 15830, lr = 0.1
I0524 01:08:13.517068 11654 solver.cpp:239] Iteration 15840 (1.24586 iter/s, 8.02661s/10 iters), loss = 6.57575
I0524 01:08:13.517120 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57575 (* 1 = 6.57575 loss)
I0524 01:08:13.943507 11654 sgd_solver.cpp:112] Iteration 15840, lr = 0.1
I0524 01:08:20.167752 11654 solver.cpp:239] Iteration 15850 (1.50367 iter/s, 6.65038s/10 iters), loss = 7.51449
I0524 01:08:20.167793 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51449 (* 1 = 7.51449 loss)
I0524 01:08:20.167805 11654 sgd_solver.cpp:112] Iteration 15850, lr = 0.1
I0524 01:08:27.788080 11654 solver.cpp:239] Iteration 15860 (1.31237 iter/s, 7.6198s/10 iters), loss = 7.13702
I0524 01:08:27.788132 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13702 (* 1 = 7.13702 loss)
I0524 01:08:27.788149 11654 sgd_solver.cpp:112] Iteration 15860, lr = 0.1
I0524 01:08:34.201612 11654 solver.cpp:239] Iteration 15870 (1.55931 iter/s, 6.4131s/10 iters), loss = 7.41466
I0524 01:08:34.201663 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.41466 (* 1 = 7.41466 loss)
I0524 01:08:34.201983 11654 sgd_solver.cpp:112] Iteration 15870, lr = 0.1
I0524 01:08:40.425289 11654 solver.cpp:239] Iteration 15880 (1.60685 iter/s, 6.22338s/10 iters), loss = 7.52839
I0524 01:08:40.425482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.52839 (* 1 = 7.52839 loss)
I0524 01:08:40.425860 11654 sgd_solver.cpp:112] Iteration 15880, lr = 0.1
I0524 01:08:50.010058 11654 solver.cpp:239] Iteration 15890 (1.04338 iter/s, 9.58422s/10 iters), loss = 7.61814
I0524 01:08:50.010107 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61814 (* 1 = 7.61814 loss)
I0524 01:08:51.195672 11654 sgd_solver.cpp:112] Iteration 15890, lr = 0.1
I0524 01:09:00.092285 11654 solver.cpp:239] Iteration 15900 (0.991887 iter/s, 10.0818s/10 iters), loss = 7.91729
I0524 01:09:00.092339 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91729 (* 1 = 7.91729 loss)
I0524 01:09:01.087272 11654 sgd_solver.cpp:112] Iteration 15900, lr = 0.1
I0524 01:09:08.223311 11654 solver.cpp:239] Iteration 15910 (1.22991 iter/s, 8.13067s/10 iters), loss = 7.06282
I0524 01:09:08.223357 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06282 (* 1 = 7.06282 loss)
I0524 01:09:08.223373 11654 sgd_solver.cpp:112] Iteration 15910, lr = 0.1
I0524 01:09:14.537513 11654 solver.cpp:239] Iteration 15920 (1.58381 iter/s, 6.31391s/10 iters), loss = 7.23446
I0524 01:09:14.537808 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23446 (* 1 = 7.23446 loss)
I0524 01:09:14.537873 11654 sgd_solver.cpp:112] Iteration 15920, lr = 0.1
I0524 01:09:21.223816 11654 solver.cpp:239] Iteration 15930 (1.49616 iter/s, 6.68378s/10 iters), loss = 6.10732
I0524 01:09:21.223858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10732 (* 1 = 6.10732 loss)
I0524 01:09:21.223897 11654 sgd_solver.cpp:112] Iteration 15930, lr = 0.1
I0524 01:09:29.268803 11654 solver.cpp:239] Iteration 15940 (1.24307 iter/s, 8.04462s/10 iters), loss = 6.93622
I0524 01:09:29.268872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93622 (* 1 = 6.93622 loss)
I0524 01:09:29.269467 11654 sgd_solver.cpp:112] Iteration 15940, lr = 0.1
I0524 01:09:37.332201 11654 solver.cpp:239] Iteration 15950 (1.24023 iter/s, 8.06303s/10 iters), loss = 7.25957
I0524 01:09:37.332242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25957 (* 1 = 7.25957 loss)
I0524 01:09:37.949684 11654 sgd_solver.cpp:112] Iteration 15950, lr = 0.1
I0524 01:09:44.472828 11654 solver.cpp:239] Iteration 15960 (1.4005 iter/s, 7.1403s/10 iters), loss = 7.51328
I0524 01:09:44.472885 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51328 (* 1 = 7.51328 loss)
I0524 01:09:44.473093 11654 sgd_solver.cpp:112] Iteration 15960, lr = 0.1
I0524 01:09:54.607270 11654 solver.cpp:239] Iteration 15970 (0.986778 iter/s, 10.134s/10 iters), loss = 7.02498
I0524 01:09:54.607556 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02498 (* 1 = 7.02498 loss)
I0524 01:09:54.607609 11654 sgd_solver.cpp:112] Iteration 15970, lr = 0.1
I0524 01:10:02.397652 11654 solver.cpp:239] Iteration 15980 (1.28378 iter/s, 7.78952s/10 iters), loss = 7.82657
I0524 01:10:02.397713 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.82657 (* 1 = 7.82657 loss)
I0524 01:10:02.634737 11654 sgd_solver.cpp:112] Iteration 15980, lr = 0.1
I0524 01:10:08.756641 11654 solver.cpp:239] Iteration 15990 (1.57265 iter/s, 6.35869s/10 iters), loss = 7.43669
I0524 01:10:08.756700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43669 (* 1 = 7.43669 loss)
I0524 01:10:08.757004 11654 sgd_solver.cpp:112] Iteration 15990, lr = 0.1
I0524 01:10:16.318567 11654 solver.cpp:239] Iteration 16000 (1.32247 iter/s, 7.56159s/10 iters), loss = 7.05378
I0524 01:10:16.318605 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05378 (* 1 = 7.05378 loss)
I0524 01:10:17.044986 11654 sgd_solver.cpp:112] Iteration 16000, lr = 0.1
I0524 01:10:23.276018 11654 solver.cpp:239] Iteration 16010 (1.43737 iter/s, 6.95714s/10 iters), loss = 7.7262
I0524 01:10:23.276070 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.7262 (* 1 = 7.7262 loss)
I0524 01:10:23.276245 11654 sgd_solver.cpp:112] Iteration 16010, lr = 0.1
I0524 01:10:30.500324 11654 solver.cpp:239] Iteration 16020 (1.38428 iter/s, 7.22398s/10 iters), loss = 6.60583
I0524 01:10:30.500504 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60583 (* 1 = 6.60583 loss)
I0524 01:10:30.855201 11654 sgd_solver.cpp:112] Iteration 16020, lr = 0.1
I0524 01:10:37.955189 11654 solver.cpp:239] Iteration 16030 (1.34149 iter/s, 7.45439s/10 iters), loss = 7.93892
I0524 01:10:37.955245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.93892 (* 1 = 7.93892 loss)
I0524 01:10:37.955261 11654 sgd_solver.cpp:112] Iteration 16030, lr = 0.1
I0524 01:10:44.172577 11654 solver.cpp:239] Iteration 16040 (1.60853 iter/s, 6.21686s/10 iters), loss = 6.67417
I0524 01:10:44.172626 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67417 (* 1 = 6.67417 loss)
I0524 01:10:44.636417 11654 sgd_solver.cpp:112] Iteration 16040, lr = 0.1
I0524 01:10:50.666083 11654 solver.cpp:239] Iteration 16050 (1.54007 iter/s, 6.49321s/10 iters), loss = 7.31402
I0524 01:10:50.666137 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31402 (* 1 = 7.31402 loss)
I0524 01:10:50.666250 11654 sgd_solver.cpp:112] Iteration 16050, lr = 0.1
I0524 01:10:58.223371 11654 solver.cpp:239] Iteration 16060 (1.32329 iter/s, 7.55695s/10 iters), loss = 7.92668
I0524 01:10:58.223413 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.92668 (* 1 = 7.92668 loss)
I0524 01:10:58.223426 11654 sgd_solver.cpp:112] Iteration 16060, lr = 0.1
I0524 01:11:04.458297 11654 solver.cpp:239] Iteration 16070 (1.60396 iter/s, 6.23456s/10 iters), loss = 7.34581
I0524 01:11:04.458569 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.34581 (* 1 = 7.34581 loss)
I0524 01:11:04.491045 11654 sgd_solver.cpp:112] Iteration 16070, lr = 0.1
I0524 01:11:11.186288 11654 solver.cpp:239] Iteration 16080 (1.48644 iter/s, 6.7275s/10 iters), loss = 7.09167
I0524 01:11:11.186359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09167 (* 1 = 7.09167 loss)
I0524 01:11:11.186383 11654 sgd_solver.cpp:112] Iteration 16080, lr = 0.1
I0524 01:11:18.592192 11654 solver.cpp:239] Iteration 16090 (1.35074 iter/s, 7.40337s/10 iters), loss = 6.05497
I0524 01:11:18.592234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05497 (* 1 = 6.05497 loss)
I0524 01:11:19.437425 11654 sgd_solver.cpp:112] Iteration 16090, lr = 0.1
I0524 01:11:27.527952 11654 solver.cpp:239] Iteration 16100 (1.11915 iter/s, 8.93537s/10 iters), loss = 8.12083
I0524 01:11:27.528002 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.12083 (* 1 = 8.12083 loss)
I0524 01:11:27.965519 11654 sgd_solver.cpp:112] Iteration 16100, lr = 0.1
I0524 01:11:37.005756 11654 solver.cpp:239] Iteration 16110 (1.05514 iter/s, 9.47739s/10 iters), loss = 7.66144
I0524 01:11:37.006023 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66144 (* 1 = 7.66144 loss)
I0524 01:11:37.006074 11654 sgd_solver.cpp:112] Iteration 16110, lr = 0.1
I0524 01:11:43.482064 11654 solver.cpp:239] Iteration 16120 (1.54422 iter/s, 6.47575s/10 iters), loss = 6.85841
I0524 01:11:43.482105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85841 (* 1 = 6.85841 loss)
I0524 01:11:43.512877 11654 sgd_solver.cpp:112] Iteration 16120, lr = 0.1
I0524 01:11:51.359330 11654 solver.cpp:239] Iteration 16130 (1.26953 iter/s, 7.87691s/10 iters), loss = 7.53958
I0524 01:11:51.359392 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.53958 (* 1 = 7.53958 loss)
I0524 01:11:51.359639 11654 sgd_solver.cpp:112] Iteration 16130, lr = 0.1
I0524 01:11:57.684466 11654 solver.cpp:239] Iteration 16140 (1.58107 iter/s, 6.32483s/10 iters), loss = 8.28265
I0524 01:11:57.684520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.28265 (* 1 = 8.28265 loss)
I0524 01:11:57.684608 11654 sgd_solver.cpp:112] Iteration 16140, lr = 0.1
I0524 01:12:03.993728 11654 solver.cpp:239] Iteration 16150 (1.58505 iter/s, 6.30896s/10 iters), loss = 7.41279
I0524 01:12:03.993793 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.41279 (* 1 = 7.41279 loss)
I0524 01:12:03.994208 11654 sgd_solver.cpp:112] Iteration 16150, lr = 0.1
I0524 01:12:12.065101 11654 solver.cpp:239] Iteration 16160 (1.239 iter/s, 8.071s/10 iters), loss = 6.78298
I0524 01:12:12.065299 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78298 (* 1 = 6.78298 loss)
I0524 01:12:12.065366 11654 sgd_solver.cpp:112] Iteration 16160, lr = 0.1
I0524 01:12:18.274394 11654 solver.cpp:239] Iteration 16170 (1.61115 iter/s, 6.20676s/10 iters), loss = 6.96271
I0524 01:12:18.274459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96271 (* 1 = 6.96271 loss)
I0524 01:12:18.452298 11654 sgd_solver.cpp:112] Iteration 16170, lr = 0.1
I0524 01:12:25.370615 11654 solver.cpp:239] Iteration 16180 (1.40927 iter/s, 7.09589s/10 iters), loss = 6.86756
I0524 01:12:25.370676 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86756 (* 1 = 6.86756 loss)
I0524 01:12:25.371083 11654 sgd_solver.cpp:112] Iteration 16180, lr = 0.1
I0524 01:12:31.942728 11654 solver.cpp:239] Iteration 16190 (1.52166 iter/s, 6.57179s/10 iters), loss = 7.69103
I0524 01:12:31.942768 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69103 (* 1 = 7.69103 loss)
I0524 01:12:31.942780 11654 sgd_solver.cpp:112] Iteration 16190, lr = 0.1
I0524 01:12:38.886957 11654 solver.cpp:239] Iteration 16200 (1.44024 iter/s, 6.94327s/10 iters), loss = 7.48739
I0524 01:12:38.887019 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48739 (* 1 = 7.48739 loss)
I0524 01:12:38.887418 11654 sgd_solver.cpp:112] Iteration 16200, lr = 0.1
I0524 01:12:45.754675 11654 solver.cpp:239] Iteration 16210 (1.45616 iter/s, 6.8674s/10 iters), loss = 8.37026
I0524 01:12:45.754948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.37026 (* 1 = 8.37026 loss)
I0524 01:12:45.754999 11654 sgd_solver.cpp:112] Iteration 16210, lr = 0.1
I0524 01:12:52.609153 11654 solver.cpp:239] Iteration 16220 (1.45901 iter/s, 6.85398s/10 iters), loss = 7.20098
I0524 01:12:52.609202 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20098 (* 1 = 7.20098 loss)
I0524 01:12:52.609371 11654 sgd_solver.cpp:112] Iteration 16220, lr = 0.1
I0524 01:12:59.623065 11654 solver.cpp:239] Iteration 16230 (1.42581 iter/s, 7.01357s/10 iters), loss = 6.25571
I0524 01:12:59.623126 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25571 (* 1 = 6.25571 loss)
I0524 01:12:59.623468 11654 sgd_solver.cpp:112] Iteration 16230, lr = 0.1
I0524 01:13:06.066318 11654 solver.cpp:239] Iteration 16240 (1.55208 iter/s, 6.44295s/10 iters), loss = 6.87193
I0524 01:13:06.066364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87193 (* 1 = 6.87193 loss)
I0524 01:13:06.066380 11654 sgd_solver.cpp:112] Iteration 16240, lr = 0.1
I0524 01:13:14.156282 11654 solver.cpp:239] Iteration 16250 (1.23616 iter/s, 8.08959s/10 iters), loss = 6.4961
I0524 01:13:14.156363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4961 (* 1 = 6.4961 loss)
I0524 01:13:14.157181 11654 sgd_solver.cpp:112] Iteration 16250, lr = 0.1
I0524 01:13:20.413272 11654 solver.cpp:239] Iteration 16260 (1.59829 iter/s, 6.25669s/10 iters), loss = 7.85376
I0524 01:13:20.413439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85376 (* 1 = 7.85376 loss)
I0524 01:13:20.413458 11654 sgd_solver.cpp:112] Iteration 16260, lr = 0.1
I0524 01:13:27.034250 11654 solver.cpp:239] Iteration 16270 (1.51045 iter/s, 6.62056s/10 iters), loss = 6.77721
I0524 01:13:27.034288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77721 (* 1 = 6.77721 loss)
I0524 01:13:27.034301 11654 sgd_solver.cpp:112] Iteration 16270, lr = 0.1
I0524 01:13:33.310055 11654 solver.cpp:239] Iteration 16280 (1.59405 iter/s, 6.27331s/10 iters), loss = 8.23283
I0524 01:13:33.310092 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.23283 (* 1 = 8.23283 loss)
I0524 01:13:33.310104 11654 sgd_solver.cpp:112] Iteration 16280, lr = 0.1
I0524 01:13:40.126317 11654 solver.cpp:239] Iteration 16290 (1.46715 iter/s, 6.81594s/10 iters), loss = 7.87659
I0524 01:13:40.126375 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87659 (* 1 = 7.87659 loss)
I0524 01:13:40.126562 11654 sgd_solver.cpp:112] Iteration 16290, lr = 0.1
I0524 01:13:47.225857 11654 solver.cpp:239] Iteration 16300 (1.40861 iter/s, 7.09922s/10 iters), loss = 7.37053
I0524 01:13:47.225906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.37053 (* 1 = 7.37053 loss)
I0524 01:13:47.225922 11654 sgd_solver.cpp:112] Iteration 16300, lr = 0.1
I0524 01:13:55.871651 11654 solver.cpp:239] Iteration 16310 (1.15679 iter/s, 8.6446s/10 iters), loss = 7.55196
I0524 01:13:55.871906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.55196 (* 1 = 7.55196 loss)
I0524 01:13:55.871966 11654 sgd_solver.cpp:112] Iteration 16310, lr = 0.1
I0524 01:14:02.568989 11654 solver.cpp:239] Iteration 16320 (1.49324 iter/s, 6.69685s/10 iters), loss = 7.31355
I0524 01:14:02.569039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31355 (* 1 = 7.31355 loss)
I0524 01:14:02.590837 11654 sgd_solver.cpp:112] Iteration 16320, lr = 0.1
I0524 01:14:08.916091 11654 solver.cpp:239] Iteration 16330 (1.5756 iter/s, 6.34681s/10 iters), loss = 7.29869
I0524 01:14:08.916147 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29869 (* 1 = 7.29869 loss)
I0524 01:14:08.916553 11654 sgd_solver.cpp:112] Iteration 16330, lr = 0.1
I0524 01:14:16.040236 11654 solver.cpp:239] Iteration 16340 (1.40374 iter/s, 7.12382s/10 iters), loss = 6.29455
I0524 01:14:16.040292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29455 (* 1 = 6.29455 loss)
I0524 01:14:16.040309 11654 sgd_solver.cpp:112] Iteration 16340, lr = 0.1
I0524 01:14:22.819052 11654 solver.cpp:239] Iteration 16350 (1.47573 iter/s, 6.7763s/10 iters), loss = 7.37664
I0524 01:14:22.819092 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.37664 (* 1 = 7.37664 loss)
I0524 01:14:22.826673 11654 sgd_solver.cpp:112] Iteration 16350, lr = 0.1
I0524 01:14:29.423907 11654 solver.cpp:239] Iteration 16360 (1.51411 iter/s, 6.60455s/10 iters), loss = 7.58935
I0524 01:14:29.424186 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58935 (* 1 = 7.58935 loss)
I0524 01:14:29.581269 11654 sgd_solver.cpp:112] Iteration 16360, lr = 0.1
I0524 01:14:36.891383 11654 solver.cpp:239] Iteration 16370 (1.33923 iter/s, 7.46697s/10 iters), loss = 7.30718
I0524 01:14:36.891444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30718 (* 1 = 7.30718 loss)
I0524 01:14:36.891468 11654 sgd_solver.cpp:112] Iteration 16370, lr = 0.1
I0524 01:14:44.153529 11654 solver.cpp:239] Iteration 16380 (1.37727 iter/s, 7.26072s/10 iters), loss = 7.59848
I0524 01:14:44.153565 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59848 (* 1 = 7.59848 loss)
I0524 01:14:44.153579 11654 sgd_solver.cpp:112] Iteration 16380, lr = 0.1
I0524 01:14:51.304076 11654 solver.cpp:239] Iteration 16390 (1.39855 iter/s, 7.15024s/10 iters), loss = 7.60767
I0524 01:14:51.304118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.60767 (* 1 = 7.60767 loss)
I0524 01:14:51.304134 11654 sgd_solver.cpp:112] Iteration 16390, lr = 0.1
I0524 01:14:58.118957 11654 solver.cpp:239] Iteration 16400 (1.46746 iter/s, 6.81449s/10 iters), loss = 7.039
I0524 01:14:58.119010 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.039 (* 1 = 7.039 loss)
I0524 01:14:58.119387 11654 sgd_solver.cpp:112] Iteration 16400, lr = 0.1
I0524 01:15:05.778793 11654 solver.cpp:239] Iteration 16410 (1.30557 iter/s, 7.65949s/10 iters), loss = 6.69442
I0524 01:15:05.779105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69442 (* 1 = 6.69442 loss)
I0524 01:15:06.083518 11654 sgd_solver.cpp:112] Iteration 16410, lr = 0.1
I0524 01:15:13.651140 11654 solver.cpp:239] Iteration 16420 (1.27036 iter/s, 7.87179s/10 iters), loss = 8.20552
I0524 01:15:13.651183 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.20552 (* 1 = 8.20552 loss)
I0524 01:15:13.651208 11654 sgd_solver.cpp:112] Iteration 16420, lr = 0.1
I0524 01:15:21.534113 11654 solver.cpp:239] Iteration 16430 (1.26861 iter/s, 7.88263s/10 iters), loss = 6.88042
I0524 01:15:21.534166 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88042 (* 1 = 6.88042 loss)
I0524 01:15:21.555919 11654 sgd_solver.cpp:112] Iteration 16430, lr = 0.1
I0524 01:15:28.080974 11654 solver.cpp:239] Iteration 16440 (1.52752 iter/s, 6.54655s/10 iters), loss = 6.81979
I0524 01:15:28.081030 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81979 (* 1 = 6.81979 loss)
I0524 01:15:28.081174 11654 sgd_solver.cpp:112] Iteration 16440, lr = 0.1
I0524 01:15:35.426689 11654 solver.cpp:239] Iteration 16450 (1.3614 iter/s, 7.34539s/10 iters), loss = 8.10775
I0524 01:15:35.426751 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.10775 (* 1 = 8.10775 loss)
I0524 01:15:35.426856 11654 sgd_solver.cpp:112] Iteration 16450, lr = 0.1
I0524 01:15:47.357033 11654 solver.cpp:239] Iteration 16460 (0.838235 iter/s, 11.9298s/10 iters), loss = 7.31564
I0524 01:15:47.357137 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31564 (* 1 = 7.31564 loss)
I0524 01:15:47.357156 11654 sgd_solver.cpp:112] Iteration 16460, lr = 0.1
I0524 01:15:54.712304 11654 solver.cpp:239] Iteration 16470 (1.35965 iter/s, 7.35485s/10 iters), loss = 7.20942
I0524 01:15:54.712369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20942 (* 1 = 7.20942 loss)
I0524 01:15:54.712388 11654 sgd_solver.cpp:112] Iteration 16470, lr = 0.1
I0524 01:16:03.019232 11654 solver.cpp:239] Iteration 16480 (1.20388 iter/s, 8.3065s/10 iters), loss = 7.12438
I0524 01:16:03.019295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12438 (* 1 = 7.12438 loss)
I0524 01:16:03.019889 11654 sgd_solver.cpp:112] Iteration 16480, lr = 0.1
I0524 01:16:09.991505 11654 solver.cpp:239] Iteration 16490 (1.43432 iter/s, 6.97194s/10 iters), loss = 7.43589
I0524 01:16:09.991562 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43589 (* 1 = 7.43589 loss)
I0524 01:16:09.992094 11654 sgd_solver.cpp:112] Iteration 16490, lr = 0.1
I0524 01:16:19.639672 11654 solver.cpp:239] Iteration 16500 (1.03651 iter/s, 9.64773s/10 iters), loss = 6.8105
I0524 01:16:19.640003 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8105 (* 1 = 6.8105 loss)
I0524 01:16:19.640194 11654 sgd_solver.cpp:112] Iteration 16500, lr = 0.1
I0524 01:16:28.151288 11654 solver.cpp:239] Iteration 16510 (1.17494 iter/s, 8.51108s/10 iters), loss = 7.54378
I0524 01:16:28.151340 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54378 (* 1 = 7.54378 loss)
I0524 01:16:28.671178 11654 sgd_solver.cpp:112] Iteration 16510, lr = 0.1
I0524 01:16:35.840346 11654 solver.cpp:239] Iteration 16520 (1.30061 iter/s, 7.68872s/10 iters), loss = 6.83086
I0524 01:16:35.840385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83086 (* 1 = 6.83086 loss)
I0524 01:16:35.840399 11654 sgd_solver.cpp:112] Iteration 16520, lr = 0.1
I0524 01:16:43.642647 11654 solver.cpp:239] Iteration 16530 (1.2821 iter/s, 7.79972s/10 iters), loss = 6.76992
I0524 01:16:43.642724 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76992 (* 1 = 6.76992 loss)
I0524 01:16:43.642742 11654 sgd_solver.cpp:112] Iteration 16530, lr = 0.1
I0524 01:16:50.510035 11654 solver.cpp:239] Iteration 16540 (1.45624 iter/s, 6.867s/10 iters), loss = 6.7814
I0524 01:16:50.510375 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7814 (* 1 = 6.7814 loss)
I0524 01:16:50.837641 11654 sgd_solver.cpp:112] Iteration 16540, lr = 0.1
I0524 01:16:58.265389 11654 solver.cpp:239] Iteration 16550 (1.28953 iter/s, 7.75478s/10 iters), loss = 7.00198
I0524 01:16:58.265429 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00198 (* 1 = 7.00198 loss)
I0524 01:16:58.328021 11654 sgd_solver.cpp:112] Iteration 16550, lr = 0.1
I0524 01:17:06.247963 11654 solver.cpp:239] Iteration 16560 (1.25278 iter/s, 7.98223s/10 iters), loss = 6.37628
I0524 01:17:06.248015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37628 (* 1 = 6.37628 loss)
I0524 01:17:06.248031 11654 sgd_solver.cpp:112] Iteration 16560, lr = 0.1
I0524 01:17:12.871654 11654 solver.cpp:239] Iteration 16570 (1.50982 iter/s, 6.62331s/10 iters), loss = 6.69845
I0524 01:17:12.871706 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69845 (* 1 = 6.69845 loss)
I0524 01:17:12.871721 11654 sgd_solver.cpp:112] Iteration 16570, lr = 0.1
I0524 01:17:22.675325 11654 solver.cpp:239] Iteration 16580 (1.02008 iter/s, 9.80319s/10 iters), loss = 7.68998
I0524 01:17:22.675554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.68998 (* 1 = 7.68998 loss)
I0524 01:17:22.677597 11654 sgd_solver.cpp:112] Iteration 16580, lr = 0.1
I0524 01:17:29.526051 11654 solver.cpp:239] Iteration 16590 (1.45979 iter/s, 6.85028s/10 iters), loss = 6.51753
I0524 01:17:29.526091 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51753 (* 1 = 6.51753 loss)
I0524 01:17:29.526104 11654 sgd_solver.cpp:112] Iteration 16590, lr = 0.1
I0524 01:17:36.294082 11654 solver.cpp:239] Iteration 16600 (1.47762 iter/s, 6.76764s/10 iters), loss = 6.58044
I0524 01:17:36.294142 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58044 (* 1 = 6.58044 loss)
I0524 01:17:37.091660 11654 sgd_solver.cpp:112] Iteration 16600, lr = 0.1
I0524 01:17:43.774338 11654 solver.cpp:239] Iteration 16610 (1.33691 iter/s, 7.47992s/10 iters), loss = 6.33865
I0524 01:17:43.774391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33865 (* 1 = 6.33865 loss)
I0524 01:17:43.776284 11654 sgd_solver.cpp:112] Iteration 16610, lr = 0.1
I0524 01:17:52.073559 11654 solver.cpp:239] Iteration 16620 (1.20499 iter/s, 8.29886s/10 iters), loss = 7.00423
I0524 01:17:52.073599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00423 (* 1 = 7.00423 loss)
I0524 01:17:52.073612 11654 sgd_solver.cpp:112] Iteration 16620, lr = 0.1
I0524 01:18:01.629137 11654 solver.cpp:239] Iteration 16630 (1.04655 iter/s, 9.55516s/10 iters), loss = 7.9648
I0524 01:18:01.629364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9648 (* 1 = 7.9648 loss)
I0524 01:18:01.950520 11654 sgd_solver.cpp:112] Iteration 16630, lr = 0.1
I0524 01:18:09.126847 11654 solver.cpp:239] Iteration 16640 (1.33382 iter/s, 7.49724s/10 iters), loss = 7.92642
I0524 01:18:09.126909 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.92642 (* 1 = 7.92642 loss)
I0524 01:18:09.134455 11654 sgd_solver.cpp:112] Iteration 16640, lr = 0.1
I0524 01:18:15.610225 11654 solver.cpp:239] Iteration 16650 (1.54248 iter/s, 6.48307s/10 iters), loss = 6.73985
I0524 01:18:15.610283 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73985 (* 1 = 6.73985 loss)
I0524 01:18:15.610302 11654 sgd_solver.cpp:112] Iteration 16650, lr = 0.1
I0524 01:18:23.754365 11654 solver.cpp:239] Iteration 16660 (1.2281 iter/s, 8.14269s/10 iters), loss = 6.17649
I0524 01:18:23.754407 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17649 (* 1 = 6.17649 loss)
I0524 01:18:23.762989 11654 sgd_solver.cpp:112] Iteration 16660, lr = 0.1
I0524 01:18:30.724851 11654 solver.cpp:239] Iteration 16670 (1.43469 iter/s, 6.97016s/10 iters), loss = 7.32271
I0524 01:18:30.724948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32271 (* 1 = 7.32271 loss)
I0524 01:18:31.877722 11654 sgd_solver.cpp:112] Iteration 16670, lr = 0.1
I0524 01:18:38.206535 11654 solver.cpp:239] Iteration 16680 (1.33666 iter/s, 7.48132s/10 iters), loss = 7.50211
I0524 01:18:38.206594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50211 (* 1 = 7.50211 loss)
I0524 01:18:38.609386 11654 sgd_solver.cpp:112] Iteration 16680, lr = 0.1
I0524 01:18:45.781956 11654 solver.cpp:239] Iteration 16690 (1.32012 iter/s, 7.57508s/10 iters), loss = 7.58907
I0524 01:18:45.781996 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58907 (* 1 = 7.58907 loss)
I0524 01:18:45.782191 11654 sgd_solver.cpp:112] Iteration 16690, lr = 0.1
I0524 01:18:51.976397 11654 solver.cpp:239] Iteration 16700 (1.61443 iter/s, 6.19415s/10 iters), loss = 7.11425
I0524 01:18:51.976456 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11425 (* 1 = 7.11425 loss)
I0524 01:18:51.976666 11654 sgd_solver.cpp:112] Iteration 16700, lr = 0.1
I0524 01:18:58.576460 11654 solver.cpp:239] Iteration 16710 (1.51521 iter/s, 6.59975s/10 iters), loss = 7.51233
I0524 01:18:58.576503 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51233 (* 1 = 7.51233 loss)
I0524 01:18:58.989544 11654 sgd_solver.cpp:112] Iteration 16710, lr = 0.1
I0524 01:19:05.161514 11654 solver.cpp:239] Iteration 16720 (1.51866 iter/s, 6.58475s/10 iters), loss = 5.95837
I0524 01:19:05.161681 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95837 (* 1 = 5.95837 loss)
I0524 01:19:05.161794 11654 sgd_solver.cpp:112] Iteration 16720, lr = 0.1
I0524 01:19:11.973677 11654 solver.cpp:239] Iteration 16730 (1.46806 iter/s, 6.81173s/10 iters), loss = 6.69274
I0524 01:19:11.973738 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69274 (* 1 = 6.69274 loss)
I0524 01:19:11.974221 11654 sgd_solver.cpp:112] Iteration 16730, lr = 0.1
I0524 01:19:18.934937 11654 solver.cpp:239] Iteration 16740 (1.43659 iter/s, 6.96094s/10 iters), loss = 6.87783
I0524 01:19:18.934978 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87783 (* 1 = 6.87783 loss)
I0524 01:19:18.936939 11654 sgd_solver.cpp:112] Iteration 16740, lr = 0.1
I0524 01:19:25.695888 11654 solver.cpp:239] Iteration 16750 (1.47915 iter/s, 6.76063s/10 iters), loss = 8.14628
I0524 01:19:25.695962 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.14628 (* 1 = 8.14628 loss)
I0524 01:19:25.695986 11654 sgd_solver.cpp:112] Iteration 16750, lr = 0.1
I0524 01:19:32.411219 11654 solver.cpp:239] Iteration 16760 (1.48929 iter/s, 6.71462s/10 iters), loss = 7.26384
I0524 01:19:32.411306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26384 (* 1 = 7.26384 loss)
I0524 01:19:32.411398 11654 sgd_solver.cpp:112] Iteration 16760, lr = 0.1
I0524 01:19:39.493187 11654 solver.cpp:239] Iteration 16770 (1.4121 iter/s, 7.08163s/10 iters), loss = 7.61569
I0524 01:19:39.493518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61569 (* 1 = 7.61569 loss)
I0524 01:19:39.885325 11654 sgd_solver.cpp:112] Iteration 16770, lr = 0.1
I0524 01:19:46.638164 11654 solver.cpp:239] Iteration 16780 (1.39968 iter/s, 7.14448s/10 iters), loss = 7.86258
I0524 01:19:46.638226 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86258 (* 1 = 7.86258 loss)
I0524 01:19:46.638243 11654 sgd_solver.cpp:112] Iteration 16780, lr = 0.1
I0524 01:19:52.775195 11654 solver.cpp:239] Iteration 16790 (1.63011 iter/s, 6.13455s/10 iters), loss = 7.19042
I0524 01:19:52.775277 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19042 (* 1 = 7.19042 loss)
I0524 01:19:54.473246 11654 sgd_solver.cpp:112] Iteration 16790, lr = 0.1
I0524 01:20:00.731222 11654 solver.cpp:239] Iteration 16800 (1.25697 iter/s, 7.95565s/10 iters), loss = 7.26657
I0524 01:20:00.731272 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26657 (* 1 = 7.26657 loss)
I0524 01:20:00.731652 11654 sgd_solver.cpp:112] Iteration 16800, lr = 0.1
I0524 01:20:08.804487 11654 solver.cpp:239] Iteration 16810 (1.23871 iter/s, 8.0729s/10 iters), loss = 7.4116
I0524 01:20:08.804540 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4116 (* 1 = 7.4116 loss)
I0524 01:20:08.925024 11654 sgd_solver.cpp:112] Iteration 16810, lr = 0.1
I0524 01:20:17.001000 11654 solver.cpp:239] Iteration 16820 (1.22009 iter/s, 8.19614s/10 iters), loss = 7.17443
I0524 01:20:17.001314 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17443 (* 1 = 7.17443 loss)
I0524 01:20:17.341743 11654 sgd_solver.cpp:112] Iteration 16820, lr = 0.1
I0524 01:20:24.818145 11654 solver.cpp:239] Iteration 16830 (1.27933 iter/s, 7.81658s/10 iters), loss = 6.3597
I0524 01:20:24.818199 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3597 (* 1 = 6.3597 loss)
I0524 01:20:25.294970 11654 sgd_solver.cpp:112] Iteration 16830, lr = 0.1
I0524 01:20:31.599468 11654 solver.cpp:239] Iteration 16840 (1.47471 iter/s, 6.781s/10 iters), loss = 7.02119
I0524 01:20:31.599527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02119 (* 1 = 7.02119 loss)
I0524 01:20:31.599544 11654 sgd_solver.cpp:112] Iteration 16840, lr = 0.1
I0524 01:20:38.486654 11654 solver.cpp:239] Iteration 16850 (1.45204 iter/s, 6.88686s/10 iters), loss = 7.19948
I0524 01:20:38.486742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19948 (* 1 = 7.19948 loss)
I0524 01:20:38.487040 11654 sgd_solver.cpp:112] Iteration 16850, lr = 0.1
I0524 01:20:45.152379 11654 solver.cpp:239] Iteration 16860 (1.50028 iter/s, 6.66541s/10 iters), loss = 7.40008
I0524 01:20:45.152423 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40008 (* 1 = 7.40008 loss)
I0524 01:20:45.152436 11654 sgd_solver.cpp:112] Iteration 16860, lr = 0.1
I0524 01:20:51.400414 11654 solver.cpp:239] Iteration 16870 (1.60058 iter/s, 6.24775s/10 iters), loss = 7.61667
I0524 01:20:51.400527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61667 (* 1 = 7.61667 loss)
I0524 01:20:51.400718 11654 sgd_solver.cpp:112] Iteration 16870, lr = 0.1
I0524 01:20:57.586613 11654 solver.cpp:239] Iteration 16880 (1.61659 iter/s, 6.18586s/10 iters), loss = 6.48542
I0524 01:20:57.586653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48542 (* 1 = 6.48542 loss)
I0524 01:20:57.586669 11654 sgd_solver.cpp:112] Iteration 16880, lr = 0.1
I0524 01:21:08.660974 11654 solver.cpp:239] Iteration 16890 (0.903031 iter/s, 11.0738s/10 iters), loss = 6.90555
I0524 01:21:08.661033 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90555 (* 1 = 6.90555 loss)
I0524 01:21:08.661484 11654 sgd_solver.cpp:112] Iteration 16890, lr = 0.1
I0524 01:21:18.071249 11654 solver.cpp:239] Iteration 16900 (1.06272 iter/s, 9.40986s/10 iters), loss = 7.0521
I0524 01:21:18.071301 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0521 (* 1 = 7.0521 loss)
I0524 01:21:18.071319 11654 sgd_solver.cpp:112] Iteration 16900, lr = 0.1
I0524 01:21:24.813840 11654 solver.cpp:239] Iteration 16910 (1.48367 iter/s, 6.74006s/10 iters), loss = 7.65943
I0524 01:21:24.813951 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.65943 (* 1 = 7.65943 loss)
I0524 01:21:24.814108 11654 sgd_solver.cpp:112] Iteration 16910, lr = 0.1
I0524 01:21:31.239233 11654 solver.cpp:239] Iteration 16920 (1.55642 iter/s, 6.42502s/10 iters), loss = 6.82918
I0524 01:21:31.239292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82918 (* 1 = 6.82918 loss)
I0524 01:21:31.243409 11654 sgd_solver.cpp:112] Iteration 16920, lr = 0.1
I0524 01:21:38.465739 11654 solver.cpp:239] Iteration 16930 (1.38386 iter/s, 7.22617s/10 iters), loss = 7.55476
I0524 01:21:38.465787 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.55476 (* 1 = 7.55476 loss)
I0524 01:21:38.466125 11654 sgd_solver.cpp:112] Iteration 16930, lr = 0.1
I0524 01:21:45.191648 11654 solver.cpp:239] Iteration 16940 (1.48686 iter/s, 6.7256s/10 iters), loss = 6.8645
I0524 01:21:45.191700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8645 (* 1 = 6.8645 loss)
I0524 01:21:45.191715 11654 sgd_solver.cpp:112] Iteration 16940, lr = 0.1
I0524 01:21:52.897670 11654 solver.cpp:239] Iteration 16950 (1.29775 iter/s, 7.70562s/10 iters), loss = 6.77055
I0524 01:21:52.897719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77055 (* 1 = 6.77055 loss)
I0524 01:21:53.584905 11654 sgd_solver.cpp:112] Iteration 16950, lr = 0.1
I0524 01:22:00.467926 11654 solver.cpp:239] Iteration 16960 (1.32102 iter/s, 7.56992s/10 iters), loss = 7.61996
I0524 01:22:00.468226 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61996 (* 1 = 7.61996 loss)
I0524 01:22:00.468286 11654 sgd_solver.cpp:112] Iteration 16960, lr = 0.1
I0524 01:22:09.002496 11654 solver.cpp:239] Iteration 16970 (1.17206 iter/s, 8.53198s/10 iters), loss = 7.32495
I0524 01:22:09.002538 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32495 (* 1 = 7.32495 loss)
I0524 01:22:09.282493 11654 sgd_solver.cpp:112] Iteration 16970, lr = 0.1
I0524 01:22:16.660040 11654 solver.cpp:239] Iteration 16980 (1.30596 iter/s, 7.6572s/10 iters), loss = 6.90323
I0524 01:22:16.660095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90323 (* 1 = 6.90323 loss)
I0524 01:22:16.660114 11654 sgd_solver.cpp:112] Iteration 16980, lr = 0.1
I0524 01:22:23.038559 11654 solver.cpp:239] Iteration 16990 (1.56785 iter/s, 6.37815s/10 iters), loss = 7.64433
I0524 01:22:23.038607 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.64433 (* 1 = 7.64433 loss)
I0524 01:22:23.039000 11654 sgd_solver.cpp:112] Iteration 16990, lr = 0.1
I0524 01:22:29.120156 11654 solver.cpp:239] Iteration 17000 (1.64438 iter/s, 6.0813s/10 iters), loss = 6.65612
I0524 01:22:29.120220 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65612 (* 1 = 6.65612 loss)
I0524 01:22:29.120345 11654 sgd_solver.cpp:112] Iteration 17000, lr = 0.1
I0524 01:22:36.067872 11654 solver.cpp:239] Iteration 17010 (1.43939 iter/s, 6.94739s/10 iters), loss = 6.75084
I0524 01:22:36.068011 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75084 (* 1 = 6.75084 loss)
I0524 01:22:36.076618 11654 sgd_solver.cpp:112] Iteration 17010, lr = 0.1
I0524 01:22:45.391144 11654 solver.cpp:239] Iteration 17020 (1.07264 iter/s, 9.32277s/10 iters), loss = 7.30661
I0524 01:22:45.391197 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30661 (* 1 = 7.30661 loss)
I0524 01:22:45.391213 11654 sgd_solver.cpp:112] Iteration 17020, lr = 0.1
I0524 01:22:53.430544 11654 solver.cpp:239] Iteration 17030 (1.24393 iter/s, 8.03901s/10 iters), loss = 6.95929
I0524 01:22:53.430588 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95929 (* 1 = 6.95929 loss)
I0524 01:22:53.430603 11654 sgd_solver.cpp:112] Iteration 17030, lr = 0.1
I0524 01:22:59.787578 11654 solver.cpp:239] Iteration 17040 (1.57317 iter/s, 6.35658s/10 iters), loss = 7.825
I0524 01:22:59.787662 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.825 (* 1 = 7.825 loss)
I0524 01:22:59.787690 11654 sgd_solver.cpp:112] Iteration 17040, lr = 0.1
I0524 01:23:06.517299 11654 solver.cpp:239] Iteration 17050 (1.48602 iter/s, 6.72938s/10 iters), loss = 6.12861
I0524 01:23:06.517565 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12861 (* 1 = 6.12861 loss)
I0524 01:23:06.517630 11654 sgd_solver.cpp:112] Iteration 17050, lr = 0.1
I0524 01:23:13.802984 11654 solver.cpp:239] Iteration 17060 (1.37275 iter/s, 7.28465s/10 iters), loss = 6.76139
I0524 01:23:13.803035 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76139 (* 1 = 6.76139 loss)
I0524 01:23:13.805536 11654 sgd_solver.cpp:112] Iteration 17060, lr = 0.1
I0524 01:23:21.710526 11654 solver.cpp:239] Iteration 17070 (1.26467 iter/s, 7.90718s/10 iters), loss = 7.92854
I0524 01:23:21.710585 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.92854 (* 1 = 7.92854 loss)
I0524 01:23:21.710746 11654 sgd_solver.cpp:112] Iteration 17070, lr = 0.1
I0524 01:23:28.536902 11654 solver.cpp:239] Iteration 17080 (1.46497 iter/s, 6.82606s/10 iters), loss = 6.65406
I0524 01:23:28.536952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65406 (* 1 = 6.65406 loss)
I0524 01:23:29.547554 11654 sgd_solver.cpp:112] Iteration 17080, lr = 0.1
I0524 01:23:37.082298 11654 solver.cpp:239] Iteration 17090 (1.17027 iter/s, 8.54503s/10 iters), loss = 7.75111
I0524 01:23:37.082603 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.75111 (* 1 = 7.75111 loss)
I0524 01:23:37.082661 11654 sgd_solver.cpp:112] Iteration 17090, lr = 0.1
I0524 01:23:43.620981 11654 solver.cpp:239] Iteration 17100 (1.52999 iter/s, 6.536s/10 iters), loss = 7.57824
I0524 01:23:43.621031 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.57824 (* 1 = 7.57824 loss)
I0524 01:23:43.621048 11654 sgd_solver.cpp:112] Iteration 17100, lr = 0.1
I0524 01:23:51.387965 11654 solver.cpp:239] Iteration 17110 (1.28756 iter/s, 7.76663s/10 iters), loss = 6.67774
I0524 01:23:51.388027 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67774 (* 1 = 6.67774 loss)
I0524 01:23:51.388355 11654 sgd_solver.cpp:112] Iteration 17110, lr = 0.1
I0524 01:23:58.379850 11654 solver.cpp:239] Iteration 17120 (1.43029 iter/s, 6.99156s/10 iters), loss = 6.67949
I0524 01:23:58.379890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67949 (* 1 = 6.67949 loss)
I0524 01:23:58.379918 11654 sgd_solver.cpp:112] Iteration 17120, lr = 0.1
I0524 01:24:05.266016 11654 solver.cpp:239] Iteration 17130 (1.45225 iter/s, 6.88585s/10 iters), loss = 6.8531
I0524 01:24:05.266069 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8531 (* 1 = 6.8531 loss)
I0524 01:24:05.266295 11654 sgd_solver.cpp:112] Iteration 17130, lr = 0.1
I0524 01:24:12.149968 11654 solver.cpp:239] Iteration 17140 (1.45272 iter/s, 6.88364s/10 iters), loss = 6.79686
I0524 01:24:12.150063 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79686 (* 1 = 6.79686 loss)
I0524 01:24:12.150624 11654 sgd_solver.cpp:112] Iteration 17140, lr = 0.1
I0524 01:24:19.180753 11654 solver.cpp:239] Iteration 17150 (1.42239 iter/s, 7.03041s/10 iters), loss = 6.52569
I0524 01:24:19.180814 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52569 (* 1 = 6.52569 loss)
I0524 01:24:19.181005 11654 sgd_solver.cpp:112] Iteration 17150, lr = 0.1
I0524 01:24:26.319732 11654 solver.cpp:239] Iteration 17160 (1.40082 iter/s, 7.13865s/10 iters), loss = 6.48783
I0524 01:24:26.319783 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48783 (* 1 = 6.48783 loss)
I0524 01:24:26.321158 11654 sgd_solver.cpp:112] Iteration 17160, lr = 0.1
I0524 01:24:33.236058 11654 solver.cpp:239] Iteration 17170 (1.44592 iter/s, 6.91601s/10 iters), loss = 7.02598
I0524 01:24:33.236109 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02598 (* 1 = 7.02598 loss)
I0524 01:24:33.236474 11654 sgd_solver.cpp:112] Iteration 17170, lr = 0.1
I0524 01:24:42.614540 11654 solver.cpp:239] Iteration 17180 (1.06632 iter/s, 9.37807s/10 iters), loss = 8.09265
I0524 01:24:42.614794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.09265 (* 1 = 8.09265 loss)
I0524 01:24:42.614853 11654 sgd_solver.cpp:112] Iteration 17180, lr = 0.1
I0524 01:24:49.713245 11654 solver.cpp:239] Iteration 17190 (1.40882 iter/s, 7.09816s/10 iters), loss = 7.86348
I0524 01:24:49.713287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86348 (* 1 = 7.86348 loss)
I0524 01:24:49.713300 11654 sgd_solver.cpp:112] Iteration 17190, lr = 0.1
I0524 01:24:56.542392 11654 solver.cpp:239] Iteration 17200 (1.46438 iter/s, 6.82884s/10 iters), loss = 7.63906
I0524 01:24:56.542454 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63906 (* 1 = 7.63906 loss)
I0524 01:24:56.542692 11654 sgd_solver.cpp:112] Iteration 17200, lr = 0.1
I0524 01:25:03.742317 11654 solver.cpp:239] Iteration 17210 (1.38897 iter/s, 7.1996s/10 iters), loss = 6.78694
I0524 01:25:03.742368 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78694 (* 1 = 6.78694 loss)
I0524 01:25:03.742384 11654 sgd_solver.cpp:112] Iteration 17210, lr = 0.1
I0524 01:25:09.880978 11654 solver.cpp:239] Iteration 17220 (1.62968 iter/s, 6.13616s/10 iters), loss = 6.64727
I0524 01:25:09.881031 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64727 (* 1 = 6.64727 loss)
I0524 01:25:09.881119 11654 sgd_solver.cpp:112] Iteration 17220, lr = 0.1
I0524 01:25:16.170801 11654 solver.cpp:239] Iteration 17230 (1.58994 iter/s, 6.28953s/10 iters), loss = 6.73827
I0524 01:25:16.171115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73827 (* 1 = 6.73827 loss)
I0524 01:25:16.200502 11654 sgd_solver.cpp:112] Iteration 17230, lr = 0.1
I0524 01:25:24.133790 11654 solver.cpp:239] Iteration 17240 (1.2559 iter/s, 7.96244s/10 iters), loss = 6.91679
I0524 01:25:24.133826 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91679 (* 1 = 6.91679 loss)
I0524 01:25:24.133839 11654 sgd_solver.cpp:112] Iteration 17240, lr = 0.1
I0524 01:25:31.384251 11654 solver.cpp:239] Iteration 17250 (1.37928 iter/s, 7.25015s/10 iters), loss = 7.76432
I0524 01:25:31.384291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76432 (* 1 = 7.76432 loss)
I0524 01:25:31.384454 11654 sgd_solver.cpp:112] Iteration 17250, lr = 0.1
I0524 01:25:38.002046 11654 solver.cpp:239] Iteration 17260 (1.51115 iter/s, 6.61749s/10 iters), loss = 7.09661
I0524 01:25:38.002102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09661 (* 1 = 7.09661 loss)
I0524 01:25:38.163702 11654 sgd_solver.cpp:112] Iteration 17260, lr = 0.1
I0524 01:25:48.656527 11654 solver.cpp:239] Iteration 17270 (0.938613 iter/s, 10.654s/10 iters), loss = 7.26246
I0524 01:25:48.656661 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26246 (* 1 = 7.26246 loss)
I0524 01:25:48.656678 11654 sgd_solver.cpp:112] Iteration 17270, lr = 0.1
I0524 01:25:56.827214 11654 solver.cpp:239] Iteration 17280 (1.22396 iter/s, 8.17022s/10 iters), loss = 7.77815
I0524 01:25:56.827266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77815 (* 1 = 7.77815 loss)
I0524 01:25:56.827281 11654 sgd_solver.cpp:112] Iteration 17280, lr = 0.1
I0524 01:26:03.469385 11654 solver.cpp:239] Iteration 17290 (1.5061 iter/s, 6.63966s/10 iters), loss = 8.2447
I0524 01:26:03.469431 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.2447 (* 1 = 8.2447 loss)
I0524 01:26:03.469511 11654 sgd_solver.cpp:112] Iteration 17290, lr = 0.1
I0524 01:26:11.042114 11654 solver.cpp:239] Iteration 17300 (1.32059 iter/s, 7.57239s/10 iters), loss = 7.71781
I0524 01:26:11.042160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.71781 (* 1 = 7.71781 loss)
I0524 01:26:11.042176 11654 sgd_solver.cpp:112] Iteration 17300, lr = 0.1
I0524 01:26:19.890400 11654 solver.cpp:239] Iteration 17310 (1.13022 iter/s, 8.84783s/10 iters), loss = 5.76646
I0524 01:26:19.890486 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76646 (* 1 = 5.76646 loss)
I0524 01:26:19.890498 11654 sgd_solver.cpp:112] Iteration 17310, lr = 0.1
I0524 01:26:26.448179 11654 solver.cpp:239] Iteration 17320 (1.52513 iter/s, 6.55682s/10 iters), loss = 5.84287
I0524 01:26:26.448230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84287 (* 1 = 5.84287 loss)
I0524 01:26:26.491451 11654 sgd_solver.cpp:112] Iteration 17320, lr = 0.1
I0524 01:26:34.220252 11654 solver.cpp:239] Iteration 17330 (1.28672 iter/s, 7.77172s/10 iters), loss = 7.28594
I0524 01:26:34.220306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28594 (* 1 = 7.28594 loss)
I0524 01:26:34.220324 11654 sgd_solver.cpp:112] Iteration 17330, lr = 0.1
I0524 01:26:41.658833 11654 solver.cpp:239] Iteration 17340 (1.34452 iter/s, 7.4376s/10 iters), loss = 6.90272
I0524 01:26:41.658898 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90272 (* 1 = 6.90272 loss)
I0524 01:26:41.658923 11654 sgd_solver.cpp:112] Iteration 17340, lr = 0.1
I0524 01:26:48.124789 11654 solver.cpp:239] Iteration 17350 (1.54686 iter/s, 6.46469s/10 iters), loss = 7.07905
I0524 01:26:48.124840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07905 (* 1 = 7.07905 loss)
I0524 01:26:48.124856 11654 sgd_solver.cpp:112] Iteration 17350, lr = 0.1
I0524 01:26:55.317739 11654 solver.cpp:239] Iteration 17360 (1.39032 iter/s, 7.19261s/10 iters), loss = 6.79288
I0524 01:26:55.317869 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79288 (* 1 = 6.79288 loss)
I0524 01:26:55.319742 11654 sgd_solver.cpp:112] Iteration 17360, lr = 0.1
I0524 01:27:01.718770 11654 solver.cpp:239] Iteration 17370 (1.56234 iter/s, 6.40067s/10 iters), loss = 6.95597
I0524 01:27:01.718807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95597 (* 1 = 6.95597 loss)
I0524 01:27:01.718821 11654 sgd_solver.cpp:112] Iteration 17370, lr = 0.1
I0524 01:27:08.186547 11654 solver.cpp:239] Iteration 17380 (1.5462 iter/s, 6.46748s/10 iters), loss = 7.15982
I0524 01:27:08.186609 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15982 (* 1 = 7.15982 loss)
I0524 01:27:08.187053 11654 sgd_solver.cpp:112] Iteration 17380, lr = 0.1
I0524 01:27:15.995503 11654 solver.cpp:239] Iteration 17390 (1.28064 iter/s, 7.8086s/10 iters), loss = 6.56941
I0524 01:27:15.995568 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56941 (* 1 = 6.56941 loss)
I0524 01:27:16.385593 11654 sgd_solver.cpp:112] Iteration 17390, lr = 0.1
I0524 01:27:22.922063 11654 solver.cpp:239] Iteration 17400 (1.44379 iter/s, 6.92623s/10 iters), loss = 7.55203
I0524 01:27:22.922118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.55203 (* 1 = 7.55203 loss)
I0524 01:27:22.922134 11654 sgd_solver.cpp:112] Iteration 17400, lr = 0.1
I0524 01:27:30.584843 11654 solver.cpp:239] Iteration 17410 (1.30508 iter/s, 7.66237s/10 iters), loss = 7.01893
I0524 01:27:30.584995 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01893 (* 1 = 7.01893 loss)
I0524 01:27:31.096572 11654 sgd_solver.cpp:112] Iteration 17410, lr = 0.1
I0524 01:27:37.607775 11654 solver.cpp:239] Iteration 17420 (1.42399 iter/s, 7.02251s/10 iters), loss = 7.21293
I0524 01:27:37.607837 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21293 (* 1 = 7.21293 loss)
I0524 01:27:37.607949 11654 sgd_solver.cpp:112] Iteration 17420, lr = 0.1
I0524 01:27:45.444622 11654 solver.cpp:239] Iteration 17430 (1.27608 iter/s, 7.83649s/10 iters), loss = 7.24926
I0524 01:27:45.444675 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24926 (* 1 = 7.24926 loss)
I0524 01:27:45.444736 11654 sgd_solver.cpp:112] Iteration 17430, lr = 0.1
I0524 01:27:53.814316 11654 solver.cpp:239] Iteration 17440 (1.19484 iter/s, 8.36932s/10 iters), loss = 7.43922
I0524 01:27:53.814368 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43922 (* 1 = 7.43922 loss)
I0524 01:27:53.814709 11654 sgd_solver.cpp:112] Iteration 17440, lr = 0.1
I0524 01:28:01.481077 11654 solver.cpp:239] Iteration 17450 (1.30439 iter/s, 7.66641s/10 iters), loss = 7.01345
I0524 01:28:01.481220 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01345 (* 1 = 7.01345 loss)
I0524 01:28:01.481345 11654 sgd_solver.cpp:112] Iteration 17450, lr = 0.1
I0524 01:28:08.271829 11654 solver.cpp:239] Iteration 17460 (1.47268 iter/s, 6.79036s/10 iters), loss = 7.9029
I0524 01:28:08.271890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9029 (* 1 = 7.9029 loss)
I0524 01:28:08.272277 11654 sgd_solver.cpp:112] Iteration 17460, lr = 0.1
I0524 01:28:15.058395 11654 solver.cpp:239] Iteration 17470 (1.47357 iter/s, 6.78625s/10 iters), loss = 7.21695
I0524 01:28:15.058444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21695 (* 1 = 7.21695 loss)
I0524 01:28:15.233685 11654 sgd_solver.cpp:112] Iteration 17470, lr = 0.1
I0524 01:28:21.883630 11654 solver.cpp:239] Iteration 17480 (1.46522 iter/s, 6.82492s/10 iters), loss = 7.01509
I0524 01:28:21.883692 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01509 (* 1 = 7.01509 loss)
I0524 01:28:21.883865 11654 sgd_solver.cpp:112] Iteration 17480, lr = 0.1
I0524 01:28:28.941408 11654 solver.cpp:239] Iteration 17490 (1.41694 iter/s, 7.05746s/10 iters), loss = 7.52442
I0524 01:28:28.941460 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.52442 (* 1 = 7.52442 loss)
I0524 01:28:29.298660 11654 sgd_solver.cpp:112] Iteration 17490, lr = 0.1
I0524 01:28:37.353730 11654 solver.cpp:239] Iteration 17500 (1.18878 iter/s, 8.41195s/10 iters), loss = 7.66951
I0524 01:28:37.354041 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66951 (* 1 = 7.66951 loss)
I0524 01:28:37.685056 11654 sgd_solver.cpp:112] Iteration 17500, lr = 0.1
I0524 01:28:45.001343 11654 solver.cpp:239] Iteration 17510 (1.30769 iter/s, 7.64706s/10 iters), loss = 7.77792
I0524 01:28:45.001386 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77792 (* 1 = 7.77792 loss)
I0524 01:28:45.349262 11654 sgd_solver.cpp:112] Iteration 17510, lr = 0.1
I0524 01:28:51.567687 11654 solver.cpp:239] Iteration 17520 (1.52299 iter/s, 6.56604s/10 iters), loss = 7.30452
I0524 01:28:51.567744 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30452 (* 1 = 7.30452 loss)
I0524 01:28:51.567953 11654 sgd_solver.cpp:112] Iteration 17520, lr = 0.1
I0524 01:28:58.644225 11654 solver.cpp:239] Iteration 17530 (1.41318 iter/s, 7.07622s/10 iters), loss = 7.63955
I0524 01:28:58.644273 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63955 (* 1 = 7.63955 loss)
I0524 01:28:58.645743 11654 sgd_solver.cpp:112] Iteration 17530, lr = 0.1
I0524 01:29:07.835173 11654 solver.cpp:239] Iteration 17540 (1.08807 iter/s, 9.19055s/10 iters), loss = 6.76919
I0524 01:29:07.835348 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76919 (* 1 = 6.76919 loss)
I0524 01:29:08.887953 11654 sgd_solver.cpp:112] Iteration 17540, lr = 0.1
I0524 01:29:16.751111 11654 solver.cpp:239] Iteration 17550 (1.12165 iter/s, 8.91545s/10 iters), loss = 6.93077
I0524 01:29:16.751168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93077 (* 1 = 6.93077 loss)
I0524 01:29:16.751188 11654 sgd_solver.cpp:112] Iteration 17550, lr = 0.1
I0524 01:29:23.878880 11654 solver.cpp:239] Iteration 17560 (1.40344 iter/s, 7.12535s/10 iters), loss = 8.00722
I0524 01:29:23.878937 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.00722 (* 1 = 8.00722 loss)
I0524 01:29:23.878954 11654 sgd_solver.cpp:112] Iteration 17560, lr = 0.1
I0524 01:29:30.259762 11654 solver.cpp:239] Iteration 17570 (1.5678 iter/s, 6.37837s/10 iters), loss = 6.49162
I0524 01:29:30.259819 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49162 (* 1 = 6.49162 loss)
I0524 01:29:30.259889 11654 sgd_solver.cpp:112] Iteration 17570, lr = 0.1
I0524 01:29:39.326493 11654 solver.cpp:239] Iteration 17580 (1.10298 iter/s, 9.06633s/10 iters), loss = 8.05997
I0524 01:29:39.326783 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.05997 (* 1 = 8.05997 loss)
I0524 01:29:39.326836 11654 sgd_solver.cpp:112] Iteration 17580, lr = 0.1
I0524 01:29:46.107389 11654 solver.cpp:239] Iteration 17590 (1.47529 iter/s, 6.77832s/10 iters), loss = 7.10018
I0524 01:29:46.107445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10018 (* 1 = 7.10018 loss)
I0524 01:29:46.107463 11654 sgd_solver.cpp:112] Iteration 17590, lr = 0.1
I0524 01:29:52.872922 11654 solver.cpp:239] Iteration 17600 (1.47863 iter/s, 6.76302s/10 iters), loss = 7.12751
I0524 01:29:52.872967 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12751 (* 1 = 7.12751 loss)
I0524 01:29:53.179860 11654 sgd_solver.cpp:112] Iteration 17600, lr = 0.1
I0524 01:29:59.704022 11654 solver.cpp:239] Iteration 17610 (1.46396 iter/s, 6.83078s/10 iters), loss = 8.20151
I0524 01:29:59.704080 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.20151 (* 1 = 8.20151 loss)
I0524 01:30:00.288926 11654 sgd_solver.cpp:112] Iteration 17610, lr = 0.1
I0524 01:30:08.391463 11654 solver.cpp:239] Iteration 17620 (1.15114 iter/s, 8.68705s/10 iters), loss = 6.60216
I0524 01:30:08.391520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60216 (* 1 = 6.60216 loss)
I0524 01:30:08.391588 11654 sgd_solver.cpp:112] Iteration 17620, lr = 0.1
I0524 01:30:15.422528 11654 solver.cpp:239] Iteration 17630 (1.42233 iter/s, 7.03074s/10 iters), loss = 7.6851
I0524 01:30:15.422675 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.6851 (* 1 = 7.6851 loss)
I0524 01:30:15.422713 11654 sgd_solver.cpp:112] Iteration 17630, lr = 0.1
I0524 01:30:22.720453 11654 solver.cpp:239] Iteration 17640 (1.37075 iter/s, 7.29529s/10 iters), loss = 6.79473
I0524 01:30:22.720510 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79473 (* 1 = 6.79473 loss)
I0524 01:30:22.720527 11654 sgd_solver.cpp:112] Iteration 17640, lr = 0.1
I0524 01:30:30.096233 11654 solver.cpp:239] Iteration 17650 (1.35586 iter/s, 7.37538s/10 iters), loss = 6.96281
I0524 01:30:30.096287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96281 (* 1 = 6.96281 loss)
I0524 01:30:30.096648 11654 sgd_solver.cpp:112] Iteration 17650, lr = 0.1
I0524 01:30:38.101894 11654 solver.cpp:239] Iteration 17660 (1.24917 iter/s, 8.00531s/10 iters), loss = 6.55519
I0524 01:30:38.101946 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55519 (* 1 = 6.55519 loss)
I0524 01:30:38.101969 11654 sgd_solver.cpp:112] Iteration 17660, lr = 0.1
I0524 01:30:44.809229 11654 solver.cpp:239] Iteration 17670 (1.49098 iter/s, 6.70702s/10 iters), loss = 7.60581
I0524 01:30:44.809289 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.60581 (* 1 = 7.60581 loss)
I0524 01:30:44.809648 11654 sgd_solver.cpp:112] Iteration 17670, lr = 0.1
I0524 01:30:51.940973 11654 solver.cpp:239] Iteration 17680 (1.40225 iter/s, 7.13142s/10 iters), loss = 6.85824
I0524 01:30:51.941229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85824 (* 1 = 6.85824 loss)
I0524 01:30:51.941282 11654 sgd_solver.cpp:112] Iteration 17680, lr = 0.1
I0524 01:30:59.528926 11654 solver.cpp:239] Iteration 17690 (1.31797 iter/s, 7.5874s/10 iters), loss = 6.73153
I0524 01:30:59.528980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73153 (* 1 = 6.73153 loss)
I0524 01:30:59.528995 11654 sgd_solver.cpp:112] Iteration 17690, lr = 0.1
I0524 01:31:07.466503 11654 solver.cpp:239] Iteration 17700 (1.2599 iter/s, 7.93715s/10 iters), loss = 7.12817
I0524 01:31:07.466545 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12817 (* 1 = 7.12817 loss)
I0524 01:31:07.579932 11654 sgd_solver.cpp:112] Iteration 17700, lr = 0.1
I0524 01:31:14.735044 11654 solver.cpp:239] Iteration 17710 (1.37586 iter/s, 7.26821s/10 iters), loss = 7.17274
I0524 01:31:14.735108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17274 (* 1 = 7.17274 loss)
I0524 01:31:14.735396 11654 sgd_solver.cpp:112] Iteration 17710, lr = 0.1
I0524 01:31:22.313307 11654 solver.cpp:239] Iteration 17720 (1.31962 iter/s, 7.57791s/10 iters), loss = 6.68443
I0524 01:31:22.313539 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68443 (* 1 = 6.68443 loss)
I0524 01:31:22.313796 11654 sgd_solver.cpp:112] Iteration 17720, lr = 0.1
I0524 01:31:30.329952 11654 solver.cpp:239] Iteration 17730 (1.24748 iter/s, 8.01613s/10 iters), loss = 6.2449
I0524 01:31:30.330006 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2449 (* 1 = 6.2449 loss)
I0524 01:31:30.330022 11654 sgd_solver.cpp:112] Iteration 17730, lr = 0.1
I0524 01:31:39.402017 11654 solver.cpp:239] Iteration 17740 (1.1026 iter/s, 9.06944s/10 iters), loss = 7.81645
I0524 01:31:39.402071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.81645 (* 1 = 7.81645 loss)
I0524 01:31:39.402088 11654 sgd_solver.cpp:112] Iteration 17740, lr = 0.1
I0524 01:31:47.900743 11654 solver.cpp:239] Iteration 17750 (1.1767 iter/s, 8.49835s/10 iters), loss = 7.2906
I0524 01:31:47.900794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2906 (* 1 = 7.2906 loss)
I0524 01:31:48.998790 11654 sgd_solver.cpp:112] Iteration 17750, lr = 0.1
I0524 01:31:55.548830 11654 solver.cpp:239] Iteration 17760 (1.30757 iter/s, 7.64775s/10 iters), loss = 6.59037
I0524 01:31:55.549079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59037 (* 1 = 6.59037 loss)
I0524 01:31:55.549136 11654 sgd_solver.cpp:112] Iteration 17760, lr = 0.1
I0524 01:32:02.917904 11654 solver.cpp:239] Iteration 17770 (1.35713 iter/s, 7.36848s/10 iters), loss = 6.1881
I0524 01:32:02.917958 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1881 (* 1 = 6.1881 loss)
I0524 01:32:02.917973 11654 sgd_solver.cpp:112] Iteration 17770, lr = 0.1
I0524 01:32:09.994339 11654 solver.cpp:239] Iteration 17780 (1.41365 iter/s, 7.0739s/10 iters), loss = 6.48894
I0524 01:32:09.994379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48894 (* 1 = 6.48894 loss)
I0524 01:32:09.994393 11654 sgd_solver.cpp:112] Iteration 17780, lr = 0.1
I0524 01:32:17.721699 11654 solver.cpp:239] Iteration 17790 (1.29417 iter/s, 7.72699s/10 iters), loss = 6.66986
I0524 01:32:17.721789 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66986 (* 1 = 6.66986 loss)
I0524 01:32:18.014055 11654 sgd_solver.cpp:112] Iteration 17790, lr = 0.1
I0524 01:32:25.412477 11654 solver.cpp:239] Iteration 17800 (1.30032 iter/s, 7.69041s/10 iters), loss = 7.051
I0524 01:32:25.412529 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.051 (* 1 = 7.051 loss)
I0524 01:32:25.412657 11654 sgd_solver.cpp:112] Iteration 17800, lr = 0.1
I0524 01:32:32.421311 11654 solver.cpp:239] Iteration 17810 (1.42684 iter/s, 7.00852s/10 iters), loss = 7.61676
I0524 01:32:32.421603 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61676 (* 1 = 7.61676 loss)
I0524 01:32:32.421676 11654 sgd_solver.cpp:112] Iteration 17810, lr = 0.1
I0524 01:32:39.291645 11654 solver.cpp:239] Iteration 17820 (1.45564 iter/s, 6.86981s/10 iters), loss = 7.96545
I0524 01:32:39.291704 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.96545 (* 1 = 7.96545 loss)
I0524 01:32:39.291746 11654 sgd_solver.cpp:112] Iteration 17820, lr = 0.1
I0524 01:32:46.652550 11654 solver.cpp:239] Iteration 17830 (1.35859 iter/s, 7.36056s/10 iters), loss = 7.3772
I0524 01:32:46.652618 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3772 (* 1 = 7.3772 loss)
I0524 01:32:46.652829 11654 sgd_solver.cpp:112] Iteration 17830, lr = 0.1
I0524 01:32:53.934396 11654 solver.cpp:239] Iteration 17840 (1.37334 iter/s, 7.2815s/10 iters), loss = 7.89762
I0524 01:32:53.934450 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89762 (* 1 = 7.89762 loss)
I0524 01:32:53.934468 11654 sgd_solver.cpp:112] Iteration 17840, lr = 0.1
I0524 01:33:00.457288 11654 solver.cpp:239] Iteration 17850 (1.53315 iter/s, 6.52253s/10 iters), loss = 7.61688
I0524 01:33:00.457329 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61688 (* 1 = 7.61688 loss)
I0524 01:33:00.457847 11654 sgd_solver.cpp:112] Iteration 17850, lr = 0.1
I0524 01:33:06.926796 11654 solver.cpp:239] Iteration 17860 (1.54578 iter/s, 6.46922s/10 iters), loss = 6.32788
I0524 01:33:06.927039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32788 (* 1 = 6.32788 loss)
I0524 01:33:06.927095 11654 sgd_solver.cpp:112] Iteration 17860, lr = 0.1
I0524 01:33:13.478570 11654 solver.cpp:239] Iteration 17870 (1.52642 iter/s, 6.55127s/10 iters), loss = 6.88717
I0524 01:33:13.478621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88717 (* 1 = 6.88717 loss)
I0524 01:33:13.478670 11654 sgd_solver.cpp:112] Iteration 17870, lr = 0.1
I0524 01:33:19.836364 11654 solver.cpp:239] Iteration 17880 (1.57295 iter/s, 6.35749s/10 iters), loss = 6.65439
I0524 01:33:19.836421 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65439 (* 1 = 6.65439 loss)
I0524 01:33:19.878944 11654 sgd_solver.cpp:112] Iteration 17880, lr = 0.1
I0524 01:33:26.436226 11654 solver.cpp:239] Iteration 17890 (1.51525 iter/s, 6.59956s/10 iters), loss = 6.87982
I0524 01:33:26.436270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87982 (* 1 = 6.87982 loss)
I0524 01:33:26.436283 11654 sgd_solver.cpp:112] Iteration 17890, lr = 0.1
I0524 01:33:32.679342 11654 solver.cpp:239] Iteration 17900 (1.60241 iter/s, 6.2406s/10 iters), loss = 6.78073
I0524 01:33:32.679395 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78073 (* 1 = 6.78073 loss)
I0524 01:33:32.679496 11654 sgd_solver.cpp:112] Iteration 17900, lr = 0.1
I0524 01:33:38.898797 11654 solver.cpp:239] Iteration 17910 (1.60794 iter/s, 6.21916s/10 iters), loss = 7.17747
I0524 01:33:38.899070 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17747 (* 1 = 7.17747 loss)
I0524 01:33:38.899242 11654 sgd_solver.cpp:112] Iteration 17910, lr = 0.1
I0524 01:33:45.066488 11654 solver.cpp:239] Iteration 17920 (1.62147 iter/s, 6.16723s/10 iters), loss = 5.78878
I0524 01:33:45.066550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78878 (* 1 = 5.78878 loss)
I0524 01:33:45.066740 11654 sgd_solver.cpp:112] Iteration 17920, lr = 0.1
I0524 01:33:53.103528 11654 solver.cpp:239] Iteration 17930 (1.2443 iter/s, 8.03667s/10 iters), loss = 7.73764
I0524 01:33:53.103581 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.73764 (* 1 = 7.73764 loss)
I0524 01:33:53.104133 11654 sgd_solver.cpp:112] Iteration 17930, lr = 0.1
I0524 01:34:01.541957 11654 solver.cpp:239] Iteration 17940 (1.18511 iter/s, 8.43806s/10 iters), loss = 5.9861
I0524 01:34:01.542011 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9861 (* 1 = 5.9861 loss)
I0524 01:34:01.547291 11654 sgd_solver.cpp:112] Iteration 17940, lr = 0.1
I0524 01:34:08.916198 11654 solver.cpp:239] Iteration 17950 (1.35613 iter/s, 7.37391s/10 iters), loss = 6.4263
I0524 01:34:08.916434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4263 (* 1 = 6.4263 loss)
I0524 01:34:09.146699 11654 sgd_solver.cpp:112] Iteration 17950, lr = 0.1
I0524 01:34:16.858955 11654 solver.cpp:239] Iteration 17960 (1.25909 iter/s, 7.94226s/10 iters), loss = 6.74396
I0524 01:34:16.859000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74396 (* 1 = 6.74396 loss)
I0524 01:34:16.859369 11654 sgd_solver.cpp:112] Iteration 17960, lr = 0.1
I0524 01:34:24.396780 11654 solver.cpp:239] Iteration 17970 (1.3267 iter/s, 7.53748s/10 iters), loss = 7.31501
I0524 01:34:24.396847 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31501 (* 1 = 7.31501 loss)
I0524 01:34:24.397243 11654 sgd_solver.cpp:112] Iteration 17970, lr = 0.1
I0524 01:34:32.012177 11654 solver.cpp:239] Iteration 17980 (1.31319 iter/s, 7.61502s/10 iters), loss = 6.97247
I0524 01:34:32.012221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97247 (* 1 = 6.97247 loss)
I0524 01:34:32.012394 11654 sgd_solver.cpp:112] Iteration 17980, lr = 0.1
I0524 01:34:38.249469 11654 solver.cpp:239] Iteration 17990 (1.60333 iter/s, 6.237s/10 iters), loss = 6.47927
I0524 01:34:38.249521 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47927 (* 1 = 6.47927 loss)
I0524 01:34:39.049319 11654 sgd_solver.cpp:112] Iteration 17990, lr = 0.1
I0524 01:34:45.643045 11654 solver.cpp:239] Iteration 18000 (1.35259 iter/s, 7.39324s/10 iters), loss = 6.86576
I0524 01:34:45.643101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86576 (* 1 = 6.86576 loss)
I0524 01:34:45.643333 11654 sgd_solver.cpp:112] Iteration 18000, lr = 0.1
I0524 01:34:52.981205 11654 solver.cpp:239] Iteration 18010 (1.3628 iter/s, 7.33783s/10 iters), loss = 7.03664
I0524 01:34:52.981251 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03664 (* 1 = 7.03664 loss)
I0524 01:34:52.981266 11654 sgd_solver.cpp:112] Iteration 18010, lr = 0.1
I0524 01:34:59.140856 11654 solver.cpp:239] Iteration 18020 (1.62413 iter/s, 6.15715s/10 iters), loss = 6.67083
I0524 01:34:59.140902 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67083 (* 1 = 6.67083 loss)
I0524 01:34:59.141016 11654 sgd_solver.cpp:112] Iteration 18020, lr = 0.1
I0524 01:35:06.815126 11654 solver.cpp:239] Iteration 18030 (1.30311 iter/s, 7.67392s/10 iters), loss = 6.66489
I0524 01:35:06.815179 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66489 (* 1 = 6.66489 loss)
I0524 01:35:06.815193 11654 sgd_solver.cpp:112] Iteration 18030, lr = 0.1
I0524 01:35:14.356322 11654 solver.cpp:239] Iteration 18040 (1.32611 iter/s, 7.54086s/10 iters), loss = 7.17858
I0524 01:35:14.356598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17858 (* 1 = 7.17858 loss)
I0524 01:35:14.356658 11654 sgd_solver.cpp:112] Iteration 18040, lr = 0.1
I0524 01:35:21.808451 11654 solver.cpp:239] Iteration 18050 (1.34199 iter/s, 7.45161s/10 iters), loss = 7.13708
I0524 01:35:21.808512 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13708 (* 1 = 7.13708 loss)
I0524 01:35:21.809051 11654 sgd_solver.cpp:112] Iteration 18050, lr = 0.1
I0524 01:35:28.351702 11654 solver.cpp:239] Iteration 18060 (1.52836 iter/s, 6.54295s/10 iters), loss = 7.07694
I0524 01:35:28.351748 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07694 (* 1 = 7.07694 loss)
I0524 01:35:28.408542 11654 sgd_solver.cpp:112] Iteration 18060, lr = 0.1
I0524 01:35:35.630955 11654 solver.cpp:239] Iteration 18070 (1.37383 iter/s, 7.27892s/10 iters), loss = 7.9071
I0524 01:35:35.631026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9071 (* 1 = 7.9071 loss)
I0524 01:35:35.631050 11654 sgd_solver.cpp:112] Iteration 18070, lr = 0.1
I0524 01:35:42.183122 11654 solver.cpp:239] Iteration 18080 (1.5263 iter/s, 6.5518s/10 iters), loss = 6.92134
I0524 01:35:42.183171 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92134 (* 1 = 6.92134 loss)
I0524 01:35:43.004724 11654 sgd_solver.cpp:112] Iteration 18080, lr = 0.1
I0524 01:35:50.793573 11654 solver.cpp:239] Iteration 18090 (1.16143 iter/s, 8.61007s/10 iters), loss = 7.6278
I0524 01:35:50.793723 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.6278 (* 1 = 7.6278 loss)
I0524 01:35:50.793741 11654 sgd_solver.cpp:112] Iteration 18090, lr = 0.1
I0524 01:35:57.287408 11654 solver.cpp:239] Iteration 18100 (1.54002 iter/s, 6.49342s/10 iters), loss = 6.66321
I0524 01:35:57.287463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66321 (* 1 = 6.66321 loss)
I0524 01:35:57.287479 11654 sgd_solver.cpp:112] Iteration 18100, lr = 0.1
I0524 01:36:04.076783 11654 solver.cpp:239] Iteration 18110 (1.47296 iter/s, 6.78906s/10 iters), loss = 8.14224
I0524 01:36:04.076825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.14224 (* 1 = 8.14224 loss)
I0524 01:36:04.493175 11654 sgd_solver.cpp:112] Iteration 18110, lr = 0.1
I0524 01:36:10.532079 11654 solver.cpp:239] Iteration 18120 (1.54919 iter/s, 6.45499s/10 iters), loss = 7.50011
I0524 01:36:10.532145 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50011 (* 1 = 7.50011 loss)
I0524 01:36:10.532166 11654 sgd_solver.cpp:112] Iteration 18120, lr = 0.1
I0524 01:36:19.142889 11654 solver.cpp:239] Iteration 18130 (1.16169 iter/s, 8.60818s/10 iters), loss = 6.66735
I0524 01:36:19.142938 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66735 (* 1 = 6.66735 loss)
I0524 01:36:19.142954 11654 sgd_solver.cpp:112] Iteration 18130, lr = 0.1
I0524 01:36:26.405822 11654 solver.cpp:239] Iteration 18140 (1.37734 iter/s, 7.26038s/10 iters), loss = 7.23913
I0524 01:36:26.406100 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23913 (* 1 = 7.23913 loss)
I0524 01:36:26.406150 11654 sgd_solver.cpp:112] Iteration 18140, lr = 0.1
I0524 01:36:32.719125 11654 solver.cpp:239] Iteration 18150 (1.58408 iter/s, 6.3128s/10 iters), loss = 6.96563
I0524 01:36:32.719182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96563 (* 1 = 6.96563 loss)
I0524 01:36:32.719200 11654 sgd_solver.cpp:112] Iteration 18150, lr = 0.1
I0524 01:36:40.612344 11654 solver.cpp:239] Iteration 18160 (1.26732 iter/s, 7.89067s/10 iters), loss = 7.71714
I0524 01:36:40.612401 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.71714 (* 1 = 7.71714 loss)
I0524 01:36:41.075716 11654 sgd_solver.cpp:112] Iteration 18160, lr = 0.1
I0524 01:36:47.962611 11654 solver.cpp:239] Iteration 18170 (1.36056 iter/s, 7.34993s/10 iters), loss = 7.968
I0524 01:36:47.962672 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.968 (* 1 = 7.968 loss)
I0524 01:36:47.962862 11654 sgd_solver.cpp:112] Iteration 18170, lr = 0.1
I0524 01:36:55.684248 11654 solver.cpp:239] Iteration 18180 (1.29512 iter/s, 7.72129s/10 iters), loss = 7.36891
I0524 01:36:55.684303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36891 (* 1 = 7.36891 loss)
I0524 01:36:55.684389 11654 sgd_solver.cpp:112] Iteration 18180, lr = 0.1
I0524 01:37:02.381677 11654 solver.cpp:239] Iteration 18190 (1.49318 iter/s, 6.69712s/10 iters), loss = 5.86362
I0524 01:37:02.381976 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86362 (* 1 = 5.86362 loss)
I0524 01:37:02.382261 11654 sgd_solver.cpp:112] Iteration 18190, lr = 0.1
I0524 01:37:09.956231 11654 solver.cpp:239] Iteration 18200 (1.3203 iter/s, 7.57401s/10 iters), loss = 7.02485
I0524 01:37:09.956291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02485 (* 1 = 7.02485 loss)
I0524 01:37:09.956424 11654 sgd_solver.cpp:112] Iteration 18200, lr = 0.1
I0524 01:37:17.811671 11654 solver.cpp:239] Iteration 18210 (1.27306 iter/s, 7.85508s/10 iters), loss = 6.13082
I0524 01:37:17.811767 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13082 (* 1 = 6.13082 loss)
I0524 01:37:17.811800 11654 sgd_solver.cpp:112] Iteration 18210, lr = 0.1
I0524 01:37:24.038889 11654 solver.cpp:239] Iteration 18220 (1.60594 iter/s, 6.22686s/10 iters), loss = 7.44507
I0524 01:37:24.038950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44507 (* 1 = 7.44507 loss)
I0524 01:37:24.039208 11654 sgd_solver.cpp:112] Iteration 18220, lr = 0.1
I0524 01:37:30.941896 11654 solver.cpp:239] Iteration 18230 (1.44871 iter/s, 6.90269s/10 iters), loss = 6.28431
I0524 01:37:30.941936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28431 (* 1 = 6.28431 loss)
I0524 01:37:30.942059 11654 sgd_solver.cpp:112] Iteration 18230, lr = 0.1
I0524 01:37:38.908332 11654 solver.cpp:239] Iteration 18240 (1.25533 iter/s, 7.96601s/10 iters), loss = 8.04174
I0524 01:37:38.908540 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.04174 (* 1 = 8.04174 loss)
I0524 01:37:38.908576 11654 sgd_solver.cpp:112] Iteration 18240, lr = 0.1
I0524 01:37:46.148126 11654 solver.cpp:239] Iteration 18250 (1.38138 iter/s, 7.23915s/10 iters), loss = 7.26464
I0524 01:37:46.148188 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26464 (* 1 = 7.26464 loss)
I0524 01:37:46.148315 11654 sgd_solver.cpp:112] Iteration 18250, lr = 0.1
I0524 01:37:52.994683 11654 solver.cpp:239] Iteration 18260 (1.46066 iter/s, 6.84624s/10 iters), loss = 7.09406
I0524 01:37:52.994750 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09406 (* 1 = 7.09406 loss)
I0524 01:37:52.994768 11654 sgd_solver.cpp:112] Iteration 18260, lr = 0.1
I0524 01:37:59.479857 11654 solver.cpp:239] Iteration 18270 (1.54258 iter/s, 6.48266s/10 iters), loss = 6.21588
I0524 01:37:59.479899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21588 (* 1 = 6.21588 loss)
I0524 01:37:59.480106 11654 sgd_solver.cpp:112] Iteration 18270, lr = 0.1
I0524 01:38:08.776087 11654 solver.cpp:239] Iteration 18280 (1.07575 iter/s, 9.29583s/10 iters), loss = 7.19512
I0524 01:38:08.776141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19512 (* 1 = 7.19512 loss)
I0524 01:38:08.776340 11654 sgd_solver.cpp:112] Iteration 18280, lr = 0.1
I0524 01:38:15.153718 11654 solver.cpp:239] Iteration 18290 (1.56805 iter/s, 6.37733s/10 iters), loss = 6.71132
I0524 01:38:15.153812 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71132 (* 1 = 6.71132 loss)
I0524 01:38:15.154296 11654 sgd_solver.cpp:112] Iteration 18290, lr = 0.1
I0524 01:38:21.382100 11654 solver.cpp:239] Iteration 18300 (1.60564 iter/s, 6.22805s/10 iters), loss = 7.59332
I0524 01:38:21.382139 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59332 (* 1 = 7.59332 loss)
I0524 01:38:21.382246 11654 sgd_solver.cpp:112] Iteration 18300, lr = 0.1
I0524 01:38:27.722018 11654 solver.cpp:239] Iteration 18310 (1.57738 iter/s, 6.33962s/10 iters), loss = 6.96278
I0524 01:38:27.722079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96278 (* 1 = 6.96278 loss)
I0524 01:38:27.722100 11654 sgd_solver.cpp:112] Iteration 18310, lr = 0.1
I0524 01:38:37.650616 11654 solver.cpp:239] Iteration 18320 (1.00724 iter/s, 9.92811s/10 iters), loss = 6.67009
I0524 01:38:37.650671 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67009 (* 1 = 6.67009 loss)
I0524 01:38:37.660575 11654 sgd_solver.cpp:112] Iteration 18320, lr = 0.1
I0524 01:38:45.731360 11654 solver.cpp:239] Iteration 18330 (1.23757 iter/s, 8.08038s/10 iters), loss = 7.78966
I0524 01:38:45.731590 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78966 (* 1 = 7.78966 loss)
I0524 01:38:45.731640 11654 sgd_solver.cpp:112] Iteration 18330, lr = 0.1
I0524 01:38:52.553683 11654 solver.cpp:239] Iteration 18340 (1.46589 iter/s, 6.82181s/10 iters), loss = 7.1736
I0524 01:38:52.553756 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1736 (* 1 = 7.1736 loss)
I0524 01:38:52.554101 11654 sgd_solver.cpp:112] Iteration 18340, lr = 0.1
I0524 01:39:00.604507 11654 solver.cpp:239] Iteration 18350 (1.24217 iter/s, 8.05045s/10 iters), loss = 6.63289
I0524 01:39:00.604576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63289 (* 1 = 6.63289 loss)
I0524 01:39:00.604601 11654 sgd_solver.cpp:112] Iteration 18350, lr = 0.1
I0524 01:39:06.966327 11654 solver.cpp:239] Iteration 18360 (1.57196 iter/s, 6.36147s/10 iters), loss = 7.13867
I0524 01:39:06.966377 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13867 (* 1 = 7.13867 loss)
I0524 01:39:06.966532 11654 sgd_solver.cpp:112] Iteration 18360, lr = 0.1
I0524 01:39:15.110213 11654 solver.cpp:239] Iteration 18370 (1.22797 iter/s, 8.14352s/10 iters), loss = 6.4767
I0524 01:39:15.110278 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4767 (* 1 = 6.4767 loss)
I0524 01:39:15.110456 11654 sgd_solver.cpp:112] Iteration 18370, lr = 0.1
I0524 01:39:21.909590 11654 solver.cpp:239] Iteration 18380 (1.47079 iter/s, 6.79906s/10 iters), loss = 6.4821
I0524 01:39:21.909832 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4821 (* 1 = 6.4821 loss)
I0524 01:39:21.909883 11654 sgd_solver.cpp:112] Iteration 18380, lr = 0.1
I0524 01:39:29.320046 11654 solver.cpp:239] Iteration 18390 (1.34992 iter/s, 7.40783s/10 iters), loss = 7.39865
I0524 01:39:29.320106 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39865 (* 1 = 7.39865 loss)
I0524 01:39:29.320125 11654 sgd_solver.cpp:112] Iteration 18390, lr = 0.1
I0524 01:39:35.917809 11654 solver.cpp:239] Iteration 18400 (1.51575 iter/s, 6.5974s/10 iters), loss = 5.98421
I0524 01:39:35.917865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98421 (* 1 = 5.98421 loss)
I0524 01:39:35.918058 11654 sgd_solver.cpp:112] Iteration 18400, lr = 0.1
I0524 01:39:42.306740 11654 solver.cpp:239] Iteration 18410 (1.56529 iter/s, 6.3886s/10 iters), loss = 7.1172
I0524 01:39:42.306780 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1172 (* 1 = 7.1172 loss)
I0524 01:39:42.380324 11654 sgd_solver.cpp:112] Iteration 18410, lr = 0.1
I0524 01:39:49.974673 11654 solver.cpp:239] Iteration 18420 (1.30419 iter/s, 7.66759s/10 iters), loss = 7.59153
I0524 01:39:49.974746 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59153 (* 1 = 7.59153 loss)
I0524 01:39:49.974764 11654 sgd_solver.cpp:112] Iteration 18420, lr = 0.1
I0524 01:39:57.271941 11654 solver.cpp:239] Iteration 18430 (1.37044 iter/s, 7.29692s/10 iters), loss = 6.45964
I0524 01:39:57.272102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45964 (* 1 = 6.45964 loss)
I0524 01:39:57.874541 11654 sgd_solver.cpp:112] Iteration 18430, lr = 0.1
I0524 01:40:04.900749 11654 solver.cpp:239] Iteration 18440 (1.3109 iter/s, 7.62837s/10 iters), loss = 6.64151
I0524 01:40:04.900805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64151 (* 1 = 6.64151 loss)
I0524 01:40:05.140455 11654 sgd_solver.cpp:112] Iteration 18440, lr = 0.1
I0524 01:40:13.007566 11654 solver.cpp:239] Iteration 18450 (1.23359 iter/s, 8.10645s/10 iters), loss = 6.99421
I0524 01:40:13.007621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99421 (* 1 = 6.99421 loss)
I0524 01:40:13.007638 11654 sgd_solver.cpp:112] Iteration 18450, lr = 0.1
I0524 01:40:20.217675 11654 solver.cpp:239] Iteration 18460 (1.38743 iter/s, 7.20756s/10 iters), loss = 7.4119
I0524 01:40:20.217733 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4119 (* 1 = 7.4119 loss)
I0524 01:40:20.218089 11654 sgd_solver.cpp:112] Iteration 18460, lr = 0.1
I0524 01:40:27.514117 11654 solver.cpp:239] Iteration 18470 (1.37059 iter/s, 7.29611s/10 iters), loss = 7.1241
I0524 01:40:27.514305 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1241 (* 1 = 7.1241 loss)
I0524 01:40:27.514333 11654 sgd_solver.cpp:112] Iteration 18470, lr = 0.1
I0524 01:40:34.215663 11654 solver.cpp:239] Iteration 18480 (1.4923 iter/s, 6.70108s/10 iters), loss = 6.21943
I0524 01:40:34.215701 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21943 (* 1 = 6.21943 loss)
I0524 01:40:34.215715 11654 sgd_solver.cpp:112] Iteration 18480, lr = 0.1
I0524 01:40:42.726387 11654 solver.cpp:239] Iteration 18490 (1.17504 iter/s, 8.51034s/10 iters), loss = 7.21781
I0524 01:40:42.726446 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21781 (* 1 = 7.21781 loss)
I0524 01:40:42.726876 11654 sgd_solver.cpp:112] Iteration 18490, lr = 0.1
I0524 01:40:50.482465 11654 solver.cpp:239] Iteration 18500 (1.28937 iter/s, 7.75572s/10 iters), loss = 7.68943
I0524 01:40:50.482520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.68943 (* 1 = 7.68943 loss)
I0524 01:40:50.538766 11654 sgd_solver.cpp:112] Iteration 18500, lr = 0.1
I0524 01:40:58.322849 11654 solver.cpp:239] Iteration 18510 (1.2755 iter/s, 7.84003s/10 iters), loss = 7.53177
I0524 01:40:58.322927 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.53177 (* 1 = 7.53177 loss)
I0524 01:40:58.754348 11654 sgd_solver.cpp:112] Iteration 18510, lr = 0.1
I0524 01:41:06.753392 11654 solver.cpp:239] Iteration 18520 (1.18622 iter/s, 8.43014s/10 iters), loss = 6.20776
I0524 01:41:06.753449 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20776 (* 1 = 6.20776 loss)
I0524 01:41:07.227097 11654 sgd_solver.cpp:112] Iteration 18520, lr = 0.1
I0524 01:41:16.223042 11654 solver.cpp:239] Iteration 18530 (1.05605 iter/s, 9.46924s/10 iters), loss = 7.01886
I0524 01:41:16.223094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01886 (* 1 = 7.01886 loss)
I0524 01:41:16.223109 11654 sgd_solver.cpp:112] Iteration 18530, lr = 0.1
I0524 01:41:22.583328 11654 solver.cpp:239] Iteration 18540 (1.57235 iter/s, 6.35991s/10 iters), loss = 6.81084
I0524 01:41:22.583385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81084 (* 1 = 6.81084 loss)
I0524 01:41:22.706583 11654 sgd_solver.cpp:112] Iteration 18540, lr = 0.1
I0524 01:41:29.505612 11654 solver.cpp:239] Iteration 18550 (1.44468 iter/s, 6.92196s/10 iters), loss = 7.97715
I0524 01:41:29.505767 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.97715 (* 1 = 7.97715 loss)
I0524 01:41:29.505789 11654 sgd_solver.cpp:112] Iteration 18550, lr = 0.1
I0524 01:41:35.946763 11654 solver.cpp:239] Iteration 18560 (1.55263 iter/s, 6.44066s/10 iters), loss = 7.10777
I0524 01:41:35.946825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10777 (* 1 = 7.10777 loss)
I0524 01:41:36.479084 11654 sgd_solver.cpp:112] Iteration 18560, lr = 0.1
I0524 01:41:44.554584 11654 solver.cpp:239] Iteration 18570 (1.16179 iter/s, 8.60742s/10 iters), loss = 6.63134
I0524 01:41:44.554652 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63134 (* 1 = 6.63134 loss)
I0524 01:41:44.555028 11654 sgd_solver.cpp:112] Iteration 18570, lr = 0.1
I0524 01:41:51.290257 11654 solver.cpp:239] Iteration 18580 (1.4847 iter/s, 6.73535s/10 iters), loss = 7.27807
I0524 01:41:51.290314 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27807 (* 1 = 7.27807 loss)
I0524 01:41:51.290834 11654 sgd_solver.cpp:112] Iteration 18580, lr = 0.1
I0524 01:41:58.010320 11654 solver.cpp:239] Iteration 18590 (1.48815 iter/s, 6.71975s/10 iters), loss = 7.91084
I0524 01:41:58.010390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91084 (* 1 = 7.91084 loss)
I0524 01:41:58.010519 11654 sgd_solver.cpp:112] Iteration 18590, lr = 0.1
I0524 01:42:04.303335 11654 solver.cpp:239] Iteration 18600 (1.58914 iter/s, 6.29272s/10 iters), loss = 7.65086
I0524 01:42:04.303632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.65086 (* 1 = 7.65086 loss)
I0524 01:42:04.303891 11654 sgd_solver.cpp:112] Iteration 18600, lr = 0.1
I0524 01:42:13.095794 11654 solver.cpp:239] Iteration 18610 (1.13742 iter/s, 8.79185s/10 iters), loss = 6.05754
I0524 01:42:13.095858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05754 (* 1 = 6.05754 loss)
I0524 01:42:13.096341 11654 sgd_solver.cpp:112] Iteration 18610, lr = 0.1
I0524 01:42:20.072769 11654 solver.cpp:239] Iteration 18620 (1.43335 iter/s, 6.97665s/10 iters), loss = 7.54393
I0524 01:42:20.072821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54393 (* 1 = 7.54393 loss)
I0524 01:42:20.072839 11654 sgd_solver.cpp:112] Iteration 18620, lr = 0.1
I0524 01:42:27.139832 11654 solver.cpp:239] Iteration 18630 (1.41509 iter/s, 7.06668s/10 iters), loss = 7.86972
I0524 01:42:27.139875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86972 (* 1 = 7.86972 loss)
I0524 01:42:27.139889 11654 sgd_solver.cpp:112] Iteration 18630, lr = 0.1
I0524 01:42:33.578645 11654 solver.cpp:239] Iteration 18640 (1.55367 iter/s, 6.43636s/10 iters), loss = 8.13678
I0524 01:42:33.578716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.13678 (* 1 = 8.13678 loss)
I0524 01:42:33.579082 11654 sgd_solver.cpp:112] Iteration 18640, lr = 0.1
I0524 01:42:41.163734 11654 solver.cpp:239] Iteration 18650 (1.31844 iter/s, 7.58474s/10 iters), loss = 8.10772
I0524 01:42:41.163856 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.10772 (* 1 = 8.10772 loss)
I0524 01:42:41.165805 11654 sgd_solver.cpp:112] Iteration 18650, lr = 0.1
I0524 01:42:48.682844 11654 solver.cpp:239] Iteration 18660 (1.33002 iter/s, 7.51871s/10 iters), loss = 6.5486
I0524 01:42:48.682898 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5486 (* 1 = 6.5486 loss)
I0524 01:42:48.682919 11654 sgd_solver.cpp:112] Iteration 18660, lr = 0.1
I0524 01:42:56.363415 11654 solver.cpp:239] Iteration 18670 (1.30206 iter/s, 7.68015s/10 iters), loss = 6.05572
I0524 01:42:56.363466 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05572 (* 1 = 6.05572 loss)
I0524 01:42:56.366264 11654 sgd_solver.cpp:112] Iteration 18670, lr = 0.1
I0524 01:43:03.443627 11654 solver.cpp:239] Iteration 18680 (1.41245 iter/s, 7.0799s/10 iters), loss = 7.04615
I0524 01:43:03.443667 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04615 (* 1 = 7.04615 loss)
I0524 01:43:03.443790 11654 sgd_solver.cpp:112] Iteration 18680, lr = 0.1
I0524 01:43:11.936743 11654 solver.cpp:239] Iteration 18690 (1.17748 iter/s, 8.49275s/10 iters), loss = 6.12379
I0524 01:43:11.936882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12379 (* 1 = 6.12379 loss)
I0524 01:43:11.936899 11654 sgd_solver.cpp:112] Iteration 18690, lr = 0.1
I0524 01:43:17.999234 11654 solver.cpp:239] Iteration 18700 (1.64979 iter/s, 6.06137s/10 iters), loss = 6.29949
I0524 01:43:17.999292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29949 (* 1 = 6.29949 loss)
I0524 01:43:17.999655 11654 sgd_solver.cpp:112] Iteration 18700, lr = 0.1
I0524 01:43:25.606207 11654 solver.cpp:239] Iteration 18710 (1.31464 iter/s, 7.60663s/10 iters), loss = 7.00239
I0524 01:43:25.606257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00239 (* 1 = 7.00239 loss)
I0524 01:43:25.606724 11654 sgd_solver.cpp:112] Iteration 18710, lr = 0.1
I0524 01:43:33.426035 11654 solver.cpp:239] Iteration 18720 (1.27886 iter/s, 7.81949s/10 iters), loss = 6.49216
I0524 01:43:33.426074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49216 (* 1 = 6.49216 loss)
I0524 01:43:34.555579 11654 sgd_solver.cpp:112] Iteration 18720, lr = 0.1
I0524 01:43:41.309352 11654 solver.cpp:239] Iteration 18730 (1.26856 iter/s, 7.88298s/10 iters), loss = 7.11697
I0524 01:43:41.309396 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11697 (* 1 = 7.11697 loss)
I0524 01:43:41.883114 11654 sgd_solver.cpp:112] Iteration 18730, lr = 0.1
I0524 01:43:50.067351 11654 solver.cpp:239] Iteration 18740 (1.14186 iter/s, 8.75762s/10 iters), loss = 7.58558
I0524 01:43:50.067638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58558 (* 1 = 7.58558 loss)
I0524 01:43:50.067699 11654 sgd_solver.cpp:112] Iteration 18740, lr = 0.1
I0524 01:43:57.606773 11654 solver.cpp:239] Iteration 18750 (1.32646 iter/s, 7.53885s/10 iters), loss = 6.03895
I0524 01:43:57.606837 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03895 (* 1 = 6.03895 loss)
I0524 01:43:57.607046 11654 sgd_solver.cpp:112] Iteration 18750, lr = 0.1
I0524 01:44:05.363225 11654 solver.cpp:239] Iteration 18760 (1.28931 iter/s, 7.7561s/10 iters), loss = 8.08486
I0524 01:44:05.363271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.08486 (* 1 = 8.08486 loss)
I0524 01:44:05.363284 11654 sgd_solver.cpp:112] Iteration 18760, lr = 0.1
I0524 01:44:11.679158 11654 solver.cpp:239] Iteration 18770 (1.58337 iter/s, 6.31564s/10 iters), loss = 7.69122
I0524 01:44:11.679211 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69122 (* 1 = 7.69122 loss)
I0524 01:44:11.679610 11654 sgd_solver.cpp:112] Iteration 18770, lr = 0.1
I0524 01:44:20.481457 11654 solver.cpp:239] Iteration 18780 (1.13612 iter/s, 8.80192s/10 iters), loss = 6.233
I0524 01:44:20.481604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.233 (* 1 = 6.233 loss)
I0524 01:44:20.481621 11654 sgd_solver.cpp:112] Iteration 18780, lr = 0.1
I0524 01:44:29.074434 11654 solver.cpp:239] Iteration 18790 (1.16411 iter/s, 8.59029s/10 iters), loss = 6.62926
I0524 01:44:29.074478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62926 (* 1 = 6.62926 loss)
I0524 01:44:29.074492 11654 sgd_solver.cpp:112] Iteration 18790, lr = 0.1
I0524 01:44:36.237705 11654 solver.cpp:239] Iteration 18800 (1.39651 iter/s, 7.16072s/10 iters), loss = 7.32356
I0524 01:44:36.237766 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32356 (* 1 = 7.32356 loss)
I0524 01:44:36.238195 11654 sgd_solver.cpp:112] Iteration 18800, lr = 0.1
I0524 01:44:43.274263 11654 solver.cpp:239] Iteration 18810 (1.42122 iter/s, 7.03623s/10 iters), loss = 6.82251
I0524 01:44:43.274317 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82251 (* 1 = 6.82251 loss)
I0524 01:44:43.347972 11654 sgd_solver.cpp:112] Iteration 18810, lr = 0.1
I0524 01:44:49.508247 11654 solver.cpp:239] Iteration 18820 (1.60419 iter/s, 6.23369s/10 iters), loss = 6.27215
I0524 01:44:49.508287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27215 (* 1 = 6.27215 loss)
I0524 01:44:49.508411 11654 sgd_solver.cpp:112] Iteration 18820, lr = 0.1
I0524 01:44:59.143524 11654 solver.cpp:239] Iteration 18830 (1.0379 iter/s, 9.63486s/10 iters), loss = 7.2297
I0524 01:44:59.143810 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2297 (* 1 = 7.2297 loss)
I0524 01:44:59.143872 11654 sgd_solver.cpp:112] Iteration 18830, lr = 0.1
I0524 01:45:06.206610 11654 solver.cpp:239] Iteration 18840 (1.41631 iter/s, 7.06061s/10 iters), loss = 7.38468
I0524 01:45:06.206660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.38468 (* 1 = 7.38468 loss)
I0524 01:45:06.207167 11654 sgd_solver.cpp:112] Iteration 18840, lr = 0.1
I0524 01:45:12.908849 11654 solver.cpp:239] Iteration 18850 (1.49212 iter/s, 6.70188s/10 iters), loss = 8.01911
I0524 01:45:12.908958 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.01911 (* 1 = 8.01911 loss)
I0524 01:45:12.909400 11654 sgd_solver.cpp:112] Iteration 18850, lr = 0.1
I0524 01:45:19.313114 11654 solver.cpp:239] Iteration 18860 (1.56154 iter/s, 6.40392s/10 iters), loss = 7.24719
I0524 01:45:19.313169 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24719 (* 1 = 7.24719 loss)
I0524 01:45:19.313535 11654 sgd_solver.cpp:112] Iteration 18860, lr = 0.1
I0524 01:45:26.223763 11654 solver.cpp:239] Iteration 18870 (1.44711 iter/s, 6.91032s/10 iters), loss = 7.26268
I0524 01:45:26.223817 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26268 (* 1 = 7.26268 loss)
I0524 01:45:26.226125 11654 sgd_solver.cpp:112] Iteration 18870, lr = 0.1
I0524 01:45:33.059278 11654 solver.cpp:239] Iteration 18880 (1.46302 iter/s, 6.83519s/10 iters), loss = 8.14485
I0524 01:45:33.059590 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.14485 (* 1 = 8.14485 loss)
I0524 01:45:33.059655 11654 sgd_solver.cpp:112] Iteration 18880, lr = 0.1
I0524 01:45:41.474148 11654 solver.cpp:239] Iteration 18890 (1.18846 iter/s, 8.41426s/10 iters), loss = 7.04329
I0524 01:45:41.474187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04329 (* 1 = 7.04329 loss)
I0524 01:45:41.474200 11654 sgd_solver.cpp:112] Iteration 18890, lr = 0.1
I0524 01:45:48.505086 11654 solver.cpp:239] Iteration 18900 (1.42236 iter/s, 7.03058s/10 iters), loss = 6.92223
I0524 01:45:48.505151 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92223 (* 1 = 6.92223 loss)
I0524 01:45:48.505563 11654 sgd_solver.cpp:112] Iteration 18900, lr = 0.1
I0524 01:45:54.957412 11654 solver.cpp:239] Iteration 18910 (1.5499 iter/s, 6.45202s/10 iters), loss = 6.33122
I0524 01:45:54.957464 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33122 (* 1 = 6.33122 loss)
I0524 01:45:54.961449 11654 sgd_solver.cpp:112] Iteration 18910, lr = 0.1
I0524 01:46:01.572108 11654 solver.cpp:239] Iteration 18920 (1.51186 iter/s, 6.61436s/10 iters), loss = 6.87526
I0524 01:46:01.572161 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87526 (* 1 = 6.87526 loss)
I0524 01:46:01.572698 11654 sgd_solver.cpp:112] Iteration 18920, lr = 0.1
I0524 01:46:07.526031 11654 solver.cpp:239] Iteration 18930 (1.67965 iter/s, 5.95363s/10 iters), loss = 6.97494
I0524 01:46:07.526180 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97494 (* 1 = 6.97494 loss)
I0524 01:46:07.526669 11654 sgd_solver.cpp:112] Iteration 18930, lr = 0.1
I0524 01:46:14.403738 11654 solver.cpp:239] Iteration 18940 (1.45406 iter/s, 6.87729s/10 iters), loss = 7.34456
I0524 01:46:14.403791 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.34456 (* 1 = 7.34456 loss)
I0524 01:46:14.403810 11654 sgd_solver.cpp:112] Iteration 18940, lr = 0.1
I0524 01:46:20.807003 11654 solver.cpp:239] Iteration 18950 (1.56177 iter/s, 6.40298s/10 iters), loss = 7.69368
I0524 01:46:20.807041 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69368 (* 1 = 7.69368 loss)
I0524 01:46:20.807152 11654 sgd_solver.cpp:112] Iteration 18950, lr = 0.1
I0524 01:46:27.959504 11654 solver.cpp:239] Iteration 18960 (1.39817 iter/s, 7.15218s/10 iters), loss = 7.25218
I0524 01:46:27.959558 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25218 (* 1 = 7.25218 loss)
I0524 01:46:27.964828 11654 sgd_solver.cpp:112] Iteration 18960, lr = 0.1
I0524 01:46:34.805665 11654 solver.cpp:239] Iteration 18970 (1.46074 iter/s, 6.84585s/10 iters), loss = 6.07116
I0524 01:46:34.805706 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07116 (* 1 = 6.07116 loss)
I0524 01:46:35.008637 11654 sgd_solver.cpp:112] Iteration 18970, lr = 0.1
I0524 01:46:42.288419 11654 solver.cpp:239] Iteration 18980 (1.33647 iter/s, 7.48242s/10 iters), loss = 7.29409
I0524 01:46:42.288666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29409 (* 1 = 7.29409 loss)
I0524 01:46:42.288714 11654 sgd_solver.cpp:112] Iteration 18980, lr = 0.1
I0524 01:46:49.971191 11654 solver.cpp:239] Iteration 18990 (1.30207 iter/s, 7.68011s/10 iters), loss = 7.59296
I0524 01:46:49.971231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59296 (* 1 = 7.59296 loss)
I0524 01:46:49.971367 11654 sgd_solver.cpp:112] Iteration 18990, lr = 0.1
I0524 01:46:58.432409 11654 solver.cpp:239] Iteration 19000 (1.18191 iter/s, 8.46085s/10 iters), loss = 6.75672
I0524 01:46:58.432461 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75672 (* 1 = 6.75672 loss)
I0524 01:46:58.432476 11654 sgd_solver.cpp:112] Iteration 19000, lr = 0.1
I0524 01:47:06.447235 11654 solver.cpp:239] Iteration 19010 (1.24774 iter/s, 8.01447s/10 iters), loss = 6.59969
I0524 01:47:06.447291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59969 (* 1 = 6.59969 loss)
I0524 01:47:06.447311 11654 sgd_solver.cpp:112] Iteration 19010, lr = 0.1
I0524 01:47:13.788666 11654 solver.cpp:239] Iteration 19020 (1.36221 iter/s, 7.34103s/10 iters), loss = 7.46945
I0524 01:47:13.788985 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.46945 (* 1 = 7.46945 loss)
I0524 01:47:14.078282 11654 sgd_solver.cpp:112] Iteration 19020, lr = 0.1
I0524 01:47:21.816855 11654 solver.cpp:239] Iteration 19030 (1.2457 iter/s, 8.02763s/10 iters), loss = 7.74897
I0524 01:47:21.816905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.74897 (* 1 = 7.74897 loss)
I0524 01:47:21.816922 11654 sgd_solver.cpp:112] Iteration 19030, lr = 0.1
I0524 01:47:28.414217 11654 solver.cpp:239] Iteration 19040 (1.51584 iter/s, 6.59699s/10 iters), loss = 6.63246
I0524 01:47:28.414255 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63246 (* 1 = 6.63246 loss)
I0524 01:47:28.414269 11654 sgd_solver.cpp:112] Iteration 19040, lr = 0.1
I0524 01:47:34.727821 11654 solver.cpp:239] Iteration 19050 (1.58397 iter/s, 6.31323s/10 iters), loss = 7.26239
I0524 01:47:34.727880 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26239 (* 1 = 7.26239 loss)
I0524 01:47:34.728428 11654 sgd_solver.cpp:112] Iteration 19050, lr = 0.1
I0524 01:47:41.079932 11654 solver.cpp:239] Iteration 19060 (1.57435 iter/s, 6.35181s/10 iters), loss = 6.69094
I0524 01:47:41.079991 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69094 (* 1 = 6.69094 loss)
I0524 01:47:41.083303 11654 sgd_solver.cpp:112] Iteration 19060, lr = 0.1
I0524 01:47:48.132004 11654 solver.cpp:239] Iteration 19070 (1.41809 iter/s, 7.05175s/10 iters), loss = 7.87043
I0524 01:47:48.132118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87043 (* 1 = 7.87043 loss)
I0524 01:47:48.316124 11654 sgd_solver.cpp:112] Iteration 19070, lr = 0.1
I0524 01:47:54.687820 11654 solver.cpp:239] Iteration 19080 (1.52545 iter/s, 6.55545s/10 iters), loss = 7.31615
I0524 01:47:54.687863 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31615 (* 1 = 7.31615 loss)
I0524 01:47:54.688072 11654 sgd_solver.cpp:112] Iteration 19080, lr = 0.1
I0524 01:48:01.847324 11654 solver.cpp:239] Iteration 19090 (1.39681 iter/s, 7.15919s/10 iters), loss = 7.10629
I0524 01:48:01.847367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10629 (* 1 = 7.10629 loss)
I0524 01:48:01.847378 11654 sgd_solver.cpp:112] Iteration 19090, lr = 0.1
I0524 01:48:08.797050 11654 solver.cpp:239] Iteration 19100 (1.43943 iter/s, 6.94719s/10 iters), loss = 8.51495
I0524 01:48:08.797103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.51495 (* 1 = 8.51495 loss)
I0524 01:48:09.238101 11654 sgd_solver.cpp:112] Iteration 19100, lr = 0.1
I0524 01:48:18.734993 11654 solver.cpp:239] Iteration 19110 (1.00629 iter/s, 9.93751s/10 iters), loss = 6.80411
I0524 01:48:18.735210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80411 (* 1 = 6.80411 loss)
I0524 01:48:18.735258 11654 sgd_solver.cpp:112] Iteration 19110, lr = 0.1
I0524 01:48:26.851047 11654 solver.cpp:239] Iteration 19120 (1.23221 iter/s, 8.11553s/10 iters), loss = 6.65609
I0524 01:48:26.851107 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65609 (* 1 = 6.65609 loss)
I0524 01:48:26.851291 11654 sgd_solver.cpp:112] Iteration 19120, lr = 0.1
I0524 01:48:33.816910 11654 solver.cpp:239] Iteration 19130 (1.43565 iter/s, 6.96549s/10 iters), loss = 6.72529
I0524 01:48:33.817005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72529 (* 1 = 6.72529 loss)
I0524 01:48:33.817224 11654 sgd_solver.cpp:112] Iteration 19130, lr = 0.1
I0524 01:48:40.386027 11654 solver.cpp:239] Iteration 19140 (1.52235 iter/s, 6.56878s/10 iters), loss = 6.97698
I0524 01:48:40.386087 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97698 (* 1 = 6.97698 loss)
I0524 01:48:40.386530 11654 sgd_solver.cpp:112] Iteration 19140, lr = 0.1
I0524 01:48:47.187144 11654 solver.cpp:239] Iteration 19150 (1.47042 iter/s, 6.8008s/10 iters), loss = 6.57012
I0524 01:48:47.187196 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57012 (* 1 = 6.57012 loss)
I0524 01:48:47.187350 11654 sgd_solver.cpp:112] Iteration 19150, lr = 0.1
I0524 01:48:54.740185 11654 solver.cpp:239] Iteration 19160 (1.32403 iter/s, 7.5527s/10 iters), loss = 6.83253
I0524 01:48:54.740392 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83253 (* 1 = 6.83253 loss)
I0524 01:48:54.740418 11654 sgd_solver.cpp:112] Iteration 19160, lr = 0.1
I0524 01:49:01.186292 11654 solver.cpp:239] Iteration 19170 (1.55144 iter/s, 6.44564s/10 iters), loss = 6.55269
I0524 01:49:01.186345 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55269 (* 1 = 6.55269 loss)
I0524 01:49:01.880939 11654 sgd_solver.cpp:112] Iteration 19170, lr = 0.1
I0524 01:49:10.291878 11654 solver.cpp:239] Iteration 19180 (1.09828 iter/s, 9.10518s/10 iters), loss = 6.92941
I0524 01:49:10.291944 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92941 (* 1 = 6.92941 loss)
I0524 01:49:10.291962 11654 sgd_solver.cpp:112] Iteration 19180, lr = 0.1
I0524 01:49:18.169395 11654 solver.cpp:239] Iteration 19190 (1.26984 iter/s, 7.87501s/10 iters), loss = 6.40552
I0524 01:49:18.169461 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40552 (* 1 = 6.40552 loss)
I0524 01:49:18.191208 11654 sgd_solver.cpp:112] Iteration 19190, lr = 0.1
I0524 01:49:25.475177 11654 solver.cpp:239] Iteration 19200 (1.36884 iter/s, 7.30544s/10 iters), loss = 6.99477
I0524 01:49:25.475364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99477 (* 1 = 6.99477 loss)
I0524 01:49:26.481295 11654 sgd_solver.cpp:112] Iteration 19200, lr = 0.1
I0524 01:49:33.501353 11654 solver.cpp:239] Iteration 19210 (1.24599 iter/s, 8.02573s/10 iters), loss = 8.28922
I0524 01:49:33.501394 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.28922 (* 1 = 8.28922 loss)
I0524 01:49:33.512825 11654 sgd_solver.cpp:112] Iteration 19210, lr = 0.1
I0524 01:49:40.302404 11654 solver.cpp:239] Iteration 19220 (1.47043 iter/s, 6.80074s/10 iters), loss = 7.31954
I0524 01:49:40.302456 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31954 (* 1 = 7.31954 loss)
I0524 01:49:40.302640 11654 sgd_solver.cpp:112] Iteration 19220, lr = 0.1
I0524 01:49:47.424206 11654 solver.cpp:239] Iteration 19230 (1.40421 iter/s, 7.12147s/10 iters), loss = 7.48007
I0524 01:49:47.424278 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48007 (* 1 = 7.48007 loss)
I0524 01:49:47.424500 11654 sgd_solver.cpp:112] Iteration 19230, lr = 0.1
I0524 01:49:53.720774 11654 solver.cpp:239] Iteration 19240 (1.58825 iter/s, 6.29626s/10 iters), loss = 7.58786
I0524 01:49:53.720832 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58786 (* 1 = 7.58786 loss)
I0524 01:49:53.721223 11654 sgd_solver.cpp:112] Iteration 19240, lr = 0.1
I0524 01:50:01.471654 11654 solver.cpp:239] Iteration 19250 (1.29023 iter/s, 7.75053s/10 iters), loss = 8.95836
I0524 01:50:01.471946 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.95836 (* 1 = 8.95836 loss)
I0524 01:50:01.471997 11654 sgd_solver.cpp:112] Iteration 19250, lr = 0.1
I0524 01:50:07.797933 11654 solver.cpp:239] Iteration 19260 (1.58135 iter/s, 6.32373s/10 iters), loss = 7.68166
I0524 01:50:07.797993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.68166 (* 1 = 7.68166 loss)
I0524 01:50:07.798370 11654 sgd_solver.cpp:112] Iteration 19260, lr = 0.1
I0524 01:50:15.164485 11654 solver.cpp:239] Iteration 19270 (1.35755 iter/s, 7.36621s/10 iters), loss = 7.6118
I0524 01:50:15.164551 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.6118 (* 1 = 7.6118 loss)
I0524 01:50:15.164697 11654 sgd_solver.cpp:112] Iteration 19270, lr = 0.1
I0524 01:50:21.376322 11654 solver.cpp:239] Iteration 19280 (1.60991 iter/s, 6.21154s/10 iters), loss = 6.76044
I0524 01:50:21.376369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76044 (* 1 = 6.76044 loss)
I0524 01:50:21.515739 11654 sgd_solver.cpp:112] Iteration 19280, lr = 0.1
I0524 01:50:30.012300 11654 solver.cpp:239] Iteration 19290 (1.158 iter/s, 8.63559s/10 iters), loss = 6.59098
I0524 01:50:30.012358 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59098 (* 1 = 6.59098 loss)
I0524 01:50:31.090378 11654 sgd_solver.cpp:112] Iteration 19290, lr = 0.1
I0524 01:50:38.229112 11654 solver.cpp:239] Iteration 19300 (1.21707 iter/s, 8.21644s/10 iters), loss = 6.74148
I0524 01:50:38.229394 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74148 (* 1 = 6.74148 loss)
I0524 01:50:38.229442 11654 sgd_solver.cpp:112] Iteration 19300, lr = 0.1
I0524 01:50:45.868592 11654 solver.cpp:239] Iteration 19310 (1.30908 iter/s, 7.63893s/10 iters), loss = 6.82539
I0524 01:50:45.868630 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82539 (* 1 = 6.82539 loss)
I0524 01:50:45.868643 11654 sgd_solver.cpp:112] Iteration 19310, lr = 0.1
I0524 01:50:53.902073 11654 solver.cpp:239] Iteration 19320 (1.24485 iter/s, 8.03312s/10 iters), loss = 6.30896
I0524 01:50:53.902138 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30896 (* 1 = 6.30896 loss)
I0524 01:50:53.902601 11654 sgd_solver.cpp:112] Iteration 19320, lr = 0.1
I0524 01:51:01.584086 11654 solver.cpp:239] Iteration 19330 (1.3018 iter/s, 7.68165s/10 iters), loss = 6.45902
I0524 01:51:01.584149 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45902 (* 1 = 6.45902 loss)
I0524 01:51:01.584213 11654 sgd_solver.cpp:112] Iteration 19330, lr = 0.1
I0524 01:51:07.803340 11654 solver.cpp:239] Iteration 19340 (1.60799 iter/s, 6.21895s/10 iters), loss = 7.54534
I0524 01:51:07.803395 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54534 (* 1 = 7.54534 loss)
I0524 01:51:07.803660 11654 sgd_solver.cpp:112] Iteration 19340, lr = 0.1
I0524 01:51:14.815347 11654 solver.cpp:239] Iteration 19350 (1.42619 iter/s, 7.01169s/10 iters), loss = 7.5276
I0524 01:51:14.815531 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.5276 (* 1 = 7.5276 loss)
I0524 01:51:14.815584 11654 sgd_solver.cpp:112] Iteration 19350, lr = 0.1
I0524 01:51:21.699703 11654 solver.cpp:239] Iteration 19360 (1.45265 iter/s, 6.88395s/10 iters), loss = 6.97724
I0524 01:51:21.699755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97724 (* 1 = 6.97724 loss)
I0524 01:51:22.619920 11654 sgd_solver.cpp:112] Iteration 19360, lr = 0.1
I0524 01:51:29.238646 11654 solver.cpp:239] Iteration 19370 (1.3265 iter/s, 7.53861s/10 iters), loss = 6.33583
I0524 01:51:29.238682 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33583 (* 1 = 6.33583 loss)
I0524 01:51:29.238714 11654 sgd_solver.cpp:112] Iteration 19370, lr = 0.1
I0524 01:51:36.037284 11654 solver.cpp:239] Iteration 19380 (1.47095 iter/s, 6.79833s/10 iters), loss = 7.9304
I0524 01:51:36.037336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9304 (* 1 = 7.9304 loss)
I0524 01:51:36.037351 11654 sgd_solver.cpp:112] Iteration 19380, lr = 0.1
I0524 01:51:44.201411 11654 solver.cpp:239] Iteration 19390 (1.22493 iter/s, 8.16376s/10 iters), loss = 7.03505
I0524 01:51:44.201468 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03505 (* 1 = 7.03505 loss)
I0524 01:51:44.201524 11654 sgd_solver.cpp:112] Iteration 19390, lr = 0.1
I0524 01:51:50.755659 11654 solver.cpp:239] Iteration 19400 (1.5258 iter/s, 6.55395s/10 iters), loss = 6.77188
I0524 01:51:50.755918 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77188 (* 1 = 6.77188 loss)
I0524 01:51:50.755977 11654 sgd_solver.cpp:112] Iteration 19400, lr = 0.1
I0524 01:51:58.942154 11654 solver.cpp:239] Iteration 19410 (1.2219 iter/s, 8.18397s/10 iters), loss = 6.77754
I0524 01:51:58.942209 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77754 (* 1 = 6.77754 loss)
I0524 01:51:58.942224 11654 sgd_solver.cpp:112] Iteration 19410, lr = 0.1
I0524 01:52:06.819097 11654 solver.cpp:239] Iteration 19420 (1.2696 iter/s, 7.87651s/10 iters), loss = 6.56535
I0524 01:52:06.819154 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56535 (* 1 = 6.56535 loss)
I0524 01:52:06.821848 11654 sgd_solver.cpp:112] Iteration 19420, lr = 0.1
I0524 01:52:15.215692 11654 solver.cpp:239] Iteration 19430 (1.19101 iter/s, 8.39622s/10 iters), loss = 6.74465
I0524 01:52:15.215747 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74465 (* 1 = 6.74465 loss)
I0524 01:52:15.215965 11654 sgd_solver.cpp:112] Iteration 19430, lr = 0.1
I0524 01:52:21.232980 11654 solver.cpp:239] Iteration 19440 (1.66196 iter/s, 6.01701s/10 iters), loss = 6.4301
I0524 01:52:21.233104 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4301 (* 1 = 6.4301 loss)
I0524 01:52:21.233132 11654 sgd_solver.cpp:112] Iteration 19440, lr = 0.1
I0524 01:52:27.297322 11654 solver.cpp:239] Iteration 19450 (1.64911 iter/s, 6.06387s/10 iters), loss = 7.95596
I0524 01:52:27.297377 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.95596 (* 1 = 7.95596 loss)
I0524 01:52:27.306161 11654 sgd_solver.cpp:112] Iteration 19450, lr = 0.1
I0524 01:52:33.796568 11654 solver.cpp:239] Iteration 19460 (1.53871 iter/s, 6.49895s/10 iters), loss = 6.39488
I0524 01:52:33.796612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39488 (* 1 = 6.39488 loss)
I0524 01:52:33.796764 11654 sgd_solver.cpp:112] Iteration 19460, lr = 0.1
I0524 01:52:42.652639 11654 solver.cpp:239] Iteration 19470 (1.12922 iter/s, 8.85569s/10 iters), loss = 6.29275
I0524 01:52:42.652694 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29275 (* 1 = 6.29275 loss)
I0524 01:52:43.365931 11654 sgd_solver.cpp:112] Iteration 19470, lr = 0.1
I0524 01:52:50.019543 11654 solver.cpp:239] Iteration 19480 (1.35748 iter/s, 7.36657s/10 iters), loss = 6.01416
I0524 01:52:50.019598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01416 (* 1 = 6.01416 loss)
I0524 01:52:50.019800 11654 sgd_solver.cpp:112] Iteration 19480, lr = 0.1
I0524 01:52:57.708794 11654 solver.cpp:239] Iteration 19490 (1.30057 iter/s, 7.68891s/10 iters), loss = 7.87665
I0524 01:52:57.709053 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.87665 (* 1 = 7.87665 loss)
I0524 01:52:57.709116 11654 sgd_solver.cpp:112] Iteration 19490, lr = 0.1
I0524 01:53:05.933682 11654 solver.cpp:239] Iteration 19500 (1.2162 iter/s, 8.2223s/10 iters), loss = 6.72181
I0524 01:53:05.933733 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72181 (* 1 = 6.72181 loss)
I0524 01:53:05.933749 11654 sgd_solver.cpp:112] Iteration 19500, lr = 0.1
I0524 01:53:12.714267 11654 solver.cpp:239] Iteration 19510 (1.47487 iter/s, 6.78027s/10 iters), loss = 6.89986
I0524 01:53:12.714323 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89986 (* 1 = 6.89986 loss)
I0524 01:53:12.714555 11654 sgd_solver.cpp:112] Iteration 19510, lr = 0.1
I0524 01:53:19.883042 11654 solver.cpp:239] Iteration 19520 (1.395 iter/s, 7.16845s/10 iters), loss = 7.13936
I0524 01:53:19.883100 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13936 (* 1 = 7.13936 loss)
I0524 01:53:20.247673 11654 sgd_solver.cpp:112] Iteration 19520, lr = 0.1
I0524 01:53:27.856115 11654 solver.cpp:239] Iteration 19530 (1.25428 iter/s, 7.97271s/10 iters), loss = 7.72513
I0524 01:53:27.856359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.72513 (* 1 = 7.72513 loss)
I0524 01:53:27.856415 11654 sgd_solver.cpp:112] Iteration 19530, lr = 0.1
I0524 01:53:34.288550 11654 solver.cpp:239] Iteration 19540 (1.55522 iter/s, 6.42994s/10 iters), loss = 6.84247
I0524 01:53:34.288605 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84247 (* 1 = 6.84247 loss)
I0524 01:53:34.289000 11654 sgd_solver.cpp:112] Iteration 19540, lr = 0.1
I0524 01:53:42.857995 11654 solver.cpp:239] Iteration 19550 (1.16699 iter/s, 8.56905s/10 iters), loss = 7.04488
I0524 01:53:42.858045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04488 (* 1 = 7.04488 loss)
I0524 01:53:43.417412 11654 sgd_solver.cpp:112] Iteration 19550, lr = 0.1
I0524 01:53:50.153369 11654 solver.cpp:239] Iteration 19560 (1.37079 iter/s, 7.29504s/10 iters), loss = 6.98631
I0524 01:53:50.153432 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98631 (* 1 = 6.98631 loss)
I0524 01:53:50.171510 11654 sgd_solver.cpp:112] Iteration 19560, lr = 0.1
I0524 01:53:56.456849 11654 solver.cpp:239] Iteration 19570 (1.5865 iter/s, 6.30318s/10 iters), loss = 6.88085
I0524 01:53:56.456903 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88085 (* 1 = 6.88085 loss)
I0524 01:53:57.272346 11654 sgd_solver.cpp:112] Iteration 19570, lr = 0.1
I0524 01:54:03.871454 11654 solver.cpp:239] Iteration 19580 (1.34875 iter/s, 7.41427s/10 iters), loss = 5.92119
I0524 01:54:03.871726 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92119 (* 1 = 5.92119 loss)
I0524 01:54:04.042052 11654 sgd_solver.cpp:112] Iteration 19580, lr = 0.1
I0524 01:54:10.526670 11654 solver.cpp:239] Iteration 19590 (1.50269 iter/s, 6.65472s/10 iters), loss = 7.31142
I0524 01:54:10.526751 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31142 (* 1 = 7.31142 loss)
I0524 01:54:10.526842 11654 sgd_solver.cpp:112] Iteration 19590, lr = 0.1
I0524 01:54:17.209126 11654 solver.cpp:239] Iteration 19600 (1.49653 iter/s, 6.68214s/10 iters), loss = 6.96144
I0524 01:54:17.209167 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96144 (* 1 = 6.96144 loss)
I0524 01:54:17.209337 11654 sgd_solver.cpp:112] Iteration 19600, lr = 0.1
I0524 01:54:23.779958 11654 solver.cpp:239] Iteration 19610 (1.52195 iter/s, 6.57053s/10 iters), loss = 6.6571
I0524 01:54:23.780017 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6571 (* 1 = 6.6571 loss)
I0524 01:54:23.780036 11654 sgd_solver.cpp:112] Iteration 19610, lr = 0.1
I0524 01:54:31.141095 11654 solver.cpp:239] Iteration 19620 (1.35855 iter/s, 7.3608s/10 iters), loss = 6.63072
I0524 01:54:31.141146 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63072 (* 1 = 6.63072 loss)
I0524 01:54:31.209950 11654 sgd_solver.cpp:112] Iteration 19620, lr = 0.1
I0524 01:54:37.940033 11654 solver.cpp:239] Iteration 19630 (1.47089 iter/s, 6.79862s/10 iters), loss = 7.04528
I0524 01:54:37.940320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04528 (* 1 = 7.04528 loss)
I0524 01:54:37.940485 11654 sgd_solver.cpp:112] Iteration 19630, lr = 0.1
I0524 01:54:46.164577 11654 solver.cpp:239] Iteration 19640 (1.21595 iter/s, 8.22402s/10 iters), loss = 6.8439
I0524 01:54:46.164618 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8439 (* 1 = 6.8439 loss)
I0524 01:54:47.174294 11654 sgd_solver.cpp:112] Iteration 19640, lr = 0.1
I0524 01:54:54.853474 11654 solver.cpp:239] Iteration 19650 (1.15095 iter/s, 8.68851s/10 iters), loss = 6.50584
I0524 01:54:54.853536 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50584 (* 1 = 6.50584 loss)
I0524 01:54:54.853605 11654 sgd_solver.cpp:112] Iteration 19650, lr = 0.1
I0524 01:55:01.073077 11654 solver.cpp:239] Iteration 19660 (1.60789 iter/s, 6.21931s/10 iters), loss = 6.39725
I0524 01:55:01.073124 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39725 (* 1 = 6.39725 loss)
I0524 01:55:01.073140 11654 sgd_solver.cpp:112] Iteration 19660, lr = 0.1
I0524 01:55:07.284540 11654 solver.cpp:239] Iteration 19670 (1.61002 iter/s, 6.2111s/10 iters), loss = 7.28149
I0524 01:55:07.284591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28149 (* 1 = 7.28149 loss)
I0524 01:55:07.284832 11654 sgd_solver.cpp:112] Iteration 19670, lr = 0.1
I0524 01:55:13.704309 11654 solver.cpp:239] Iteration 19680 (1.55776 iter/s, 6.41947s/10 iters), loss = 7.9817
I0524 01:55:13.704524 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9817 (* 1 = 7.9817 loss)
I0524 01:55:13.704581 11654 sgd_solver.cpp:112] Iteration 19680, lr = 0.1
I0524 01:55:21.183497 11654 solver.cpp:239] Iteration 19690 (1.33719 iter/s, 7.4784s/10 iters), loss = 7.89975
I0524 01:55:21.183542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89975 (* 1 = 7.89975 loss)
I0524 01:55:21.183670 11654 sgd_solver.cpp:112] Iteration 19690, lr = 0.1
I0524 01:55:28.472731 11654 solver.cpp:239] Iteration 19700 (1.37195 iter/s, 7.2889s/10 iters), loss = 7.68237
I0524 01:55:28.472780 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.68237 (* 1 = 7.68237 loss)
I0524 01:55:28.645114 11654 sgd_solver.cpp:112] Iteration 19700, lr = 0.1
I0524 01:55:36.439478 11654 solver.cpp:239] Iteration 19710 (1.25527 iter/s, 7.96639s/10 iters), loss = 7.97047
I0524 01:55:36.439532 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.97047 (* 1 = 7.97047 loss)
I0524 01:55:36.443943 11654 sgd_solver.cpp:112] Iteration 19710, lr = 0.1
I0524 01:55:44.245488 11654 solver.cpp:239] Iteration 19720 (1.28112 iter/s, 7.80566s/10 iters), loss = 7.57123
I0524 01:55:44.245654 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.57123 (* 1 = 7.57123 loss)
I0524 01:55:44.245678 11654 sgd_solver.cpp:112] Iteration 19720, lr = 0.1
I0524 01:55:51.268514 11654 solver.cpp:239] Iteration 19730 (1.4244 iter/s, 7.0205s/10 iters), loss = 6.61603
I0524 01:55:51.268565 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61603 (* 1 = 6.61603 loss)
I0524 01:55:51.268581 11654 sgd_solver.cpp:112] Iteration 19730, lr = 0.1
I0524 01:55:57.757747 11654 solver.cpp:239] Iteration 19740 (1.54109 iter/s, 6.48893s/10 iters), loss = 7.40032
I0524 01:55:57.757807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40032 (* 1 = 7.40032 loss)
I0524 01:55:57.758280 11654 sgd_solver.cpp:112] Iteration 19740, lr = 0.1
I0524 01:56:04.131181 11654 solver.cpp:239] Iteration 19750 (1.56909 iter/s, 6.37313s/10 iters), loss = 6.98866
I0524 01:56:04.131233 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98866 (* 1 = 6.98866 loss)
I0524 01:56:04.484685 11654 sgd_solver.cpp:112] Iteration 19750, lr = 0.1
I0524 01:56:10.792448 11654 solver.cpp:239] Iteration 19760 (1.50128 iter/s, 6.66096s/10 iters), loss = 6.57351
I0524 01:56:10.792487 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57351 (* 1 = 6.57351 loss)
I0524 01:56:10.798750 11654 sgd_solver.cpp:112] Iteration 19760, lr = 0.1
I0524 01:56:16.944104 11654 solver.cpp:239] Iteration 19770 (1.62565 iter/s, 6.15138s/10 iters), loss = 7.02805
I0524 01:56:16.944252 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02805 (* 1 = 7.02805 loss)
I0524 01:56:16.944267 11654 sgd_solver.cpp:112] Iteration 19770, lr = 0.1
I0524 01:56:24.176182 11654 solver.cpp:239] Iteration 19780 (1.38282 iter/s, 7.23162s/10 iters), loss = 8.13937
I0524 01:56:24.176234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.13937 (* 1 = 8.13937 loss)
I0524 01:56:24.176249 11654 sgd_solver.cpp:112] Iteration 19780, lr = 0.1
I0524 01:56:32.486752 11654 solver.cpp:239] Iteration 19790 (1.20334 iter/s, 8.3102s/10 iters), loss = 5.70154
I0524 01:56:32.486807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70154 (* 1 = 5.70154 loss)
I0524 01:56:32.486824 11654 sgd_solver.cpp:112] Iteration 19790, lr = 0.1
I0524 01:56:40.180935 11654 solver.cpp:239] Iteration 19800 (1.29975 iter/s, 7.69378s/10 iters), loss = 6.70286
I0524 01:56:40.180989 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70286 (* 1 = 6.70286 loss)
I0524 01:56:40.182775 11654 sgd_solver.cpp:112] Iteration 19800, lr = 0.1
I0524 01:56:46.677747 11654 solver.cpp:239] Iteration 19810 (1.53929 iter/s, 6.49651s/10 iters), loss = 7.17448
I0524 01:56:46.677795 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17448 (* 1 = 7.17448 loss)
I0524 01:56:46.677991 11654 sgd_solver.cpp:112] Iteration 19810, lr = 0.1
I0524 01:56:52.984995 11654 solver.cpp:239] Iteration 19820 (1.58555 iter/s, 6.30695s/10 iters), loss = 5.82117
I0524 01:56:52.985244 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82117 (* 1 = 5.82117 loss)
I0524 01:56:52.985299 11654 sgd_solver.cpp:112] Iteration 19820, lr = 0.1
I0524 01:57:02.334844 11654 solver.cpp:239] Iteration 19830 (1.06961 iter/s, 9.34923s/10 iters), loss = 7.19474
I0524 01:57:02.334897 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19474 (* 1 = 7.19474 loss)
I0524 01:57:02.335091 11654 sgd_solver.cpp:112] Iteration 19830, lr = 0.1
I0524 01:57:09.193565 11654 solver.cpp:239] Iteration 19840 (1.45806 iter/s, 6.85841s/10 iters), loss = 7.43462
I0524 01:57:09.193606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43462 (* 1 = 7.43462 loss)
I0524 01:57:09.193619 11654 sgd_solver.cpp:112] Iteration 19840, lr = 0.1
I0524 01:57:15.424144 11654 solver.cpp:239] Iteration 19850 (1.60508 iter/s, 6.23023s/10 iters), loss = 6.89393
I0524 01:57:15.424194 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89393 (* 1 = 6.89393 loss)
I0524 01:57:15.424774 11654 sgd_solver.cpp:112] Iteration 19850, lr = 0.1
I0524 01:57:22.635753 11654 solver.cpp:239] Iteration 19860 (1.38672 iter/s, 7.21128s/10 iters), loss = 7.39448
I0524 01:57:22.635802 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39448 (* 1 = 7.39448 loss)
I0524 01:57:22.635821 11654 sgd_solver.cpp:112] Iteration 19860, lr = 0.1
I0524 01:57:30.046587 11654 solver.cpp:239] Iteration 19870 (1.34984 iter/s, 7.40826s/10 iters), loss = 6.09109
I0524 01:57:30.046761 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09109 (* 1 = 6.09109 loss)
I0524 01:57:30.046782 11654 sgd_solver.cpp:112] Iteration 19870, lr = 0.1
I0524 01:57:36.540117 11654 solver.cpp:239] Iteration 19880 (1.5401 iter/s, 6.49309s/10 iters), loss = 7.14277
I0524 01:57:36.540158 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14277 (* 1 = 7.14277 loss)
I0524 01:57:36.540184 11654 sgd_solver.cpp:112] Iteration 19880, lr = 0.1
I0524 01:57:43.213282 11654 solver.cpp:239] Iteration 19890 (1.49861 iter/s, 6.67287s/10 iters), loss = 6.76939
I0524 01:57:43.213320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76939 (* 1 = 6.76939 loss)
I0524 01:57:43.213351 11654 sgd_solver.cpp:112] Iteration 19890, lr = 0.1
I0524 01:57:49.766533 11654 solver.cpp:239] Iteration 19900 (1.52603 iter/s, 6.55295s/10 iters), loss = 6.13817
I0524 01:57:49.766595 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13817 (* 1 = 6.13817 loss)
I0524 01:57:49.766832 11654 sgd_solver.cpp:112] Iteration 19900, lr = 0.1
I0524 01:57:56.168961 11654 solver.cpp:239] Iteration 19910 (1.56198 iter/s, 6.40213s/10 iters), loss = 6.87189
I0524 01:57:56.169005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87189 (* 1 = 6.87189 loss)
I0524 01:57:56.170047 11654 sgd_solver.cpp:112] Iteration 19910, lr = 0.1
I0524 01:58:02.791105 11654 solver.cpp:239] Iteration 19920 (1.51021 iter/s, 6.62161s/10 iters), loss = 6.15657
I0524 01:58:02.791234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15657 (* 1 = 6.15657 loss)
I0524 01:58:02.791251 11654 sgd_solver.cpp:112] Iteration 19920, lr = 0.1
I0524 01:58:11.084623 11654 solver.cpp:239] Iteration 19930 (1.20585 iter/s, 8.29288s/10 iters), loss = 6.58066
I0524 01:58:11.084686 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58066 (* 1 = 6.58066 loss)
I0524 01:58:11.084760 11654 sgd_solver.cpp:112] Iteration 19930, lr = 0.1
I0524 01:58:18.768293 11654 solver.cpp:239] Iteration 19940 (1.30152 iter/s, 7.68332s/10 iters), loss = 6.52967
I0524 01:58:18.768347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52967 (* 1 = 6.52967 loss)
I0524 01:58:18.768515 11654 sgd_solver.cpp:112] Iteration 19940, lr = 0.1
I0524 01:58:26.299556 11654 solver.cpp:239] Iteration 19950 (1.32786 iter/s, 7.53093s/10 iters), loss = 6.78355
I0524 01:58:26.299607 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78355 (* 1 = 6.78355 loss)
I0524 01:58:26.299621 11654 sgd_solver.cpp:112] Iteration 19950, lr = 0.1
I0524 01:58:33.203558 11654 solver.cpp:239] Iteration 19960 (1.4485 iter/s, 6.90369s/10 iters), loss = 6.82087
I0524 01:58:33.203801 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82087 (* 1 = 6.82087 loss)
I0524 01:58:33.203851 11654 sgd_solver.cpp:112] Iteration 19960, lr = 0.1
I0524 01:58:39.318110 11654 solver.cpp:239] Iteration 19970 (1.63557 iter/s, 6.11408s/10 iters), loss = 7.7513
I0524 01:58:39.318169 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.7513 (* 1 = 7.7513 loss)
I0524 01:58:39.318634 11654 sgd_solver.cpp:112] Iteration 19970, lr = 0.1
I0524 01:58:46.310536 11654 solver.cpp:239] Iteration 19980 (1.43018 iter/s, 6.9921s/10 iters), loss = 6.89834
I0524 01:58:46.310593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89834 (* 1 = 6.89834 loss)
I0524 01:58:46.319267 11654 sgd_solver.cpp:112] Iteration 19980, lr = 0.1
I0524 01:58:53.138789 11654 solver.cpp:239] Iteration 19990 (1.46457 iter/s, 6.82794s/10 iters), loss = 7.1264
I0524 01:58:53.138844 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1264 (* 1 = 7.1264 loss)
I0524 01:58:53.138860 11654 sgd_solver.cpp:112] Iteration 19990, lr = 0.1
I0524 01:59:02.582024 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_20000.caffemodel
I0524 01:59:03.635144 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_20000.solverstate
I0524 01:59:04.212028 11654 solver.cpp:239] Iteration 20000 (0.903299 iter/s, 11.0705s/10 iters), loss = 6.7641
I0524 01:59:04.212074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7641 (* 1 = 6.7641 loss)
I0524 01:59:04.212342 11654 sgd_solver.cpp:112] Iteration 20000, lr = 0.1
I0524 01:59:10.618659 11654 solver.cpp:239] Iteration 20010 (1.56095 iter/s, 6.40634s/10 iters), loss = 5.88979
I0524 01:59:10.618721 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88979 (* 1 = 5.88979 loss)
I0524 01:59:10.618903 11654 sgd_solver.cpp:112] Iteration 20010, lr = 0.1
I0524 01:59:17.597442 11654 solver.cpp:239] Iteration 20020 (1.43298 iter/s, 6.97847s/10 iters), loss = 7.43928
I0524 01:59:17.597501 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43928 (* 1 = 7.43928 loss)
I0524 01:59:17.597515 11654 sgd_solver.cpp:112] Iteration 20020, lr = 0.1
I0524 01:59:24.315187 11654 solver.cpp:239] Iteration 20030 (1.48866 iter/s, 6.71744s/10 iters), loss = 6.30639
I0524 01:59:24.315237 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30639 (* 1 = 6.30639 loss)
I0524 01:59:24.316320 11654 sgd_solver.cpp:112] Iteration 20030, lr = 0.1
I0524 01:59:30.193557 11654 solver.cpp:239] Iteration 20040 (1.70124 iter/s, 5.87807s/10 iters), loss = 7.90444
I0524 01:59:30.193619 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90444 (* 1 = 7.90444 loss)
I0524 01:59:30.193836 11654 sgd_solver.cpp:112] Iteration 20040, lr = 0.1
I0524 01:59:36.693895 11654 solver.cpp:239] Iteration 20050 (1.53845 iter/s, 6.50003s/10 iters), loss = 7.0208
I0524 01:59:36.694139 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0208 (* 1 = 7.0208 loss)
I0524 01:59:36.694190 11654 sgd_solver.cpp:112] Iteration 20050, lr = 0.1
I0524 01:59:43.624825 11654 solver.cpp:239] Iteration 20060 (1.44295 iter/s, 6.93025s/10 iters), loss = 6.65724
I0524 01:59:43.624873 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65724 (* 1 = 6.65724 loss)
I0524 01:59:43.624979 11654 sgd_solver.cpp:112] Iteration 20060, lr = 0.1
I0524 01:59:51.534018 11654 solver.cpp:239] Iteration 20070 (1.26441 iter/s, 7.90885s/10 iters), loss = 7.14506
I0524 01:59:51.534073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14506 (* 1 = 7.14506 loss)
I0524 01:59:51.536285 11654 sgd_solver.cpp:112] Iteration 20070, lr = 0.1
I0524 01:59:59.167726 11654 solver.cpp:239] Iteration 20080 (1.31004 iter/s, 7.63336s/10 iters), loss = 7.66951
I0524 01:59:59.167788 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66951 (* 1 = 7.66951 loss)
I0524 01:59:59.167804 11654 sgd_solver.cpp:112] Iteration 20080, lr = 0.1
I0524 02:00:06.236331 11654 solver.cpp:239] Iteration 20090 (1.41482 iter/s, 7.06803s/10 iters), loss = 8.17119
I0524 02:00:06.236373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.17119 (* 1 = 8.17119 loss)
I0524 02:00:07.116068 11654 sgd_solver.cpp:112] Iteration 20090, lr = 0.1
I0524 02:00:15.352638 11654 solver.cpp:239] Iteration 20100 (1.09698 iter/s, 9.11591s/10 iters), loss = 6.857
I0524 02:00:15.352689 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.857 (* 1 = 6.857 loss)
I0524 02:00:15.352705 11654 sgd_solver.cpp:112] Iteration 20100, lr = 0.1
I0524 02:00:22.510051 11654 solver.cpp:239] Iteration 20110 (1.39722 iter/s, 7.15708s/10 iters), loss = 8.74896
I0524 02:00:22.510105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.74896 (* 1 = 8.74896 loss)
I0524 02:00:22.777952 11654 sgd_solver.cpp:112] Iteration 20110, lr = 0.1
I0524 02:00:29.508997 11654 solver.cpp:239] Iteration 20120 (1.42885 iter/s, 6.99863s/10 iters), loss = 7.35787
I0524 02:00:29.509047 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.35787 (* 1 = 7.35787 loss)
I0524 02:00:29.509065 11654 sgd_solver.cpp:112] Iteration 20120, lr = 0.1
I0524 02:00:38.937222 11654 solver.cpp:239] Iteration 20130 (1.0607 iter/s, 9.42774s/10 iters), loss = 7.14958
I0524 02:00:38.937495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14958 (* 1 = 7.14958 loss)
I0524 02:00:39.117141 11654 sgd_solver.cpp:112] Iteration 20130, lr = 0.1
I0524 02:00:46.114143 11654 solver.cpp:239] Iteration 20140 (1.39345 iter/s, 7.17643s/10 iters), loss = 6.66985
I0524 02:00:46.114182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66985 (* 1 = 6.66985 loss)
I0524 02:00:46.114261 11654 sgd_solver.cpp:112] Iteration 20140, lr = 0.1
I0524 02:00:52.241470 11654 solver.cpp:239] Iteration 20150 (1.63211 iter/s, 6.12703s/10 iters), loss = 7.51221
I0524 02:00:52.241525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51221 (* 1 = 7.51221 loss)
I0524 02:00:52.241798 11654 sgd_solver.cpp:112] Iteration 20150, lr = 0.1
I0524 02:00:58.605350 11654 solver.cpp:239] Iteration 20160 (1.57144 iter/s, 6.36359s/10 iters), loss = 7.67347
I0524 02:00:58.605397 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.67347 (* 1 = 7.67347 loss)
I0524 02:00:58.605554 11654 sgd_solver.cpp:112] Iteration 20160, lr = 0.1
I0524 02:01:05.205793 11654 solver.cpp:239] Iteration 20170 (1.51512 iter/s, 6.60014s/10 iters), loss = 6.95119
I0524 02:01:05.205847 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95119 (* 1 = 6.95119 loss)
I0524 02:01:05.205862 11654 sgd_solver.cpp:112] Iteration 20170, lr = 0.1
I0524 02:01:11.391623 11654 solver.cpp:239] Iteration 20180 (1.61669 iter/s, 6.18547s/10 iters), loss = 6.03243
I0524 02:01:11.391731 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03243 (* 1 = 6.03243 loss)
I0524 02:01:11.901409 11654 sgd_solver.cpp:112] Iteration 20180, lr = 0.1
I0524 02:01:18.541209 11654 solver.cpp:239] Iteration 20190 (1.39876 iter/s, 7.14921s/10 iters), loss = 7.39761
I0524 02:01:18.541257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39761 (* 1 = 7.39761 loss)
I0524 02:01:18.543220 11654 sgd_solver.cpp:112] Iteration 20190, lr = 0.1
I0524 02:01:25.349059 11654 solver.cpp:239] Iteration 20200 (1.46896 iter/s, 6.80753s/10 iters), loss = 7.89252
I0524 02:01:25.349112 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89252 (* 1 = 7.89252 loss)
I0524 02:01:25.487036 11654 sgd_solver.cpp:112] Iteration 20200, lr = 0.1
I0524 02:01:33.357848 11654 solver.cpp:239] Iteration 20210 (1.24868 iter/s, 8.00843s/10 iters), loss = 7.11979
I0524 02:01:33.357897 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11979 (* 1 = 7.11979 loss)
I0524 02:01:34.043193 11654 sgd_solver.cpp:112] Iteration 20210, lr = 0.1
I0524 02:01:40.439399 11654 solver.cpp:239] Iteration 20220 (1.41219 iter/s, 7.08122s/10 iters), loss = 7.06926
I0524 02:01:40.439465 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06926 (* 1 = 7.06926 loss)
I0524 02:01:40.453716 11654 sgd_solver.cpp:112] Iteration 20220, lr = 0.1
I0524 02:01:46.764077 11654 solver.cpp:239] Iteration 20230 (1.58118 iter/s, 6.32438s/10 iters), loss = 6.96306
I0524 02:01:46.764294 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96306 (* 1 = 6.96306 loss)
I0524 02:01:46.764353 11654 sgd_solver.cpp:112] Iteration 20230, lr = 0.1
I0524 02:01:54.922003 11654 solver.cpp:239] Iteration 20240 (1.22591 iter/s, 8.15719s/10 iters), loss = 7.84695
I0524 02:01:54.922067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.84695 (* 1 = 7.84695 loss)
I0524 02:01:54.928076 11654 sgd_solver.cpp:112] Iteration 20240, lr = 0.1
I0524 02:02:01.714025 11654 solver.cpp:239] Iteration 20250 (1.47239 iter/s, 6.7917s/10 iters), loss = 7.0251
I0524 02:02:01.714082 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0251 (* 1 = 7.0251 loss)
I0524 02:02:01.714108 11654 sgd_solver.cpp:112] Iteration 20250, lr = 0.1
I0524 02:02:10.109447 11654 solver.cpp:239] Iteration 20260 (1.19118 iter/s, 8.39505s/10 iters), loss = 6.89063
I0524 02:02:10.109488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89063 (* 1 = 6.89063 loss)
I0524 02:02:10.109500 11654 sgd_solver.cpp:112] Iteration 20260, lr = 0.1
I0524 02:02:17.116379 11654 solver.cpp:239] Iteration 20270 (1.42766 iter/s, 7.00446s/10 iters), loss = 6.91259
I0524 02:02:17.116659 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91259 (* 1 = 6.91259 loss)
I0524 02:02:17.116721 11654 sgd_solver.cpp:112] Iteration 20270, lr = 0.1
I0524 02:02:24.579515 11654 solver.cpp:239] Iteration 20280 (1.34002 iter/s, 7.46259s/10 iters), loss = 7.06344
I0524 02:02:24.579571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06344 (* 1 = 7.06344 loss)
I0524 02:02:24.582504 11654 sgd_solver.cpp:112] Iteration 20280, lr = 0.1
I0524 02:02:30.806859 11654 solver.cpp:239] Iteration 20290 (1.6059 iter/s, 6.22705s/10 iters), loss = 6.71633
I0524 02:02:30.806910 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71633 (* 1 = 6.71633 loss)
I0524 02:02:30.806927 11654 sgd_solver.cpp:112] Iteration 20290, lr = 0.1
I0524 02:02:38.054831 11654 solver.cpp:239] Iteration 20300 (1.37976 iter/s, 7.24765s/10 iters), loss = 7.09094
I0524 02:02:38.054882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09094 (* 1 = 7.09094 loss)
I0524 02:02:38.072374 11654 sgd_solver.cpp:112] Iteration 20300, lr = 0.1
I0524 02:02:45.643584 11654 solver.cpp:239] Iteration 20310 (1.3178 iter/s, 7.58841s/10 iters), loss = 7.39502
I0524 02:02:45.643633 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39502 (* 1 = 7.39502 loss)
I0524 02:02:45.643651 11654 sgd_solver.cpp:112] Iteration 20310, lr = 0.1
I0524 02:02:51.917529 11654 solver.cpp:239] Iteration 20320 (1.59396 iter/s, 6.27366s/10 iters), loss = 7.18591
I0524 02:02:51.917644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18591 (* 1 = 7.18591 loss)
I0524 02:02:51.919312 11654 sgd_solver.cpp:112] Iteration 20320, lr = 0.1
I0524 02:02:58.103188 11654 solver.cpp:239] Iteration 20330 (1.61674 iter/s, 6.1853s/10 iters), loss = 6.87134
I0524 02:02:58.103246 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87134 (* 1 = 6.87134 loss)
I0524 02:02:58.103829 11654 sgd_solver.cpp:112] Iteration 20330, lr = 0.1
I0524 02:03:04.209748 11654 solver.cpp:239] Iteration 20340 (1.63766 iter/s, 6.10627s/10 iters), loss = 7.20113
I0524 02:03:04.209801 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20113 (* 1 = 7.20113 loss)
I0524 02:03:04.210011 11654 sgd_solver.cpp:112] Iteration 20340, lr = 0.1
I0524 02:03:11.218391 11654 solver.cpp:239] Iteration 20350 (1.42687 iter/s, 7.00832s/10 iters), loss = 5.91828
I0524 02:03:11.218433 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91828 (* 1 = 5.91828 loss)
I0524 02:03:11.218818 11654 sgd_solver.cpp:112] Iteration 20350, lr = 0.1
I0524 02:03:18.425551 11654 solver.cpp:239] Iteration 20360 (1.38757 iter/s, 7.20685s/10 iters), loss = 6.70066
I0524 02:03:18.425595 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70066 (* 1 = 6.70066 loss)
I0524 02:03:18.425608 11654 sgd_solver.cpp:112] Iteration 20360, lr = 0.1
I0524 02:03:25.475383 11654 solver.cpp:239] Iteration 20370 (1.41859 iter/s, 7.04926s/10 iters), loss = 6.84314
I0524 02:03:25.475550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84314 (* 1 = 6.84314 loss)
I0524 02:03:25.475622 11654 sgd_solver.cpp:112] Iteration 20370, lr = 0.1
I0524 02:03:33.061498 11654 solver.cpp:239] Iteration 20380 (1.31827 iter/s, 7.58568s/10 iters), loss = 6.9975
I0524 02:03:33.061552 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9975 (* 1 = 6.9975 loss)
I0524 02:03:33.361776 11654 sgd_solver.cpp:112] Iteration 20380, lr = 0.1
I0524 02:03:40.575361 11654 solver.cpp:239] Iteration 20390 (1.33093 iter/s, 7.51353s/10 iters), loss = 6.97895
I0524 02:03:40.575408 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97895 (* 1 = 6.97895 loss)
I0524 02:03:40.575664 11654 sgd_solver.cpp:112] Iteration 20390, lr = 0.1
I0524 02:03:50.222498 11654 solver.cpp:239] Iteration 20400 (1.03662 iter/s, 9.64672s/10 iters), loss = 6.34599
I0524 02:03:50.222553 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34599 (* 1 = 6.34599 loss)
I0524 02:03:51.297451 11654 sgd_solver.cpp:112] Iteration 20400, lr = 0.1
I0524 02:03:58.352900 11654 solver.cpp:239] Iteration 20410 (1.23001 iter/s, 8.13004s/10 iters), loss = 6.83405
I0524 02:03:58.353137 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83405 (* 1 = 6.83405 loss)
I0524 02:03:58.353189 11654 sgd_solver.cpp:112] Iteration 20410, lr = 0.1
I0524 02:04:08.031383 11654 solver.cpp:239] Iteration 20420 (1.0333 iter/s, 9.67772s/10 iters), loss = 6.61346
I0524 02:04:08.031440 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61346 (* 1 = 6.61346 loss)
I0524 02:04:08.121665 11654 sgd_solver.cpp:112] Iteration 20420, lr = 0.1
I0524 02:04:14.625838 11654 solver.cpp:239] Iteration 20430 (1.5165 iter/s, 6.59415s/10 iters), loss = 7.15205
I0524 02:04:14.625890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15205 (* 1 = 7.15205 loss)
I0524 02:04:15.024613 11654 sgd_solver.cpp:112] Iteration 20430, lr = 0.1
I0524 02:04:22.419581 11654 solver.cpp:239] Iteration 20440 (1.28314 iter/s, 7.79339s/10 iters), loss = 7.5148
I0524 02:04:22.419636 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.5148 (* 1 = 7.5148 loss)
I0524 02:04:22.419651 11654 sgd_solver.cpp:112] Iteration 20440, lr = 0.1
I0524 02:04:31.186733 11654 solver.cpp:239] Iteration 20450 (1.14067 iter/s, 8.76676s/10 iters), loss = 6.91607
I0524 02:04:31.186915 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91607 (* 1 = 6.91607 loss)
I0524 02:04:31.187356 11654 sgd_solver.cpp:112] Iteration 20450, lr = 0.1
I0524 02:04:38.266959 11654 solver.cpp:239] Iteration 20460 (1.41247 iter/s, 7.0798s/10 iters), loss = 6.67087
I0524 02:04:38.267014 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67087 (* 1 = 6.67087 loss)
I0524 02:04:38.267029 11654 sgd_solver.cpp:112] Iteration 20460, lr = 0.1
I0524 02:04:46.165877 11654 solver.cpp:239] Iteration 20470 (1.26606 iter/s, 7.8985s/10 iters), loss = 7.55732
I0524 02:04:46.165937 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.55732 (* 1 = 7.55732 loss)
I0524 02:04:46.537215 11654 sgd_solver.cpp:112] Iteration 20470, lr = 0.1
I0524 02:04:55.327472 11654 solver.cpp:239] Iteration 20480 (1.09156 iter/s, 9.16119s/10 iters), loss = 6.76172
I0524 02:04:55.327524 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76172 (* 1 = 6.76172 loss)
I0524 02:04:55.327540 11654 sgd_solver.cpp:112] Iteration 20480, lr = 0.1
I0524 02:05:01.611274 11654 solver.cpp:239] Iteration 20490 (1.59147 iter/s, 6.28352s/10 iters), loss = 6.73385
I0524 02:05:01.611425 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73385 (* 1 = 6.73385 loss)
I0524 02:05:01.611451 11654 sgd_solver.cpp:112] Iteration 20490, lr = 0.1
I0524 02:05:09.743032 11654 solver.cpp:239] Iteration 20500 (1.22982 iter/s, 8.13125s/10 iters), loss = 6.65503
I0524 02:05:09.743095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65503 (* 1 = 6.65503 loss)
I0524 02:05:09.743481 11654 sgd_solver.cpp:112] Iteration 20500, lr = 0.1
I0524 02:05:16.439723 11654 solver.cpp:239] Iteration 20510 (1.49335 iter/s, 6.69637s/10 iters), loss = 6.94508
I0524 02:05:16.439774 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94508 (* 1 = 6.94508 loss)
I0524 02:05:16.439867 11654 sgd_solver.cpp:112] Iteration 20510, lr = 0.1
I0524 02:05:24.126112 11654 solver.cpp:239] Iteration 20520 (1.30106 iter/s, 7.68604s/10 iters), loss = 6.76395
I0524 02:05:24.126169 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76395 (* 1 = 6.76395 loss)
I0524 02:05:24.126591 11654 sgd_solver.cpp:112] Iteration 20520, lr = 0.1
I0524 02:05:30.415184 11654 solver.cpp:239] Iteration 20530 (1.59014 iter/s, 6.28876s/10 iters), loss = 7.26385
I0524 02:05:30.415237 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26385 (* 1 = 7.26385 loss)
I0524 02:05:30.415537 11654 sgd_solver.cpp:112] Iteration 20530, lr = 0.1
I0524 02:05:36.712066 11654 solver.cpp:239] Iteration 20540 (1.58816 iter/s, 6.29658s/10 iters), loss = 6.50289
I0524 02:05:36.712349 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50289 (* 1 = 6.50289 loss)
I0524 02:05:36.712411 11654 sgd_solver.cpp:112] Iteration 20540, lr = 0.1
I0524 02:05:44.533074 11654 solver.cpp:239] Iteration 20550 (1.27869 iter/s, 7.82048s/10 iters), loss = 7.30652
I0524 02:05:44.533115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30652 (* 1 = 7.30652 loss)
I0524 02:05:44.533159 11654 sgd_solver.cpp:112] Iteration 20550, lr = 0.1
I0524 02:05:53.532411 11654 solver.cpp:239] Iteration 20560 (1.11124 iter/s, 8.99895s/10 iters), loss = 7.04486
I0524 02:05:53.532471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04486 (* 1 = 7.04486 loss)
I0524 02:05:53.837321 11654 sgd_solver.cpp:112] Iteration 20560, lr = 0.1
I0524 02:06:00.618317 11654 solver.cpp:239] Iteration 20570 (1.41132 iter/s, 7.08557s/10 iters), loss = 6.60396
I0524 02:06:00.618379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60396 (* 1 = 6.60396 loss)
I0524 02:06:00.618513 11654 sgd_solver.cpp:112] Iteration 20570, lr = 0.1
I0524 02:06:07.028669 11654 solver.cpp:239] Iteration 20580 (1.56005 iter/s, 6.41005s/10 iters), loss = 7.10579
I0524 02:06:07.028769 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10579 (* 1 = 7.10579 loss)
I0524 02:06:07.028782 11654 sgd_solver.cpp:112] Iteration 20580, lr = 0.1
I0524 02:06:14.194121 11654 solver.cpp:239] Iteration 20590 (1.39567 iter/s, 7.16504s/10 iters), loss = 6.42951
I0524 02:06:14.194187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42951 (* 1 = 6.42951 loss)
I0524 02:06:14.194559 11654 sgd_solver.cpp:112] Iteration 20590, lr = 0.1
I0524 02:06:21.352847 11654 solver.cpp:239] Iteration 20600 (1.39696 iter/s, 7.15839s/10 iters), loss = 7.12513
I0524 02:06:21.352907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12513 (* 1 = 7.12513 loss)
I0524 02:06:21.353060 11654 sgd_solver.cpp:112] Iteration 20600, lr = 0.1
I0524 02:06:28.577647 11654 solver.cpp:239] Iteration 20610 (1.38419 iter/s, 7.22446s/10 iters), loss = 6.33505
I0524 02:06:28.577710 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33505 (* 1 = 6.33505 loss)
I0524 02:06:28.577986 11654 sgd_solver.cpp:112] Iteration 20610, lr = 0.1
I0524 02:06:36.509387 11654 solver.cpp:239] Iteration 20620 (1.26081 iter/s, 7.93139s/10 iters), loss = 7.13915
I0524 02:06:36.509423 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13915 (* 1 = 7.13915 loss)
I0524 02:06:36.509436 11654 sgd_solver.cpp:112] Iteration 20620, lr = 0.1
I0524 02:06:44.199764 11654 solver.cpp:239] Iteration 20630 (1.30038 iter/s, 7.69003s/10 iters), loss = 6.81242
I0524 02:06:44.199859 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81242 (* 1 = 6.81242 loss)
I0524 02:06:44.199879 11654 sgd_solver.cpp:112] Iteration 20630, lr = 0.1
I0524 02:06:50.913070 11654 solver.cpp:239] Iteration 20640 (1.48966 iter/s, 6.71296s/10 iters), loss = 8.08465
I0524 02:06:50.913125 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.08465 (* 1 = 8.08465 loss)
I0524 02:06:50.913143 11654 sgd_solver.cpp:112] Iteration 20640, lr = 0.1
I0524 02:06:57.707129 11654 solver.cpp:239] Iteration 20650 (1.47194 iter/s, 6.79375s/10 iters), loss = 7.14782
I0524 02:06:57.707178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14782 (* 1 = 7.14782 loss)
I0524 02:06:57.707192 11654 sgd_solver.cpp:112] Iteration 20650, lr = 0.1
I0524 02:07:05.970204 11654 solver.cpp:239] Iteration 20660 (1.21026 iter/s, 8.26271s/10 iters), loss = 7.19539
I0524 02:07:05.970263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19539 (* 1 = 7.19539 loss)
I0524 02:07:06.277160 11654 sgd_solver.cpp:112] Iteration 20660, lr = 0.1
I0524 02:07:13.581609 11654 solver.cpp:239] Iteration 20670 (1.31388 iter/s, 7.61106s/10 iters), loss = 6.62601
I0524 02:07:13.581671 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62601 (* 1 = 6.62601 loss)
I0524 02:07:13.581688 11654 sgd_solver.cpp:112] Iteration 20670, lr = 0.1
I0524 02:07:21.344007 11654 solver.cpp:239] Iteration 20680 (1.28868 iter/s, 7.75989s/10 iters), loss = 7.08396
I0524 02:07:21.344162 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08396 (* 1 = 7.08396 loss)
I0524 02:07:21.344594 11654 sgd_solver.cpp:112] Iteration 20680, lr = 0.1
I0524 02:07:29.224854 11654 solver.cpp:239] Iteration 20690 (1.26897 iter/s, 7.88041s/10 iters), loss = 7.44347
I0524 02:07:29.224908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44347 (* 1 = 7.44347 loss)
I0524 02:07:29.224925 11654 sgd_solver.cpp:112] Iteration 20690, lr = 0.1
I0524 02:07:36.584731 11654 solver.cpp:239] Iteration 20700 (1.35878 iter/s, 7.35954s/10 iters), loss = 6.96212
I0524 02:07:36.584781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96212 (* 1 = 6.96212 loss)
I0524 02:07:36.594390 11654 sgd_solver.cpp:112] Iteration 20700, lr = 0.1
I0524 02:07:44.024312 11654 solver.cpp:239] Iteration 20710 (1.34422 iter/s, 7.43925s/10 iters), loss = 7.30661
I0524 02:07:44.024363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30661 (* 1 = 7.30661 loss)
I0524 02:07:44.426368 11654 sgd_solver.cpp:112] Iteration 20710, lr = 0.1
I0524 02:07:50.726817 11654 solver.cpp:239] Iteration 20720 (1.49205 iter/s, 6.70219s/10 iters), loss = 6.54205
I0524 02:07:50.726881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54205 (* 1 = 6.54205 loss)
I0524 02:07:50.727111 11654 sgd_solver.cpp:112] Iteration 20720, lr = 0.1
I0524 02:07:57.815731 11654 solver.cpp:239] Iteration 20730 (1.41072 iter/s, 7.08859s/10 iters), loss = 7.05229
I0524 02:07:57.815948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05229 (* 1 = 7.05229 loss)
I0524 02:07:57.815987 11654 sgd_solver.cpp:112] Iteration 20730, lr = 0.1
I0524 02:08:05.618523 11654 solver.cpp:239] Iteration 20740 (1.282 iter/s, 7.80029s/10 iters), loss = 6.47741
I0524 02:08:05.618578 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47741 (* 1 = 6.47741 loss)
I0524 02:08:05.618593 11654 sgd_solver.cpp:112] Iteration 20740, lr = 0.1
I0524 02:08:12.467896 11654 solver.cpp:239] Iteration 20750 (1.46053 iter/s, 6.84685s/10 iters), loss = 7.05868
I0524 02:08:12.467950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05868 (* 1 = 7.05868 loss)
I0524 02:08:12.467967 11654 sgd_solver.cpp:112] Iteration 20750, lr = 0.1
I0524 02:08:19.078959 11654 solver.cpp:239] Iteration 20760 (1.51277 iter/s, 6.61037s/10 iters), loss = 7.57715
I0524 02:08:19.079026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.57715 (* 1 = 7.57715 loss)
I0524 02:08:19.079388 11654 sgd_solver.cpp:112] Iteration 20760, lr = 0.1
I0524 02:08:26.365346 11654 solver.cpp:239] Iteration 20770 (1.37249 iter/s, 7.28603s/10 iters), loss = 7.21773
I0524 02:08:26.365435 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21773 (* 1 = 7.21773 loss)
I0524 02:08:26.365466 11654 sgd_solver.cpp:112] Iteration 20770, lr = 0.1
I0524 02:08:32.607676 11654 solver.cpp:239] Iteration 20780 (1.60221 iter/s, 6.24139s/10 iters), loss = 5.65375
I0524 02:08:32.607826 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65375 (* 1 = 5.65375 loss)
I0524 02:08:32.608292 11654 sgd_solver.cpp:112] Iteration 20780, lr = 0.1
I0524 02:08:39.546967 11654 solver.cpp:239] Iteration 20790 (1.44115 iter/s, 6.93889s/10 iters), loss = 6.39687
I0524 02:08:39.547006 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39687 (* 1 = 6.39687 loss)
I0524 02:08:39.547020 11654 sgd_solver.cpp:112] Iteration 20790, lr = 0.1
I0524 02:08:46.187207 11654 solver.cpp:239] Iteration 20800 (1.50604 iter/s, 6.63994s/10 iters), loss = 6.78332
I0524 02:08:46.187258 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78332 (* 1 = 6.78332 loss)
I0524 02:08:46.187274 11654 sgd_solver.cpp:112] Iteration 20800, lr = 0.1
I0524 02:08:53.008595 11654 solver.cpp:239] Iteration 20810 (1.46604 iter/s, 6.82107s/10 iters), loss = 7.72616
I0524 02:08:53.008641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.72616 (* 1 = 7.72616 loss)
I0524 02:08:53.008707 11654 sgd_solver.cpp:112] Iteration 20810, lr = 0.1
I0524 02:08:59.239509 11654 solver.cpp:239] Iteration 20820 (1.60498 iter/s, 6.23062s/10 iters), loss = 6.54592
I0524 02:08:59.239567 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54592 (* 1 = 6.54592 loss)
I0524 02:08:59.239583 11654 sgd_solver.cpp:112] Iteration 20820, lr = 0.1
I0524 02:09:05.991580 11654 solver.cpp:239] Iteration 20830 (1.48112 iter/s, 6.75165s/10 iters), loss = 6.3911
I0524 02:09:05.991858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3911 (* 1 = 6.3911 loss)
I0524 02:09:06.006310 11654 sgd_solver.cpp:112] Iteration 20830, lr = 0.1
I0524 02:09:13.187419 11654 solver.cpp:239] Iteration 20840 (1.38979 iter/s, 7.19536s/10 iters), loss = 6.71617
I0524 02:09:13.187459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71617 (* 1 = 6.71617 loss)
I0524 02:09:13.187676 11654 sgd_solver.cpp:112] Iteration 20840, lr = 0.1
I0524 02:09:20.260205 11654 solver.cpp:239] Iteration 20850 (1.41394 iter/s, 7.07246s/10 iters), loss = 7.49834
I0524 02:09:20.260265 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.49834 (* 1 = 7.49834 loss)
I0524 02:09:20.260299 11654 sgd_solver.cpp:112] Iteration 20850, lr = 0.1
I0524 02:09:26.929967 11654 solver.cpp:239] Iteration 20860 (1.49938 iter/s, 6.66944s/10 iters), loss = 7.10494
I0524 02:09:26.930032 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10494 (* 1 = 7.10494 loss)
I0524 02:09:26.931586 11654 sgd_solver.cpp:112] Iteration 20860, lr = 0.1
I0524 02:09:33.560043 11654 solver.cpp:239] Iteration 20870 (1.50835 iter/s, 6.62975s/10 iters), loss = 6.85976
I0524 02:09:33.560114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85976 (* 1 = 6.85976 loss)
I0524 02:09:34.202005 11654 sgd_solver.cpp:112] Iteration 20870, lr = 0.1
I0524 02:09:40.632191 11654 solver.cpp:239] Iteration 20880 (1.41406 iter/s, 7.07181s/10 iters), loss = 7.10042
I0524 02:09:40.632411 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10042 (* 1 = 7.10042 loss)
I0524 02:09:40.632622 11654 sgd_solver.cpp:112] Iteration 20880, lr = 0.1
I0524 02:09:47.897547 11654 solver.cpp:239] Iteration 20890 (1.37648 iter/s, 7.26489s/10 iters), loss = 6.4612
I0524 02:09:47.897599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4612 (* 1 = 6.4612 loss)
I0524 02:09:47.897686 11654 sgd_solver.cpp:112] Iteration 20890, lr = 0.1
I0524 02:09:53.875579 11654 solver.cpp:239] Iteration 20900 (1.67287 iter/s, 5.97775s/10 iters), loss = 6.75525
I0524 02:09:53.875633 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75525 (* 1 = 6.75525 loss)
I0524 02:09:53.875648 11654 sgd_solver.cpp:112] Iteration 20900, lr = 0.1
I0524 02:10:01.479183 11654 solver.cpp:239] Iteration 20910 (1.31522 iter/s, 7.60327s/10 iters), loss = 7.90352
I0524 02:10:01.479224 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.90352 (* 1 = 7.90352 loss)
I0524 02:10:01.479368 11654 sgd_solver.cpp:112] Iteration 20910, lr = 0.1
I0524 02:10:08.379024 11654 solver.cpp:239] Iteration 20920 (1.44938 iter/s, 6.89952s/10 iters), loss = 7.69308
I0524 02:10:08.379097 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69308 (* 1 = 7.69308 loss)
I0524 02:10:08.379987 11654 sgd_solver.cpp:112] Iteration 20920, lr = 0.1
I0524 02:10:16.481314 11654 solver.cpp:239] Iteration 20930 (1.23428 iter/s, 8.10191s/10 iters), loss = 6.80646
I0524 02:10:16.481444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80646 (* 1 = 6.80646 loss)
I0524 02:10:16.481464 11654 sgd_solver.cpp:112] Iteration 20930, lr = 0.1
I0524 02:10:23.654884 11654 solver.cpp:239] Iteration 20940 (1.39409 iter/s, 7.17314s/10 iters), loss = 7.27619
I0524 02:10:23.654924 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27619 (* 1 = 7.27619 loss)
I0524 02:10:24.764266 11654 sgd_solver.cpp:112] Iteration 20940, lr = 0.1
I0524 02:10:32.483594 11654 solver.cpp:239] Iteration 20950 (1.13272 iter/s, 8.82832s/10 iters), loss = 6.70668
I0524 02:10:32.483655 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70668 (* 1 = 6.70668 loss)
I0524 02:10:32.993784 11654 sgd_solver.cpp:112] Iteration 20950, lr = 0.1
I0524 02:10:39.173673 11654 solver.cpp:239] Iteration 20960 (1.49482 iter/s, 6.68977s/10 iters), loss = 6.50506
I0524 02:10:39.173712 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50506 (* 1 = 6.50506 loss)
I0524 02:10:39.902691 11654 sgd_solver.cpp:112] Iteration 20960, lr = 0.1
I0524 02:10:47.159406 11654 solver.cpp:239] Iteration 20970 (1.25229 iter/s, 7.98538s/10 iters), loss = 6.99802
I0524 02:10:47.159641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99802 (* 1 = 6.99802 loss)
I0524 02:10:47.159695 11654 sgd_solver.cpp:112] Iteration 20970, lr = 0.1
I0524 02:10:53.764860 11654 solver.cpp:239] Iteration 20980 (1.51412 iter/s, 6.60451s/10 iters), loss = 7.52816
I0524 02:10:53.764912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.52816 (* 1 = 7.52816 loss)
I0524 02:10:53.764927 11654 sgd_solver.cpp:112] Iteration 20980, lr = 0.1
I0524 02:11:01.902714 11654 solver.cpp:239] Iteration 20990 (1.22888 iter/s, 8.13749s/10 iters), loss = 6.59677
I0524 02:11:01.902760 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59677 (* 1 = 6.59677 loss)
I0524 02:11:01.902776 11654 sgd_solver.cpp:112] Iteration 20990, lr = 0.1
I0524 02:11:09.487056 11654 solver.cpp:239] Iteration 21000 (1.31858 iter/s, 7.58393s/10 iters), loss = 6.96401
I0524 02:11:09.487119 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96401 (* 1 = 6.96401 loss)
I0524 02:11:09.487258 11654 sgd_solver.cpp:112] Iteration 21000, lr = 0.1
I0524 02:11:16.143421 11654 solver.cpp:239] Iteration 21010 (1.50239 iter/s, 6.65605s/10 iters), loss = 7.76278
I0524 02:11:16.143472 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76278 (* 1 = 7.76278 loss)
I0524 02:11:16.143489 11654 sgd_solver.cpp:112] Iteration 21010, lr = 0.1
I0524 02:11:23.861467 11654 solver.cpp:239] Iteration 21020 (1.29573 iter/s, 7.71763s/10 iters), loss = 6.49275
I0524 02:11:23.861707 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49275 (* 1 = 6.49275 loss)
I0524 02:11:23.861763 11654 sgd_solver.cpp:112] Iteration 21020, lr = 0.1
I0524 02:11:31.780241 11654 solver.cpp:239] Iteration 21030 (1.26323 iter/s, 7.9162s/10 iters), loss = 7.32787
I0524 02:11:31.780297 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32787 (* 1 = 7.32787 loss)
I0524 02:11:31.796339 11654 sgd_solver.cpp:112] Iteration 21030, lr = 0.1
I0524 02:11:38.266110 11654 solver.cpp:239] Iteration 21040 (1.54189 iter/s, 6.48557s/10 iters), loss = 7.32907
I0524 02:11:38.266163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32907 (* 1 = 7.32907 loss)
I0524 02:11:38.907413 11654 sgd_solver.cpp:112] Iteration 21040, lr = 0.1
I0524 02:11:46.238342 11654 solver.cpp:239] Iteration 21050 (1.25441 iter/s, 7.97187s/10 iters), loss = 6.44953
I0524 02:11:46.238385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44953 (* 1 = 6.44953 loss)
I0524 02:11:46.238759 11654 sgd_solver.cpp:112] Iteration 21050, lr = 0.1
I0524 02:11:53.494941 11654 solver.cpp:239] Iteration 21060 (1.37812 iter/s, 7.25627s/10 iters), loss = 6.54781
I0524 02:11:53.494992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54781 (* 1 = 6.54781 loss)
I0524 02:11:53.495008 11654 sgd_solver.cpp:112] Iteration 21060, lr = 0.1
I0524 02:12:00.437466 11654 solver.cpp:239] Iteration 21070 (1.44091 iter/s, 6.94006s/10 iters), loss = 7.23658
I0524 02:12:00.437665 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23658 (* 1 = 7.23658 loss)
I0524 02:12:00.557821 11654 sgd_solver.cpp:112] Iteration 21070, lr = 0.1
I0524 02:12:07.428728 11654 solver.cpp:239] Iteration 21080 (1.43045 iter/s, 6.99081s/10 iters), loss = 6.98597
I0524 02:12:07.428771 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98597 (* 1 = 6.98597 loss)
I0524 02:12:07.458317 11654 sgd_solver.cpp:112] Iteration 21080, lr = 0.1
I0524 02:12:14.487205 11654 solver.cpp:239] Iteration 21090 (1.4168 iter/s, 7.05816s/10 iters), loss = 6.14259
I0524 02:12:14.487259 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14259 (* 1 = 6.14259 loss)
I0524 02:12:14.487275 11654 sgd_solver.cpp:112] Iteration 21090, lr = 0.1
I0524 02:12:22.214884 11654 solver.cpp:239] Iteration 21100 (1.29411 iter/s, 7.72733s/10 iters), loss = 7.11413
I0524 02:12:22.214936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11413 (* 1 = 7.11413 loss)
I0524 02:12:22.222936 11654 sgd_solver.cpp:112] Iteration 21100, lr = 0.1
I0524 02:12:30.564826 11654 solver.cpp:239] Iteration 21110 (1.19767 iter/s, 8.34957s/10 iters), loss = 7.06748
I0524 02:12:30.565052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06748 (* 1 = 7.06748 loss)
I0524 02:12:30.565446 11654 sgd_solver.cpp:112] Iteration 21110, lr = 0.1
I0524 02:12:39.382149 11654 solver.cpp:239] Iteration 21120 (1.1342 iter/s, 8.81681s/10 iters), loss = 6.6945
I0524 02:12:39.382197 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6945 (* 1 = 6.6945 loss)
I0524 02:12:39.563689 11654 sgd_solver.cpp:112] Iteration 21120, lr = 0.1
I0524 02:12:47.707929 11654 solver.cpp:239] Iteration 21130 (1.20114 iter/s, 8.3254s/10 iters), loss = 6.99698
I0524 02:12:47.707983 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99698 (* 1 = 6.99698 loss)
I0524 02:12:48.208712 11654 sgd_solver.cpp:112] Iteration 21130, lr = 0.1
I0524 02:12:55.628813 11654 solver.cpp:239] Iteration 21140 (1.26254 iter/s, 7.92053s/10 iters), loss = 8.11478
I0524 02:12:55.628868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.11478 (* 1 = 8.11478 loss)
I0524 02:12:55.628885 11654 sgd_solver.cpp:112] Iteration 21140, lr = 0.1
I0524 02:13:04.807097 11654 solver.cpp:239] Iteration 21150 (1.08958 iter/s, 9.17789s/10 iters), loss = 7.13366
I0524 02:13:04.807374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13366 (* 1 = 7.13366 loss)
I0524 02:13:05.753887 11654 sgd_solver.cpp:112] Iteration 21150, lr = 0.1
I0524 02:13:12.478037 11654 solver.cpp:239] Iteration 21160 (1.30371 iter/s, 7.67042s/10 iters), loss = 6.08577
I0524 02:13:12.478091 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08577 (* 1 = 6.08577 loss)
I0524 02:13:12.581342 11654 sgd_solver.cpp:112] Iteration 21160, lr = 0.1
I0524 02:13:18.542109 11654 solver.cpp:239] Iteration 21170 (1.64913 iter/s, 6.06379s/10 iters), loss = 6.45483
I0524 02:13:18.542160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45483 (* 1 = 6.45483 loss)
I0524 02:13:18.542177 11654 sgd_solver.cpp:112] Iteration 21170, lr = 0.1
I0524 02:13:25.085686 11654 solver.cpp:239] Iteration 21180 (1.52881 iter/s, 6.54103s/10 iters), loss = 6.73995
I0524 02:13:25.085748 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73995 (* 1 = 6.73995 loss)
I0524 02:13:25.085800 11654 sgd_solver.cpp:112] Iteration 21180, lr = 0.1
I0524 02:13:34.109418 11654 solver.cpp:239] Iteration 21190 (1.10824 iter/s, 9.02333s/10 iters), loss = 7.40476
I0524 02:13:34.109465 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40476 (* 1 = 7.40476 loss)
I0524 02:13:34.111491 11654 sgd_solver.cpp:112] Iteration 21190, lr = 0.1
I0524 02:13:40.966667 11654 solver.cpp:239] Iteration 21200 (1.45838 iter/s, 6.85694s/10 iters), loss = 7.98683
I0524 02:13:40.966998 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.98683 (* 1 = 7.98683 loss)
I0524 02:13:40.967041 11654 sgd_solver.cpp:112] Iteration 21200, lr = 0.1
I0524 02:13:46.950294 11654 solver.cpp:239] Iteration 21210 (1.67151 iter/s, 5.98262s/10 iters), loss = 7.31824
I0524 02:13:46.950354 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31824 (* 1 = 7.31824 loss)
I0524 02:13:46.950723 11654 sgd_solver.cpp:112] Iteration 21210, lr = 0.1
I0524 02:13:53.872994 11654 solver.cpp:239] Iteration 21220 (1.44459 iter/s, 6.92239s/10 iters), loss = 7.26455
I0524 02:13:53.873037 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26455 (* 1 = 7.26455 loss)
I0524 02:13:54.111011 11654 sgd_solver.cpp:112] Iteration 21220, lr = 0.1
I0524 02:14:01.080752 11654 solver.cpp:239] Iteration 21230 (1.38746 iter/s, 7.20743s/10 iters), loss = 6.46184
I0524 02:14:01.080814 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46184 (* 1 = 6.46184 loss)
I0524 02:14:01.081145 11654 sgd_solver.cpp:112] Iteration 21230, lr = 0.1
I0524 02:14:10.022653 11654 solver.cpp:239] Iteration 21240 (1.11838 iter/s, 8.9415s/10 iters), loss = 5.59229
I0524 02:14:10.022743 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59229 (* 1 = 5.59229 loss)
I0524 02:14:10.022873 11654 sgd_solver.cpp:112] Iteration 21240, lr = 0.1
I0524 02:14:17.965826 11654 solver.cpp:239] Iteration 21250 (1.259 iter/s, 7.94278s/10 iters), loss = 7.10909
I0524 02:14:17.966001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10909 (* 1 = 7.10909 loss)
I0524 02:14:17.966301 11654 sgd_solver.cpp:112] Iteration 21250, lr = 0.1
I0524 02:14:23.888252 11654 solver.cpp:239] Iteration 21260 (1.68861 iter/s, 5.92204s/10 iters), loss = 5.66531
I0524 02:14:23.888291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66531 (* 1 = 5.66531 loss)
I0524 02:14:23.888432 11654 sgd_solver.cpp:112] Iteration 21260, lr = 0.1
I0524 02:14:31.406774 11654 solver.cpp:239] Iteration 21270 (1.33011 iter/s, 7.51819s/10 iters), loss = 6.30617
I0524 02:14:31.406826 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30617 (* 1 = 6.30617 loss)
I0524 02:14:31.406843 11654 sgd_solver.cpp:112] Iteration 21270, lr = 0.1
I0524 02:14:38.175416 11654 solver.cpp:239] Iteration 21280 (1.47749 iter/s, 6.76825s/10 iters), loss = 6.43889
I0524 02:14:38.175467 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43889 (* 1 = 6.43889 loss)
I0524 02:14:38.175644 11654 sgd_solver.cpp:112] Iteration 21280, lr = 0.1
I0524 02:14:44.172870 11654 solver.cpp:239] Iteration 21290 (1.66745 iter/s, 5.99718s/10 iters), loss = 6.7729
I0524 02:14:44.172909 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7729 (* 1 = 6.7729 loss)
I0524 02:14:44.172922 11654 sgd_solver.cpp:112] Iteration 21290, lr = 0.1
I0524 02:14:51.482450 11654 solver.cpp:239] Iteration 21300 (1.36813 iter/s, 7.30925s/10 iters), loss = 6.98408
I0524 02:14:51.482817 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98408 (* 1 = 6.98408 loss)
I0524 02:14:51.482884 11654 sgd_solver.cpp:112] Iteration 21300, lr = 0.1
I0524 02:14:59.849934 11654 solver.cpp:239] Iteration 21310 (1.19519 iter/s, 8.36688s/10 iters), loss = 7.88095
I0524 02:14:59.849985 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.88095 (* 1 = 7.88095 loss)
I0524 02:14:59.920827 11654 sgd_solver.cpp:112] Iteration 21310, lr = 0.1
I0524 02:15:05.905562 11654 solver.cpp:239] Iteration 21320 (1.65143 iter/s, 6.05535s/10 iters), loss = 7.4616
I0524 02:15:05.905604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4616 (* 1 = 7.4616 loss)
I0524 02:15:05.905956 11654 sgd_solver.cpp:112] Iteration 21320, lr = 0.1
I0524 02:15:12.615496 11654 solver.cpp:239] Iteration 21330 (1.4904 iter/s, 6.70963s/10 iters), loss = 7.53383
I0524 02:15:12.615553 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.53383 (* 1 = 7.53383 loss)
I0524 02:15:12.639050 11654 sgd_solver.cpp:112] Iteration 21330, lr = 0.1
I0524 02:15:18.854557 11654 solver.cpp:239] Iteration 21340 (1.60288 iter/s, 6.23876s/10 iters), loss = 7.04084
I0524 02:15:18.854604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04084 (* 1 = 7.04084 loss)
I0524 02:15:18.854620 11654 sgd_solver.cpp:112] Iteration 21340, lr = 0.1
I0524 02:15:27.191195 11654 solver.cpp:239] Iteration 21350 (1.19959 iter/s, 8.33619s/10 iters), loss = 7.01123
I0524 02:15:27.191341 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01123 (* 1 = 7.01123 loss)
I0524 02:15:27.191494 11654 sgd_solver.cpp:112] Iteration 21350, lr = 0.1
I0524 02:15:34.848623 11654 solver.cpp:239] Iteration 21360 (1.306 iter/s, 7.65699s/10 iters), loss = 6.45011
I0524 02:15:34.848677 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45011 (* 1 = 6.45011 loss)
I0524 02:15:34.848731 11654 sgd_solver.cpp:112] Iteration 21360, lr = 0.1
I0524 02:15:41.452780 11654 solver.cpp:239] Iteration 21370 (1.51427 iter/s, 6.60385s/10 iters), loss = 6.65766
I0524 02:15:41.452821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65766 (* 1 = 6.65766 loss)
I0524 02:15:41.452836 11654 sgd_solver.cpp:112] Iteration 21370, lr = 0.1
I0524 02:15:48.704912 11654 solver.cpp:239] Iteration 21380 (1.37897 iter/s, 7.2518s/10 iters), loss = 6.66378
I0524 02:15:48.704974 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66378 (* 1 = 6.66378 loss)
I0524 02:15:48.705070 11654 sgd_solver.cpp:112] Iteration 21380, lr = 0.1
I0524 02:15:54.593650 11654 solver.cpp:239] Iteration 21390 (1.69824 iter/s, 5.88846s/10 iters), loss = 6.64183
I0524 02:15:54.593688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64183 (* 1 = 6.64183 loss)
I0524 02:15:54.593703 11654 sgd_solver.cpp:112] Iteration 21390, lr = 0.1
I0524 02:16:01.331029 11654 solver.cpp:239] Iteration 21400 (1.48432 iter/s, 6.73708s/10 iters), loss = 7.43186
I0524 02:16:01.331140 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43186 (* 1 = 7.43186 loss)
I0524 02:16:01.331157 11654 sgd_solver.cpp:112] Iteration 21400, lr = 0.1
I0524 02:16:08.392601 11654 solver.cpp:239] Iteration 21410 (1.41631 iter/s, 7.0606s/10 iters), loss = 5.9599
I0524 02:16:08.392660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9599 (* 1 = 5.9599 loss)
I0524 02:16:08.393038 11654 sgd_solver.cpp:112] Iteration 21410, lr = 0.1
I0524 02:16:16.296943 11654 solver.cpp:239] Iteration 21420 (1.26518 iter/s, 7.90399s/10 iters), loss = 7.0247
I0524 02:16:16.296983 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0247 (* 1 = 7.0247 loss)
I0524 02:16:16.296996 11654 sgd_solver.cpp:112] Iteration 21420, lr = 0.1
I0524 02:16:22.702262 11654 solver.cpp:239] Iteration 21430 (1.56135 iter/s, 6.40472s/10 iters), loss = 7.7412
I0524 02:16:22.702320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.7412 (* 1 = 7.7412 loss)
I0524 02:16:22.702338 11654 sgd_solver.cpp:112] Iteration 21430, lr = 0.1
I0524 02:16:28.798800 11654 solver.cpp:239] Iteration 21440 (1.64035 iter/s, 6.09625s/10 iters), loss = 7.69057
I0524 02:16:28.798852 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69057 (* 1 = 7.69057 loss)
I0524 02:16:28.799228 11654 sgd_solver.cpp:112] Iteration 21440, lr = 0.1
I0524 02:16:35.529525 11654 solver.cpp:239] Iteration 21450 (1.48579 iter/s, 6.73041s/10 iters), loss = 7.64697
I0524 02:16:35.529742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.64697 (* 1 = 7.64697 loss)
I0524 02:16:35.529793 11654 sgd_solver.cpp:112] Iteration 21450, lr = 0.1
I0524 02:16:41.642657 11654 solver.cpp:239] Iteration 21460 (1.63603 iter/s, 6.11237s/10 iters), loss = 6.73703
I0524 02:16:41.642714 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73703 (* 1 = 6.73703 loss)
I0524 02:16:41.642905 11654 sgd_solver.cpp:112] Iteration 21460, lr = 0.1
I0524 02:16:48.594111 11654 solver.cpp:239] Iteration 21470 (1.43861 iter/s, 6.95114s/10 iters), loss = 6.52992
I0524 02:16:48.594164 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52992 (* 1 = 6.52992 loss)
I0524 02:16:48.594346 11654 sgd_solver.cpp:112] Iteration 21470, lr = 0.1
I0524 02:16:55.075791 11654 solver.cpp:239] Iteration 21480 (1.54288 iter/s, 6.48138s/10 iters), loss = 6.18838
I0524 02:16:55.075834 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18838 (* 1 = 6.18838 loss)
I0524 02:16:55.075846 11654 sgd_solver.cpp:112] Iteration 21480, lr = 0.1
I0524 02:17:01.562366 11654 solver.cpp:239] Iteration 21490 (1.54172 iter/s, 6.48628s/10 iters), loss = 7.69289
I0524 02:17:01.562418 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.69289 (* 1 = 7.69289 loss)
I0524 02:17:01.978839 11654 sgd_solver.cpp:112] Iteration 21490, lr = 0.1
I0524 02:17:09.760359 11654 solver.cpp:239] Iteration 21500 (1.21986 iter/s, 8.19764s/10 iters), loss = 6.84022
I0524 02:17:09.760658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84022 (* 1 = 6.84022 loss)
I0524 02:17:09.829224 11654 sgd_solver.cpp:112] Iteration 21500, lr = 0.1
I0524 02:17:18.248670 11654 solver.cpp:239] Iteration 21510 (1.17817 iter/s, 8.48773s/10 iters), loss = 6.72414
I0524 02:17:18.248719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72414 (* 1 = 6.72414 loss)
I0524 02:17:18.248737 11654 sgd_solver.cpp:112] Iteration 21510, lr = 0.1
I0524 02:17:25.608463 11654 solver.cpp:239] Iteration 21520 (1.35881 iter/s, 7.35941s/10 iters), loss = 6.77834
I0524 02:17:25.608510 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77834 (* 1 = 6.77834 loss)
I0524 02:17:25.608525 11654 sgd_solver.cpp:112] Iteration 21520, lr = 0.1
I0524 02:17:32.850641 11654 solver.cpp:239] Iteration 21530 (1.38086 iter/s, 7.24186s/10 iters), loss = 7.2197
I0524 02:17:32.850688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2197 (* 1 = 7.2197 loss)
I0524 02:17:32.850775 11654 sgd_solver.cpp:112] Iteration 21530, lr = 0.1
I0524 02:17:39.298758 11654 solver.cpp:239] Iteration 21540 (1.55092 iter/s, 6.4478s/10 iters), loss = 7.58101
I0524 02:17:39.298816 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58101 (* 1 = 7.58101 loss)
I0524 02:17:39.357254 11654 sgd_solver.cpp:112] Iteration 21540, lr = 0.1
I0524 02:17:46.564214 11654 solver.cpp:239] Iteration 21550 (1.37644 iter/s, 7.26513s/10 iters), loss = 6.31233
I0524 02:17:46.564481 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31233 (* 1 = 6.31233 loss)
I0524 02:17:46.564538 11654 sgd_solver.cpp:112] Iteration 21550, lr = 0.1
I0524 02:17:53.193724 11654 solver.cpp:239] Iteration 21560 (1.50853 iter/s, 6.62899s/10 iters), loss = 6.16921
I0524 02:17:53.193785 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16921 (* 1 = 6.16921 loss)
I0524 02:17:53.193924 11654 sgd_solver.cpp:112] Iteration 21560, lr = 0.1
I0524 02:17:59.456857 11654 solver.cpp:239] Iteration 21570 (1.59672 iter/s, 6.26283s/10 iters), loss = 7.12118
I0524 02:17:59.456914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12118 (* 1 = 7.12118 loss)
I0524 02:17:59.796552 11654 sgd_solver.cpp:112] Iteration 21570, lr = 0.1
I0524 02:18:06.649983 11654 solver.cpp:239] Iteration 21580 (1.39028 iter/s, 7.1928s/10 iters), loss = 7.21026
I0524 02:18:06.650022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21026 (* 1 = 7.21026 loss)
I0524 02:18:06.650035 11654 sgd_solver.cpp:112] Iteration 21580, lr = 0.1
I0524 02:18:13.888011 11654 solver.cpp:239] Iteration 21590 (1.38168 iter/s, 7.23759s/10 iters), loss = 6.99823
I0524 02:18:13.888062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99823 (* 1 = 6.99823 loss)
I0524 02:18:13.888078 11654 sgd_solver.cpp:112] Iteration 21590, lr = 0.1
I0524 02:18:19.981559 11654 solver.cpp:239] Iteration 21600 (1.64176 iter/s, 6.09101s/10 iters), loss = 6.3787
I0524 02:18:19.981909 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3787 (* 1 = 6.3787 loss)
I0524 02:18:19.981971 11654 sgd_solver.cpp:112] Iteration 21600, lr = 0.1
I0524 02:18:27.926007 11654 solver.cpp:239] Iteration 21610 (1.25893 iter/s, 7.94327s/10 iters), loss = 7.91526
I0524 02:18:27.926049 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91526 (* 1 = 7.91526 loss)
I0524 02:18:27.926064 11654 sgd_solver.cpp:112] Iteration 21610, lr = 0.1
I0524 02:18:37.058235 11654 solver.cpp:239] Iteration 21620 (1.09533 iter/s, 9.12966s/10 iters), loss = 6.26023
I0524 02:18:37.058302 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26023 (* 1 = 6.26023 loss)
I0524 02:18:37.058620 11654 sgd_solver.cpp:112] Iteration 21620, lr = 0.1
I0524 02:18:43.645630 11654 solver.cpp:239] Iteration 21630 (1.51812 iter/s, 6.58708s/10 iters), loss = 6.50563
I0524 02:18:43.645690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50563 (* 1 = 6.50563 loss)
I0524 02:18:43.645738 11654 sgd_solver.cpp:112] Iteration 21630, lr = 0.1
I0524 02:18:50.422988 11654 solver.cpp:239] Iteration 21640 (1.47557 iter/s, 6.77704s/10 iters), loss = 6.42138
I0524 02:18:50.423249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42138 (* 1 = 6.42138 loss)
I0524 02:18:50.423432 11654 sgd_solver.cpp:112] Iteration 21640, lr = 0.1
I0524 02:18:57.348637 11654 solver.cpp:239] Iteration 21650 (1.44401 iter/s, 6.92517s/10 iters), loss = 6.7527
I0524 02:18:57.348691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7527 (* 1 = 6.7527 loss)
I0524 02:18:57.348979 11654 sgd_solver.cpp:112] Iteration 21650, lr = 0.1
I0524 02:19:04.046344 11654 solver.cpp:239] Iteration 21660 (1.49312 iter/s, 6.6974s/10 iters), loss = 6.73921
I0524 02:19:04.046398 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73921 (* 1 = 6.73921 loss)
I0524 02:19:05.121747 11654 sgd_solver.cpp:112] Iteration 21660, lr = 0.1
I0524 02:19:11.806278 11654 solver.cpp:239] Iteration 21670 (1.28873 iter/s, 7.75958s/10 iters), loss = 6.7469
I0524 02:19:11.806336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7469 (* 1 = 6.7469 loss)
I0524 02:19:11.806680 11654 sgd_solver.cpp:112] Iteration 21670, lr = 0.1
I0524 02:19:18.473078 11654 solver.cpp:239] Iteration 21680 (1.50004 iter/s, 6.6665s/10 iters), loss = 6.3594
I0524 02:19:18.473129 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3594 (* 1 = 6.3594 loss)
I0524 02:19:18.586096 11654 sgd_solver.cpp:112] Iteration 21680, lr = 0.1
I0524 02:19:28.087631 11654 solver.cpp:239] Iteration 21690 (1.04013 iter/s, 9.61414s/10 iters), loss = 6.86455
I0524 02:19:28.087874 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86455 (* 1 = 6.86455 loss)
I0524 02:19:28.087929 11654 sgd_solver.cpp:112] Iteration 21690, lr = 0.1
I0524 02:19:35.450876 11654 solver.cpp:239] Iteration 21700 (1.35819 iter/s, 7.36274s/10 iters), loss = 6.92621
I0524 02:19:35.450932 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92621 (* 1 = 6.92621 loss)
I0524 02:19:35.450948 11654 sgd_solver.cpp:112] Iteration 21700, lr = 0.1
I0524 02:19:43.464555 11654 solver.cpp:239] Iteration 21710 (1.24826 iter/s, 8.01112s/10 iters), loss = 5.91547
I0524 02:19:43.464601 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91547 (* 1 = 5.91547 loss)
I0524 02:19:43.464617 11654 sgd_solver.cpp:112] Iteration 21710, lr = 0.1
I0524 02:19:50.613674 11654 solver.cpp:239] Iteration 21720 (1.39884 iter/s, 7.1488s/10 iters), loss = 7.05263
I0524 02:19:50.613739 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05263 (* 1 = 7.05263 loss)
I0524 02:19:50.613875 11654 sgd_solver.cpp:112] Iteration 21720, lr = 0.1
I0524 02:19:57.972594 11654 solver.cpp:239] Iteration 21730 (1.35896 iter/s, 7.35857s/10 iters), loss = 6.7329
I0524 02:19:57.972647 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7329 (* 1 = 6.7329 loss)
I0524 02:19:57.972860 11654 sgd_solver.cpp:112] Iteration 21730, lr = 0.1
I0524 02:20:05.981894 11654 solver.cpp:239] Iteration 21740 (1.24861 iter/s, 8.00893s/10 iters), loss = 6.46269
I0524 02:20:05.982084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46269 (* 1 = 6.46269 loss)
I0524 02:20:05.982278 11654 sgd_solver.cpp:112] Iteration 21740, lr = 0.1
I0524 02:20:13.484628 11654 solver.cpp:239] Iteration 21750 (1.33293 iter/s, 7.50226s/10 iters), loss = 6.52717
I0524 02:20:13.484686 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52717 (* 1 = 6.52717 loss)
I0524 02:20:13.484889 11654 sgd_solver.cpp:112] Iteration 21750, lr = 0.1
I0524 02:20:20.117961 11654 solver.cpp:239] Iteration 21760 (1.50761 iter/s, 6.63303s/10 iters), loss = 7.09913
I0524 02:20:20.118002 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09913 (* 1 = 7.09913 loss)
I0524 02:20:20.118067 11654 sgd_solver.cpp:112] Iteration 21760, lr = 0.1
I0524 02:20:28.634102 11654 solver.cpp:239] Iteration 21770 (1.17429 iter/s, 8.51577s/10 iters), loss = 7.27102
I0524 02:20:28.634160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27102 (* 1 = 7.27102 loss)
I0524 02:20:28.634598 11654 sgd_solver.cpp:112] Iteration 21770, lr = 0.1
I0524 02:20:35.195180 11654 solver.cpp:239] Iteration 21780 (1.52421 iter/s, 6.56076s/10 iters), loss = 6.75589
I0524 02:20:35.195240 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75589 (* 1 = 6.75589 loss)
I0524 02:20:35.195258 11654 sgd_solver.cpp:112] Iteration 21780, lr = 0.1
I0524 02:20:41.531016 11654 solver.cpp:239] Iteration 21790 (1.5784 iter/s, 6.33554s/10 iters), loss = 7.10907
I0524 02:20:41.531266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10907 (* 1 = 7.10907 loss)
I0524 02:20:41.531324 11654 sgd_solver.cpp:112] Iteration 21790, lr = 0.1
I0524 02:20:49.348009 11654 solver.cpp:239] Iteration 21800 (1.27935 iter/s, 7.81645s/10 iters), loss = 6.55139
I0524 02:20:49.348062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55139 (* 1 = 6.55139 loss)
I0524 02:20:49.348078 11654 sgd_solver.cpp:112] Iteration 21800, lr = 0.1
I0524 02:20:57.141290 11654 solver.cpp:239] Iteration 21810 (1.28325 iter/s, 7.79273s/10 iters), loss = 6.54462
I0524 02:20:57.141348 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54462 (* 1 = 6.54462 loss)
I0524 02:20:58.034140 11654 sgd_solver.cpp:112] Iteration 21810, lr = 0.1
I0524 02:21:05.018144 11654 solver.cpp:239] Iteration 21820 (1.2696 iter/s, 7.87649s/10 iters), loss = 7.42311
I0524 02:21:05.018198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.42311 (* 1 = 7.42311 loss)
I0524 02:21:05.018376 11654 sgd_solver.cpp:112] Iteration 21820, lr = 0.1
I0524 02:21:13.067745 11654 solver.cpp:239] Iteration 21830 (1.24235 iter/s, 8.04925s/10 iters), loss = 6.50659
I0524 02:21:13.067978 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50659 (* 1 = 6.50659 loss)
I0524 02:21:13.447921 11654 sgd_solver.cpp:112] Iteration 21830, lr = 0.1
I0524 02:21:20.224335 11654 solver.cpp:239] Iteration 21840 (1.39741 iter/s, 7.15611s/10 iters), loss = 6.39879
I0524 02:21:20.224385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39879 (* 1 = 6.39879 loss)
I0524 02:21:20.224402 11654 sgd_solver.cpp:112] Iteration 21840, lr = 0.1
I0524 02:21:26.466951 11654 solver.cpp:239] Iteration 21850 (1.60254 iter/s, 6.2401s/10 iters), loss = 6.70793
I0524 02:21:26.467000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70793 (* 1 = 6.70793 loss)
I0524 02:21:27.064898 11654 sgd_solver.cpp:112] Iteration 21850, lr = 0.1
I0524 02:21:34.309031 11654 solver.cpp:239] Iteration 21860 (1.27523 iter/s, 7.84173s/10 iters), loss = 6.24384
I0524 02:21:34.309075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24384 (* 1 = 6.24384 loss)
I0524 02:21:34.309089 11654 sgd_solver.cpp:112] Iteration 21860, lr = 0.1
I0524 02:21:40.732386 11654 solver.cpp:239] Iteration 21870 (1.55693 iter/s, 6.42288s/10 iters), loss = 5.82196
I0524 02:21:40.732440 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82196 (* 1 = 5.82196 loss)
I0524 02:21:40.732456 11654 sgd_solver.cpp:112] Iteration 21870, lr = 0.1
I0524 02:21:47.015321 11654 solver.cpp:239] Iteration 21880 (1.59169 iter/s, 6.28265s/10 iters), loss = 7.2653
I0524 02:21:47.015605 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2653 (* 1 = 7.2653 loss)
I0524 02:21:47.015666 11654 sgd_solver.cpp:112] Iteration 21880, lr = 0.1
I0524 02:21:54.430820 11654 solver.cpp:239] Iteration 21890 (1.34863 iter/s, 7.41496s/10 iters), loss = 6.94068
I0524 02:21:54.430886 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94068 (* 1 = 6.94068 loss)
I0524 02:21:54.431169 11654 sgd_solver.cpp:112] Iteration 21890, lr = 0.1
I0524 02:22:01.182440 11654 solver.cpp:239] Iteration 21900 (1.4812 iter/s, 6.7513s/10 iters), loss = 6.42323
I0524 02:22:01.182490 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42323 (* 1 = 6.42323 loss)
I0524 02:22:01.182507 11654 sgd_solver.cpp:112] Iteration 21900, lr = 0.1
I0524 02:22:09.855727 11654 solver.cpp:239] Iteration 21910 (1.15302 iter/s, 8.67291s/10 iters), loss = 6.95035
I0524 02:22:09.855777 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95035 (* 1 = 6.95035 loss)
I0524 02:22:09.856199 11654 sgd_solver.cpp:112] Iteration 21910, lr = 0.1
I0524 02:22:16.192486 11654 solver.cpp:239] Iteration 21920 (1.57817 iter/s, 6.33646s/10 iters), loss = 7.83864
I0524 02:22:16.192541 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.83864 (* 1 = 7.83864 loss)
I0524 02:22:16.192703 11654 sgd_solver.cpp:112] Iteration 21920, lr = 0.1
I0524 02:22:22.649930 11654 solver.cpp:239] Iteration 21930 (1.54867 iter/s, 6.45715s/10 iters), loss = 6.98661
I0524 02:22:22.650061 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98661 (* 1 = 6.98661 loss)
I0524 02:22:22.650334 11654 sgd_solver.cpp:112] Iteration 21930, lr = 0.1
I0524 02:22:30.758776 11654 solver.cpp:239] Iteration 21940 (1.23329 iter/s, 8.10839s/10 iters), loss = 6.53371
I0524 02:22:30.758855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53371 (* 1 = 6.53371 loss)
I0524 02:22:30.758882 11654 sgd_solver.cpp:112] Iteration 21940, lr = 0.1
I0524 02:22:38.386873 11654 solver.cpp:239] Iteration 21950 (1.31138 iter/s, 7.62555s/10 iters), loss = 7.0237
I0524 02:22:38.386940 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0237 (* 1 = 7.0237 loss)
I0524 02:22:38.387301 11654 sgd_solver.cpp:112] Iteration 21950, lr = 0.1
I0524 02:22:44.963438 11654 solver.cpp:239] Iteration 21960 (1.52062 iter/s, 6.57625s/10 iters), loss = 6.31141
I0524 02:22:44.963485 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31141 (* 1 = 6.31141 loss)
I0524 02:22:44.963603 11654 sgd_solver.cpp:112] Iteration 21960, lr = 0.1
I0524 02:22:54.237612 11654 solver.cpp:239] Iteration 21970 (1.07831 iter/s, 9.27377s/10 iters), loss = 7.54726
I0524 02:22:54.237881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54726 (* 1 = 7.54726 loss)
I0524 02:22:54.237946 11654 sgd_solver.cpp:112] Iteration 21970, lr = 0.1
I0524 02:23:01.420491 11654 solver.cpp:239] Iteration 21980 (1.39234 iter/s, 7.18218s/10 iters), loss = 6.35792
I0524 02:23:01.420544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35792 (* 1 = 6.35792 loss)
I0524 02:23:01.420560 11654 sgd_solver.cpp:112] Iteration 21980, lr = 0.1
I0524 02:23:09.452282 11654 solver.cpp:239] Iteration 21990 (1.24515 iter/s, 8.03118s/10 iters), loss = 6.49079
I0524 02:23:09.452318 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49079 (* 1 = 6.49079 loss)
I0524 02:23:09.811766 11654 sgd_solver.cpp:112] Iteration 21990, lr = 0.1
I0524 02:23:16.527783 11654 solver.cpp:239] Iteration 22000 (1.41339 iter/s, 7.07518s/10 iters), loss = 7.39623
I0524 02:23:16.527840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39623 (* 1 = 7.39623 loss)
I0524 02:23:16.528136 11654 sgd_solver.cpp:112] Iteration 22000, lr = 0.1
I0524 02:23:25.389232 11654 solver.cpp:239] Iteration 22010 (1.12854 iter/s, 8.86104s/10 iters), loss = 7.00812
I0524 02:23:25.389554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00812 (* 1 = 7.00812 loss)
I0524 02:23:25.389622 11654 sgd_solver.cpp:112] Iteration 22010, lr = 0.1
I0524 02:23:32.742784 11654 solver.cpp:239] Iteration 22020 (1.35999 iter/s, 7.353s/10 iters), loss = 7.09509
I0524 02:23:32.742837 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09509 (* 1 = 7.09509 loss)
I0524 02:23:33.240391 11654 sgd_solver.cpp:112] Iteration 22020, lr = 0.1
I0524 02:23:40.108654 11654 solver.cpp:239] Iteration 22030 (1.35768 iter/s, 7.36553s/10 iters), loss = 6.26886
I0524 02:23:40.108712 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26886 (* 1 = 6.26886 loss)
I0524 02:23:40.882345 11654 sgd_solver.cpp:112] Iteration 22030, lr = 0.1
I0524 02:23:47.019937 11654 solver.cpp:239] Iteration 22040 (1.44698 iter/s, 6.91096s/10 iters), loss = 6.14767
I0524 02:23:47.019987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14767 (* 1 = 6.14767 loss)
I0524 02:23:47.020104 11654 sgd_solver.cpp:112] Iteration 22040, lr = 0.1
I0524 02:23:54.951459 11654 solver.cpp:239] Iteration 22050 (1.26085 iter/s, 7.93117s/10 iters), loss = 6.94147
I0524 02:23:54.951532 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94147 (* 1 = 6.94147 loss)
I0524 02:23:54.951944 11654 sgd_solver.cpp:112] Iteration 22050, lr = 0.1
I0524 02:24:02.180387 11654 solver.cpp:239] Iteration 22060 (1.38339 iter/s, 7.2286s/10 iters), loss = 6.51597
I0524 02:24:02.180481 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51597 (* 1 = 6.51597 loss)
I0524 02:24:02.180646 11654 sgd_solver.cpp:112] Iteration 22060, lr = 0.1
I0524 02:24:08.993789 11654 solver.cpp:239] Iteration 22070 (1.46778 iter/s, 6.81303s/10 iters), loss = 6.79018
I0524 02:24:08.993850 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79018 (* 1 = 6.79018 loss)
I0524 02:24:08.994380 11654 sgd_solver.cpp:112] Iteration 22070, lr = 0.1
I0524 02:24:16.303113 11654 solver.cpp:239] Iteration 22080 (1.36818 iter/s, 7.30898s/10 iters), loss = 6.7044
I0524 02:24:16.303176 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7044 (* 1 = 6.7044 loss)
I0524 02:24:16.303299 11654 sgd_solver.cpp:112] Iteration 22080, lr = 0.1
I0524 02:24:25.194381 11654 solver.cpp:239] Iteration 22090 (1.12475 iter/s, 8.89086s/10 iters), loss = 6.96811
I0524 02:24:25.194442 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96811 (* 1 = 6.96811 loss)
I0524 02:24:25.194728 11654 sgd_solver.cpp:112] Iteration 22090, lr = 0.1
I0524 02:24:33.972966 11654 solver.cpp:239] Iteration 22100 (1.13919 iter/s, 8.7782s/10 iters), loss = 7.77634
I0524 02:24:33.973114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77634 (* 1 = 7.77634 loss)
I0524 02:24:34.122052 11654 sgd_solver.cpp:112] Iteration 22100, lr = 0.1
I0524 02:24:40.886777 11654 solver.cpp:239] Iteration 22110 (1.44647 iter/s, 6.9134s/10 iters), loss = 7.43088
I0524 02:24:40.886829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43088 (* 1 = 7.43088 loss)
I0524 02:24:40.886844 11654 sgd_solver.cpp:112] Iteration 22110, lr = 0.1
I0524 02:24:47.307468 11654 solver.cpp:239] Iteration 22120 (1.55755 iter/s, 6.42033s/10 iters), loss = 6.8339
I0524 02:24:47.307529 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8339 (* 1 = 6.8339 loss)
I0524 02:24:47.307793 11654 sgd_solver.cpp:112] Iteration 22120, lr = 0.1
I0524 02:24:54.129114 11654 solver.cpp:239] Iteration 22130 (1.46599 iter/s, 6.82133s/10 iters), loss = 7.20449
I0524 02:24:54.129163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20449 (* 1 = 7.20449 loss)
I0524 02:24:54.129179 11654 sgd_solver.cpp:112] Iteration 22130, lr = 0.1
I0524 02:25:02.895017 11654 solver.cpp:239] Iteration 22140 (1.14084 iter/s, 8.76546s/10 iters), loss = 6.93693
I0524 02:25:02.895056 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93693 (* 1 = 6.93693 loss)
I0524 02:25:02.895069 11654 sgd_solver.cpp:112] Iteration 22140, lr = 0.1
I0524 02:25:09.943718 11654 solver.cpp:239] Iteration 22150 (1.41876 iter/s, 7.04839s/10 iters), loss = 7.16512
I0524 02:25:09.944007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16512 (* 1 = 7.16512 loss)
I0524 02:25:09.944074 11654 sgd_solver.cpp:112] Iteration 22150, lr = 0.1
I0524 02:25:18.339946 11654 solver.cpp:239] Iteration 22160 (1.1911 iter/s, 8.39563s/10 iters), loss = 7.31931
I0524 02:25:18.340000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31931 (* 1 = 7.31931 loss)
I0524 02:25:18.569972 11654 sgd_solver.cpp:112] Iteration 22160, lr = 0.1
I0524 02:25:25.151940 11654 solver.cpp:239] Iteration 22170 (1.46807 iter/s, 6.81165s/10 iters), loss = 6.01302
I0524 02:25:25.152048 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01302 (* 1 = 6.01302 loss)
I0524 02:25:25.152523 11654 sgd_solver.cpp:112] Iteration 22170, lr = 0.1
I0524 02:25:31.351231 11654 solver.cpp:239] Iteration 22180 (1.61317 iter/s, 6.19897s/10 iters), loss = 6.41899
I0524 02:25:31.351286 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41899 (* 1 = 6.41899 loss)
I0524 02:25:31.351488 11654 sgd_solver.cpp:112] Iteration 22180, lr = 0.1
I0524 02:25:40.248841 11654 solver.cpp:239] Iteration 22190 (1.12395 iter/s, 8.89722s/10 iters), loss = 7.70144
I0524 02:25:40.248931 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70144 (* 1 = 7.70144 loss)
I0524 02:25:40.248948 11654 sgd_solver.cpp:112] Iteration 22190, lr = 0.1
I0524 02:25:48.041566 11654 solver.cpp:239] Iteration 22200 (1.28332 iter/s, 7.7923s/10 iters), loss = 6.54986
I0524 02:25:48.041617 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54986 (* 1 = 6.54986 loss)
I0524 02:25:48.439934 11654 sgd_solver.cpp:112] Iteration 22200, lr = 0.1
I0524 02:25:54.865300 11654 solver.cpp:239] Iteration 22210 (1.46554 iter/s, 6.82341s/10 iters), loss = 7.38116
I0524 02:25:54.865360 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.38116 (* 1 = 7.38116 loss)
I0524 02:25:54.865927 11654 sgd_solver.cpp:112] Iteration 22210, lr = 0.1
I0524 02:26:01.546226 11654 solver.cpp:239] Iteration 22220 (1.49687 iter/s, 6.6806s/10 iters), loss = 7.10084
I0524 02:26:01.546291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10084 (* 1 = 7.10084 loss)
I0524 02:26:01.546689 11654 sgd_solver.cpp:112] Iteration 22220, lr = 0.1
I0524 02:26:08.926594 11654 solver.cpp:239] Iteration 22230 (1.35501 iter/s, 7.38003s/10 iters), loss = 6.98828
I0524 02:26:08.926635 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98828 (* 1 = 6.98828 loss)
I0524 02:26:09.186676 11654 sgd_solver.cpp:112] Iteration 22230, lr = 0.1
I0524 02:26:15.791400 11654 solver.cpp:239] Iteration 22240 (1.45677 iter/s, 6.86449s/10 iters), loss = 6.57014
I0524 02:26:15.791645 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57014 (* 1 = 6.57014 loss)
I0524 02:26:15.791704 11654 sgd_solver.cpp:112] Iteration 22240, lr = 0.1
I0524 02:26:24.206280 11654 solver.cpp:239] Iteration 22250 (1.18844 iter/s, 8.41438s/10 iters), loss = 5.88622
I0524 02:26:24.206334 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88622 (* 1 = 5.88622 loss)
I0524 02:26:25.033478 11654 sgd_solver.cpp:112] Iteration 22250, lr = 0.1
I0524 02:26:32.872262 11654 solver.cpp:239] Iteration 22260 (1.15399 iter/s, 8.6656s/10 iters), loss = 7.8717
I0524 02:26:32.872319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.8717 (* 1 = 7.8717 loss)
I0524 02:26:32.872339 11654 sgd_solver.cpp:112] Iteration 22260, lr = 0.1
I0524 02:26:39.848827 11654 solver.cpp:239] Iteration 22270 (1.43389 iter/s, 6.97403s/10 iters), loss = 7.01492
I0524 02:26:39.848889 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01492 (* 1 = 7.01492 loss)
I0524 02:26:39.849045 11654 sgd_solver.cpp:112] Iteration 22270, lr = 0.1
I0524 02:26:46.963762 11654 solver.cpp:239] Iteration 22280 (1.40556 iter/s, 7.11461s/10 iters), loss = 7.43306
I0524 02:26:46.964074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43306 (* 1 = 7.43306 loss)
I0524 02:26:46.964128 11654 sgd_solver.cpp:112] Iteration 22280, lr = 0.1
I0524 02:26:53.554380 11654 solver.cpp:239] Iteration 22290 (1.51745 iter/s, 6.59002s/10 iters), loss = 7.28688
I0524 02:26:53.554435 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28688 (* 1 = 7.28688 loss)
I0524 02:26:54.102859 11654 sgd_solver.cpp:112] Iteration 22290, lr = 0.1
I0524 02:27:00.267693 11654 solver.cpp:239] Iteration 22300 (1.48965 iter/s, 6.713s/10 iters), loss = 6.84975
I0524 02:27:00.267742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84975 (* 1 = 6.84975 loss)
I0524 02:27:00.267938 11654 sgd_solver.cpp:112] Iteration 22300, lr = 0.1
I0524 02:27:07.316239 11654 solver.cpp:239] Iteration 22310 (1.4188 iter/s, 7.0482s/10 iters), loss = 6.58691
I0524 02:27:07.316295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58691 (* 1 = 6.58691 loss)
I0524 02:27:07.316537 11654 sgd_solver.cpp:112] Iteration 22310, lr = 0.1
I0524 02:27:14.347051 11654 solver.cpp:239] Iteration 22320 (1.42238 iter/s, 7.03049s/10 iters), loss = 7.66583
I0524 02:27:14.347095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.66583 (* 1 = 7.66583 loss)
I0524 02:27:14.377406 11654 sgd_solver.cpp:112] Iteration 22320, lr = 0.1
I0524 02:27:22.336202 11654 solver.cpp:239] Iteration 22330 (1.25175 iter/s, 7.98879s/10 iters), loss = 6.77508
I0524 02:27:22.336464 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77508 (* 1 = 6.77508 loss)
I0524 02:27:22.677839 11654 sgd_solver.cpp:112] Iteration 22330, lr = 0.1
I0524 02:27:29.666832 11654 solver.cpp:239] Iteration 22340 (1.36423 iter/s, 7.33012s/10 iters), loss = 6.65873
I0524 02:27:29.666890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65873 (* 1 = 6.65873 loss)
I0524 02:27:29.667023 11654 sgd_solver.cpp:112] Iteration 22340, lr = 0.1
I0524 02:27:37.052304 11654 solver.cpp:239] Iteration 22350 (1.35407 iter/s, 7.38514s/10 iters), loss = 7.4097
I0524 02:27:37.052359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4097 (* 1 = 7.4097 loss)
I0524 02:27:37.052376 11654 sgd_solver.cpp:112] Iteration 22350, lr = 0.1
I0524 02:27:44.000666 11654 solver.cpp:239] Iteration 22360 (1.43971 iter/s, 6.94583s/10 iters), loss = 7.06924
I0524 02:27:44.000708 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06924 (* 1 = 7.06924 loss)
I0524 02:27:44.000721 11654 sgd_solver.cpp:112] Iteration 22360, lr = 0.1
I0524 02:27:50.636643 11654 solver.cpp:239] Iteration 22370 (1.50701 iter/s, 6.63567s/10 iters), loss = 7.0787
I0524 02:27:50.636709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0787 (* 1 = 7.0787 loss)
I0524 02:27:50.636894 11654 sgd_solver.cpp:112] Iteration 22370, lr = 0.1
I0524 02:27:58.548337 11654 solver.cpp:239] Iteration 22380 (1.26401 iter/s, 7.91134s/10 iters), loss = 6.97378
I0524 02:27:58.548579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97378 (* 1 = 6.97378 loss)
I0524 02:27:58.548645 11654 sgd_solver.cpp:112] Iteration 22380, lr = 0.1
I0524 02:28:08.235335 11654 solver.cpp:239] Iteration 22390 (1.03237 iter/s, 9.68641s/10 iters), loss = 6.55805
I0524 02:28:08.235390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55805 (* 1 = 6.55805 loss)
I0524 02:28:08.235407 11654 sgd_solver.cpp:112] Iteration 22390, lr = 0.1
I0524 02:28:14.734377 11654 solver.cpp:239] Iteration 22400 (1.53928 iter/s, 6.49653s/10 iters), loss = 6.45329
I0524 02:28:14.734428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45329 (* 1 = 6.45329 loss)
I0524 02:28:14.734489 11654 sgd_solver.cpp:112] Iteration 22400, lr = 0.1
I0524 02:28:22.287662 11654 solver.cpp:239] Iteration 22410 (1.32399 iter/s, 7.55295s/10 iters), loss = 6.68118
I0524 02:28:22.287725 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68118 (* 1 = 6.68118 loss)
I0524 02:28:22.287744 11654 sgd_solver.cpp:112] Iteration 22410, lr = 0.1
I0524 02:28:29.713613 11654 solver.cpp:239] Iteration 22420 (1.34669 iter/s, 7.42562s/10 iters), loss = 7.40436
I0524 02:28:29.713909 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40436 (* 1 = 7.40436 loss)
I0524 02:28:30.431486 11654 sgd_solver.cpp:112] Iteration 22420, lr = 0.1
I0524 02:28:39.170467 11654 solver.cpp:239] Iteration 22430 (1.0575 iter/s, 9.45624s/10 iters), loss = 6.46123
I0524 02:28:39.170524 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46123 (* 1 = 6.46123 loss)
I0524 02:28:39.171087 11654 sgd_solver.cpp:112] Iteration 22430, lr = 0.1
I0524 02:28:46.060520 11654 solver.cpp:239] Iteration 22440 (1.45144 iter/s, 6.88973s/10 iters), loss = 7.00693
I0524 02:28:46.060582 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00693 (* 1 = 7.00693 loss)
I0524 02:28:46.062522 11654 sgd_solver.cpp:112] Iteration 22440, lr = 0.1
I0524 02:28:52.477602 11654 solver.cpp:239] Iteration 22450 (1.55842 iter/s, 6.41677s/10 iters), loss = 6.46346
I0524 02:28:52.477659 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46346 (* 1 = 6.46346 loss)
I0524 02:28:52.477887 11654 sgd_solver.cpp:112] Iteration 22450, lr = 0.1
I0524 02:28:58.539111 11654 solver.cpp:239] Iteration 22460 (1.64983 iter/s, 6.06122s/10 iters), loss = 6.27649
I0524 02:28:58.539151 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27649 (* 1 = 6.27649 loss)
I0524 02:28:58.539165 11654 sgd_solver.cpp:112] Iteration 22460, lr = 0.1
I0524 02:29:05.748626 11654 solver.cpp:239] Iteration 22470 (1.38712 iter/s, 7.20918s/10 iters), loss = 6.59071
I0524 02:29:05.748754 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59071 (* 1 = 6.59071 loss)
I0524 02:29:05.748786 11654 sgd_solver.cpp:112] Iteration 22470, lr = 0.1
I0524 02:29:13.630499 11654 solver.cpp:239] Iteration 22480 (1.2688 iter/s, 7.88145s/10 iters), loss = 6.63849
I0524 02:29:13.630559 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63849 (* 1 = 6.63849 loss)
I0524 02:29:13.631721 11654 sgd_solver.cpp:112] Iteration 22480, lr = 0.1
I0524 02:29:19.672209 11654 solver.cpp:239] Iteration 22490 (1.65524 iter/s, 6.04142s/10 iters), loss = 7.43104
I0524 02:29:19.672262 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43104 (* 1 = 7.43104 loss)
I0524 02:29:19.672392 11654 sgd_solver.cpp:112] Iteration 22490, lr = 0.1
I0524 02:29:25.916375 11654 solver.cpp:239] Iteration 22500 (1.60157 iter/s, 6.24387s/10 iters), loss = 6.13037
I0524 02:29:25.916427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13037 (* 1 = 6.13037 loss)
I0524 02:29:25.916620 11654 sgd_solver.cpp:112] Iteration 22500, lr = 0.1
I0524 02:29:32.030310 11654 solver.cpp:239] Iteration 22510 (1.63569 iter/s, 6.11364s/10 iters), loss = 6.40454
I0524 02:29:32.030362 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40454 (* 1 = 6.40454 loss)
I0524 02:29:32.030768 11654 sgd_solver.cpp:112] Iteration 22510, lr = 0.1
I0524 02:29:40.314482 11654 solver.cpp:239] Iteration 22520 (1.20718 iter/s, 8.2838s/10 iters), loss = 6.47863
I0524 02:29:40.314586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47863 (* 1 = 6.47863 loss)
I0524 02:29:40.314605 11654 sgd_solver.cpp:112] Iteration 22520, lr = 0.1
I0524 02:29:46.617463 11654 solver.cpp:239] Iteration 22530 (1.58664 iter/s, 6.30261s/10 iters), loss = 7.11943
I0524 02:29:46.617504 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11943 (* 1 = 7.11943 loss)
I0524 02:29:46.733839 11654 sgd_solver.cpp:112] Iteration 22530, lr = 0.1
I0524 02:29:54.711853 11654 solver.cpp:239] Iteration 22540 (1.23548 iter/s, 8.09403s/10 iters), loss = 6.34301
I0524 02:29:54.711904 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34301 (* 1 = 6.34301 loss)
I0524 02:29:54.711918 11654 sgd_solver.cpp:112] Iteration 22540, lr = 0.1
I0524 02:30:00.872303 11654 solver.cpp:239] Iteration 22550 (1.62336 iter/s, 6.16008s/10 iters), loss = 6.1036
I0524 02:30:00.872365 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1036 (* 1 = 6.1036 loss)
I0524 02:30:00.872622 11654 sgd_solver.cpp:112] Iteration 22550, lr = 0.1
I0524 02:30:07.696013 11654 solver.cpp:239] Iteration 22560 (1.46555 iter/s, 6.82339s/10 iters), loss = 5.88898
I0524 02:30:07.696063 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88898 (* 1 = 5.88898 loss)
I0524 02:30:07.696080 11654 sgd_solver.cpp:112] Iteration 22560, lr = 0.1
I0524 02:30:14.460743 11654 solver.cpp:239] Iteration 22570 (1.47834 iter/s, 6.76433s/10 iters), loss = 7.39217
I0524 02:30:14.461048 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39217 (* 1 = 7.39217 loss)
I0524 02:30:14.461230 11654 sgd_solver.cpp:112] Iteration 22570, lr = 0.1
I0524 02:30:20.692446 11654 solver.cpp:239] Iteration 22580 (1.60483 iter/s, 6.23121s/10 iters), loss = 6.94736
I0524 02:30:20.692497 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94736 (* 1 = 6.94736 loss)
I0524 02:30:20.692811 11654 sgd_solver.cpp:112] Iteration 22580, lr = 0.1
I0524 02:30:26.928625 11654 solver.cpp:239] Iteration 22590 (1.60362 iter/s, 6.23588s/10 iters), loss = 6.56533
I0524 02:30:26.928679 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56533 (* 1 = 6.56533 loss)
I0524 02:30:26.928794 11654 sgd_solver.cpp:112] Iteration 22590, lr = 0.1
I0524 02:30:37.930299 11654 solver.cpp:239] Iteration 22600 (0.908991 iter/s, 11.0012s/10 iters), loss = 7.46496
I0524 02:30:37.930356 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.46496 (* 1 = 7.46496 loss)
I0524 02:30:37.930374 11654 sgd_solver.cpp:112] Iteration 22600, lr = 0.1
I0524 02:30:44.174342 11654 solver.cpp:239] Iteration 22610 (1.60162 iter/s, 6.24368s/10 iters), loss = 6.35598
I0524 02:30:44.174401 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35598 (* 1 = 6.35598 loss)
I0524 02:30:44.174420 11654 sgd_solver.cpp:112] Iteration 22610, lr = 0.1
I0524 02:30:53.427565 11654 solver.cpp:239] Iteration 22620 (1.08076 iter/s, 9.25276s/10 iters), loss = 7.29645
I0524 02:30:53.427842 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29645 (* 1 = 7.29645 loss)
I0524 02:30:53.428033 11654 sgd_solver.cpp:112] Iteration 22620, lr = 0.1
I0524 02:30:59.546814 11654 solver.cpp:239] Iteration 22630 (1.63431 iter/s, 6.11879s/10 iters), loss = 7.65267
I0524 02:30:59.546866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.65267 (* 1 = 7.65267 loss)
I0524 02:30:59.759404 11654 sgd_solver.cpp:112] Iteration 22630, lr = 0.1
I0524 02:31:06.456990 11654 solver.cpp:239] Iteration 22640 (1.44721 iter/s, 6.90986s/10 iters), loss = 6.05735
I0524 02:31:06.457036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05735 (* 1 = 6.05735 loss)
I0524 02:31:06.457314 11654 sgd_solver.cpp:112] Iteration 22640, lr = 0.1
I0524 02:31:14.277199 11654 solver.cpp:239] Iteration 22650 (1.2788 iter/s, 7.81986s/10 iters), loss = 6.56033
I0524 02:31:14.277251 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56033 (* 1 = 6.56033 loss)
I0524 02:31:15.295761 11654 sgd_solver.cpp:112] Iteration 22650, lr = 0.1
I0524 02:31:22.133353 11654 solver.cpp:239] Iteration 22660 (1.27294 iter/s, 7.85581s/10 iters), loss = 6.76841
I0524 02:31:22.133394 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76841 (* 1 = 6.76841 loss)
I0524 02:31:22.133405 11654 sgd_solver.cpp:112] Iteration 22660, lr = 0.1
I0524 02:31:28.665643 11654 solver.cpp:239] Iteration 22670 (1.53093 iter/s, 6.53199s/10 iters), loss = 6.4156
I0524 02:31:28.665907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4156 (* 1 = 6.4156 loss)
I0524 02:31:28.666105 11654 sgd_solver.cpp:112] Iteration 22670, lr = 0.1
I0524 02:31:34.877693 11654 solver.cpp:239] Iteration 22680 (1.60989 iter/s, 6.2116s/10 iters), loss = 6.69213
I0524 02:31:34.877735 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69213 (* 1 = 6.69213 loss)
I0524 02:31:34.880432 11654 sgd_solver.cpp:112] Iteration 22680, lr = 0.1
I0524 02:31:41.672380 11654 solver.cpp:239] Iteration 22690 (1.47181 iter/s, 6.79436s/10 iters), loss = 6.29935
I0524 02:31:41.672444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29935 (* 1 = 6.29935 loss)
I0524 02:31:41.672652 11654 sgd_solver.cpp:112] Iteration 22690, lr = 0.1
I0524 02:31:50.180248 11654 solver.cpp:239] Iteration 22700 (1.17544 iter/s, 8.50749s/10 iters), loss = 6.89646
I0524 02:31:50.180292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89646 (* 1 = 6.89646 loss)
I0524 02:31:50.180305 11654 sgd_solver.cpp:112] Iteration 22700, lr = 0.1
I0524 02:31:57.512648 11654 solver.cpp:239] Iteration 22710 (1.36428 iter/s, 7.3299s/10 iters), loss = 7.45712
I0524 02:31:57.512711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.45712 (* 1 = 7.45712 loss)
I0524 02:31:57.512863 11654 sgd_solver.cpp:112] Iteration 22710, lr = 0.1
I0524 02:32:04.574766 11654 solver.cpp:239] Iteration 22720 (1.41607 iter/s, 7.06179s/10 iters), loss = 6.09448
I0524 02:32:04.575064 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09448 (* 1 = 6.09448 loss)
I0524 02:32:05.339536 11654 sgd_solver.cpp:112] Iteration 22720, lr = 0.1
I0524 02:32:11.576658 11654 solver.cpp:239] Iteration 22730 (1.42829 iter/s, 7.00137s/10 iters), loss = 7.18793
I0524 02:32:11.576719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18793 (* 1 = 7.18793 loss)
I0524 02:32:11.577155 11654 sgd_solver.cpp:112] Iteration 22730, lr = 0.1
I0524 02:32:17.784335 11654 solver.cpp:239] Iteration 22740 (1.61098 iter/s, 6.20738s/10 iters), loss = 6.54192
I0524 02:32:17.784380 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54192 (* 1 = 6.54192 loss)
I0524 02:32:17.784572 11654 sgd_solver.cpp:112] Iteration 22740, lr = 0.1
I0524 02:32:24.402431 11654 solver.cpp:239] Iteration 22750 (1.51108 iter/s, 6.61778s/10 iters), loss = 6.29965
I0524 02:32:24.402496 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29965 (* 1 = 6.29965 loss)
I0524 02:32:24.402631 11654 sgd_solver.cpp:112] Iteration 22750, lr = 0.1
I0524 02:32:31.524961 11654 solver.cpp:239] Iteration 22760 (1.40406 iter/s, 7.1222s/10 iters), loss = 6.60129
I0524 02:32:31.525019 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60129 (* 1 = 6.60129 loss)
I0524 02:32:31.525038 11654 sgd_solver.cpp:112] Iteration 22760, lr = 0.1
I0524 02:32:38.668856 11654 solver.cpp:239] Iteration 22770 (1.39987 iter/s, 7.14351s/10 iters), loss = 7.72084
I0524 02:32:38.669172 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.72084 (* 1 = 7.72084 loss)
I0524 02:32:39.281697 11654 sgd_solver.cpp:112] Iteration 22770, lr = 0.1
I0524 02:32:47.468096 11654 solver.cpp:239] Iteration 22780 (1.13654 iter/s, 8.79864s/10 iters), loss = 6.77747
I0524 02:32:47.468152 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77747 (* 1 = 6.77747 loss)
I0524 02:32:47.471422 11654 sgd_solver.cpp:112] Iteration 22780, lr = 0.1
I0524 02:32:55.245162 11654 solver.cpp:239] Iteration 22790 (1.28589 iter/s, 7.77672s/10 iters), loss = 6.06303
I0524 02:32:55.245214 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06303 (* 1 = 6.06303 loss)
I0524 02:32:55.268631 11654 sgd_solver.cpp:112] Iteration 22790, lr = 0.1
I0524 02:33:02.301069 11654 solver.cpp:239] Iteration 22800 (1.41732 iter/s, 7.05556s/10 iters), loss = 6.67096
I0524 02:33:02.301168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67096 (* 1 = 6.67096 loss)
I0524 02:33:02.301446 11654 sgd_solver.cpp:112] Iteration 22800, lr = 0.1
I0524 02:33:11.119472 11654 solver.cpp:239] Iteration 22810 (1.13405 iter/s, 8.81799s/10 iters), loss = 6.41031
I0524 02:33:11.119804 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41031 (* 1 = 6.41031 loss)
I0524 02:33:11.396317 11654 sgd_solver.cpp:112] Iteration 22810, lr = 0.1
I0524 02:33:19.649152 11654 solver.cpp:239] Iteration 22820 (1.17246 iter/s, 8.52909s/10 iters), loss = 6.72965
I0524 02:33:19.649200 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72965 (* 1 = 6.72965 loss)
I0524 02:33:21.057809 11654 sgd_solver.cpp:112] Iteration 22820, lr = 0.1
I0524 02:33:29.842742 11654 solver.cpp:239] Iteration 22830 (0.981051 iter/s, 10.1931s/10 iters), loss = 6.00463
I0524 02:33:29.842793 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00463 (* 1 = 6.00463 loss)
I0524 02:33:29.843246 11654 sgd_solver.cpp:112] Iteration 22830, lr = 0.1
I0524 02:33:36.161501 11654 solver.cpp:239] Iteration 22840 (1.58267 iter/s, 6.31845s/10 iters), loss = 7.23898
I0524 02:33:36.161561 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23898 (* 1 = 7.23898 loss)
I0524 02:33:36.161782 11654 sgd_solver.cpp:112] Iteration 22840, lr = 0.1
I0524 02:33:43.072365 11654 solver.cpp:239] Iteration 22850 (1.44706 iter/s, 6.91054s/10 iters), loss = 7.03554
I0524 02:33:43.072542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03554 (* 1 = 7.03554 loss)
I0524 02:33:43.945698 11654 sgd_solver.cpp:112] Iteration 22850, lr = 0.1
I0524 02:33:52.174691 11654 solver.cpp:239] Iteration 22860 (1.09868 iter/s, 9.10179s/10 iters), loss = 6.6122
I0524 02:33:52.174782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6122 (* 1 = 6.6122 loss)
I0524 02:33:52.174813 11654 sgd_solver.cpp:112] Iteration 22860, lr = 0.1
I0524 02:33:59.611804 11654 solver.cpp:239] Iteration 22870 (1.34478 iter/s, 7.43617s/10 iters), loss = 6.93393
I0524 02:33:59.611855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93393 (* 1 = 6.93393 loss)
I0524 02:33:59.611872 11654 sgd_solver.cpp:112] Iteration 22870, lr = 0.1
I0524 02:34:05.910203 11654 solver.cpp:239] Iteration 22880 (1.58835 iter/s, 6.29586s/10 iters), loss = 6.87453
I0524 02:34:05.910253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87453 (* 1 = 6.87453 loss)
I0524 02:34:05.910303 11654 sgd_solver.cpp:112] Iteration 22880, lr = 0.1
I0524 02:34:13.460882 11654 solver.cpp:239] Iteration 22890 (1.32444 iter/s, 7.55034s/10 iters), loss = 6.59755
I0524 02:34:13.460981 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59755 (* 1 = 6.59755 loss)
I0524 02:34:13.478325 11654 sgd_solver.cpp:112] Iteration 22890, lr = 0.1
I0524 02:34:19.862208 11654 solver.cpp:239] Iteration 22900 (1.56226 iter/s, 6.40099s/10 iters), loss = 7.915
I0524 02:34:19.862249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.915 (* 1 = 7.915 loss)
I0524 02:34:19.862505 11654 sgd_solver.cpp:112] Iteration 22900, lr = 0.1
I0524 02:34:27.585436 11654 solver.cpp:239] Iteration 22910 (1.29485 iter/s, 7.72289s/10 iters), loss = 7.37915
I0524 02:34:27.585482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.37915 (* 1 = 7.37915 loss)
I0524 02:34:27.604845 11654 sgd_solver.cpp:112] Iteration 22910, lr = 0.1
I0524 02:34:35.746589 11654 solver.cpp:239] Iteration 22920 (1.22537 iter/s, 8.16079s/10 iters), loss = 7.10386
I0524 02:34:35.746644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10386 (* 1 = 7.10386 loss)
I0524 02:34:35.746659 11654 sgd_solver.cpp:112] Iteration 22920, lr = 0.1
I0524 02:34:42.841637 11654 solver.cpp:239] Iteration 22930 (1.40951 iter/s, 7.09466s/10 iters), loss = 7.20701
I0524 02:34:42.841688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20701 (* 1 = 7.20701 loss)
I0524 02:34:42.841862 11654 sgd_solver.cpp:112] Iteration 22930, lr = 0.1
I0524 02:34:49.181398 11654 solver.cpp:239] Iteration 22940 (1.57742 iter/s, 6.33946s/10 iters), loss = 6.55584
I0524 02:34:49.181691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55584 (* 1 = 6.55584 loss)
I0524 02:34:49.690798 11654 sgd_solver.cpp:112] Iteration 22940, lr = 0.1
I0524 02:34:56.663805 11654 solver.cpp:239] Iteration 22950 (1.33656 iter/s, 7.48189s/10 iters), loss = 6.41267
I0524 02:34:56.663843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41267 (* 1 = 6.41267 loss)
I0524 02:34:56.664037 11654 sgd_solver.cpp:112] Iteration 22950, lr = 0.1
I0524 02:35:03.134992 11654 solver.cpp:239] Iteration 22960 (1.54538 iter/s, 6.47089s/10 iters), loss = 7.18485
I0524 02:35:03.135042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18485 (* 1 = 7.18485 loss)
I0524 02:35:03.135059 11654 sgd_solver.cpp:112] Iteration 22960, lr = 0.1
I0524 02:35:10.965195 11654 solver.cpp:239] Iteration 22970 (1.27753 iter/s, 7.82761s/10 iters), loss = 6.26519
I0524 02:35:10.965234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26519 (* 1 = 6.26519 loss)
I0524 02:35:11.017315 11654 sgd_solver.cpp:112] Iteration 22970, lr = 0.1
I0524 02:35:17.477433 11654 solver.cpp:239] Iteration 22980 (1.53564 iter/s, 6.51194s/10 iters), loss = 7.50041
I0524 02:35:17.477494 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50041 (* 1 = 7.50041 loss)
I0524 02:35:17.507318 11654 sgd_solver.cpp:112] Iteration 22980, lr = 0.1
I0524 02:35:24.025733 11654 solver.cpp:239] Iteration 22990 (1.52719 iter/s, 6.54799s/10 iters), loss = 5.97734
I0524 02:35:24.026067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97734 (* 1 = 5.97734 loss)
I0524 02:35:24.347839 11654 sgd_solver.cpp:112] Iteration 22990, lr = 0.1
I0524 02:35:31.163941 11654 solver.cpp:239] Iteration 23000 (1.40102 iter/s, 7.13766s/10 iters), loss = 5.3829
I0524 02:35:31.163990 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3829 (* 1 = 5.3829 loss)
I0524 02:35:31.164193 11654 sgd_solver.cpp:112] Iteration 23000, lr = 0.1
I0524 02:35:38.165153 11654 solver.cpp:239] Iteration 23010 (1.42839 iter/s, 7.00089s/10 iters), loss = 7.01557
I0524 02:35:38.165208 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01557 (* 1 = 7.01557 loss)
I0524 02:35:38.165225 11654 sgd_solver.cpp:112] Iteration 23010, lr = 0.1
I0524 02:35:44.658041 11654 solver.cpp:239] Iteration 23020 (1.54029 iter/s, 6.49228s/10 iters), loss = 7.50238
I0524 02:35:44.658095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50238 (* 1 = 7.50238 loss)
I0524 02:35:44.658196 11654 sgd_solver.cpp:112] Iteration 23020, lr = 0.1
I0524 02:35:51.247634 11654 solver.cpp:239] Iteration 23030 (1.51761 iter/s, 6.5893s/10 iters), loss = 6.33572
I0524 02:35:51.247673 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33572 (* 1 = 6.33572 loss)
I0524 02:35:51.247687 11654 sgd_solver.cpp:112] Iteration 23030, lr = 0.1
I0524 02:35:57.796517 11654 solver.cpp:239] Iteration 23040 (1.52709 iter/s, 6.5484s/10 iters), loss = 6.52183
I0524 02:35:57.796782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52183 (* 1 = 6.52183 loss)
I0524 02:35:58.146309 11654 sgd_solver.cpp:112] Iteration 23040, lr = 0.1
I0524 02:36:04.480901 11654 solver.cpp:239] Iteration 23050 (1.49613 iter/s, 6.68391s/10 iters), loss = 6.66335
I0524 02:36:04.480948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66335 (* 1 = 6.66335 loss)
I0524 02:36:04.480970 11654 sgd_solver.cpp:112] Iteration 23050, lr = 0.1
I0524 02:36:11.443104 11654 solver.cpp:239] Iteration 23060 (1.43639 iter/s, 6.96188s/10 iters), loss = 6.43254
I0524 02:36:11.443166 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43254 (* 1 = 6.43254 loss)
I0524 02:36:11.443375 11654 sgd_solver.cpp:112] Iteration 23060, lr = 0.1
I0524 02:36:18.765332 11654 solver.cpp:239] Iteration 23070 (1.36577 iter/s, 7.3219s/10 iters), loss = 7.35608
I0524 02:36:18.765372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.35608 (* 1 = 7.35608 loss)
I0524 02:36:18.765530 11654 sgd_solver.cpp:112] Iteration 23070, lr = 0.1
I0524 02:36:26.503046 11654 solver.cpp:239] Iteration 23080 (1.29243 iter/s, 7.73737s/10 iters), loss = 7.59425
I0524 02:36:26.503098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59425 (* 1 = 7.59425 loss)
I0524 02:36:26.503227 11654 sgd_solver.cpp:112] Iteration 23080, lr = 0.1
I0524 02:36:32.340526 11654 solver.cpp:239] Iteration 23090 (1.71315 iter/s, 5.8372s/10 iters), loss = 6.42854
I0524 02:36:32.340675 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42854 (* 1 = 6.42854 loss)
I0524 02:36:32.340976 11654 sgd_solver.cpp:112] Iteration 23090, lr = 0.1
I0524 02:36:40.567296 11654 solver.cpp:239] Iteration 23100 (1.21561 iter/s, 8.22631s/10 iters), loss = 6.49979
I0524 02:36:40.567333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49979 (* 1 = 6.49979 loss)
I0524 02:36:40.567404 11654 sgd_solver.cpp:112] Iteration 23100, lr = 0.1
I0524 02:36:48.286528 11654 solver.cpp:239] Iteration 23110 (1.29552 iter/s, 7.71889s/10 iters), loss = 6.2757
I0524 02:36:48.286579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2757 (* 1 = 6.2757 loss)
I0524 02:36:48.286634 11654 sgd_solver.cpp:112] Iteration 23110, lr = 0.1
I0524 02:36:54.911453 11654 solver.cpp:239] Iteration 23120 (1.50952 iter/s, 6.62462s/10 iters), loss = 6.82466
I0524 02:36:54.911501 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82466 (* 1 = 6.82466 loss)
I0524 02:36:55.038215 11654 sgd_solver.cpp:112] Iteration 23120, lr = 0.1
I0524 02:37:03.162407 11654 solver.cpp:239] Iteration 23130 (1.21203 iter/s, 8.25059s/10 iters), loss = 7.70202
I0524 02:37:03.162606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70202 (* 1 = 7.70202 loss)
I0524 02:37:03.162636 11654 sgd_solver.cpp:112] Iteration 23130, lr = 0.1
I0524 02:37:09.369518 11654 solver.cpp:239] Iteration 23140 (1.61117 iter/s, 6.20667s/10 iters), loss = 6.13093
I0524 02:37:09.369599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13093 (* 1 = 6.13093 loss)
I0524 02:37:09.371279 11654 sgd_solver.cpp:112] Iteration 23140, lr = 0.1
I0524 02:37:16.710492 11654 solver.cpp:239] Iteration 23150 (1.36228 iter/s, 7.34062s/10 iters), loss = 5.51061
I0524 02:37:16.710543 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51061 (* 1 = 5.51061 loss)
I0524 02:37:16.710644 11654 sgd_solver.cpp:112] Iteration 23150, lr = 0.1
I0524 02:37:24.117548 11654 solver.cpp:239] Iteration 23160 (1.35013 iter/s, 7.40671s/10 iters), loss = 6.91484
I0524 02:37:24.117614 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91484 (* 1 = 6.91484 loss)
I0524 02:37:24.118172 11654 sgd_solver.cpp:112] Iteration 23160, lr = 0.1
I0524 02:37:30.448066 11654 solver.cpp:239] Iteration 23170 (1.57973 iter/s, 6.33021s/10 iters), loss = 6.88151
I0524 02:37:30.448125 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88151 (* 1 = 6.88151 loss)
I0524 02:37:30.448357 11654 sgd_solver.cpp:112] Iteration 23170, lr = 0.1
I0524 02:37:36.529148 11654 solver.cpp:239] Iteration 23180 (1.64452 iter/s, 6.08079s/10 iters), loss = 6.19611
I0524 02:37:36.529428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19611 (* 1 = 6.19611 loss)
I0524 02:37:36.529491 11654 sgd_solver.cpp:112] Iteration 23180, lr = 0.1
I0524 02:37:42.807029 11654 solver.cpp:239] Iteration 23190 (1.59309 iter/s, 6.2771s/10 iters), loss = 7.05577
I0524 02:37:42.807090 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05577 (* 1 = 7.05577 loss)
I0524 02:37:42.807265 11654 sgd_solver.cpp:112] Iteration 23190, lr = 0.1
I0524 02:37:49.084161 11654 solver.cpp:239] Iteration 23200 (1.59316 iter/s, 6.27683s/10 iters), loss = 6.8274
I0524 02:37:49.084205 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8274 (* 1 = 6.8274 loss)
I0524 02:37:49.313339 11654 sgd_solver.cpp:112] Iteration 23200, lr = 0.1
I0524 02:37:57.014142 11654 solver.cpp:239] Iteration 23210 (1.26109 iter/s, 7.92963s/10 iters), loss = 7.62823
I0524 02:37:57.014194 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62823 (* 1 = 7.62823 loss)
I0524 02:37:57.014681 11654 sgd_solver.cpp:112] Iteration 23210, lr = 0.1
I0524 02:38:03.407997 11654 solver.cpp:239] Iteration 23220 (1.56408 iter/s, 6.39355s/10 iters), loss = 6.3848
I0524 02:38:03.408059 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3848 (* 1 = 6.3848 loss)
I0524 02:38:03.408438 11654 sgd_solver.cpp:112] Iteration 23220, lr = 0.1
I0524 02:38:11.008872 11654 solver.cpp:239] Iteration 23230 (1.3157 iter/s, 7.60053s/10 iters), loss = 7.32802
I0524 02:38:11.009004 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32802 (* 1 = 7.32802 loss)
I0524 02:38:12.343786 11654 sgd_solver.cpp:112] Iteration 23230, lr = 0.1
I0524 02:38:19.479743 11654 solver.cpp:239] Iteration 23240 (1.18058 iter/s, 8.47041s/10 iters), loss = 5.98051
I0524 02:38:19.479802 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98051 (* 1 = 5.98051 loss)
I0524 02:38:19.771646 11654 sgd_solver.cpp:112] Iteration 23240, lr = 0.1
I0524 02:38:28.177678 11654 solver.cpp:239] Iteration 23250 (1.14975 iter/s, 8.69755s/10 iters), loss = 6.26459
I0524 02:38:28.177734 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26459 (* 1 = 6.26459 loss)
I0524 02:38:28.177752 11654 sgd_solver.cpp:112] Iteration 23250, lr = 0.1
I0524 02:38:36.206147 11654 solver.cpp:239] Iteration 23260 (1.24562 iter/s, 8.0281s/10 iters), loss = 7.4222
I0524 02:38:36.206207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4222 (* 1 = 7.4222 loss)
I0524 02:38:36.330737 11654 sgd_solver.cpp:112] Iteration 23260, lr = 0.1
I0524 02:38:45.562146 11654 solver.cpp:239] Iteration 23270 (1.06888 iter/s, 9.35559s/10 iters), loss = 6.85015
I0524 02:38:45.562445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85015 (* 1 = 6.85015 loss)
I0524 02:38:45.562507 11654 sgd_solver.cpp:112] Iteration 23270, lr = 0.1
I0524 02:38:54.510201 11654 solver.cpp:239] Iteration 23280 (1.11766 iter/s, 8.94728s/10 iters), loss = 6.74844
I0524 02:38:54.510255 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74844 (* 1 = 6.74844 loss)
I0524 02:38:54.510762 11654 sgd_solver.cpp:112] Iteration 23280, lr = 0.1
I0524 02:39:02.593278 11654 solver.cpp:239] Iteration 23290 (1.23721 iter/s, 8.08272s/10 iters), loss = 6.11472
I0524 02:39:02.593320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11472 (* 1 = 6.11472 loss)
I0524 02:39:02.593350 11654 sgd_solver.cpp:112] Iteration 23290, lr = 0.1
I0524 02:39:09.582129 11654 solver.cpp:239] Iteration 23300 (1.43092 iter/s, 6.98853s/10 iters), loss = 6.86799
I0524 02:39:09.582192 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86799 (* 1 = 6.86799 loss)
I0524 02:39:09.582281 11654 sgd_solver.cpp:112] Iteration 23300, lr = 0.1
I0524 02:39:16.280751 11654 solver.cpp:239] Iteration 23310 (1.49291 iter/s, 6.69831s/10 iters), loss = 7.33506
I0524 02:39:16.281045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33506 (* 1 = 7.33506 loss)
I0524 02:39:16.281108 11654 sgd_solver.cpp:112] Iteration 23310, lr = 0.1
I0524 02:39:22.797276 11654 solver.cpp:239] Iteration 23320 (1.53515 iter/s, 6.51402s/10 iters), loss = 6.77071
I0524 02:39:22.797327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77071 (* 1 = 6.77071 loss)
I0524 02:39:22.797343 11654 sgd_solver.cpp:112] Iteration 23320, lr = 0.1
I0524 02:39:30.242523 11654 solver.cpp:239] Iteration 23330 (1.34321 iter/s, 7.44485s/10 iters), loss = 7.70014
I0524 02:39:30.242564 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.70014 (* 1 = 7.70014 loss)
I0524 02:39:30.306653 11654 sgd_solver.cpp:112] Iteration 23330, lr = 0.1
I0524 02:39:37.554239 11654 solver.cpp:239] Iteration 23340 (1.36773 iter/s, 7.31138s/10 iters), loss = 6.92578
I0524 02:39:37.554291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92578 (* 1 = 6.92578 loss)
I0524 02:39:37.563560 11654 sgd_solver.cpp:112] Iteration 23340, lr = 0.1
I0524 02:39:44.421718 11654 solver.cpp:239] Iteration 23350 (1.4562 iter/s, 6.86717s/10 iters), loss = 6.58444
I0524 02:39:44.421756 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58444 (* 1 = 6.58444 loss)
I0524 02:39:44.421772 11654 sgd_solver.cpp:112] Iteration 23350, lr = 0.1
I0524 02:39:53.395916 11654 solver.cpp:239] Iteration 23360 (1.11435 iter/s, 8.97381s/10 iters), loss = 6.20599
I0524 02:39:53.396242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20599 (* 1 = 6.20599 loss)
I0524 02:39:53.906303 11654 sgd_solver.cpp:112] Iteration 23360, lr = 0.1
I0524 02:40:00.898092 11654 solver.cpp:239] Iteration 23370 (1.33305 iter/s, 7.50161s/10 iters), loss = 6.73007
I0524 02:40:00.898156 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73007 (* 1 = 6.73007 loss)
I0524 02:40:00.898396 11654 sgd_solver.cpp:112] Iteration 23370, lr = 0.1
I0524 02:40:07.274111 11654 solver.cpp:239] Iteration 23380 (1.56845 iter/s, 6.37571s/10 iters), loss = 6.63222
I0524 02:40:07.274168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63222 (* 1 = 6.63222 loss)
I0524 02:40:07.276401 11654 sgd_solver.cpp:112] Iteration 23380, lr = 0.1
I0524 02:40:16.424607 11654 solver.cpp:239] Iteration 23390 (1.09288 iter/s, 9.15009s/10 iters), loss = 5.39483
I0524 02:40:16.424664 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.39483 (* 1 = 5.39483 loss)
I0524 02:40:16.424679 11654 sgd_solver.cpp:112] Iteration 23390, lr = 0.1
I0524 02:40:23.824376 11654 solver.cpp:239] Iteration 23400 (1.35147 iter/s, 7.39936s/10 iters), loss = 6.46189
I0524 02:40:23.824710 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46189 (* 1 = 6.46189 loss)
I0524 02:40:23.824792 11654 sgd_solver.cpp:112] Iteration 23400, lr = 0.1
I0524 02:40:30.492848 11654 solver.cpp:239] Iteration 23410 (1.49981 iter/s, 6.66752s/10 iters), loss = 8.10892
I0524 02:40:30.492905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.10892 (* 1 = 8.10892 loss)
I0524 02:40:30.492923 11654 sgd_solver.cpp:112] Iteration 23410, lr = 0.1
I0524 02:40:37.313814 11654 solver.cpp:239] Iteration 23420 (1.46661 iter/s, 6.81845s/10 iters), loss = 5.9523
I0524 02:40:37.313860 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9523 (* 1 = 5.9523 loss)
I0524 02:40:37.313874 11654 sgd_solver.cpp:112] Iteration 23420, lr = 0.1
I0524 02:40:45.055620 11654 solver.cpp:239] Iteration 23430 (1.29212 iter/s, 7.73924s/10 iters), loss = 6.66665
I0524 02:40:45.055673 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66665 (* 1 = 6.66665 loss)
I0524 02:40:45.055833 11654 sgd_solver.cpp:112] Iteration 23430, lr = 0.1
I0524 02:40:52.263614 11654 solver.cpp:239] Iteration 23440 (1.38741 iter/s, 7.20766s/10 iters), loss = 6.74629
I0524 02:40:52.263672 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74629 (* 1 = 6.74629 loss)
I0524 02:40:52.263689 11654 sgd_solver.cpp:112] Iteration 23440, lr = 0.1
I0524 02:40:59.762753 11654 solver.cpp:239] Iteration 23450 (1.33355 iter/s, 7.49879s/10 iters), loss = 6.79465
I0524 02:40:59.763053 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79465 (* 1 = 6.79465 loss)
I0524 02:40:59.763116 11654 sgd_solver.cpp:112] Iteration 23450, lr = 0.1
I0524 02:41:06.469712 11654 solver.cpp:239] Iteration 23460 (1.49158 iter/s, 6.7043s/10 iters), loss = 6.74902
I0524 02:41:06.469770 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74902 (* 1 = 6.74902 loss)
I0524 02:41:06.721644 11654 sgd_solver.cpp:112] Iteration 23460, lr = 0.1
I0524 02:41:13.222138 11654 solver.cpp:239] Iteration 23470 (1.48102 iter/s, 6.75211s/10 iters), loss = 7.05029
I0524 02:41:13.222185 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05029 (* 1 = 7.05029 loss)
I0524 02:41:13.222342 11654 sgd_solver.cpp:112] Iteration 23470, lr = 0.1
I0524 02:41:21.035818 11654 solver.cpp:239] Iteration 23480 (1.27986 iter/s, 7.81333s/10 iters), loss = 7.31158
I0524 02:41:21.035871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31158 (* 1 = 7.31158 loss)
I0524 02:41:21.626744 11654 sgd_solver.cpp:112] Iteration 23480, lr = 0.1
I0524 02:41:28.377030 11654 solver.cpp:239] Iteration 23490 (1.36223 iter/s, 7.34088s/10 iters), loss = 6.66366
I0524 02:41:28.377084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66366 (* 1 = 6.66366 loss)
I0524 02:41:28.796097 11654 sgd_solver.cpp:112] Iteration 23490, lr = 0.1
I0524 02:41:37.854570 11654 solver.cpp:239] Iteration 23500 (1.05517 iter/s, 9.47712s/10 iters), loss = 6.50728
I0524 02:41:37.854828 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50728 (* 1 = 6.50728 loss)
I0524 02:41:38.605883 11654 sgd_solver.cpp:112] Iteration 23500, lr = 0.1
I0524 02:41:44.930325 11654 solver.cpp:239] Iteration 23510 (1.41337 iter/s, 7.07527s/10 iters), loss = 6.92131
I0524 02:41:44.930379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92131 (* 1 = 6.92131 loss)
I0524 02:41:44.930601 11654 sgd_solver.cpp:112] Iteration 23510, lr = 0.1
I0524 02:41:52.276633 11654 solver.cpp:239] Iteration 23520 (1.36129 iter/s, 7.34596s/10 iters), loss = 6.70629
I0524 02:41:52.276692 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70629 (* 1 = 6.70629 loss)
I0524 02:41:52.277086 11654 sgd_solver.cpp:112] Iteration 23520, lr = 0.1
I0524 02:41:58.817559 11654 solver.cpp:239] Iteration 23530 (1.52891 iter/s, 6.54062s/10 iters), loss = 7.46099
I0524 02:41:58.817615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.46099 (* 1 = 7.46099 loss)
I0524 02:41:58.817634 11654 sgd_solver.cpp:112] Iteration 23530, lr = 0.1
I0524 02:42:04.944530 11654 solver.cpp:239] Iteration 23540 (1.63222 iter/s, 6.12662s/10 iters), loss = 6.78417
I0524 02:42:04.944567 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78417 (* 1 = 6.78417 loss)
I0524 02:42:04.945379 11654 sgd_solver.cpp:112] Iteration 23540, lr = 0.1
I0524 02:42:11.713871 11654 solver.cpp:239] Iteration 23550 (1.47732 iter/s, 6.76902s/10 iters), loss = 6.41198
I0524 02:42:11.714154 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41198 (* 1 = 6.41198 loss)
I0524 02:42:11.714576 11654 sgd_solver.cpp:112] Iteration 23550, lr = 0.1
I0524 02:42:19.891670 11654 solver.cpp:239] Iteration 23560 (1.22291 iter/s, 8.17725s/10 iters), loss = 6.78264
I0524 02:42:19.891723 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78264 (* 1 = 6.78264 loss)
I0524 02:42:19.892531 11654 sgd_solver.cpp:112] Iteration 23560, lr = 0.1
I0524 02:42:26.692806 11654 solver.cpp:239] Iteration 23570 (1.47041 iter/s, 6.80083s/10 iters), loss = 6.90859
I0524 02:42:26.692848 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90859 (* 1 = 6.90859 loss)
I0524 02:42:26.693110 11654 sgd_solver.cpp:112] Iteration 23570, lr = 0.1
I0524 02:42:34.288429 11654 solver.cpp:239] Iteration 23580 (1.31661 iter/s, 7.59526s/10 iters), loss = 5.58977
I0524 02:42:34.288529 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58977 (* 1 = 5.58977 loss)
I0524 02:42:34.290524 11654 sgd_solver.cpp:112] Iteration 23580, lr = 0.1
I0524 02:42:40.928664 11654 solver.cpp:239] Iteration 23590 (1.50605 iter/s, 6.6399s/10 iters), loss = 5.83915
I0524 02:42:40.928722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83915 (* 1 = 5.83915 loss)
I0524 02:42:40.991349 11654 sgd_solver.cpp:112] Iteration 23590, lr = 0.1
I0524 02:42:47.288199 11654 solver.cpp:239] Iteration 23600 (1.57251 iter/s, 6.35924s/10 iters), loss = 6.31896
I0524 02:42:47.288439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31896 (* 1 = 6.31896 loss)
I0524 02:42:47.288590 11654 sgd_solver.cpp:112] Iteration 23600, lr = 0.1
I0524 02:42:53.914471 11654 solver.cpp:239] Iteration 23610 (1.50925 iter/s, 6.62581s/10 iters), loss = 5.92021
I0524 02:42:53.914525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92021 (* 1 = 5.92021 loss)
I0524 02:42:53.914541 11654 sgd_solver.cpp:112] Iteration 23610, lr = 0.1
I0524 02:43:00.633718 11654 solver.cpp:239] Iteration 23620 (1.48881 iter/s, 6.71678s/10 iters), loss = 6.57417
I0524 02:43:00.633761 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57417 (* 1 = 6.57417 loss)
I0524 02:43:00.911269 11654 sgd_solver.cpp:112] Iteration 23620, lr = 0.1
I0524 02:43:07.335176 11654 solver.cpp:239] Iteration 23630 (1.49228 iter/s, 6.70115s/10 iters), loss = 7.04232
I0524 02:43:07.335229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04232 (* 1 = 7.04232 loss)
I0524 02:43:07.335245 11654 sgd_solver.cpp:112] Iteration 23630, lr = 0.1
I0524 02:43:15.591604 11654 solver.cpp:239] Iteration 23640 (1.21124 iter/s, 8.25599s/10 iters), loss = 6.60661
I0524 02:43:15.591660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60661 (* 1 = 6.60661 loss)
I0524 02:43:16.182379 11654 sgd_solver.cpp:112] Iteration 23640, lr = 0.1
I0524 02:43:22.268008 11654 solver.cpp:239] Iteration 23650 (1.49788 iter/s, 6.67609s/10 iters), loss = 6.944
I0524 02:43:22.268368 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.944 (* 1 = 6.944 loss)
I0524 02:43:22.283040 11654 sgd_solver.cpp:112] Iteration 23650, lr = 0.1
I0524 02:43:29.863888 11654 solver.cpp:239] Iteration 23660 (1.3166 iter/s, 7.5953s/10 iters), loss = 6.55204
I0524 02:43:29.863946 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55204 (* 1 = 6.55204 loss)
I0524 02:43:29.863999 11654 sgd_solver.cpp:112] Iteration 23660, lr = 0.1
I0524 02:43:37.440155 11654 solver.cpp:239] Iteration 23670 (1.31997 iter/s, 7.57592s/10 iters), loss = 7.3816
I0524 02:43:37.440203 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3816 (* 1 = 7.3816 loss)
I0524 02:43:37.440218 11654 sgd_solver.cpp:112] Iteration 23670, lr = 0.1
I0524 02:43:43.993295 11654 solver.cpp:239] Iteration 23680 (1.52657 iter/s, 6.55063s/10 iters), loss = 6.84468
I0524 02:43:43.993347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84468 (* 1 = 6.84468 loss)
I0524 02:43:43.993362 11654 sgd_solver.cpp:112] Iteration 23680, lr = 0.1
I0524 02:43:50.724853 11654 solver.cpp:239] Iteration 23690 (1.48562 iter/s, 6.73119s/10 iters), loss = 7.04203
I0524 02:43:50.724907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04203 (* 1 = 7.04203 loss)
I0524 02:43:50.725952 11654 sgd_solver.cpp:112] Iteration 23690, lr = 0.1
I0524 02:43:59.442438 11654 solver.cpp:239] Iteration 23700 (1.14716 iter/s, 8.7172s/10 iters), loss = 6.86127
I0524 02:43:59.442759 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86127 (* 1 = 6.86127 loss)
I0524 02:43:59.442855 11654 sgd_solver.cpp:112] Iteration 23700, lr = 0.1
I0524 02:44:06.867717 11654 solver.cpp:239] Iteration 23710 (1.34688 iter/s, 7.42457s/10 iters), loss = 6.27872
I0524 02:44:06.867782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27872 (* 1 = 6.27872 loss)
I0524 02:44:06.868893 11654 sgd_solver.cpp:112] Iteration 23710, lr = 0.1
I0524 02:44:18.117122 11654 solver.cpp:239] Iteration 23720 (0.888975 iter/s, 11.2489s/10 iters), loss = 5.49593
I0524 02:44:18.117175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49593 (* 1 = 5.49593 loss)
I0524 02:44:18.612987 11654 sgd_solver.cpp:112] Iteration 23720, lr = 0.1
I0524 02:44:24.811990 11654 solver.cpp:239] Iteration 23730 (1.49375 iter/s, 6.69456s/10 iters), loss = 6.5544
I0524 02:44:24.812049 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5544 (* 1 = 6.5544 loss)
I0524 02:44:24.812239 11654 sgd_solver.cpp:112] Iteration 23730, lr = 0.1
I0524 02:44:31.718417 11654 solver.cpp:239] Iteration 23740 (1.44799 iter/s, 6.90611s/10 iters), loss = 6.96082
I0524 02:44:31.718655 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96082 (* 1 = 6.96082 loss)
I0524 02:44:31.718737 11654 sgd_solver.cpp:112] Iteration 23740, lr = 0.1
I0524 02:44:40.818907 11654 solver.cpp:239] Iteration 23750 (1.09891 iter/s, 9.09993s/10 iters), loss = 7.18159
I0524 02:44:40.818958 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18159 (* 1 = 7.18159 loss)
I0524 02:44:40.818974 11654 sgd_solver.cpp:112] Iteration 23750, lr = 0.1
I0524 02:44:48.405671 11654 solver.cpp:239] Iteration 23760 (1.31816 iter/s, 7.58634s/10 iters), loss = 7.11542
I0524 02:44:48.405735 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11542 (* 1 = 7.11542 loss)
I0524 02:44:48.405854 11654 sgd_solver.cpp:112] Iteration 23760, lr = 0.1
I0524 02:44:54.868162 11654 solver.cpp:239] Iteration 23770 (1.54749 iter/s, 6.46206s/10 iters), loss = 7.16774
I0524 02:44:54.868280 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16774 (* 1 = 7.16774 loss)
I0524 02:44:54.868366 11654 sgd_solver.cpp:112] Iteration 23770, lr = 0.1
I0524 02:45:01.195026 11654 solver.cpp:239] Iteration 23780 (1.58065 iter/s, 6.32652s/10 iters), loss = 7.15944
I0524 02:45:01.195073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15944 (* 1 = 7.15944 loss)
I0524 02:45:01.195310 11654 sgd_solver.cpp:112] Iteration 23780, lr = 0.1
I0524 02:45:09.518618 11654 solver.cpp:239] Iteration 23790 (1.20146 iter/s, 8.32322s/10 iters), loss = 6.4775
I0524 02:45:09.518914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4775 (* 1 = 6.4775 loss)
I0524 02:45:09.518935 11654 sgd_solver.cpp:112] Iteration 23790, lr = 0.1
I0524 02:45:17.186951 11654 solver.cpp:239] Iteration 23800 (1.30417 iter/s, 7.66771s/10 iters), loss = 6.78378
I0524 02:45:17.187002 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78378 (* 1 = 6.78378 loss)
I0524 02:45:17.517753 11654 sgd_solver.cpp:112] Iteration 23800, lr = 0.1
I0524 02:45:24.051005 11654 solver.cpp:239] Iteration 23810 (1.45693 iter/s, 6.86374s/10 iters), loss = 6.99922
I0524 02:45:24.051064 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99922 (* 1 = 6.99922 loss)
I0524 02:45:24.182953 11654 sgd_solver.cpp:112] Iteration 23810, lr = 0.1
I0524 02:45:32.921212 11654 solver.cpp:239] Iteration 23820 (1.12742 iter/s, 8.86982s/10 iters), loss = 6.16092
I0524 02:45:32.921265 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16092 (* 1 = 6.16092 loss)
I0524 02:45:32.921281 11654 sgd_solver.cpp:112] Iteration 23820, lr = 0.1
I0524 02:45:39.786352 11654 solver.cpp:239] Iteration 23830 (1.45672 iter/s, 6.86474s/10 iters), loss = 6.70632
I0524 02:45:39.786648 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70632 (* 1 = 6.70632 loss)
I0524 02:45:39.796185 11654 sgd_solver.cpp:112] Iteration 23830, lr = 0.1
I0524 02:45:47.003650 11654 solver.cpp:239] Iteration 23840 (1.38566 iter/s, 7.21678s/10 iters), loss = 8.08306
I0524 02:45:47.003691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.08306 (* 1 = 8.08306 loss)
I0524 02:45:47.039321 11654 sgd_solver.cpp:112] Iteration 23840, lr = 0.1
I0524 02:45:55.800303 11654 solver.cpp:239] Iteration 23850 (1.13685 iter/s, 8.79627s/10 iters), loss = 7.56105
I0524 02:45:55.800362 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.56105 (* 1 = 7.56105 loss)
I0524 02:45:55.967794 11654 sgd_solver.cpp:112] Iteration 23850, lr = 0.1
I0524 02:46:03.241844 11654 solver.cpp:239] Iteration 23860 (1.34387 iter/s, 7.4412s/10 iters), loss = 6.26172
I0524 02:46:03.241891 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26172 (* 1 = 6.26172 loss)
I0524 02:46:03.241907 11654 sgd_solver.cpp:112] Iteration 23860, lr = 0.1
I0524 02:46:11.266780 11654 solver.cpp:239] Iteration 23870 (1.24618 iter/s, 8.02451s/10 iters), loss = 6.44085
I0524 02:46:11.267093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44085 (* 1 = 6.44085 loss)
I0524 02:46:11.856871 11654 sgd_solver.cpp:112] Iteration 23870, lr = 0.1
I0524 02:46:18.171602 11654 solver.cpp:239] Iteration 23880 (1.44837 iter/s, 6.9043s/10 iters), loss = 6.85936
I0524 02:46:18.171650 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85936 (* 1 = 6.85936 loss)
I0524 02:46:18.171806 11654 sgd_solver.cpp:112] Iteration 23880, lr = 0.1
I0524 02:46:26.665004 11654 solver.cpp:239] Iteration 23890 (1.17744 iter/s, 8.49301s/10 iters), loss = 6.56726
I0524 02:46:26.665066 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56726 (* 1 = 6.56726 loss)
I0524 02:46:26.665554 11654 sgd_solver.cpp:112] Iteration 23890, lr = 0.1
I0524 02:46:33.896858 11654 solver.cpp:239] Iteration 23900 (1.38284 iter/s, 7.23152s/10 iters), loss = 6.9317
I0524 02:46:33.896912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9317 (* 1 = 6.9317 loss)
I0524 02:46:33.897068 11654 sgd_solver.cpp:112] Iteration 23900, lr = 0.1
I0524 02:46:41.399093 11654 solver.cpp:239] Iteration 23910 (1.333 iter/s, 7.50189s/10 iters), loss = 5.8759
I0524 02:46:41.399413 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8759 (* 1 = 5.8759 loss)
I0524 02:46:42.040935 11654 sgd_solver.cpp:112] Iteration 23910, lr = 0.1
I0524 02:46:48.956073 11654 solver.cpp:239] Iteration 23920 (1.32337 iter/s, 7.55645s/10 iters), loss = 6.43625
I0524 02:46:48.956131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43625 (* 1 = 6.43625 loss)
I0524 02:46:49.059546 11654 sgd_solver.cpp:112] Iteration 23920, lr = 0.1
I0524 02:46:56.005252 11654 solver.cpp:239] Iteration 23930 (1.41867 iter/s, 7.04886s/10 iters), loss = 6.41567
I0524 02:46:56.005300 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41567 (* 1 = 6.41567 loss)
I0524 02:46:56.005457 11654 sgd_solver.cpp:112] Iteration 23930, lr = 0.1
I0524 02:47:00.854552 11654 solver.cpp:239] Iteration 23940 (2.06226 iter/s, 4.84905s/10 iters), loss = 6.20764
I0524 02:47:00.854605 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20764 (* 1 = 6.20764 loss)
I0524 02:47:00.855077 11654 sgd_solver.cpp:112] Iteration 23940, lr = 0.1
I0524 02:47:08.378284 11654 solver.cpp:239] Iteration 23950 (1.32919 iter/s, 7.52338s/10 iters), loss = 6.92265
I0524 02:47:08.378345 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92265 (* 1 = 6.92265 loss)
I0524 02:47:08.378736 11654 sgd_solver.cpp:112] Iteration 23950, lr = 0.1
I0524 02:47:15.705174 11654 solver.cpp:239] Iteration 23960 (1.3649 iter/s, 7.32655s/10 iters), loss = 5.85262
I0524 02:47:15.705497 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85262 (* 1 = 5.85262 loss)
I0524 02:47:15.708499 11654 sgd_solver.cpp:112] Iteration 23960, lr = 0.1
I0524 02:47:22.978476 11654 solver.cpp:239] Iteration 23970 (1.375 iter/s, 7.27275s/10 iters), loss = 6.86544
I0524 02:47:22.978523 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86544 (* 1 = 6.86544 loss)
I0524 02:47:23.440039 11654 sgd_solver.cpp:112] Iteration 23970, lr = 0.1
I0524 02:47:33.429091 11654 solver.cpp:239] Iteration 23980 (0.956922 iter/s, 10.4502s/10 iters), loss = 6.47926
I0524 02:47:33.429150 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47926 (* 1 = 6.47926 loss)
I0524 02:47:33.429170 11654 sgd_solver.cpp:112] Iteration 23980, lr = 0.1
I0524 02:47:39.583457 11654 solver.cpp:239] Iteration 23990 (1.62496 iter/s, 6.15401s/10 iters), loss = 7.4918
I0524 02:47:39.583505 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4918 (* 1 = 7.4918 loss)
I0524 02:47:39.742987 11654 sgd_solver.cpp:112] Iteration 23990, lr = 0.1
I0524 02:47:47.021270 11654 solver.cpp:239] Iteration 24000 (1.34454 iter/s, 7.43746s/10 iters), loss = 6.9527
I0524 02:47:47.021554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9527 (* 1 = 6.9527 loss)
I0524 02:47:47.516798 11654 sgd_solver.cpp:112] Iteration 24000, lr = 0.1
I0524 02:47:54.642971 11654 solver.cpp:239] Iteration 24010 (1.31213 iter/s, 7.62119s/10 iters), loss = 6.85328
I0524 02:47:54.643008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85328 (* 1 = 6.85328 loss)
I0524 02:47:54.643030 11654 sgd_solver.cpp:112] Iteration 24010, lr = 0.1
I0524 02:48:00.606212 11654 solver.cpp:239] Iteration 24020 (1.67702 iter/s, 5.96296s/10 iters), loss = 7.67417
I0524 02:48:00.606269 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.67417 (* 1 = 7.67417 loss)
I0524 02:48:00.606498 11654 sgd_solver.cpp:112] Iteration 24020, lr = 0.1
I0524 02:48:07.480500 11654 solver.cpp:239] Iteration 24030 (1.45476 iter/s, 6.87397s/10 iters), loss = 6.79644
I0524 02:48:07.480558 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79644 (* 1 = 6.79644 loss)
I0524 02:48:07.480607 11654 sgd_solver.cpp:112] Iteration 24030, lr = 0.1
I0524 02:48:13.487655 11654 solver.cpp:239] Iteration 24040 (1.66476 iter/s, 6.00686s/10 iters), loss = 6.16467
I0524 02:48:13.487709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16467 (* 1 = 6.16467 loss)
I0524 02:48:13.488132 11654 sgd_solver.cpp:112] Iteration 24040, lr = 0.1
I0524 02:48:20.644209 11654 solver.cpp:239] Iteration 24050 (1.39739 iter/s, 7.15621s/10 iters), loss = 7.65448
I0524 02:48:20.644325 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.65448 (* 1 = 7.65448 loss)
I0524 02:48:20.644376 11654 sgd_solver.cpp:112] Iteration 24050, lr = 0.1
I0524 02:48:28.599892 11654 solver.cpp:239] Iteration 24060 (1.25703 iter/s, 7.95527s/10 iters), loss = 5.60541
I0524 02:48:28.599952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60541 (* 1 = 5.60541 loss)
I0524 02:48:28.946746 11654 sgd_solver.cpp:112] Iteration 24060, lr = 0.1
I0524 02:48:35.289844 11654 solver.cpp:239] Iteration 24070 (1.49485 iter/s, 6.68963s/10 iters), loss = 6.76986
I0524 02:48:35.289906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76986 (* 1 = 6.76986 loss)
I0524 02:48:35.290156 11654 sgd_solver.cpp:112] Iteration 24070, lr = 0.1
I0524 02:48:41.941625 11654 solver.cpp:239] Iteration 24080 (1.50343 iter/s, 6.65146s/10 iters), loss = 6.44513
I0524 02:48:41.941684 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44513 (* 1 = 6.44513 loss)
I0524 02:48:41.942016 11654 sgd_solver.cpp:112] Iteration 24080, lr = 0.1
I0524 02:48:49.499191 11654 solver.cpp:239] Iteration 24090 (1.32324 iter/s, 7.55721s/10 iters), loss = 6.63185
I0524 02:48:49.499249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63185 (* 1 = 6.63185 loss)
I0524 02:48:49.499361 11654 sgd_solver.cpp:112] Iteration 24090, lr = 0.1
I0524 02:48:56.481092 11654 solver.cpp:239] Iteration 24100 (1.43234 iter/s, 6.98158s/10 iters), loss = 5.61096
I0524 02:48:56.481444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61096 (* 1 = 5.61096 loss)
I0524 02:48:57.195674 11654 sgd_solver.cpp:112] Iteration 24100, lr = 0.1
I0524 02:49:04.501574 11654 solver.cpp:239] Iteration 24110 (1.2469 iter/s, 8.01987s/10 iters), loss = 7.4047
I0524 02:49:04.501638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4047 (* 1 = 7.4047 loss)
I0524 02:49:04.501924 11654 sgd_solver.cpp:112] Iteration 24110, lr = 0.1
I0524 02:49:10.311980 11654 solver.cpp:239] Iteration 24120 (1.72113 iter/s, 5.81012s/10 iters), loss = 5.94544
I0524 02:49:10.312031 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94544 (* 1 = 5.94544 loss)
I0524 02:49:10.312048 11654 sgd_solver.cpp:112] Iteration 24120, lr = 0.1
I0524 02:49:18.488277 11654 solver.cpp:239] Iteration 24130 (1.22311 iter/s, 8.17586s/10 iters), loss = 8.02067
I0524 02:49:18.488322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.02067 (* 1 = 8.02067 loss)
I0524 02:49:18.488337 11654 sgd_solver.cpp:112] Iteration 24130, lr = 0.1
I0524 02:49:26.440089 11654 solver.cpp:239] Iteration 24140 (1.25767 iter/s, 7.95122s/10 iters), loss = 7.45591
I0524 02:49:26.440145 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.45591 (* 1 = 7.45591 loss)
I0524 02:49:26.447206 11654 sgd_solver.cpp:112] Iteration 24140, lr = 0.1
I0524 02:49:33.152395 11654 solver.cpp:239] Iteration 24150 (1.48987 iter/s, 6.712s/10 iters), loss = 6.98333
I0524 02:49:33.152631 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98333 (* 1 = 6.98333 loss)
I0524 02:49:33.154744 11654 sgd_solver.cpp:112] Iteration 24150, lr = 0.1
I0524 02:49:39.338161 11654 solver.cpp:239] Iteration 24160 (1.61673 iter/s, 6.18532s/10 iters), loss = 6.18618
I0524 02:49:39.338228 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18618 (* 1 = 6.18618 loss)
I0524 02:49:39.361050 11654 sgd_solver.cpp:112] Iteration 24160, lr = 0.1
I0524 02:49:45.839977 11654 solver.cpp:239] Iteration 24170 (1.5381 iter/s, 6.50151s/10 iters), loss = 6.81061
I0524 02:49:45.840016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81061 (* 1 = 6.81061 loss)
I0524 02:49:46.278000 11654 sgd_solver.cpp:112] Iteration 24170, lr = 0.1
I0524 02:49:54.452178 11654 solver.cpp:239] Iteration 24180 (1.16119 iter/s, 8.61182s/10 iters), loss = 6.19016
I0524 02:49:54.452239 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19016 (* 1 = 6.19016 loss)
I0524 02:49:54.452257 11654 sgd_solver.cpp:112] Iteration 24180, lr = 0.1
I0524 02:50:00.939710 11654 solver.cpp:239] Iteration 24190 (1.54149 iter/s, 6.48722s/10 iters), loss = 7.12261
I0524 02:50:00.939770 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12261 (* 1 = 7.12261 loss)
I0524 02:50:00.939872 11654 sgd_solver.cpp:112] Iteration 24190, lr = 0.1
I0524 02:50:07.422024 11654 solver.cpp:239] Iteration 24200 (1.54273 iter/s, 6.48201s/10 iters), loss = 6.70938
I0524 02:50:07.422322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70938 (* 1 = 6.70938 loss)
I0524 02:50:07.422391 11654 sgd_solver.cpp:112] Iteration 24200, lr = 0.1
I0524 02:50:15.635202 11654 solver.cpp:239] Iteration 24210 (1.21764 iter/s, 8.21259s/10 iters), loss = 6.21311
I0524 02:50:15.635243 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21311 (* 1 = 6.21311 loss)
I0524 02:50:15.686195 11654 sgd_solver.cpp:112] Iteration 24210, lr = 0.1
I0524 02:50:22.154772 11654 solver.cpp:239] Iteration 24220 (1.53391 iter/s, 6.51927s/10 iters), loss = 5.60533
I0524 02:50:22.154824 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60533 (* 1 = 5.60533 loss)
I0524 02:50:22.154840 11654 sgd_solver.cpp:112] Iteration 24220, lr = 0.1
I0524 02:50:29.403110 11654 solver.cpp:239] Iteration 24230 (1.38011 iter/s, 7.24579s/10 iters), loss = 7.19093
I0524 02:50:29.403163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19093 (* 1 = 7.19093 loss)
I0524 02:50:29.403182 11654 sgd_solver.cpp:112] Iteration 24230, lr = 0.1
I0524 02:50:37.843816 11654 solver.cpp:239] Iteration 24240 (1.1848 iter/s, 8.44026s/10 iters), loss = 6.00866
I0524 02:50:37.844059 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00866 (* 1 = 6.00866 loss)
I0524 02:50:37.844105 11654 sgd_solver.cpp:112] Iteration 24240, lr = 0.1
I0524 02:50:45.028856 11654 solver.cpp:239] Iteration 24250 (1.39188 iter/s, 7.18452s/10 iters), loss = 6.41568
I0524 02:50:45.028897 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41568 (* 1 = 6.41568 loss)
I0524 02:50:45.028910 11654 sgd_solver.cpp:112] Iteration 24250, lr = 0.1
I0524 02:50:51.692801 11654 solver.cpp:239] Iteration 24260 (1.50119 iter/s, 6.66139s/10 iters), loss = 6.53543
I0524 02:50:51.692863 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53543 (* 1 = 6.53543 loss)
I0524 02:50:51.692952 11654 sgd_solver.cpp:112] Iteration 24260, lr = 0.1
I0524 02:50:58.852943 11654 solver.cpp:239] Iteration 24270 (1.39669 iter/s, 7.15981s/10 iters), loss = 6.08937
I0524 02:50:58.853001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08937 (* 1 = 6.08937 loss)
I0524 02:50:58.853034 11654 sgd_solver.cpp:112] Iteration 24270, lr = 0.1
I0524 02:51:05.497674 11654 solver.cpp:239] Iteration 24280 (1.50502 iter/s, 6.64442s/10 iters), loss = 5.86223
I0524 02:51:05.497721 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86223 (* 1 = 5.86223 loss)
I0524 02:51:05.498116 11654 sgd_solver.cpp:112] Iteration 24280, lr = 0.1
I0524 02:51:12.708223 11654 solver.cpp:239] Iteration 24290 (1.38692 iter/s, 7.21022s/10 iters), loss = 8.5231
I0524 02:51:12.708473 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.5231 (* 1 = 8.5231 loss)
I0524 02:51:12.708674 11654 sgd_solver.cpp:112] Iteration 24290, lr = 0.1
I0524 02:51:19.944659 11654 solver.cpp:239] Iteration 24300 (1.38199 iter/s, 7.23596s/10 iters), loss = 6.61104
I0524 02:51:19.944700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61104 (* 1 = 6.61104 loss)
I0524 02:51:19.944712 11654 sgd_solver.cpp:112] Iteration 24300, lr = 0.1
I0524 02:51:27.344455 11654 solver.cpp:239] Iteration 24310 (1.35146 iter/s, 7.39938s/10 iters), loss = 7.04277
I0524 02:51:27.344513 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04277 (* 1 = 7.04277 loss)
I0524 02:51:27.488394 11654 sgd_solver.cpp:112] Iteration 24310, lr = 0.1
I0524 02:51:33.693786 11654 solver.cpp:239] Iteration 24320 (1.57504 iter/s, 6.34904s/10 iters), loss = 6.57891
I0524 02:51:33.693825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57891 (* 1 = 6.57891 loss)
I0524 02:51:33.693838 11654 sgd_solver.cpp:112] Iteration 24320, lr = 0.1
I0524 02:51:41.669052 11654 solver.cpp:239] Iteration 24330 (1.25393 iter/s, 7.97491s/10 iters), loss = 6.75092
I0524 02:51:41.669122 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75092 (* 1 = 6.75092 loss)
I0524 02:51:42.047754 11654 sgd_solver.cpp:112] Iteration 24330, lr = 0.1
I0524 02:51:48.596772 11654 solver.cpp:239] Iteration 24340 (1.44355 iter/s, 6.92739s/10 iters), loss = 6.9597
I0524 02:51:48.597071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9597 (* 1 = 6.9597 loss)
I0524 02:51:48.597126 11654 sgd_solver.cpp:112] Iteration 24340, lr = 0.1
I0524 02:51:56.145851 11654 solver.cpp:239] Iteration 24350 (1.32476 iter/s, 7.54854s/10 iters), loss = 7.14884
I0524 02:51:56.145903 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14884 (* 1 = 7.14884 loss)
I0524 02:51:56.145918 11654 sgd_solver.cpp:112] Iteration 24350, lr = 0.1
I0524 02:52:02.470021 11654 solver.cpp:239] Iteration 24360 (1.58131 iter/s, 6.32388s/10 iters), loss = 5.93776
I0524 02:52:02.470073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93776 (* 1 = 5.93776 loss)
I0524 02:52:02.497601 11654 sgd_solver.cpp:112] Iteration 24360, lr = 0.1
I0524 02:52:10.018539 11654 solver.cpp:239] Iteration 24370 (1.32482 iter/s, 7.54818s/10 iters), loss = 6.34472
I0524 02:52:10.018594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34472 (* 1 = 6.34472 loss)
I0524 02:52:10.018610 11654 sgd_solver.cpp:112] Iteration 24370, lr = 0.1
I0524 02:52:16.478816 11654 solver.cpp:239] Iteration 24380 (1.54804 iter/s, 6.45979s/10 iters), loss = 6.68752
I0524 02:52:16.478868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68752 (* 1 = 6.68752 loss)
I0524 02:52:16.479043 11654 sgd_solver.cpp:112] Iteration 24380, lr = 0.1
I0524 02:52:22.829488 11654 solver.cpp:239] Iteration 24390 (1.57471 iter/s, 6.35037s/10 iters), loss = 6.80884
I0524 02:52:22.829812 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80884 (* 1 = 6.80884 loss)
I0524 02:52:22.829910 11654 sgd_solver.cpp:112] Iteration 24390, lr = 0.1
I0524 02:52:29.775490 11654 solver.cpp:239] Iteration 24400 (1.43979 iter/s, 6.94547s/10 iters), loss = 8.05433
I0524 02:52:29.775554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.05433 (* 1 = 8.05433 loss)
I0524 02:52:29.797312 11654 sgd_solver.cpp:112] Iteration 24400, lr = 0.1
I0524 02:52:36.153965 11654 solver.cpp:239] Iteration 24410 (1.56785 iter/s, 6.37817s/10 iters), loss = 6.60786
I0524 02:52:36.154027 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60786 (* 1 = 6.60786 loss)
I0524 02:52:36.569285 11654 sgd_solver.cpp:112] Iteration 24410, lr = 0.1
I0524 02:52:44.024181 11654 solver.cpp:239] Iteration 24420 (1.27067 iter/s, 7.86986s/10 iters), loss = 6.1099
I0524 02:52:44.024227 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1099 (* 1 = 6.1099 loss)
I0524 02:52:44.024854 11654 sgd_solver.cpp:112] Iteration 24420, lr = 0.1
I0524 02:52:50.269318 11654 solver.cpp:239] Iteration 24430 (1.60132 iter/s, 6.24484s/10 iters), loss = 6.66552
I0524 02:52:50.269372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66552 (* 1 = 6.66552 loss)
I0524 02:52:50.269388 11654 sgd_solver.cpp:112] Iteration 24430, lr = 0.1
I0524 02:52:58.013483 11654 solver.cpp:239] Iteration 24440 (1.29144 iter/s, 7.74329s/10 iters), loss = 6.67132
I0524 02:52:58.013705 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67132 (* 1 = 6.67132 loss)
I0524 02:52:58.013758 11654 sgd_solver.cpp:112] Iteration 24440, lr = 0.1
I0524 02:53:05.942910 11654 solver.cpp:239] Iteration 24450 (1.26121 iter/s, 7.92889s/10 iters), loss = 6.12106
I0524 02:53:05.942975 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12106 (* 1 = 6.12106 loss)
I0524 02:53:05.943277 11654 sgd_solver.cpp:112] Iteration 24450, lr = 0.1
I0524 02:53:12.566722 11654 solver.cpp:239] Iteration 24460 (1.50978 iter/s, 6.62348s/10 iters), loss = 5.49968
I0524 02:53:12.566776 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49968 (* 1 = 5.49968 loss)
I0524 02:53:12.566982 11654 sgd_solver.cpp:112] Iteration 24460, lr = 0.1
I0524 02:53:18.780484 11654 solver.cpp:239] Iteration 24470 (1.60941 iter/s, 6.21347s/10 iters), loss = 6.02338
I0524 02:53:18.780539 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02338 (* 1 = 6.02338 loss)
I0524 02:53:18.780786 11654 sgd_solver.cpp:112] Iteration 24470, lr = 0.1
I0524 02:53:25.927081 11654 solver.cpp:239] Iteration 24480 (1.39933 iter/s, 7.14627s/10 iters), loss = 5.77057
I0524 02:53:25.927126 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77057 (* 1 = 5.77057 loss)
I0524 02:53:25.927139 11654 sgd_solver.cpp:112] Iteration 24480, lr = 0.1
I0524 02:53:32.245712 11654 solver.cpp:239] Iteration 24490 (1.5827 iter/s, 6.31833s/10 iters), loss = 7.07845
I0524 02:53:32.246022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07845 (* 1 = 7.07845 loss)
I0524 02:53:32.246085 11654 sgd_solver.cpp:112] Iteration 24490, lr = 0.1
I0524 02:53:39.082958 11654 solver.cpp:239] Iteration 24500 (1.4628 iter/s, 6.83622s/10 iters), loss = 6.12003
I0524 02:53:39.083021 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12003 (* 1 = 6.12003 loss)
I0524 02:53:39.083118 11654 sgd_solver.cpp:112] Iteration 24500, lr = 0.1
I0524 02:53:45.613059 11654 solver.cpp:239] Iteration 24510 (1.53144 iter/s, 6.52979s/10 iters), loss = 5.81688
I0524 02:53:45.613106 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81688 (* 1 = 5.81688 loss)
I0524 02:53:45.613478 11654 sgd_solver.cpp:112] Iteration 24510, lr = 0.1
I0524 02:53:51.730852 11654 solver.cpp:239] Iteration 24520 (1.63465 iter/s, 6.11751s/10 iters), loss = 5.9176
I0524 02:53:51.730911 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9176 (* 1 = 5.9176 loss)
I0524 02:53:51.731029 11654 sgd_solver.cpp:112] Iteration 24520, lr = 0.1
I0524 02:53:59.935851 11654 solver.cpp:239] Iteration 24530 (1.21882 iter/s, 8.20464s/10 iters), loss = 6.98564
I0524 02:53:59.935901 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98564 (* 1 = 6.98564 loss)
I0524 02:54:00.750427 11654 sgd_solver.cpp:112] Iteration 24530, lr = 0.1
I0524 02:54:08.359567 11654 solver.cpp:239] Iteration 24540 (1.18718 iter/s, 8.42334s/10 iters), loss = 6.79183
I0524 02:54:08.359719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79183 (* 1 = 6.79183 loss)
I0524 02:54:08.359736 11654 sgd_solver.cpp:112] Iteration 24540, lr = 0.1
I0524 02:54:17.033382 11654 solver.cpp:239] Iteration 24550 (1.15296 iter/s, 8.67331s/10 iters), loss = 6.45936
I0524 02:54:17.033427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45936 (* 1 = 6.45936 loss)
I0524 02:54:17.033466 11654 sgd_solver.cpp:112] Iteration 24550, lr = 0.1
I0524 02:54:25.990159 11654 solver.cpp:239] Iteration 24560 (1.11652 iter/s, 8.95639s/10 iters), loss = 6.55138
I0524 02:54:25.990213 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55138 (* 1 = 6.55138 loss)
I0524 02:54:26.208420 11654 sgd_solver.cpp:112] Iteration 24560, lr = 0.1
I0524 02:54:32.244436 11654 solver.cpp:239] Iteration 24570 (1.59898 iter/s, 6.25398s/10 iters), loss = 5.53272
I0524 02:54:32.244496 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53272 (* 1 = 5.53272 loss)
I0524 02:54:32.244606 11654 sgd_solver.cpp:112] Iteration 24570, lr = 0.1
I0524 02:54:38.749392 11654 solver.cpp:239] Iteration 24580 (1.53736 iter/s, 6.50465s/10 iters), loss = 7.4415
I0524 02:54:38.749660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4415 (* 1 = 7.4415 loss)
I0524 02:54:38.749719 11654 sgd_solver.cpp:112] Iteration 24580, lr = 0.1
I0524 02:54:45.843179 11654 solver.cpp:239] Iteration 24590 (1.40978 iter/s, 7.09329s/10 iters), loss = 6.42826
I0524 02:54:45.843232 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42826 (* 1 = 6.42826 loss)
I0524 02:54:45.851469 11654 sgd_solver.cpp:112] Iteration 24590, lr = 0.1
I0524 02:54:54.536718 11654 solver.cpp:239] Iteration 24600 (1.15033 iter/s, 8.69316s/10 iters), loss = 7.09994
I0524 02:54:54.536777 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09994 (* 1 = 7.09994 loss)
I0524 02:54:54.536792 11654 sgd_solver.cpp:112] Iteration 24600, lr = 0.1
I0524 02:55:01.169025 11654 solver.cpp:239] Iteration 24610 (1.50833 iter/s, 6.62984s/10 iters), loss = 6.2671
I0524 02:55:01.169071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2671 (* 1 = 6.2671 loss)
I0524 02:55:01.169139 11654 sgd_solver.cpp:112] Iteration 24610, lr = 0.1
I0524 02:55:07.776182 11654 solver.cpp:239] Iteration 24620 (1.51358 iter/s, 6.60685s/10 iters), loss = 6.77402
I0524 02:55:07.776232 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77402 (* 1 = 6.77402 loss)
I0524 02:55:08.029888 11654 sgd_solver.cpp:112] Iteration 24620, lr = 0.1
I0524 02:55:15.705363 11654 solver.cpp:239] Iteration 24630 (1.26122 iter/s, 7.92883s/10 iters), loss = 6.25387
I0524 02:55:15.705538 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25387 (* 1 = 6.25387 loss)
I0524 02:55:15.732759 11654 sgd_solver.cpp:112] Iteration 24630, lr = 0.1
I0524 02:55:22.674816 11654 solver.cpp:239] Iteration 24640 (1.43493 iter/s, 6.969s/10 iters), loss = 6.97183
I0524 02:55:22.674875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97183 (* 1 = 6.97183 loss)
I0524 02:55:22.675338 11654 sgd_solver.cpp:112] Iteration 24640, lr = 0.1
I0524 02:55:29.194182 11654 solver.cpp:239] Iteration 24650 (1.53396 iter/s, 6.51906s/10 iters), loss = 6.73357
I0524 02:55:29.194221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73357 (* 1 = 6.73357 loss)
I0524 02:55:29.194236 11654 sgd_solver.cpp:112] Iteration 24650, lr = 0.1
I0524 02:55:35.171842 11654 solver.cpp:239] Iteration 24660 (1.67301 iter/s, 5.97726s/10 iters), loss = 6.56998
I0524 02:55:35.171900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56998 (* 1 = 6.56998 loss)
I0524 02:55:35.171916 11654 sgd_solver.cpp:112] Iteration 24660, lr = 0.1
I0524 02:55:43.797178 11654 solver.cpp:239] Iteration 24670 (1.15972 iter/s, 8.62276s/10 iters), loss = 6.1501
I0524 02:55:43.797219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1501 (* 1 = 6.1501 loss)
I0524 02:55:43.797233 11654 sgd_solver.cpp:112] Iteration 24670, lr = 0.1
I0524 02:55:51.280226 11654 solver.cpp:239] Iteration 24680 (1.33681 iter/s, 7.4805s/10 iters), loss = 7.33527
I0524 02:55:51.280488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33527 (* 1 = 7.33527 loss)
I0524 02:55:51.280551 11654 sgd_solver.cpp:112] Iteration 24680, lr = 0.1
I0524 02:55:58.272759 11654 solver.cpp:239] Iteration 24690 (1.43021 iter/s, 6.992s/10 iters), loss = 6.16135
I0524 02:55:58.272825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16135 (* 1 = 6.16135 loss)
I0524 02:55:58.272997 11654 sgd_solver.cpp:112] Iteration 24690, lr = 0.1
I0524 02:56:05.136740 11654 solver.cpp:239] Iteration 24700 (1.45695 iter/s, 6.86366s/10 iters), loss = 6.93757
I0524 02:56:05.136780 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93757 (* 1 = 6.93757 loss)
I0524 02:56:05.812520 11654 sgd_solver.cpp:112] Iteration 24700, lr = 0.1
I0524 02:56:14.401240 11654 solver.cpp:239] Iteration 24710 (1.07944 iter/s, 9.2641s/10 iters), loss = 7.76544
I0524 02:56:14.401299 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.76544 (* 1 = 7.76544 loss)
I0524 02:56:14.401319 11654 sgd_solver.cpp:112] Iteration 24710, lr = 0.1
I0524 02:56:20.786417 11654 solver.cpp:239] Iteration 24720 (1.56621 iter/s, 6.38483s/10 iters), loss = 7.24687
I0524 02:56:20.786473 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24687 (* 1 = 7.24687 loss)
I0524 02:56:20.786489 11654 sgd_solver.cpp:112] Iteration 24720, lr = 0.1
I0524 02:56:26.685554 11654 solver.cpp:239] Iteration 24730 (1.69542 iter/s, 5.89823s/10 iters), loss = 5.55237
I0524 02:56:26.685807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55237 (* 1 = 5.55237 loss)
I0524 02:56:26.685865 11654 sgd_solver.cpp:112] Iteration 24730, lr = 0.1
I0524 02:56:33.149413 11654 solver.cpp:239] Iteration 24740 (1.5472 iter/s, 6.4633s/10 iters), loss = 5.98937
I0524 02:56:33.149464 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98937 (* 1 = 5.98937 loss)
I0524 02:56:33.419196 11654 sgd_solver.cpp:112] Iteration 24740, lr = 0.1
I0524 02:56:41.481895 11654 solver.cpp:239] Iteration 24750 (1.20017 iter/s, 8.33212s/10 iters), loss = 7.00746
I0524 02:56:41.481936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00746 (* 1 = 7.00746 loss)
I0524 02:56:41.481950 11654 sgd_solver.cpp:112] Iteration 24750, lr = 0.1
I0524 02:56:49.049695 11654 solver.cpp:239] Iteration 24760 (1.32146 iter/s, 7.56739s/10 iters), loss = 6.55973
I0524 02:56:49.049751 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55973 (* 1 = 6.55973 loss)
I0524 02:56:49.049767 11654 sgd_solver.cpp:112] Iteration 24760, lr = 0.1
I0524 02:56:56.020077 11654 solver.cpp:239] Iteration 24770 (1.43471 iter/s, 6.97005s/10 iters), loss = 5.29436
I0524 02:56:56.020141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29436 (* 1 = 5.29436 loss)
I0524 02:56:56.020257 11654 sgd_solver.cpp:112] Iteration 24770, lr = 0.1
I0524 02:57:03.082286 11654 solver.cpp:239] Iteration 24780 (1.41605 iter/s, 7.06189s/10 iters), loss = 7.91225
I0524 02:57:03.082582 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.91225 (* 1 = 7.91225 loss)
I0524 02:57:03.082641 11654 sgd_solver.cpp:112] Iteration 24780, lr = 0.1
I0524 02:57:09.945905 11654 solver.cpp:239] Iteration 24790 (1.45707 iter/s, 6.86307s/10 iters), loss = 7.72092
I0524 02:57:09.945950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.72092 (* 1 = 7.72092 loss)
I0524 02:57:09.946300 11654 sgd_solver.cpp:112] Iteration 24790, lr = 0.1
I0524 02:57:16.882079 11654 solver.cpp:239] Iteration 24800 (1.44178 iter/s, 6.93585s/10 iters), loss = 6.74679
I0524 02:57:16.882131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74679 (* 1 = 6.74679 loss)
I0524 02:57:16.882148 11654 sgd_solver.cpp:112] Iteration 24800, lr = 0.1
I0524 02:57:23.147969 11654 solver.cpp:239] Iteration 24810 (1.59602 iter/s, 6.2656s/10 iters), loss = 7.08232
I0524 02:57:23.148020 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08232 (* 1 = 7.08232 loss)
I0524 02:57:24.197732 11654 sgd_solver.cpp:112] Iteration 24810, lr = 0.1
I0524 02:57:30.387950 11654 solver.cpp:239] Iteration 24820 (1.38128 iter/s, 7.23965s/10 iters), loss = 5.67125
I0524 02:57:30.388000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67125 (* 1 = 5.67125 loss)
I0524 02:57:30.388162 11654 sgd_solver.cpp:112] Iteration 24820, lr = 0.1
I0524 02:57:36.641544 11654 solver.cpp:239] Iteration 24830 (1.59916 iter/s, 6.25328s/10 iters), loss = 7.51502
I0524 02:57:36.641870 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51502 (* 1 = 7.51502 loss)
I0524 02:57:36.642055 11654 sgd_solver.cpp:112] Iteration 24830, lr = 0.1
I0524 02:57:42.934325 11654 solver.cpp:239] Iteration 24840 (1.58925 iter/s, 6.29227s/10 iters), loss = 7.25664
I0524 02:57:42.934365 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25664 (* 1 = 7.25664 loss)
I0524 02:57:42.934377 11654 sgd_solver.cpp:112] Iteration 24840, lr = 0.1
I0524 02:57:49.090159 11654 solver.cpp:239] Iteration 24850 (1.62455 iter/s, 6.15554s/10 iters), loss = 5.89957
I0524 02:57:49.090221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89957 (* 1 = 5.89957 loss)
I0524 02:57:49.090579 11654 sgd_solver.cpp:112] Iteration 24850, lr = 0.1
I0524 02:57:56.740821 11654 solver.cpp:239] Iteration 24860 (1.30714 iter/s, 7.65032s/10 iters), loss = 6.75068
I0524 02:57:56.740870 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75068 (* 1 = 6.75068 loss)
I0524 02:57:56.879056 11654 sgd_solver.cpp:112] Iteration 24860, lr = 0.1
I0524 02:58:05.380189 11654 solver.cpp:239] Iteration 24870 (1.15754 iter/s, 8.63899s/10 iters), loss = 6.51469
I0524 02:58:05.380246 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51469 (* 1 = 6.51469 loss)
I0524 02:58:05.380426 11654 sgd_solver.cpp:112] Iteration 24870, lr = 0.1
I0524 02:58:11.526185 11654 solver.cpp:239] Iteration 24880 (1.62715 iter/s, 6.14571s/10 iters), loss = 6.49545
I0524 02:58:11.526326 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49545 (* 1 = 6.49545 loss)
I0524 02:58:11.526422 11654 sgd_solver.cpp:112] Iteration 24880, lr = 0.1
I0524 02:58:18.986317 11654 solver.cpp:239] Iteration 24890 (1.34054 iter/s, 7.45969s/10 iters), loss = 7.78464
I0524 02:58:18.986373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78464 (* 1 = 7.78464 loss)
I0524 02:58:18.986665 11654 sgd_solver.cpp:112] Iteration 24890, lr = 0.1
I0524 02:58:26.610498 11654 solver.cpp:239] Iteration 24900 (1.31168 iter/s, 7.62383s/10 iters), loss = 5.72055
I0524 02:58:26.610550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72055 (* 1 = 5.72055 loss)
I0524 02:58:26.610569 11654 sgd_solver.cpp:112] Iteration 24900, lr = 0.1
I0524 02:58:33.596261 11654 solver.cpp:239] Iteration 24910 (1.43156 iter/s, 6.98538s/10 iters), loss = 5.92711
I0524 02:58:33.596303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92711 (* 1 = 5.92711 loss)
I0524 02:58:33.596318 11654 sgd_solver.cpp:112] Iteration 24910, lr = 0.1
I0524 02:58:39.817128 11654 solver.cpp:239] Iteration 24920 (1.60758 iter/s, 6.22052s/10 iters), loss = 6.49485
I0524 02:58:39.817170 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49485 (* 1 = 6.49485 loss)
I0524 02:58:39.817184 11654 sgd_solver.cpp:112] Iteration 24920, lr = 0.1
I0524 02:58:46.994022 11654 solver.cpp:239] Iteration 24930 (1.39386 iter/s, 7.17434s/10 iters), loss = 6.67467
I0524 02:58:46.994350 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67467 (* 1 = 6.67467 loss)
I0524 02:58:47.214165 11654 sgd_solver.cpp:112] Iteration 24930, lr = 0.1
I0524 02:58:54.998085 11654 solver.cpp:239] Iteration 24940 (1.24946 iter/s, 8.00348s/10 iters), loss = 7.44127
I0524 02:58:54.998132 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44127 (* 1 = 7.44127 loss)
I0524 02:58:54.998353 11654 sgd_solver.cpp:112] Iteration 24940, lr = 0.1
I0524 02:59:02.182379 11654 solver.cpp:239] Iteration 24950 (1.39199 iter/s, 7.18396s/10 iters), loss = 6.43877
I0524 02:59:02.182441 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43877 (* 1 = 6.43877 loss)
I0524 02:59:02.182570 11654 sgd_solver.cpp:112] Iteration 24950, lr = 0.1
I0524 02:59:09.428648 11654 solver.cpp:239] Iteration 24960 (1.38008 iter/s, 7.24593s/10 iters), loss = 6.88214
I0524 02:59:09.428701 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88214 (* 1 = 6.88214 loss)
I0524 02:59:09.571669 11654 sgd_solver.cpp:112] Iteration 24960, lr = 0.1
I0524 02:59:16.928879 11654 solver.cpp:239] Iteration 24970 (1.33335 iter/s, 7.49989s/10 iters), loss = 6.452
I0524 02:59:16.928922 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.452 (* 1 = 6.452 loss)
I0524 02:59:16.957015 11654 sgd_solver.cpp:112] Iteration 24970, lr = 0.1
I0524 02:59:23.906867 11654 solver.cpp:239] Iteration 24980 (1.43314 iter/s, 6.97767s/10 iters), loss = 6.23044
I0524 02:59:23.907074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23044 (* 1 = 6.23044 loss)
I0524 02:59:23.907096 11654 sgd_solver.cpp:112] Iteration 24980, lr = 0.1
I0524 02:59:32.316097 11654 solver.cpp:239] Iteration 24990 (1.18926 iter/s, 8.4086s/10 iters), loss = 6.38608
I0524 02:59:32.316153 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38608 (* 1 = 6.38608 loss)
I0524 02:59:33.034973 11654 sgd_solver.cpp:112] Iteration 24990, lr = 0.1
I0524 02:59:39.652820 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_25000.caffemodel
I0524 02:59:41.585722 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_25000.solverstate
I0524 02:59:42.277173 11654 solver.cpp:239] Iteration 25000 (1.00395 iter/s, 9.96066s/10 iters), loss = 6.65739
I0524 02:59:42.277213 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65739 (* 1 = 6.65739 loss)
I0524 02:59:42.277314 11654 sgd_solver.cpp:112] Iteration 25000, lr = 0.1
I0524 02:59:48.692970 11654 solver.cpp:239] Iteration 25010 (1.55872 iter/s, 6.4155s/10 iters), loss = 7.03451
I0524 02:59:48.693025 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03451 (* 1 = 7.03451 loss)
I0524 02:59:48.722546 11654 sgd_solver.cpp:112] Iteration 25010, lr = 0.1
I0524 02:59:55.623790 11654 solver.cpp:239] Iteration 25020 (1.4429 iter/s, 6.93051s/10 iters), loss = 7.27079
I0524 02:59:55.623961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27079 (* 1 = 7.27079 loss)
I0524 02:59:55.734635 11654 sgd_solver.cpp:112] Iteration 25020, lr = 0.1
I0524 03:00:04.546150 11654 solver.cpp:239] Iteration 25030 (1.12084 iter/s, 8.92184s/10 iters), loss = 6.76455
I0524 03:00:04.546209 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76455 (* 1 = 6.76455 loss)
I0524 03:00:04.546226 11654 sgd_solver.cpp:112] Iteration 25030, lr = 0.1
I0524 03:00:11.009573 11654 solver.cpp:239] Iteration 25040 (1.54726 iter/s, 6.46305s/10 iters), loss = 6.9519
I0524 03:00:11.009637 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9519 (* 1 = 6.9519 loss)
I0524 03:00:11.019639 11654 sgd_solver.cpp:112] Iteration 25040, lr = 0.1
I0524 03:00:18.640254 11654 solver.cpp:239] Iteration 25050 (1.31056 iter/s, 7.63033s/10 iters), loss = 6.8832
I0524 03:00:18.640307 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8832 (* 1 = 6.8832 loss)
I0524 03:00:18.640322 11654 sgd_solver.cpp:112] Iteration 25050, lr = 0.1
I0524 03:00:24.756590 11654 solver.cpp:239] Iteration 25060 (1.63506 iter/s, 6.11598s/10 iters), loss = 6.64615
I0524 03:00:24.756646 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64615 (* 1 = 6.64615 loss)
I0524 03:00:24.757078 11654 sgd_solver.cpp:112] Iteration 25060, lr = 0.1
I0524 03:00:33.086783 11654 solver.cpp:239] Iteration 25070 (1.20051 iter/s, 8.32981s/10 iters), loss = 7.10124
I0524 03:00:33.086921 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10124 (* 1 = 7.10124 loss)
I0524 03:00:33.087266 11654 sgd_solver.cpp:112] Iteration 25070, lr = 0.1
I0524 03:00:41.326647 11654 solver.cpp:239] Iteration 25080 (1.21368 iter/s, 8.23942s/10 iters), loss = 7.46848
I0524 03:00:41.326716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.46848 (* 1 = 7.46848 loss)
I0524 03:00:41.327208 11654 sgd_solver.cpp:112] Iteration 25080, lr = 0.1
I0524 03:00:47.636567 11654 solver.cpp:239] Iteration 25090 (1.58488 iter/s, 6.30961s/10 iters), loss = 7.20427
I0524 03:00:47.636670 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20427 (* 1 = 7.20427 loss)
I0524 03:00:47.636708 11654 sgd_solver.cpp:112] Iteration 25090, lr = 0.1
I0524 03:00:54.552526 11654 solver.cpp:239] Iteration 25100 (1.44601 iter/s, 6.91557s/10 iters), loss = 6.4332
I0524 03:00:54.552582 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4332 (* 1 = 6.4332 loss)
I0524 03:00:54.552601 11654 sgd_solver.cpp:112] Iteration 25100, lr = 0.1
I0524 03:01:02.496639 11654 solver.cpp:239] Iteration 25110 (1.25886 iter/s, 7.9437s/10 iters), loss = 6.86105
I0524 03:01:02.496690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86105 (* 1 = 6.86105 loss)
I0524 03:01:02.496707 11654 sgd_solver.cpp:112] Iteration 25110, lr = 0.1
I0524 03:01:10.466802 11654 solver.cpp:239] Iteration 25120 (1.25508 iter/s, 7.96765s/10 iters), loss = 7.01226
I0524 03:01:10.467056 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01226 (* 1 = 7.01226 loss)
I0524 03:01:10.467115 11654 sgd_solver.cpp:112] Iteration 25120, lr = 0.1
I0524 03:01:17.491024 11654 solver.cpp:239] Iteration 25130 (1.42417 iter/s, 7.02162s/10 iters), loss = 6.36985
I0524 03:01:17.491075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36985 (* 1 = 6.36985 loss)
I0524 03:01:17.491192 11654 sgd_solver.cpp:112] Iteration 25130, lr = 0.1
I0524 03:01:25.213579 11654 solver.cpp:239] Iteration 25140 (1.29497 iter/s, 7.72221s/10 iters), loss = 7.23774
I0524 03:01:25.213631 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23774 (* 1 = 7.23774 loss)
I0524 03:01:25.213647 11654 sgd_solver.cpp:112] Iteration 25140, lr = 0.1
I0524 03:01:32.039258 11654 solver.cpp:239] Iteration 25150 (1.4653 iter/s, 6.82454s/10 iters), loss = 6.23827
I0524 03:01:32.039319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23827 (* 1 = 6.23827 loss)
I0524 03:01:32.039582 11654 sgd_solver.cpp:112] Iteration 25150, lr = 0.1
I0524 03:01:38.151300 11654 solver.cpp:239] Iteration 25160 (1.63619 iter/s, 6.11174s/10 iters), loss = 7.19674
I0524 03:01:38.151360 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19674 (* 1 = 7.19674 loss)
I0524 03:01:38.151376 11654 sgd_solver.cpp:112] Iteration 25160, lr = 0.1
I0524 03:01:44.175750 11654 solver.cpp:239] Iteration 25170 (1.66003 iter/s, 6.02399s/10 iters), loss = 5.96938
I0524 03:01:44.175879 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96938 (* 1 = 5.96938 loss)
I0524 03:01:44.695495 11654 sgd_solver.cpp:112] Iteration 25170, lr = 0.1
I0524 03:01:51.413106 11654 solver.cpp:239] Iteration 25180 (1.3818 iter/s, 7.23694s/10 iters), loss = 6.16967
I0524 03:01:51.413163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16967 (* 1 = 6.16967 loss)
I0524 03:01:51.416043 11654 sgd_solver.cpp:112] Iteration 25180, lr = 0.1
I0524 03:01:57.615730 11654 solver.cpp:239] Iteration 25190 (1.6123 iter/s, 6.20233s/10 iters), loss = 6.09245
I0524 03:01:57.615775 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09245 (* 1 = 6.09245 loss)
I0524 03:01:57.615829 11654 sgd_solver.cpp:112] Iteration 25190, lr = 0.1
I0524 03:02:03.924734 11654 solver.cpp:239] Iteration 25200 (1.58511 iter/s, 6.30871s/10 iters), loss = 7.54455
I0524 03:02:03.924787 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54455 (* 1 = 7.54455 loss)
I0524 03:02:03.924803 11654 sgd_solver.cpp:112] Iteration 25200, lr = 0.1
I0524 03:02:11.269443 11654 solver.cpp:239] Iteration 25210 (1.36159 iter/s, 7.34437s/10 iters), loss = 6.94598
I0524 03:02:11.269493 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94598 (* 1 = 6.94598 loss)
I0524 03:02:11.269848 11654 sgd_solver.cpp:112] Iteration 25210, lr = 0.1
I0524 03:02:17.237443 11654 solver.cpp:239] Iteration 25220 (1.67568 iter/s, 5.96771s/10 iters), loss = 6.72701
I0524 03:02:17.237578 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72701 (* 1 = 6.72701 loss)
I0524 03:02:17.237597 11654 sgd_solver.cpp:112] Iteration 25220, lr = 0.1
I0524 03:02:23.837302 11654 solver.cpp:239] Iteration 25230 (1.51528 iter/s, 6.59943s/10 iters), loss = 6.99632
I0524 03:02:23.837343 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99632 (* 1 = 6.99632 loss)
I0524 03:02:23.849840 11654 sgd_solver.cpp:112] Iteration 25230, lr = 0.1
I0524 03:02:32.961957 11654 solver.cpp:239] Iteration 25240 (1.09598 iter/s, 9.12426s/10 iters), loss = 7.59523
I0524 03:02:32.962003 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59523 (* 1 = 7.59523 loss)
I0524 03:02:32.962019 11654 sgd_solver.cpp:112] Iteration 25240, lr = 0.1
I0524 03:02:40.402562 11654 solver.cpp:239] Iteration 25250 (1.34404 iter/s, 7.44028s/10 iters), loss = 7.68584
I0524 03:02:40.402616 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.68584 (* 1 = 7.68584 loss)
I0524 03:02:40.402634 11654 sgd_solver.cpp:112] Iteration 25250, lr = 0.1
I0524 03:02:46.522387 11654 solver.cpp:239] Iteration 25260 (1.63423 iter/s, 6.11907s/10 iters), loss = 8.24761
I0524 03:02:46.522433 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.24761 (* 1 = 8.24761 loss)
I0524 03:02:46.522655 11654 sgd_solver.cpp:112] Iteration 25260, lr = 0.1
I0524 03:02:53.347635 11654 solver.cpp:239] Iteration 25270 (1.46522 iter/s, 6.82493s/10 iters), loss = 7.73296
I0524 03:02:53.347726 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.73296 (* 1 = 7.73296 loss)
I0524 03:02:53.347743 11654 sgd_solver.cpp:112] Iteration 25270, lr = 0.1
I0524 03:03:00.396914 11654 solver.cpp:239] Iteration 25280 (1.41908 iter/s, 7.04683s/10 iters), loss = 6.06885
I0524 03:03:00.396972 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06885 (* 1 = 6.06885 loss)
I0524 03:03:00.397121 11654 sgd_solver.cpp:112] Iteration 25280, lr = 0.1
I0524 03:03:09.338454 11654 solver.cpp:239] Iteration 25290 (1.11842 iter/s, 8.94115s/10 iters), loss = 7.39053
I0524 03:03:09.338507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39053 (* 1 = 7.39053 loss)
I0524 03:03:09.338522 11654 sgd_solver.cpp:112] Iteration 25290, lr = 0.1
I0524 03:03:17.440285 11654 solver.cpp:239] Iteration 25300 (1.23434 iter/s, 8.10147s/10 iters), loss = 6.73869
I0524 03:03:17.440342 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73869 (* 1 = 6.73869 loss)
I0524 03:03:18.138186 11654 sgd_solver.cpp:112] Iteration 25300, lr = 0.1
I0524 03:03:24.451273 11654 solver.cpp:239] Iteration 25310 (1.4264 iter/s, 7.01067s/10 iters), loss = 6.13811
I0524 03:03:24.451627 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13811 (* 1 = 6.13811 loss)
I0524 03:03:24.451695 11654 sgd_solver.cpp:112] Iteration 25310, lr = 0.1
I0524 03:03:31.810150 11654 solver.cpp:239] Iteration 25320 (1.35905 iter/s, 7.35808s/10 iters), loss = 6.31613
I0524 03:03:31.810200 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31613 (* 1 = 6.31613 loss)
I0524 03:03:31.810223 11654 sgd_solver.cpp:112] Iteration 25320, lr = 0.1
I0524 03:03:37.917049 11654 solver.cpp:239] Iteration 25330 (1.63757 iter/s, 6.10662s/10 iters), loss = 7.17058
I0524 03:03:37.917090 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17058 (* 1 = 7.17058 loss)
I0524 03:03:37.917255 11654 sgd_solver.cpp:112] Iteration 25330, lr = 0.1
I0524 03:03:45.147063 11654 solver.cpp:239] Iteration 25340 (1.38319 iter/s, 7.22967s/10 iters), loss = 6.33296
I0524 03:03:45.147116 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33296 (* 1 = 6.33296 loss)
I0524 03:03:45.147644 11654 sgd_solver.cpp:112] Iteration 25340, lr = 0.1
I0524 03:03:51.259426 11654 solver.cpp:239] Iteration 25350 (1.6361 iter/s, 6.11208s/10 iters), loss = 6.23726
I0524 03:03:51.259477 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23726 (* 1 = 6.23726 loss)
I0524 03:03:51.259493 11654 sgd_solver.cpp:112] Iteration 25350, lr = 0.1
I0524 03:03:58.300523 11654 solver.cpp:239] Iteration 25360 (1.4203 iter/s, 7.04078s/10 iters), loss = 6.37273
I0524 03:03:58.300806 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37273 (* 1 = 6.37273 loss)
I0524 03:03:58.469712 11654 sgd_solver.cpp:112] Iteration 25360, lr = 0.1
I0524 03:04:05.751713 11654 solver.cpp:239] Iteration 25370 (1.34216 iter/s, 7.45068s/10 iters), loss = 7.3007
I0524 03:04:05.751772 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3007 (* 1 = 7.3007 loss)
I0524 03:04:06.312870 11654 sgd_solver.cpp:112] Iteration 25370, lr = 0.1
I0524 03:04:12.734688 11654 solver.cpp:239] Iteration 25380 (1.43212 iter/s, 6.98265s/10 iters), loss = 6.83556
I0524 03:04:12.734766 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83556 (* 1 = 6.83556 loss)
I0524 03:04:12.734782 11654 sgd_solver.cpp:112] Iteration 25380, lr = 0.1
I0524 03:04:19.726964 11654 solver.cpp:239] Iteration 25390 (1.43022 iter/s, 6.99194s/10 iters), loss = 6.35848
I0524 03:04:19.727010 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35848 (* 1 = 6.35848 loss)
I0524 03:04:19.727113 11654 sgd_solver.cpp:112] Iteration 25390, lr = 0.1
I0524 03:04:26.987344 11654 solver.cpp:239] Iteration 25400 (1.3774 iter/s, 7.26005s/10 iters), loss = 5.78282
I0524 03:04:26.987396 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78282 (* 1 = 5.78282 loss)
I0524 03:04:26.987411 11654 sgd_solver.cpp:112] Iteration 25400, lr = 0.1
I0524 03:04:35.040917 11654 solver.cpp:239] Iteration 25410 (1.24174 iter/s, 8.05321s/10 iters), loss = 6.3517
I0524 03:04:35.041229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3517 (* 1 = 6.3517 loss)
I0524 03:04:35.041296 11654 sgd_solver.cpp:112] Iteration 25410, lr = 0.1
I0524 03:04:44.250989 11654 solver.cpp:239] Iteration 25420 (1.08589 iter/s, 9.20905s/10 iters), loss = 6.91573
I0524 03:04:44.251044 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91573 (* 1 = 6.91573 loss)
I0524 03:04:44.251140 11654 sgd_solver.cpp:112] Iteration 25420, lr = 0.1
I0524 03:04:51.684922 11654 solver.cpp:239] Iteration 25430 (1.34524 iter/s, 7.4336s/10 iters), loss = 6.85767
I0524 03:04:51.684981 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85767 (* 1 = 6.85767 loss)
I0524 03:04:51.684999 11654 sgd_solver.cpp:112] Iteration 25430, lr = 0.1
I0524 03:04:58.757046 11654 solver.cpp:239] Iteration 25440 (1.4145 iter/s, 7.06966s/10 iters), loss = 6.65318
I0524 03:04:58.757095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65318 (* 1 = 6.65318 loss)
I0524 03:04:58.757320 11654 sgd_solver.cpp:112] Iteration 25440, lr = 0.1
I0524 03:05:06.961292 11654 solver.cpp:239] Iteration 25450 (1.21894 iter/s, 8.20388s/10 iters), loss = 6.0416
I0524 03:05:06.961453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0416 (* 1 = 6.0416 loss)
I0524 03:05:06.961472 11654 sgd_solver.cpp:112] Iteration 25450, lr = 0.1
I0524 03:05:13.677572 11654 solver.cpp:239] Iteration 25460 (1.48901 iter/s, 6.71585s/10 iters), loss = 7.08647
I0524 03:05:13.677621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08647 (* 1 = 7.08647 loss)
I0524 03:05:13.919322 11654 sgd_solver.cpp:112] Iteration 25460, lr = 0.1
I0524 03:05:20.797024 11654 solver.cpp:239] Iteration 25470 (1.40467 iter/s, 7.11912s/10 iters), loss = 6.83856
I0524 03:05:20.797075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83856 (* 1 = 6.83856 loss)
I0524 03:05:20.797191 11654 sgd_solver.cpp:112] Iteration 25470, lr = 0.1
I0524 03:05:28.253099 11654 solver.cpp:239] Iteration 25480 (1.34125 iter/s, 7.45573s/10 iters), loss = 7.28799
I0524 03:05:28.253156 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28799 (* 1 = 7.28799 loss)
I0524 03:05:28.889494 11654 sgd_solver.cpp:112] Iteration 25480, lr = 0.1
I0524 03:05:35.219595 11654 solver.cpp:239] Iteration 25490 (1.43551 iter/s, 6.96617s/10 iters), loss = 6.01301
I0524 03:05:35.219640 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01301 (* 1 = 6.01301 loss)
I0524 03:05:35.220113 11654 sgd_solver.cpp:112] Iteration 25490, lr = 0.1
I0524 03:05:41.497710 11654 solver.cpp:239] Iteration 25500 (1.59291 iter/s, 6.27782s/10 iters), loss = 5.03
I0524 03:05:41.497866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.03 (* 1 = 5.03 loss)
I0524 03:05:42.204671 11654 sgd_solver.cpp:112] Iteration 25500, lr = 0.1
I0524 03:05:48.954582 11654 solver.cpp:239] Iteration 25510 (1.34112 iter/s, 7.45644s/10 iters), loss = 6.16528
I0524 03:05:48.954627 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16528 (* 1 = 6.16528 loss)
I0524 03:05:49.604492 11654 sgd_solver.cpp:112] Iteration 25510, lr = 0.1
I0524 03:05:56.364202 11654 solver.cpp:239] Iteration 25520 (1.34966 iter/s, 7.40928s/10 iters), loss = 6.72889
I0524 03:05:56.364262 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72889 (* 1 = 6.72889 loss)
I0524 03:05:56.364284 11654 sgd_solver.cpp:112] Iteration 25520, lr = 0.1
I0524 03:06:06.042801 11654 solver.cpp:239] Iteration 25530 (1.03349 iter/s, 9.67597s/10 iters), loss = 6.75972
I0524 03:06:06.042855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75972 (* 1 = 6.75972 loss)
I0524 03:06:06.291875 11654 sgd_solver.cpp:112] Iteration 25530, lr = 0.1
I0524 03:06:14.113679 11654 solver.cpp:239] Iteration 25540 (1.23908 iter/s, 8.07051s/10 iters), loss = 6.62013
I0524 03:06:14.113920 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62013 (* 1 = 6.62013 loss)
I0524 03:06:14.114255 11654 sgd_solver.cpp:112] Iteration 25540, lr = 0.1
I0524 03:06:20.596710 11654 solver.cpp:239] Iteration 25550 (1.5426 iter/s, 6.48258s/10 iters), loss = 6.83224
I0524 03:06:20.596763 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83224 (* 1 = 6.83224 loss)
I0524 03:06:20.597260 11654 sgd_solver.cpp:112] Iteration 25550, lr = 0.1
I0524 03:06:29.688859 11654 solver.cpp:239] Iteration 25560 (1.0999 iter/s, 9.09174s/10 iters), loss = 7.67059
I0524 03:06:29.688923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.67059 (* 1 = 7.67059 loss)
I0524 03:06:29.719346 11654 sgd_solver.cpp:112] Iteration 25560, lr = 0.1
I0524 03:06:38.064843 11654 solver.cpp:239] Iteration 25570 (1.19394 iter/s, 8.3756s/10 iters), loss = 6.96908
I0524 03:06:38.064898 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96908 (* 1 = 6.96908 loss)
I0524 03:06:38.065196 11654 sgd_solver.cpp:112] Iteration 25570, lr = 0.1
I0524 03:06:45.271286 11654 solver.cpp:239] Iteration 25580 (1.38771 iter/s, 7.20611s/10 iters), loss = 6.07967
I0524 03:06:45.271425 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07967 (* 1 = 6.07967 loss)
I0524 03:06:45.271456 11654 sgd_solver.cpp:112] Iteration 25580, lr = 0.1
I0524 03:06:52.681682 11654 solver.cpp:239] Iteration 25590 (1.34954 iter/s, 7.40995s/10 iters), loss = 6.54735
I0524 03:06:52.681722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54735 (* 1 = 6.54735 loss)
I0524 03:06:52.681736 11654 sgd_solver.cpp:112] Iteration 25590, lr = 0.1
I0524 03:06:59.395375 11654 solver.cpp:239] Iteration 25600 (1.49005 iter/s, 6.71116s/10 iters), loss = 6.64682
I0524 03:06:59.395427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64682 (* 1 = 6.64682 loss)
I0524 03:06:59.395612 11654 sgd_solver.cpp:112] Iteration 25600, lr = 0.1
I0524 03:07:05.749737 11654 solver.cpp:239] Iteration 25610 (1.57379 iter/s, 6.35407s/10 iters), loss = 6.46076
I0524 03:07:05.749794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46076 (* 1 = 6.46076 loss)
I0524 03:07:05.749809 11654 sgd_solver.cpp:112] Iteration 25610, lr = 0.1
I0524 03:07:11.886184 11654 solver.cpp:239] Iteration 25620 (1.6297 iter/s, 6.1361s/10 iters), loss = 6.92867
I0524 03:07:11.886229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92867 (* 1 = 6.92867 loss)
I0524 03:07:11.965122 11654 sgd_solver.cpp:112] Iteration 25620, lr = 0.1
I0524 03:07:18.208988 11654 solver.cpp:239] Iteration 25630 (1.58165 iter/s, 6.3225s/10 iters), loss = 6.94059
I0524 03:07:18.209278 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94059 (* 1 = 6.94059 loss)
I0524 03:07:18.209342 11654 sgd_solver.cpp:112] Iteration 25630, lr = 0.1
I0524 03:07:25.206869 11654 solver.cpp:239] Iteration 25640 (1.42914 iter/s, 6.99723s/10 iters), loss = 7.40956
I0524 03:07:25.206933 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40956 (* 1 = 7.40956 loss)
I0524 03:07:25.208102 11654 sgd_solver.cpp:112] Iteration 25640, lr = 0.1
I0524 03:07:31.978660 11654 solver.cpp:239] Iteration 25650 (1.47679 iter/s, 6.77146s/10 iters), loss = 7.00355
I0524 03:07:31.978736 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00355 (* 1 = 7.00355 loss)
I0524 03:07:32.001689 11654 sgd_solver.cpp:112] Iteration 25650, lr = 0.1
I0524 03:07:38.637028 11654 solver.cpp:239] Iteration 25660 (1.50194 iter/s, 6.65806s/10 iters), loss = 6.08962
I0524 03:07:38.637084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08962 (* 1 = 6.08962 loss)
I0524 03:07:38.637217 11654 sgd_solver.cpp:112] Iteration 25660, lr = 0.1
I0524 03:07:45.342238 11654 solver.cpp:239] Iteration 25670 (1.49145 iter/s, 6.70491s/10 iters), loss = 5.47377
I0524 03:07:45.342291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47377 (* 1 = 5.47377 loss)
I0524 03:07:45.342308 11654 sgd_solver.cpp:112] Iteration 25670, lr = 0.1
I0524 03:07:53.594806 11654 solver.cpp:239] Iteration 25680 (1.2118 iter/s, 8.2522s/10 iters), loss = 7.04089
I0524 03:07:53.595082 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04089 (* 1 = 7.04089 loss)
I0524 03:07:53.595141 11654 sgd_solver.cpp:112] Iteration 25680, lr = 0.1
I0524 03:08:00.819648 11654 solver.cpp:239] Iteration 25690 (1.38422 iter/s, 7.22429s/10 iters), loss = 7.19846
I0524 03:08:00.819701 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19846 (* 1 = 7.19846 loss)
I0524 03:08:00.819716 11654 sgd_solver.cpp:112] Iteration 25690, lr = 0.1
I0524 03:08:09.463904 11654 solver.cpp:239] Iteration 25700 (1.15719 iter/s, 8.64165s/10 iters), loss = 6.4669
I0524 03:08:09.463963 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4669 (* 1 = 6.4669 loss)
I0524 03:08:10.241576 11654 sgd_solver.cpp:112] Iteration 25700, lr = 0.1
I0524 03:08:18.360414 11654 solver.cpp:239] Iteration 25710 (1.12409 iter/s, 8.89612s/10 iters), loss = 7.62871
I0524 03:08:18.360455 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62871 (* 1 = 7.62871 loss)
I0524 03:08:18.368427 11654 sgd_solver.cpp:112] Iteration 25710, lr = 0.1
I0524 03:08:26.202677 11654 solver.cpp:239] Iteration 25720 (1.2752 iter/s, 7.8419s/10 iters), loss = 5.6485
I0524 03:08:26.202867 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6485 (* 1 = 5.6485 loss)
I0524 03:08:26.203142 11654 sgd_solver.cpp:112] Iteration 25720, lr = 0.1
I0524 03:08:32.877070 11654 solver.cpp:239] Iteration 25730 (1.49836 iter/s, 6.67396s/10 iters), loss = 7.16066
I0524 03:08:32.877130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16066 (* 1 = 7.16066 loss)
I0524 03:08:32.877626 11654 sgd_solver.cpp:112] Iteration 25730, lr = 0.1
I0524 03:08:39.958806 11654 solver.cpp:239] Iteration 25740 (1.41215 iter/s, 7.08141s/10 iters), loss = 6.06003
I0524 03:08:39.958851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06003 (* 1 = 6.06003 loss)
I0524 03:08:39.958925 11654 sgd_solver.cpp:112] Iteration 25740, lr = 0.1
I0524 03:08:46.051846 11654 solver.cpp:239] Iteration 25750 (1.64129 iter/s, 6.09276s/10 iters), loss = 5.67015
I0524 03:08:46.051899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67015 (* 1 = 5.67015 loss)
I0524 03:08:46.051914 11654 sgd_solver.cpp:112] Iteration 25750, lr = 0.1
I0524 03:08:52.234278 11654 solver.cpp:239] Iteration 25760 (1.61756 iter/s, 6.18215s/10 iters), loss = 5.44243
I0524 03:08:52.234323 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44243 (* 1 = 5.44243 loss)
I0524 03:08:52.234349 11654 sgd_solver.cpp:112] Iteration 25760, lr = 0.1
I0524 03:08:58.747195 11654 solver.cpp:239] Iteration 25770 (1.53548 iter/s, 6.51262s/10 iters), loss = 6.83071
I0524 03:08:58.747474 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83071 (* 1 = 6.83071 loss)
I0524 03:08:58.747541 11654 sgd_solver.cpp:112] Iteration 25770, lr = 0.1
I0524 03:09:06.413610 11654 solver.cpp:239] Iteration 25780 (1.30456 iter/s, 7.66544s/10 iters), loss = 6.67532
I0524 03:09:06.413669 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67532 (* 1 = 6.67532 loss)
I0524 03:09:06.413944 11654 sgd_solver.cpp:112] Iteration 25780, lr = 0.1
I0524 03:09:13.620234 11654 solver.cpp:239] Iteration 25790 (1.38768 iter/s, 7.20629s/10 iters), loss = 6.38062
I0524 03:09:13.620311 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38062 (* 1 = 6.38062 loss)
I0524 03:09:13.620599 11654 sgd_solver.cpp:112] Iteration 25790, lr = 0.1
I0524 03:09:20.136936 11654 solver.cpp:239] Iteration 25800 (1.53459 iter/s, 6.51639s/10 iters), loss = 7.34427
I0524 03:09:20.136976 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.34427 (* 1 = 7.34427 loss)
I0524 03:09:20.136999 11654 sgd_solver.cpp:112] Iteration 25800, lr = 0.1
I0524 03:09:26.179848 11654 solver.cpp:239] Iteration 25810 (1.65491 iter/s, 6.04262s/10 iters), loss = 6.65865
I0524 03:09:26.179906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65865 (* 1 = 6.65865 loss)
I0524 03:09:26.180244 11654 sgd_solver.cpp:112] Iteration 25810, lr = 0.1
I0524 03:09:32.914007 11654 solver.cpp:239] Iteration 25820 (1.48503 iter/s, 6.73385s/10 iters), loss = 5.82172
I0524 03:09:32.914270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82172 (* 1 = 5.82172 loss)
I0524 03:09:32.914332 11654 sgd_solver.cpp:112] Iteration 25820, lr = 0.1
I0524 03:09:39.918952 11654 solver.cpp:239] Iteration 25830 (1.4281 iter/s, 7.00229s/10 iters), loss = 5.97957
I0524 03:09:39.919014 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97957 (* 1 = 5.97957 loss)
I0524 03:09:39.919041 11654 sgd_solver.cpp:112] Iteration 25830, lr = 0.1
I0524 03:09:47.095767 11654 solver.cpp:239] Iteration 25840 (1.39381 iter/s, 7.1746s/10 iters), loss = 6.29085
I0524 03:09:47.095823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29085 (* 1 = 6.29085 loss)
I0524 03:09:47.375015 11654 sgd_solver.cpp:112] Iteration 25840, lr = 0.1
I0524 03:09:54.168579 11654 solver.cpp:239] Iteration 25850 (1.41393 iter/s, 7.07248s/10 iters), loss = 5.89905
I0524 03:09:54.168642 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89905 (* 1 = 5.89905 loss)
I0524 03:09:54.169029 11654 sgd_solver.cpp:112] Iteration 25850, lr = 0.1
I0524 03:10:00.289005 11654 solver.cpp:239] Iteration 25860 (1.63395 iter/s, 6.12013s/10 iters), loss = 7.72811
I0524 03:10:00.289052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.72811 (* 1 = 7.72811 loss)
I0524 03:10:00.289324 11654 sgd_solver.cpp:112] Iteration 25860, lr = 0.1
I0524 03:10:06.864440 11654 solver.cpp:239] Iteration 25870 (1.52088 iter/s, 6.57513s/10 iters), loss = 6.27664
I0524 03:10:06.864643 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27664 (* 1 = 6.27664 loss)
I0524 03:10:06.864667 11654 sgd_solver.cpp:112] Iteration 25870, lr = 0.1
I0524 03:10:13.368338 11654 solver.cpp:239] Iteration 25880 (1.53764 iter/s, 6.50345s/10 iters), loss = 6.47545
I0524 03:10:13.368386 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47545 (* 1 = 6.47545 loss)
I0524 03:10:13.368744 11654 sgd_solver.cpp:112] Iteration 25880, lr = 0.1
I0524 03:10:19.733065 11654 solver.cpp:239] Iteration 25890 (1.57123 iter/s, 6.36443s/10 iters), loss = 6.22761
I0524 03:10:19.733117 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22761 (* 1 = 6.22761 loss)
I0524 03:10:19.733225 11654 sgd_solver.cpp:112] Iteration 25890, lr = 0.1
I0524 03:10:25.982199 11654 solver.cpp:239] Iteration 25900 (1.6003 iter/s, 6.24884s/10 iters), loss = 7.0082
I0524 03:10:25.982259 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0082 (* 1 = 7.0082 loss)
I0524 03:10:25.982488 11654 sgd_solver.cpp:112] Iteration 25900, lr = 0.1
I0524 03:10:33.580621 11654 solver.cpp:239] Iteration 25910 (1.31612 iter/s, 7.59808s/10 iters), loss = 6.08277
I0524 03:10:33.580660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08277 (* 1 = 6.08277 loss)
I0524 03:10:33.580674 11654 sgd_solver.cpp:112] Iteration 25910, lr = 0.1
I0524 03:10:40.377171 11654 solver.cpp:239] Iteration 25920 (1.47146 iter/s, 6.79598s/10 iters), loss = 6.50682
I0524 03:10:40.377372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50682 (* 1 = 6.50682 loss)
I0524 03:10:41.246150 11654 sgd_solver.cpp:112] Iteration 25920, lr = 0.1
I0524 03:10:49.878140 11654 solver.cpp:239] Iteration 25930 (1.05258 iter/s, 9.50044s/10 iters), loss = 6.34531
I0524 03:10:49.878195 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34531 (* 1 = 6.34531 loss)
I0524 03:10:50.721014 11654 sgd_solver.cpp:112] Iteration 25930, lr = 0.1
I0524 03:10:59.749138 11654 solver.cpp:239] Iteration 25940 (1.01311 iter/s, 9.87058s/10 iters), loss = 5.48798
I0524 03:10:59.749182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48798 (* 1 = 5.48798 loss)
I0524 03:10:59.752176 11654 sgd_solver.cpp:112] Iteration 25940, lr = 0.1
I0524 03:11:08.376090 11654 solver.cpp:239] Iteration 25950 (1.15921 iter/s, 8.62657s/10 iters), loss = 7.56592
I0524 03:11:08.376140 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.56592 (* 1 = 7.56592 loss)
I0524 03:11:08.382076 11654 sgd_solver.cpp:112] Iteration 25950, lr = 0.1
I0524 03:11:14.476478 11654 solver.cpp:239] Iteration 25960 (1.63932 iter/s, 6.1001s/10 iters), loss = 5.94375
I0524 03:11:14.476757 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94375 (* 1 = 5.94375 loss)
I0524 03:11:14.476822 11654 sgd_solver.cpp:112] Iteration 25960, lr = 0.1
I0524 03:11:20.920691 11654 solver.cpp:239] Iteration 25970 (1.55189 iter/s, 6.44375s/10 iters), loss = 6.27974
I0524 03:11:20.920729 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27974 (* 1 = 6.27974 loss)
I0524 03:11:21.026178 11654 sgd_solver.cpp:112] Iteration 25970, lr = 0.1
I0524 03:11:28.190918 11654 solver.cpp:239] Iteration 25980 (1.37554 iter/s, 7.2699s/10 iters), loss = 6.00609
I0524 03:11:28.190981 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00609 (* 1 = 6.00609 loss)
I0524 03:11:28.191154 11654 sgd_solver.cpp:112] Iteration 25980, lr = 0.1
I0524 03:11:34.708828 11654 solver.cpp:239] Iteration 25990 (1.53431 iter/s, 6.5176s/10 iters), loss = 6.14136
I0524 03:11:34.708884 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14136 (* 1 = 6.14136 loss)
I0524 03:11:35.018044 11654 sgd_solver.cpp:112] Iteration 25990, lr = 0.1
I0524 03:11:41.812300 11654 solver.cpp:239] Iteration 26000 (1.40783 iter/s, 7.10315s/10 iters), loss = 6.58721
I0524 03:11:41.812345 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58721 (* 1 = 6.58721 loss)
I0524 03:11:41.812651 11654 sgd_solver.cpp:112] Iteration 26000, lr = 0.1
I0524 03:11:48.589180 11654 solver.cpp:239] Iteration 26010 (1.47567 iter/s, 6.77657s/10 iters), loss = 7.06094
I0524 03:11:48.589495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06094 (* 1 = 7.06094 loss)
I0524 03:11:48.875579 11654 sgd_solver.cpp:112] Iteration 26010, lr = 0.1
I0524 03:11:55.482585 11654 solver.cpp:239] Iteration 26020 (1.45077 iter/s, 6.89288s/10 iters), loss = 5.84588
I0524 03:11:55.482632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84588 (* 1 = 5.84588 loss)
I0524 03:11:55.482648 11654 sgd_solver.cpp:112] Iteration 26020, lr = 0.1
I0524 03:12:02.597072 11654 solver.cpp:239] Iteration 26030 (1.40566 iter/s, 7.1141s/10 iters), loss = 6.87481
I0524 03:12:02.597124 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87481 (* 1 = 6.87481 loss)
I0524 03:12:02.597347 11654 sgd_solver.cpp:112] Iteration 26030, lr = 0.1
I0524 03:12:10.988236 11654 solver.cpp:239] Iteration 26040 (1.19178 iter/s, 8.39079s/10 iters), loss = 6.05504
I0524 03:12:10.988286 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05504 (* 1 = 6.05504 loss)
I0524 03:12:11.011976 11654 sgd_solver.cpp:112] Iteration 26040, lr = 0.1
I0524 03:12:17.950131 11654 solver.cpp:239] Iteration 26050 (1.43646 iter/s, 6.96158s/10 iters), loss = 6.63169
I0524 03:12:17.950170 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63169 (* 1 = 6.63169 loss)
I0524 03:12:17.950392 11654 sgd_solver.cpp:112] Iteration 26050, lr = 0.1
I0524 03:12:24.820873 11654 solver.cpp:239] Iteration 26060 (1.45552 iter/s, 6.87042s/10 iters), loss = 7.50006
I0524 03:12:24.821151 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50006 (* 1 = 7.50006 loss)
I0524 03:12:24.911109 11654 sgd_solver.cpp:112] Iteration 26060, lr = 0.1
I0524 03:12:31.740731 11654 solver.cpp:239] Iteration 26070 (1.44522 iter/s, 6.91936s/10 iters), loss = 6.4099
I0524 03:12:31.740772 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4099 (* 1 = 6.4099 loss)
I0524 03:12:31.740931 11654 sgd_solver.cpp:112] Iteration 26070, lr = 0.1
I0524 03:12:39.173298 11654 solver.cpp:239] Iteration 26080 (1.34549 iter/s, 7.43224s/10 iters), loss = 6.16079
I0524 03:12:39.173349 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16079 (* 1 = 6.16079 loss)
I0524 03:12:39.938230 11654 sgd_solver.cpp:112] Iteration 26080, lr = 0.1
I0524 03:12:47.329972 11654 solver.cpp:239] Iteration 26090 (1.22604 iter/s, 8.15631s/10 iters), loss = 6.90843
I0524 03:12:47.330019 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90843 (* 1 = 6.90843 loss)
I0524 03:12:47.619436 11654 sgd_solver.cpp:112] Iteration 26090, lr = 0.1
I0524 03:12:55.525499 11654 solver.cpp:239] Iteration 26100 (1.22023 iter/s, 8.19516s/10 iters), loss = 6.88186
I0524 03:12:55.525784 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88186 (* 1 = 6.88186 loss)
I0524 03:12:55.824173 11654 sgd_solver.cpp:112] Iteration 26100, lr = 0.1
I0524 03:13:03.045126 11654 solver.cpp:239] Iteration 26110 (1.32994 iter/s, 7.51911s/10 iters), loss = 6.18071
I0524 03:13:03.045179 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18071 (* 1 = 6.18071 loss)
I0524 03:13:03.045197 11654 sgd_solver.cpp:112] Iteration 26110, lr = 0.1
I0524 03:13:09.980283 11654 solver.cpp:239] Iteration 26120 (1.44201 iter/s, 6.93477s/10 iters), loss = 6.80769
I0524 03:13:09.980336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80769 (* 1 = 6.80769 loss)
I0524 03:13:09.980476 11654 sgd_solver.cpp:112] Iteration 26120, lr = 0.1
I0524 03:13:17.324808 11654 solver.cpp:239] Iteration 26130 (1.36162 iter/s, 7.3442s/10 iters), loss = 6.39005
I0524 03:13:17.324849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39005 (* 1 = 6.39005 loss)
I0524 03:13:17.325062 11654 sgd_solver.cpp:112] Iteration 26130, lr = 0.1
I0524 03:13:24.554795 11654 solver.cpp:239] Iteration 26140 (1.38319 iter/s, 7.22966s/10 iters), loss = 6.25481
I0524 03:13:24.554852 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25481 (* 1 = 6.25481 loss)
I0524 03:13:24.554975 11654 sgd_solver.cpp:112] Iteration 26140, lr = 0.1
I0524 03:13:31.614362 11654 solver.cpp:239] Iteration 26150 (1.41658 iter/s, 7.05924s/10 iters), loss = 6.24127
I0524 03:13:31.614748 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24127 (* 1 = 6.24127 loss)
I0524 03:13:31.614822 11654 sgd_solver.cpp:112] Iteration 26150, lr = 0.1
I0524 03:13:39.650553 11654 solver.cpp:239] Iteration 26160 (1.24446 iter/s, 8.03561s/10 iters), loss = 6.24616
I0524 03:13:39.650594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24616 (* 1 = 6.24616 loss)
I0524 03:13:39.661079 11654 sgd_solver.cpp:112] Iteration 26160, lr = 0.1
I0524 03:13:47.120833 11654 solver.cpp:239] Iteration 26170 (1.3387 iter/s, 7.46994s/10 iters), loss = 7.94597
I0524 03:13:47.120899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.94597 (* 1 = 7.94597 loss)
I0524 03:13:47.121115 11654 sgd_solver.cpp:112] Iteration 26170, lr = 0.1
I0524 03:13:53.645215 11654 solver.cpp:239] Iteration 26180 (1.53278 iter/s, 6.52408s/10 iters), loss = 6.21397
I0524 03:13:53.645269 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21397 (* 1 = 6.21397 loss)
I0524 03:13:53.645285 11654 sgd_solver.cpp:112] Iteration 26180, lr = 0.1
I0524 03:14:01.270527 11654 solver.cpp:239] Iteration 26190 (1.31186 iter/s, 7.62274s/10 iters), loss = 6.14724
I0524 03:14:01.270565 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14724 (* 1 = 6.14724 loss)
I0524 03:14:01.329133 11654 sgd_solver.cpp:112] Iteration 26190, lr = 0.1
I0524 03:14:08.156379 11654 solver.cpp:239] Iteration 26200 (1.45232 iter/s, 6.88554s/10 iters), loss = 6.38389
I0524 03:14:08.156518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38389 (* 1 = 6.38389 loss)
I0524 03:14:08.454013 11654 sgd_solver.cpp:112] Iteration 26200, lr = 0.1
I0524 03:14:15.657259 11654 solver.cpp:239] Iteration 26210 (1.33325 iter/s, 7.50045s/10 iters), loss = 6.55677
I0524 03:14:15.657315 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55677 (* 1 = 6.55677 loss)
I0524 03:14:15.659251 11654 sgd_solver.cpp:112] Iteration 26210, lr = 0.1
I0524 03:14:21.821516 11654 solver.cpp:239] Iteration 26220 (1.62233 iter/s, 6.16396s/10 iters), loss = 6.82918
I0524 03:14:21.821568 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82918 (* 1 = 6.82918 loss)
I0524 03:14:21.821585 11654 sgd_solver.cpp:112] Iteration 26220, lr = 0.1
I0524 03:14:28.121410 11654 solver.cpp:239] Iteration 26230 (1.5874 iter/s, 6.2996s/10 iters), loss = 7.08909
I0524 03:14:28.121462 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08909 (* 1 = 7.08909 loss)
I0524 03:14:28.121515 11654 sgd_solver.cpp:112] Iteration 26230, lr = 0.1
I0524 03:14:35.631448 11654 solver.cpp:239] Iteration 26240 (1.33161 iter/s, 7.50971s/10 iters), loss = 6.80638
I0524 03:14:35.631491 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80638 (* 1 = 6.80638 loss)
I0524 03:14:35.631508 11654 sgd_solver.cpp:112] Iteration 26240, lr = 0.1
I0524 03:14:42.688540 11654 solver.cpp:239] Iteration 26250 (1.41708 iter/s, 7.05677s/10 iters), loss = 6.30614
I0524 03:14:42.688860 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30614 (* 1 = 6.30614 loss)
I0524 03:14:43.476356 11654 sgd_solver.cpp:112] Iteration 26250, lr = 0.1
I0524 03:14:51.979362 11654 solver.cpp:239] Iteration 26260 (1.0764 iter/s, 9.29021s/10 iters), loss = 7.01904
I0524 03:14:51.979419 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01904 (* 1 = 7.01904 loss)
I0524 03:14:51.979439 11654 sgd_solver.cpp:112] Iteration 26260, lr = 0.1
I0524 03:14:59.166496 11654 solver.cpp:239] Iteration 26270 (1.39145 iter/s, 7.18673s/10 iters), loss = 6.39826
I0524 03:14:59.166553 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39826 (* 1 = 6.39826 loss)
I0524 03:14:59.166570 11654 sgd_solver.cpp:112] Iteration 26270, lr = 0.1
I0524 03:15:05.606634 11654 solver.cpp:239] Iteration 26280 (1.55286 iter/s, 6.43973s/10 iters), loss = 7.08645
I0524 03:15:05.606680 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08645 (* 1 = 7.08645 loss)
I0524 03:15:06.040765 11654 sgd_solver.cpp:112] Iteration 26280, lr = 0.1
I0524 03:15:12.490605 11654 solver.cpp:239] Iteration 26290 (1.45272 iter/s, 6.88365s/10 iters), loss = 6.68951
I0524 03:15:12.490658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68951 (* 1 = 6.68951 loss)
I0524 03:15:12.490998 11654 sgd_solver.cpp:112] Iteration 26290, lr = 0.1
I0524 03:15:19.112054 11654 solver.cpp:239] Iteration 26300 (1.51031 iter/s, 6.62115s/10 iters), loss = 6.4952
I0524 03:15:19.112325 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4952 (* 1 = 6.4952 loss)
I0524 03:15:19.112390 11654 sgd_solver.cpp:112] Iteration 26300, lr = 0.1
I0524 03:15:25.556032 11654 solver.cpp:239] Iteration 26310 (1.55203 iter/s, 6.44318s/10 iters), loss = 5.602
I0524 03:15:25.556092 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.602 (* 1 = 5.602 loss)
I0524 03:15:26.095337 11654 sgd_solver.cpp:112] Iteration 26310, lr = 0.1
I0524 03:15:32.837857 11654 solver.cpp:239] Iteration 26320 (1.37335 iter/s, 7.28148s/10 iters), loss = 7.63394
I0524 03:15:32.837918 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63394 (* 1 = 7.63394 loss)
I0524 03:15:32.838150 11654 sgd_solver.cpp:112] Iteration 26320, lr = 0.1
I0524 03:15:38.947801 11654 solver.cpp:239] Iteration 26330 (1.63675 iter/s, 6.10965s/10 iters), loss = 6.43448
I0524 03:15:38.947856 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43448 (* 1 = 6.43448 loss)
I0524 03:15:38.947872 11654 sgd_solver.cpp:112] Iteration 26330, lr = 0.1
I0524 03:15:46.338673 11654 solver.cpp:239] Iteration 26340 (1.3531 iter/s, 7.39046s/10 iters), loss = 5.59188
I0524 03:15:46.338726 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59188 (* 1 = 5.59188 loss)
I0524 03:15:46.338739 11654 sgd_solver.cpp:112] Iteration 26340, lr = 0.1
I0524 03:15:52.480804 11654 solver.cpp:239] Iteration 26350 (1.62876 iter/s, 6.13964s/10 iters), loss = 6.09228
I0524 03:15:52.480881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09228 (* 1 = 6.09228 loss)
I0524 03:15:52.481031 11654 sgd_solver.cpp:112] Iteration 26350, lr = 0.1
I0524 03:15:59.598652 11654 solver.cpp:239] Iteration 26360 (1.40499 iter/s, 7.11749s/10 iters), loss = 6.72977
I0524 03:15:59.598706 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72977 (* 1 = 6.72977 loss)
I0524 03:15:59.598721 11654 sgd_solver.cpp:112] Iteration 26360, lr = 0.1
I0524 03:16:07.714649 11654 solver.cpp:239] Iteration 26370 (1.23222 iter/s, 8.11546s/10 iters), loss = 6.62332
I0524 03:16:07.714725 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62332 (* 1 = 6.62332 loss)
I0524 03:16:07.714753 11654 sgd_solver.cpp:112] Iteration 26370, lr = 0.1
I0524 03:16:16.128204 11654 solver.cpp:239] Iteration 26380 (1.18862 iter/s, 8.41312s/10 iters), loss = 7.12803
I0524 03:16:16.128259 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12803 (* 1 = 7.12803 loss)
I0524 03:16:16.329536 11654 sgd_solver.cpp:112] Iteration 26380, lr = 0.1
I0524 03:16:22.427212 11654 solver.cpp:239] Iteration 26390 (1.58763 iter/s, 6.29871s/10 iters), loss = 5.92246
I0524 03:16:22.427263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92246 (* 1 = 5.92246 loss)
I0524 03:16:22.427387 11654 sgd_solver.cpp:112] Iteration 26390, lr = 0.1
I0524 03:16:30.659109 11654 solver.cpp:239] Iteration 26400 (1.21484 iter/s, 8.23153s/10 iters), loss = 6.10668
I0524 03:16:30.659395 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10668 (* 1 = 6.10668 loss)
I0524 03:16:30.659476 11654 sgd_solver.cpp:112] Iteration 26400, lr = 0.1
I0524 03:16:37.356135 11654 solver.cpp:239] Iteration 26410 (1.49378 iter/s, 6.69445s/10 iters), loss = 6.21359
I0524 03:16:37.356190 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21359 (* 1 = 6.21359 loss)
I0524 03:16:37.356617 11654 sgd_solver.cpp:112] Iteration 26410, lr = 0.1
I0524 03:16:44.049028 11654 solver.cpp:239] Iteration 26420 (1.49419 iter/s, 6.69259s/10 iters), loss = 6.40037
I0524 03:16:44.049068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40037 (* 1 = 6.40037 loss)
I0524 03:16:44.049310 11654 sgd_solver.cpp:112] Iteration 26420, lr = 0.1
I0524 03:16:52.690078 11654 solver.cpp:239] Iteration 26430 (1.15732 iter/s, 8.64067s/10 iters), loss = 5.97205
I0524 03:16:52.690136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97205 (* 1 = 5.97205 loss)
I0524 03:16:52.690155 11654 sgd_solver.cpp:112] Iteration 26430, lr = 0.1
I0524 03:16:59.202008 11654 solver.cpp:239] Iteration 26440 (1.53573 iter/s, 6.51155s/10 iters), loss = 6.746
I0524 03:16:59.202067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.746 (* 1 = 6.746 loss)
I0524 03:16:59.202205 11654 sgd_solver.cpp:112] Iteration 26440, lr = 0.1
I0524 03:17:06.376848 11654 solver.cpp:239] Iteration 26450 (1.39382 iter/s, 7.17451s/10 iters), loss = 6.1368
I0524 03:17:06.376986 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1368 (* 1 = 6.1368 loss)
I0524 03:17:06.377156 11654 sgd_solver.cpp:112] Iteration 26450, lr = 0.1
I0524 03:17:12.891942 11654 solver.cpp:239] Iteration 26460 (1.53499 iter/s, 6.5147s/10 iters), loss = 6.27435
I0524 03:17:12.891993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27435 (* 1 = 6.27435 loss)
I0524 03:17:13.543455 11654 sgd_solver.cpp:112] Iteration 26460, lr = 0.1
I0524 03:17:19.697298 11654 solver.cpp:239] Iteration 26470 (1.4695 iter/s, 6.80505s/10 iters), loss = 6.67367
I0524 03:17:19.697340 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67367 (* 1 = 6.67367 loss)
I0524 03:17:19.697860 11654 sgd_solver.cpp:112] Iteration 26470, lr = 0.1
I0524 03:17:26.662967 11654 solver.cpp:239] Iteration 26480 (1.43568 iter/s, 6.96535s/10 iters), loss = 7.09055
I0524 03:17:26.663017 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09055 (* 1 = 7.09055 loss)
I0524 03:17:26.663066 11654 sgd_solver.cpp:112] Iteration 26480, lr = 0.1
I0524 03:17:34.015321 11654 solver.cpp:239] Iteration 26490 (1.36017 iter/s, 7.35203s/10 iters), loss = 6.60402
I0524 03:17:34.015379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60402 (* 1 = 6.60402 loss)
I0524 03:17:34.015527 11654 sgd_solver.cpp:112] Iteration 26490, lr = 0.1
I0524 03:17:40.601536 11654 solver.cpp:239] Iteration 26500 (1.51839 iter/s, 6.5859s/10 iters), loss = 6.40238
I0524 03:17:40.601773 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40238 (* 1 = 6.40238 loss)
I0524 03:17:40.601878 11654 sgd_solver.cpp:112] Iteration 26500, lr = 0.1
I0524 03:17:46.741122 11654 solver.cpp:239] Iteration 26510 (1.62889 iter/s, 6.13917s/10 iters), loss = 6.04223
I0524 03:17:46.741173 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04223 (* 1 = 6.04223 loss)
I0524 03:17:46.741483 11654 sgd_solver.cpp:112] Iteration 26510, lr = 0.1
I0524 03:17:53.137804 11654 solver.cpp:239] Iteration 26520 (1.56338 iter/s, 6.39639s/10 iters), loss = 5.74346
I0524 03:17:53.137848 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74346 (* 1 = 5.74346 loss)
I0524 03:17:53.139060 11654 sgd_solver.cpp:112] Iteration 26520, lr = 0.1
I0524 03:17:59.981979 11654 solver.cpp:239] Iteration 26530 (1.46116 iter/s, 6.84387s/10 iters), loss = 5.93024
I0524 03:17:59.982023 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93024 (* 1 = 5.93024 loss)
I0524 03:17:59.982406 11654 sgd_solver.cpp:112] Iteration 26530, lr = 0.1
I0524 03:18:06.915143 11654 solver.cpp:239] Iteration 26540 (1.44241 iter/s, 6.93285s/10 iters), loss = 7.43392
I0524 03:18:06.915201 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.43392 (* 1 = 7.43392 loss)
I0524 03:18:06.915364 11654 sgd_solver.cpp:112] Iteration 26540, lr = 0.1
I0524 03:18:14.794627 11654 solver.cpp:239] Iteration 26550 (1.26918 iter/s, 7.87913s/10 iters), loss = 6.32309
I0524 03:18:14.794942 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32309 (* 1 = 6.32309 loss)
I0524 03:18:14.795006 11654 sgd_solver.cpp:112] Iteration 26550, lr = 0.1
I0524 03:18:21.882102 11654 solver.cpp:239] Iteration 26560 (1.41105 iter/s, 7.08692s/10 iters), loss = 5.75429
I0524 03:18:21.882144 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75429 (* 1 = 5.75429 loss)
I0524 03:18:21.882344 11654 sgd_solver.cpp:112] Iteration 26560, lr = 0.1
I0524 03:18:29.121004 11654 solver.cpp:239] Iteration 26570 (1.38149 iter/s, 7.23858s/10 iters), loss = 7.07552
I0524 03:18:29.121060 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07552 (* 1 = 7.07552 loss)
I0524 03:18:29.121078 11654 sgd_solver.cpp:112] Iteration 26570, lr = 0.1
I0524 03:18:37.538789 11654 solver.cpp:239] Iteration 26580 (1.18802 iter/s, 8.41735s/10 iters), loss = 7.2943
I0524 03:18:37.538830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2943 (* 1 = 7.2943 loss)
I0524 03:18:37.539746 11654 sgd_solver.cpp:112] Iteration 26580, lr = 0.1
I0524 03:18:45.187212 11654 solver.cpp:239] Iteration 26590 (1.30752 iter/s, 7.64809s/10 iters), loss = 6.07925
I0524 03:18:45.187484 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07925 (* 1 = 6.07925 loss)
I0524 03:18:45.187544 11654 sgd_solver.cpp:112] Iteration 26590, lr = 0.1
I0524 03:18:51.832701 11654 solver.cpp:239] Iteration 26600 (1.50489 iter/s, 6.64498s/10 iters), loss = 5.8917
I0524 03:18:51.832741 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8917 (* 1 = 5.8917 loss)
I0524 03:18:52.048960 11654 sgd_solver.cpp:112] Iteration 26600, lr = 0.1
I0524 03:19:00.289232 11654 solver.cpp:239] Iteration 26610 (1.18257 iter/s, 8.45616s/10 iters), loss = 6.13243
I0524 03:19:00.289288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13243 (* 1 = 6.13243 loss)
I0524 03:19:00.289304 11654 sgd_solver.cpp:112] Iteration 26610, lr = 0.1
I0524 03:19:07.921180 11654 solver.cpp:239] Iteration 26620 (1.31072 iter/s, 7.62937s/10 iters), loss = 7.36891
I0524 03:19:07.921238 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36891 (* 1 = 7.36891 loss)
I0524 03:19:07.921433 11654 sgd_solver.cpp:112] Iteration 26620, lr = 0.1
I0524 03:19:15.308284 11654 solver.cpp:239] Iteration 26630 (1.35377 iter/s, 7.38676s/10 iters), loss = 6.45627
I0524 03:19:15.308393 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45627 (* 1 = 6.45627 loss)
I0524 03:19:16.274893 11654 sgd_solver.cpp:112] Iteration 26630, lr = 0.1
I0524 03:19:25.000180 11654 solver.cpp:239] Iteration 26640 (1.03184 iter/s, 9.69142s/10 iters), loss = 6.33564
I0524 03:19:25.000236 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33564 (* 1 = 6.33564 loss)
I0524 03:19:26.040931 11654 sgd_solver.cpp:112] Iteration 26640, lr = 0.1
I0524 03:19:33.229874 11654 solver.cpp:239] Iteration 26650 (1.21517 iter/s, 8.22932s/10 iters), loss = 5.83543
I0524 03:19:33.229930 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83543 (* 1 = 5.83543 loss)
I0524 03:19:33.230607 11654 sgd_solver.cpp:112] Iteration 26650, lr = 0.1
I0524 03:19:39.855657 11654 solver.cpp:239] Iteration 26660 (1.50933 iter/s, 6.62545s/10 iters), loss = 7.09709
I0524 03:19:39.855720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09709 (* 1 = 7.09709 loss)
I0524 03:19:39.856094 11654 sgd_solver.cpp:112] Iteration 26660, lr = 0.1
I0524 03:19:46.780376 11654 solver.cpp:239] Iteration 26670 (1.44417 iter/s, 6.92438s/10 iters), loss = 6.23224
I0524 03:19:46.780586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23224 (* 1 = 6.23224 loss)
I0524 03:19:46.780659 11654 sgd_solver.cpp:112] Iteration 26670, lr = 0.1
I0524 03:19:55.086783 11654 solver.cpp:239] Iteration 26680 (1.20397 iter/s, 8.30588s/10 iters), loss = 6.22658
I0524 03:19:55.086848 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22658 (* 1 = 6.22658 loss)
I0524 03:19:55.618759 11654 sgd_solver.cpp:112] Iteration 26680, lr = 0.1
I0524 03:20:01.861874 11654 solver.cpp:239] Iteration 26690 (1.47606 iter/s, 6.77477s/10 iters), loss = 7.02808
I0524 03:20:01.861917 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02808 (* 1 = 7.02808 loss)
I0524 03:20:01.862061 11654 sgd_solver.cpp:112] Iteration 26690, lr = 0.1
I0524 03:20:08.908737 11654 solver.cpp:239] Iteration 26700 (1.41914 iter/s, 7.04654s/10 iters), loss = 5.8202
I0524 03:20:08.908790 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8202 (* 1 = 5.8202 loss)
I0524 03:20:08.967073 11654 sgd_solver.cpp:112] Iteration 26700, lr = 0.1
I0524 03:20:17.465644 11654 solver.cpp:239] Iteration 26710 (1.1687 iter/s, 8.55653s/10 iters), loss = 5.93661
I0524 03:20:17.465905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93661 (* 1 = 5.93661 loss)
I0524 03:20:17.465960 11654 sgd_solver.cpp:112] Iteration 26710, lr = 0.1
I0524 03:20:24.346683 11654 solver.cpp:239] Iteration 26720 (1.45337 iter/s, 6.88055s/10 iters), loss = 6.23802
I0524 03:20:24.346730 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23802 (* 1 = 6.23802 loss)
I0524 03:20:24.346868 11654 sgd_solver.cpp:112] Iteration 26720, lr = 0.1
I0524 03:20:32.722998 11654 solver.cpp:239] Iteration 26730 (1.1939 iter/s, 8.37594s/10 iters), loss = 6.91889
I0524 03:20:32.723070 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91889 (* 1 = 6.91889 loss)
I0524 03:20:33.657593 11654 sgd_solver.cpp:112] Iteration 26730, lr = 0.1
I0524 03:20:41.261828 11654 solver.cpp:239] Iteration 26740 (1.17117 iter/s, 8.53845s/10 iters), loss = 6.52682
I0524 03:20:41.261878 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52682 (* 1 = 6.52682 loss)
I0524 03:20:41.261900 11654 sgd_solver.cpp:112] Iteration 26740, lr = 0.1
I0524 03:20:47.637552 11654 solver.cpp:239] Iteration 26750 (1.56852 iter/s, 6.37543s/10 iters), loss = 6.23382
I0524 03:20:47.637650 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23382 (* 1 = 6.23382 loss)
I0524 03:20:47.637761 11654 sgd_solver.cpp:112] Iteration 26750, lr = 0.1
I0524 03:20:53.850921 11654 solver.cpp:239] Iteration 26760 (1.60952 iter/s, 6.21303s/10 iters), loss = 7.0844
I0524 03:20:53.850973 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0844 (* 1 = 7.0844 loss)
I0524 03:20:53.851042 11654 sgd_solver.cpp:112] Iteration 26760, lr = 0.1
I0524 03:21:00.545888 11654 solver.cpp:239] Iteration 26770 (1.49373 iter/s, 6.69465s/10 iters), loss = 6.03549
I0524 03:21:00.545953 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03549 (* 1 = 6.03549 loss)
I0524 03:21:00.546296 11654 sgd_solver.cpp:112] Iteration 26770, lr = 0.1
I0524 03:21:09.412711 11654 solver.cpp:239] Iteration 26780 (1.12785 iter/s, 8.86642s/10 iters), loss = 6.78538
I0524 03:21:09.412753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78538 (* 1 = 6.78538 loss)
I0524 03:21:09.425705 11654 sgd_solver.cpp:112] Iteration 26780, lr = 0.1
I0524 03:21:15.576472 11654 solver.cpp:239] Iteration 26790 (1.62246 iter/s, 6.16347s/10 iters), loss = 6.23038
I0524 03:21:15.576534 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23038 (* 1 = 6.23038 loss)
I0524 03:21:15.577056 11654 sgd_solver.cpp:112] Iteration 26790, lr = 0.1
I0524 03:21:23.041575 11654 solver.cpp:239] Iteration 26800 (1.33963 iter/s, 7.46476s/10 iters), loss = 5.88212
I0524 03:21:23.041894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88212 (* 1 = 5.88212 loss)
I0524 03:21:23.041965 11654 sgd_solver.cpp:112] Iteration 26800, lr = 0.1
I0524 03:21:29.526191 11654 solver.cpp:239] Iteration 26810 (1.54224 iter/s, 6.48407s/10 iters), loss = 5.86807
I0524 03:21:29.526245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86807 (* 1 = 5.86807 loss)
I0524 03:21:29.526262 11654 sgd_solver.cpp:112] Iteration 26810, lr = 0.1
I0524 03:21:36.479342 11654 solver.cpp:239] Iteration 26820 (1.43826 iter/s, 6.95284s/10 iters), loss = 7.61719
I0524 03:21:36.479384 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61719 (* 1 = 7.61719 loss)
I0524 03:21:36.479559 11654 sgd_solver.cpp:112] Iteration 26820, lr = 0.1
I0524 03:21:45.336340 11654 solver.cpp:239] Iteration 26830 (1.1291 iter/s, 8.85661s/10 iters), loss = 5.85105
I0524 03:21:45.336390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85105 (* 1 = 5.85105 loss)
I0524 03:21:45.337466 11654 sgd_solver.cpp:112] Iteration 26830, lr = 0.1
I0524 03:21:51.832824 11654 solver.cpp:239] Iteration 26840 (1.53937 iter/s, 6.49617s/10 iters), loss = 7.07656
I0524 03:21:51.832885 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07656 (* 1 = 7.07656 loss)
I0524 03:21:51.833164 11654 sgd_solver.cpp:112] Iteration 26840, lr = 0.1
I0524 03:21:59.023217 11654 solver.cpp:239] Iteration 26850 (1.39081 iter/s, 7.19006s/10 iters), loss = 6.49845
I0524 03:21:59.023356 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49845 (* 1 = 6.49845 loss)
I0524 03:21:59.023375 11654 sgd_solver.cpp:112] Iteration 26850, lr = 0.1
I0524 03:22:07.024243 11654 solver.cpp:239] Iteration 26860 (1.24997 iter/s, 8.00022s/10 iters), loss = 6.1748
I0524 03:22:07.024292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1748 (* 1 = 6.1748 loss)
I0524 03:22:07.024310 11654 sgd_solver.cpp:112] Iteration 26860, lr = 0.1
I0524 03:22:13.647197 11654 solver.cpp:239] Iteration 26870 (1.50999 iter/s, 6.62258s/10 iters), loss = 6.56388
I0524 03:22:13.647258 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56388 (* 1 = 6.56388 loss)
I0524 03:22:13.647279 11654 sgd_solver.cpp:112] Iteration 26870, lr = 0.1
I0524 03:22:21.859030 11654 solver.cpp:239] Iteration 26880 (1.21781 iter/s, 8.21146s/10 iters), loss = 7.37161
I0524 03:22:21.859094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.37161 (* 1 = 7.37161 loss)
I0524 03:22:21.859213 11654 sgd_solver.cpp:112] Iteration 26880, lr = 0.1
I0524 03:22:30.483961 11654 solver.cpp:239] Iteration 26890 (1.15948 iter/s, 8.62454s/10 iters), loss = 6.82259
I0524 03:22:30.484103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82259 (* 1 = 6.82259 loss)
I0524 03:22:30.484122 11654 sgd_solver.cpp:112] Iteration 26890, lr = 0.1
I0524 03:22:37.074254 11654 solver.cpp:239] Iteration 26900 (1.51748 iter/s, 6.58988s/10 iters), loss = 7.10539
I0524 03:22:37.074304 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10539 (* 1 = 7.10539 loss)
I0524 03:22:37.074319 11654 sgd_solver.cpp:112] Iteration 26900, lr = 0.1
I0524 03:22:43.310775 11654 solver.cpp:239] Iteration 26910 (1.60353 iter/s, 6.23623s/10 iters), loss = 6.76359
I0524 03:22:43.310827 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76359 (* 1 = 6.76359 loss)
I0524 03:22:43.310845 11654 sgd_solver.cpp:112] Iteration 26910, lr = 0.1
I0524 03:22:50.132911 11654 solver.cpp:239] Iteration 26920 (1.46588 iter/s, 6.82183s/10 iters), loss = 5.99091
I0524 03:22:50.132949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99091 (* 1 = 5.99091 loss)
I0524 03:22:50.132961 11654 sgd_solver.cpp:112] Iteration 26920, lr = 0.1
I0524 03:22:56.572557 11654 solver.cpp:239] Iteration 26930 (1.55295 iter/s, 6.43935s/10 iters), loss = 6.77589
I0524 03:22:56.572610 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77589 (* 1 = 6.77589 loss)
I0524 03:22:56.572739 11654 sgd_solver.cpp:112] Iteration 26930, lr = 0.1
I0524 03:23:04.263348 11654 solver.cpp:239] Iteration 26940 (1.30031 iter/s, 7.69045s/10 iters), loss = 6.00966
I0524 03:23:04.263514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00966 (* 1 = 6.00966 loss)
I0524 03:23:04.263538 11654 sgd_solver.cpp:112] Iteration 26940, lr = 0.1
I0524 03:23:11.572531 11654 solver.cpp:239] Iteration 26950 (1.36862 iter/s, 7.30663s/10 iters), loss = 6.1938
I0524 03:23:11.572594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1938 (* 1 = 6.1938 loss)
I0524 03:23:11.572671 11654 sgd_solver.cpp:112] Iteration 26950, lr = 0.1
I0524 03:23:18.918260 11654 solver.cpp:239] Iteration 26960 (1.3614 iter/s, 7.34539s/10 iters), loss = 6.15394
I0524 03:23:18.918324 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15394 (* 1 = 6.15394 loss)
I0524 03:23:18.918480 11654 sgd_solver.cpp:112] Iteration 26960, lr = 0.1
I0524 03:23:25.594544 11654 solver.cpp:239] Iteration 26970 (1.49791 iter/s, 6.67598s/10 iters), loss = 7.29849
I0524 03:23:25.594585 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29849 (* 1 = 7.29849 loss)
I0524 03:23:25.595535 11654 sgd_solver.cpp:112] Iteration 26970, lr = 0.1
I0524 03:23:33.327813 11654 solver.cpp:239] Iteration 26980 (1.29317 iter/s, 7.73293s/10 iters), loss = 6.96813
I0524 03:23:33.327870 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96813 (* 1 = 6.96813 loss)
I0524 03:23:33.790163 11654 sgd_solver.cpp:112] Iteration 26980, lr = 0.1
I0524 03:23:42.128581 11654 solver.cpp:239] Iteration 26990 (1.13631 iter/s, 8.80038s/10 iters), loss = 5.51735
I0524 03:23:42.128847 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51735 (* 1 = 5.51735 loss)
I0524 03:23:42.804641 11654 sgd_solver.cpp:112] Iteration 26990, lr = 0.1
I0524 03:23:50.643436 11654 solver.cpp:239] Iteration 27000 (1.17449 iter/s, 8.51431s/10 iters), loss = 6.73895
I0524 03:23:50.643472 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73895 (* 1 = 6.73895 loss)
I0524 03:23:50.643486 11654 sgd_solver.cpp:112] Iteration 27000, lr = 0.1
I0524 03:23:57.208461 11654 solver.cpp:239] Iteration 27010 (1.5233 iter/s, 6.56472s/10 iters), loss = 7.64424
I0524 03:23:57.208518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.64424 (* 1 = 7.64424 loss)
I0524 03:23:57.208596 11654 sgd_solver.cpp:112] Iteration 27010, lr = 0.1
I0524 03:24:03.273356 11654 solver.cpp:239] Iteration 27020 (1.64891 iter/s, 6.0646s/10 iters), loss = 6.63829
I0524 03:24:03.273407 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63829 (* 1 = 6.63829 loss)
I0524 03:24:03.273449 11654 sgd_solver.cpp:112] Iteration 27020, lr = 0.1
I0524 03:24:11.090324 11654 solver.cpp:239] Iteration 27030 (1.27933 iter/s, 7.81662s/10 iters), loss = 6.90928
I0524 03:24:11.090371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90928 (* 1 = 6.90928 loss)
I0524 03:24:11.090391 11654 sgd_solver.cpp:112] Iteration 27030, lr = 0.1
I0524 03:24:18.247382 11654 solver.cpp:239] Iteration 27040 (1.39728 iter/s, 7.15674s/10 iters), loss = 7.41528
I0524 03:24:18.247475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.41528 (* 1 = 7.41528 loss)
I0524 03:24:18.247494 11654 sgd_solver.cpp:112] Iteration 27040, lr = 0.1
I0524 03:24:24.823873 11654 solver.cpp:239] Iteration 27050 (1.52066 iter/s, 6.5761s/10 iters), loss = 6.39159
I0524 03:24:24.823923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39159 (* 1 = 6.39159 loss)
I0524 03:24:24.824090 11654 sgd_solver.cpp:112] Iteration 27050, lr = 0.1
I0524 03:24:31.060360 11654 solver.cpp:239] Iteration 27060 (1.60354 iter/s, 6.23619s/10 iters), loss = 6.82368
I0524 03:24:31.060415 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82368 (* 1 = 6.82368 loss)
I0524 03:24:31.060670 11654 sgd_solver.cpp:112] Iteration 27060, lr = 0.1
I0524 03:24:38.332195 11654 solver.cpp:239] Iteration 27070 (1.37523 iter/s, 7.27151s/10 iters), loss = 6.03005
I0524 03:24:38.332254 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03005 (* 1 = 6.03005 loss)
I0524 03:24:38.332391 11654 sgd_solver.cpp:112] Iteration 27070, lr = 0.1
I0524 03:24:45.086930 11654 solver.cpp:239] Iteration 27080 (1.48051 iter/s, 6.75443s/10 iters), loss = 6.19347
I0524 03:24:45.086966 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19347 (* 1 = 6.19347 loss)
I0524 03:24:45.124750 11654 sgd_solver.cpp:112] Iteration 27080, lr = 0.1
I0524 03:24:52.077543 11654 solver.cpp:239] Iteration 27090 (1.43056 iter/s, 6.99029s/10 iters), loss = 6.52012
I0524 03:24:52.077711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52012 (* 1 = 6.52012 loss)
I0524 03:24:52.078742 11654 sgd_solver.cpp:112] Iteration 27090, lr = 0.1
I0524 03:24:58.614953 11654 solver.cpp:239] Iteration 27100 (1.52976 iter/s, 6.53698s/10 iters), loss = 5.99504
I0524 03:24:58.615015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99504 (* 1 = 5.99504 loss)
I0524 03:24:58.615499 11654 sgd_solver.cpp:112] Iteration 27100, lr = 0.1
I0524 03:25:04.832643 11654 solver.cpp:239] Iteration 27110 (1.60839 iter/s, 6.2174s/10 iters), loss = 6.96593
I0524 03:25:04.832684 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96593 (* 1 = 6.96593 loss)
I0524 03:25:04.832936 11654 sgd_solver.cpp:112] Iteration 27110, lr = 0.1
I0524 03:25:11.532208 11654 solver.cpp:239] Iteration 27120 (1.4927 iter/s, 6.69926s/10 iters), loss = 5.90797
I0524 03:25:11.532263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90797 (* 1 = 5.90797 loss)
I0524 03:25:11.532825 11654 sgd_solver.cpp:112] Iteration 27120, lr = 0.1
I0524 03:25:18.279943 11654 solver.cpp:239] Iteration 27130 (1.48205 iter/s, 6.74742s/10 iters), loss = 6.9036
I0524 03:25:18.279989 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9036 (* 1 = 6.9036 loss)
I0524 03:25:18.280002 11654 sgd_solver.cpp:112] Iteration 27130, lr = 0.1
I0524 03:25:25.299326 11654 solver.cpp:239] Iteration 27140 (1.42472 iter/s, 7.01894s/10 iters), loss = 6.36341
I0524 03:25:25.299576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36341 (* 1 = 6.36341 loss)
I0524 03:25:25.299625 11654 sgd_solver.cpp:112] Iteration 27140, lr = 0.1
I0524 03:25:33.545683 11654 solver.cpp:239] Iteration 27150 (1.21303 iter/s, 8.24382s/10 iters), loss = 5.68473
I0524 03:25:33.545739 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68473 (* 1 = 5.68473 loss)
I0524 03:25:34.228261 11654 sgd_solver.cpp:112] Iteration 27150, lr = 0.1
I0524 03:25:41.769306 11654 solver.cpp:239] Iteration 27160 (1.21606 iter/s, 8.22325s/10 iters), loss = 7.30923
I0524 03:25:41.769367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30923 (* 1 = 7.30923 loss)
I0524 03:25:41.777755 11654 sgd_solver.cpp:112] Iteration 27160, lr = 0.1
I0524 03:25:49.424448 11654 solver.cpp:239] Iteration 27170 (1.30637 iter/s, 7.6548s/10 iters), loss = 7.06071
I0524 03:25:49.424496 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06071 (* 1 = 7.06071 loss)
I0524 03:25:49.424512 11654 sgd_solver.cpp:112] Iteration 27170, lr = 0.1
I0524 03:25:57.383478 11654 solver.cpp:239] Iteration 27180 (1.25684 iter/s, 7.95644s/10 iters), loss = 5.91848
I0524 03:25:57.383733 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91848 (* 1 = 5.91848 loss)
I0524 03:25:57.383792 11654 sgd_solver.cpp:112] Iteration 27180, lr = 0.1
I0524 03:26:04.265874 11654 solver.cpp:239] Iteration 27190 (1.45309 iter/s, 6.8819s/10 iters), loss = 6.09015
I0524 03:26:04.265926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09015 (* 1 = 6.09015 loss)
I0524 03:26:04.265945 11654 sgd_solver.cpp:112] Iteration 27190, lr = 0.1
I0524 03:26:12.834545 11654 solver.cpp:239] Iteration 27200 (1.1671 iter/s, 8.56822s/10 iters), loss = 6.2958
I0524 03:26:12.834594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2958 (* 1 = 6.2958 loss)
I0524 03:26:12.834667 11654 sgd_solver.cpp:112] Iteration 27200, lr = 0.1
I0524 03:26:19.655244 11654 solver.cpp:239] Iteration 27210 (1.46619 iter/s, 6.82038s/10 iters), loss = 5.59926
I0524 03:26:19.655306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59926 (* 1 = 5.59926 loss)
I0524 03:26:19.655436 11654 sgd_solver.cpp:112] Iteration 27210, lr = 0.1
I0524 03:26:28.363812 11654 solver.cpp:239] Iteration 27220 (1.14835 iter/s, 8.70818s/10 iters), loss = 7.62607
I0524 03:26:28.364095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62607 (* 1 = 7.62607 loss)
I0524 03:26:29.046172 11654 sgd_solver.cpp:112] Iteration 27220, lr = 0.1
I0524 03:26:35.135334 11654 solver.cpp:239] Iteration 27230 (1.47688 iter/s, 6.77103s/10 iters), loss = 6.90577
I0524 03:26:35.135373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90577 (* 1 = 6.90577 loss)
I0524 03:26:35.135498 11654 sgd_solver.cpp:112] Iteration 27230, lr = 0.1
I0524 03:26:41.411341 11654 solver.cpp:239] Iteration 27240 (1.59344 iter/s, 6.27572s/10 iters), loss = 7.4921
I0524 03:26:41.411393 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4921 (* 1 = 7.4921 loss)
I0524 03:26:41.411409 11654 sgd_solver.cpp:112] Iteration 27240, lr = 0.1
I0524 03:26:49.614177 11654 solver.cpp:239] Iteration 27250 (1.21914 iter/s, 8.20247s/10 iters), loss = 5.61678
I0524 03:26:49.614217 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61678 (* 1 = 5.61678 loss)
I0524 03:26:49.614492 11654 sgd_solver.cpp:112] Iteration 27250, lr = 0.1
I0524 03:26:55.872238 11654 solver.cpp:239] Iteration 27260 (1.59801 iter/s, 6.25777s/10 iters), loss = 6.69752
I0524 03:26:55.872292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69752 (* 1 = 6.69752 loss)
I0524 03:26:55.872397 11654 sgd_solver.cpp:112] Iteration 27260, lr = 0.1
I0524 03:27:03.523473 11654 solver.cpp:239] Iteration 27270 (1.30704 iter/s, 7.65089s/10 iters), loss = 6.52873
I0524 03:27:03.523761 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52873 (* 1 = 6.52873 loss)
I0524 03:27:03.929859 11654 sgd_solver.cpp:112] Iteration 27270, lr = 0.1
I0524 03:27:11.824964 11654 solver.cpp:239] Iteration 27280 (1.20469 iter/s, 8.30092s/10 iters), loss = 7.05327
I0524 03:27:11.825016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05327 (* 1 = 7.05327 loss)
I0524 03:27:11.842818 11654 sgd_solver.cpp:112] Iteration 27280, lr = 0.1
I0524 03:27:20.668633 11654 solver.cpp:239] Iteration 27290 (1.1308 iter/s, 8.84328s/10 iters), loss = 6.0772
I0524 03:27:20.668691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0772 (* 1 = 6.0772 loss)
I0524 03:27:20.763895 11654 sgd_solver.cpp:112] Iteration 27290, lr = 0.1
I0524 03:27:30.272382 11654 solver.cpp:239] Iteration 27300 (1.04131 iter/s, 9.60332s/10 iters), loss = 6.70521
I0524 03:27:30.272439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70521 (* 1 = 6.70521 loss)
I0524 03:27:30.272456 11654 sgd_solver.cpp:112] Iteration 27300, lr = 0.1
I0524 03:27:36.543725 11654 solver.cpp:239] Iteration 27310 (1.59465 iter/s, 6.27096s/10 iters), loss = 6.78708
I0524 03:27:36.543901 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78708 (* 1 = 6.78708 loss)
I0524 03:27:36.544001 11654 sgd_solver.cpp:112] Iteration 27310, lr = 0.1
I0524 03:27:43.129812 11654 solver.cpp:239] Iteration 27320 (1.51845 iter/s, 6.58567s/10 iters), loss = 6.02788
I0524 03:27:43.129847 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02788 (* 1 = 6.02788 loss)
I0524 03:27:43.129863 11654 sgd_solver.cpp:112] Iteration 27320, lr = 0.1
I0524 03:27:51.399515 11654 solver.cpp:239] Iteration 27330 (1.2093 iter/s, 8.26928s/10 iters), loss = 6.62755
I0524 03:27:51.399579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62755 (* 1 = 6.62755 loss)
I0524 03:27:51.399827 11654 sgd_solver.cpp:112] Iteration 27330, lr = 0.1
I0524 03:27:58.391810 11654 solver.cpp:239] Iteration 27340 (1.43021 iter/s, 6.99197s/10 iters), loss = 7.28405
I0524 03:27:58.391858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28405 (* 1 = 7.28405 loss)
I0524 03:27:58.391886 11654 sgd_solver.cpp:112] Iteration 27340, lr = 0.1
I0524 03:28:06.258000 11654 solver.cpp:239] Iteration 27350 (1.27132 iter/s, 7.86584s/10 iters), loss = 6.72935
I0524 03:28:06.258062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72935 (* 1 = 6.72935 loss)
I0524 03:28:06.316242 11654 sgd_solver.cpp:112] Iteration 27350, lr = 0.1
I0524 03:28:13.576759 11654 solver.cpp:239] Iteration 27360 (1.36642 iter/s, 7.31842s/10 iters), loss = 6.88174
I0524 03:28:13.577039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88174 (* 1 = 6.88174 loss)
I0524 03:28:14.141646 11654 sgd_solver.cpp:112] Iteration 27360, lr = 0.1
I0524 03:28:21.869076 11654 solver.cpp:239] Iteration 27370 (1.20602 iter/s, 8.29176s/10 iters), loss = 7.32837
I0524 03:28:21.869130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32837 (* 1 = 7.32837 loss)
I0524 03:28:21.892287 11654 sgd_solver.cpp:112] Iteration 27370, lr = 0.1
I0524 03:28:28.007387 11654 solver.cpp:239] Iteration 27380 (1.62919 iter/s, 6.13802s/10 iters), loss = 6.50184
I0524 03:28:28.007441 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50184 (* 1 = 6.50184 loss)
I0524 03:28:28.007557 11654 sgd_solver.cpp:112] Iteration 27380, lr = 0.1
I0524 03:28:37.728279 11654 solver.cpp:239] Iteration 27390 (1.02876 iter/s, 9.72047s/10 iters), loss = 5.808
I0524 03:28:37.728328 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.808 (* 1 = 5.808 loss)
I0524 03:28:38.163280 11654 sgd_solver.cpp:112] Iteration 27390, lr = 0.1
I0524 03:28:44.307317 11654 solver.cpp:239] Iteration 27400 (1.52005 iter/s, 6.57872s/10 iters), loss = 6.47889
I0524 03:28:44.307615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47889 (* 1 = 6.47889 loss)
I0524 03:28:44.307687 11654 sgd_solver.cpp:112] Iteration 27400, lr = 0.1
I0524 03:28:51.935956 11654 solver.cpp:239] Iteration 27410 (1.31094 iter/s, 7.62813s/10 iters), loss = 7.39553
I0524 03:28:51.935997 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39553 (* 1 = 7.39553 loss)
I0524 03:28:51.936009 11654 sgd_solver.cpp:112] Iteration 27410, lr = 0.1
I0524 03:29:01.036855 11654 solver.cpp:239] Iteration 27420 (1.09884 iter/s, 9.1005s/10 iters), loss = 5.40088
I0524 03:29:01.036917 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40088 (* 1 = 5.40088 loss)
I0524 03:29:01.037036 11654 sgd_solver.cpp:112] Iteration 27420, lr = 0.1
I0524 03:29:07.239389 11654 solver.cpp:239] Iteration 27430 (1.61232 iter/s, 6.20224s/10 iters), loss = 6.80202
I0524 03:29:07.239442 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80202 (* 1 = 6.80202 loss)
I0524 03:29:07.239457 11654 sgd_solver.cpp:112] Iteration 27430, lr = 0.1
I0524 03:29:14.063071 11654 solver.cpp:239] Iteration 27440 (1.46555 iter/s, 6.82337s/10 iters), loss = 7.27394
I0524 03:29:14.063127 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27394 (* 1 = 7.27394 loss)
I0524 03:29:14.063243 11654 sgd_solver.cpp:112] Iteration 27440, lr = 0.1
I0524 03:29:22.263746 11654 solver.cpp:239] Iteration 27450 (1.21947 iter/s, 8.20031s/10 iters), loss = 6.25314
I0524 03:29:22.264010 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25314 (* 1 = 6.25314 loss)
I0524 03:29:22.264067 11654 sgd_solver.cpp:112] Iteration 27450, lr = 0.1
I0524 03:29:28.654780 11654 solver.cpp:239] Iteration 27460 (1.56481 iter/s, 6.39057s/10 iters), loss = 6.27378
I0524 03:29:28.654839 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27378 (* 1 = 6.27378 loss)
I0524 03:29:28.656004 11654 sgd_solver.cpp:112] Iteration 27460, lr = 0.1
I0524 03:29:36.679167 11654 solver.cpp:239] Iteration 27470 (1.24626 iter/s, 8.02402s/10 iters), loss = 6.36556
I0524 03:29:36.679221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36556 (* 1 = 6.36556 loss)
I0524 03:29:36.679239 11654 sgd_solver.cpp:112] Iteration 27470, lr = 0.1
I0524 03:29:42.948248 11654 solver.cpp:239] Iteration 27480 (1.59522 iter/s, 6.26872s/10 iters), loss = 6.43898
I0524 03:29:42.948287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43898 (* 1 = 6.43898 loss)
I0524 03:29:44.197559 11654 sgd_solver.cpp:112] Iteration 27480, lr = 0.1
I0524 03:29:50.283015 11654 solver.cpp:239] Iteration 27490 (1.36343 iter/s, 7.33443s/10 iters), loss = 6.01956
I0524 03:29:50.283071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01956 (* 1 = 6.01956 loss)
I0524 03:29:50.283453 11654 sgd_solver.cpp:112] Iteration 27490, lr = 0.1
I0524 03:29:58.453480 11654 solver.cpp:239] Iteration 27500 (1.22398 iter/s, 8.1701s/10 iters), loss = 6.22534
I0524 03:29:58.453656 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22534 (* 1 = 6.22534 loss)
I0524 03:29:58.453678 11654 sgd_solver.cpp:112] Iteration 27500, lr = 0.1
I0524 03:30:06.529958 11654 solver.cpp:239] Iteration 27510 (1.23824 iter/s, 8.07596s/10 iters), loss = 5.65407
I0524 03:30:06.530010 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65407 (* 1 = 5.65407 loss)
I0524 03:30:07.193536 11654 sgd_solver.cpp:112] Iteration 27510, lr = 0.1
I0524 03:30:14.078328 11654 solver.cpp:239] Iteration 27520 (1.32485 iter/s, 7.54803s/10 iters), loss = 6.72926
I0524 03:30:14.078388 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72926 (* 1 = 6.72926 loss)
I0524 03:30:14.078407 11654 sgd_solver.cpp:112] Iteration 27520, lr = 0.1
I0524 03:30:21.143476 11654 solver.cpp:239] Iteration 27530 (1.41591 iter/s, 7.06261s/10 iters), loss = 6.86642
I0524 03:30:21.143517 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86642 (* 1 = 6.86642 loss)
I0524 03:30:21.143543 11654 sgd_solver.cpp:112] Iteration 27530, lr = 0.1
I0524 03:30:28.231540 11654 solver.cpp:239] Iteration 27540 (1.41089 iter/s, 7.08775s/10 iters), loss = 6.46686
I0524 03:30:28.231591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46686 (* 1 = 6.46686 loss)
I0524 03:30:28.231606 11654 sgd_solver.cpp:112] Iteration 27540, lr = 0.1
I0524 03:30:35.373430 11654 solver.cpp:239] Iteration 27550 (1.40025 iter/s, 7.14156s/10 iters), loss = 6.91582
I0524 03:30:35.373562 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91582 (* 1 = 6.91582 loss)
I0524 03:30:35.373708 11654 sgd_solver.cpp:112] Iteration 27550, lr = 0.1
I0524 03:30:41.766170 11654 solver.cpp:239] Iteration 27560 (1.56437 iter/s, 6.39236s/10 iters), loss = 6.12855
I0524 03:30:41.766240 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12855 (* 1 = 6.12855 loss)
I0524 03:30:41.792726 11654 sgd_solver.cpp:112] Iteration 27560, lr = 0.1
I0524 03:30:48.616364 11654 solver.cpp:239] Iteration 27570 (1.45988 iter/s, 6.84987s/10 iters), loss = 7.42419
I0524 03:30:48.616415 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.42419 (* 1 = 7.42419 loss)
I0524 03:30:48.616433 11654 sgd_solver.cpp:112] Iteration 27570, lr = 0.1
I0524 03:30:54.838407 11654 solver.cpp:239] Iteration 27580 (1.60728 iter/s, 6.22169s/10 iters), loss = 6.02531
I0524 03:30:54.838464 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02531 (* 1 = 6.02531 loss)
I0524 03:30:54.838562 11654 sgd_solver.cpp:112] Iteration 27580, lr = 0.1
I0524 03:31:00.986358 11654 solver.cpp:239] Iteration 27590 (1.62663 iter/s, 6.14766s/10 iters), loss = 6.06767
I0524 03:31:00.986413 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06767 (* 1 = 6.06767 loss)
I0524 03:31:00.986429 11654 sgd_solver.cpp:112] Iteration 27590, lr = 0.1
I0524 03:31:06.961959 11654 solver.cpp:239] Iteration 27600 (1.67363 iter/s, 5.97505s/10 iters), loss = 5.61906
I0524 03:31:06.962122 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61906 (* 1 = 5.61906 loss)
I0524 03:31:07.002066 11654 sgd_solver.cpp:112] Iteration 27600, lr = 0.1
I0524 03:31:13.002650 11654 solver.cpp:239] Iteration 27610 (1.65555 iter/s, 6.04029s/10 iters), loss = 7.45786
I0524 03:31:13.002709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.45786 (* 1 = 7.45786 loss)
I0524 03:31:13.002840 11654 sgd_solver.cpp:112] Iteration 27610, lr = 0.1
I0524 03:31:21.184577 11654 solver.cpp:239] Iteration 27620 (1.22226 iter/s, 8.18157s/10 iters), loss = 6.00555
I0524 03:31:21.184617 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00555 (* 1 = 6.00555 loss)
I0524 03:31:21.185716 11654 sgd_solver.cpp:112] Iteration 27620, lr = 0.1
I0524 03:31:27.837523 11654 solver.cpp:239] Iteration 27630 (1.50316 iter/s, 6.65263s/10 iters), loss = 6.30294
I0524 03:31:27.837589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30294 (* 1 = 6.30294 loss)
I0524 03:31:27.837755 11654 sgd_solver.cpp:112] Iteration 27630, lr = 0.1
I0524 03:31:35.191483 11654 solver.cpp:239] Iteration 27640 (1.35987 iter/s, 7.35362s/10 iters), loss = 6.05758
I0524 03:31:35.191524 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05758 (* 1 = 6.05758 loss)
I0524 03:31:35.191539 11654 sgd_solver.cpp:112] Iteration 27640, lr = 0.1
I0524 03:31:41.246347 11654 solver.cpp:239] Iteration 27650 (1.65166 iter/s, 6.0545s/10 iters), loss = 6.74079
I0524 03:31:41.246672 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74079 (* 1 = 6.74079 loss)
I0524 03:31:41.246762 11654 sgd_solver.cpp:112] Iteration 27650, lr = 0.1
I0524 03:31:48.182164 11654 solver.cpp:239] Iteration 27660 (1.44191 iter/s, 6.93527s/10 iters), loss = 7.31148
I0524 03:31:48.182240 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.31148 (* 1 = 7.31148 loss)
I0524 03:31:48.182623 11654 sgd_solver.cpp:112] Iteration 27660, lr = 0.1
I0524 03:31:54.929772 11654 solver.cpp:239] Iteration 27670 (1.48208 iter/s, 6.74728s/10 iters), loss = 5.63181
I0524 03:31:54.929821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63181 (* 1 = 5.63181 loss)
I0524 03:31:55.632633 11654 sgd_solver.cpp:112] Iteration 27670, lr = 0.1
I0524 03:32:03.760143 11654 solver.cpp:239] Iteration 27680 (1.1325 iter/s, 8.82999s/10 iters), loss = 6.42308
I0524 03:32:03.760190 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42308 (* 1 = 6.42308 loss)
I0524 03:32:03.760205 11654 sgd_solver.cpp:112] Iteration 27680, lr = 0.1
I0524 03:32:10.209843 11654 solver.cpp:239] Iteration 27690 (1.55055 iter/s, 6.44933s/10 iters), loss = 5.64232
I0524 03:32:10.209902 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64232 (* 1 = 5.64232 loss)
I0524 03:32:10.210440 11654 sgd_solver.cpp:112] Iteration 27690, lr = 0.1
I0524 03:32:16.816099 11654 solver.cpp:239] Iteration 27700 (1.51379 iter/s, 6.60594s/10 iters), loss = 6.8816
I0524 03:32:16.816370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8816 (* 1 = 6.8816 loss)
I0524 03:32:16.816431 11654 sgd_solver.cpp:112] Iteration 27700, lr = 0.1
I0524 03:32:23.046087 11654 solver.cpp:239] Iteration 27710 (1.60528 iter/s, 6.22943s/10 iters), loss = 6.88421
I0524 03:32:23.046134 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88421 (* 1 = 6.88421 loss)
I0524 03:32:23.046380 11654 sgd_solver.cpp:112] Iteration 27710, lr = 0.1
I0524 03:32:29.658430 11654 solver.cpp:239] Iteration 27720 (1.51239 iter/s, 6.61203s/10 iters), loss = 5.98167
I0524 03:32:29.658488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98167 (* 1 = 5.98167 loss)
I0524 03:32:29.658638 11654 sgd_solver.cpp:112] Iteration 27720, lr = 0.1
I0524 03:32:35.970142 11654 solver.cpp:239] Iteration 27730 (1.58443 iter/s, 6.31141s/10 iters), loss = 5.61992
I0524 03:32:35.970201 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61992 (* 1 = 5.61992 loss)
I0524 03:32:35.970484 11654 sgd_solver.cpp:112] Iteration 27730, lr = 0.1
I0524 03:32:42.325490 11654 solver.cpp:239] Iteration 27740 (1.57355 iter/s, 6.35505s/10 iters), loss = 6.9729
I0524 03:32:42.325543 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9729 (* 1 = 6.9729 loss)
I0524 03:32:42.325650 11654 sgd_solver.cpp:112] Iteration 27740, lr = 0.1
I0524 03:32:48.794101 11654 solver.cpp:239] Iteration 27750 (1.546 iter/s, 6.46831s/10 iters), loss = 6.70341
I0524 03:32:48.794366 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70341 (* 1 = 6.70341 loss)
I0524 03:32:48.794464 11654 sgd_solver.cpp:112] Iteration 27750, lr = 0.1
I0524 03:32:55.052192 11654 solver.cpp:239] Iteration 27760 (1.59805 iter/s, 6.25762s/10 iters), loss = 6.45382
I0524 03:32:55.052247 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45382 (* 1 = 6.45382 loss)
I0524 03:32:55.052759 11654 sgd_solver.cpp:112] Iteration 27760, lr = 0.1
I0524 03:33:03.329771 11654 solver.cpp:239] Iteration 27770 (1.20814 iter/s, 8.27721s/10 iters), loss = 7.11402
I0524 03:33:03.329823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11402 (* 1 = 7.11402 loss)
I0524 03:33:03.329838 11654 sgd_solver.cpp:112] Iteration 27770, lr = 0.1
I0524 03:33:09.534641 11654 solver.cpp:239] Iteration 27780 (1.61171 iter/s, 6.20458s/10 iters), loss = 6.26185
I0524 03:33:09.534759 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26185 (* 1 = 6.26185 loss)
I0524 03:33:09.534896 11654 sgd_solver.cpp:112] Iteration 27780, lr = 0.1
I0524 03:33:15.865658 11654 solver.cpp:239] Iteration 27790 (1.5796 iter/s, 6.33071s/10 iters), loss = 6.04045
I0524 03:33:15.865711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04045 (* 1 = 6.04045 loss)
I0524 03:33:15.866219 11654 sgd_solver.cpp:112] Iteration 27790, lr = 0.1
I0524 03:33:22.966204 11654 solver.cpp:239] Iteration 27800 (1.40841 iter/s, 7.10021s/10 iters), loss = 7.08156
I0524 03:33:22.966487 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08156 (* 1 = 7.08156 loss)
I0524 03:33:22.966562 11654 sgd_solver.cpp:112] Iteration 27800, lr = 0.1
I0524 03:33:31.283663 11654 solver.cpp:239] Iteration 27810 (1.20237 iter/s, 8.31691s/10 iters), loss = 7.19341
I0524 03:33:31.283720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19341 (* 1 = 7.19341 loss)
I0524 03:33:31.283862 11654 sgd_solver.cpp:112] Iteration 27810, lr = 0.1
I0524 03:33:37.572973 11654 solver.cpp:239] Iteration 27820 (1.59007 iter/s, 6.28902s/10 iters), loss = 6.57987
I0524 03:33:37.573015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57987 (* 1 = 6.57987 loss)
I0524 03:33:37.573109 11654 sgd_solver.cpp:112] Iteration 27820, lr = 0.1
I0524 03:33:44.511226 11654 solver.cpp:239] Iteration 27830 (1.44135 iter/s, 6.93794s/10 iters), loss = 6.47624
I0524 03:33:44.511277 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47624 (* 1 = 6.47624 loss)
I0524 03:33:44.518777 11654 sgd_solver.cpp:112] Iteration 27830, lr = 0.1
I0524 03:33:52.498548 11654 solver.cpp:239] Iteration 27840 (1.25204 iter/s, 7.98697s/10 iters), loss = 6.77957
I0524 03:33:52.498602 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77957 (* 1 = 6.77957 loss)
I0524 03:33:52.498618 11654 sgd_solver.cpp:112] Iteration 27840, lr = 0.1
I0524 03:34:00.021450 11654 solver.cpp:239] Iteration 27850 (1.32935 iter/s, 7.52249s/10 iters), loss = 5.92216
I0524 03:34:00.021693 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92216 (* 1 = 5.92216 loss)
I0524 03:34:00.021925 11654 sgd_solver.cpp:112] Iteration 27850, lr = 0.1
I0524 03:34:07.061971 11654 solver.cpp:239] Iteration 27860 (1.42045 iter/s, 7.04004s/10 iters), loss = 6.44408
I0524 03:34:07.062024 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44408 (* 1 = 6.44408 loss)
I0524 03:34:07.062038 11654 sgd_solver.cpp:112] Iteration 27860, lr = 0.1
I0524 03:34:14.025677 11654 solver.cpp:239] Iteration 27870 (1.43654 iter/s, 6.96116s/10 iters), loss = 6.91174
I0524 03:34:14.025729 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91174 (* 1 = 6.91174 loss)
I0524 03:34:14.026067 11654 sgd_solver.cpp:112] Iteration 27870, lr = 0.1
I0524 03:34:20.790472 11654 solver.cpp:239] Iteration 27880 (1.47831 iter/s, 6.76448s/10 iters), loss = 6.86809
I0524 03:34:20.790520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86809 (* 1 = 6.86809 loss)
I0524 03:34:20.790537 11654 sgd_solver.cpp:112] Iteration 27880, lr = 0.1
I0524 03:34:28.383893 11654 solver.cpp:239] Iteration 27890 (1.31699 iter/s, 7.59309s/10 iters), loss = 5.72598
I0524 03:34:28.383937 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72598 (* 1 = 5.72598 loss)
I0524 03:34:28.383951 11654 sgd_solver.cpp:112] Iteration 27890, lr = 0.1
I0524 03:34:34.359087 11654 solver.cpp:239] Iteration 27900 (1.67429 iter/s, 5.97268s/10 iters), loss = 6.23113
I0524 03:34:34.359405 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23113 (* 1 = 6.23113 loss)
I0524 03:34:34.359477 11654 sgd_solver.cpp:112] Iteration 27900, lr = 0.1
I0524 03:34:42.220980 11654 solver.cpp:239] Iteration 27910 (1.27215 iter/s, 7.8607s/10 iters), loss = 6.63578
I0524 03:34:42.221045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63578 (* 1 = 6.63578 loss)
I0524 03:34:42.221066 11654 sgd_solver.cpp:112] Iteration 27910, lr = 0.1
I0524 03:34:49.905532 11654 solver.cpp:239] Iteration 27920 (1.30175 iter/s, 7.68196s/10 iters), loss = 7.21696
I0524 03:34:49.905573 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21696 (* 1 = 7.21696 loss)
I0524 03:34:49.905586 11654 sgd_solver.cpp:112] Iteration 27920, lr = 0.1
I0524 03:34:58.396839 11654 solver.cpp:239] Iteration 27930 (1.17804 iter/s, 8.4887s/10 iters), loss = 5.73476
I0524 03:34:58.396914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73476 (* 1 = 5.73476 loss)
I0524 03:34:58.397182 11654 sgd_solver.cpp:112] Iteration 27930, lr = 0.1
I0524 03:35:04.547633 11654 solver.cpp:239] Iteration 27940 (1.62589 iter/s, 6.15048s/10 iters), loss = 5.50753
I0524 03:35:04.547896 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50753 (* 1 = 5.50753 loss)
I0524 03:35:04.547955 11654 sgd_solver.cpp:112] Iteration 27940, lr = 0.1
I0524 03:35:10.706967 11654 solver.cpp:239] Iteration 27950 (1.62367 iter/s, 6.15889s/10 iters), loss = 7.64872
I0524 03:35:10.707018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.64872 (* 1 = 7.64872 loss)
I0524 03:35:10.769592 11654 sgd_solver.cpp:112] Iteration 27950, lr = 0.1
I0524 03:35:19.406565 11654 solver.cpp:239] Iteration 27960 (1.14953 iter/s, 8.69922s/10 iters), loss = 6.78927
I0524 03:35:19.406612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78927 (* 1 = 6.78927 loss)
I0524 03:35:19.406630 11654 sgd_solver.cpp:112] Iteration 27960, lr = 0.1
I0524 03:35:27.441989 11654 solver.cpp:239] Iteration 27970 (1.24455 iter/s, 8.03501s/10 iters), loss = 6.0616
I0524 03:35:27.442042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0616 (* 1 = 6.0616 loss)
I0524 03:35:27.442116 11654 sgd_solver.cpp:112] Iteration 27970, lr = 0.1
I0524 03:35:35.186496 11654 solver.cpp:239] Iteration 27980 (1.2913 iter/s, 7.74415s/10 iters), loss = 5.96727
I0524 03:35:35.186638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96727 (* 1 = 5.96727 loss)
I0524 03:35:35.186659 11654 sgd_solver.cpp:112] Iteration 27980, lr = 0.1
I0524 03:35:41.892053 11654 solver.cpp:239] Iteration 27990 (1.49139 iter/s, 6.70516s/10 iters), loss = 4.98941
I0524 03:35:41.892108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.98941 (* 1 = 4.98941 loss)
I0524 03:35:41.892256 11654 sgd_solver.cpp:112] Iteration 27990, lr = 0.1
I0524 03:35:53.124002 11654 solver.cpp:239] Iteration 28000 (0.890355 iter/s, 11.2315s/10 iters), loss = 5.95329
I0524 03:35:53.124056 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95329 (* 1 = 5.95329 loss)
I0524 03:35:53.124073 11654 sgd_solver.cpp:112] Iteration 28000, lr = 0.1
I0524 03:35:59.481317 11654 solver.cpp:239] Iteration 28010 (1.57307 iter/s, 6.35701s/10 iters), loss = 6.51523
I0524 03:35:59.481374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51523 (* 1 = 6.51523 loss)
I0524 03:35:59.481600 11654 sgd_solver.cpp:112] Iteration 28010, lr = 0.1
I0524 03:36:05.827646 11654 solver.cpp:239] Iteration 28020 (1.57579 iter/s, 6.34603s/10 iters), loss = 6.34935
I0524 03:36:05.827939 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34935 (* 1 = 6.34935 loss)
I0524 03:36:05.828001 11654 sgd_solver.cpp:112] Iteration 28020, lr = 0.1
I0524 03:36:12.189658 11654 solver.cpp:239] Iteration 28030 (1.57201 iter/s, 6.36128s/10 iters), loss = 7.07147
I0524 03:36:12.189712 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07147 (* 1 = 7.07147 loss)
I0524 03:36:12.189877 11654 sgd_solver.cpp:112] Iteration 28030, lr = 0.1
I0524 03:36:18.339356 11654 solver.cpp:239] Iteration 28040 (1.62617 iter/s, 6.14941s/10 iters), loss = 6.83644
I0524 03:36:18.339395 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83644 (* 1 = 6.83644 loss)
I0524 03:36:18.414764 11654 sgd_solver.cpp:112] Iteration 28040, lr = 0.1
I0524 03:36:25.962064 11654 solver.cpp:239] Iteration 28050 (1.31193 iter/s, 7.62237s/10 iters), loss = 5.85726
I0524 03:36:25.962119 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85726 (* 1 = 5.85726 loss)
I0524 03:36:25.962136 11654 sgd_solver.cpp:112] Iteration 28050, lr = 0.1
I0524 03:36:32.589372 11654 solver.cpp:239] Iteration 28060 (1.50898 iter/s, 6.627s/10 iters), loss = 7.22133
I0524 03:36:32.589419 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22133 (* 1 = 7.22133 loss)
I0524 03:36:32.589437 11654 sgd_solver.cpp:112] Iteration 28060, lr = 0.1
I0524 03:36:40.675328 11654 solver.cpp:239] Iteration 28070 (1.23694 iter/s, 8.08449s/10 iters), loss = 6.45715
I0524 03:36:40.675617 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45715 (* 1 = 6.45715 loss)
I0524 03:36:41.985924 11654 sgd_solver.cpp:112] Iteration 28070, lr = 0.1
I0524 03:36:49.611564 11654 solver.cpp:239] Iteration 28080 (1.11912 iter/s, 8.93563s/10 iters), loss = 6.63019
I0524 03:36:49.611629 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63019 (* 1 = 6.63019 loss)
I0524 03:36:49.611830 11654 sgd_solver.cpp:112] Iteration 28080, lr = 0.1
I0524 03:36:56.217463 11654 solver.cpp:239] Iteration 28090 (1.51387 iter/s, 6.60558s/10 iters), loss = 5.64375
I0524 03:36:56.217525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64375 (* 1 = 5.64375 loss)
I0524 03:36:57.402549 11654 sgd_solver.cpp:112] Iteration 28090, lr = 0.1
I0524 03:37:04.094298 11654 solver.cpp:239] Iteration 28100 (1.2696 iter/s, 7.87648s/10 iters), loss = 5.90156
I0524 03:37:04.094344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90156 (* 1 = 5.90156 loss)
I0524 03:37:04.094601 11654 sgd_solver.cpp:112] Iteration 28100, lr = 0.1
I0524 03:37:10.401482 11654 solver.cpp:239] Iteration 28110 (1.58557 iter/s, 6.30689s/10 iters), loss = 6.7226
I0524 03:37:10.401540 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7226 (* 1 = 6.7226 loss)
I0524 03:37:10.401638 11654 sgd_solver.cpp:112] Iteration 28110, lr = 0.1
I0524 03:37:17.411468 11654 solver.cpp:239] Iteration 28120 (1.4266 iter/s, 7.00966s/10 iters), loss = 7.95873
I0524 03:37:17.411589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.95873 (* 1 = 7.95873 loss)
I0524 03:37:17.411607 11654 sgd_solver.cpp:112] Iteration 28120, lr = 0.1
I0524 03:37:23.538547 11654 solver.cpp:239] Iteration 28130 (1.63222 iter/s, 6.12663s/10 iters), loss = 5.47795
I0524 03:37:23.538602 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47795 (* 1 = 5.47795 loss)
I0524 03:37:23.538666 11654 sgd_solver.cpp:112] Iteration 28130, lr = 0.1
I0524 03:37:30.688530 11654 solver.cpp:239] Iteration 28140 (1.39867 iter/s, 7.14966s/10 iters), loss = 5.60836
I0524 03:37:30.688578 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60836 (* 1 = 5.60836 loss)
I0524 03:37:30.688596 11654 sgd_solver.cpp:112] Iteration 28140, lr = 0.1
I0524 03:37:36.970346 11654 solver.cpp:239] Iteration 28150 (1.59197 iter/s, 6.28153s/10 iters), loss = 7.33548
I0524 03:37:36.970391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33548 (* 1 = 7.33548 loss)
I0524 03:37:36.970810 11654 sgd_solver.cpp:112] Iteration 28150, lr = 0.1
I0524 03:37:44.878571 11654 solver.cpp:239] Iteration 28160 (1.26456 iter/s, 7.90787s/10 iters), loss = 6.60641
I0524 03:37:44.878629 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60641 (* 1 = 6.60641 loss)
I0524 03:37:44.935698 11654 sgd_solver.cpp:112] Iteration 28160, lr = 0.1
I0524 03:37:51.630012 11654 solver.cpp:239] Iteration 28170 (1.48124 iter/s, 6.75112s/10 iters), loss = 6.99833
I0524 03:37:51.630347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99833 (* 1 = 6.99833 loss)
I0524 03:37:51.630409 11654 sgd_solver.cpp:112] Iteration 28170, lr = 0.1
I0524 03:37:57.865448 11654 solver.cpp:239] Iteration 28180 (1.60393 iter/s, 6.23469s/10 iters), loss = 7.03338
I0524 03:37:57.865499 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03338 (* 1 = 7.03338 loss)
I0524 03:37:57.865702 11654 sgd_solver.cpp:112] Iteration 28180, lr = 0.1
I0524 03:38:06.475971 11654 solver.cpp:239] Iteration 28190 (1.16142 iter/s, 8.61015s/10 iters), loss = 7.32731
I0524 03:38:06.476009 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32731 (* 1 = 7.32731 loss)
I0524 03:38:06.476033 11654 sgd_solver.cpp:112] Iteration 28190, lr = 0.1
I0524 03:38:14.694417 11654 solver.cpp:239] Iteration 28200 (1.21683 iter/s, 8.21809s/10 iters), loss = 6.86923
I0524 03:38:14.694470 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86923 (* 1 = 6.86923 loss)
I0524 03:38:14.749112 11654 sgd_solver.cpp:112] Iteration 28200, lr = 0.1
I0524 03:38:21.881404 11654 solver.cpp:239] Iteration 28210 (1.39147 iter/s, 7.18666s/10 iters), loss = 5.9304
I0524 03:38:21.881680 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9304 (* 1 = 5.9304 loss)
I0524 03:38:21.881745 11654 sgd_solver.cpp:112] Iteration 28210, lr = 0.1
I0524 03:38:29.461695 11654 solver.cpp:239] Iteration 28220 (1.31931 iter/s, 7.57975s/10 iters), loss = 6.33973
I0524 03:38:29.461750 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33973 (* 1 = 6.33973 loss)
I0524 03:38:29.461769 11654 sgd_solver.cpp:112] Iteration 28220, lr = 0.1
I0524 03:38:35.811389 11654 solver.cpp:239] Iteration 28230 (1.57497 iter/s, 6.34933s/10 iters), loss = 6.25533
I0524 03:38:35.811439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25533 (* 1 = 6.25533 loss)
I0524 03:38:35.811802 11654 sgd_solver.cpp:112] Iteration 28230, lr = 0.1
I0524 03:38:43.303696 11654 solver.cpp:239] Iteration 28240 (1.33476 iter/s, 7.49196s/10 iters), loss = 6.34529
I0524 03:38:43.303747 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34529 (* 1 = 6.34529 loss)
I0524 03:38:43.303763 11654 sgd_solver.cpp:112] Iteration 28240, lr = 0.1
I0524 03:38:50.047010 11654 solver.cpp:239] Iteration 28250 (1.48303 iter/s, 6.74294s/10 iters), loss = 6.61835
I0524 03:38:50.047077 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61835 (* 1 = 6.61835 loss)
I0524 03:38:50.047307 11654 sgd_solver.cpp:112] Iteration 28250, lr = 0.1
I0524 03:38:56.220695 11654 solver.cpp:239] Iteration 28260 (1.61985 iter/s, 6.17339s/10 iters), loss = 6.17735
I0524 03:38:56.220952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17735 (* 1 = 6.17735 loss)
I0524 03:38:56.221021 11654 sgd_solver.cpp:112] Iteration 28260, lr = 0.1
I0524 03:39:04.398820 11654 solver.cpp:239] Iteration 28270 (1.22285 iter/s, 8.17761s/10 iters), loss = 5.90694
I0524 03:39:04.398864 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90694 (* 1 = 5.90694 loss)
I0524 03:39:05.058131 11654 sgd_solver.cpp:112] Iteration 28270, lr = 0.1
I0524 03:39:13.981287 11654 solver.cpp:239] Iteration 28280 (1.04362 iter/s, 9.58204s/10 iters), loss = 6.99493
I0524 03:39:13.981369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99493 (* 1 = 6.99493 loss)
I0524 03:39:13.981395 11654 sgd_solver.cpp:112] Iteration 28280, lr = 0.1
I0524 03:39:20.671528 11654 solver.cpp:239] Iteration 28290 (1.49526 iter/s, 6.6878s/10 iters), loss = 6.79914
I0524 03:39:20.671582 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79914 (* 1 = 6.79914 loss)
I0524 03:39:20.686453 11654 sgd_solver.cpp:112] Iteration 28290, lr = 0.1
I0524 03:39:28.589406 11654 solver.cpp:239] Iteration 28300 (1.26302 iter/s, 7.91753s/10 iters), loss = 5.99311
I0524 03:39:28.589686 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99311 (* 1 = 5.99311 loss)
I0524 03:39:28.589741 11654 sgd_solver.cpp:112] Iteration 28300, lr = 0.1
I0524 03:39:35.594175 11654 solver.cpp:239] Iteration 28310 (1.4277 iter/s, 7.00425s/10 iters), loss = 6.73993
I0524 03:39:35.594226 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73993 (* 1 = 6.73993 loss)
I0524 03:39:35.594241 11654 sgd_solver.cpp:112] Iteration 28310, lr = 0.1
I0524 03:39:42.175524 11654 solver.cpp:239] Iteration 28320 (1.51953 iter/s, 6.58098s/10 iters), loss = 7.04291
I0524 03:39:42.175576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04291 (* 1 = 7.04291 loss)
I0524 03:39:42.175593 11654 sgd_solver.cpp:112] Iteration 28320, lr = 0.1
I0524 03:39:50.321141 11654 solver.cpp:239] Iteration 28330 (1.22772 iter/s, 8.14519s/10 iters), loss = 6.61601
I0524 03:39:50.321183 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61601 (* 1 = 6.61601 loss)
I0524 03:39:50.321414 11654 sgd_solver.cpp:112] Iteration 28330, lr = 0.1
I0524 03:39:57.271580 11654 solver.cpp:239] Iteration 28340 (1.43882 iter/s, 6.95012s/10 iters), loss = 6.53481
I0524 03:39:57.271633 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53481 (* 1 = 6.53481 loss)
I0524 03:39:57.271805 11654 sgd_solver.cpp:112] Iteration 28340, lr = 0.1
I0524 03:40:03.371162 11654 solver.cpp:239] Iteration 28350 (1.63953 iter/s, 6.09929s/10 iters), loss = 5.96383
I0524 03:40:03.371302 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96383 (* 1 = 5.96383 loss)
I0524 03:40:03.371449 11654 sgd_solver.cpp:112] Iteration 28350, lr = 0.1
I0524 03:40:11.368438 11654 solver.cpp:239] Iteration 28360 (1.2505 iter/s, 7.99683s/10 iters), loss = 6.61062
I0524 03:40:11.368491 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61062 (* 1 = 6.61062 loss)
I0524 03:40:11.368618 11654 sgd_solver.cpp:112] Iteration 28360, lr = 0.1
I0524 03:40:17.577589 11654 solver.cpp:239] Iteration 28370 (1.6106 iter/s, 6.20885s/10 iters), loss = 6.74566
I0524 03:40:17.577647 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74566 (* 1 = 6.74566 loss)
I0524 03:40:18.032707 11654 sgd_solver.cpp:112] Iteration 28370, lr = 0.1
I0524 03:40:28.087921 11654 solver.cpp:239] Iteration 28380 (0.951486 iter/s, 10.5099s/10 iters), loss = 6.46503
I0524 03:40:28.087976 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46503 (* 1 = 6.46503 loss)
I0524 03:40:28.087996 11654 sgd_solver.cpp:112] Iteration 28380, lr = 0.1
I0524 03:40:36.483531 11654 solver.cpp:239] Iteration 28390 (1.19116 iter/s, 8.39517s/10 iters), loss = 6.11544
I0524 03:40:36.483762 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11544 (* 1 = 6.11544 loss)
I0524 03:40:36.483814 11654 sgd_solver.cpp:112] Iteration 28390, lr = 0.1
I0524 03:40:43.055634 11654 solver.cpp:239] Iteration 28400 (1.5217 iter/s, 6.57161s/10 iters), loss = 6.24613
I0524 03:40:43.055693 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24613 (* 1 = 6.24613 loss)
I0524 03:40:43.055855 11654 sgd_solver.cpp:112] Iteration 28400, lr = 0.1
I0524 03:40:49.171864 11654 solver.cpp:239] Iteration 28410 (1.63507 iter/s, 6.11594s/10 iters), loss = 6.62367
I0524 03:40:49.171931 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62367 (* 1 = 6.62367 loss)
I0524 03:40:49.172264 11654 sgd_solver.cpp:112] Iteration 28410, lr = 0.1
I0524 03:40:55.969638 11654 solver.cpp:239] Iteration 28420 (1.47114 iter/s, 6.79745s/10 iters), loss = 5.46426
I0524 03:40:55.969691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46426 (* 1 = 5.46426 loss)
I0524 03:40:55.969913 11654 sgd_solver.cpp:112] Iteration 28420, lr = 0.1
I0524 03:41:03.659898 11654 solver.cpp:239] Iteration 28430 (1.30041 iter/s, 7.6899s/10 iters), loss = 6.81906
I0524 03:41:03.659950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81906 (* 1 = 6.81906 loss)
I0524 03:41:03.660284 11654 sgd_solver.cpp:112] Iteration 28430, lr = 0.1
I0524 03:41:10.558390 11654 solver.cpp:239] Iteration 28440 (1.44966 iter/s, 6.89818s/10 iters), loss = 6.45831
I0524 03:41:10.558548 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45831 (* 1 = 6.45831 loss)
I0524 03:41:10.558640 11654 sgd_solver.cpp:112] Iteration 28440, lr = 0.1
I0524 03:41:17.809772 11654 solver.cpp:239] Iteration 28450 (1.37913 iter/s, 7.25096s/10 iters), loss = 6.45012
I0524 03:41:17.809834 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45012 (* 1 = 6.45012 loss)
I0524 03:41:17.809856 11654 sgd_solver.cpp:112] Iteration 28450, lr = 0.1
I0524 03:41:25.080165 11654 solver.cpp:239] Iteration 28460 (1.37591 iter/s, 7.26791s/10 iters), loss = 5.9561
I0524 03:41:25.080206 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9561 (* 1 = 5.9561 loss)
I0524 03:41:25.080413 11654 sgd_solver.cpp:112] Iteration 28460, lr = 0.1
I0524 03:41:32.918208 11654 solver.cpp:239] Iteration 28470 (1.27589 iter/s, 7.8377s/10 iters), loss = 6.34897
I0524 03:41:32.918263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34897 (* 1 = 6.34897 loss)
I0524 03:41:32.918279 11654 sgd_solver.cpp:112] Iteration 28470, lr = 0.1
I0524 03:41:40.054419 11654 solver.cpp:239] Iteration 28480 (1.40138 iter/s, 7.13582s/10 iters), loss = 6.53977
I0524 03:41:40.054476 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53977 (* 1 = 6.53977 loss)
I0524 03:41:40.054498 11654 sgd_solver.cpp:112] Iteration 28480, lr = 0.1
I0524 03:41:47.400954 11654 solver.cpp:239] Iteration 28490 (1.36166 iter/s, 7.344s/10 iters), loss = 5.85395
I0524 03:41:47.401067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85395 (* 1 = 5.85395 loss)
I0524 03:41:47.401084 11654 sgd_solver.cpp:112] Iteration 28490, lr = 0.1
I0524 03:41:53.935792 11654 solver.cpp:239] Iteration 28500 (1.53087 iter/s, 6.53225s/10 iters), loss = 6.55865
I0524 03:41:53.935830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55865 (* 1 = 6.55865 loss)
I0524 03:41:53.935870 11654 sgd_solver.cpp:112] Iteration 28500, lr = 0.1
I0524 03:42:00.660559 11654 solver.cpp:239] Iteration 28510 (1.48711 iter/s, 6.72446s/10 iters), loss = 5.824
I0524 03:42:00.660612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.824 (* 1 = 5.824 loss)
I0524 03:42:00.660795 11654 sgd_solver.cpp:112] Iteration 28510, lr = 0.1
I0524 03:42:07.291373 11654 solver.cpp:239] Iteration 28520 (1.50818 iter/s, 6.63051s/10 iters), loss = 5.95374
I0524 03:42:07.291424 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95374 (* 1 = 5.95374 loss)
I0524 03:42:07.291438 11654 sgd_solver.cpp:112] Iteration 28520, lr = 0.1
I0524 03:42:13.532745 11654 solver.cpp:239] Iteration 28530 (1.60229 iter/s, 6.24109s/10 iters), loss = 6.61172
I0524 03:42:13.532794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61172 (* 1 = 6.61172 loss)
I0524 03:42:14.428148 11654 sgd_solver.cpp:112] Iteration 28530, lr = 0.1
I0524 03:42:20.808406 11654 solver.cpp:239] Iteration 28540 (1.37451 iter/s, 7.27532s/10 iters), loss = 7.16287
I0524 03:42:20.808517 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16287 (* 1 = 7.16287 loss)
I0524 03:42:20.808792 11654 sgd_solver.cpp:112] Iteration 28540, lr = 0.1
I0524 03:42:26.928807 11654 solver.cpp:239] Iteration 28550 (1.63397 iter/s, 6.12006s/10 iters), loss = 6.85598
I0524 03:42:26.928851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85598 (* 1 = 6.85598 loss)
I0524 03:42:27.594496 11654 sgd_solver.cpp:112] Iteration 28550, lr = 0.1
I0524 03:42:34.416440 11654 solver.cpp:239] Iteration 28560 (1.3356 iter/s, 7.48729s/10 iters), loss = 6.78187
I0524 03:42:34.416501 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78187 (* 1 = 6.78187 loss)
I0524 03:42:34.416517 11654 sgd_solver.cpp:112] Iteration 28560, lr = 0.1
I0524 03:42:40.521759 11654 solver.cpp:239] Iteration 28570 (1.63857 iter/s, 6.10287s/10 iters), loss = 6.51586
I0524 03:42:40.521819 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51586 (* 1 = 6.51586 loss)
I0524 03:42:40.522020 11654 sgd_solver.cpp:112] Iteration 28570, lr = 0.1
I0524 03:42:47.858335 11654 solver.cpp:239] Iteration 28580 (1.36309 iter/s, 7.33625s/10 iters), loss = 6.25196
I0524 03:42:47.858376 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25196 (* 1 = 6.25196 loss)
I0524 03:42:47.860348 11654 sgd_solver.cpp:112] Iteration 28580, lr = 0.1
I0524 03:42:55.850112 11654 solver.cpp:239] Iteration 28590 (1.25134 iter/s, 7.99143s/10 iters), loss = 6.81291
I0524 03:42:55.850371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81291 (* 1 = 6.81291 loss)
I0524 03:42:55.850415 11654 sgd_solver.cpp:112] Iteration 28590, lr = 0.1
I0524 03:43:02.340468 11654 solver.cpp:239] Iteration 28600 (1.54136 iter/s, 6.48778s/10 iters), loss = 6.24422
I0524 03:43:02.340519 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24422 (* 1 = 6.24422 loss)
I0524 03:43:02.340534 11654 sgd_solver.cpp:112] Iteration 28600, lr = 0.1
I0524 03:43:09.068409 11654 solver.cpp:239] Iteration 28610 (1.4869 iter/s, 6.72542s/10 iters), loss = 7.64116
I0524 03:43:09.068464 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.64116 (* 1 = 7.64116 loss)
I0524 03:43:09.068753 11654 sgd_solver.cpp:112] Iteration 28610, lr = 0.1
I0524 03:43:15.215232 11654 solver.cpp:239] Iteration 28620 (1.62693 iter/s, 6.14654s/10 iters), loss = 5.28118
I0524 03:43:15.215273 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28118 (* 1 = 5.28118 loss)
I0524 03:43:15.215535 11654 sgd_solver.cpp:112] Iteration 28620, lr = 0.1
I0524 03:43:21.592576 11654 solver.cpp:239] Iteration 28630 (1.56813 iter/s, 6.37704s/10 iters), loss = 5.68307
I0524 03:43:21.592643 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68307 (* 1 = 5.68307 loss)
I0524 03:43:21.592850 11654 sgd_solver.cpp:112] Iteration 28630, lr = 0.1
I0524 03:43:28.848970 11654 solver.cpp:239] Iteration 28640 (1.37816 iter/s, 7.25606s/10 iters), loss = 6.52206
I0524 03:43:28.849112 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52206 (* 1 = 6.52206 loss)
I0524 03:43:28.849203 11654 sgd_solver.cpp:112] Iteration 28640, lr = 0.1
I0524 03:43:35.249717 11654 solver.cpp:239] Iteration 28650 (1.56241 iter/s, 6.40037s/10 iters), loss = 5.58782
I0524 03:43:35.249758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58782 (* 1 = 5.58782 loss)
I0524 03:43:35.249770 11654 sgd_solver.cpp:112] Iteration 28650, lr = 0.1
I0524 03:43:41.356216 11654 solver.cpp:239] Iteration 28660 (1.6377 iter/s, 6.10614s/10 iters), loss = 6.88436
I0524 03:43:41.356271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88436 (* 1 = 6.88436 loss)
I0524 03:43:41.358217 11654 sgd_solver.cpp:112] Iteration 28660, lr = 0.1
I0524 03:43:47.523869 11654 solver.cpp:239] Iteration 28670 (1.62144 iter/s, 6.16736s/10 iters), loss = 5.66357
I0524 03:43:47.523931 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66357 (* 1 = 5.66357 loss)
I0524 03:43:47.551229 11654 sgd_solver.cpp:112] Iteration 28670, lr = 0.1
I0524 03:43:55.165666 11654 solver.cpp:239] Iteration 28680 (1.30865 iter/s, 7.64144s/10 iters), loss = 6.13691
I0524 03:43:55.165724 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13691 (* 1 = 6.13691 loss)
I0524 03:43:55.165760 11654 sgd_solver.cpp:112] Iteration 28680, lr = 0.1
I0524 03:44:02.263833 11654 solver.cpp:239] Iteration 28690 (1.40888 iter/s, 7.09785s/10 iters), loss = 6.05615
I0524 03:44:02.263950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05615 (* 1 = 6.05615 loss)
I0524 03:44:02.263967 11654 sgd_solver.cpp:112] Iteration 28690, lr = 0.1
I0524 03:44:08.348254 11654 solver.cpp:239] Iteration 28700 (1.64365 iter/s, 6.084s/10 iters), loss = 6.45863
I0524 03:44:08.348353 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45863 (* 1 = 6.45863 loss)
I0524 03:44:08.348383 11654 sgd_solver.cpp:112] Iteration 28700, lr = 0.1
I0524 03:44:13.780658 11654 solver.cpp:239] Iteration 28710 (1.8409 iter/s, 5.43211s/10 iters), loss = 5.52634
I0524 03:44:13.780702 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.52634 (* 1 = 5.52634 loss)
I0524 03:44:13.780750 11654 sgd_solver.cpp:112] Iteration 28710, lr = 0.1
I0524 03:44:20.049988 11654 solver.cpp:239] Iteration 28720 (1.59514 iter/s, 6.26903s/10 iters), loss = 7.62754
I0524 03:44:20.050052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62754 (* 1 = 7.62754 loss)
I0524 03:44:20.050449 11654 sgd_solver.cpp:112] Iteration 28720, lr = 0.1
I0524 03:44:26.434100 11654 solver.cpp:239] Iteration 28730 (1.56646 iter/s, 6.38381s/10 iters), loss = 6.17473
I0524 03:44:26.434159 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17473 (* 1 = 6.17473 loss)
I0524 03:44:26.635485 11654 sgd_solver.cpp:112] Iteration 28730, lr = 0.1
I0524 03:44:32.847841 11654 solver.cpp:239] Iteration 28740 (1.55922 iter/s, 6.41344s/10 iters), loss = 6.56878
I0524 03:44:32.848160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56878 (* 1 = 6.56878 loss)
I0524 03:44:32.848515 11654 sgd_solver.cpp:112] Iteration 28740, lr = 0.1
I0524 03:44:41.751322 11654 solver.cpp:239] Iteration 28750 (1.12323 iter/s, 8.90286s/10 iters), loss = 6.91006
I0524 03:44:41.751374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91006 (* 1 = 6.91006 loss)
I0524 03:44:42.051620 11654 sgd_solver.cpp:112] Iteration 28750, lr = 0.1
I0524 03:44:48.806484 11654 solver.cpp:239] Iteration 28760 (1.41747 iter/s, 7.05484s/10 iters), loss = 7.44853
I0524 03:44:48.806531 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44853 (* 1 = 7.44853 loss)
I0524 03:44:48.806548 11654 sgd_solver.cpp:112] Iteration 28760, lr = 0.1
I0524 03:44:55.583631 11654 solver.cpp:239] Iteration 28770 (1.47563 iter/s, 6.77677s/10 iters), loss = 7.85519
I0524 03:44:55.583684 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.85519 (* 1 = 7.85519 loss)
I0524 03:44:55.583705 11654 sgd_solver.cpp:112] Iteration 28770, lr = 0.1
I0524 03:45:02.939693 11654 solver.cpp:239] Iteration 28780 (1.35948 iter/s, 7.35573s/10 iters), loss = 7.77775
I0524 03:45:02.939895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77775 (* 1 = 7.77775 loss)
I0524 03:45:03.060425 11654 sgd_solver.cpp:112] Iteration 28780, lr = 0.1
I0524 03:45:10.996726 11654 solver.cpp:239] Iteration 28790 (1.24123 iter/s, 8.05655s/10 iters), loss = 6.56593
I0524 03:45:10.996781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56593 (* 1 = 6.56593 loss)
I0524 03:45:11.113602 11654 sgd_solver.cpp:112] Iteration 28790, lr = 0.1
I0524 03:45:17.414356 11654 solver.cpp:239] Iteration 28800 (1.55828 iter/s, 6.41733s/10 iters), loss = 6.48093
I0524 03:45:17.414412 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48093 (* 1 = 6.48093 loss)
I0524 03:45:17.414659 11654 sgd_solver.cpp:112] Iteration 28800, lr = 0.1
I0524 03:45:24.630986 11654 solver.cpp:239] Iteration 28810 (1.38575 iter/s, 7.2163s/10 iters), loss = 6.26425
I0524 03:45:24.631052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26425 (* 1 = 6.26425 loss)
I0524 03:45:24.631072 11654 sgd_solver.cpp:112] Iteration 28810, lr = 0.1
I0524 03:45:31.710067 11654 solver.cpp:239] Iteration 28820 (1.41269 iter/s, 7.0787s/10 iters), loss = 6.66748
I0524 03:45:31.710134 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66748 (* 1 = 6.66748 loss)
I0524 03:45:31.712069 11654 sgd_solver.cpp:112] Iteration 28820, lr = 0.1
I0524 03:45:40.119197 11654 solver.cpp:239] Iteration 28830 (1.18925 iter/s, 8.40867s/10 iters), loss = 6.3205
I0524 03:45:40.119449 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3205 (* 1 = 6.3205 loss)
I0524 03:45:40.119695 11654 sgd_solver.cpp:112] Iteration 28830, lr = 0.1
I0524 03:45:47.283797 11654 solver.cpp:239] Iteration 28840 (1.39585 iter/s, 7.1641s/10 iters), loss = 6.40766
I0524 03:45:47.283841 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40766 (* 1 = 6.40766 loss)
I0524 03:45:47.284114 11654 sgd_solver.cpp:112] Iteration 28840, lr = 0.1
I0524 03:45:54.601047 11654 solver.cpp:239] Iteration 28850 (1.3667 iter/s, 7.31692s/10 iters), loss = 6.81014
I0524 03:45:54.601100 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81014 (* 1 = 6.81014 loss)
I0524 03:45:54.601117 11654 sgd_solver.cpp:112] Iteration 28850, lr = 0.1
I0524 03:46:01.512529 11654 solver.cpp:239] Iteration 28860 (1.44695 iter/s, 6.91111s/10 iters), loss = 5.67919
I0524 03:46:01.512583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67919 (* 1 = 5.67919 loss)
I0524 03:46:01.512719 11654 sgd_solver.cpp:112] Iteration 28860, lr = 0.1
I0524 03:46:10.218598 11654 solver.cpp:239] Iteration 28870 (1.14867 iter/s, 8.70569s/10 iters), loss = 5.87832
I0524 03:46:10.218777 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87832 (* 1 = 5.87832 loss)
I0524 03:46:10.314962 11654 sgd_solver.cpp:112] Iteration 28870, lr = 0.1
I0524 03:46:18.408334 11654 solver.cpp:239] Iteration 28880 (1.22111 iter/s, 8.18924s/10 iters), loss = 7.1114
I0524 03:46:18.408390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1114 (* 1 = 7.1114 loss)
I0524 03:46:18.916688 11654 sgd_solver.cpp:112] Iteration 28880, lr = 0.1
I0524 03:46:25.870894 11654 solver.cpp:239] Iteration 28890 (1.34008 iter/s, 7.46222s/10 iters), loss = 7.08584
I0524 03:46:25.870959 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08584 (* 1 = 7.08584 loss)
I0524 03:46:26.333039 11654 sgd_solver.cpp:112] Iteration 28890, lr = 0.1
I0524 03:46:32.623060 11654 solver.cpp:239] Iteration 28900 (1.48108 iter/s, 6.75185s/10 iters), loss = 6.17416
I0524 03:46:32.623111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17416 (* 1 = 6.17416 loss)
I0524 03:46:32.960359 11654 sgd_solver.cpp:112] Iteration 28900, lr = 0.1
I0524 03:46:40.044416 11654 solver.cpp:239] Iteration 28910 (1.34752 iter/s, 7.42102s/10 iters), loss = 5.97745
I0524 03:46:40.044476 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97745 (* 1 = 5.97745 loss)
I0524 03:46:40.695765 11654 sgd_solver.cpp:112] Iteration 28910, lr = 0.1
I0524 03:46:46.821214 11654 solver.cpp:239] Iteration 28920 (1.47569 iter/s, 6.77648s/10 iters), loss = 7.1321
I0524 03:46:46.821252 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1321 (* 1 = 7.1321 loss)
I0524 03:46:47.547633 11654 sgd_solver.cpp:112] Iteration 28920, lr = 0.1
I0524 03:46:55.624227 11654 solver.cpp:239] Iteration 28930 (1.13602 iter/s, 8.80263s/10 iters), loss = 6.17505
I0524 03:46:55.624279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17505 (* 1 = 6.17505 loss)
I0524 03:46:55.720623 11654 sgd_solver.cpp:112] Iteration 28930, lr = 0.1
I0524 03:47:02.680933 11654 solver.cpp:239] Iteration 28940 (1.41716 iter/s, 7.05638s/10 iters), loss = 6.86429
I0524 03:47:02.680991 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86429 (* 1 = 6.86429 loss)
I0524 03:47:03.196620 11654 sgd_solver.cpp:112] Iteration 28940, lr = 0.1
I0524 03:47:09.670140 11654 solver.cpp:239] Iteration 28950 (1.43084 iter/s, 6.98888s/10 iters), loss = 7.62191
I0524 03:47:09.670192 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62191 (* 1 = 7.62191 loss)
I0524 03:47:09.796002 11654 sgd_solver.cpp:112] Iteration 28950, lr = 0.1
I0524 03:47:16.176826 11654 solver.cpp:239] Iteration 28960 (1.53695 iter/s, 6.50639s/10 iters), loss = 6.34751
I0524 03:47:16.176976 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34751 (* 1 = 6.34751 loss)
I0524 03:47:16.176995 11654 sgd_solver.cpp:112] Iteration 28960, lr = 0.1
I0524 03:47:24.443344 11654 solver.cpp:239] Iteration 28970 (1.20977 iter/s, 8.26606s/10 iters), loss = 6.49087
I0524 03:47:24.443410 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49087 (* 1 = 6.49087 loss)
I0524 03:47:24.459450 11654 sgd_solver.cpp:112] Iteration 28970, lr = 0.1
I0524 03:47:32.708685 11654 solver.cpp:239] Iteration 28980 (1.20993 iter/s, 8.26497s/10 iters), loss = 7.89288
I0524 03:47:32.708730 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.89288 (* 1 = 7.89288 loss)
I0524 03:47:32.977141 11654 sgd_solver.cpp:112] Iteration 28980, lr = 0.1
I0524 03:47:43.754281 11654 solver.cpp:239] Iteration 28990 (0.905377 iter/s, 11.0451s/10 iters), loss = 7.24025
I0524 03:47:43.754333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24025 (* 1 = 7.24025 loss)
I0524 03:47:43.754349 11654 sgd_solver.cpp:112] Iteration 28990, lr = 0.1
I0524 03:47:50.319922 11654 solver.cpp:239] Iteration 29000 (1.52315 iter/s, 6.56533s/10 iters), loss = 6.57246
I0524 03:47:50.320055 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57246 (* 1 = 6.57246 loss)
I0524 03:47:50.320399 11654 sgd_solver.cpp:112] Iteration 29000, lr = 0.1
I0524 03:47:57.045841 11654 solver.cpp:239] Iteration 29010 (1.48687 iter/s, 6.72553s/10 iters), loss = 6.7923
I0524 03:47:57.045883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7923 (* 1 = 6.7923 loss)
I0524 03:47:57.350594 11654 sgd_solver.cpp:112] Iteration 29010, lr = 0.1
I0524 03:48:04.619853 11654 solver.cpp:239] Iteration 29020 (1.32036 iter/s, 7.57367s/10 iters), loss = 6.80226
I0524 03:48:04.619907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80226 (* 1 = 6.80226 loss)
I0524 03:48:04.621073 11654 sgd_solver.cpp:112] Iteration 29020, lr = 0.1
I0524 03:48:11.776742 11654 solver.cpp:239] Iteration 29030 (1.39732 iter/s, 7.15657s/10 iters), loss = 7.17207
I0524 03:48:11.776792 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17207 (* 1 = 7.17207 loss)
I0524 03:48:12.315466 11654 sgd_solver.cpp:112] Iteration 29030, lr = 0.1
I0524 03:48:19.553680 11654 solver.cpp:239] Iteration 29040 (1.28591 iter/s, 7.7766s/10 iters), loss = 6.99027
I0524 03:48:19.553719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99027 (* 1 = 6.99027 loss)
I0524 03:48:19.553735 11654 sgd_solver.cpp:112] Iteration 29040, lr = 0.1
I0524 03:48:27.844451 11654 solver.cpp:239] Iteration 29050 (1.20621 iter/s, 8.2904s/10 iters), loss = 6.90195
I0524 03:48:27.844621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90195 (* 1 = 6.90195 loss)
I0524 03:48:27.844640 11654 sgd_solver.cpp:112] Iteration 29050, lr = 0.1
I0524 03:48:35.478322 11654 solver.cpp:239] Iteration 29060 (1.31003 iter/s, 7.63341s/10 iters), loss = 6.49999
I0524 03:48:35.478376 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49999 (* 1 = 6.49999 loss)
I0524 03:48:35.732244 11654 sgd_solver.cpp:112] Iteration 29060, lr = 0.1
I0524 03:48:45.087061 11654 solver.cpp:239] Iteration 29070 (1.04076 iter/s, 9.60832s/10 iters), loss = 5.77627
I0524 03:48:45.087115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77627 (* 1 = 5.77627 loss)
I0524 03:48:45.087131 11654 sgd_solver.cpp:112] Iteration 29070, lr = 0.1
I0524 03:48:53.761811 11654 solver.cpp:239] Iteration 29080 (1.15282 iter/s, 8.67437s/10 iters), loss = 5.1544
I0524 03:48:53.761849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.1544 (* 1 = 5.1544 loss)
I0524 03:48:53.761863 11654 sgd_solver.cpp:112] Iteration 29080, lr = 0.1
I0524 03:49:00.908746 11654 solver.cpp:239] Iteration 29090 (1.39969 iter/s, 7.14445s/10 iters), loss = 6.0636
I0524 03:49:00.908865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0636 (* 1 = 6.0636 loss)
I0524 03:49:01.613031 11654 sgd_solver.cpp:112] Iteration 29090, lr = 0.1
I0524 03:49:08.446794 11654 solver.cpp:239] Iteration 29100 (1.32668 iter/s, 7.53764s/10 iters), loss = 7.32471
I0524 03:49:08.446851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32471 (* 1 = 7.32471 loss)
I0524 03:49:08.447041 11654 sgd_solver.cpp:112] Iteration 29100, lr = 0.1
I0524 03:49:15.132221 11654 solver.cpp:239] Iteration 29110 (1.49586 iter/s, 6.68511s/10 iters), loss = 6.3715
I0524 03:49:15.132279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3715 (* 1 = 6.3715 loss)
I0524 03:49:15.694169 11654 sgd_solver.cpp:112] Iteration 29110, lr = 0.1
I0524 03:49:22.539314 11654 solver.cpp:239] Iteration 29120 (1.35012 iter/s, 7.40675s/10 iters), loss = 6.42261
I0524 03:49:22.539364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42261 (* 1 = 6.42261 loss)
I0524 03:49:22.539381 11654 sgd_solver.cpp:112] Iteration 29120, lr = 0.1
I0524 03:49:30.208117 11654 solver.cpp:239] Iteration 29130 (1.30404 iter/s, 7.66846s/10 iters), loss = 6.70098
I0524 03:49:30.208173 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70098 (* 1 = 6.70098 loss)
I0524 03:49:30.429096 11654 sgd_solver.cpp:112] Iteration 29130, lr = 0.1
I0524 03:49:39.194416 11654 solver.cpp:239] Iteration 29140 (1.11285 iter/s, 8.9859s/10 iters), loss = 6.13545
I0524 03:49:39.194733 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13545 (* 1 = 6.13545 loss)
I0524 03:49:39.194797 11654 sgd_solver.cpp:112] Iteration 29140, lr = 0.1
I0524 03:49:45.554996 11654 solver.cpp:239] Iteration 29150 (1.57253 iter/s, 6.35917s/10 iters), loss = 6.40351
I0524 03:49:45.555042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40351 (* 1 = 6.40351 loss)
I0524 03:49:45.555574 11654 sgd_solver.cpp:112] Iteration 29150, lr = 0.1
I0524 03:49:52.300606 11654 solver.cpp:239] Iteration 29160 (1.48252 iter/s, 6.74529s/10 iters), loss = 6.3197
I0524 03:49:52.300669 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3197 (* 1 = 6.3197 loss)
I0524 03:49:52.653169 11654 sgd_solver.cpp:112] Iteration 29160, lr = 0.1
I0524 03:50:01.062609 11654 solver.cpp:239] Iteration 29170 (1.14134 iter/s, 8.76161s/10 iters), loss = 6.33219
I0524 03:50:01.062660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33219 (* 1 = 6.33219 loss)
I0524 03:50:01.071306 11654 sgd_solver.cpp:112] Iteration 29170, lr = 0.1
I0524 03:50:07.541923 11654 solver.cpp:239] Iteration 29180 (1.54344 iter/s, 6.47902s/10 iters), loss = 5.58714
I0524 03:50:07.541965 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58714 (* 1 = 5.58714 loss)
I0524 03:50:07.542498 11654 sgd_solver.cpp:112] Iteration 29180, lr = 0.1
I0524 03:50:13.700469 11654 solver.cpp:239] Iteration 29190 (1.62384 iter/s, 6.15826s/10 iters), loss = 6.30902
I0524 03:50:13.700736 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30902 (* 1 = 6.30902 loss)
I0524 03:50:13.700976 11654 sgd_solver.cpp:112] Iteration 29190, lr = 0.1
I0524 03:50:20.245708 11654 solver.cpp:239] Iteration 29200 (1.52794 iter/s, 6.54476s/10 iters), loss = 5.89162
I0524 03:50:20.245760 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89162 (* 1 = 5.89162 loss)
I0524 03:50:20.245954 11654 sgd_solver.cpp:112] Iteration 29200, lr = 0.1
I0524 03:50:26.673542 11654 solver.cpp:239] Iteration 29210 (1.55581 iter/s, 6.42754s/10 iters), loss = 6.46079
I0524 03:50:26.673593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46079 (* 1 = 6.46079 loss)
I0524 03:50:26.674240 11654 sgd_solver.cpp:112] Iteration 29210, lr = 0.1
I0524 03:50:33.822275 11654 solver.cpp:239] Iteration 29220 (1.39891 iter/s, 7.1484s/10 iters), loss = 6.98049
I0524 03:50:33.822335 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98049 (* 1 = 6.98049 loss)
I0524 03:50:33.822567 11654 sgd_solver.cpp:112] Iteration 29220, lr = 0.1
I0524 03:50:43.371932 11654 solver.cpp:239] Iteration 29230 (1.0472 iter/s, 9.54923s/10 iters), loss = 5.54794
I0524 03:50:43.371989 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54794 (* 1 = 5.54794 loss)
I0524 03:50:43.574877 11654 sgd_solver.cpp:112] Iteration 29230, lr = 0.1
I0524 03:50:52.491883 11654 solver.cpp:239] Iteration 29240 (1.09655 iter/s, 9.11954s/10 iters), loss = 7.00243
I0524 03:50:52.492022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00243 (* 1 = 7.00243 loss)
I0524 03:50:52.601269 11654 sgd_solver.cpp:112] Iteration 29240, lr = 0.1
I0524 03:50:58.820307 11654 solver.cpp:239] Iteration 29250 (1.58026 iter/s, 6.32806s/10 iters), loss = 6.76153
I0524 03:50:58.820365 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76153 (* 1 = 6.76153 loss)
I0524 03:50:58.820479 11654 sgd_solver.cpp:112] Iteration 29250, lr = 0.1
I0524 03:51:06.536161 11654 solver.cpp:239] Iteration 29260 (1.29609 iter/s, 7.71549s/10 iters), loss = 6.39622
I0524 03:51:06.536228 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39622 (* 1 = 6.39622 loss)
I0524 03:51:06.544839 11654 sgd_solver.cpp:112] Iteration 29260, lr = 0.1
I0524 03:51:13.787559 11654 solver.cpp:239] Iteration 29270 (1.37911 iter/s, 7.25105s/10 iters), loss = 6.33891
I0524 03:51:13.787613 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33891 (* 1 = 6.33891 loss)
I0524 03:51:13.787818 11654 sgd_solver.cpp:112] Iteration 29270, lr = 0.1
I0524 03:51:20.445798 11654 solver.cpp:239] Iteration 29280 (1.50197 iter/s, 6.65793s/10 iters), loss = 5.88875
I0524 03:51:20.445849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88875 (* 1 = 5.88875 loss)
I0524 03:51:20.445864 11654 sgd_solver.cpp:112] Iteration 29280, lr = 0.1
I0524 03:51:26.867535 11654 solver.cpp:239] Iteration 29290 (1.55728 iter/s, 6.42144s/10 iters), loss = 6.18913
I0524 03:51:26.867820 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18913 (* 1 = 6.18913 loss)
I0524 03:51:26.867887 11654 sgd_solver.cpp:112] Iteration 29290, lr = 0.1
I0524 03:51:33.622133 11654 solver.cpp:239] Iteration 29300 (1.48064 iter/s, 6.75383s/10 iters), loss = 5.40942
I0524 03:51:33.622198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40942 (* 1 = 5.40942 loss)
I0524 03:51:33.622217 11654 sgd_solver.cpp:112] Iteration 29300, lr = 0.1
I0524 03:51:39.682749 11654 solver.cpp:239] Iteration 29310 (1.65008 iter/s, 6.06033s/10 iters), loss = 7.16963
I0524 03:51:39.682791 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16963 (* 1 = 7.16963 loss)
I0524 03:51:39.683012 11654 sgd_solver.cpp:112] Iteration 29310, lr = 0.1
I0524 03:51:47.853046 11654 solver.cpp:239] Iteration 29320 (1.224 iter/s, 8.16994s/10 iters), loss = 7.18756
I0524 03:51:47.853101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18756 (* 1 = 7.18756 loss)
I0524 03:51:47.853116 11654 sgd_solver.cpp:112] Iteration 29320, lr = 0.1
I0524 03:51:54.165138 11654 solver.cpp:239] Iteration 29330 (1.58435 iter/s, 6.31173s/10 iters), loss = 5.91561
I0524 03:51:54.165200 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91561 (* 1 = 5.91561 loss)
I0524 03:51:54.165313 11654 sgd_solver.cpp:112] Iteration 29330, lr = 0.1
I0524 03:52:03.503944 11654 solver.cpp:239] Iteration 29340 (1.07085 iter/s, 9.3384s/10 iters), loss = 6.36619
I0524 03:52:03.504039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36619 (* 1 = 6.36619 loss)
I0524 03:52:03.504057 11654 sgd_solver.cpp:112] Iteration 29340, lr = 0.1
I0524 03:52:10.715919 11654 solver.cpp:239] Iteration 29350 (1.38707 iter/s, 7.20943s/10 iters), loss = 7.16931
I0524 03:52:10.715973 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16931 (* 1 = 7.16931 loss)
I0524 03:52:10.716007 11654 sgd_solver.cpp:112] Iteration 29350, lr = 0.1
I0524 03:52:16.947701 11654 solver.cpp:239] Iteration 29360 (1.60475 iter/s, 6.23149s/10 iters), loss = 6.47423
I0524 03:52:16.947754 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47423 (* 1 = 6.47423 loss)
I0524 03:52:16.948405 11654 sgd_solver.cpp:112] Iteration 29360, lr = 0.1
I0524 03:52:23.943478 11654 solver.cpp:239] Iteration 29370 (1.4295 iter/s, 6.99546s/10 iters), loss = 5.26693
I0524 03:52:23.943531 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26693 (* 1 = 5.26693 loss)
I0524 03:52:23.943544 11654 sgd_solver.cpp:112] Iteration 29370, lr = 0.1
I0524 03:52:32.556087 11654 solver.cpp:239] Iteration 29380 (1.16115 iter/s, 8.61216s/10 iters), loss = 5.6773
I0524 03:52:32.556145 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6773 (* 1 = 5.6773 loss)
I0524 03:52:32.841593 11654 sgd_solver.cpp:112] Iteration 29380, lr = 0.1
I0524 03:52:39.301609 11654 solver.cpp:239] Iteration 29390 (1.48253 iter/s, 6.74521s/10 iters), loss = 6.92982
I0524 03:52:39.301862 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92982 (* 1 = 6.92982 loss)
I0524 03:52:39.301913 11654 sgd_solver.cpp:112] Iteration 29390, lr = 0.1
I0524 03:52:45.947711 11654 solver.cpp:239] Iteration 29400 (1.50475 iter/s, 6.64562s/10 iters), loss = 5.86399
I0524 03:52:45.947767 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86399 (* 1 = 5.86399 loss)
I0524 03:52:45.947839 11654 sgd_solver.cpp:112] Iteration 29400, lr = 0.1
I0524 03:52:54.019029 11654 solver.cpp:239] Iteration 29410 (1.23901 iter/s, 8.07096s/10 iters), loss = 5.78352
I0524 03:52:54.019084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78352 (* 1 = 5.78352 loss)
I0524 03:52:54.019102 11654 sgd_solver.cpp:112] Iteration 29410, lr = 0.1
I0524 03:53:02.032500 11654 solver.cpp:239] Iteration 29420 (1.24796 iter/s, 8.01305s/10 iters), loss = 6.90361
I0524 03:53:02.032546 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90361 (* 1 = 6.90361 loss)
I0524 03:53:02.521798 11654 sgd_solver.cpp:112] Iteration 29420, lr = 0.1
I0524 03:53:11.510201 11654 solver.cpp:239] Iteration 29430 (1.05515 iter/s, 9.47728s/10 iters), loss = 5.90047
I0524 03:53:11.510457 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90047 (* 1 = 5.90047 loss)
I0524 03:53:11.510509 11654 sgd_solver.cpp:112] Iteration 29430, lr = 0.1
I0524 03:53:17.905661 11654 solver.cpp:239] Iteration 29440 (1.56377 iter/s, 6.39479s/10 iters), loss = 6.45546
I0524 03:53:17.905719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45546 (* 1 = 6.45546 loss)
I0524 03:53:18.109369 11654 sgd_solver.cpp:112] Iteration 29440, lr = 0.1
I0524 03:53:24.801746 11654 solver.cpp:239] Iteration 29450 (1.45016 iter/s, 6.89577s/10 iters), loss = 5.61664
I0524 03:53:24.801786 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61664 (* 1 = 5.61664 loss)
I0524 03:53:24.951059 11654 sgd_solver.cpp:112] Iteration 29450, lr = 0.1
I0524 03:53:31.954411 11654 solver.cpp:239] Iteration 29460 (1.39814 iter/s, 7.15234s/10 iters), loss = 5.65012
I0524 03:53:31.954463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65012 (* 1 = 5.65012 loss)
I0524 03:53:31.954747 11654 sgd_solver.cpp:112] Iteration 29460, lr = 0.1
I0524 03:53:38.544332 11654 solver.cpp:239] Iteration 29470 (1.51754 iter/s, 6.58962s/10 iters), loss = 6.32281
I0524 03:53:38.544383 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32281 (* 1 = 6.32281 loss)
I0524 03:53:39.382226 11654 sgd_solver.cpp:112] Iteration 29470, lr = 0.1
I0524 03:53:45.560387 11654 solver.cpp:239] Iteration 29480 (1.42537 iter/s, 7.01574s/10 iters), loss = 5.96961
I0524 03:53:45.560541 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96961 (* 1 = 5.96961 loss)
I0524 03:53:45.560679 11654 sgd_solver.cpp:112] Iteration 29480, lr = 0.1
I0524 03:53:54.182111 11654 solver.cpp:239] Iteration 29490 (1.15993 iter/s, 8.62123s/10 iters), loss = 7.35872
I0524 03:53:54.182165 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.35872 (* 1 = 7.35872 loss)
I0524 03:53:54.182382 11654 sgd_solver.cpp:112] Iteration 29490, lr = 0.1
I0524 03:54:02.298638 11654 solver.cpp:239] Iteration 29500 (1.23211 iter/s, 8.11617s/10 iters), loss = 6.01814
I0524 03:54:02.298698 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01814 (* 1 = 6.01814 loss)
I0524 03:54:02.298729 11654 sgd_solver.cpp:112] Iteration 29500, lr = 0.1
I0524 03:54:09.333665 11654 solver.cpp:239] Iteration 29510 (1.42197 iter/s, 7.03248s/10 iters), loss = 6.61517
I0524 03:54:09.333722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61517 (* 1 = 6.61517 loss)
I0524 03:54:09.333884 11654 sgd_solver.cpp:112] Iteration 29510, lr = 0.1
I0524 03:54:15.808400 11654 solver.cpp:239] Iteration 29520 (1.54454 iter/s, 6.47443s/10 iters), loss = 5.78125
I0524 03:54:15.808692 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78125 (* 1 = 5.78125 loss)
I0524 03:54:15.808830 11654 sgd_solver.cpp:112] Iteration 29520, lr = 0.1
I0524 03:54:22.485347 11654 solver.cpp:239] Iteration 29530 (1.4983 iter/s, 6.67424s/10 iters), loss = 6.29018
I0524 03:54:22.485409 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29018 (* 1 = 6.29018 loss)
I0524 03:54:22.485627 11654 sgd_solver.cpp:112] Iteration 29530, lr = 0.1
I0524 03:54:29.265388 11654 solver.cpp:239] Iteration 29540 (1.47499 iter/s, 6.77973s/10 iters), loss = 6.22011
I0524 03:54:29.265444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22011 (* 1 = 6.22011 loss)
I0524 03:54:29.354141 11654 sgd_solver.cpp:112] Iteration 29540, lr = 0.1
I0524 03:54:38.122076 11654 solver.cpp:239] Iteration 29550 (1.12914 iter/s, 8.8563s/10 iters), loss = 6.55384
I0524 03:54:38.122125 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55384 (* 1 = 6.55384 loss)
I0524 03:54:38.122146 11654 sgd_solver.cpp:112] Iteration 29550, lr = 0.1
I0524 03:54:44.512382 11654 solver.cpp:239] Iteration 29560 (1.56494 iter/s, 6.39001s/10 iters), loss = 6.28001
I0524 03:54:44.512436 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28001 (* 1 = 6.28001 loss)
I0524 03:54:44.512452 11654 sgd_solver.cpp:112] Iteration 29560, lr = 0.1
I0524 03:54:51.946581 11654 solver.cpp:239] Iteration 29570 (1.34543 iter/s, 7.43257s/10 iters), loss = 6.97273
I0524 03:54:51.946866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97273 (* 1 = 6.97273 loss)
I0524 03:54:51.946920 11654 sgd_solver.cpp:112] Iteration 29570, lr = 0.1
I0524 03:54:59.418359 11654 solver.cpp:239] Iteration 29580 (1.33883 iter/s, 7.46923s/10 iters), loss = 6.15215
I0524 03:54:59.418417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15215 (* 1 = 6.15215 loss)
I0524 03:54:59.418437 11654 sgd_solver.cpp:112] Iteration 29580, lr = 0.1
I0524 03:55:05.639750 11654 solver.cpp:239] Iteration 29590 (1.60759 iter/s, 6.22048s/10 iters), loss = 6.30051
I0524 03:55:05.639791 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30051 (* 1 = 6.30051 loss)
I0524 03:55:05.774195 11654 sgd_solver.cpp:112] Iteration 29590, lr = 0.1
I0524 03:55:12.049693 11654 solver.cpp:239] Iteration 29600 (1.56015 iter/s, 6.40965s/10 iters), loss = 7.10112
I0524 03:55:12.049744 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10112 (* 1 = 7.10112 loss)
I0524 03:55:12.049974 11654 sgd_solver.cpp:112] Iteration 29600, lr = 0.1
I0524 03:55:18.176553 11654 solver.cpp:239] Iteration 29610 (1.63224 iter/s, 6.12656s/10 iters), loss = 6.87333
I0524 03:55:18.176615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87333 (* 1 = 6.87333 loss)
I0524 03:55:18.177078 11654 sgd_solver.cpp:112] Iteration 29610, lr = 0.1
I0524 03:55:27.268584 11654 solver.cpp:239] Iteration 29620 (1.09991 iter/s, 9.09163s/10 iters), loss = 7.33985
I0524 03:55:27.268715 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33985 (* 1 = 7.33985 loss)
I0524 03:55:27.268733 11654 sgd_solver.cpp:112] Iteration 29620, lr = 0.1
I0524 03:55:37.582610 11654 solver.cpp:239] Iteration 29630 (0.969606 iter/s, 10.3135s/10 iters), loss = 6.71343
I0524 03:55:37.582680 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71343 (* 1 = 6.71343 loss)
I0524 03:55:37.591351 11654 sgd_solver.cpp:112] Iteration 29630, lr = 0.1
I0524 03:55:43.677126 11654 solver.cpp:239] Iteration 29640 (1.6409 iter/s, 6.09422s/10 iters), loss = 6.29825
I0524 03:55:43.677178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29825 (* 1 = 6.29825 loss)
I0524 03:55:43.677194 11654 sgd_solver.cpp:112] Iteration 29640, lr = 0.1
I0524 03:55:49.826759 11654 solver.cpp:239] Iteration 29650 (1.62621 iter/s, 6.14928s/10 iters), loss = 6.8143
I0524 03:55:49.826814 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8143 (* 1 = 6.8143 loss)
I0524 03:55:49.826834 11654 sgd_solver.cpp:112] Iteration 29650, lr = 0.1
I0524 03:55:57.002737 11654 solver.cpp:239] Iteration 29660 (1.39362 iter/s, 7.17556s/10 iters), loss = 6.84987
I0524 03:55:57.002771 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84987 (* 1 = 6.84987 loss)
I0524 03:55:57.572695 11654 sgd_solver.cpp:112] Iteration 29660, lr = 0.1
I0524 03:56:04.332823 11654 solver.cpp:239] Iteration 29670 (1.3643 iter/s, 7.32976s/10 iters), loss = 6.83097
I0524 03:56:04.332878 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83097 (* 1 = 6.83097 loss)
I0524 03:56:04.358811 11654 sgd_solver.cpp:112] Iteration 29670, lr = 0.1
I0524 03:56:11.226336 11654 solver.cpp:239] Iteration 29680 (1.45071 iter/s, 6.8932s/10 iters), loss = 6.6081
I0524 03:56:11.226387 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6081 (* 1 = 6.6081 loss)
I0524 03:56:11.226722 11654 sgd_solver.cpp:112] Iteration 29680, lr = 0.1
I0524 03:56:17.367211 11654 solver.cpp:239] Iteration 29690 (1.62851 iter/s, 6.14059s/10 iters), loss = 6.3871
I0524 03:56:17.367260 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3871 (* 1 = 6.3871 loss)
I0524 03:56:17.367372 11654 sgd_solver.cpp:112] Iteration 29690, lr = 0.1
I0524 03:56:23.510936 11654 solver.cpp:239] Iteration 29700 (1.62775 iter/s, 6.14344s/10 iters), loss = 6.69459
I0524 03:56:23.510993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69459 (* 1 = 6.69459 loss)
I0524 03:56:23.511018 11654 sgd_solver.cpp:112] Iteration 29700, lr = 0.1
I0524 03:56:29.856223 11654 solver.cpp:239] Iteration 29710 (1.57605 iter/s, 6.34499s/10 iters), loss = 5.08324
I0524 03:56:29.856415 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.08324 (* 1 = 5.08324 loss)
I0524 03:56:29.858394 11654 sgd_solver.cpp:112] Iteration 29710, lr = 0.1
I0524 03:56:36.806409 11654 solver.cpp:239] Iteration 29720 (1.43891 iter/s, 6.94973s/10 iters), loss = 6.90374
I0524 03:56:36.806459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90374 (* 1 = 6.90374 loss)
I0524 03:56:36.806475 11654 sgd_solver.cpp:112] Iteration 29720, lr = 0.1
I0524 03:56:43.539489 11654 solver.cpp:239] Iteration 29730 (1.48527 iter/s, 6.73278s/10 iters), loss = 6.1495
I0524 03:56:43.539533 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1495 (* 1 = 6.1495 loss)
I0524 03:56:43.547540 11654 sgd_solver.cpp:112] Iteration 29730, lr = 0.1
I0524 03:56:50.388720 11654 solver.cpp:239] Iteration 29740 (1.46009 iter/s, 6.84891s/10 iters), loss = 6.10393
I0524 03:56:50.388788 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10393 (* 1 = 6.10393 loss)
I0524 03:56:50.389231 11654 sgd_solver.cpp:112] Iteration 29740, lr = 0.1
I0524 03:56:56.476209 11654 solver.cpp:239] Iteration 29750 (1.64279 iter/s, 6.08719s/10 iters), loss = 5.94504
I0524 03:56:56.476260 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94504 (* 1 = 5.94504 loss)
I0524 03:56:56.476761 11654 sgd_solver.cpp:112] Iteration 29750, lr = 0.1
I0524 03:57:03.729466 11654 solver.cpp:239] Iteration 29760 (1.37875 iter/s, 7.25293s/10 iters), loss = 7.3011
I0524 03:57:03.729576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3011 (* 1 = 7.3011 loss)
I0524 03:57:03.729594 11654 sgd_solver.cpp:112] Iteration 29760, lr = 0.1
I0524 03:57:10.554772 11654 solver.cpp:239] Iteration 29770 (1.46522 iter/s, 6.82491s/10 iters), loss = 6.07555
I0524 03:57:10.554816 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07555 (* 1 = 6.07555 loss)
I0524 03:57:10.554846 11654 sgd_solver.cpp:112] Iteration 29770, lr = 0.1
I0524 03:57:16.905050 11654 solver.cpp:239] Iteration 29780 (1.57481 iter/s, 6.34998s/10 iters), loss = 6.18749
I0524 03:57:16.905108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18749 (* 1 = 6.18749 loss)
I0524 03:57:17.028338 11654 sgd_solver.cpp:112] Iteration 29780, lr = 0.1
I0524 03:57:23.203280 11654 solver.cpp:239] Iteration 29790 (1.58782 iter/s, 6.29794s/10 iters), loss = 6.84613
I0524 03:57:23.203322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84613 (* 1 = 6.84613 loss)
I0524 03:57:24.438864 11654 sgd_solver.cpp:112] Iteration 29790, lr = 0.1
I0524 03:57:30.589773 11654 solver.cpp:239] Iteration 29800 (1.35388 iter/s, 7.38616s/10 iters), loss = 7.54214
I0524 03:57:30.589825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54214 (* 1 = 7.54214 loss)
I0524 03:57:30.838919 11654 sgd_solver.cpp:112] Iteration 29800, lr = 0.1
I0524 03:57:37.347358 11654 solver.cpp:239] Iteration 29810 (1.47989 iter/s, 6.75727s/10 iters), loss = 7.17258
I0524 03:57:37.347666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17258 (* 1 = 7.17258 loss)
I0524 03:57:37.347987 11654 sgd_solver.cpp:112] Iteration 29810, lr = 0.1
I0524 03:57:44.100805 11654 solver.cpp:239] Iteration 29820 (1.48084 iter/s, 6.75293s/10 iters), loss = 5.3894
I0524 03:57:44.100841 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3894 (* 1 = 5.3894 loss)
I0524 03:57:44.100855 11654 sgd_solver.cpp:112] Iteration 29820, lr = 0.1
I0524 03:57:50.862205 11654 solver.cpp:239] Iteration 29830 (1.47905 iter/s, 6.7611s/10 iters), loss = 5.73047
I0524 03:57:50.862253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73047 (* 1 = 5.73047 loss)
I0524 03:57:50.862269 11654 sgd_solver.cpp:112] Iteration 29830, lr = 0.1
I0524 03:57:59.943352 11654 solver.cpp:239] Iteration 29840 (1.10123 iter/s, 9.08075s/10 iters), loss = 6.68624
I0524 03:57:59.943408 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68624 (* 1 = 6.68624 loss)
I0524 03:57:59.943552 11654 sgd_solver.cpp:112] Iteration 29840, lr = 0.1
I0524 03:58:06.477998 11654 solver.cpp:239] Iteration 29850 (1.53038 iter/s, 6.53434s/10 iters), loss = 6.38904
I0524 03:58:06.478044 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38904 (* 1 = 6.38904 loss)
I0524 03:58:06.479176 11654 sgd_solver.cpp:112] Iteration 29850, lr = 0.1
I0524 03:58:12.919191 11654 solver.cpp:239] Iteration 29860 (1.55258 iter/s, 6.44089s/10 iters), loss = 6.20645
I0524 03:58:12.919294 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20645 (* 1 = 6.20645 loss)
I0524 03:58:12.919312 11654 sgd_solver.cpp:112] Iteration 29860, lr = 0.1
I0524 03:58:19.698810 11654 solver.cpp:239] Iteration 29870 (1.47555 iter/s, 6.77715s/10 iters), loss = 6.25223
I0524 03:58:19.698873 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25223 (* 1 = 6.25223 loss)
I0524 03:58:19.699484 11654 sgd_solver.cpp:112] Iteration 29870, lr = 0.1
I0524 03:58:27.291400 11654 solver.cpp:239] Iteration 29880 (1.31714 iter/s, 7.59223s/10 iters), loss = 6.38687
I0524 03:58:27.291453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38687 (* 1 = 6.38687 loss)
I0524 03:58:27.291469 11654 sgd_solver.cpp:112] Iteration 29880, lr = 0.1
I0524 03:58:35.152652 11654 solver.cpp:239] Iteration 29890 (1.27214 iter/s, 7.86076s/10 iters), loss = 6.80674
I0524 03:58:35.152695 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80674 (* 1 = 6.80674 loss)
I0524 03:58:35.723465 11654 sgd_solver.cpp:112] Iteration 29890, lr = 0.1
I0524 03:58:42.709703 11654 solver.cpp:239] Iteration 29900 (1.32333 iter/s, 7.5567s/10 iters), loss = 7.15024
I0524 03:58:42.709760 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15024 (* 1 = 7.15024 loss)
I0524 03:58:42.709781 11654 sgd_solver.cpp:112] Iteration 29900, lr = 0.1
I0524 03:58:50.963009 11654 solver.cpp:239] Iteration 29910 (1.21169 iter/s, 8.25293s/10 iters), loss = 6.45749
I0524 03:58:50.963160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45749 (* 1 = 6.45749 loss)
I0524 03:58:51.476336 11654 sgd_solver.cpp:112] Iteration 29910, lr = 0.1
I0524 03:58:58.548753 11654 solver.cpp:239] Iteration 29920 (1.31834 iter/s, 7.58531s/10 iters), loss = 6.06495
I0524 03:58:58.548810 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06495 (* 1 = 6.06495 loss)
I0524 03:58:58.548825 11654 sgd_solver.cpp:112] Iteration 29920, lr = 0.1
I0524 03:59:05.465909 11654 solver.cpp:239] Iteration 29930 (1.44621 iter/s, 6.91461s/10 iters), loss = 6.2144
I0524 03:59:05.465975 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2144 (* 1 = 6.2144 loss)
I0524 03:59:05.466307 11654 sgd_solver.cpp:112] Iteration 29930, lr = 0.1
I0524 03:59:11.554740 11654 solver.cpp:239] Iteration 29940 (1.64243 iter/s, 6.08852s/10 iters), loss = 6.23204
I0524 03:59:11.554806 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23204 (* 1 = 6.23204 loss)
I0524 03:59:11.555198 11654 sgd_solver.cpp:112] Iteration 29940, lr = 0.1
I0524 03:59:19.310505 11654 solver.cpp:239] Iteration 29950 (1.28943 iter/s, 7.75538s/10 iters), loss = 6.60617
I0524 03:59:19.310554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60617 (* 1 = 6.60617 loss)
I0524 03:59:19.550053 11654 sgd_solver.cpp:112] Iteration 29950, lr = 0.1
I0524 03:59:26.216325 11654 solver.cpp:239] Iteration 29960 (1.44812 iter/s, 6.9055s/10 iters), loss = 6.02399
I0524 03:59:26.216639 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02399 (* 1 = 6.02399 loss)
I0524 03:59:26.224701 11654 sgd_solver.cpp:112] Iteration 29960, lr = 0.1
I0524 03:59:33.591905 11654 solver.cpp:239] Iteration 29970 (1.35593 iter/s, 7.37503s/10 iters), loss = 5.95602
I0524 03:59:33.591955 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95602 (* 1 = 5.95602 loss)
I0524 03:59:33.591974 11654 sgd_solver.cpp:112] Iteration 29970, lr = 0.1
I0524 03:59:40.438439 11654 solver.cpp:239] Iteration 29980 (1.46067 iter/s, 6.84615s/10 iters), loss = 6.65869
I0524 03:59:40.438480 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65869 (* 1 = 6.65869 loss)
I0524 03:59:40.438495 11654 sgd_solver.cpp:112] Iteration 29980, lr = 0.1
I0524 03:59:47.142612 11654 solver.cpp:239] Iteration 29990 (1.49218 iter/s, 6.7016s/10 iters), loss = 6.69308
I0524 03:59:47.142666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69308 (* 1 = 6.69308 loss)
I0524 03:59:47.142774 11654 sgd_solver.cpp:112] Iteration 29990, lr = 0.1
I0524 03:59:53.444326 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_30000.caffemodel
I0524 03:59:53.606997 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_30000.solverstate
I0524 03:59:54.222610 11654 solver.cpp:239] Iteration 30000 (1.41249 iter/s, 7.07968s/10 iters), loss = 7.50378
I0524 03:59:54.222657 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50378 (* 1 = 7.50378 loss)
I0524 03:59:54.222872 11654 sgd_solver.cpp:112] Iteration 30000, lr = 0.1
I0524 04:00:01.211982 11654 solver.cpp:239] Iteration 30010 (1.43081 iter/s, 6.98906s/10 iters), loss = 5.33618
I0524 04:00:01.212246 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.33618 (* 1 = 5.33618 loss)
I0524 04:00:01.212298 11654 sgd_solver.cpp:112] Iteration 30010, lr = 0.1
I0524 04:00:10.559142 11654 solver.cpp:239] Iteration 30020 (1.06991 iter/s, 9.34655s/10 iters), loss = 6.67148
I0524 04:00:10.559200 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67148 (* 1 = 6.67148 loss)
I0524 04:00:10.559371 11654 sgd_solver.cpp:112] Iteration 30020, lr = 0.1
I0524 04:00:18.638022 11654 solver.cpp:239] Iteration 30030 (1.23785 iter/s, 8.07852s/10 iters), loss = 6.45168
I0524 04:00:18.638077 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45168 (* 1 = 6.45168 loss)
I0524 04:00:18.832720 11654 sgd_solver.cpp:112] Iteration 30030, lr = 0.1
I0524 04:00:27.259269 11654 solver.cpp:239] Iteration 30040 (1.15998 iter/s, 8.62086s/10 iters), loss = 6.0923
I0524 04:00:27.259321 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0923 (* 1 = 6.0923 loss)
I0524 04:00:27.259337 11654 sgd_solver.cpp:112] Iteration 30040, lr = 0.1
I0524 04:00:35.693908 11654 solver.cpp:239] Iteration 30050 (1.18564 iter/s, 8.43427s/10 iters), loss = 6.41796
I0524 04:00:35.694131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41796 (* 1 = 6.41796 loss)
I0524 04:00:35.694185 11654 sgd_solver.cpp:112] Iteration 30050, lr = 0.1
I0524 04:00:43.105454 11654 solver.cpp:239] Iteration 30060 (1.34934 iter/s, 7.41105s/10 iters), loss = 5.83413
I0524 04:00:43.105507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83413 (* 1 = 5.83413 loss)
I0524 04:00:43.105523 11654 sgd_solver.cpp:112] Iteration 30060, lr = 0.1
I0524 04:00:49.688905 11654 solver.cpp:239] Iteration 30070 (1.51903 iter/s, 6.58315s/10 iters), loss = 5.84278
I0524 04:00:49.688957 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84278 (* 1 = 5.84278 loss)
I0524 04:00:49.689478 11654 sgd_solver.cpp:112] Iteration 30070, lr = 0.1
I0524 04:00:55.989136 11654 solver.cpp:239] Iteration 30080 (1.58732 iter/s, 6.29994s/10 iters), loss = 6.73597
I0524 04:00:55.989178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73597 (* 1 = 6.73597 loss)
I0524 04:00:56.330902 11654 sgd_solver.cpp:112] Iteration 30080, lr = 0.1
I0524 04:01:03.287392 11654 solver.cpp:239] Iteration 30090 (1.37025 iter/s, 7.29791s/10 iters), loss = 6.00624
I0524 04:01:03.287454 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00624 (* 1 = 6.00624 loss)
I0524 04:01:03.289043 11654 sgd_solver.cpp:112] Iteration 30090, lr = 0.1
I0524 04:01:09.847569 11654 solver.cpp:239] Iteration 30100 (1.52442 iter/s, 6.55986s/10 iters), loss = 7.10927
I0524 04:01:09.847728 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10927 (* 1 = 7.10927 loss)
I0524 04:01:11.110906 11654 sgd_solver.cpp:112] Iteration 30100, lr = 0.1
I0524 04:01:19.149581 11654 solver.cpp:239] Iteration 30110 (1.07509 iter/s, 9.30151s/10 iters), loss = 7.35489
I0524 04:01:19.149631 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.35489 (* 1 = 7.35489 loss)
I0524 04:01:19.149647 11654 sgd_solver.cpp:112] Iteration 30110, lr = 0.1
I0524 04:01:26.685638 11654 solver.cpp:239] Iteration 30120 (1.32705 iter/s, 7.53554s/10 iters), loss = 6.08684
I0524 04:01:26.685690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08684 (* 1 = 6.08684 loss)
I0524 04:01:26.884979 11654 sgd_solver.cpp:112] Iteration 30120, lr = 0.1
I0524 04:01:35.364691 11654 solver.cpp:239] Iteration 30130 (1.15225 iter/s, 8.67867s/10 iters), loss = 6.00585
I0524 04:01:35.364742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00585 (* 1 = 6.00585 loss)
I0524 04:01:35.365170 11654 sgd_solver.cpp:112] Iteration 30130, lr = 0.1
I0524 04:01:42.912498 11654 solver.cpp:239] Iteration 30140 (1.32495 iter/s, 7.54746s/10 iters), loss = 6.6114
I0524 04:01:42.912788 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6114 (* 1 = 6.6114 loss)
I0524 04:01:43.480453 11654 sgd_solver.cpp:112] Iteration 30140, lr = 0.1
I0524 04:01:52.172785 11654 solver.cpp:239] Iteration 30150 (1.07995 iter/s, 9.25972s/10 iters), loss = 6.02036
I0524 04:01:52.172828 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02036 (* 1 = 6.02036 loss)
I0524 04:01:52.172842 11654 sgd_solver.cpp:112] Iteration 30150, lr = 0.1
I0524 04:02:00.259166 11654 solver.cpp:239] Iteration 30160 (1.23704 iter/s, 8.0838s/10 iters), loss = 7.54445
I0524 04:02:00.259227 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54445 (* 1 = 7.54445 loss)
I0524 04:02:00.259259 11654 sgd_solver.cpp:112] Iteration 30160, lr = 0.1
I0524 04:02:06.180173 11654 solver.cpp:239] Iteration 30170 (1.68898 iter/s, 5.92072s/10 iters), loss = 6.34654
I0524 04:02:06.180222 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34654 (* 1 = 6.34654 loss)
I0524 04:02:06.180236 11654 sgd_solver.cpp:112] Iteration 30170, lr = 0.1
I0524 04:02:12.680794 11654 solver.cpp:239] Iteration 30180 (1.53839 iter/s, 6.50032s/10 iters), loss = 7.35775
I0524 04:02:12.680840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.35775 (* 1 = 7.35775 loss)
I0524 04:02:12.680852 11654 sgd_solver.cpp:112] Iteration 30180, lr = 0.1
I0524 04:02:19.731613 11654 solver.cpp:239] Iteration 30190 (1.41837 iter/s, 7.05034s/10 iters), loss = 6.02913
I0524 04:02:19.731863 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02913 (* 1 = 6.02913 loss)
I0524 04:02:19.731968 11654 sgd_solver.cpp:112] Iteration 30190, lr = 0.1
I0524 04:02:28.014624 11654 solver.cpp:239] Iteration 30200 (1.20737 iter/s, 8.28249s/10 iters), loss = 6.59623
I0524 04:02:28.014678 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59623 (* 1 = 6.59623 loss)
I0524 04:02:28.014711 11654 sgd_solver.cpp:112] Iteration 30200, lr = 0.1
I0524 04:02:35.699913 11654 solver.cpp:239] Iteration 30210 (1.30126 iter/s, 7.68487s/10 iters), loss = 6.54486
I0524 04:02:35.699965 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54486 (* 1 = 6.54486 loss)
I0524 04:02:35.699981 11654 sgd_solver.cpp:112] Iteration 30210, lr = 0.1
I0524 04:02:43.332926 11654 solver.cpp:239] Iteration 30220 (1.31017 iter/s, 7.63259s/10 iters), loss = 6.51076
I0524 04:02:43.332981 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51076 (* 1 = 6.51076 loss)
I0524 04:02:43.332999 11654 sgd_solver.cpp:112] Iteration 30220, lr = 0.1
I0524 04:02:50.135917 11654 solver.cpp:239] Iteration 30230 (1.47003 iter/s, 6.8026s/10 iters), loss = 5.31528
I0524 04:02:50.136068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.31528 (* 1 = 5.31528 loss)
I0524 04:02:50.136091 11654 sgd_solver.cpp:112] Iteration 30230, lr = 0.1
I0524 04:02:56.766042 11654 solver.cpp:239] Iteration 30240 (1.50838 iter/s, 6.62963s/10 iters), loss = 5.78671
I0524 04:02:56.766095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78671 (* 1 = 5.78671 loss)
I0524 04:02:56.823846 11654 sgd_solver.cpp:112] Iteration 30240, lr = 0.1
I0524 04:03:03.036926 11654 solver.cpp:239] Iteration 30250 (1.59475 iter/s, 6.27059s/10 iters), loss = 6.62922
I0524 04:03:03.036973 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62922 (* 1 = 6.62922 loss)
I0524 04:03:03.037406 11654 sgd_solver.cpp:112] Iteration 30250, lr = 0.1
I0524 04:03:09.673498 11654 solver.cpp:239] Iteration 30260 (1.50687 iter/s, 6.63627s/10 iters), loss = 6.46779
I0524 04:03:09.673552 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46779 (* 1 = 6.46779 loss)
I0524 04:03:09.673568 11654 sgd_solver.cpp:112] Iteration 30260, lr = 0.1
I0524 04:03:16.760886 11654 solver.cpp:239] Iteration 30270 (1.41102 iter/s, 7.08706s/10 iters), loss = 6.23373
I0524 04:03:16.760948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23373 (* 1 = 6.23373 loss)
I0524 04:03:16.761003 11654 sgd_solver.cpp:112] Iteration 30270, lr = 0.1
I0524 04:03:22.779142 11654 solver.cpp:239] Iteration 30280 (1.66169 iter/s, 6.01797s/10 iters), loss = 6.37099
I0524 04:03:22.779390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37099 (* 1 = 6.37099 loss)
I0524 04:03:22.779444 11654 sgd_solver.cpp:112] Iteration 30280, lr = 0.1
I0524 04:03:29.566573 11654 solver.cpp:239] Iteration 30290 (1.47342 iter/s, 6.78695s/10 iters), loss = 4.91612
I0524 04:03:29.566625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.91612 (* 1 = 4.91612 loss)
I0524 04:03:31.063797 11654 sgd_solver.cpp:112] Iteration 30290, lr = 0.1
I0524 04:03:37.408725 11654 solver.cpp:239] Iteration 30300 (1.27522 iter/s, 7.8418s/10 iters), loss = 7.24952
I0524 04:03:37.408787 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24952 (* 1 = 7.24952 loss)
I0524 04:03:37.408805 11654 sgd_solver.cpp:112] Iteration 30300, lr = 0.1
I0524 04:03:45.738179 11654 solver.cpp:239] Iteration 30310 (1.20093 iter/s, 8.32687s/10 iters), loss = 7.21694
I0524 04:03:45.738227 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21694 (* 1 = 7.21694 loss)
I0524 04:03:45.738808 11654 sgd_solver.cpp:112] Iteration 30310, lr = 0.1
I0524 04:03:51.860877 11654 solver.cpp:239] Iteration 30320 (1.63334 iter/s, 6.12241s/10 iters), loss = 5.55433
I0524 04:03:51.860934 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55433 (* 1 = 5.55433 loss)
I0524 04:03:51.861176 11654 sgd_solver.cpp:112] Iteration 30320, lr = 0.1
I0524 04:03:58.566737 11654 solver.cpp:239] Iteration 30330 (1.4913 iter/s, 6.70554s/10 iters), loss = 7.12267
I0524 04:03:58.566862 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12267 (* 1 = 7.12267 loss)
I0524 04:03:58.566877 11654 sgd_solver.cpp:112] Iteration 30330, lr = 0.1
I0524 04:04:05.658771 11654 solver.cpp:239] Iteration 30340 (1.41022 iter/s, 7.09108s/10 iters), loss = 6.99173
I0524 04:04:05.658828 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99173 (* 1 = 6.99173 loss)
I0524 04:04:05.658964 11654 sgd_solver.cpp:112] Iteration 30340, lr = 0.1
I0524 04:04:11.930438 11654 solver.cpp:239] Iteration 30350 (1.59455 iter/s, 6.27137s/10 iters), loss = 6.12046
I0524 04:04:11.930493 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12046 (* 1 = 6.12046 loss)
I0524 04:04:12.374666 11654 sgd_solver.cpp:112] Iteration 30350, lr = 0.1
I0524 04:04:19.424547 11654 solver.cpp:239] Iteration 30360 (1.33444 iter/s, 7.49377s/10 iters), loss = 6.14857
I0524 04:04:19.424585 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14857 (* 1 = 6.14857 loss)
I0524 04:04:20.370059 11654 sgd_solver.cpp:112] Iteration 30360, lr = 0.1
I0524 04:04:26.872553 11654 solver.cpp:239] Iteration 30370 (1.3427 iter/s, 7.44767s/10 iters), loss = 5.29961
I0524 04:04:26.872609 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29961 (* 1 = 5.29961 loss)
I0524 04:04:26.945653 11654 sgd_solver.cpp:112] Iteration 30370, lr = 0.1
I0524 04:04:32.791338 11654 solver.cpp:239] Iteration 30380 (1.68962 iter/s, 5.91851s/10 iters), loss = 6.20316
I0524 04:04:32.791815 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20316 (* 1 = 6.20316 loss)
I0524 04:04:32.791838 11654 sgd_solver.cpp:112] Iteration 30380, lr = 0.1
I0524 04:04:40.675298 11654 solver.cpp:239] Iteration 30390 (1.26865 iter/s, 7.88238s/10 iters), loss = 7.21783
I0524 04:04:40.675349 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21783 (* 1 = 7.21783 loss)
I0524 04:04:40.675451 11654 sgd_solver.cpp:112] Iteration 30390, lr = 0.1
I0524 04:04:47.332008 11654 solver.cpp:239] Iteration 30400 (1.50231 iter/s, 6.65641s/10 iters), loss = 7.25536
I0524 04:04:47.332058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25536 (* 1 = 7.25536 loss)
I0524 04:04:47.332073 11654 sgd_solver.cpp:112] Iteration 30400, lr = 0.1
I0524 04:04:54.552762 11654 solver.cpp:239] Iteration 30410 (1.38497 iter/s, 7.22037s/10 iters), loss = 6.59506
I0524 04:04:54.552805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59506 (* 1 = 6.59506 loss)
I0524 04:04:54.552819 11654 sgd_solver.cpp:112] Iteration 30410, lr = 0.1
I0524 04:05:01.611404 11654 solver.cpp:239] Iteration 30420 (1.41677 iter/s, 7.05832s/10 iters), loss = 6.44376
I0524 04:05:01.611460 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44376 (* 1 = 6.44376 loss)
I0524 04:05:01.611555 11654 sgd_solver.cpp:112] Iteration 30420, lr = 0.1
I0524 04:05:09.857841 11654 solver.cpp:239] Iteration 30430 (1.2127 iter/s, 8.24606s/10 iters), loss = 6.62375
I0524 04:05:09.858144 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62375 (* 1 = 6.62375 loss)
I0524 04:05:09.858516 11654 sgd_solver.cpp:112] Iteration 30430, lr = 0.1
I0524 04:05:16.351770 11654 solver.cpp:239] Iteration 30440 (1.54002 iter/s, 6.49344s/10 iters), loss = 5.95636
I0524 04:05:16.351824 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95636 (* 1 = 5.95636 loss)
I0524 04:05:16.382097 11654 sgd_solver.cpp:112] Iteration 30440, lr = 0.1
I0524 04:05:22.810740 11654 solver.cpp:239] Iteration 30450 (1.54831 iter/s, 6.45867s/10 iters), loss = 6.78891
I0524 04:05:22.810788 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78891 (* 1 = 6.78891 loss)
I0524 04:05:22.810976 11654 sgd_solver.cpp:112] Iteration 30450, lr = 0.1
I0524 04:05:30.008196 11654 solver.cpp:239] Iteration 30460 (1.38944 iter/s, 7.19712s/10 iters), loss = 6.31774
I0524 04:05:30.008249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31774 (* 1 = 6.31774 loss)
I0524 04:05:30.010200 11654 sgd_solver.cpp:112] Iteration 30460, lr = 0.1
I0524 04:05:36.391408 11654 solver.cpp:239] Iteration 30470 (1.56668 iter/s, 6.38292s/10 iters), loss = 6.80593
I0524 04:05:36.391450 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80593 (* 1 = 6.80593 loss)
I0524 04:05:36.391463 11654 sgd_solver.cpp:112] Iteration 30470, lr = 0.1
I0524 04:05:43.362171 11654 solver.cpp:239] Iteration 30480 (1.43463 iter/s, 6.97045s/10 iters), loss = 5.96759
I0524 04:05:43.362514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96759 (* 1 = 5.96759 loss)
I0524 04:05:43.362581 11654 sgd_solver.cpp:112] Iteration 30480, lr = 0.1
I0524 04:05:49.531961 11654 solver.cpp:239] Iteration 30490 (1.62097 iter/s, 6.16916s/10 iters), loss = 5.92517
I0524 04:05:49.532017 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92517 (* 1 = 5.92517 loss)
I0524 04:05:49.532033 11654 sgd_solver.cpp:112] Iteration 30490, lr = 0.1
I0524 04:05:57.671537 11654 solver.cpp:239] Iteration 30500 (1.22895 iter/s, 8.137s/10 iters), loss = 6.25341
I0524 04:05:57.671592 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25341 (* 1 = 6.25341 loss)
I0524 04:05:57.672041 11654 sgd_solver.cpp:112] Iteration 30500, lr = 0.1
I0524 04:06:04.287140 11654 solver.cpp:239] Iteration 30510 (1.51165 iter/s, 6.61529s/10 iters), loss = 6.1779
I0524 04:06:04.287199 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1779 (* 1 = 6.1779 loss)
I0524 04:06:04.287308 11654 sgd_solver.cpp:112] Iteration 30510, lr = 0.1
I0524 04:06:10.595798 11654 solver.cpp:239] Iteration 30520 (1.5852 iter/s, 6.30836s/10 iters), loss = 6.50891
I0524 04:06:10.595851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50891 (* 1 = 6.50891 loss)
I0524 04:06:10.604887 11654 sgd_solver.cpp:112] Iteration 30520, lr = 0.1
I0524 04:06:18.979836 11654 solver.cpp:239] Iteration 30530 (1.1928 iter/s, 8.38366s/10 iters), loss = 6.48351
I0524 04:06:18.979951 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48351 (* 1 = 6.48351 loss)
I0524 04:06:18.979976 11654 sgd_solver.cpp:112] Iteration 30530, lr = 0.1
I0524 04:06:26.351373 11654 solver.cpp:239] Iteration 30540 (1.35705 iter/s, 7.36893s/10 iters), loss = 6.62684
I0524 04:06:26.351430 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62684 (* 1 = 6.62684 loss)
I0524 04:06:26.819378 11654 sgd_solver.cpp:112] Iteration 30540, lr = 0.1
I0524 04:06:34.035449 11654 solver.cpp:239] Iteration 30550 (1.30145 iter/s, 7.68373s/10 iters), loss = 6.50683
I0524 04:06:34.035492 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50683 (* 1 = 6.50683 loss)
I0524 04:06:34.035729 11654 sgd_solver.cpp:112] Iteration 30550, lr = 0.1
I0524 04:06:42.151564 11654 solver.cpp:239] Iteration 30560 (1.23217 iter/s, 8.11576s/10 iters), loss = 6.47785
I0524 04:06:42.151613 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47785 (* 1 = 6.47785 loss)
I0524 04:06:42.151628 11654 sgd_solver.cpp:112] Iteration 30560, lr = 0.1
I0524 04:06:51.245940 11654 solver.cpp:239] Iteration 30570 (1.09963 iter/s, 9.09398s/10 iters), loss = 6.73947
I0524 04:06:51.246065 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73947 (* 1 = 6.73947 loss)
I0524 04:06:51.246083 11654 sgd_solver.cpp:112] Iteration 30570, lr = 0.1
I0524 04:06:58.290323 11654 solver.cpp:239] Iteration 30580 (1.41966 iter/s, 7.04396s/10 iters), loss = 6.48645
I0524 04:06:58.290390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48645 (* 1 = 6.48645 loss)
I0524 04:06:58.323709 11654 sgd_solver.cpp:112] Iteration 30580, lr = 0.1
I0524 04:07:04.638017 11654 solver.cpp:239] Iteration 30590 (1.57545 iter/s, 6.34738s/10 iters), loss = 6.36084
I0524 04:07:04.638084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36084 (* 1 = 6.36084 loss)
I0524 04:07:04.638236 11654 sgd_solver.cpp:112] Iteration 30590, lr = 0.1
I0524 04:07:11.606884 11654 solver.cpp:239] Iteration 30600 (1.43502 iter/s, 6.96854s/10 iters), loss = 7.48004
I0524 04:07:11.606935 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48004 (* 1 = 7.48004 loss)
I0524 04:07:11.606956 11654 sgd_solver.cpp:112] Iteration 30600, lr = 0.1
I0524 04:07:19.502506 11654 solver.cpp:239] Iteration 30610 (1.26659 iter/s, 7.8952s/10 iters), loss = 6.75476
I0524 04:07:19.502557 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75476 (* 1 = 6.75476 loss)
I0524 04:07:19.502573 11654 sgd_solver.cpp:112] Iteration 30610, lr = 0.1
I0524 04:07:29.208534 11654 solver.cpp:239] Iteration 30620 (1.03034 iter/s, 9.70554s/10 iters), loss = 6.13741
I0524 04:07:29.208690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13741 (* 1 = 6.13741 loss)
I0524 04:07:29.216514 11654 sgd_solver.cpp:112] Iteration 30620, lr = 0.1
I0524 04:07:35.670600 11654 solver.cpp:239] Iteration 30630 (1.54758 iter/s, 6.46169s/10 iters), loss = 6.63671
I0524 04:07:35.670644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63671 (* 1 = 6.63671 loss)
I0524 04:07:35.670825 11654 sgd_solver.cpp:112] Iteration 30630, lr = 0.1
I0524 04:07:41.789270 11654 solver.cpp:239] Iteration 30640 (1.63442 iter/s, 6.11839s/10 iters), loss = 5.94768
I0524 04:07:41.789322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94768 (* 1 = 5.94768 loss)
I0524 04:07:41.789340 11654 sgd_solver.cpp:112] Iteration 30640, lr = 0.1
I0524 04:07:48.264194 11654 solver.cpp:239] Iteration 30650 (1.54451 iter/s, 6.47456s/10 iters), loss = 6.86731
I0524 04:07:48.264231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86731 (* 1 = 6.86731 loss)
I0524 04:07:48.618770 11654 sgd_solver.cpp:112] Iteration 30650, lr = 0.1
I0524 04:07:55.575959 11654 solver.cpp:239] Iteration 30660 (1.36772 iter/s, 7.31144s/10 iters), loss = 6.10701
I0524 04:07:55.576009 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10701 (* 1 = 6.10701 loss)
I0524 04:07:55.576169 11654 sgd_solver.cpp:112] Iteration 30660, lr = 0.1
I0524 04:08:01.641839 11654 solver.cpp:239] Iteration 30670 (1.64864 iter/s, 6.06559s/10 iters), loss = 6.41102
I0524 04:08:01.641949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41102 (* 1 = 6.41102 loss)
I0524 04:08:01.641969 11654 sgd_solver.cpp:112] Iteration 30670, lr = 0.1
I0524 04:08:08.617739 11654 solver.cpp:239] Iteration 30680 (1.43359 iter/s, 6.97548s/10 iters), loss = 6.20602
I0524 04:08:08.617795 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20602 (* 1 = 6.20602 loss)
I0524 04:08:09.293397 11654 sgd_solver.cpp:112] Iteration 30680, lr = 0.1
I0524 04:08:15.809190 11654 solver.cpp:239] Iteration 30690 (1.3906 iter/s, 7.19112s/10 iters), loss = 6.38631
I0524 04:08:15.809245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38631 (* 1 = 6.38631 loss)
I0524 04:08:15.809334 11654 sgd_solver.cpp:112] Iteration 30690, lr = 0.1
I0524 04:08:22.768183 11654 solver.cpp:239] Iteration 30700 (1.43706 iter/s, 6.95867s/10 iters), loss = 6.69836
I0524 04:08:22.768241 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69836 (* 1 = 6.69836 loss)
I0524 04:08:22.791139 11654 sgd_solver.cpp:112] Iteration 30700, lr = 0.1
I0524 04:08:33.167496 11654 solver.cpp:239] Iteration 30710 (0.961644 iter/s, 10.3989s/10 iters), loss = 5.89532
I0524 04:08:33.167770 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89532 (* 1 = 5.89532 loss)
I0524 04:08:33.168825 11654 sgd_solver.cpp:112] Iteration 30710, lr = 0.1
I0524 04:08:39.533284 11654 solver.cpp:239] Iteration 30720 (1.57102 iter/s, 6.36528s/10 iters), loss = 6.85056
I0524 04:08:39.533368 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85056 (* 1 = 6.85056 loss)
I0524 04:08:39.533571 11654 sgd_solver.cpp:112] Iteration 30720, lr = 0.1
I0524 04:08:47.078753 11654 solver.cpp:239] Iteration 30730 (1.32537 iter/s, 7.54508s/10 iters), loss = 5.74463
I0524 04:08:47.078802 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74463 (* 1 = 5.74463 loss)
I0524 04:08:47.424505 11654 sgd_solver.cpp:112] Iteration 30730, lr = 0.1
I0524 04:08:54.776051 11654 solver.cpp:239] Iteration 30740 (1.29922 iter/s, 7.69694s/10 iters), loss = 6.57879
I0524 04:08:54.776111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57879 (* 1 = 6.57879 loss)
I0524 04:08:54.776435 11654 sgd_solver.cpp:112] Iteration 30740, lr = 0.1
I0524 04:09:03.196349 11654 solver.cpp:239] Iteration 30750 (1.18766 iter/s, 8.41992s/10 iters), loss = 6.34645
I0524 04:09:03.196637 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34645 (* 1 = 6.34645 loss)
I0524 04:09:03.196696 11654 sgd_solver.cpp:112] Iteration 30750, lr = 0.1
I0524 04:09:09.587105 11654 solver.cpp:239] Iteration 30760 (1.56488 iter/s, 6.39027s/10 iters), loss = 5.80773
I0524 04:09:09.587146 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80773 (* 1 = 5.80773 loss)
I0524 04:09:10.004842 11654 sgd_solver.cpp:112] Iteration 30760, lr = 0.1
I0524 04:09:16.193210 11654 solver.cpp:239] Iteration 30770 (1.51382 iter/s, 6.6058s/10 iters), loss = 5.64615
I0524 04:09:16.193271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64615 (* 1 = 5.64615 loss)
I0524 04:09:16.193871 11654 sgd_solver.cpp:112] Iteration 30770, lr = 0.1
I0524 04:09:22.201447 11654 solver.cpp:239] Iteration 30780 (1.66446 iter/s, 6.00795s/10 iters), loss = 5.4914
I0524 04:09:22.201504 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4914 (* 1 = 5.4914 loss)
I0524 04:09:22.201520 11654 sgd_solver.cpp:112] Iteration 30780, lr = 0.1
I0524 04:09:28.375018 11654 solver.cpp:239] Iteration 30790 (1.61991 iter/s, 6.1732s/10 iters), loss = 6.07143
I0524 04:09:28.375074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07143 (* 1 = 6.07143 loss)
I0524 04:09:28.533002 11654 sgd_solver.cpp:112] Iteration 30790, lr = 0.1
I0524 04:09:35.451663 11654 solver.cpp:239] Iteration 30800 (1.41316 iter/s, 7.07633s/10 iters), loss = 7.19766
I0524 04:09:35.451890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19766 (* 1 = 7.19766 loss)
I0524 04:09:35.451932 11654 sgd_solver.cpp:112] Iteration 30800, lr = 0.1
I0524 04:09:43.422541 11654 solver.cpp:239] Iteration 30810 (1.25465 iter/s, 7.97034s/10 iters), loss = 6.00196
I0524 04:09:43.422598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00196 (* 1 = 6.00196 loss)
I0524 04:09:43.422616 11654 sgd_solver.cpp:112] Iteration 30810, lr = 0.1
I0524 04:09:51.434439 11654 solver.cpp:239] Iteration 30820 (1.24854 iter/s, 8.00933s/10 iters), loss = 7.17521
I0524 04:09:51.434495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17521 (* 1 = 7.17521 loss)
I0524 04:09:51.434510 11654 sgd_solver.cpp:112] Iteration 30820, lr = 0.1
I0524 04:09:59.847105 11654 solver.cpp:239] Iteration 30830 (1.18904 iter/s, 8.41014s/10 iters), loss = 6.61111
I0524 04:09:59.847139 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61111 (* 1 = 6.61111 loss)
I0524 04:09:59.847156 11654 sgd_solver.cpp:112] Iteration 30830, lr = 0.1
I0524 04:10:05.865299 11654 solver.cpp:239] Iteration 30840 (1.66171 iter/s, 6.01791s/10 iters), loss = 6.19615
I0524 04:10:05.865417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19615 (* 1 = 6.19615 loss)
I0524 04:10:05.865772 11654 sgd_solver.cpp:112] Iteration 30840, lr = 0.1
I0524 04:10:12.612833 11654 solver.cpp:239] Iteration 30850 (1.4821 iter/s, 6.74716s/10 iters), loss = 6.32635
I0524 04:10:12.612886 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32635 (* 1 = 6.32635 loss)
I0524 04:10:12.625844 11654 sgd_solver.cpp:112] Iteration 30850, lr = 0.1
I0524 04:10:19.052585 11654 solver.cpp:239] Iteration 30860 (1.55293 iter/s, 6.43946s/10 iters), loss = 6.60755
I0524 04:10:19.052621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60755 (* 1 = 6.60755 loss)
I0524 04:10:19.113085 11654 sgd_solver.cpp:112] Iteration 30860, lr = 0.1
I0524 04:10:25.474344 11654 solver.cpp:239] Iteration 30870 (1.55728 iter/s, 6.42146s/10 iters), loss = 7.08516
I0524 04:10:25.474411 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08516 (* 1 = 7.08516 loss)
I0524 04:10:25.474763 11654 sgd_solver.cpp:112] Iteration 30870, lr = 0.1
I0524 04:10:33.465209 11654 solver.cpp:239] Iteration 30880 (1.25149 iter/s, 7.9905s/10 iters), loss = 6.47933
I0524 04:10:33.465253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47933 (* 1 = 6.47933 loss)
I0524 04:10:33.465674 11654 sgd_solver.cpp:112] Iteration 30880, lr = 0.1
I0524 04:10:41.544064 11654 solver.cpp:239] Iteration 30890 (1.23785 iter/s, 8.07849s/10 iters), loss = 6.36011
I0524 04:10:41.544253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36011 (* 1 = 6.36011 loss)
I0524 04:10:41.544276 11654 sgd_solver.cpp:112] Iteration 30890, lr = 0.1
I0524 04:10:48.675653 11654 solver.cpp:239] Iteration 30900 (1.4027 iter/s, 7.12908s/10 iters), loss = 6.8644
I0524 04:10:48.675706 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8644 (* 1 = 6.8644 loss)
I0524 04:10:48.675724 11654 sgd_solver.cpp:112] Iteration 30900, lr = 0.1
I0524 04:10:55.211143 11654 solver.cpp:239] Iteration 30910 (1.53019 iter/s, 6.53513s/10 iters), loss = 6.30525
I0524 04:10:55.211194 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30525 (* 1 = 6.30525 loss)
I0524 04:10:55.211627 11654 sgd_solver.cpp:112] Iteration 30910, lr = 0.1
I0524 04:11:02.087342 11654 solver.cpp:239] Iteration 30920 (1.45436 iter/s, 6.87588s/10 iters), loss = 6.57426
I0524 04:11:02.087391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57426 (* 1 = 6.57426 loss)
I0524 04:11:02.087488 11654 sgd_solver.cpp:112] Iteration 30920, lr = 0.1
I0524 04:11:12.902288 11654 solver.cpp:239] Iteration 30930 (0.924685 iter/s, 10.8145s/10 iters), loss = 6.61783
I0524 04:11:12.902523 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61783 (* 1 = 6.61783 loss)
I0524 04:11:12.902576 11654 sgd_solver.cpp:112] Iteration 30930, lr = 0.1
I0524 04:11:19.345983 11654 solver.cpp:239] Iteration 30940 (1.55252 iter/s, 6.44116s/10 iters), loss = 6.37613
I0524 04:11:19.346040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37613 (* 1 = 6.37613 loss)
I0524 04:11:19.406644 11654 sgd_solver.cpp:112] Iteration 30940, lr = 0.1
I0524 04:11:30.723673 11654 solver.cpp:239] Iteration 30950 (0.87895 iter/s, 11.3772s/10 iters), loss = 7.26725
I0524 04:11:30.723726 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26725 (* 1 = 7.26725 loss)
I0524 04:11:30.723742 11654 sgd_solver.cpp:112] Iteration 30950, lr = 0.1
I0524 04:11:37.463690 11654 solver.cpp:239] Iteration 30960 (1.48376 iter/s, 6.73964s/10 iters), loss = 6.70798
I0524 04:11:37.463743 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70798 (* 1 = 6.70798 loss)
I0524 04:11:37.463762 11654 sgd_solver.cpp:112] Iteration 30960, lr = 0.1
I0524 04:11:43.907014 11654 solver.cpp:239] Iteration 30970 (1.55208 iter/s, 6.44297s/10 iters), loss = 6.56196
I0524 04:11:43.907280 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56196 (* 1 = 6.56196 loss)
I0524 04:11:44.078130 11654 sgd_solver.cpp:112] Iteration 30970, lr = 0.1
I0524 04:11:50.333539 11654 solver.cpp:239] Iteration 30980 (1.55617 iter/s, 6.42605s/10 iters), loss = 5.53359
I0524 04:11:50.333585 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53359 (* 1 = 5.53359 loss)
I0524 04:11:50.706632 11654 sgd_solver.cpp:112] Iteration 30980, lr = 0.1
I0524 04:11:57.919152 11654 solver.cpp:239] Iteration 30990 (1.31834 iter/s, 7.58528s/10 iters), loss = 6.25763
I0524 04:11:57.919203 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25763 (* 1 = 6.25763 loss)
I0524 04:11:57.949539 11654 sgd_solver.cpp:112] Iteration 30990, lr = 0.1
I0524 04:12:05.626096 11654 solver.cpp:239] Iteration 31000 (1.29759 iter/s, 7.7066s/10 iters), loss = 6.31419
I0524 04:12:05.626142 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31419 (* 1 = 6.31419 loss)
I0524 04:12:05.626318 11654 sgd_solver.cpp:112] Iteration 31000, lr = 0.1
I0524 04:12:12.172497 11654 solver.cpp:239] Iteration 31010 (1.52763 iter/s, 6.54609s/10 iters), loss = 6.41936
I0524 04:12:12.172560 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41936 (* 1 = 6.41936 loss)
I0524 04:12:12.172634 11654 sgd_solver.cpp:112] Iteration 31010, lr = 0.1
I0524 04:12:19.242839 11654 solver.cpp:239] Iteration 31020 (1.41442 iter/s, 7.07002s/10 iters), loss = 6.7946
I0524 04:12:19.243101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7946 (* 1 = 6.7946 loss)
I0524 04:12:19.243154 11654 sgd_solver.cpp:112] Iteration 31020, lr = 0.1
I0524 04:12:27.919909 11654 solver.cpp:239] Iteration 31030 (1.1526 iter/s, 8.67605s/10 iters), loss = 6.62342
I0524 04:12:27.919961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62342 (* 1 = 6.62342 loss)
I0524 04:12:27.919976 11654 sgd_solver.cpp:112] Iteration 31030, lr = 0.1
I0524 04:12:34.202428 11654 solver.cpp:239] Iteration 31040 (1.59181 iter/s, 6.28215s/10 iters), loss = 5.36275
I0524 04:12:34.202474 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.36275 (* 1 = 5.36275 loss)
I0524 04:12:34.615700 11654 sgd_solver.cpp:112] Iteration 31040, lr = 0.1
I0524 04:12:42.003299 11654 solver.cpp:239] Iteration 31050 (1.28197 iter/s, 7.80052s/10 iters), loss = 6.76799
I0524 04:12:42.003352 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76799 (* 1 = 6.76799 loss)
I0524 04:12:42.003367 11654 sgd_solver.cpp:112] Iteration 31050, lr = 0.1
I0524 04:12:48.597232 11654 solver.cpp:239] Iteration 31060 (1.51663 iter/s, 6.59356s/10 iters), loss = 6.47817
I0524 04:12:48.597280 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47817 (* 1 = 6.47817 loss)
I0524 04:12:48.597499 11654 sgd_solver.cpp:112] Iteration 31060, lr = 0.1
I0524 04:12:55.828904 11654 solver.cpp:239] Iteration 31070 (1.38287 iter/s, 7.23133s/10 iters), loss = 6.07713
I0524 04:12:55.829167 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07713 (* 1 = 6.07713 loss)
I0524 04:12:55.829216 11654 sgd_solver.cpp:112] Iteration 31070, lr = 0.1
I0524 04:13:02.599869 11654 solver.cpp:239] Iteration 31080 (1.47745 iter/s, 6.76843s/10 iters), loss = 6.25813
I0524 04:13:02.599943 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25813 (* 1 = 6.25813 loss)
I0524 04:13:02.600119 11654 sgd_solver.cpp:112] Iteration 31080, lr = 0.1
I0524 04:13:09.876772 11654 solver.cpp:239] Iteration 31090 (1.37428 iter/s, 7.27656s/10 iters), loss = 6.3538
I0524 04:13:09.876811 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3538 (* 1 = 6.3538 loss)
I0524 04:13:09.876840 11654 sgd_solver.cpp:112] Iteration 31090, lr = 0.1
I0524 04:13:16.816483 11654 solver.cpp:239] Iteration 31100 (1.44105 iter/s, 6.93939s/10 iters), loss = 6.69862
I0524 04:13:16.816536 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69862 (* 1 = 6.69862 loss)
I0524 04:13:17.869298 11654 sgd_solver.cpp:112] Iteration 31100, lr = 0.1
I0524 04:13:24.008527 11654 solver.cpp:239] Iteration 31110 (1.39049 iter/s, 7.19171s/10 iters), loss = 6.35723
I0524 04:13:24.008579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35723 (* 1 = 6.35723 loss)
I0524 04:13:24.008700 11654 sgd_solver.cpp:112] Iteration 31110, lr = 0.1
I0524 04:13:30.283274 11654 solver.cpp:239] Iteration 31120 (1.59376 iter/s, 6.27445s/10 iters), loss = 5.76183
I0524 04:13:30.283370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76183 (* 1 = 5.76183 loss)
I0524 04:13:30.283471 11654 sgd_solver.cpp:112] Iteration 31120, lr = 0.1
I0524 04:13:37.384646 11654 solver.cpp:239] Iteration 31130 (1.40825 iter/s, 7.101s/10 iters), loss = 6.94878
I0524 04:13:37.384704 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94878 (* 1 = 6.94878 loss)
I0524 04:13:37.384724 11654 sgd_solver.cpp:112] Iteration 31130, lr = 0.1
I0524 04:13:43.961668 11654 solver.cpp:239] Iteration 31140 (1.52052 iter/s, 6.57671s/10 iters), loss = 6.47052
I0524 04:13:43.961722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47052 (* 1 = 6.47052 loss)
I0524 04:13:43.961796 11654 sgd_solver.cpp:112] Iteration 31140, lr = 0.1
I0524 04:13:50.593580 11654 solver.cpp:239] Iteration 31150 (1.50793 iter/s, 6.63161s/10 iters), loss = 6.11317
I0524 04:13:50.593632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11317 (* 1 = 6.11317 loss)
I0524 04:13:50.593763 11654 sgd_solver.cpp:112] Iteration 31150, lr = 0.1
I0524 04:13:59.798446 11654 solver.cpp:239] Iteration 31160 (1.08643 iter/s, 9.20447s/10 iters), loss = 6.0779
I0524 04:13:59.798506 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0779 (* 1 = 6.0779 loss)
I0524 04:13:59.798558 11654 sgd_solver.cpp:112] Iteration 31160, lr = 0.1
I0524 04:14:06.224990 11654 solver.cpp:239] Iteration 31170 (1.55612 iter/s, 6.42623s/10 iters), loss = 5.63562
I0524 04:14:06.225297 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63562 (* 1 = 5.63562 loss)
I0524 04:14:06.225371 11654 sgd_solver.cpp:112] Iteration 31170, lr = 0.1
I0524 04:14:12.249531 11654 solver.cpp:239] Iteration 31180 (1.66005 iter/s, 6.02392s/10 iters), loss = 5.80006
I0524 04:14:12.249590 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80006 (* 1 = 5.80006 loss)
I0524 04:14:12.249977 11654 sgd_solver.cpp:112] Iteration 31180, lr = 0.1
I0524 04:14:18.490620 11654 solver.cpp:239] Iteration 31190 (1.60236 iter/s, 6.2408s/10 iters), loss = 5.43904
I0524 04:14:18.490660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.43904 (* 1 = 5.43904 loss)
I0524 04:14:18.490942 11654 sgd_solver.cpp:112] Iteration 31190, lr = 0.1
I0524 04:14:25.891685 11654 solver.cpp:239] Iteration 31200 (1.35122 iter/s, 7.40074s/10 iters), loss = 6.35454
I0524 04:14:25.891739 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35454 (* 1 = 6.35454 loss)
I0524 04:14:25.891757 11654 sgd_solver.cpp:112] Iteration 31200, lr = 0.1
I0524 04:14:32.184047 11654 solver.cpp:239] Iteration 31210 (1.58932 iter/s, 6.292s/10 iters), loss = 7.88942
I0524 04:14:32.184088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.88942 (* 1 = 7.88942 loss)
I0524 04:14:32.184103 11654 sgd_solver.cpp:112] Iteration 31210, lr = 0.1
I0524 04:14:40.746953 11654 solver.cpp:239] Iteration 31220 (1.16788 iter/s, 8.56253s/10 iters), loss = 5.52357
I0524 04:14:40.747212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.52357 (* 1 = 5.52357 loss)
I0524 04:14:40.747268 11654 sgd_solver.cpp:112] Iteration 31220, lr = 0.1
I0524 04:14:48.877944 11654 solver.cpp:239] Iteration 31230 (1.22996 iter/s, 8.13037s/10 iters), loss = 6.38023
I0524 04:14:48.878002 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38023 (* 1 = 6.38023 loss)
I0524 04:14:48.878021 11654 sgd_solver.cpp:112] Iteration 31230, lr = 0.1
I0524 04:14:56.213227 11654 solver.cpp:239] Iteration 31240 (1.36335 iter/s, 7.33489s/10 iters), loss = 6.439
I0524 04:14:56.213264 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.439 (* 1 = 6.439 loss)
I0524 04:14:56.213277 11654 sgd_solver.cpp:112] Iteration 31240, lr = 0.1
I0524 04:15:03.560673 11654 solver.cpp:239] Iteration 31250 (1.36108 iter/s, 7.34712s/10 iters), loss = 6.24288
I0524 04:15:03.560724 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24288 (* 1 = 6.24288 loss)
I0524 04:15:03.560739 11654 sgd_solver.cpp:112] Iteration 31250, lr = 0.1
I0524 04:15:10.171383 11654 solver.cpp:239] Iteration 31260 (1.51281 iter/s, 6.61023s/10 iters), loss = 7.20672
I0524 04:15:10.171428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20672 (* 1 = 7.20672 loss)
I0524 04:15:10.171741 11654 sgd_solver.cpp:112] Iteration 31260, lr = 0.1
I0524 04:15:17.524302 11654 solver.cpp:239] Iteration 31270 (1.36007 iter/s, 7.35258s/10 iters), loss = 6.08224
I0524 04:15:17.524559 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08224 (* 1 = 6.08224 loss)
I0524 04:15:17.524616 11654 sgd_solver.cpp:112] Iteration 31270, lr = 0.1
I0524 04:15:23.782595 11654 solver.cpp:239] Iteration 31280 (1.59852 iter/s, 6.2558s/10 iters), loss = 6.47093
I0524 04:15:23.782642 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47093 (* 1 = 6.47093 loss)
I0524 04:15:23.782937 11654 sgd_solver.cpp:112] Iteration 31280, lr = 0.1
I0524 04:15:30.599814 11654 solver.cpp:239] Iteration 31290 (1.46694 iter/s, 6.8169s/10 iters), loss = 7.11756
I0524 04:15:30.599874 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11756 (* 1 = 7.11756 loss)
I0524 04:15:30.600023 11654 sgd_solver.cpp:112] Iteration 31290, lr = 0.1
I0524 04:15:37.210222 11654 solver.cpp:239] Iteration 31300 (1.51284 iter/s, 6.6101s/10 iters), loss = 7.95318
I0524 04:15:37.210260 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.95318 (* 1 = 7.95318 loss)
I0524 04:15:37.210273 11654 sgd_solver.cpp:112] Iteration 31300, lr = 0.1
I0524 04:15:44.355587 11654 solver.cpp:239] Iteration 31310 (1.39957 iter/s, 7.14504s/10 iters), loss = 6.28885
I0524 04:15:44.355643 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28885 (* 1 = 6.28885 loss)
I0524 04:15:44.403522 11654 sgd_solver.cpp:112] Iteration 31310, lr = 0.1
I0524 04:15:52.016170 11654 solver.cpp:239] Iteration 31320 (1.30544 iter/s, 7.66024s/10 iters), loss = 6.64795
I0524 04:15:52.016338 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64795 (* 1 = 6.64795 loss)
I0524 04:15:52.429507 11654 sgd_solver.cpp:112] Iteration 31320, lr = 0.1
I0524 04:15:59.858882 11654 solver.cpp:239] Iteration 31330 (1.27515 iter/s, 7.84224s/10 iters), loss = 7.07003
I0524 04:15:59.858958 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07003 (* 1 = 7.07003 loss)
I0524 04:15:59.859349 11654 sgd_solver.cpp:112] Iteration 31330, lr = 0.1
I0524 04:16:07.649147 11654 solver.cpp:239] Iteration 31340 (1.28371 iter/s, 7.7899s/10 iters), loss = 6.56658
I0524 04:16:07.649199 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56658 (* 1 = 6.56658 loss)
I0524 04:16:07.649216 11654 sgd_solver.cpp:112] Iteration 31340, lr = 0.1
I0524 04:16:15.341018 11654 solver.cpp:239] Iteration 31350 (1.30014 iter/s, 7.69146s/10 iters), loss = 6.3507
I0524 04:16:15.341073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3507 (* 1 = 6.3507 loss)
I0524 04:16:15.341090 11654 sgd_solver.cpp:112] Iteration 31350, lr = 0.1
I0524 04:16:21.653089 11654 solver.cpp:239] Iteration 31360 (1.58436 iter/s, 6.31171s/10 iters), loss = 5.88605
I0524 04:16:21.653134 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88605 (* 1 = 5.88605 loss)
I0524 04:16:21.653338 11654 sgd_solver.cpp:112] Iteration 31360, lr = 0.1
I0524 04:16:28.560542 11654 solver.cpp:239] Iteration 31370 (1.44778 iter/s, 6.90713s/10 iters), loss = 5.23666
I0524 04:16:28.560644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.23666 (* 1 = 5.23666 loss)
I0524 04:16:28.560662 11654 sgd_solver.cpp:112] Iteration 31370, lr = 0.1
I0524 04:16:34.796227 11654 solver.cpp:239] Iteration 31380 (1.60377 iter/s, 6.23531s/10 iters), loss = 7.77941
I0524 04:16:34.796279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.77941 (* 1 = 7.77941 loss)
I0524 04:16:34.796296 11654 sgd_solver.cpp:112] Iteration 31380, lr = 0.1
I0524 04:16:40.847131 11654 solver.cpp:239] Iteration 31390 (1.65274 iter/s, 6.05054s/10 iters), loss = 5.7433
I0524 04:16:40.847187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.7433 (* 1 = 5.7433 loss)
I0524 04:16:40.990303 11654 sgd_solver.cpp:112] Iteration 31390, lr = 0.1
I0524 04:16:47.014636 11654 solver.cpp:239] Iteration 31400 (1.62148 iter/s, 6.16721s/10 iters), loss = 7.24595
I0524 04:16:47.014683 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24595 (* 1 = 7.24595 loss)
I0524 04:16:47.014943 11654 sgd_solver.cpp:112] Iteration 31400, lr = 0.1
I0524 04:16:54.217696 11654 solver.cpp:239] Iteration 31410 (1.38836 iter/s, 7.20273s/10 iters), loss = 5.64494
I0524 04:16:54.217751 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64494 (* 1 = 5.64494 loss)
I0524 04:16:54.217767 11654 sgd_solver.cpp:112] Iteration 31410, lr = 0.1
I0524 04:17:00.254637 11654 solver.cpp:239] Iteration 31420 (1.65655 iter/s, 6.03666s/10 iters), loss = 6.06173
I0524 04:17:00.254814 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06173 (* 1 = 6.06173 loss)
I0524 04:17:00.254832 11654 sgd_solver.cpp:112] Iteration 31420, lr = 0.1
I0524 04:17:08.316362 11654 solver.cpp:239] Iteration 31430 (1.24051 iter/s, 8.0612s/10 iters), loss = 6.99134
I0524 04:17:08.316422 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99134 (* 1 = 6.99134 loss)
I0524 04:17:08.316650 11654 sgd_solver.cpp:112] Iteration 31430, lr = 0.1
I0524 04:17:14.745296 11654 solver.cpp:239] Iteration 31440 (1.55554 iter/s, 6.42863s/10 iters), loss = 6.14791
I0524 04:17:14.745347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14791 (* 1 = 6.14791 loss)
I0524 04:17:14.745638 11654 sgd_solver.cpp:112] Iteration 31440, lr = 0.1
I0524 04:17:23.380980 11654 solver.cpp:239] Iteration 31450 (1.15804 iter/s, 8.6353s/10 iters), loss = 5.34343
I0524 04:17:23.381038 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.34343 (* 1 = 5.34343 loss)
I0524 04:17:23.811362 11654 sgd_solver.cpp:112] Iteration 31450, lr = 0.1
I0524 04:17:29.898838 11654 solver.cpp:239] Iteration 31460 (1.53432 iter/s, 6.51754s/10 iters), loss = 7.10621
I0524 04:17:29.898901 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10621 (* 1 = 7.10621 loss)
I0524 04:17:29.899391 11654 sgd_solver.cpp:112] Iteration 31460, lr = 0.1
I0524 04:17:37.339063 11654 solver.cpp:239] Iteration 31470 (1.34411 iter/s, 7.43988s/10 iters), loss = 7.99749
I0524 04:17:37.339377 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.99749 (* 1 = 7.99749 loss)
I0524 04:17:37.339431 11654 sgd_solver.cpp:112] Iteration 31470, lr = 0.1
I0524 04:17:43.660207 11654 solver.cpp:239] Iteration 31480 (1.58212 iter/s, 6.32063s/10 iters), loss = 6.56738
I0524 04:17:43.660272 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56738 (* 1 = 6.56738 loss)
I0524 04:17:43.660481 11654 sgd_solver.cpp:112] Iteration 31480, lr = 0.1
I0524 04:17:50.351084 11654 solver.cpp:239] Iteration 31490 (1.49464 iter/s, 6.69057s/10 iters), loss = 5.78206
I0524 04:17:50.351121 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78206 (* 1 = 5.78206 loss)
I0524 04:17:50.521960 11654 sgd_solver.cpp:112] Iteration 31490, lr = 0.1
I0524 04:17:56.588964 11654 solver.cpp:239] Iteration 31500 (1.60318 iter/s, 6.23759s/10 iters), loss = 5.78316
I0524 04:17:56.589025 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78316 (* 1 = 5.78316 loss)
I0524 04:17:56.589529 11654 sgd_solver.cpp:112] Iteration 31500, lr = 0.1
I0524 04:18:03.460768 11654 solver.cpp:239] Iteration 31510 (1.45529 iter/s, 6.87149s/10 iters), loss = 6.58676
I0524 04:18:03.460809 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58676 (* 1 = 6.58676 loss)
I0524 04:18:03.480235 11654 sgd_solver.cpp:112] Iteration 31510, lr = 0.1
I0524 04:18:09.940152 11654 solver.cpp:239] Iteration 31520 (1.54343 iter/s, 6.47908s/10 iters), loss = 6.88097
I0524 04:18:09.940261 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88097 (* 1 = 6.88097 loss)
I0524 04:18:09.940277 11654 sgd_solver.cpp:112] Iteration 31520, lr = 0.1
I0524 04:18:16.271519 11654 solver.cpp:239] Iteration 31530 (1.57953 iter/s, 6.33101s/10 iters), loss = 6.01159
I0524 04:18:16.271580 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01159 (* 1 = 6.01159 loss)
I0524 04:18:16.271970 11654 sgd_solver.cpp:112] Iteration 31530, lr = 0.1
I0524 04:18:22.188235 11654 solver.cpp:239] Iteration 31540 (1.69021 iter/s, 5.91643s/10 iters), loss = 6.27398
I0524 04:18:22.188290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27398 (* 1 = 6.27398 loss)
I0524 04:18:22.188305 11654 sgd_solver.cpp:112] Iteration 31540, lr = 0.1
I0524 04:18:28.583847 11654 solver.cpp:239] Iteration 31550 (1.56392 iter/s, 6.3942s/10 iters), loss = 6.57904
I0524 04:18:28.583894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57904 (* 1 = 6.57904 loss)
I0524 04:18:28.583910 11654 sgd_solver.cpp:112] Iteration 31550, lr = 0.1
I0524 04:18:35.600579 11654 solver.cpp:239] Iteration 31560 (1.42524 iter/s, 7.01634s/10 iters), loss = 6.15618
I0524 04:18:35.600630 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15618 (* 1 = 6.15618 loss)
I0524 04:18:35.600934 11654 sgd_solver.cpp:112] Iteration 31560, lr = 0.1
I0524 04:18:42.652092 11654 solver.cpp:239] Iteration 31570 (1.4182 iter/s, 7.05119s/10 iters), loss = 5.58532
I0524 04:18:42.652313 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58532 (* 1 = 5.58532 loss)
I0524 04:18:42.652552 11654 sgd_solver.cpp:112] Iteration 31570, lr = 0.1
I0524 04:18:48.853953 11654 solver.cpp:239] Iteration 31580 (1.61253 iter/s, 6.20145s/10 iters), loss = 6.86094
I0524 04:18:48.854008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86094 (* 1 = 6.86094 loss)
I0524 04:18:49.199753 11654 sgd_solver.cpp:112] Iteration 31580, lr = 0.1
I0524 04:18:59.113443 11654 solver.cpp:239] Iteration 31590 (0.974749 iter/s, 10.259s/10 iters), loss = 6.1336
I0524 04:18:59.113495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1336 (* 1 = 6.1336 loss)
I0524 04:18:59.115388 11654 sgd_solver.cpp:112] Iteration 31590, lr = 0.1
I0524 04:19:07.447547 11654 solver.cpp:239] Iteration 31600 (1.19994 iter/s, 8.33372s/10 iters), loss = 6.72513
I0524 04:19:07.447612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72513 (* 1 = 6.72513 loss)
I0524 04:19:07.448117 11654 sgd_solver.cpp:112] Iteration 31600, lr = 0.1
I0524 04:19:13.841872 11654 solver.cpp:239] Iteration 31610 (1.56396 iter/s, 6.39402s/10 iters), loss = 5.49599
I0524 04:19:13.842038 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49599 (* 1 = 5.49599 loss)
I0524 04:19:13.842061 11654 sgd_solver.cpp:112] Iteration 31610, lr = 0.1
I0524 04:19:21.365762 11654 solver.cpp:239] Iteration 31620 (1.32918 iter/s, 7.52342s/10 iters), loss = 6.33025
I0524 04:19:21.365818 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33025 (* 1 = 6.33025 loss)
I0524 04:19:21.660538 11654 sgd_solver.cpp:112] Iteration 31620, lr = 0.1
I0524 04:19:29.408098 11654 solver.cpp:239] Iteration 31630 (1.24348 iter/s, 8.04197s/10 iters), loss = 5.90066
I0524 04:19:29.408159 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90066 (* 1 = 5.90066 loss)
I0524 04:19:29.408440 11654 sgd_solver.cpp:112] Iteration 31630, lr = 0.1
I0524 04:19:37.456061 11654 solver.cpp:239] Iteration 31640 (1.24261 iter/s, 8.0476s/10 iters), loss = 6.57204
I0524 04:19:37.456121 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57204 (* 1 = 6.57204 loss)
I0524 04:19:37.456529 11654 sgd_solver.cpp:112] Iteration 31640, lr = 0.1
I0524 04:19:46.164445 11654 solver.cpp:239] Iteration 31650 (1.14837 iter/s, 8.70799s/10 iters), loss = 6.12295
I0524 04:19:46.164700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12295 (* 1 = 6.12295 loss)
I0524 04:19:46.177631 11654 sgd_solver.cpp:112] Iteration 31650, lr = 0.1
I0524 04:19:54.490284 11654 solver.cpp:239] Iteration 31660 (1.20115 iter/s, 8.32532s/10 iters), loss = 6.11571
I0524 04:19:54.490325 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11571 (* 1 = 6.11571 loss)
I0524 04:19:54.490339 11654 sgd_solver.cpp:112] Iteration 31660, lr = 0.1
I0524 04:20:01.229171 11654 solver.cpp:239] Iteration 31670 (1.48411 iter/s, 6.73803s/10 iters), loss = 6.8733
I0524 04:20:01.229231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8733 (* 1 = 6.8733 loss)
I0524 04:20:01.229249 11654 sgd_solver.cpp:112] Iteration 31670, lr = 0.1
I0524 04:20:08.433107 11654 solver.cpp:239] Iteration 31680 (1.38819 iter/s, 7.2036s/10 iters), loss = 6.90122
I0524 04:20:08.433169 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90122 (* 1 = 6.90122 loss)
I0524 04:20:08.433193 11654 sgd_solver.cpp:112] Iteration 31680, lr = 0.1
I0524 04:20:15.879742 11654 solver.cpp:239] Iteration 31690 (1.34335 iter/s, 7.44405s/10 iters), loss = 5.55953
I0524 04:20:15.879796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55953 (* 1 = 5.55953 loss)
I0524 04:20:15.879962 11654 sgd_solver.cpp:112] Iteration 31690, lr = 0.1
I0524 04:20:23.429258 11654 solver.cpp:239] Iteration 31700 (1.32465 iter/s, 7.54917s/10 iters), loss = 7.00362
I0524 04:20:23.429359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00362 (* 1 = 7.00362 loss)
I0524 04:20:24.356091 11654 sgd_solver.cpp:112] Iteration 31700, lr = 0.1
I0524 04:20:31.276584 11654 solver.cpp:239] Iteration 31710 (1.27438 iter/s, 7.84693s/10 iters), loss = 6.29131
I0524 04:20:31.276635 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29131 (* 1 = 6.29131 loss)
I0524 04:20:31.276674 11654 sgd_solver.cpp:112] Iteration 31710, lr = 0.1
I0524 04:20:37.764672 11654 solver.cpp:239] Iteration 31720 (1.54136 iter/s, 6.48779s/10 iters), loss = 7.36953
I0524 04:20:37.764725 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36953 (* 1 = 7.36953 loss)
I0524 04:20:37.766386 11654 sgd_solver.cpp:112] Iteration 31720, lr = 0.1
I0524 04:20:44.720535 11654 solver.cpp:239] Iteration 31730 (1.4377 iter/s, 6.95554s/10 iters), loss = 6.19807
I0524 04:20:44.720599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19807 (* 1 = 6.19807 loss)
I0524 04:20:44.761684 11654 sgd_solver.cpp:112] Iteration 31730, lr = 0.1
I0524 04:20:52.242727 11654 solver.cpp:239] Iteration 31740 (1.32946 iter/s, 7.52185s/10 iters), loss = 7.15933
I0524 04:20:52.242769 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15933 (* 1 = 7.15933 loss)
I0524 04:20:53.530833 11654 sgd_solver.cpp:112] Iteration 31740, lr = 0.1
I0524 04:21:00.144304 11654 solver.cpp:239] Iteration 31750 (1.26563 iter/s, 7.90122s/10 iters), loss = 6.84069
I0524 04:21:00.144353 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84069 (* 1 = 6.84069 loss)
I0524 04:21:00.144374 11654 sgd_solver.cpp:112] Iteration 31750, lr = 0.1
I0524 04:21:06.256995 11654 solver.cpp:239] Iteration 31760 (1.63602 iter/s, 6.11241s/10 iters), loss = 5.99858
I0524 04:21:06.257055 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99858 (* 1 = 5.99858 loss)
I0524 04:21:06.282008 11654 sgd_solver.cpp:112] Iteration 31760, lr = 0.1
I0524 04:21:14.236449 11654 solver.cpp:239] Iteration 31770 (1.25328 iter/s, 7.97909s/10 iters), loss = 6.53089
I0524 04:21:14.236515 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53089 (* 1 = 6.53089 loss)
I0524 04:21:14.236834 11654 sgd_solver.cpp:112] Iteration 31770, lr = 0.1
I0524 04:21:21.686800 11654 solver.cpp:239] Iteration 31780 (1.34228 iter/s, 7.45s/10 iters), loss = 5.82401
I0524 04:21:21.686863 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82401 (* 1 = 5.82401 loss)
I0524 04:21:21.689038 11654 sgd_solver.cpp:112] Iteration 31780, lr = 0.1
I0524 04:21:29.855989 11654 solver.cpp:239] Iteration 31790 (1.22417 iter/s, 8.16883s/10 iters), loss = 6.54932
I0524 04:21:29.856222 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54932 (* 1 = 6.54932 loss)
I0524 04:21:29.856271 11654 sgd_solver.cpp:112] Iteration 31790, lr = 0.1
I0524 04:21:38.761806 11654 solver.cpp:239] Iteration 31800 (1.12293 iter/s, 8.90524s/10 iters), loss = 6.49129
I0524 04:21:38.761859 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49129 (* 1 = 6.49129 loss)
I0524 04:21:38.761875 11654 sgd_solver.cpp:112] Iteration 31800, lr = 0.1
I0524 04:21:44.844657 11654 solver.cpp:239] Iteration 31810 (1.64406 iter/s, 6.0825s/10 iters), loss = 6.25837
I0524 04:21:44.844713 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25837 (* 1 = 6.25837 loss)
I0524 04:21:44.844748 11654 sgd_solver.cpp:112] Iteration 31810, lr = 0.1
I0524 04:21:52.246634 11654 solver.cpp:239] Iteration 31820 (1.35105 iter/s, 7.40165s/10 iters), loss = 7.45937
I0524 04:21:52.246673 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.45937 (* 1 = 7.45937 loss)
I0524 04:21:52.246687 11654 sgd_solver.cpp:112] Iteration 31820, lr = 0.1
I0524 04:21:58.574429 11654 solver.cpp:239] Iteration 31830 (1.58042 iter/s, 6.32744s/10 iters), loss = 7.32187
I0524 04:21:58.574481 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32187 (* 1 = 7.32187 loss)
I0524 04:21:58.574807 11654 sgd_solver.cpp:112] Iteration 31830, lr = 0.1
I0524 04:22:06.362450 11654 solver.cpp:239] Iteration 31840 (1.28408 iter/s, 7.78767s/10 iters), loss = 5.54593
I0524 04:22:06.362748 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54593 (* 1 = 5.54593 loss)
I0524 04:22:06.362802 11654 sgd_solver.cpp:112] Iteration 31840, lr = 0.1
I0524 04:22:12.873818 11654 solver.cpp:239] Iteration 31850 (1.53637 iter/s, 6.50885s/10 iters), loss = 6.4015
I0524 04:22:12.873872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4015 (* 1 = 6.4015 loss)
I0524 04:22:12.874048 11654 sgd_solver.cpp:112] Iteration 31850, lr = 0.1
I0524 04:22:20.980491 11654 solver.cpp:239] Iteration 31860 (1.23361 iter/s, 8.10631s/10 iters), loss = 5.09358
I0524 04:22:20.980548 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.09358 (* 1 = 5.09358 loss)
I0524 04:22:20.980718 11654 sgd_solver.cpp:112] Iteration 31860, lr = 0.1
I0524 04:22:27.529495 11654 solver.cpp:239] Iteration 31870 (1.52702 iter/s, 6.54869s/10 iters), loss = 6.16769
I0524 04:22:27.529553 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16769 (* 1 = 6.16769 loss)
I0524 04:22:27.530416 11654 sgd_solver.cpp:112] Iteration 31870, lr = 0.1
I0524 04:22:34.053007 11654 solver.cpp:239] Iteration 31880 (1.53299 iter/s, 6.52321s/10 iters), loss = 5.83623
I0524 04:22:34.053050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83623 (* 1 = 5.83623 loss)
I0524 04:22:34.167866 11654 sgd_solver.cpp:112] Iteration 31880, lr = 0.1
I0524 04:22:41.387392 11654 solver.cpp:239] Iteration 31890 (1.3635 iter/s, 7.33405s/10 iters), loss = 6.27892
I0524 04:22:41.387688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27892 (* 1 = 6.27892 loss)
I0524 04:22:41.387753 11654 sgd_solver.cpp:112] Iteration 31890, lr = 0.1
I0524 04:22:49.637043 11654 solver.cpp:239] Iteration 31900 (1.21226 iter/s, 8.24908s/10 iters), loss = 4.95844
I0524 04:22:49.637096 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.95844 (* 1 = 4.95844 loss)
I0524 04:22:49.637521 11654 sgd_solver.cpp:112] Iteration 31900, lr = 0.1
I0524 04:22:56.012652 11654 solver.cpp:239] Iteration 31910 (1.56855 iter/s, 6.37531s/10 iters), loss = 6.35391
I0524 04:22:56.012706 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35391 (* 1 = 6.35391 loss)
I0524 04:22:56.146311 11654 sgd_solver.cpp:112] Iteration 31910, lr = 0.1
I0524 04:23:03.379276 11654 solver.cpp:239] Iteration 31920 (1.35754 iter/s, 7.36628s/10 iters), loss = 6.54621
I0524 04:23:03.379343 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54621 (* 1 = 6.54621 loss)
I0524 04:23:03.899106 11654 sgd_solver.cpp:112] Iteration 31920, lr = 0.1
I0524 04:23:11.642160 11654 solver.cpp:239] Iteration 31930 (1.21029 iter/s, 8.2625s/10 iters), loss = 6.33128
I0524 04:23:11.642436 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33128 (* 1 = 6.33128 loss)
I0524 04:23:11.642489 11654 sgd_solver.cpp:112] Iteration 31930, lr = 0.1
I0524 04:23:18.782683 11654 solver.cpp:239] Iteration 31940 (1.40057 iter/s, 7.13995s/10 iters), loss = 7.35855
I0524 04:23:18.782749 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.35855 (* 1 = 7.35855 loss)
I0524 04:23:18.783033 11654 sgd_solver.cpp:112] Iteration 31940, lr = 0.1
I0524 04:23:27.212462 11654 solver.cpp:239] Iteration 31950 (1.18633 iter/s, 8.42939s/10 iters), loss = 6.38005
I0524 04:23:27.212518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38005 (* 1 = 6.38005 loss)
I0524 04:23:27.212538 11654 sgd_solver.cpp:112] Iteration 31950, lr = 0.1
I0524 04:23:34.648419 11654 solver.cpp:239] Iteration 31960 (1.34489 iter/s, 7.43554s/10 iters), loss = 5.86426
I0524 04:23:34.648476 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86426 (* 1 = 5.86426 loss)
I0524 04:23:34.648494 11654 sgd_solver.cpp:112] Iteration 31960, lr = 0.1
I0524 04:23:41.537608 11654 solver.cpp:239] Iteration 31970 (1.45185 iter/s, 6.88778s/10 iters), loss = 7.07152
I0524 04:23:41.537664 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07152 (* 1 = 7.07152 loss)
I0524 04:23:41.537683 11654 sgd_solver.cpp:112] Iteration 31970, lr = 0.1
I0524 04:23:48.766075 11654 solver.cpp:239] Iteration 31980 (1.38391 iter/s, 7.22592s/10 iters), loss = 7.96686
I0524 04:23:48.766206 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.96686 (* 1 = 7.96686 loss)
I0524 04:23:48.833303 11654 sgd_solver.cpp:112] Iteration 31980, lr = 0.1
I0524 04:23:55.146423 11654 solver.cpp:239] Iteration 31990 (1.5674 iter/s, 6.37998s/10 iters), loss = 6.58719
I0524 04:23:55.146462 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58719 (* 1 = 6.58719 loss)
I0524 04:23:55.146476 11654 sgd_solver.cpp:112] Iteration 31990, lr = 0.1
I0524 04:24:02.163206 11654 solver.cpp:239] Iteration 32000 (1.42533 iter/s, 7.01592s/10 iters), loss = 6.39378
I0524 04:24:02.163265 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39378 (* 1 = 6.39378 loss)
I0524 04:24:02.163282 11654 sgd_solver.cpp:112] Iteration 32000, lr = 0.1
I0524 04:24:09.993181 11654 solver.cpp:239] Iteration 32010 (1.27721 iter/s, 7.82957s/10 iters), loss = 6.15766
I0524 04:24:09.993225 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15766 (* 1 = 6.15766 loss)
I0524 04:24:10.292093 11654 sgd_solver.cpp:112] Iteration 32010, lr = 0.1
I0524 04:24:16.518563 11654 solver.cpp:239] Iteration 32020 (1.53255 iter/s, 6.52508s/10 iters), loss = 6.52905
I0524 04:24:16.518611 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52905 (* 1 = 6.52905 loss)
I0524 04:24:16.518972 11654 sgd_solver.cpp:112] Iteration 32020, lr = 0.1
I0524 04:24:24.075305 11654 solver.cpp:239] Iteration 32030 (1.32338 iter/s, 7.55639s/10 iters), loss = 5.3445
I0524 04:24:24.075634 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3445 (* 1 = 5.3445 loss)
I0524 04:24:24.075829 11654 sgd_solver.cpp:112] Iteration 32030, lr = 0.1
I0524 04:24:30.617933 11654 solver.cpp:239] Iteration 32040 (1.52856 iter/s, 6.54209s/10 iters), loss = 6.81049
I0524 04:24:30.617997 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81049 (* 1 = 6.81049 loss)
I0524 04:24:30.618178 11654 sgd_solver.cpp:112] Iteration 32040, lr = 0.1
I0524 04:24:36.770433 11654 solver.cpp:239] Iteration 32050 (1.62543 iter/s, 6.1522s/10 iters), loss = 5.59963
I0524 04:24:36.770472 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59963 (* 1 = 5.59963 loss)
I0524 04:24:37.791934 11654 sgd_solver.cpp:112] Iteration 32050, lr = 0.1
I0524 04:24:45.489177 11654 solver.cpp:239] Iteration 32060 (1.147 iter/s, 8.71837s/10 iters), loss = 7.01276
I0524 04:24:45.489230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01276 (* 1 = 7.01276 loss)
I0524 04:24:45.489472 11654 sgd_solver.cpp:112] Iteration 32060, lr = 0.1
I0524 04:24:52.216040 11654 solver.cpp:239] Iteration 32070 (1.48665 iter/s, 6.72655s/10 iters), loss = 7.30818
I0524 04:24:52.216087 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30818 (* 1 = 7.30818 loss)
I0524 04:24:52.225997 11654 sgd_solver.cpp:112] Iteration 32070, lr = 0.1
I0524 04:25:00.341377 11654 solver.cpp:239] Iteration 32080 (1.23077 iter/s, 8.12497s/10 iters), loss = 6.51399
I0524 04:25:00.341511 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51399 (* 1 = 6.51399 loss)
I0524 04:25:00.352519 11654 sgd_solver.cpp:112] Iteration 32080, lr = 0.1
I0524 04:25:07.436476 11654 solver.cpp:239] Iteration 32090 (1.4095 iter/s, 7.0947s/10 iters), loss = 6.10638
I0524 04:25:07.436518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10638 (* 1 = 6.10638 loss)
I0524 04:25:07.436532 11654 sgd_solver.cpp:112] Iteration 32090, lr = 0.1
I0524 04:25:14.757067 11654 solver.cpp:239] Iteration 32100 (1.36649 iter/s, 7.31804s/10 iters), loss = 5.80946
I0524 04:25:14.757125 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80946 (* 1 = 5.80946 loss)
I0524 04:25:15.712766 11654 sgd_solver.cpp:112] Iteration 32100, lr = 0.1
I0524 04:25:23.392297 11654 solver.cpp:239] Iteration 32110 (1.1581 iter/s, 8.63484s/10 iters), loss = 5.2138
I0524 04:25:23.392346 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.2138 (* 1 = 5.2138 loss)
I0524 04:25:23.392362 11654 sgd_solver.cpp:112] Iteration 32110, lr = 0.1
I0524 04:25:30.387670 11654 solver.cpp:239] Iteration 32120 (1.42958 iter/s, 6.99505s/10 iters), loss = 6.54189
I0524 04:25:30.387812 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54189 (* 1 = 6.54189 loss)
I0524 04:25:30.401985 11654 sgd_solver.cpp:112] Iteration 32120, lr = 0.1
I0524 04:25:37.498317 11654 solver.cpp:239] Iteration 32130 (1.40643 iter/s, 7.11022s/10 iters), loss = 6.23698
I0524 04:25:37.498373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23698 (* 1 = 6.23698 loss)
I0524 04:25:37.498544 11654 sgd_solver.cpp:112] Iteration 32130, lr = 0.1
I0524 04:25:44.339524 11654 solver.cpp:239] Iteration 32140 (1.4618 iter/s, 6.84089s/10 iters), loss = 6.01242
I0524 04:25:44.339579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01242 (* 1 = 6.01242 loss)
I0524 04:25:44.339596 11654 sgd_solver.cpp:112] Iteration 32140, lr = 0.1
I0524 04:25:50.464290 11654 solver.cpp:239] Iteration 32150 (1.63279 iter/s, 6.12447s/10 iters), loss = 7.2603
I0524 04:25:50.464345 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2603 (* 1 = 7.2603 loss)
I0524 04:25:50.464684 11654 sgd_solver.cpp:112] Iteration 32150, lr = 0.1
I0524 04:25:58.310679 11654 solver.cpp:239] Iteration 32160 (1.27453 iter/s, 7.84604s/10 iters), loss = 5.91391
I0524 04:25:58.310753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91391 (* 1 = 5.91391 loss)
I0524 04:25:58.439764 11654 sgd_solver.cpp:112] Iteration 32160, lr = 0.1
I0524 04:26:04.733059 11654 solver.cpp:239] Iteration 32170 (1.55713 iter/s, 6.42205s/10 iters), loss = 7.59735
I0524 04:26:04.733333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.59735 (* 1 = 7.59735 loss)
I0524 04:26:04.799340 11654 sgd_solver.cpp:112] Iteration 32170, lr = 0.1
I0524 04:26:12.189574 11654 solver.cpp:239] Iteration 32180 (1.3412 iter/s, 7.45599s/10 iters), loss = 6.42569
I0524 04:26:12.189628 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42569 (* 1 = 6.42569 loss)
I0524 04:26:12.189643 11654 sgd_solver.cpp:112] Iteration 32180, lr = 0.1
I0524 04:26:21.164844 11654 solver.cpp:239] Iteration 32190 (1.11422 iter/s, 8.97487s/10 iters), loss = 5.65467
I0524 04:26:21.164906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65467 (* 1 = 5.65467 loss)
I0524 04:26:21.165024 11654 sgd_solver.cpp:112] Iteration 32190, lr = 0.1
I0524 04:26:27.529152 11654 solver.cpp:239] Iteration 32200 (1.57134 iter/s, 6.36401s/10 iters), loss = 6.56012
I0524 04:26:27.529207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56012 (* 1 = 6.56012 loss)
I0524 04:26:27.529569 11654 sgd_solver.cpp:112] Iteration 32200, lr = 0.1
I0524 04:26:33.934922 11654 solver.cpp:239] Iteration 32210 (1.56117 iter/s, 6.40545s/10 iters), loss = 6.103
I0524 04:26:33.935003 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.103 (* 1 = 6.103 loss)
I0524 04:26:33.935395 11654 sgd_solver.cpp:112] Iteration 32210, lr = 0.1
I0524 04:26:40.232429 11654 solver.cpp:239] Iteration 32220 (1.58801 iter/s, 6.29719s/10 iters), loss = 6.64918
I0524 04:26:40.232543 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64918 (* 1 = 6.64918 loss)
I0524 04:26:40.232703 11654 sgd_solver.cpp:112] Iteration 32220, lr = 0.1
I0524 04:26:47.590018 11654 solver.cpp:239] Iteration 32230 (1.35921 iter/s, 7.3572s/10 iters), loss = 6.46624
I0524 04:26:47.590070 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46624 (* 1 = 6.46624 loss)
I0524 04:26:47.590086 11654 sgd_solver.cpp:112] Iteration 32230, lr = 0.1
I0524 04:26:55.637610 11654 solver.cpp:239] Iteration 32240 (1.24284 iter/s, 8.04611s/10 iters), loss = 5.96438
I0524 04:26:55.637672 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96438 (* 1 = 5.96438 loss)
I0524 04:26:55.637991 11654 sgd_solver.cpp:112] Iteration 32240, lr = 0.1
I0524 04:27:03.167735 11654 solver.cpp:239] Iteration 32250 (1.32806 iter/s, 7.52978s/10 iters), loss = 6.34862
I0524 04:27:03.167790 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34862 (* 1 = 6.34862 loss)
I0524 04:27:03.168090 11654 sgd_solver.cpp:112] Iteration 32250, lr = 0.1
I0524 04:27:09.696522 11654 solver.cpp:239] Iteration 32260 (1.53175 iter/s, 6.52848s/10 iters), loss = 7.18913
I0524 04:27:09.696571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18913 (* 1 = 7.18913 loss)
I0524 04:27:09.697135 11654 sgd_solver.cpp:112] Iteration 32260, lr = 0.1
I0524 04:27:16.689236 11654 solver.cpp:239] Iteration 32270 (1.43013 iter/s, 6.99238s/10 iters), loss = 5.97636
I0524 04:27:16.689558 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97636 (* 1 = 5.97636 loss)
I0524 04:27:16.831570 11654 sgd_solver.cpp:112] Iteration 32270, lr = 0.1
I0524 04:27:24.259235 11654 solver.cpp:239] Iteration 32280 (1.3211 iter/s, 7.56945s/10 iters), loss = 5.65286
I0524 04:27:24.259276 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65286 (* 1 = 5.65286 loss)
I0524 04:27:24.259289 11654 sgd_solver.cpp:112] Iteration 32280, lr = 0.1
I0524 04:27:31.711671 11654 solver.cpp:239] Iteration 32290 (1.3419 iter/s, 7.4521s/10 iters), loss = 6.49353
I0524 04:27:31.711735 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49353 (* 1 = 6.49353 loss)
I0524 04:27:31.711755 11654 sgd_solver.cpp:112] Iteration 32290, lr = 0.1
I0524 04:27:42.229986 11654 solver.cpp:239] Iteration 32300 (0.950966 iter/s, 10.5156s/10 iters), loss = 7.42875
I0524 04:27:42.230046 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.42875 (* 1 = 7.42875 loss)
I0524 04:27:42.230581 11654 sgd_solver.cpp:112] Iteration 32300, lr = 0.1
I0524 04:27:49.296878 11654 solver.cpp:239] Iteration 32310 (1.41511 iter/s, 7.06657s/10 iters), loss = 6.08668
I0524 04:27:49.297173 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08668 (* 1 = 6.08668 loss)
I0524 04:27:49.297236 11654 sgd_solver.cpp:112] Iteration 32310, lr = 0.1
I0524 04:27:55.775810 11654 solver.cpp:239] Iteration 32320 (1.54358 iter/s, 6.47845s/10 iters), loss = 5.81134
I0524 04:27:55.775849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81134 (* 1 = 5.81134 loss)
I0524 04:27:55.849412 11654 sgd_solver.cpp:112] Iteration 32320, lr = 0.1
I0524 04:28:03.150169 11654 solver.cpp:239] Iteration 32330 (1.35611 iter/s, 7.37402s/10 iters), loss = 6.33623
I0524 04:28:03.150229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33623 (* 1 = 6.33623 loss)
I0524 04:28:03.150640 11654 sgd_solver.cpp:112] Iteration 32330, lr = 0.1
I0524 04:28:09.123517 11654 solver.cpp:239] Iteration 32340 (1.67418 iter/s, 5.97306s/10 iters), loss = 6.19311
I0524 04:28:09.123571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19311 (* 1 = 6.19311 loss)
I0524 04:28:09.123706 11654 sgd_solver.cpp:112] Iteration 32340, lr = 0.1
I0524 04:28:16.009600 11654 solver.cpp:239] Iteration 32350 (1.45227 iter/s, 6.88576s/10 iters), loss = 6.95425
I0524 04:28:16.009660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95425 (* 1 = 6.95425 loss)
I0524 04:28:16.010124 11654 sgd_solver.cpp:112] Iteration 32350, lr = 0.1
I0524 04:28:25.742056 11654 solver.cpp:239] Iteration 32360 (1.02753 iter/s, 9.73203s/10 iters), loss = 5.6399
I0524 04:28:25.742271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6399 (* 1 = 5.6399 loss)
I0524 04:28:25.742328 11654 sgd_solver.cpp:112] Iteration 32360, lr = 0.1
I0524 04:28:32.207095 11654 solver.cpp:239] Iteration 32370 (1.54739 iter/s, 6.46252s/10 iters), loss = 6.14505
I0524 04:28:32.207144 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14505 (* 1 = 6.14505 loss)
I0524 04:28:32.207367 11654 sgd_solver.cpp:112] Iteration 32370, lr = 0.1
I0524 04:28:38.705909 11654 solver.cpp:239] Iteration 32380 (1.53882 iter/s, 6.4985s/10 iters), loss = 6.0069
I0524 04:28:38.705968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0069 (* 1 = 6.0069 loss)
I0524 04:28:38.707911 11654 sgd_solver.cpp:112] Iteration 32380, lr = 0.1
I0524 04:28:46.230098 11654 solver.cpp:239] Iteration 32390 (1.32911 iter/s, 7.52385s/10 iters), loss = 5.87419
I0524 04:28:46.230141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87419 (* 1 = 5.87419 loss)
I0524 04:28:46.896031 11654 sgd_solver.cpp:112] Iteration 32390, lr = 0.1
I0524 04:28:53.507956 11654 solver.cpp:239] Iteration 32400 (1.37409 iter/s, 7.27753s/10 iters), loss = 6.10198
I0524 04:28:53.508008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10198 (* 1 = 6.10198 loss)
I0524 04:28:53.508132 11654 sgd_solver.cpp:112] Iteration 32400, lr = 0.1
I0524 04:29:01.049952 11654 solver.cpp:239] Iteration 32410 (1.32597 iter/s, 7.54165s/10 iters), loss = 6.05451
I0524 04:29:01.050266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05451 (* 1 = 6.05451 loss)
I0524 04:29:01.050319 11654 sgd_solver.cpp:112] Iteration 32410, lr = 0.1
I0524 04:29:07.734118 11654 solver.cpp:239] Iteration 32420 (1.4962 iter/s, 6.6836s/10 iters), loss = 5.71816
I0524 04:29:07.734182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71816 (* 1 = 5.71816 loss)
I0524 04:29:07.734601 11654 sgd_solver.cpp:112] Iteration 32420, lr = 0.1
I0524 04:29:15.825212 11654 solver.cpp:239] Iteration 32430 (1.23598 iter/s, 8.09072s/10 iters), loss = 6.94479
I0524 04:29:15.825273 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94479 (* 1 = 6.94479 loss)
I0524 04:29:15.825438 11654 sgd_solver.cpp:112] Iteration 32430, lr = 0.1
I0524 04:29:22.492478 11654 solver.cpp:239] Iteration 32440 (1.49994 iter/s, 6.66695s/10 iters), loss = 6.52704
I0524 04:29:22.492525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52704 (* 1 = 6.52704 loss)
I0524 04:29:22.492941 11654 sgd_solver.cpp:112] Iteration 32440, lr = 0.1
I0524 04:29:28.946782 11654 solver.cpp:239] Iteration 32450 (1.54943 iter/s, 6.454s/10 iters), loss = 6.17419
I0524 04:29:28.946832 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17419 (* 1 = 6.17419 loss)
I0524 04:29:28.946847 11654 sgd_solver.cpp:112] Iteration 32450, lr = 0.1
I0524 04:29:35.188304 11654 solver.cpp:239] Iteration 32460 (1.60225 iter/s, 6.24123s/10 iters), loss = 6.15911
I0524 04:29:35.188590 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15911 (* 1 = 6.15911 loss)
I0524 04:29:35.707873 11654 sgd_solver.cpp:112] Iteration 32460, lr = 0.1
I0524 04:29:43.248015 11654 solver.cpp:239] Iteration 32470 (1.24083 iter/s, 8.05915s/10 iters), loss = 6.01681
I0524 04:29:43.248093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01681 (* 1 = 6.01681 loss)
I0524 04:29:43.248632 11654 sgd_solver.cpp:112] Iteration 32470, lr = 0.1
I0524 04:29:49.772681 11654 solver.cpp:239] Iteration 32480 (1.53272 iter/s, 6.52435s/10 iters), loss = 7.47483
I0524 04:29:49.772722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.47483 (* 1 = 7.47483 loss)
I0524 04:29:49.772734 11654 sgd_solver.cpp:112] Iteration 32480, lr = 0.1
I0524 04:29:56.919178 11654 solver.cpp:239] Iteration 32490 (1.39938 iter/s, 7.14604s/10 iters), loss = 5.30938
I0524 04:29:56.919229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30938 (* 1 = 5.30938 loss)
I0524 04:29:56.919250 11654 sgd_solver.cpp:112] Iteration 32490, lr = 0.1
I0524 04:30:04.940985 11654 solver.cpp:239] Iteration 32500 (1.24667 iter/s, 8.02138s/10 iters), loss = 5.47272
I0524 04:30:04.941042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47272 (* 1 = 5.47272 loss)
I0524 04:30:04.941061 11654 sgd_solver.cpp:112] Iteration 32500, lr = 0.1
I0524 04:30:13.387740 11654 solver.cpp:239] Iteration 32510 (1.18395 iter/s, 8.44631s/10 iters), loss = 6.41161
I0524 04:30:13.387997 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41161 (* 1 = 6.41161 loss)
I0524 04:30:13.388125 11654 sgd_solver.cpp:112] Iteration 32510, lr = 0.1
I0524 04:30:20.574023 11654 solver.cpp:239] Iteration 32520 (1.39164 iter/s, 7.18578s/10 iters), loss = 5.91556
I0524 04:30:20.574071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91556 (* 1 = 5.91556 loss)
I0524 04:30:20.580284 11654 sgd_solver.cpp:112] Iteration 32520, lr = 0.1
I0524 04:30:27.570150 11654 solver.cpp:239] Iteration 32530 (1.42943 iter/s, 6.9958s/10 iters), loss = 6.21953
I0524 04:30:27.570212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21953 (* 1 = 6.21953 loss)
I0524 04:30:27.570436 11654 sgd_solver.cpp:112] Iteration 32530, lr = 0.1
I0524 04:30:35.429935 11654 solver.cpp:239] Iteration 32540 (1.27236 iter/s, 7.85943s/10 iters), loss = 7.73242
I0524 04:30:35.429972 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.73242 (* 1 = 7.73242 loss)
I0524 04:30:35.689357 11654 sgd_solver.cpp:112] Iteration 32540, lr = 0.1
I0524 04:30:42.671797 11654 solver.cpp:239] Iteration 32550 (1.38092 iter/s, 7.24154s/10 iters), loss = 6.2628
I0524 04:30:42.671854 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2628 (* 1 = 6.2628 loss)
I0524 04:30:42.671939 11654 sgd_solver.cpp:112] Iteration 32550, lr = 0.1
I0524 04:30:48.630213 11654 solver.cpp:239] Iteration 32560 (1.67838 iter/s, 5.95813s/10 iters), loss = 5.90543
I0524 04:30:48.630502 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90543 (* 1 = 5.90543 loss)
I0524 04:30:48.630553 11654 sgd_solver.cpp:112] Iteration 32560, lr = 0.1
I0524 04:30:56.023465 11654 solver.cpp:239] Iteration 32570 (1.35269 iter/s, 7.39269s/10 iters), loss = 5.63349
I0524 04:30:56.023520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63349 (* 1 = 5.63349 loss)
I0524 04:30:56.023608 11654 sgd_solver.cpp:112] Iteration 32570, lr = 0.1
I0524 04:31:02.186892 11654 solver.cpp:239] Iteration 32580 (1.62255 iter/s, 6.16313s/10 iters), loss = 6.11206
I0524 04:31:02.186954 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11206 (* 1 = 6.11206 loss)
I0524 04:31:02.187029 11654 sgd_solver.cpp:112] Iteration 32580, lr = 0.1
I0524 04:31:08.965131 11654 solver.cpp:239] Iteration 32590 (1.47538 iter/s, 6.77792s/10 iters), loss = 7.40949
I0524 04:31:08.965178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.40949 (* 1 = 7.40949 loss)
I0524 04:31:08.965195 11654 sgd_solver.cpp:112] Iteration 32590, lr = 0.1
I0524 04:31:16.642894 11654 solver.cpp:239] Iteration 32600 (1.30252 iter/s, 7.67741s/10 iters), loss = 6.7653
I0524 04:31:16.642952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7653 (* 1 = 6.7653 loss)
I0524 04:31:17.516520 11654 sgd_solver.cpp:112] Iteration 32600, lr = 0.1
I0524 04:31:24.021392 11654 solver.cpp:239] Iteration 32610 (1.35535 iter/s, 7.37816s/10 iters), loss = 6.14202
I0524 04:31:24.021662 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14202 (* 1 = 6.14202 loss)
I0524 04:31:24.124613 11654 sgd_solver.cpp:112] Iteration 32610, lr = 0.1
I0524 04:31:31.002528 11654 solver.cpp:239] Iteration 32620 (1.43253 iter/s, 6.98064s/10 iters), loss = 6.45389
I0524 04:31:31.002580 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45389 (* 1 = 6.45389 loss)
I0524 04:31:31.002831 11654 sgd_solver.cpp:112] Iteration 32620, lr = 0.1
I0524 04:31:37.519582 11654 solver.cpp:239] Iteration 32630 (1.53451 iter/s, 6.51676s/10 iters), loss = 6.01859
I0524 04:31:37.519621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01859 (* 1 = 6.01859 loss)
I0524 04:31:37.541275 11654 sgd_solver.cpp:112] Iteration 32630, lr = 0.1
I0524 04:31:43.915149 11654 solver.cpp:239] Iteration 32640 (1.56365 iter/s, 6.39527s/10 iters), loss = 5.22289
I0524 04:31:43.915208 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.22289 (* 1 = 5.22289 loss)
I0524 04:31:43.915226 11654 sgd_solver.cpp:112] Iteration 32640, lr = 0.1
I0524 04:31:50.746973 11654 solver.cpp:239] Iteration 32650 (1.46382 iter/s, 6.83145s/10 iters), loss = 6.2082
I0524 04:31:50.747028 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2082 (* 1 = 6.2082 loss)
I0524 04:31:50.747045 11654 sgd_solver.cpp:112] Iteration 32650, lr = 0.1
I0524 04:31:57.494367 11654 solver.cpp:239] Iteration 32660 (1.48214 iter/s, 6.74701s/10 iters), loss = 6.53458
I0524 04:31:57.494478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53458 (* 1 = 6.53458 loss)
I0524 04:31:57.494501 11654 sgd_solver.cpp:112] Iteration 32660, lr = 0.1
I0524 04:32:05.902770 11654 solver.cpp:239] Iteration 32670 (1.18935 iter/s, 8.40798s/10 iters), loss = 7.26497
I0524 04:32:05.902822 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26497 (* 1 = 7.26497 loss)
I0524 04:32:05.902837 11654 sgd_solver.cpp:112] Iteration 32670, lr = 0.1
I0524 04:32:15.907413 11654 solver.cpp:239] Iteration 32680 (0.999586 iter/s, 10.0041s/10 iters), loss = 6.0798
I0524 04:32:15.907470 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0798 (* 1 = 6.0798 loss)
I0524 04:32:17.420912 11654 sgd_solver.cpp:112] Iteration 32680, lr = 0.1
I0524 04:32:24.939585 11654 solver.cpp:239] Iteration 32690 (1.1072 iter/s, 9.03177s/10 iters), loss = 7.13671
I0524 04:32:24.939638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13671 (* 1 = 7.13671 loss)
I0524 04:32:26.356812 11654 sgd_solver.cpp:112] Iteration 32690, lr = 0.1
I0524 04:32:33.138092 11654 solver.cpp:239] Iteration 32700 (1.21979 iter/s, 8.19814s/10 iters), loss = 6.5451
I0524 04:32:33.138430 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5451 (* 1 = 6.5451 loss)
I0524 04:32:33.138492 11654 sgd_solver.cpp:112] Iteration 32700, lr = 0.1
I0524 04:32:39.440600 11654 solver.cpp:239] Iteration 32710 (1.58732 iter/s, 6.29994s/10 iters), loss = 6.17575
I0524 04:32:39.440641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17575 (* 1 = 6.17575 loss)
I0524 04:32:39.440654 11654 sgd_solver.cpp:112] Iteration 32710, lr = 0.1
I0524 04:32:48.660616 11654 solver.cpp:239] Iteration 32720 (1.08464 iter/s, 9.21961s/10 iters), loss = 4.63188
I0524 04:32:48.660678 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.63188 (* 1 = 4.63188 loss)
I0524 04:32:48.661192 11654 sgd_solver.cpp:112] Iteration 32720, lr = 0.1
I0524 04:32:57.431807 11654 solver.cpp:239] Iteration 32730 (1.14015 iter/s, 8.7708s/10 iters), loss = 5.87779
I0524 04:32:57.431865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87779 (* 1 = 5.87779 loss)
I0524 04:32:57.450879 11654 sgd_solver.cpp:112] Iteration 32730, lr = 0.1
I0524 04:33:05.678323 11654 solver.cpp:239] Iteration 32740 (1.21269 iter/s, 8.24614s/10 iters), loss = 5.27056
I0524 04:33:05.678597 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.27056 (* 1 = 5.27056 loss)
I0524 04:33:05.679136 11654 sgd_solver.cpp:112] Iteration 32740, lr = 0.1
I0524 04:33:14.294391 11654 solver.cpp:239] Iteration 32750 (1.1607 iter/s, 8.61553s/10 iters), loss = 6.7033
I0524 04:33:14.294443 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7033 (* 1 = 6.7033 loss)
I0524 04:33:15.551508 11654 sgd_solver.cpp:112] Iteration 32750, lr = 0.1
I0524 04:33:24.949930 11654 solver.cpp:239] Iteration 32760 (0.938519 iter/s, 10.6551s/10 iters), loss = 5.97196
I0524 04:33:24.949987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97196 (* 1 = 5.97196 loss)
I0524 04:33:24.950004 11654 sgd_solver.cpp:112] Iteration 32760, lr = 0.1
I0524 04:33:32.299278 11654 solver.cpp:239] Iteration 32770 (1.36113 iter/s, 7.34686s/10 iters), loss = 6.04436
I0524 04:33:32.299315 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04436 (* 1 = 6.04436 loss)
I0524 04:33:32.769372 11654 sgd_solver.cpp:112] Iteration 32770, lr = 0.1
I0524 04:33:39.984925 11654 solver.cpp:239] Iteration 32780 (1.30118 iter/s, 7.68531s/10 iters), loss = 6.20427
I0524 04:33:39.985163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20427 (* 1 = 6.20427 loss)
I0524 04:33:39.985214 11654 sgd_solver.cpp:112] Iteration 32780, lr = 0.1
I0524 04:33:48.049167 11654 solver.cpp:239] Iteration 32790 (1.24012 iter/s, 8.06374s/10 iters), loss = 6.95712
I0524 04:33:48.049221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95712 (* 1 = 6.95712 loss)
I0524 04:33:48.049237 11654 sgd_solver.cpp:112] Iteration 32790, lr = 0.1
I0524 04:33:54.002727 11654 solver.cpp:239] Iteration 32800 (1.68038 iter/s, 5.95105s/10 iters), loss = 5.70789
I0524 04:33:54.002787 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70789 (* 1 = 5.70789 loss)
I0524 04:33:54.003259 11654 sgd_solver.cpp:112] Iteration 32800, lr = 0.1
I0524 04:34:00.528424 11654 solver.cpp:239] Iteration 32810 (1.53248 iter/s, 6.52539s/10 iters), loss = 6.34879
I0524 04:34:00.528478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34879 (* 1 = 6.34879 loss)
I0524 04:34:00.529013 11654 sgd_solver.cpp:112] Iteration 32810, lr = 0.1
I0524 04:34:07.333768 11654 solver.cpp:239] Iteration 32820 (1.4695 iter/s, 6.80502s/10 iters), loss = 7.21658
I0524 04:34:07.333822 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21658 (* 1 = 7.21658 loss)
I0524 04:34:07.333837 11654 sgd_solver.cpp:112] Iteration 32820, lr = 0.1
I0524 04:34:14.546332 11654 solver.cpp:239] Iteration 32830 (1.38653 iter/s, 7.21224s/10 iters), loss = 6.41299
I0524 04:34:14.546591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41299 (* 1 = 6.41299 loss)
I0524 04:34:14.546648 11654 sgd_solver.cpp:112] Iteration 32830, lr = 0.1
I0524 04:34:21.178537 11654 solver.cpp:239] Iteration 32840 (1.50792 iter/s, 6.63167s/10 iters), loss = 6.90526
I0524 04:34:21.178591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90526 (* 1 = 6.90526 loss)
I0524 04:34:21.178874 11654 sgd_solver.cpp:112] Iteration 32840, lr = 0.1
I0524 04:34:29.576643 11654 solver.cpp:239] Iteration 32850 (1.1908 iter/s, 8.39773s/10 iters), loss = 5.90358
I0524 04:34:29.576700 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90358 (* 1 = 5.90358 loss)
I0524 04:34:29.576716 11654 sgd_solver.cpp:112] Iteration 32850, lr = 0.1
I0524 04:34:36.060554 11654 solver.cpp:239] Iteration 32860 (1.54288 iter/s, 6.4814s/10 iters), loss = 5.89983
I0524 04:34:36.060606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89983 (* 1 = 5.89983 loss)
I0524 04:34:36.060827 11654 sgd_solver.cpp:112] Iteration 32860, lr = 0.1
I0524 04:34:44.110682 11654 solver.cpp:239] Iteration 32870 (1.24227 iter/s, 8.04977s/10 iters), loss = 6.35007
I0524 04:34:44.110754 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35007 (* 1 = 6.35007 loss)
I0524 04:34:44.111136 11654 sgd_solver.cpp:112] Iteration 32870, lr = 0.1
I0524 04:34:51.506837 11654 solver.cpp:239] Iteration 32880 (1.35212 iter/s, 7.39579s/10 iters), loss = 6.19182
I0524 04:34:51.507097 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19182 (* 1 = 6.19182 loss)
I0524 04:34:51.507155 11654 sgd_solver.cpp:112] Iteration 32880, lr = 0.1
I0524 04:34:58.757246 11654 solver.cpp:239] Iteration 32890 (1.37933 iter/s, 7.24991s/10 iters), loss = 7.54083
I0524 04:34:58.757304 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54083 (* 1 = 7.54083 loss)
I0524 04:34:58.757688 11654 sgd_solver.cpp:112] Iteration 32890, lr = 0.1
I0524 04:35:05.856181 11654 solver.cpp:239] Iteration 32900 (1.40873 iter/s, 7.09861s/10 iters), loss = 6.37679
I0524 04:35:05.856231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37679 (* 1 = 6.37679 loss)
I0524 04:35:05.856248 11654 sgd_solver.cpp:112] Iteration 32900, lr = 0.1
I0524 04:35:13.026909 11654 solver.cpp:239] Iteration 32910 (1.39462 iter/s, 7.17041s/10 iters), loss = 6.40788
I0524 04:35:13.026949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40788 (* 1 = 6.40788 loss)
I0524 04:35:13.026963 11654 sgd_solver.cpp:112] Iteration 32910, lr = 0.1
I0524 04:35:19.449864 11654 solver.cpp:239] Iteration 32920 (1.55702 iter/s, 6.42254s/10 iters), loss = 6.9039
I0524 04:35:19.449919 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9039 (* 1 = 6.9039 loss)
I0524 04:35:19.449936 11654 sgd_solver.cpp:112] Iteration 32920, lr = 0.1
I0524 04:35:25.771472 11654 solver.cpp:239] Iteration 32930 (1.58197 iter/s, 6.32124s/10 iters), loss = 6.65563
I0524 04:35:25.771618 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65563 (* 1 = 6.65563 loss)
I0524 04:35:25.771638 11654 sgd_solver.cpp:112] Iteration 32930, lr = 0.1
I0524 04:35:34.337036 11654 solver.cpp:239] Iteration 32940 (1.16761 iter/s, 8.56451s/10 iters), loss = 6.46158
I0524 04:35:34.337095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46158 (* 1 = 6.46158 loss)
I0524 04:35:34.337116 11654 sgd_solver.cpp:112] Iteration 32940, lr = 0.1
I0524 04:35:41.932415 11654 solver.cpp:239] Iteration 32950 (1.31665 iter/s, 7.59503s/10 iters), loss = 6.60189
I0524 04:35:41.932476 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60189 (* 1 = 6.60189 loss)
I0524 04:35:41.932590 11654 sgd_solver.cpp:112] Iteration 32950, lr = 0.1
I0524 04:35:48.361081 11654 solver.cpp:239] Iteration 32960 (1.55561 iter/s, 6.42836s/10 iters), loss = 6.36667
I0524 04:35:48.361137 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36667 (* 1 = 6.36667 loss)
I0524 04:35:48.361155 11654 sgd_solver.cpp:112] Iteration 32960, lr = 0.1
I0524 04:35:57.422024 11654 solver.cpp:239] Iteration 32970 (1.10376 iter/s, 9.05993s/10 iters), loss = 5.94576
I0524 04:35:57.422257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94576 (* 1 = 5.94576 loss)
I0524 04:35:57.503296 11654 sgd_solver.cpp:112] Iteration 32970, lr = 0.1
I0524 04:36:03.564759 11654 solver.cpp:239] Iteration 32980 (1.62806 iter/s, 6.1423s/10 iters), loss = 5.74701
I0524 04:36:03.564805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74701 (* 1 = 5.74701 loss)
I0524 04:36:03.564827 11654 sgd_solver.cpp:112] Iteration 32980, lr = 0.1
I0524 04:36:10.910286 11654 solver.cpp:239] Iteration 32990 (1.36143 iter/s, 7.34519s/10 iters), loss = 5.93588
I0524 04:36:10.910337 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93588 (* 1 = 5.93588 loss)
I0524 04:36:10.910354 11654 sgd_solver.cpp:112] Iteration 32990, lr = 0.1
I0524 04:36:16.852867 11654 solver.cpp:239] Iteration 33000 (1.68285 iter/s, 5.9423s/10 iters), loss = 6.85986
I0524 04:36:16.852916 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85986 (* 1 = 6.85986 loss)
I0524 04:36:16.853169 11654 sgd_solver.cpp:112] Iteration 33000, lr = 0.1
I0524 04:36:24.305673 11654 solver.cpp:239] Iteration 33010 (1.34184 iter/s, 7.45247s/10 iters), loss = 5.93381
I0524 04:36:24.305718 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93381 (* 1 = 5.93381 loss)
I0524 04:36:24.512683 11654 sgd_solver.cpp:112] Iteration 33010, lr = 0.1
I0524 04:36:31.517885 11654 solver.cpp:239] Iteration 33020 (1.3866 iter/s, 7.21188s/10 iters), loss = 6.10613
I0524 04:36:31.518151 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10613 (* 1 = 6.10613 loss)
I0524 04:36:31.518254 11654 sgd_solver.cpp:112] Iteration 33020, lr = 0.1
I0524 04:36:38.252915 11654 solver.cpp:239] Iteration 33030 (1.48488 iter/s, 6.73455s/10 iters), loss = 6.07919
I0524 04:36:38.252969 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07919 (* 1 = 6.07919 loss)
I0524 04:36:38.252985 11654 sgd_solver.cpp:112] Iteration 33030, lr = 0.1
I0524 04:36:46.920001 11654 solver.cpp:239] Iteration 33040 (1.15387 iter/s, 8.66651s/10 iters), loss = 6.9071
I0524 04:36:46.920051 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9071 (* 1 = 6.9071 loss)
I0524 04:36:46.984927 11654 sgd_solver.cpp:112] Iteration 33040, lr = 0.1
I0524 04:36:54.398572 11654 solver.cpp:239] Iteration 33050 (1.33722 iter/s, 7.47822s/10 iters), loss = 5.663
I0524 04:36:54.398632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.663 (* 1 = 5.663 loss)
I0524 04:36:54.399085 11654 sgd_solver.cpp:112] Iteration 33050, lr = 0.1
I0524 04:37:00.884097 11654 solver.cpp:239] Iteration 33060 (1.54197 iter/s, 6.48522s/10 iters), loss = 5.42459
I0524 04:37:00.884142 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42459 (* 1 = 5.42459 loss)
I0524 04:37:00.907601 11654 sgd_solver.cpp:112] Iteration 33060, lr = 0.1
I0524 04:37:08.617005 11654 solver.cpp:239] Iteration 33070 (1.29323 iter/s, 7.73256s/10 iters), loss = 7.53935
I0524 04:37:08.617276 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.53935 (* 1 = 7.53935 loss)
I0524 04:37:08.617336 11654 sgd_solver.cpp:112] Iteration 33070, lr = 0.1
I0524 04:37:15.282964 11654 solver.cpp:239] Iteration 33080 (1.50028 iter/s, 6.66544s/10 iters), loss = 5.49364
I0524 04:37:15.283018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49364 (* 1 = 5.49364 loss)
I0524 04:37:15.283120 11654 sgd_solver.cpp:112] Iteration 33080, lr = 0.1
I0524 04:37:22.211948 11654 solver.cpp:239] Iteration 33090 (1.44328 iter/s, 6.92867s/10 iters), loss = 6.52112
I0524 04:37:22.212005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52112 (* 1 = 6.52112 loss)
I0524 04:37:22.212144 11654 sgd_solver.cpp:112] Iteration 33090, lr = 0.1
I0524 04:37:29.595633 11654 solver.cpp:239] Iteration 33100 (1.3544 iter/s, 7.38335s/10 iters), loss = 6.18851
I0524 04:37:29.595679 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18851 (* 1 = 6.18851 loss)
I0524 04:37:29.596254 11654 sgd_solver.cpp:112] Iteration 33100, lr = 0.1
I0524 04:37:36.857017 11654 solver.cpp:239] Iteration 33110 (1.37721 iter/s, 7.26106s/10 iters), loss = 5.31275
I0524 04:37:36.857066 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.31275 (* 1 = 5.31275 loss)
I0524 04:37:36.857084 11654 sgd_solver.cpp:112] Iteration 33110, lr = 0.1
I0524 04:37:43.175137 11654 solver.cpp:239] Iteration 33120 (1.58282 iter/s, 6.31782s/10 iters), loss = 6.59704
I0524 04:37:43.175287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59704 (* 1 = 6.59704 loss)
I0524 04:37:43.287190 11654 sgd_solver.cpp:112] Iteration 33120, lr = 0.1
I0524 04:37:49.293962 11654 solver.cpp:239] Iteration 33130 (1.6344 iter/s, 6.11844s/10 iters), loss = 5.9188
I0524 04:37:49.294015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9188 (* 1 = 5.9188 loss)
I0524 04:37:49.294339 11654 sgd_solver.cpp:112] Iteration 33130, lr = 0.1
I0524 04:37:57.282220 11654 solver.cpp:239] Iteration 33140 (1.25189 iter/s, 7.9879s/10 iters), loss = 6.96114
I0524 04:37:57.282269 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96114 (* 1 = 6.96114 loss)
I0524 04:37:57.282691 11654 sgd_solver.cpp:112] Iteration 33140, lr = 0.1
I0524 04:38:04.641387 11654 solver.cpp:239] Iteration 33150 (1.35891 iter/s, 7.35884s/10 iters), loss = 6.61326
I0524 04:38:04.641432 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61326 (* 1 = 6.61326 loss)
I0524 04:38:04.641547 11654 sgd_solver.cpp:112] Iteration 33150, lr = 0.1
I0524 04:38:12.082942 11654 solver.cpp:239] Iteration 33160 (1.34387 iter/s, 7.44121s/10 iters), loss = 6.85222
I0524 04:38:12.083003 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85222 (* 1 = 6.85222 loss)
I0524 04:38:12.083619 11654 sgd_solver.cpp:112] Iteration 33160, lr = 0.1
I0524 04:38:19.293153 11654 solver.cpp:239] Iteration 33170 (1.38699 iter/s, 7.20988s/10 iters), loss = 5.89606
I0524 04:38:19.293256 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89606 (* 1 = 5.89606 loss)
I0524 04:38:19.293274 11654 sgd_solver.cpp:112] Iteration 33170, lr = 0.1
I0524 04:38:26.069128 11654 solver.cpp:239] Iteration 33180 (1.47589 iter/s, 6.77559s/10 iters), loss = 5.9926
I0524 04:38:26.069176 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9926 (* 1 = 5.9926 loss)
I0524 04:38:26.069675 11654 sgd_solver.cpp:112] Iteration 33180, lr = 0.1
I0524 04:38:32.545732 11654 solver.cpp:239] Iteration 33190 (1.54409 iter/s, 6.4763s/10 iters), loss = 4.5761
I0524 04:38:32.545795 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.5761 (* 1 = 4.5761 loss)
I0524 04:38:32.546136 11654 sgd_solver.cpp:112] Iteration 33190, lr = 0.1
I0524 04:38:40.314252 11654 solver.cpp:239] Iteration 33200 (1.2873 iter/s, 7.76817s/10 iters), loss = 6.78733
I0524 04:38:40.314303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78733 (* 1 = 6.78733 loss)
I0524 04:38:40.314357 11654 sgd_solver.cpp:112] Iteration 33200, lr = 0.1
I0524 04:38:49.406973 11654 solver.cpp:239] Iteration 33210 (1.09983 iter/s, 9.09233s/10 iters), loss = 6.01563
I0524 04:38:49.407264 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01563 (* 1 = 6.01563 loss)
I0524 04:38:49.407318 11654 sgd_solver.cpp:112] Iteration 33210, lr = 0.1
I0524 04:38:56.064606 11654 solver.cpp:239] Iteration 33220 (1.5026 iter/s, 6.65511s/10 iters), loss = 4.8707
I0524 04:38:56.064661 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.8707 (* 1 = 4.8707 loss)
I0524 04:38:56.064728 11654 sgd_solver.cpp:112] Iteration 33220, lr = 0.1
I0524 04:39:02.887178 11654 solver.cpp:239] Iteration 33230 (1.46579 iter/s, 6.82225s/10 iters), loss = 6.23898
I0524 04:39:02.887234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23898 (* 1 = 6.23898 loss)
I0524 04:39:02.887253 11654 sgd_solver.cpp:112] Iteration 33230, lr = 0.1
I0524 04:39:09.487587 11654 solver.cpp:239] Iteration 33240 (1.51515 iter/s, 6.60001s/10 iters), loss = 6.15203
I0524 04:39:09.487646 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15203 (* 1 = 6.15203 loss)
I0524 04:39:09.487758 11654 sgd_solver.cpp:112] Iteration 33240, lr = 0.1
I0524 04:39:17.129173 11654 solver.cpp:239] Iteration 33250 (1.30869 iter/s, 7.64124s/10 iters), loss = 6.54691
I0524 04:39:17.129232 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54691 (* 1 = 6.54691 loss)
I0524 04:39:17.129393 11654 sgd_solver.cpp:112] Iteration 33250, lr = 0.1
I0524 04:39:23.206578 11654 solver.cpp:239] Iteration 33260 (1.64552 iter/s, 6.07712s/10 iters), loss = 6.73483
I0524 04:39:23.206773 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73483 (* 1 = 6.73483 loss)
I0524 04:39:23.206791 11654 sgd_solver.cpp:112] Iteration 33260, lr = 0.1
I0524 04:39:29.283495 11654 solver.cpp:239] Iteration 33270 (1.6457 iter/s, 6.07644s/10 iters), loss = 6.35335
I0524 04:39:29.283560 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35335 (* 1 = 6.35335 loss)
I0524 04:39:29.283974 11654 sgd_solver.cpp:112] Iteration 33270, lr = 0.1
I0524 04:39:35.751547 11654 solver.cpp:239] Iteration 33280 (1.54613 iter/s, 6.46775s/10 iters), loss = 6.50019
I0524 04:39:35.751595 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50019 (* 1 = 6.50019 loss)
I0524 04:39:35.751968 11654 sgd_solver.cpp:112] Iteration 33280, lr = 0.1
I0524 04:39:43.407203 11654 solver.cpp:239] Iteration 33290 (1.30628 iter/s, 7.6553s/10 iters), loss = 6.1975
I0524 04:39:43.407263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1975 (* 1 = 6.1975 loss)
I0524 04:39:43.407402 11654 sgd_solver.cpp:112] Iteration 33290, lr = 0.1
I0524 04:39:49.876973 11654 solver.cpp:239] Iteration 33300 (1.54572 iter/s, 6.46946s/10 iters), loss = 6.69521
I0524 04:39:49.877035 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69521 (* 1 = 6.69521 loss)
I0524 04:39:49.877239 11654 sgd_solver.cpp:112] Iteration 33300, lr = 0.1
I0524 04:39:57.375669 11654 solver.cpp:239] Iteration 33310 (1.33363 iter/s, 7.49836s/10 iters), loss = 7.11044
I0524 04:39:57.375758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11044 (* 1 = 7.11044 loss)
I0524 04:39:57.375772 11654 sgd_solver.cpp:112] Iteration 33310, lr = 0.1
I0524 04:40:04.102558 11654 solver.cpp:239] Iteration 33320 (1.48666 iter/s, 6.72651s/10 iters), loss = 6.38094
I0524 04:40:04.102613 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38094 (* 1 = 6.38094 loss)
I0524 04:40:04.102926 11654 sgd_solver.cpp:112] Iteration 33320, lr = 0.1
I0524 04:40:10.239292 11654 solver.cpp:239] Iteration 33330 (1.62961 iter/s, 6.13645s/10 iters), loss = 7.22805
I0524 04:40:10.239334 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22805 (* 1 = 7.22805 loss)
I0524 04:40:10.239542 11654 sgd_solver.cpp:112] Iteration 33330, lr = 0.1
I0524 04:40:16.947631 11654 solver.cpp:239] Iteration 33340 (1.49075 iter/s, 6.70804s/10 iters), loss = 6.5064
I0524 04:40:16.947692 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5064 (* 1 = 6.5064 loss)
I0524 04:40:16.947722 11654 sgd_solver.cpp:112] Iteration 33340, lr = 0.1
I0524 04:40:24.923107 11654 solver.cpp:239] Iteration 33350 (1.25391 iter/s, 7.97506s/10 iters), loss = 6.73185
I0524 04:40:24.923163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73185 (* 1 = 6.73185 loss)
I0524 04:40:24.923584 11654 sgd_solver.cpp:112] Iteration 33350, lr = 0.1
I0524 04:40:31.458590 11654 solver.cpp:239] Iteration 33360 (1.53018 iter/s, 6.53518s/10 iters), loss = 6.14091
I0524 04:40:31.458801 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14091 (* 1 = 6.14091 loss)
I0524 04:40:31.458832 11654 sgd_solver.cpp:112] Iteration 33360, lr = 0.1
I0524 04:40:38.178019 11654 solver.cpp:239] Iteration 33370 (1.48833 iter/s, 6.71893s/10 iters), loss = 6.54709
I0524 04:40:38.178079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54709 (* 1 = 6.54709 loss)
I0524 04:40:38.178192 11654 sgd_solver.cpp:112] Iteration 33370, lr = 0.1
I0524 04:40:44.781251 11654 solver.cpp:239] Iteration 33380 (1.51448 iter/s, 6.60293s/10 iters), loss = 6.34939
I0524 04:40:44.781296 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34939 (* 1 = 6.34939 loss)
I0524 04:40:44.781838 11654 sgd_solver.cpp:112] Iteration 33380, lr = 0.1
I0524 04:40:51.582706 11654 solver.cpp:239] Iteration 33390 (1.47034 iter/s, 6.80113s/10 iters), loss = 5.46925
I0524 04:40:51.582756 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46925 (* 1 = 5.46925 loss)
I0524 04:40:51.771334 11654 sgd_solver.cpp:112] Iteration 33390, lr = 0.1
I0524 04:40:58.137619 11654 solver.cpp:239] Iteration 33400 (1.52564 iter/s, 6.55461s/10 iters), loss = 5.5907
I0524 04:40:58.137665 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5907 (* 1 = 5.5907 loss)
I0524 04:40:58.138095 11654 sgd_solver.cpp:112] Iteration 33400, lr = 0.1
I0524 04:41:05.820585 11654 solver.cpp:239] Iteration 33410 (1.30164 iter/s, 7.68261s/10 iters), loss = 5.82085
I0524 04:41:05.820737 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82085 (* 1 = 5.82085 loss)
I0524 04:41:05.821096 11654 sgd_solver.cpp:112] Iteration 33410, lr = 0.1
I0524 04:41:12.563743 11654 solver.cpp:239] Iteration 33420 (1.48307 iter/s, 6.74275s/10 iters), loss = 6.34551
I0524 04:41:12.563808 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34551 (* 1 = 6.34551 loss)
I0524 04:41:13.030908 11654 sgd_solver.cpp:112] Iteration 33420, lr = 0.1
I0524 04:41:19.474885 11654 solver.cpp:239] Iteration 33430 (1.44701 iter/s, 6.91081s/10 iters), loss = 6.65957
I0524 04:41:19.474946 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65957 (* 1 = 6.65957 loss)
I0524 04:41:19.475052 11654 sgd_solver.cpp:112] Iteration 33430, lr = 0.1
I0524 04:41:27.078732 11654 solver.cpp:239] Iteration 33440 (1.31519 iter/s, 7.60349s/10 iters), loss = 6.38304
I0524 04:41:27.078771 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38304 (* 1 = 6.38304 loss)
I0524 04:41:27.078788 11654 sgd_solver.cpp:112] Iteration 33440, lr = 0.1
I0524 04:41:35.173562 11654 solver.cpp:239] Iteration 33450 (1.23542 iter/s, 8.0944s/10 iters), loss = 6.01038
I0524 04:41:35.173612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01038 (* 1 = 6.01038 loss)
I0524 04:41:35.844015 11654 sgd_solver.cpp:112] Iteration 33450, lr = 0.1
I0524 04:41:44.041172 11654 solver.cpp:239] Iteration 33460 (1.12775 iter/s, 8.86722s/10 iters), loss = 6.85175
I0524 04:41:44.041226 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85175 (* 1 = 6.85175 loss)
I0524 04:41:44.041615 11654 sgd_solver.cpp:112] Iteration 33460, lr = 0.1
I0524 04:41:50.225533 11654 solver.cpp:239] Iteration 33470 (1.61706 iter/s, 6.18406s/10 iters), loss = 6.03309
I0524 04:41:50.225594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03309 (* 1 = 6.03309 loss)
I0524 04:41:50.225812 11654 sgd_solver.cpp:112] Iteration 33470, lr = 0.1
I0524 04:41:57.511518 11654 solver.cpp:239] Iteration 33480 (1.37256 iter/s, 7.28565s/10 iters), loss = 5.88481
I0524 04:41:57.511571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88481 (* 1 = 5.88481 loss)
I0524 04:41:57.512090 11654 sgd_solver.cpp:112] Iteration 33480, lr = 0.1
I0524 04:42:04.704267 11654 solver.cpp:239] Iteration 33490 (1.39035 iter/s, 7.19243s/10 iters), loss = 5.28789
I0524 04:42:04.704306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28789 (* 1 = 5.28789 loss)
I0524 04:42:04.940027 11654 sgd_solver.cpp:112] Iteration 33490, lr = 0.1
I0524 04:42:12.007753 11654 solver.cpp:239] Iteration 33500 (1.36927 iter/s, 7.30315s/10 iters), loss = 5.88183
I0524 04:42:12.008074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88183 (* 1 = 5.88183 loss)
I0524 04:42:12.008272 11654 sgd_solver.cpp:112] Iteration 33500, lr = 0.1
I0524 04:42:19.594164 11654 solver.cpp:239] Iteration 33510 (1.31824 iter/s, 7.58587s/10 iters), loss = 6.40027
I0524 04:42:19.594218 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40027 (* 1 = 6.40027 loss)
I0524 04:42:19.964244 11654 sgd_solver.cpp:112] Iteration 33510, lr = 0.1
I0524 04:42:26.130970 11654 solver.cpp:239] Iteration 33520 (1.52987 iter/s, 6.5365s/10 iters), loss = 6.8131
I0524 04:42:26.131026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8131 (* 1 = 6.8131 loss)
I0524 04:42:26.131448 11654 sgd_solver.cpp:112] Iteration 33520, lr = 0.1
I0524 04:42:32.295262 11654 solver.cpp:239] Iteration 33530 (1.62232 iter/s, 6.164s/10 iters), loss = 5.40938
I0524 04:42:32.295317 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40938 (* 1 = 5.40938 loss)
I0524 04:42:32.295564 11654 sgd_solver.cpp:112] Iteration 33530, lr = 0.1
I0524 04:42:39.132283 11654 solver.cpp:239] Iteration 33540 (1.46269 iter/s, 6.83671s/10 iters), loss = 7.02689
I0524 04:42:39.132326 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02689 (* 1 = 7.02689 loss)
I0524 04:42:39.313653 11654 sgd_solver.cpp:112] Iteration 33540, lr = 0.1
I0524 04:42:45.814520 11654 solver.cpp:239] Iteration 33550 (1.49658 iter/s, 6.68192s/10 iters), loss = 7.10461
I0524 04:42:45.814610 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10461 (* 1 = 7.10461 loss)
I0524 04:42:45.814796 11654 sgd_solver.cpp:112] Iteration 33550, lr = 0.1
I0524 04:42:53.408929 11654 solver.cpp:239] Iteration 33560 (1.31682 iter/s, 7.59403s/10 iters), loss = 6.55893
I0524 04:42:53.408982 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55893 (* 1 = 6.55893 loss)
I0524 04:42:53.435273 11654 sgd_solver.cpp:112] Iteration 33560, lr = 0.1
I0524 04:43:01.816854 11654 solver.cpp:239] Iteration 33570 (1.18941 iter/s, 8.40754s/10 iters), loss = 5.49844
I0524 04:43:01.816910 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49844 (* 1 = 5.49844 loss)
I0524 04:43:01.817342 11654 sgd_solver.cpp:112] Iteration 33570, lr = 0.1
I0524 04:43:08.430418 11654 solver.cpp:239] Iteration 33580 (1.51212 iter/s, 6.61325s/10 iters), loss = 5.39978
I0524 04:43:08.430471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.39978 (* 1 = 5.39978 loss)
I0524 04:43:08.430487 11654 sgd_solver.cpp:112] Iteration 33580, lr = 0.1
I0524 04:43:17.439908 11654 solver.cpp:239] Iteration 33590 (1.10999 iter/s, 9.0091s/10 iters), loss = 5.79975
I0524 04:43:17.440008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79975 (* 1 = 5.79975 loss)
I0524 04:43:17.440026 11654 sgd_solver.cpp:112] Iteration 33590, lr = 0.1
I0524 04:43:23.656985 11654 solver.cpp:239] Iteration 33600 (1.60912 iter/s, 6.21456s/10 iters), loss = 5.72616
I0524 04:43:23.657042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72616 (* 1 = 5.72616 loss)
I0524 04:43:23.657289 11654 sgd_solver.cpp:112] Iteration 33600, lr = 0.1
I0524 04:43:31.924757 11654 solver.cpp:239] Iteration 33610 (1.20957 iter/s, 8.26741s/10 iters), loss = 7.64444
I0524 04:43:31.924809 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.64444 (* 1 = 7.64444 loss)
I0524 04:43:31.924825 11654 sgd_solver.cpp:112] Iteration 33610, lr = 0.1
I0524 04:43:41.093535 11654 solver.cpp:239] Iteration 33620 (1.09071 iter/s, 9.16838s/10 iters), loss = 6.90545
I0524 04:43:41.093586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90545 (* 1 = 6.90545 loss)
I0524 04:43:41.785063 11654 sgd_solver.cpp:112] Iteration 33620, lr = 0.1
I0524 04:43:48.338750 11654 solver.cpp:239] Iteration 33630 (1.38029 iter/s, 7.24487s/10 iters), loss = 7.08604
I0524 04:43:48.339015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08604 (* 1 = 7.08604 loss)
I0524 04:43:48.339066 11654 sgd_solver.cpp:112] Iteration 33630, lr = 0.1
I0524 04:43:54.376080 11654 solver.cpp:239] Iteration 33640 (1.65661 iter/s, 6.03641s/10 iters), loss = 5.00222
I0524 04:43:54.376117 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.00222 (* 1 = 5.00222 loss)
I0524 04:43:54.389243 11654 sgd_solver.cpp:112] Iteration 33640, lr = 0.1
I0524 04:44:01.614261 11654 solver.cpp:239] Iteration 33650 (1.38162 iter/s, 7.23786s/10 iters), loss = 6.21543
I0524 04:44:01.614315 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21543 (* 1 = 6.21543 loss)
I0524 04:44:01.614550 11654 sgd_solver.cpp:112] Iteration 33650, lr = 0.1
I0524 04:44:07.757812 11654 solver.cpp:239] Iteration 33660 (1.6278 iter/s, 6.14327s/10 iters), loss = 6.69708
I0524 04:44:07.757855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69708 (* 1 = 6.69708 loss)
I0524 04:44:08.642877 11654 sgd_solver.cpp:112] Iteration 33660, lr = 0.1
I0524 04:44:16.576604 11654 solver.cpp:239] Iteration 33670 (1.13399 iter/s, 8.81841s/10 iters), loss = 5.71266
I0524 04:44:16.576653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71266 (* 1 = 5.71266 loss)
I0524 04:44:16.576666 11654 sgd_solver.cpp:112] Iteration 33670, lr = 0.1
I0524 04:44:26.516657 11654 solver.cpp:239] Iteration 33680 (1.00607 iter/s, 9.93962s/10 iters), loss = 6.54415
I0524 04:44:26.516772 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54415 (* 1 = 6.54415 loss)
I0524 04:44:26.516794 11654 sgd_solver.cpp:112] Iteration 33680, lr = 0.1
I0524 04:44:33.226336 11654 solver.cpp:239] Iteration 33690 (1.49095 iter/s, 6.70715s/10 iters), loss = 6.77938
I0524 04:44:33.226373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77938 (* 1 = 6.77938 loss)
I0524 04:44:33.242403 11654 sgd_solver.cpp:112] Iteration 33690, lr = 0.1
I0524 04:44:39.411404 11654 solver.cpp:239] Iteration 33700 (1.61687 iter/s, 6.18477s/10 iters), loss = 7.79064
I0524 04:44:39.411463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.79064 (* 1 = 7.79064 loss)
I0524 04:44:39.411583 11654 sgd_solver.cpp:112] Iteration 33700, lr = 0.1
I0524 04:44:46.739863 11654 solver.cpp:239] Iteration 33710 (1.36461 iter/s, 7.32812s/10 iters), loss = 6.59256
I0524 04:44:46.739912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59256 (* 1 = 6.59256 loss)
I0524 04:44:46.739928 11654 sgd_solver.cpp:112] Iteration 33710, lr = 0.1
I0524 04:44:53.432387 11654 solver.cpp:239] Iteration 33720 (1.49427 iter/s, 6.69222s/10 iters), loss = 6.05278
I0524 04:44:53.432436 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05278 (* 1 = 6.05278 loss)
I0524 04:44:54.115356 11654 sgd_solver.cpp:112] Iteration 33720, lr = 0.1
I0524 04:45:02.471511 11654 solver.cpp:239] Iteration 33730 (1.10635 iter/s, 9.03872s/10 iters), loss = 5.33635
I0524 04:45:02.471799 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.33635 (* 1 = 5.33635 loss)
I0524 04:45:02.471856 11654 sgd_solver.cpp:112] Iteration 33730, lr = 0.1
I0524 04:45:08.958526 11654 solver.cpp:239] Iteration 33740 (1.5417 iter/s, 6.48633s/10 iters), loss = 6.15522
I0524 04:45:08.958575 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15522 (* 1 = 6.15522 loss)
I0524 04:45:08.958926 11654 sgd_solver.cpp:112] Iteration 33740, lr = 0.1
I0524 04:45:15.587942 11654 solver.cpp:239] Iteration 33750 (1.5085 iter/s, 6.6291s/10 iters), loss = 6.66807
I0524 04:45:15.588009 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66807 (* 1 = 6.66807 loss)
I0524 04:45:15.588076 11654 sgd_solver.cpp:112] Iteration 33750, lr = 0.1
I0524 04:45:22.330216 11654 solver.cpp:239] Iteration 33760 (1.48325 iter/s, 6.74195s/10 iters), loss = 7.27349
I0524 04:45:22.330278 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27349 (* 1 = 7.27349 loss)
I0524 04:45:22.330538 11654 sgd_solver.cpp:112] Iteration 33760, lr = 0.1
I0524 04:45:29.084072 11654 solver.cpp:239] Iteration 33770 (1.4807 iter/s, 6.75355s/10 iters), loss = 6.86587
I0524 04:45:29.084108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86587 (* 1 = 6.86587 loss)
I0524 04:45:29.084121 11654 sgd_solver.cpp:112] Iteration 33770, lr = 0.1
I0524 04:45:36.775411 11654 solver.cpp:239] Iteration 33780 (1.30022 iter/s, 7.691s/10 iters), loss = 7.57282
I0524 04:45:36.775688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.57282 (* 1 = 7.57282 loss)
I0524 04:45:36.775730 11654 sgd_solver.cpp:112] Iteration 33780, lr = 0.1
I0524 04:45:44.299063 11654 solver.cpp:239] Iteration 33790 (1.32924 iter/s, 7.52308s/10 iters), loss = 6.22579
I0524 04:45:44.299131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22579 (* 1 = 6.22579 loss)
I0524 04:45:44.299154 11654 sgd_solver.cpp:112] Iteration 33790, lr = 0.1
I0524 04:45:51.817332 11654 solver.cpp:239] Iteration 33800 (1.33055 iter/s, 7.51569s/10 iters), loss = 5.40416
I0524 04:45:51.817373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40416 (* 1 = 5.40416 loss)
I0524 04:45:51.817417 11654 sgd_solver.cpp:112] Iteration 33800, lr = 0.1
I0524 04:45:59.137056 11654 solver.cpp:239] Iteration 33810 (1.36623 iter/s, 7.3194s/10 iters), loss = 5.65596
I0524 04:45:59.137111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65596 (* 1 = 5.65596 loss)
I0524 04:45:59.166249 11654 sgd_solver.cpp:112] Iteration 33810, lr = 0.1
I0524 04:46:06.541610 11654 solver.cpp:239] Iteration 33820 (1.35098 iter/s, 7.40205s/10 iters), loss = 6.46931
I0524 04:46:06.541668 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46931 (* 1 = 6.46931 loss)
I0524 04:46:06.541703 11654 sgd_solver.cpp:112] Iteration 33820, lr = 0.1
I0524 04:46:13.646674 11654 solver.cpp:239] Iteration 33830 (1.40751 iter/s, 7.10474s/10 iters), loss = 6.46646
I0524 04:46:13.646980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46646 (* 1 = 6.46646 loss)
I0524 04:46:13.647045 11654 sgd_solver.cpp:112] Iteration 33830, lr = 0.1
I0524 04:46:20.520236 11654 solver.cpp:239] Iteration 33840 (1.45539 iter/s, 6.87101s/10 iters), loss = 6.69278
I0524 04:46:20.520309 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69278 (* 1 = 6.69278 loss)
I0524 04:46:20.524571 11654 sgd_solver.cpp:112] Iteration 33840, lr = 0.1
I0524 04:46:26.748841 11654 solver.cpp:239] Iteration 33850 (1.60558 iter/s, 6.22829s/10 iters), loss = 6.13548
I0524 04:46:26.748900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13548 (* 1 = 6.13548 loss)
I0524 04:46:26.749275 11654 sgd_solver.cpp:112] Iteration 33850, lr = 0.1
I0524 04:46:34.070852 11654 solver.cpp:239] Iteration 33860 (1.36581 iter/s, 7.32168s/10 iters), loss = 6.94505
I0524 04:46:34.070905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94505 (* 1 = 6.94505 loss)
I0524 04:46:34.071156 11654 sgd_solver.cpp:112] Iteration 33860, lr = 0.1
I0524 04:46:41.018944 11654 solver.cpp:239] Iteration 33870 (1.43931 iter/s, 6.94778s/10 iters), loss = 6.27869
I0524 04:46:41.018985 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27869 (* 1 = 6.27869 loss)
I0524 04:46:41.756505 11654 sgd_solver.cpp:112] Iteration 33870, lr = 0.1
I0524 04:46:48.935303 11654 solver.cpp:239] Iteration 33880 (1.26326 iter/s, 7.916s/10 iters), loss = 5.87192
I0524 04:46:48.935578 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87192 (* 1 = 5.87192 loss)
I0524 04:46:48.987437 11654 sgd_solver.cpp:112] Iteration 33880, lr = 0.1
I0524 04:46:55.773818 11654 solver.cpp:239] Iteration 33890 (1.46241 iter/s, 6.83802s/10 iters), loss = 6.82363
I0524 04:46:55.773872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82363 (* 1 = 6.82363 loss)
I0524 04:46:55.844123 11654 sgd_solver.cpp:112] Iteration 33890, lr = 0.1
I0524 04:47:02.898324 11654 solver.cpp:239] Iteration 33900 (1.40367 iter/s, 7.12418s/10 iters), loss = 6.92455
I0524 04:47:02.898363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92455 (* 1 = 6.92455 loss)
I0524 04:47:03.411726 11654 sgd_solver.cpp:112] Iteration 33900, lr = 0.1
I0524 04:47:10.703956 11654 solver.cpp:239] Iteration 33910 (1.28118 iter/s, 7.80528s/10 iters), loss = 6.18859
I0524 04:47:10.704016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18859 (* 1 = 6.18859 loss)
I0524 04:47:10.704192 11654 sgd_solver.cpp:112] Iteration 33910, lr = 0.1
I0524 04:47:21.138052 11654 solver.cpp:239] Iteration 33920 (0.958438 iter/s, 10.4336s/10 iters), loss = 6.39639
I0524 04:47:21.138317 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39639 (* 1 = 6.39639 loss)
I0524 04:47:21.328744 11654 sgd_solver.cpp:112] Iteration 33920, lr = 0.1
I0524 04:47:28.064132 11654 solver.cpp:239] Iteration 33930 (1.44392 iter/s, 6.9256s/10 iters), loss = 6.24486
I0524 04:47:28.064179 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24486 (* 1 = 6.24486 loss)
I0524 04:47:28.073496 11654 sgd_solver.cpp:112] Iteration 33930, lr = 0.1
I0524 04:47:34.720901 11654 solver.cpp:239] Iteration 33940 (1.5023 iter/s, 6.65646s/10 iters), loss = 5.81044
I0524 04:47:34.720949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81044 (* 1 = 5.81044 loss)
I0524 04:47:34.721302 11654 sgd_solver.cpp:112] Iteration 33940, lr = 0.1
I0524 04:47:42.546903 11654 solver.cpp:239] Iteration 33950 (1.27785 iter/s, 7.82562s/10 iters), loss = 5.59142
I0524 04:47:42.546965 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59142 (* 1 = 5.59142 loss)
I0524 04:47:42.547235 11654 sgd_solver.cpp:112] Iteration 33950, lr = 0.1
I0524 04:47:49.969986 11654 solver.cpp:239] Iteration 33960 (1.34721 iter/s, 7.42274s/10 iters), loss = 6.52435
I0524 04:47:49.970036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52435 (* 1 = 6.52435 loss)
I0524 04:47:49.970188 11654 sgd_solver.cpp:112] Iteration 33960, lr = 0.1
I0524 04:47:56.249758 11654 solver.cpp:239] Iteration 33970 (1.59249 iter/s, 6.27948s/10 iters), loss = 6.36074
I0524 04:47:56.250071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36074 (* 1 = 6.36074 loss)
I0524 04:47:56.250133 11654 sgd_solver.cpp:112] Iteration 33970, lr = 0.1
I0524 04:48:03.134052 11654 solver.cpp:239] Iteration 33980 (1.45272 iter/s, 6.88365s/10 iters), loss = 5.82582
I0524 04:48:03.134094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82582 (* 1 = 5.82582 loss)
I0524 04:48:03.134233 11654 sgd_solver.cpp:112] Iteration 33980, lr = 0.1
I0524 04:48:10.116837 11654 solver.cpp:239] Iteration 33990 (1.43216 iter/s, 6.98247s/10 iters), loss = 6.28764
I0524 04:48:10.116888 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28764 (* 1 = 6.28764 loss)
I0524 04:48:10.116904 11654 sgd_solver.cpp:112] Iteration 33990, lr = 0.1
I0524 04:48:16.641444 11654 solver.cpp:239] Iteration 34000 (1.53275 iter/s, 6.52424s/10 iters), loss = 6.62196
I0524 04:48:16.641505 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62196 (* 1 = 6.62196 loss)
I0524 04:48:16.641553 11654 sgd_solver.cpp:112] Iteration 34000, lr = 0.1
I0524 04:48:23.987571 11654 solver.cpp:239] Iteration 34010 (1.36132 iter/s, 7.34579s/10 iters), loss = 5.32074
I0524 04:48:23.987617 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.32074 (* 1 = 5.32074 loss)
I0524 04:48:23.987632 11654 sgd_solver.cpp:112] Iteration 34010, lr = 0.1
I0524 04:48:31.719506 11654 solver.cpp:239] Iteration 34020 (1.29339 iter/s, 7.7316s/10 iters), loss = 6.44375
I0524 04:48:31.719782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44375 (* 1 = 6.44375 loss)
I0524 04:48:31.726588 11654 sgd_solver.cpp:112] Iteration 34020, lr = 0.1
I0524 04:48:37.901681 11654 solver.cpp:239] Iteration 34030 (1.61768 iter/s, 6.18169s/10 iters), loss = 6.92864
I0524 04:48:37.901733 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92864 (* 1 = 6.92864 loss)
I0524 04:48:37.901955 11654 sgd_solver.cpp:112] Iteration 34030, lr = 0.1
I0524 04:48:44.685519 11654 solver.cpp:239] Iteration 34040 (1.47416 iter/s, 6.78353s/10 iters), loss = 6.52433
I0524 04:48:44.685570 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52433 (* 1 = 6.52433 loss)
I0524 04:48:45.349290 11654 sgd_solver.cpp:112] Iteration 34040, lr = 0.1
I0524 04:48:53.450335 11654 solver.cpp:239] Iteration 34050 (1.14098 iter/s, 8.76442s/10 iters), loss = 5.99122
I0524 04:48:53.450397 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99122 (* 1 = 5.99122 loss)
I0524 04:48:53.862038 11654 sgd_solver.cpp:112] Iteration 34050, lr = 0.1
I0524 04:49:00.566763 11654 solver.cpp:239] Iteration 34060 (1.40527 iter/s, 7.11608s/10 iters), loss = 5.99129
I0524 04:49:00.566823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99129 (* 1 = 5.99129 loss)
I0524 04:49:00.566890 11654 sgd_solver.cpp:112] Iteration 34060, lr = 0.1
I0524 04:49:07.914566 11654 solver.cpp:239] Iteration 34070 (1.36102 iter/s, 7.34746s/10 iters), loss = 7.60296
I0524 04:49:07.914888 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.60296 (* 1 = 7.60296 loss)
I0524 04:49:07.914942 11654 sgd_solver.cpp:112] Iteration 34070, lr = 0.1
I0524 04:49:14.728060 11654 solver.cpp:239] Iteration 34080 (1.46815 iter/s, 6.81128s/10 iters), loss = 5.81651
I0524 04:49:14.728101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81651 (* 1 = 5.81651 loss)
I0524 04:49:14.728117 11654 sgd_solver.cpp:112] Iteration 34080, lr = 0.1
I0524 04:49:22.417354 11654 solver.cpp:239] Iteration 34090 (1.30058 iter/s, 7.68888s/10 iters), loss = 6.2268
I0524 04:49:22.417407 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2268 (* 1 = 6.2268 loss)
I0524 04:49:23.304016 11654 sgd_solver.cpp:112] Iteration 34090, lr = 0.1
I0524 04:49:29.653664 11654 solver.cpp:239] Iteration 34100 (1.38198 iter/s, 7.23598s/10 iters), loss = 6.03924
I0524 04:49:29.653717 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03924 (* 1 = 6.03924 loss)
I0524 04:49:29.653749 11654 sgd_solver.cpp:112] Iteration 34100, lr = 0.1
I0524 04:49:35.820732 11654 solver.cpp:239] Iteration 34110 (1.62159 iter/s, 6.16678s/10 iters), loss = 5.36271
I0524 04:49:35.820781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.36271 (* 1 = 5.36271 loss)
I0524 04:49:35.821226 11654 sgd_solver.cpp:112] Iteration 34110, lr = 0.1
I0524 04:49:42.414691 11654 solver.cpp:239] Iteration 34120 (1.51661 iter/s, 6.59365s/10 iters), loss = 6.0393
I0524 04:49:42.414863 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0393 (* 1 = 6.0393 loss)
I0524 04:49:42.927526 11654 sgd_solver.cpp:112] Iteration 34120, lr = 0.1
I0524 04:49:49.398155 11654 solver.cpp:239] Iteration 34130 (1.43204 iter/s, 6.98303s/10 iters), loss = 7.07359
I0524 04:49:49.398195 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07359 (* 1 = 7.07359 loss)
I0524 04:49:49.571472 11654 sgd_solver.cpp:112] Iteration 34130, lr = 0.1
I0524 04:49:56.156175 11654 solver.cpp:239] Iteration 34140 (1.47979 iter/s, 6.75771s/10 iters), loss = 5.26424
I0524 04:49:56.156229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26424 (* 1 = 5.26424 loss)
I0524 04:49:56.156247 11654 sgd_solver.cpp:112] Iteration 34140, lr = 0.1
I0524 04:50:02.976929 11654 solver.cpp:239] Iteration 34150 (1.46666 iter/s, 6.81822s/10 iters), loss = 6.13786
I0524 04:50:02.976987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13786 (* 1 = 6.13786 loss)
I0524 04:50:02.977329 11654 sgd_solver.cpp:112] Iteration 34150, lr = 0.1
I0524 04:50:08.888770 11654 solver.cpp:239] Iteration 34160 (1.6916 iter/s, 5.91157s/10 iters), loss = 7.02298
I0524 04:50:08.888813 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02298 (* 1 = 7.02298 loss)
I0524 04:50:08.888826 11654 sgd_solver.cpp:112] Iteration 34160, lr = 0.1
I0524 04:50:15.113056 11654 solver.cpp:239] Iteration 34170 (1.60671 iter/s, 6.22391s/10 iters), loss = 5.49224
I0524 04:50:15.113332 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49224 (* 1 = 5.49224 loss)
I0524 04:50:15.113396 11654 sgd_solver.cpp:112] Iteration 34170, lr = 0.1
I0524 04:50:21.140249 11654 solver.cpp:239] Iteration 34180 (1.6594 iter/s, 6.02629s/10 iters), loss = 5.78885
I0524 04:50:21.140290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78885 (* 1 = 5.78885 loss)
I0524 04:50:21.140301 11654 sgd_solver.cpp:112] Iteration 34180, lr = 0.1
I0524 04:50:28.839817 11654 solver.cpp:239] Iteration 34190 (1.29883 iter/s, 7.69923s/10 iters), loss = 5.57852
I0524 04:50:28.839867 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57852 (* 1 = 5.57852 loss)
I0524 04:50:29.040451 11654 sgd_solver.cpp:112] Iteration 34190, lr = 0.1
I0524 04:50:37.321223 11654 solver.cpp:239] Iteration 34200 (1.1791 iter/s, 8.48103s/10 iters), loss = 6.22004
I0524 04:50:37.321275 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22004 (* 1 = 6.22004 loss)
I0524 04:50:37.321291 11654 sgd_solver.cpp:112] Iteration 34200, lr = 0.1
I0524 04:50:46.199751 11654 solver.cpp:239] Iteration 34210 (1.12636 iter/s, 8.87814s/10 iters), loss = 5.97504
I0524 04:50:46.199946 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97504 (* 1 = 5.97504 loss)
I0524 04:50:46.199968 11654 sgd_solver.cpp:112] Iteration 34210, lr = 0.1
I0524 04:50:52.827708 11654 solver.cpp:239] Iteration 34220 (1.50887 iter/s, 6.62748s/10 iters), loss = 6.79409
I0524 04:50:52.827764 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79409 (* 1 = 6.79409 loss)
I0524 04:50:52.827780 11654 sgd_solver.cpp:112] Iteration 34220, lr = 0.1
I0524 04:50:59.988658 11654 solver.cpp:239] Iteration 34230 (1.39696 iter/s, 7.15841s/10 iters), loss = 6.33448
I0524 04:50:59.988708 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33448 (* 1 = 6.33448 loss)
I0524 04:50:59.988724 11654 sgd_solver.cpp:112] Iteration 34230, lr = 0.1
I0524 04:51:06.341691 11654 solver.cpp:239] Iteration 34240 (1.57415 iter/s, 6.35265s/10 iters), loss = 6.20841
I0524 04:51:06.341753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20841 (* 1 = 6.20841 loss)
I0524 04:51:07.902592 11654 sgd_solver.cpp:112] Iteration 34240, lr = 0.1
I0524 04:51:16.067579 11654 solver.cpp:239] Iteration 34250 (1.02823 iter/s, 9.72546s/10 iters), loss = 7.11404
I0524 04:51:16.067636 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11404 (* 1 = 7.11404 loss)
I0524 04:51:16.067653 11654 sgd_solver.cpp:112] Iteration 34250, lr = 0.1
I0524 04:51:23.471375 11654 solver.cpp:239] Iteration 34260 (1.35072 iter/s, 7.40346s/10 iters), loss = 6.29594
I0524 04:51:23.471515 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29594 (* 1 = 6.29594 loss)
I0524 04:51:23.471534 11654 sgd_solver.cpp:112] Iteration 34260, lr = 0.1
I0524 04:51:31.482790 11654 solver.cpp:239] Iteration 34270 (1.24829 iter/s, 8.01095s/10 iters), loss = 7.06856
I0524 04:51:31.482831 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06856 (* 1 = 7.06856 loss)
I0524 04:51:31.978157 11654 sgd_solver.cpp:112] Iteration 34270, lr = 0.1
I0524 04:51:38.183614 11654 solver.cpp:239] Iteration 34280 (1.49242 iter/s, 6.70052s/10 iters), loss = 6.58693
I0524 04:51:38.183676 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58693 (* 1 = 6.58693 loss)
I0524 04:51:38.789880 11654 sgd_solver.cpp:112] Iteration 34280, lr = 0.1
I0524 04:51:45.893906 11654 solver.cpp:239] Iteration 34290 (1.29703 iter/s, 7.70994s/10 iters), loss = 5.05041
I0524 04:51:45.893959 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.05041 (* 1 = 5.05041 loss)
I0524 04:51:45.894037 11654 sgd_solver.cpp:112] Iteration 34290, lr = 0.1
I0524 04:51:52.301048 11654 solver.cpp:239] Iteration 34300 (1.56083 iter/s, 6.40685s/10 iters), loss = 6.50494
I0524 04:51:52.301095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50494 (* 1 = 6.50494 loss)
I0524 04:51:52.301281 11654 sgd_solver.cpp:112] Iteration 34300, lr = 0.1
I0524 04:52:00.708856 11654 solver.cpp:239] Iteration 34310 (1.18942 iter/s, 8.40743s/10 iters), loss = 5.90322
I0524 04:52:00.709130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90322 (* 1 = 5.90322 loss)
I0524 04:52:00.757791 11654 sgd_solver.cpp:112] Iteration 34310, lr = 0.1
I0524 04:52:08.660110 11654 solver.cpp:239] Iteration 34320 (1.25775 iter/s, 7.95074s/10 iters), loss = 6.7206
I0524 04:52:08.660164 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7206 (* 1 = 6.7206 loss)
I0524 04:52:08.660179 11654 sgd_solver.cpp:112] Iteration 34320, lr = 0.1
I0524 04:52:14.650117 11654 solver.cpp:239] Iteration 34330 (1.67014 iter/s, 5.98753s/10 iters), loss = 5.99008
I0524 04:52:14.650156 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99008 (* 1 = 5.99008 loss)
I0524 04:52:14.650169 11654 sgd_solver.cpp:112] Iteration 34330, lr = 0.1
I0524 04:52:21.466605 11654 solver.cpp:239] Iteration 34340 (1.4671 iter/s, 6.81618s/10 iters), loss = 6.30956
I0524 04:52:21.466662 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30956 (* 1 = 6.30956 loss)
I0524 04:52:21.826475 11654 sgd_solver.cpp:112] Iteration 34340, lr = 0.1
I0524 04:52:29.772373 11654 solver.cpp:239] Iteration 34350 (1.20404 iter/s, 8.3054s/10 iters), loss = 6.07659
I0524 04:52:29.772424 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07659 (* 1 = 6.07659 loss)
I0524 04:52:29.772440 11654 sgd_solver.cpp:112] Iteration 34350, lr = 0.1
I0524 04:52:35.801578 11654 solver.cpp:239] Iteration 34360 (1.65869 iter/s, 6.02885s/10 iters), loss = 6.9973
I0524 04:52:35.801702 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9973 (* 1 = 6.9973 loss)
I0524 04:52:35.801719 11654 sgd_solver.cpp:112] Iteration 34360, lr = 0.1
I0524 04:52:41.671491 11654 solver.cpp:239] Iteration 34370 (1.70371 iter/s, 5.86956s/10 iters), loss = 6.79718
I0524 04:52:41.671545 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79718 (* 1 = 6.79718 loss)
I0524 04:52:41.671561 11654 sgd_solver.cpp:112] Iteration 34370, lr = 0.1
I0524 04:52:48.068981 11654 solver.cpp:239] Iteration 34380 (1.56321 iter/s, 6.39707s/10 iters), loss = 6.7121
I0524 04:52:48.069046 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7121 (* 1 = 6.7121 loss)
I0524 04:52:48.069211 11654 sgd_solver.cpp:112] Iteration 34380, lr = 0.1
I0524 04:52:54.545650 11654 solver.cpp:239] Iteration 34390 (1.54408 iter/s, 6.47636s/10 iters), loss = 6.66508
I0524 04:52:54.545699 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66508 (* 1 = 6.66508 loss)
I0524 04:52:54.545717 11654 sgd_solver.cpp:112] Iteration 34390, lr = 0.1
I0524 04:53:01.145560 11654 solver.cpp:239] Iteration 34400 (1.51575 iter/s, 6.59739s/10 iters), loss = 7.04865
I0524 04:53:01.145612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04865 (* 1 = 7.04865 loss)
I0524 04:53:01.155567 11654 sgd_solver.cpp:112] Iteration 34400, lr = 0.1
I0524 04:53:07.759150 11654 solver.cpp:239] Iteration 34410 (1.51211 iter/s, 6.61328s/10 iters), loss = 7.51546
I0524 04:53:07.759246 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.51546 (* 1 = 7.51546 loss)
I0524 04:53:07.759363 11654 sgd_solver.cpp:112] Iteration 34410, lr = 0.1
I0524 04:53:13.877353 11654 solver.cpp:239] Iteration 34420 (1.63456 iter/s, 6.11787s/10 iters), loss = 5.8475
I0524 04:53:13.877404 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8475 (* 1 = 5.8475 loss)
I0524 04:53:14.261705 11654 sgd_solver.cpp:112] Iteration 34420, lr = 0.1
I0524 04:53:20.575605 11654 solver.cpp:239] Iteration 34430 (1.493 iter/s, 6.69794s/10 iters), loss = 6.24701
I0524 04:53:20.575662 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24701 (* 1 = 6.24701 loss)
I0524 04:53:20.605878 11654 sgd_solver.cpp:112] Iteration 34430, lr = 0.1
I0524 04:53:28.173295 11654 solver.cpp:239] Iteration 34440 (1.31625 iter/s, 7.59735s/10 iters), loss = 6.58911
I0524 04:53:28.173341 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58911 (* 1 = 6.58911 loss)
I0524 04:53:28.173635 11654 sgd_solver.cpp:112] Iteration 34440, lr = 0.1
I0524 04:53:34.222805 11654 solver.cpp:239] Iteration 34450 (1.6531 iter/s, 6.04922s/10 iters), loss = 6.44579
I0524 04:53:34.222865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44579 (* 1 = 6.44579 loss)
I0524 04:53:34.599702 11654 sgd_solver.cpp:112] Iteration 34450, lr = 0.1
I0524 04:53:40.736598 11654 solver.cpp:239] Iteration 34460 (1.53528 iter/s, 6.51349s/10 iters), loss = 7.39638
I0524 04:53:40.736879 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.39638 (* 1 = 7.39638 loss)
I0524 04:53:40.750550 11654 sgd_solver.cpp:112] Iteration 34460, lr = 0.1
I0524 04:53:47.240273 11654 solver.cpp:239] Iteration 34470 (1.53771 iter/s, 6.50317s/10 iters), loss = 6.14826
I0524 04:53:47.240327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14826 (* 1 = 6.14826 loss)
I0524 04:53:47.240360 11654 sgd_solver.cpp:112] Iteration 34470, lr = 0.1
I0524 04:53:53.930143 11654 solver.cpp:239] Iteration 34480 (1.49487 iter/s, 6.68957s/10 iters), loss = 5.91092
I0524 04:53:53.930186 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91092 (* 1 = 5.91092 loss)
I0524 04:53:53.930395 11654 sgd_solver.cpp:112] Iteration 34480, lr = 0.1
I0524 04:54:00.132371 11654 solver.cpp:239] Iteration 34490 (1.6124 iter/s, 6.20194s/10 iters), loss = 7.17273
I0524 04:54:00.132424 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17273 (* 1 = 7.17273 loss)
I0524 04:54:00.238402 11654 sgd_solver.cpp:112] Iteration 34490, lr = 0.1
I0524 04:54:07.741094 11654 solver.cpp:239] Iteration 34500 (1.31434 iter/s, 7.60839s/10 iters), loss = 6.88884
I0524 04:54:07.741134 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88884 (* 1 = 6.88884 loss)
I0524 04:54:08.579039 11654 sgd_solver.cpp:112] Iteration 34500, lr = 0.1
I0524 04:54:15.443310 11654 solver.cpp:239] Iteration 34510 (1.29839 iter/s, 7.70187s/10 iters), loss = 6.54753
I0524 04:54:15.443575 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54753 (* 1 = 6.54753 loss)
I0524 04:54:15.443642 11654 sgd_solver.cpp:112] Iteration 34510, lr = 0.1
I0524 04:54:21.823096 11654 solver.cpp:239] Iteration 34520 (1.56757 iter/s, 6.37932s/10 iters), loss = 6.93786
I0524 04:54:21.823141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93786 (* 1 = 6.93786 loss)
I0524 04:54:21.823278 11654 sgd_solver.cpp:112] Iteration 34520, lr = 0.1
I0524 04:54:30.298283 11654 solver.cpp:239] Iteration 34530 (1.17997 iter/s, 8.47482s/10 iters), loss = 5.48947
I0524 04:54:30.298333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48947 (* 1 = 5.48947 loss)
I0524 04:54:30.781908 11654 sgd_solver.cpp:112] Iteration 34530, lr = 0.1
I0524 04:54:37.452424 11654 solver.cpp:239] Iteration 34540 (1.39786 iter/s, 7.15381s/10 iters), loss = 6.15089
I0524 04:54:37.452482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15089 (* 1 = 6.15089 loss)
I0524 04:54:37.452499 11654 sgd_solver.cpp:112] Iteration 34540, lr = 0.1
I0524 04:54:43.533689 11654 solver.cpp:239] Iteration 34550 (1.64447 iter/s, 6.08098s/10 iters), loss = 5.64084
I0524 04:54:43.533740 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64084 (* 1 = 5.64084 loss)
I0524 04:54:43.533757 11654 sgd_solver.cpp:112] Iteration 34550, lr = 0.1
I0524 04:54:51.280233 11654 solver.cpp:239] Iteration 34560 (1.29097 iter/s, 7.74613s/10 iters), loss = 6.3821
I0524 04:54:51.280390 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3821 (* 1 = 6.3821 loss)
I0524 04:54:51.804608 11654 sgd_solver.cpp:112] Iteration 34560, lr = 0.1
I0524 04:54:57.867305 11654 solver.cpp:239] Iteration 34570 (1.51822 iter/s, 6.58667s/10 iters), loss = 5.6944
I0524 04:54:57.867358 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6944 (* 1 = 5.6944 loss)
I0524 04:54:57.867594 11654 sgd_solver.cpp:112] Iteration 34570, lr = 0.1
I0524 04:55:05.424072 11654 solver.cpp:239] Iteration 34580 (1.32338 iter/s, 7.55642s/10 iters), loss = 6.87208
I0524 04:55:05.424135 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87208 (* 1 = 6.87208 loss)
I0524 04:55:05.436110 11654 sgd_solver.cpp:112] Iteration 34580, lr = 0.1
I0524 04:55:12.668166 11654 solver.cpp:239] Iteration 34590 (1.3805 iter/s, 7.24376s/10 iters), loss = 6.02923
I0524 04:55:12.668218 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02923 (* 1 = 6.02923 loss)
I0524 04:55:12.668239 11654 sgd_solver.cpp:112] Iteration 34590, lr = 0.1
I0524 04:55:21.144285 11654 solver.cpp:239] Iteration 34600 (1.17984 iter/s, 8.47574s/10 iters), loss = 5.73539
I0524 04:55:21.144330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73539 (* 1 = 5.73539 loss)
I0524 04:55:21.144398 11654 sgd_solver.cpp:112] Iteration 34600, lr = 0.1
I0524 04:55:28.197613 11654 solver.cpp:239] Iteration 34610 (1.41784 iter/s, 7.053s/10 iters), loss = 6.06608
I0524 04:55:28.197753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06608 (* 1 = 6.06608 loss)
I0524 04:55:28.212445 11654 sgd_solver.cpp:112] Iteration 34610, lr = 0.1
I0524 04:55:37.105175 11654 solver.cpp:239] Iteration 34620 (1.1227 iter/s, 8.90709s/10 iters), loss = 6.15365
I0524 04:55:37.105231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15365 (* 1 = 6.15365 loss)
I0524 04:55:37.105247 11654 sgd_solver.cpp:112] Iteration 34620, lr = 0.1
I0524 04:55:44.213359 11654 solver.cpp:239] Iteration 34630 (1.40702 iter/s, 7.10724s/10 iters), loss = 6.65555
I0524 04:55:44.213402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65555 (* 1 = 6.65555 loss)
I0524 04:55:44.213418 11654 sgd_solver.cpp:112] Iteration 34630, lr = 0.1
I0524 04:55:54.160573 11654 solver.cpp:239] Iteration 34640 (1.00557 iter/s, 9.94457s/10 iters), loss = 5.94479
I0524 04:55:54.160635 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94479 (* 1 = 5.94479 loss)
I0524 04:55:54.160658 11654 sgd_solver.cpp:112] Iteration 34640, lr = 0.1
I0524 04:56:00.730849 11654 solver.cpp:239] Iteration 34650 (1.52259 iter/s, 6.56776s/10 iters), loss = 6.04831
I0524 04:56:00.730963 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04831 (* 1 = 6.04831 loss)
I0524 04:56:00.751724 11654 sgd_solver.cpp:112] Iteration 34650, lr = 0.1
I0524 04:56:07.599670 11654 solver.cpp:239] Iteration 34660 (1.45593 iter/s, 6.86846s/10 iters), loss = 5.97249
I0524 04:56:07.599714 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97249 (* 1 = 5.97249 loss)
I0524 04:56:07.612684 11654 sgd_solver.cpp:112] Iteration 34660, lr = 0.1
I0524 04:56:15.797490 11654 solver.cpp:239] Iteration 34670 (1.21989 iter/s, 8.19746s/10 iters), loss = 7.71098
I0524 04:56:15.797549 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.71098 (* 1 = 7.71098 loss)
I0524 04:56:16.235159 11654 sgd_solver.cpp:112] Iteration 34670, lr = 0.1
I0524 04:56:23.423065 11654 solver.cpp:239] Iteration 34680 (1.31144 iter/s, 7.62523s/10 iters), loss = 5.82462
I0524 04:56:23.423125 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82462 (* 1 = 5.82462 loss)
I0524 04:56:23.423192 11654 sgd_solver.cpp:112] Iteration 34680, lr = 0.1
I0524 04:56:29.843367 11654 solver.cpp:239] Iteration 34690 (1.55763 iter/s, 6.41999s/10 iters), loss = 6.41397
I0524 04:56:29.843428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41397 (* 1 = 6.41397 loss)
I0524 04:56:29.843577 11654 sgd_solver.cpp:112] Iteration 34690, lr = 0.1
I0524 04:56:37.257184 11654 solver.cpp:239] Iteration 34700 (1.3489 iter/s, 7.41346s/10 iters), loss = 7.9031
I0524 04:56:37.257292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.9031 (* 1 = 7.9031 loss)
I0524 04:56:37.257390 11654 sgd_solver.cpp:112] Iteration 34700, lr = 0.1
I0524 04:56:43.585392 11654 solver.cpp:239] Iteration 34710 (1.58031 iter/s, 6.32786s/10 iters), loss = 6.19653
I0524 04:56:43.585458 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19653 (* 1 = 6.19653 loss)
I0524 04:56:43.586920 11654 sgd_solver.cpp:112] Iteration 34710, lr = 0.1
I0524 04:56:50.121974 11654 solver.cpp:239] Iteration 34720 (1.52992 iter/s, 6.53627s/10 iters), loss = 6.1329
I0524 04:56:50.122016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1329 (* 1 = 6.1329 loss)
I0524 04:56:50.646101 11654 sgd_solver.cpp:112] Iteration 34720, lr = 0.1
I0524 04:56:57.537384 11654 solver.cpp:239] Iteration 34730 (1.3486 iter/s, 7.41507s/10 iters), loss = 5.92274
I0524 04:56:57.537439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92274 (* 1 = 5.92274 loss)
I0524 04:56:57.788267 11654 sgd_solver.cpp:112] Iteration 34730, lr = 0.1
I0524 04:57:04.002326 11654 solver.cpp:239] Iteration 34740 (1.54688 iter/s, 6.46464s/10 iters), loss = 6.40456
I0524 04:57:04.002364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40456 (* 1 = 6.40456 loss)
I0524 04:57:04.002377 11654 sgd_solver.cpp:112] Iteration 34740, lr = 0.1
I0524 04:57:10.294621 11654 solver.cpp:239] Iteration 34750 (1.58934 iter/s, 6.29192s/10 iters), loss = 6.59051
I0524 04:57:10.294952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59051 (* 1 = 6.59051 loss)
I0524 04:57:10.295059 11654 sgd_solver.cpp:112] Iteration 34750, lr = 0.1
I0524 04:57:18.966830 11654 solver.cpp:239] Iteration 34760 (1.15319 iter/s, 8.6716s/10 iters), loss = 6.34391
I0524 04:57:18.966883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34391 (* 1 = 6.34391 loss)
I0524 04:57:18.967643 11654 sgd_solver.cpp:112] Iteration 34760, lr = 0.1
I0524 04:57:26.145521 11654 solver.cpp:239] Iteration 34770 (1.39307 iter/s, 7.17837s/10 iters), loss = 4.92504
I0524 04:57:26.145558 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.92504 (* 1 = 4.92504 loss)
I0524 04:57:26.146461 11654 sgd_solver.cpp:112] Iteration 34770, lr = 0.1
I0524 04:57:34.863116 11654 solver.cpp:239] Iteration 34780 (1.14716 iter/s, 8.71722s/10 iters), loss = 6.93378
I0524 04:57:34.863168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93378 (* 1 = 6.93378 loss)
I0524 04:57:35.227934 11654 sgd_solver.cpp:112] Iteration 34780, lr = 0.1
I0524 04:57:41.273414 11654 solver.cpp:239] Iteration 34790 (1.56006 iter/s, 6.41s/10 iters), loss = 6.85582
I0524 04:57:41.273679 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85582 (* 1 = 6.85582 loss)
I0524 04:57:41.273733 11654 sgd_solver.cpp:112] Iteration 34790, lr = 0.1
I0524 04:57:49.225363 11654 solver.cpp:239] Iteration 34800 (1.25765 iter/s, 7.95131s/10 iters), loss = 6.6171
I0524 04:57:49.225409 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6171 (* 1 = 6.6171 loss)
I0524 04:57:49.225584 11654 sgd_solver.cpp:112] Iteration 34800, lr = 0.1
I0524 04:57:55.788244 11654 solver.cpp:239] Iteration 34810 (1.52379 iter/s, 6.56258s/10 iters), loss = 5.77858
I0524 04:57:55.788295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77858 (* 1 = 5.77858 loss)
I0524 04:57:55.788312 11654 sgd_solver.cpp:112] Iteration 34810, lr = 0.1
I0524 04:58:03.397223 11654 solver.cpp:239] Iteration 34820 (1.3143 iter/s, 7.60863s/10 iters), loss = 7.2588
I0524 04:58:03.397290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2588 (* 1 = 7.2588 loss)
I0524 04:58:03.397630 11654 sgd_solver.cpp:112] Iteration 34820, lr = 0.1
I0524 04:58:09.875514 11654 solver.cpp:239] Iteration 34830 (1.54369 iter/s, 6.47798s/10 iters), loss = 6.11201
I0524 04:58:09.875557 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11201 (* 1 = 6.11201 loss)
I0524 04:58:09.875879 11654 sgd_solver.cpp:112] Iteration 34830, lr = 0.1
I0524 04:58:17.301867 11654 solver.cpp:239] Iteration 34840 (1.34662 iter/s, 7.42602s/10 iters), loss = 6.5569
I0524 04:58:17.302004 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5569 (* 1 = 6.5569 loss)
I0524 04:58:17.798020 11654 sgd_solver.cpp:112] Iteration 34840, lr = 0.1
I0524 04:58:26.124016 11654 solver.cpp:239] Iteration 34850 (1.13357 iter/s, 8.82168s/10 iters), loss = 6.37189
I0524 04:58:26.124071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37189 (* 1 = 6.37189 loss)
I0524 04:58:26.124089 11654 sgd_solver.cpp:112] Iteration 34850, lr = 0.1
I0524 04:58:32.762866 11654 solver.cpp:239] Iteration 34860 (1.50635 iter/s, 6.63855s/10 iters), loss = 6.65081
I0524 04:58:32.762912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65081 (* 1 = 6.65081 loss)
I0524 04:58:32.762928 11654 sgd_solver.cpp:112] Iteration 34860, lr = 0.1
I0524 04:58:39.082523 11654 solver.cpp:239] Iteration 34870 (1.58244 iter/s, 6.31937s/10 iters), loss = 7.05883
I0524 04:58:39.082566 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05883 (* 1 = 7.05883 loss)
I0524 04:58:39.082590 11654 sgd_solver.cpp:112] Iteration 34870, lr = 0.1
I0524 04:58:45.846645 11654 solver.cpp:239] Iteration 34880 (1.47846 iter/s, 6.76381s/10 iters), loss = 6.67318
I0524 04:58:45.846709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67318 (* 1 = 6.67318 loss)
I0524 04:58:45.982656 11654 sgd_solver.cpp:112] Iteration 34880, lr = 0.1
I0524 04:58:53.843482 11654 solver.cpp:239] Iteration 34890 (1.25055 iter/s, 7.99648s/10 iters), loss = 6.6196
I0524 04:58:53.843672 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6196 (* 1 = 6.6196 loss)
I0524 04:58:55.144240 11654 sgd_solver.cpp:112] Iteration 34890, lr = 0.1
I0524 04:59:03.606521 11654 solver.cpp:239] Iteration 34900 (1.02433 iter/s, 9.76247s/10 iters), loss = 5.77815
I0524 04:59:03.606580 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77815 (* 1 = 5.77815 loss)
I0524 04:59:03.606739 11654 sgd_solver.cpp:112] Iteration 34900, lr = 0.1
I0524 04:59:10.380832 11654 solver.cpp:239] Iteration 34910 (1.47623 iter/s, 6.77399s/10 iters), loss = 6.56924
I0524 04:59:10.380884 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56924 (* 1 = 6.56924 loss)
I0524 04:59:10.380901 11654 sgd_solver.cpp:112] Iteration 34910, lr = 0.1
I0524 04:59:16.675557 11654 solver.cpp:239] Iteration 34920 (1.58877 iter/s, 6.29416s/10 iters), loss = 5.40134
I0524 04:59:16.675611 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40134 (* 1 = 5.40134 loss)
I0524 04:59:17.031172 11654 sgd_solver.cpp:112] Iteration 34920, lr = 0.1
I0524 04:59:24.734302 11654 solver.cpp:239] Iteration 34930 (1.24094 iter/s, 8.05839s/10 iters), loss = 6.47766
I0524 04:59:24.734401 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47766 (* 1 = 6.47766 loss)
I0524 04:59:24.795362 11654 sgd_solver.cpp:112] Iteration 34930, lr = 0.1
I0524 04:59:33.051506 11654 solver.cpp:239] Iteration 34940 (1.20239 iter/s, 8.31677s/10 iters), loss = 6.04652
I0524 04:59:33.051571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04652 (* 1 = 6.04652 loss)
I0524 04:59:33.052181 11654 sgd_solver.cpp:112] Iteration 34940, lr = 0.1
I0524 04:59:41.457773 11654 solver.cpp:239] Iteration 34950 (1.18964 iter/s, 8.40589s/10 iters), loss = 6.58771
I0524 04:59:41.457815 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58771 (* 1 = 6.58771 loss)
I0524 04:59:41.457830 11654 sgd_solver.cpp:112] Iteration 34950, lr = 0.1
I0524 04:59:48.846504 11654 solver.cpp:239] Iteration 34960 (1.35348 iter/s, 7.38834s/10 iters), loss = 6.93953
I0524 04:59:48.846556 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93953 (* 1 = 6.93953 loss)
I0524 04:59:48.965544 11654 sgd_solver.cpp:112] Iteration 34960, lr = 0.1
I0524 04:59:55.226109 11654 solver.cpp:239] Iteration 34970 (1.56757 iter/s, 6.37931s/10 iters), loss = 6.46746
I0524 04:59:55.226197 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46746 (* 1 = 6.46746 loss)
I0524 04:59:55.226227 11654 sgd_solver.cpp:112] Iteration 34970, lr = 0.1
I0524 05:00:01.299242 11654 solver.cpp:239] Iteration 34980 (1.64668 iter/s, 6.07281s/10 iters), loss = 6.23066
I0524 05:00:01.299295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23066 (* 1 = 6.23066 loss)
I0524 05:00:01.299551 11654 sgd_solver.cpp:112] Iteration 34980, lr = 0.1
I0524 05:00:07.241695 11654 solver.cpp:239] Iteration 34990 (1.68289 iter/s, 5.94217s/10 iters), loss = 5.1419
I0524 05:00:07.241736 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.1419 (* 1 = 5.1419 loss)
I0524 05:00:07.241845 11654 sgd_solver.cpp:112] Iteration 34990, lr = 0.1
I0524 05:00:14.271319 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_35000.caffemodel
I0524 05:00:15.764791 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_35000.solverstate
I0524 05:00:16.389005 11654 solver.cpp:239] Iteration 35000 (1.09326 iter/s, 9.14692s/10 iters), loss = 6.63722
I0524 05:00:16.389052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63722 (* 1 = 6.63722 loss)
I0524 05:00:16.389662 11654 sgd_solver.cpp:112] Iteration 35000, lr = 0.1
I0524 05:00:22.640132 11654 solver.cpp:239] Iteration 35010 (1.59979 iter/s, 6.25083s/10 iters), loss = 5.89021
I0524 05:00:22.640184 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89021 (* 1 = 5.89021 loss)
I0524 05:00:22.640202 11654 sgd_solver.cpp:112] Iteration 35010, lr = 0.1
I0524 05:00:31.443167 11654 solver.cpp:239] Iteration 35020 (1.13605 iter/s, 8.80247s/10 iters), loss = 6.62194
I0524 05:00:31.443311 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62194 (* 1 = 6.62194 loss)
I0524 05:00:31.737681 11654 sgd_solver.cpp:112] Iteration 35020, lr = 0.1
I0524 05:00:38.482244 11654 solver.cpp:239] Iteration 35030 (1.42073 iter/s, 7.03866s/10 iters), loss = 6.67281
I0524 05:00:38.482303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67281 (* 1 = 6.67281 loss)
I0524 05:00:38.482321 11654 sgd_solver.cpp:112] Iteration 35030, lr = 0.1
I0524 05:00:45.151881 11654 solver.cpp:239] Iteration 35040 (1.4999 iter/s, 6.66712s/10 iters), loss = 6.23977
I0524 05:00:45.151926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23977 (* 1 = 6.23977 loss)
I0524 05:00:45.151943 11654 sgd_solver.cpp:112] Iteration 35040, lr = 0.1
I0524 05:00:51.537374 11654 solver.cpp:239] Iteration 35050 (1.56667 iter/s, 6.38297s/10 iters), loss = 6.47395
I0524 05:00:51.537425 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47395 (* 1 = 6.47395 loss)
I0524 05:00:51.597352 11654 sgd_solver.cpp:112] Iteration 35050, lr = 0.1
I0524 05:00:57.764904 11654 solver.cpp:239] Iteration 35060 (1.60585 iter/s, 6.22723s/10 iters), loss = 5.44474
I0524 05:00:57.764961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44474 (* 1 = 5.44474 loss)
I0524 05:00:58.922338 11654 sgd_solver.cpp:112] Iteration 35060, lr = 0.1
I0524 05:01:07.020479 11654 solver.cpp:239] Iteration 35070 (1.08048 iter/s, 9.25517s/10 iters), loss = 6.87083
I0524 05:01:07.020583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87083 (* 1 = 6.87083 loss)
I0524 05:01:07.020602 11654 sgd_solver.cpp:112] Iteration 35070, lr = 0.1
I0524 05:01:14.290733 11654 solver.cpp:239] Iteration 35080 (1.37555 iter/s, 7.26983s/10 iters), loss = 6.07132
I0524 05:01:14.290794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07132 (* 1 = 6.07132 loss)
I0524 05:01:14.290812 11654 sgd_solver.cpp:112] Iteration 35080, lr = 0.1
I0524 05:01:21.103364 11654 solver.cpp:239] Iteration 35090 (1.46795 iter/s, 6.81222s/10 iters), loss = 6.05351
I0524 05:01:21.103406 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05351 (* 1 = 6.05351 loss)
I0524 05:01:21.103421 11654 sgd_solver.cpp:112] Iteration 35090, lr = 0.1
I0524 05:01:27.716529 11654 solver.cpp:239] Iteration 35100 (1.51271 iter/s, 6.61063s/10 iters), loss = 5.23621
I0524 05:01:27.716586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.23621 (* 1 = 5.23621 loss)
I0524 05:01:27.716903 11654 sgd_solver.cpp:112] Iteration 35100, lr = 0.1
I0524 05:01:35.056376 11654 solver.cpp:239] Iteration 35110 (1.36249 iter/s, 7.33951s/10 iters), loss = 6.36911
I0524 05:01:35.056426 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36911 (* 1 = 6.36911 loss)
I0524 05:01:35.056440 11654 sgd_solver.cpp:112] Iteration 35110, lr = 0.1
I0524 05:01:41.129863 11654 solver.cpp:239] Iteration 35120 (1.64658 iter/s, 6.0732s/10 iters), loss = 6.60858
I0524 05:01:41.130164 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60858 (* 1 = 6.60858 loss)
I0524 05:01:41.130283 11654 sgd_solver.cpp:112] Iteration 35120, lr = 0.1
I0524 05:01:47.448042 11654 solver.cpp:239] Iteration 35130 (1.58285 iter/s, 6.3177s/10 iters), loss = 6.94025
I0524 05:01:47.448091 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94025 (* 1 = 6.94025 loss)
I0524 05:01:47.448240 11654 sgd_solver.cpp:112] Iteration 35130, lr = 0.1
I0524 05:01:55.764744 11654 solver.cpp:239] Iteration 35140 (1.20245 iter/s, 8.31633s/10 iters), loss = 7.6292
I0524 05:01:55.764797 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.6292 (* 1 = 7.6292 loss)
I0524 05:01:55.773492 11654 sgd_solver.cpp:112] Iteration 35140, lr = 0.1
I0524 05:02:02.867605 11654 solver.cpp:239] Iteration 35150 (1.40795 iter/s, 7.10254s/10 iters), loss = 5.97618
I0524 05:02:02.867657 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97618 (* 1 = 5.97618 loss)
I0524 05:02:02.867811 11654 sgd_solver.cpp:112] Iteration 35150, lr = 0.1
I0524 05:02:09.242815 11654 solver.cpp:239] Iteration 35160 (1.56865 iter/s, 6.37492s/10 iters), loss = 6.17517
I0524 05:02:09.242861 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17517 (* 1 = 6.17517 loss)
I0524 05:02:09.243062 11654 sgd_solver.cpp:112] Iteration 35160, lr = 0.1
I0524 05:02:16.194772 11654 solver.cpp:239] Iteration 35170 (1.43851 iter/s, 6.95164s/10 iters), loss = 6.24662
I0524 05:02:16.195055 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24662 (* 1 = 6.24662 loss)
I0524 05:02:16.195106 11654 sgd_solver.cpp:112] Iteration 35170, lr = 0.1
I0524 05:02:23.869973 11654 solver.cpp:239] Iteration 35180 (1.30299 iter/s, 7.67463s/10 iters), loss = 5.49728
I0524 05:02:23.870045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49728 (* 1 = 5.49728 loss)
I0524 05:02:23.870478 11654 sgd_solver.cpp:112] Iteration 35180, lr = 0.1
I0524 05:02:30.350741 11654 solver.cpp:239] Iteration 35190 (1.54311 iter/s, 6.48041s/10 iters), loss = 6.56837
I0524 05:02:30.350807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56837 (* 1 = 6.56837 loss)
I0524 05:02:31.026687 11654 sgd_solver.cpp:112] Iteration 35190, lr = 0.1
I0524 05:02:37.260659 11654 solver.cpp:239] Iteration 35200 (1.44726 iter/s, 6.90959s/10 iters), loss = 6.65444
I0524 05:02:37.260712 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65444 (* 1 = 6.65444 loss)
I0524 05:02:37.260839 11654 sgd_solver.cpp:112] Iteration 35200, lr = 0.1
I0524 05:02:43.615231 11654 solver.cpp:239] Iteration 35210 (1.57374 iter/s, 6.35428s/10 iters), loss = 6.12843
I0524 05:02:43.615272 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12843 (* 1 = 6.12843 loss)
I0524 05:02:43.615285 11654 sgd_solver.cpp:112] Iteration 35210, lr = 0.1
I0524 05:02:52.430665 11654 solver.cpp:239] Iteration 35220 (1.13471 iter/s, 8.81282s/10 iters), loss = 6.47151
I0524 05:02:52.430830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47151 (* 1 = 6.47151 loss)
I0524 05:02:52.430848 11654 sgd_solver.cpp:112] Iteration 35220, lr = 0.1
I0524 05:03:00.642066 11654 solver.cpp:239] Iteration 35230 (1.21789 iter/s, 8.21093s/10 iters), loss = 6.53687
I0524 05:03:00.642127 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53687 (* 1 = 6.53687 loss)
I0524 05:03:00.714583 11654 sgd_solver.cpp:112] Iteration 35230, lr = 0.1
I0524 05:03:08.498010 11654 solver.cpp:239] Iteration 35240 (1.27298 iter/s, 7.85559s/10 iters), loss = 6.3773
I0524 05:03:08.498065 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3773 (* 1 = 6.3773 loss)
I0524 05:03:08.498275 11654 sgd_solver.cpp:112] Iteration 35240, lr = 0.1
I0524 05:03:15.535580 11654 solver.cpp:239] Iteration 35250 (1.42101 iter/s, 7.03726s/10 iters), loss = 6.94904
I0524 05:03:15.535620 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94904 (* 1 = 6.94904 loss)
I0524 05:03:16.330905 11654 sgd_solver.cpp:112] Iteration 35250, lr = 0.1
I0524 05:03:23.583381 11654 solver.cpp:239] Iteration 35260 (1.24263 iter/s, 8.04744s/10 iters), loss = 6.77412
I0524 05:03:23.583570 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77412 (* 1 = 6.77412 loss)
I0524 05:03:23.734921 11654 sgd_solver.cpp:112] Iteration 35260, lr = 0.1
I0524 05:03:31.204740 11654 solver.cpp:239] Iteration 35270 (1.31218 iter/s, 7.62088s/10 iters), loss = 5.2281
I0524 05:03:31.204794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.2281 (* 1 = 5.2281 loss)
I0524 05:03:31.351752 11654 sgd_solver.cpp:112] Iteration 35270, lr = 0.1
I0524 05:03:37.829998 11654 solver.cpp:239] Iteration 35280 (1.50945 iter/s, 6.62495s/10 iters), loss = 6.45877
I0524 05:03:37.830049 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45877 (* 1 = 6.45877 loss)
I0524 05:03:37.882411 11654 sgd_solver.cpp:112] Iteration 35280, lr = 0.1
I0524 05:03:46.706921 11654 solver.cpp:239] Iteration 35290 (1.12657 iter/s, 8.87653s/10 iters), loss = 6.07625
I0524 05:03:46.706975 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07625 (* 1 = 6.07625 loss)
I0524 05:03:46.720597 11654 sgd_solver.cpp:112] Iteration 35290, lr = 0.1
I0524 05:03:53.632133 11654 solver.cpp:239] Iteration 35300 (1.44407 iter/s, 6.92488s/10 iters), loss = 7.12442
I0524 05:03:53.632292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12442 (* 1 = 7.12442 loss)
I0524 05:03:53.722630 11654 sgd_solver.cpp:112] Iteration 35300, lr = 0.1
I0524 05:04:01.443814 11654 solver.cpp:239] Iteration 35310 (1.28021 iter/s, 7.81123s/10 iters), loss = 6.20985
I0524 05:04:01.443869 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20985 (* 1 = 6.20985 loss)
I0524 05:04:01.445343 11654 sgd_solver.cpp:112] Iteration 35310, lr = 0.1
I0524 05:04:09.054308 11654 solver.cpp:239] Iteration 35320 (1.31403 iter/s, 7.61015s/10 iters), loss = 5.9133
I0524 05:04:09.054352 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9133 (* 1 = 5.9133 loss)
I0524 05:04:09.054366 11654 sgd_solver.cpp:112] Iteration 35320, lr = 0.1
I0524 05:04:18.856886 11654 solver.cpp:239] Iteration 35330 (1.02021 iter/s, 9.80192s/10 iters), loss = 5.64819
I0524 05:04:18.856937 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64819 (* 1 = 5.64819 loss)
I0524 05:04:18.856976 11654 sgd_solver.cpp:112] Iteration 35330, lr = 0.1
I0524 05:04:25.666522 11654 solver.cpp:239] Iteration 35340 (1.46858 iter/s, 6.80932s/10 iters), loss = 6.6661
I0524 05:04:25.666810 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6661 (* 1 = 6.6661 loss)
I0524 05:04:25.666860 11654 sgd_solver.cpp:112] Iteration 35340, lr = 0.1
I0524 05:04:32.192672 11654 solver.cpp:239] Iteration 35350 (1.53252 iter/s, 6.52521s/10 iters), loss = 6.73762
I0524 05:04:32.192720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73762 (* 1 = 6.73762 loss)
I0524 05:04:32.504235 11654 sgd_solver.cpp:112] Iteration 35350, lr = 0.1
I0524 05:04:39.717984 11654 solver.cpp:239] Iteration 35360 (1.32891 iter/s, 7.52496s/10 iters), loss = 5.39074
I0524 05:04:39.718050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.39074 (* 1 = 5.39074 loss)
I0524 05:04:39.718550 11654 sgd_solver.cpp:112] Iteration 35360, lr = 0.1
I0524 05:04:46.259481 11654 solver.cpp:239] Iteration 35370 (1.52877 iter/s, 6.54119s/10 iters), loss = 6.7863
I0524 05:04:46.259528 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7863 (* 1 = 6.7863 loss)
I0524 05:04:46.259721 11654 sgd_solver.cpp:112] Iteration 35370, lr = 0.1
I0524 05:04:54.394636 11654 solver.cpp:239] Iteration 35380 (1.22929 iter/s, 8.13479s/10 iters), loss = 6.21459
I0524 05:04:54.394691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21459 (* 1 = 6.21459 loss)
I0524 05:04:54.394882 11654 sgd_solver.cpp:112] Iteration 35380, lr = 0.1
I0524 05:05:02.185148 11654 solver.cpp:239] Iteration 35390 (1.28367 iter/s, 7.79016s/10 iters), loss = 7.27618
I0524 05:05:02.185381 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27618 (* 1 = 7.27618 loss)
I0524 05:05:02.185432 11654 sgd_solver.cpp:112] Iteration 35390, lr = 0.1
I0524 05:05:09.316936 11654 solver.cpp:239] Iteration 35400 (1.40268 iter/s, 7.12924s/10 iters), loss = 5.9704
I0524 05:05:09.316992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9704 (* 1 = 5.9704 loss)
I0524 05:05:09.317045 11654 sgd_solver.cpp:112] Iteration 35400, lr = 0.1
I0524 05:05:18.579787 11654 solver.cpp:239] Iteration 35410 (1.07963 iter/s, 9.26245s/10 iters), loss = 6.56576
I0524 05:05:18.579829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56576 (* 1 = 6.56576 loss)
I0524 05:05:18.580087 11654 sgd_solver.cpp:112] Iteration 35410, lr = 0.1
I0524 05:05:24.998366 11654 solver.cpp:239] Iteration 35420 (1.55805 iter/s, 6.41828s/10 iters), loss = 5.89989
I0524 05:05:24.998417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89989 (* 1 = 5.89989 loss)
I0524 05:05:24.998432 11654 sgd_solver.cpp:112] Iteration 35420, lr = 0.1
I0524 05:05:31.379374 11654 solver.cpp:239] Iteration 35430 (1.56738 iter/s, 6.38008s/10 iters), loss = 7.20764
I0524 05:05:31.379438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20764 (* 1 = 7.20764 loss)
I0524 05:05:32.354951 11654 sgd_solver.cpp:112] Iteration 35430, lr = 0.1
I0524 05:05:38.814791 11654 solver.cpp:239] Iteration 35440 (1.34498 iter/s, 7.43507s/10 iters), loss = 6.83177
I0524 05:05:38.814849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83177 (* 1 = 6.83177 loss)
I0524 05:05:38.815073 11654 sgd_solver.cpp:112] Iteration 35440, lr = 0.1
I0524 05:05:46.491816 11654 solver.cpp:239] Iteration 35450 (1.30265 iter/s, 7.67667s/10 iters), loss = 7.00577
I0524 05:05:46.491869 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00577 (* 1 = 7.00577 loss)
I0524 05:05:46.491884 11654 sgd_solver.cpp:112] Iteration 35450, lr = 0.1
I0524 05:05:53.684767 11654 solver.cpp:239] Iteration 35460 (1.39072 iter/s, 7.19051s/10 iters), loss = 6.80377
I0524 05:05:53.684806 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80377 (* 1 = 6.80377 loss)
I0524 05:05:53.684819 11654 sgd_solver.cpp:112] Iteration 35460, lr = 0.1
I0524 05:05:59.817378 11654 solver.cpp:239] Iteration 35470 (1.63072 iter/s, 6.13225s/10 iters), loss = 6.93328
I0524 05:05:59.817427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93328 (* 1 = 6.93328 loss)
I0524 05:05:59.817445 11654 sgd_solver.cpp:112] Iteration 35470, lr = 0.1
I0524 05:06:07.722213 11654 solver.cpp:239] Iteration 35480 (1.26511 iter/s, 7.90447s/10 iters), loss = 6.8381
I0524 05:06:07.722373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8381 (* 1 = 6.8381 loss)
I0524 05:06:07.722400 11654 sgd_solver.cpp:112] Iteration 35480, lr = 0.1
I0524 05:06:13.841863 11654 solver.cpp:239] Iteration 35490 (1.63469 iter/s, 6.11735s/10 iters), loss = 6.45245
I0524 05:06:13.841900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45245 (* 1 = 6.45245 loss)
I0524 05:06:13.842034 11654 sgd_solver.cpp:112] Iteration 35490, lr = 0.1
I0524 05:06:20.350095 11654 solver.cpp:239] Iteration 35500 (1.53659 iter/s, 6.50792s/10 iters), loss = 5.42519
I0524 05:06:20.350150 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42519 (* 1 = 5.42519 loss)
I0524 05:06:20.350219 11654 sgd_solver.cpp:112] Iteration 35500, lr = 0.1
I0524 05:06:27.709548 11654 solver.cpp:239] Iteration 35510 (1.35886 iter/s, 7.35913s/10 iters), loss = 6.54159
I0524 05:06:27.709591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54159 (* 1 = 6.54159 loss)
I0524 05:06:27.709604 11654 sgd_solver.cpp:112] Iteration 35510, lr = 0.1
I0524 05:06:34.392035 11654 solver.cpp:239] Iteration 35520 (1.49701 iter/s, 6.67996s/10 iters), loss = 4.83369
I0524 05:06:34.392094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.83369 (* 1 = 4.83369 loss)
I0524 05:06:34.392567 11654 sgd_solver.cpp:112] Iteration 35520, lr = 0.1
I0524 05:06:42.436105 11654 solver.cpp:239] Iteration 35530 (1.24321 iter/s, 8.04371s/10 iters), loss = 5.57577
I0524 05:06:42.436216 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57577 (* 1 = 5.57577 loss)
I0524 05:06:42.436236 11654 sgd_solver.cpp:112] Iteration 35530, lr = 0.1
I0524 05:06:49.413185 11654 solver.cpp:239] Iteration 35540 (1.43335 iter/s, 6.97668s/10 iters), loss = 5.98401
I0524 05:06:49.413226 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98401 (* 1 = 5.98401 loss)
I0524 05:06:49.413239 11654 sgd_solver.cpp:112] Iteration 35540, lr = 0.1
I0524 05:06:56.277931 11654 solver.cpp:239] Iteration 35550 (1.45679 iter/s, 6.86443s/10 iters), loss = 5.671
I0524 05:06:56.277992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.671 (* 1 = 5.671 loss)
I0524 05:06:56.278126 11654 sgd_solver.cpp:112] Iteration 35550, lr = 0.1
I0524 05:07:03.658408 11654 solver.cpp:239] Iteration 35560 (1.35504 iter/s, 7.37984s/10 iters), loss = 6.08942
I0524 05:07:03.658447 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08942 (* 1 = 6.08942 loss)
I0524 05:07:03.658459 11654 sgd_solver.cpp:112] Iteration 35560, lr = 0.1
I0524 05:07:10.000424 11654 solver.cpp:239] Iteration 35570 (1.57738 iter/s, 6.33963s/10 iters), loss = 6.57436
I0524 05:07:10.000479 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57436 (* 1 = 6.57436 loss)
I0524 05:07:10.000496 11654 sgd_solver.cpp:112] Iteration 35570, lr = 0.1
I0524 05:07:16.572721 11654 solver.cpp:239] Iteration 35580 (1.52162 iter/s, 6.57193s/10 iters), loss = 6.46725
I0524 05:07:16.572968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46725 (* 1 = 6.46725 loss)
I0524 05:07:16.573021 11654 sgd_solver.cpp:112] Iteration 35580, lr = 0.1
I0524 05:07:23.829622 11654 solver.cpp:239] Iteration 35590 (1.3782 iter/s, 7.25586s/10 iters), loss = 5.48981
I0524 05:07:23.829669 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48981 (* 1 = 5.48981 loss)
I0524 05:07:23.829685 11654 sgd_solver.cpp:112] Iteration 35590, lr = 0.1
I0524 05:07:31.104820 11654 solver.cpp:239] Iteration 35600 (1.3746 iter/s, 7.27487s/10 iters), loss = 6.57637
I0524 05:07:31.104871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57637 (* 1 = 6.57637 loss)
I0524 05:07:31.105085 11654 sgd_solver.cpp:112] Iteration 35600, lr = 0.1
I0524 05:07:37.785265 11654 solver.cpp:239] Iteration 35610 (1.49698 iter/s, 6.68013s/10 iters), loss = 6.29648
I0524 05:07:37.785320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29648 (* 1 = 6.29648 loss)
I0524 05:07:37.785336 11654 sgd_solver.cpp:112] Iteration 35610, lr = 0.1
I0524 05:07:44.990381 11654 solver.cpp:239] Iteration 35620 (1.38797 iter/s, 7.20478s/10 iters), loss = 6.36396
I0524 05:07:44.990434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36396 (* 1 = 6.36396 loss)
I0524 05:07:44.990449 11654 sgd_solver.cpp:112] Iteration 35620, lr = 0.1
I0524 05:07:51.163954 11654 solver.cpp:239] Iteration 35630 (1.61989 iter/s, 6.17327s/10 iters), loss = 6.99437
I0524 05:07:51.164121 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99437 (* 1 = 6.99437 loss)
I0524 05:07:51.164436 11654 sgd_solver.cpp:112] Iteration 35630, lr = 0.1
I0524 05:07:58.110347 11654 solver.cpp:239] Iteration 35640 (1.43969 iter/s, 6.94596s/10 iters), loss = 6.97086
I0524 05:07:58.110407 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97086 (* 1 = 6.97086 loss)
I0524 05:07:58.143889 11654 sgd_solver.cpp:112] Iteration 35640, lr = 0.1
I0524 05:08:04.624127 11654 solver.cpp:239] Iteration 35650 (1.53528 iter/s, 6.51348s/10 iters), loss = 7.00107
I0524 05:08:04.624181 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00107 (* 1 = 7.00107 loss)
I0524 05:08:04.660845 11654 sgd_solver.cpp:112] Iteration 35650, lr = 0.1
I0524 05:08:11.335952 11654 solver.cpp:239] Iteration 35660 (1.48998 iter/s, 6.71152s/10 iters), loss = 6.37084
I0524 05:08:11.336001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37084 (* 1 = 6.37084 loss)
I0524 05:08:11.982491 11654 sgd_solver.cpp:112] Iteration 35660, lr = 0.1
I0524 05:08:18.645150 11654 solver.cpp:239] Iteration 35670 (1.3682 iter/s, 7.30887s/10 iters), loss = 6.51349
I0524 05:08:18.645203 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51349 (* 1 = 6.51349 loss)
I0524 05:08:19.207990 11654 sgd_solver.cpp:112] Iteration 35670, lr = 0.1
I0524 05:08:25.883055 11654 solver.cpp:239] Iteration 35680 (1.38168 iter/s, 7.23758s/10 iters), loss = 6.62919
I0524 05:08:25.883339 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62919 (* 1 = 6.62919 loss)
I0524 05:08:25.883399 11654 sgd_solver.cpp:112] Iteration 35680, lr = 0.1
I0524 05:08:32.190331 11654 solver.cpp:239] Iteration 35690 (1.5861 iter/s, 6.30476s/10 iters), loss = 6.56357
I0524 05:08:32.190382 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56357 (* 1 = 6.56357 loss)
I0524 05:08:32.190397 11654 sgd_solver.cpp:112] Iteration 35690, lr = 0.1
I0524 05:08:38.404814 11654 solver.cpp:239] Iteration 35700 (1.60979 iter/s, 6.21201s/10 iters), loss = 5.8167
I0524 05:08:38.404868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8167 (* 1 = 5.8167 loss)
I0524 05:08:38.813516 11654 sgd_solver.cpp:112] Iteration 35700, lr = 0.1
I0524 05:08:46.856477 11654 solver.cpp:239] Iteration 35710 (1.18325 iter/s, 8.45129s/10 iters), loss = 7.03284
I0524 05:08:46.856523 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03284 (* 1 = 7.03284 loss)
I0524 05:08:46.856540 11654 sgd_solver.cpp:112] Iteration 35710, lr = 0.1
I0524 05:08:53.694046 11654 solver.cpp:239] Iteration 35720 (1.46257 iter/s, 6.83726s/10 iters), loss = 6.4719
I0524 05:08:53.694097 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4719 (* 1 = 6.4719 loss)
I0524 05:08:53.694114 11654 sgd_solver.cpp:112] Iteration 35720, lr = 0.1
I0524 05:09:00.834728 11654 solver.cpp:239] Iteration 35730 (1.40093 iter/s, 7.13814s/10 iters), loss = 6.24197
I0524 05:09:00.834936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24197 (* 1 = 6.24197 loss)
I0524 05:09:01.336896 11654 sgd_solver.cpp:112] Iteration 35730, lr = 0.1
I0524 05:09:08.381525 11654 solver.cpp:239] Iteration 35740 (1.32515 iter/s, 7.54631s/10 iters), loss = 6.66036
I0524 05:09:08.381564 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66036 (* 1 = 6.66036 loss)
I0524 05:09:08.382153 11654 sgd_solver.cpp:112] Iteration 35740, lr = 0.1
I0524 05:09:14.629559 11654 solver.cpp:239] Iteration 35750 (1.60058 iter/s, 6.24774s/10 iters), loss = 5.58347
I0524 05:09:14.629623 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58347 (* 1 = 5.58347 loss)
I0524 05:09:15.060847 11654 sgd_solver.cpp:112] Iteration 35750, lr = 0.1
I0524 05:09:21.412498 11654 solver.cpp:239] Iteration 35760 (1.47436 iter/s, 6.78263s/10 iters), loss = 6.69114
I0524 05:09:21.412549 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69114 (* 1 = 6.69114 loss)
I0524 05:09:21.412896 11654 sgd_solver.cpp:112] Iteration 35760, lr = 0.1
I0524 05:09:28.263620 11654 solver.cpp:239] Iteration 35770 (1.45968 iter/s, 6.85081s/10 iters), loss = 6.5203
I0524 05:09:28.263674 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5203 (* 1 = 6.5203 loss)
I0524 05:09:28.263690 11654 sgd_solver.cpp:112] Iteration 35770, lr = 0.1
I0524 05:09:34.681903 11654 solver.cpp:239] Iteration 35780 (1.55866 iter/s, 6.41577s/10 iters), loss = 5.13939
I0524 05:09:34.682178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.13939 (* 1 = 5.13939 loss)
I0524 05:09:34.682242 11654 sgd_solver.cpp:112] Iteration 35780, lr = 0.1
I0524 05:09:40.784251 11654 solver.cpp:239] Iteration 35790 (1.63939 iter/s, 6.09984s/10 iters), loss = 7.10544
I0524 05:09:40.784302 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10544 (* 1 = 7.10544 loss)
I0524 05:09:40.859961 11654 sgd_solver.cpp:112] Iteration 35790, lr = 0.1
I0524 05:09:50.210724 11654 solver.cpp:239] Iteration 35800 (1.06089 iter/s, 9.42607s/10 iters), loss = 5.43991
I0524 05:09:50.210773 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.43991 (* 1 = 5.43991 loss)
I0524 05:09:50.225824 11654 sgd_solver.cpp:112] Iteration 35800, lr = 0.1
I0524 05:09:58.447859 11654 solver.cpp:239] Iteration 35810 (1.21407 iter/s, 8.23677s/10 iters), loss = 6.06598
I0524 05:09:58.447916 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06598 (* 1 = 6.06598 loss)
I0524 05:09:58.447934 11654 sgd_solver.cpp:112] Iteration 35810, lr = 0.1
I0524 05:10:05.296887 11654 solver.cpp:239] Iteration 35820 (1.46026 iter/s, 6.84807s/10 iters), loss = 6.98017
I0524 05:10:05.297219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98017 (* 1 = 6.98017 loss)
I0524 05:10:05.307767 11654 sgd_solver.cpp:112] Iteration 35820, lr = 0.1
I0524 05:10:13.256532 11654 solver.cpp:239] Iteration 35830 (1.25643 iter/s, 7.95906s/10 iters), loss = 6.17737
I0524 05:10:13.256595 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17737 (* 1 = 6.17737 loss)
I0524 05:10:13.257118 11654 sgd_solver.cpp:112] Iteration 35830, lr = 0.1
I0524 05:10:20.601162 11654 solver.cpp:239] Iteration 35840 (1.3616 iter/s, 7.34429s/10 iters), loss = 6.49624
I0524 05:10:20.601213 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49624 (* 1 = 6.49624 loss)
I0524 05:10:20.601229 11654 sgd_solver.cpp:112] Iteration 35840, lr = 0.1
I0524 05:10:28.797870 11654 solver.cpp:239] Iteration 35850 (1.22006 iter/s, 8.19635s/10 iters), loss = 5.5169
I0524 05:10:28.797920 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5169 (* 1 = 5.5169 loss)
I0524 05:10:28.797936 11654 sgd_solver.cpp:112] Iteration 35850, lr = 0.1
I0524 05:10:37.730921 11654 solver.cpp:239] Iteration 35860 (1.11949 iter/s, 8.93266s/10 iters), loss = 5.98582
I0524 05:10:37.731004 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98582 (* 1 = 5.98582 loss)
I0524 05:10:38.381361 11654 sgd_solver.cpp:112] Iteration 35860, lr = 0.1
I0524 05:10:45.736538 11654 solver.cpp:239] Iteration 35870 (1.24919 iter/s, 8.00522s/10 iters), loss = 5.00685
I0524 05:10:45.736606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.00685 (* 1 = 5.00685 loss)
I0524 05:10:45.736672 11654 sgd_solver.cpp:112] Iteration 35870, lr = 0.1
I0524 05:10:52.503726 11654 solver.cpp:239] Iteration 35880 (1.47779 iter/s, 6.76687s/10 iters), loss = 5.96883
I0524 05:10:52.503778 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96883 (* 1 = 5.96883 loss)
I0524 05:10:52.504007 11654 sgd_solver.cpp:112] Iteration 35880, lr = 0.1
I0524 05:11:01.347018 11654 solver.cpp:239] Iteration 35890 (1.13085 iter/s, 8.8429s/10 iters), loss = 7.33081
I0524 05:11:01.347072 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33081 (* 1 = 7.33081 loss)
I0524 05:11:01.347087 11654 sgd_solver.cpp:112] Iteration 35890, lr = 0.1
I0524 05:11:08.535531 11654 solver.cpp:239] Iteration 35900 (1.39117 iter/s, 7.18818s/10 iters), loss = 5.9717
I0524 05:11:08.535784 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9717 (* 1 = 5.9717 loss)
I0524 05:11:08.535835 11654 sgd_solver.cpp:112] Iteration 35900, lr = 0.1
I0524 05:11:16.667557 11654 solver.cpp:239] Iteration 35910 (1.22983 iter/s, 8.13124s/10 iters), loss = 5.55804
I0524 05:11:16.667606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55804 (* 1 = 5.55804 loss)
I0524 05:11:16.667623 11654 sgd_solver.cpp:112] Iteration 35910, lr = 0.1
I0524 05:11:24.629798 11654 solver.cpp:239] Iteration 35920 (1.25599 iter/s, 7.96182s/10 iters), loss = 6.16643
I0524 05:11:24.629839 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16643 (* 1 = 6.16643 loss)
I0524 05:11:25.190794 11654 sgd_solver.cpp:112] Iteration 35920, lr = 0.1
I0524 05:11:32.661911 11654 solver.cpp:239] Iteration 35930 (1.24506 iter/s, 8.03176s/10 iters), loss = 6.67474
I0524 05:11:32.661957 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67474 (* 1 = 6.67474 loss)
I0524 05:11:32.662081 11654 sgd_solver.cpp:112] Iteration 35930, lr = 0.1
I0524 05:11:40.451887 11654 solver.cpp:239] Iteration 35940 (1.28376 iter/s, 7.78963s/10 iters), loss = 4.98581
I0524 05:11:40.452204 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.98581 (* 1 = 4.98581 loss)
I0524 05:11:40.452270 11654 sgd_solver.cpp:112] Iteration 35940, lr = 0.1
I0524 05:11:46.503947 11654 solver.cpp:239] Iteration 35950 (1.65261 iter/s, 6.05104s/10 iters), loss = 6.88062
I0524 05:11:46.503988 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88062 (* 1 = 6.88062 loss)
I0524 05:11:46.504101 11654 sgd_solver.cpp:112] Iteration 35950, lr = 0.1
I0524 05:11:55.169222 11654 solver.cpp:239] Iteration 35960 (1.15408 iter/s, 8.66488s/10 iters), loss = 6.80132
I0524 05:11:55.169306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80132 (* 1 = 6.80132 loss)
I0524 05:11:55.169693 11654 sgd_solver.cpp:112] Iteration 35960, lr = 0.1
I0524 05:12:01.536818 11654 solver.cpp:239] Iteration 35970 (1.57053 iter/s, 6.36728s/10 iters), loss = 6.86457
I0524 05:12:01.536875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86457 (* 1 = 6.86457 loss)
I0524 05:12:01.536892 11654 sgd_solver.cpp:112] Iteration 35970, lr = 0.1
I0524 05:12:08.211751 11654 solver.cpp:239] Iteration 35980 (1.49823 iter/s, 6.67455s/10 iters), loss = 6.92366
I0524 05:12:08.211794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92366 (* 1 = 6.92366 loss)
I0524 05:12:08.631531 11654 sgd_solver.cpp:112] Iteration 35980, lr = 0.1
I0524 05:12:15.993010 11654 solver.cpp:239] Iteration 35990 (1.2852 iter/s, 7.7809s/10 iters), loss = 5.85033
I0524 05:12:15.993290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85033 (* 1 = 5.85033 loss)
I0524 05:12:15.993347 11654 sgd_solver.cpp:112] Iteration 35990, lr = 0.1
I0524 05:12:22.394670 11654 solver.cpp:239] Iteration 36000 (1.56221 iter/s, 6.40117s/10 iters), loss = 6.3394
I0524 05:12:22.394757 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3394 (* 1 = 6.3394 loss)
I0524 05:12:22.395143 11654 sgd_solver.cpp:112] Iteration 36000, lr = 0.1
I0524 05:12:29.131995 11654 solver.cpp:239] Iteration 36010 (1.48434 iter/s, 6.73699s/10 iters), loss = 6.43501
I0524 05:12:29.132036 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43501 (* 1 = 6.43501 loss)
I0524 05:12:29.132050 11654 sgd_solver.cpp:112] Iteration 36010, lr = 0.1
I0524 05:12:36.369181 11654 solver.cpp:239] Iteration 36020 (1.38223 iter/s, 7.2347s/10 iters), loss = 6.50902
I0524 05:12:36.369235 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50902 (* 1 = 6.50902 loss)
I0524 05:12:36.627615 11654 sgd_solver.cpp:112] Iteration 36020, lr = 0.1
I0524 05:12:42.625866 11654 solver.cpp:239] Iteration 36030 (1.59837 iter/s, 6.25639s/10 iters), loss = 6.02874
I0524 05:12:42.625912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02874 (* 1 = 6.02874 loss)
I0524 05:12:42.626019 11654 sgd_solver.cpp:112] Iteration 36030, lr = 0.1
I0524 05:12:50.842985 11654 solver.cpp:239] Iteration 36040 (1.21703 iter/s, 8.21675s/10 iters), loss = 7.186
I0524 05:12:50.843219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.186 (* 1 = 7.186 loss)
I0524 05:12:51.415078 11654 sgd_solver.cpp:112] Iteration 36040, lr = 0.1
I0524 05:12:57.433028 11654 solver.cpp:239] Iteration 36050 (1.51754 iter/s, 6.5896s/10 iters), loss = 5.63698
I0524 05:12:57.433079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63698 (* 1 = 5.63698 loss)
I0524 05:12:57.433399 11654 sgd_solver.cpp:112] Iteration 36050, lr = 0.1
I0524 05:13:06.070855 11654 solver.cpp:239] Iteration 36060 (1.15775 iter/s, 8.63744s/10 iters), loss = 6.12845
I0524 05:13:06.070907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12845 (* 1 = 6.12845 loss)
I0524 05:13:06.070936 11654 sgd_solver.cpp:112] Iteration 36060, lr = 0.1
I0524 05:13:12.632341 11654 solver.cpp:239] Iteration 36070 (1.52412 iter/s, 6.56117s/10 iters), loss = 6.68974
I0524 05:13:12.632400 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68974 (* 1 = 6.68974 loss)
I0524 05:13:12.632556 11654 sgd_solver.cpp:112] Iteration 36070, lr = 0.1
I0524 05:13:21.091794 11654 solver.cpp:239] Iteration 36080 (1.18216 iter/s, 8.45908s/10 iters), loss = 5.87281
I0524 05:13:21.092038 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87281 (* 1 = 5.87281 loss)
I0524 05:13:21.092090 11654 sgd_solver.cpp:112] Iteration 36080, lr = 0.1
I0524 05:13:28.535694 11654 solver.cpp:239] Iteration 36090 (1.34384 iter/s, 7.44137s/10 iters), loss = 6.14913
I0524 05:13:28.535749 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14913 (* 1 = 6.14913 loss)
I0524 05:13:28.649480 11654 sgd_solver.cpp:112] Iteration 36090, lr = 0.1
I0524 05:13:34.662353 11654 solver.cpp:239] Iteration 36100 (1.63229 iter/s, 6.12637s/10 iters), loss = 5.74823
I0524 05:13:34.662395 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74823 (* 1 = 5.74823 loss)
I0524 05:13:34.662408 11654 sgd_solver.cpp:112] Iteration 36100, lr = 0.1
I0524 05:13:41.507172 11654 solver.cpp:239] Iteration 36110 (1.46103 iter/s, 6.84451s/10 iters), loss = 6.45854
I0524 05:13:41.507220 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45854 (* 1 = 6.45854 loss)
I0524 05:13:41.507234 11654 sgd_solver.cpp:112] Iteration 36110, lr = 0.1
I0524 05:13:48.163765 11654 solver.cpp:239] Iteration 36120 (1.50236 iter/s, 6.65621s/10 iters), loss = 7.78724
I0524 05:13:48.163827 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.78724 (* 1 = 7.78724 loss)
I0524 05:13:48.163925 11654 sgd_solver.cpp:112] Iteration 36120, lr = 0.1
I0524 05:13:54.584686 11654 solver.cpp:239] Iteration 36130 (1.55748 iter/s, 6.42062s/10 iters), loss = 6.58817
I0524 05:13:54.584957 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58817 (* 1 = 6.58817 loss)
I0524 05:13:54.585013 11654 sgd_solver.cpp:112] Iteration 36130, lr = 0.1
I0524 05:14:00.837937 11654 solver.cpp:239] Iteration 36140 (1.59984 iter/s, 6.25063s/10 iters), loss = 6.41723
I0524 05:14:00.838001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41723 (* 1 = 6.41723 loss)
I0524 05:14:00.838197 11654 sgd_solver.cpp:112] Iteration 36140, lr = 0.1
I0524 05:14:08.723565 11654 solver.cpp:239] Iteration 36150 (1.26819 iter/s, 7.88527s/10 iters), loss = 5.64721
I0524 05:14:08.723624 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64721 (* 1 = 5.64721 loss)
I0524 05:14:08.723645 11654 sgd_solver.cpp:112] Iteration 36150, lr = 0.1
I0524 05:14:15.194800 11654 solver.cpp:239] Iteration 36160 (1.54585 iter/s, 6.46893s/10 iters), loss = 6.68336
I0524 05:14:15.194839 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68336 (* 1 = 6.68336 loss)
I0524 05:14:15.194851 11654 sgd_solver.cpp:112] Iteration 36160, lr = 0.1
I0524 05:14:23.190065 11654 solver.cpp:239] Iteration 36170 (1.25081 iter/s, 7.99483s/10 iters), loss = 5.79953
I0524 05:14:23.190126 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79953 (* 1 = 5.79953 loss)
I0524 05:14:23.190609 11654 sgd_solver.cpp:112] Iteration 36170, lr = 0.1
I0524 05:14:31.630754 11654 solver.cpp:239] Iteration 36180 (1.18479 iter/s, 8.44031s/10 iters), loss = 6.61585
I0524 05:14:31.631045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61585 (* 1 = 6.61585 loss)
I0524 05:14:31.631105 11654 sgd_solver.cpp:112] Iteration 36180, lr = 0.1
I0524 05:14:37.986619 11654 solver.cpp:239] Iteration 36190 (1.57398 iter/s, 6.35332s/10 iters), loss = 6.33809
I0524 05:14:37.986666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33809 (* 1 = 6.33809 loss)
I0524 05:14:37.986680 11654 sgd_solver.cpp:112] Iteration 36190, lr = 0.1
I0524 05:14:44.769242 11654 solver.cpp:239] Iteration 36200 (1.47442 iter/s, 6.78231s/10 iters), loss = 6.18079
I0524 05:14:44.769295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18079 (* 1 = 6.18079 loss)
I0524 05:14:44.931596 11654 sgd_solver.cpp:112] Iteration 36200, lr = 0.1
I0524 05:14:51.551158 11654 solver.cpp:239] Iteration 36210 (1.47458 iter/s, 6.78161s/10 iters), loss = 6.53175
I0524 05:14:51.551198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53175 (* 1 = 6.53175 loss)
I0524 05:14:51.700625 11654 sgd_solver.cpp:112] Iteration 36210, lr = 0.1
I0524 05:14:58.395732 11654 solver.cpp:239] Iteration 36220 (1.46108 iter/s, 6.84426s/10 iters), loss = 5.78313
I0524 05:14:58.395781 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78313 (* 1 = 5.78313 loss)
I0524 05:14:59.334800 11654 sgd_solver.cpp:112] Iteration 36220, lr = 0.1
I0524 05:15:08.477975 11654 solver.cpp:239] Iteration 36230 (0.991886 iter/s, 10.0818s/10 iters), loss = 5.90702
I0524 05:15:08.478289 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90702 (* 1 = 5.90702 loss)
I0524 05:15:08.478586 11654 sgd_solver.cpp:112] Iteration 36230, lr = 0.1
I0524 05:15:16.579176 11654 solver.cpp:239] Iteration 36240 (1.23447 iter/s, 8.10062s/10 iters), loss = 5.73774
I0524 05:15:16.579233 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73774 (* 1 = 5.73774 loss)
I0524 05:15:16.579253 11654 sgd_solver.cpp:112] Iteration 36240, lr = 0.1
I0524 05:15:24.531257 11654 solver.cpp:239] Iteration 36250 (1.2576 iter/s, 7.95165s/10 iters), loss = 6.46139
I0524 05:15:24.531303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46139 (* 1 = 6.46139 loss)
I0524 05:15:25.030980 11654 sgd_solver.cpp:112] Iteration 36250, lr = 0.1
I0524 05:15:31.189846 11654 solver.cpp:239] Iteration 36260 (1.50189 iter/s, 6.65827s/10 iters), loss = 5.83192
I0524 05:15:31.189904 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83192 (* 1 = 5.83192 loss)
I0524 05:15:31.189986 11654 sgd_solver.cpp:112] Iteration 36260, lr = 0.1
I0524 05:15:37.478732 11654 solver.cpp:239] Iteration 36270 (1.59019 iter/s, 6.28857s/10 iters), loss = 5.36388
I0524 05:15:37.478773 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.36388 (* 1 = 5.36388 loss)
I0524 05:15:37.478785 11654 sgd_solver.cpp:112] Iteration 36270, lr = 0.1
I0524 05:15:44.098433 11654 solver.cpp:239] Iteration 36280 (1.51085 iter/s, 6.61877s/10 iters), loss = 5.97201
I0524 05:15:44.098765 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97201 (* 1 = 5.97201 loss)
I0524 05:15:44.098839 11654 sgd_solver.cpp:112] Iteration 36280, lr = 0.1
I0524 05:15:50.579360 11654 solver.cpp:239] Iteration 36290 (1.54332 iter/s, 6.47952s/10 iters), loss = 6.90476
I0524 05:15:50.579408 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90476 (* 1 = 6.90476 loss)
I0524 05:15:50.579424 11654 sgd_solver.cpp:112] Iteration 36290, lr = 0.1
I0524 05:15:57.463656 11654 solver.cpp:239] Iteration 36300 (1.45265 iter/s, 6.88397s/10 iters), loss = 6.93668
I0524 05:15:57.463711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93668 (* 1 = 6.93668 loss)
I0524 05:15:57.464594 11654 sgd_solver.cpp:112] Iteration 36300, lr = 0.1
I0524 05:16:05.027782 11654 solver.cpp:239] Iteration 36310 (1.32209 iter/s, 7.56378s/10 iters), loss = 5.52995
I0524 05:16:05.027844 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.52995 (* 1 = 5.52995 loss)
I0524 05:16:05.028322 11654 sgd_solver.cpp:112] Iteration 36310, lr = 0.1
I0524 05:16:11.713142 11654 solver.cpp:239] Iteration 36320 (1.49588 iter/s, 6.68504s/10 iters), loss = 5.9439
I0524 05:16:11.713193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9439 (* 1 = 5.9439 loss)
I0524 05:16:11.714545 11654 sgd_solver.cpp:112] Iteration 36320, lr = 0.1
I0524 05:16:19.046972 11654 solver.cpp:239] Iteration 36330 (1.36361 iter/s, 7.3335s/10 iters), loss = 6.00589
I0524 05:16:19.047061 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00589 (* 1 = 6.00589 loss)
I0524 05:16:19.047077 11654 sgd_solver.cpp:112] Iteration 36330, lr = 0.1
I0524 05:16:26.833218 11654 solver.cpp:239] Iteration 36340 (1.28448 iter/s, 7.78526s/10 iters), loss = 6.49362
I0524 05:16:26.833271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49362 (* 1 = 6.49362 loss)
I0524 05:16:26.833287 11654 sgd_solver.cpp:112] Iteration 36340, lr = 0.1
I0524 05:16:32.948132 11654 solver.cpp:239] Iteration 36350 (1.63544 iter/s, 6.11455s/10 iters), loss = 5.06531
I0524 05:16:32.948179 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.06531 (* 1 = 5.06531 loss)
I0524 05:16:32.948436 11654 sgd_solver.cpp:112] Iteration 36350, lr = 0.1
I0524 05:16:41.802181 11654 solver.cpp:239] Iteration 36360 (1.12948 iter/s, 8.85365s/10 iters), loss = 6.73388
I0524 05:16:41.802242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73388 (* 1 = 6.73388 loss)
I0524 05:16:41.802336 11654 sgd_solver.cpp:112] Iteration 36360, lr = 0.1
I0524 05:16:50.081665 11654 solver.cpp:239] Iteration 36370 (1.20786 iter/s, 8.2791s/10 iters), loss = 7.52061
I0524 05:16:50.081967 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.52061 (* 1 = 7.52061 loss)
I0524 05:16:50.082067 11654 sgd_solver.cpp:112] Iteration 36370, lr = 0.1
I0524 05:16:56.503753 11654 solver.cpp:239] Iteration 36380 (1.55725 iter/s, 6.42159s/10 iters), loss = 6.62036
I0524 05:16:56.503813 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62036 (* 1 = 6.62036 loss)
I0524 05:16:56.503878 11654 sgd_solver.cpp:112] Iteration 36380, lr = 0.1
I0524 05:17:03.976689 11654 solver.cpp:239] Iteration 36390 (1.33822 iter/s, 7.47259s/10 iters), loss = 6.02984
I0524 05:17:03.976740 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02984 (* 1 = 6.02984 loss)
I0524 05:17:04.004359 11654 sgd_solver.cpp:112] Iteration 36390, lr = 0.1
I0524 05:17:12.399183 11654 solver.cpp:239] Iteration 36400 (1.18735 iter/s, 8.42213s/10 iters), loss = 6.73892
I0524 05:17:12.399236 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73892 (* 1 = 6.73892 loss)
I0524 05:17:12.399253 11654 sgd_solver.cpp:112] Iteration 36400, lr = 0.1
I0524 05:17:18.701063 11654 solver.cpp:239] Iteration 36410 (1.5869 iter/s, 6.30158s/10 iters), loss = 6.51527
I0524 05:17:18.701114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51527 (* 1 = 6.51527 loss)
I0524 05:17:19.062913 11654 sgd_solver.cpp:112] Iteration 36410, lr = 0.1
I0524 05:17:27.082231 11654 solver.cpp:239] Iteration 36420 (1.1932 iter/s, 8.38079s/10 iters), loss = 6.35979
I0524 05:17:27.082515 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35979 (* 1 = 6.35979 loss)
I0524 05:17:27.105036 11654 sgd_solver.cpp:112] Iteration 36420, lr = 0.1
I0524 05:17:33.688788 11654 solver.cpp:239] Iteration 36430 (1.51376 iter/s, 6.60606s/10 iters), loss = 6.56406
I0524 05:17:33.688845 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56406 (* 1 = 6.56406 loss)
I0524 05:17:34.024715 11654 sgd_solver.cpp:112] Iteration 36430, lr = 0.1
I0524 05:17:40.319715 11654 solver.cpp:239] Iteration 36440 (1.50816 iter/s, 6.63061s/10 iters), loss = 7.17978
I0524 05:17:40.319780 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17978 (* 1 = 7.17978 loss)
I0524 05:17:40.319921 11654 sgd_solver.cpp:112] Iteration 36440, lr = 0.1
I0524 05:17:47.010908 11654 solver.cpp:239] Iteration 36450 (1.49457 iter/s, 6.69088s/10 iters), loss = 6.6206
I0524 05:17:47.010952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6206 (* 1 = 6.6206 loss)
I0524 05:17:47.010967 11654 sgd_solver.cpp:112] Iteration 36450, lr = 0.1
I0524 05:17:53.239279 11654 solver.cpp:239] Iteration 36460 (1.60563 iter/s, 6.22807s/10 iters), loss = 5.06714
I0524 05:17:53.239346 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.06714 (* 1 = 5.06714 loss)
I0524 05:17:53.239382 11654 sgd_solver.cpp:112] Iteration 36460, lr = 0.1
I0524 05:18:02.167688 11654 solver.cpp:239] Iteration 36470 (1.12007 iter/s, 8.92801s/10 iters), loss = 6.99716
I0524 05:18:02.167991 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99716 (* 1 = 6.99716 loss)
I0524 05:18:02.168277 11654 sgd_solver.cpp:112] Iteration 36470, lr = 0.1
I0524 05:18:09.209926 11654 solver.cpp:239] Iteration 36480 (1.4201 iter/s, 7.04175s/10 iters), loss = 5.40335
I0524 05:18:09.209995 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40335 (* 1 = 5.40335 loss)
I0524 05:18:09.210018 11654 sgd_solver.cpp:112] Iteration 36480, lr = 0.1
I0524 05:18:16.335644 11654 solver.cpp:239] Iteration 36490 (1.40343 iter/s, 7.12539s/10 iters), loss = 6.122
I0524 05:18:16.335685 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.122 (* 1 = 6.122 loss)
I0524 05:18:16.335698 11654 sgd_solver.cpp:112] Iteration 36490, lr = 0.1
I0524 05:18:22.591274 11654 solver.cpp:239] Iteration 36500 (1.59864 iter/s, 6.25532s/10 iters), loss = 6.36984
I0524 05:18:22.591362 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36984 (* 1 = 6.36984 loss)
I0524 05:18:22.591420 11654 sgd_solver.cpp:112] Iteration 36500, lr = 0.1
I0524 05:18:32.727701 11654 solver.cpp:239] Iteration 36510 (0.986586 iter/s, 10.136s/10 iters), loss = 6.44336
I0524 05:18:32.727901 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44336 (* 1 = 6.44336 loss)
I0524 05:18:32.727921 11654 sgd_solver.cpp:112] Iteration 36510, lr = 0.1
I0524 05:18:40.599833 11654 solver.cpp:239] Iteration 36520 (1.27039 iter/s, 7.87157s/10 iters), loss = 6.3595
I0524 05:18:40.599911 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3595 (* 1 = 6.3595 loss)
I0524 05:18:40.600248 11654 sgd_solver.cpp:112] Iteration 36520, lr = 0.1
I0524 05:18:47.353353 11654 solver.cpp:239] Iteration 36530 (1.48078 iter/s, 6.75318s/10 iters), loss = 6.14957
I0524 05:18:47.353417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14957 (* 1 = 6.14957 loss)
I0524 05:18:47.353531 11654 sgd_solver.cpp:112] Iteration 36530, lr = 0.1
I0524 05:18:57.009989 11654 solver.cpp:239] Iteration 36540 (1.0356 iter/s, 9.6562s/10 iters), loss = 6.15597
I0524 05:18:57.010073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15597 (* 1 = 6.15597 loss)
I0524 05:18:57.010107 11654 sgd_solver.cpp:112] Iteration 36540, lr = 0.1
I0524 05:19:03.180861 11654 solver.cpp:239] Iteration 36550 (1.62061 iter/s, 6.17053s/10 iters), loss = 6.93464
I0524 05:19:03.181025 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93464 (* 1 = 6.93464 loss)
I0524 05:19:03.219964 11654 sgd_solver.cpp:112] Iteration 36550, lr = 0.1
I0524 05:19:10.303405 11654 solver.cpp:239] Iteration 36560 (1.40408 iter/s, 7.1221s/10 iters), loss = 5.77994
I0524 05:19:10.303459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77994 (* 1 = 5.77994 loss)
I0524 05:19:10.508605 11654 sgd_solver.cpp:112] Iteration 36560, lr = 0.1
I0524 05:19:19.195322 11654 solver.cpp:239] Iteration 36570 (1.12467 iter/s, 8.8915s/10 iters), loss = 5.94377
I0524 05:19:19.195394 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94377 (* 1 = 5.94377 loss)
I0524 05:19:19.195492 11654 sgd_solver.cpp:112] Iteration 36570, lr = 0.1
I0524 05:19:27.901792 11654 solver.cpp:239] Iteration 36580 (1.14862 iter/s, 8.70608s/10 iters), loss = 6.11646
I0524 05:19:27.901839 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11646 (* 1 = 6.11646 loss)
I0524 05:19:27.902145 11654 sgd_solver.cpp:112] Iteration 36580, lr = 0.1
I0524 05:19:34.661005 11654 solver.cpp:239] Iteration 36590 (1.47953 iter/s, 6.75888s/10 iters), loss = 7.33106
I0524 05:19:34.661314 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33106 (* 1 = 7.33106 loss)
I0524 05:19:34.661361 11654 sgd_solver.cpp:112] Iteration 36590, lr = 0.1
I0524 05:19:41.915580 11654 solver.cpp:239] Iteration 36600 (1.37855 iter/s, 7.25402s/10 iters), loss = 6.09883
I0524 05:19:41.915637 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09883 (* 1 = 6.09883 loss)
I0524 05:19:41.915922 11654 sgd_solver.cpp:112] Iteration 36600, lr = 0.1
I0524 05:19:50.319074 11654 solver.cpp:239] Iteration 36610 (1.19003 iter/s, 8.40312s/10 iters), loss = 6.676
I0524 05:19:50.319128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.676 (* 1 = 6.676 loss)
I0524 05:19:50.319524 11654 sgd_solver.cpp:112] Iteration 36610, lr = 0.1
I0524 05:20:00.397096 11654 solver.cpp:239] Iteration 36620 (0.992301 iter/s, 10.0776s/10 iters), loss = 6.10728
I0524 05:20:00.397148 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10728 (* 1 = 6.10728 loss)
I0524 05:20:01.334372 11654 sgd_solver.cpp:112] Iteration 36620, lr = 0.1
I0524 05:20:07.721864 11654 solver.cpp:239] Iteration 36630 (1.36529 iter/s, 7.32443s/10 iters), loss = 5.74023
I0524 05:20:07.722117 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74023 (* 1 = 5.74023 loss)
I0524 05:20:07.722165 11654 sgd_solver.cpp:112] Iteration 36630, lr = 0.1
I0524 05:20:16.422792 11654 solver.cpp:239] Iteration 36640 (1.14966 iter/s, 8.69823s/10 iters), loss = 7.0336
I0524 05:20:16.422847 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0336 (* 1 = 7.0336 loss)
I0524 05:20:16.423218 11654 sgd_solver.cpp:112] Iteration 36640, lr = 0.1
I0524 05:20:23.739758 11654 solver.cpp:239] Iteration 36650 (1.36675 iter/s, 7.31663s/10 iters), loss = 5.63076
I0524 05:20:23.739810 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63076 (* 1 = 5.63076 loss)
I0524 05:20:23.739826 11654 sgd_solver.cpp:112] Iteration 36650, lr = 0.1
I0524 05:20:32.222196 11654 solver.cpp:239] Iteration 36660 (1.17897 iter/s, 8.48198s/10 iters), loss = 6.20478
I0524 05:20:32.222244 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20478 (* 1 = 6.20478 loss)
I0524 05:20:32.222395 11654 sgd_solver.cpp:112] Iteration 36660, lr = 0.1
I0524 05:20:40.376361 11654 solver.cpp:239] Iteration 36670 (1.22642 iter/s, 8.1538s/10 iters), loss = 6.71601
I0524 05:20:40.376646 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71601 (* 1 = 6.71601 loss)
I0524 05:20:40.376685 11654 sgd_solver.cpp:112] Iteration 36670, lr = 0.1
I0524 05:20:46.892068 11654 solver.cpp:239] Iteration 36680 (1.53488 iter/s, 6.51517s/10 iters), loss = 6.43136
I0524 05:20:46.892129 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43136 (* 1 = 6.43136 loss)
I0524 05:20:47.155875 11654 sgd_solver.cpp:112] Iteration 36680, lr = 0.1
I0524 05:20:54.104583 11654 solver.cpp:239] Iteration 36690 (1.38654 iter/s, 7.21218s/10 iters), loss = 6.21819
I0524 05:20:54.104632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21819 (* 1 = 6.21819 loss)
I0524 05:20:54.105213 11654 sgd_solver.cpp:112] Iteration 36690, lr = 0.1
I0524 05:21:02.376102 11654 solver.cpp:239] Iteration 36700 (1.20902 iter/s, 8.27115s/10 iters), loss = 7.47379
I0524 05:21:02.376163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.47379 (* 1 = 7.47379 loss)
I0524 05:21:02.376202 11654 sgd_solver.cpp:112] Iteration 36700, lr = 0.1
I0524 05:21:09.809041 11654 solver.cpp:239] Iteration 36710 (1.34542 iter/s, 7.4326s/10 iters), loss = 6.33094
I0524 05:21:09.809098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33094 (* 1 = 6.33094 loss)
I0524 05:21:09.809118 11654 sgd_solver.cpp:112] Iteration 36710, lr = 0.1
I0524 05:21:19.230614 11654 solver.cpp:239] Iteration 36720 (1.06169 iter/s, 9.41896s/10 iters), loss = 6.77112
I0524 05:21:19.230779 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77112 (* 1 = 6.77112 loss)
I0524 05:21:19.243203 11654 sgd_solver.cpp:112] Iteration 36720, lr = 0.1
I0524 05:21:26.725978 11654 solver.cpp:239] Iteration 36730 (1.33424 iter/s, 7.4949s/10 iters), loss = 6.63743
I0524 05:21:26.726040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63743 (* 1 = 6.63743 loss)
I0524 05:21:26.726301 11654 sgd_solver.cpp:112] Iteration 36730, lr = 0.1
I0524 05:21:35.838222 11654 solver.cpp:239] Iteration 36740 (1.09747 iter/s, 9.11184s/10 iters), loss = 5.84931
I0524 05:21:35.838279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84931 (* 1 = 5.84931 loss)
I0524 05:21:36.148936 11654 sgd_solver.cpp:112] Iteration 36740, lr = 0.1
I0524 05:21:48.073483 11654 solver.cpp:239] Iteration 36750 (0.817345 iter/s, 12.2347s/10 iters), loss = 6.46111
I0524 05:21:48.073539 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46111 (* 1 = 6.46111 loss)
I0524 05:21:48.073554 11654 sgd_solver.cpp:112] Iteration 36750, lr = 0.1
I0524 05:21:56.693341 11654 solver.cpp:239] Iteration 36760 (1.16016 iter/s, 8.61947s/10 iters), loss = 6.856
I0524 05:21:56.693572 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.856 (* 1 = 6.856 loss)
I0524 05:21:56.693799 11654 sgd_solver.cpp:112] Iteration 36760, lr = 0.1
I0524 05:22:03.383764 11654 solver.cpp:239] Iteration 36770 (1.49478 iter/s, 6.68993s/10 iters), loss = 6.16485
I0524 05:22:03.383893 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16485 (* 1 = 6.16485 loss)
I0524 05:22:03.383914 11654 sgd_solver.cpp:112] Iteration 36770, lr = 0.1
I0524 05:22:11.298354 11654 solver.cpp:239] Iteration 36780 (1.26357 iter/s, 7.9141s/10 iters), loss = 7.28681
I0524 05:22:11.298413 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28681 (* 1 = 7.28681 loss)
I0524 05:22:11.298946 11654 sgd_solver.cpp:112] Iteration 36780, lr = 0.1
I0524 05:22:17.670797 11654 solver.cpp:239] Iteration 36790 (1.56933 iter/s, 6.37213s/10 iters), loss = 7.13526
I0524 05:22:17.670858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13526 (* 1 = 7.13526 loss)
I0524 05:22:17.670878 11654 sgd_solver.cpp:112] Iteration 36790, lr = 0.1
I0524 05:22:24.577723 11654 solver.cpp:239] Iteration 36800 (1.4479 iter/s, 6.90654s/10 iters), loss = 5.49699
I0524 05:22:24.577803 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49699 (* 1 = 5.49699 loss)
I0524 05:22:24.577921 11654 sgd_solver.cpp:112] Iteration 36800, lr = 0.1
I0524 05:22:34.161746 11654 solver.cpp:239] Iteration 36810 (1.04345 iter/s, 9.58358s/10 iters), loss = 5.97098
I0524 05:22:34.161942 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97098 (* 1 = 5.97098 loss)
I0524 05:22:34.162010 11654 sgd_solver.cpp:112] Iteration 36810, lr = 0.1
I0524 05:22:42.840381 11654 solver.cpp:239] Iteration 36820 (1.15233 iter/s, 8.6781s/10 iters), loss = 6.13656
I0524 05:22:42.840447 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13656 (* 1 = 6.13656 loss)
I0524 05:22:42.840498 11654 sgd_solver.cpp:112] Iteration 36820, lr = 0.1
I0524 05:22:50.090754 11654 solver.cpp:239] Iteration 36830 (1.37931 iter/s, 7.24998s/10 iters), loss = 6.52893
I0524 05:22:50.090821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52893 (* 1 = 6.52893 loss)
I0524 05:22:50.335523 11654 sgd_solver.cpp:112] Iteration 36830, lr = 0.1
I0524 05:22:57.360278 11654 solver.cpp:239] Iteration 36840 (1.37568 iter/s, 7.26914s/10 iters), loss = 5.90452
I0524 05:22:57.360350 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90452 (* 1 = 5.90452 loss)
I0524 05:22:57.360544 11654 sgd_solver.cpp:112] Iteration 36840, lr = 0.1
I0524 05:23:04.346487 11654 solver.cpp:239] Iteration 36850 (1.43146 iter/s, 6.98588s/10 iters), loss = 6.26713
I0524 05:23:04.346647 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26713 (* 1 = 6.26713 loss)
I0524 05:23:04.346678 11654 sgd_solver.cpp:112] Iteration 36850, lr = 0.1
I0524 05:23:10.803002 11654 solver.cpp:239] Iteration 36860 (1.54893 iter/s, 6.45606s/10 iters), loss = 7.14236
I0524 05:23:10.803052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14236 (* 1 = 7.14236 loss)
I0524 05:23:10.803205 11654 sgd_solver.cpp:112] Iteration 36860, lr = 0.1
I0524 05:23:16.908877 11654 solver.cpp:239] Iteration 36870 (1.63784 iter/s, 6.10558s/10 iters), loss = 6.57525
I0524 05:23:16.908934 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57525 (* 1 = 6.57525 loss)
I0524 05:23:16.909339 11654 sgd_solver.cpp:112] Iteration 36870, lr = 0.1
I0524 05:23:26.110916 11654 solver.cpp:239] Iteration 36880 (1.08676 iter/s, 9.20162s/10 iters), loss = 6.33961
I0524 05:23:26.110980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33961 (* 1 = 6.33961 loss)
I0524 05:23:26.110998 11654 sgd_solver.cpp:112] Iteration 36880, lr = 0.1
I0524 05:23:35.054549 11654 solver.cpp:239] Iteration 36890 (1.11844 iter/s, 8.94104s/10 iters), loss = 5.75097
I0524 05:23:35.054838 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75097 (* 1 = 5.75097 loss)
I0524 05:23:35.223253 11654 sgd_solver.cpp:112] Iteration 36890, lr = 0.1
I0524 05:23:43.174183 11654 solver.cpp:239] Iteration 36900 (1.23167 iter/s, 8.11907s/10 iters), loss = 6.60336
I0524 05:23:43.174252 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60336 (* 1 = 6.60336 loss)
I0524 05:23:43.174789 11654 sgd_solver.cpp:112] Iteration 36900, lr = 0.1
I0524 05:23:51.329638 11654 solver.cpp:239] Iteration 36910 (1.22623 iter/s, 8.15508s/10 iters), loss = 6.00934
I0524 05:23:51.329696 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00934 (* 1 = 6.00934 loss)
I0524 05:23:51.329728 11654 sgd_solver.cpp:112] Iteration 36910, lr = 0.1
I0524 05:24:01.178246 11654 solver.cpp:239] Iteration 36920 (1.01542 iter/s, 9.84817s/10 iters), loss = 6.11368
I0524 05:24:01.178308 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11368 (* 1 = 6.11368 loss)
I0524 05:24:01.178326 11654 sgd_solver.cpp:112] Iteration 36920, lr = 0.1
I0524 05:24:10.125188 11654 solver.cpp:239] Iteration 36930 (1.1178 iter/s, 8.94614s/10 iters), loss = 5.15198
I0524 05:24:10.125587 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.15198 (* 1 = 5.15198 loss)
I0524 05:24:10.126139 11654 sgd_solver.cpp:112] Iteration 36930, lr = 0.1
I0524 05:24:19.132369 11654 solver.cpp:239] Iteration 36940 (1.11031 iter/s, 9.00652s/10 iters), loss = 6.59464
I0524 05:24:19.132457 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59464 (* 1 = 6.59464 loss)
I0524 05:24:19.628347 11654 sgd_solver.cpp:112] Iteration 36940, lr = 0.1
I0524 05:24:27.100709 11654 solver.cpp:239] Iteration 36950 (1.25503 iter/s, 7.96795s/10 iters), loss = 6.14663
I0524 05:24:27.100770 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14663 (* 1 = 6.14663 loss)
I0524 05:24:27.100854 11654 sgd_solver.cpp:112] Iteration 36950, lr = 0.1
I0524 05:24:35.520936 11654 solver.cpp:239] Iteration 36960 (1.18767 iter/s, 8.41984s/10 iters), loss = 6.57713
I0524 05:24:35.521029 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57713 (* 1 = 6.57713 loss)
I0524 05:24:35.802769 11654 sgd_solver.cpp:112] Iteration 36960, lr = 0.1
I0524 05:24:42.986042 11654 solver.cpp:239] Iteration 36970 (1.33963 iter/s, 7.46476s/10 iters), loss = 6.12903
I0524 05:24:42.986214 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12903 (* 1 = 6.12903 loss)
I0524 05:24:43.169754 11654 sgd_solver.cpp:112] Iteration 36970, lr = 0.1
I0524 05:24:51.942139 11654 solver.cpp:239] Iteration 36980 (1.11662 iter/s, 8.95557s/10 iters), loss = 6.48839
I0524 05:24:51.942255 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48839 (* 1 = 6.48839 loss)
I0524 05:24:51.942283 11654 sgd_solver.cpp:112] Iteration 36980, lr = 0.1
I0524 05:25:00.652132 11654 solver.cpp:239] Iteration 36990 (1.14817 iter/s, 8.70951s/10 iters), loss = 6.27975
I0524 05:25:00.652242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27975 (* 1 = 6.27975 loss)
I0524 05:25:00.652262 11654 sgd_solver.cpp:112] Iteration 36990, lr = 0.1
I0524 05:25:07.207325 11654 solver.cpp:239] Iteration 37000 (1.52559 iter/s, 6.55484s/10 iters), loss = 6.65585
I0524 05:25:07.207391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65585 (* 1 = 6.65585 loss)
I0524 05:25:07.207520 11654 sgd_solver.cpp:112] Iteration 37000, lr = 0.1
I0524 05:25:13.723877 11654 solver.cpp:239] Iteration 37010 (1.53463 iter/s, 6.51624s/10 iters), loss = 6.49711
I0524 05:25:13.724050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49711 (* 1 = 6.49711 loss)
I0524 05:25:13.724092 11654 sgd_solver.cpp:112] Iteration 37010, lr = 0.1
I0524 05:25:20.971212 11654 solver.cpp:239] Iteration 37020 (1.37991 iter/s, 7.24685s/10 iters), loss = 5.48944
I0524 05:25:20.971287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48944 (* 1 = 5.48944 loss)
I0524 05:25:20.971345 11654 sgd_solver.cpp:112] Iteration 37020, lr = 0.1
I0524 05:25:31.173689 11654 solver.cpp:239] Iteration 37030 (0.980199 iter/s, 10.202s/10 iters), loss = 6.71761
I0524 05:25:31.173754 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71761 (* 1 = 6.71761 loss)
I0524 05:25:31.599381 11654 sgd_solver.cpp:112] Iteration 37030, lr = 0.1
I0524 05:25:40.362602 11654 solver.cpp:239] Iteration 37040 (1.08832 iter/s, 9.18849s/10 iters), loss = 6.71777
I0524 05:25:40.362681 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71777 (* 1 = 6.71777 loss)
I0524 05:25:40.362931 11654 sgd_solver.cpp:112] Iteration 37040, lr = 0.1
I0524 05:25:47.949589 11654 solver.cpp:239] Iteration 37050 (1.31811 iter/s, 7.58661s/10 iters), loss = 5.76004
I0524 05:25:47.949858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76004 (* 1 = 5.76004 loss)
I0524 05:25:47.949906 11654 sgd_solver.cpp:112] Iteration 37050, lr = 0.1
I0524 05:25:56.379396 11654 solver.cpp:239] Iteration 37060 (1.18635 iter/s, 8.4292s/10 iters), loss = 6.87191
I0524 05:25:56.379451 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87191 (* 1 = 6.87191 loss)
I0524 05:25:56.379467 11654 sgd_solver.cpp:112] Iteration 37060, lr = 0.1
I0524 05:26:05.195916 11654 solver.cpp:239] Iteration 37070 (1.1343 iter/s, 8.81604s/10 iters), loss = 5.44856
I0524 05:26:05.195984 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44856 (* 1 = 5.44856 loss)
I0524 05:26:05.211145 11654 sgd_solver.cpp:112] Iteration 37070, lr = 0.1
I0524 05:26:14.427881 11654 solver.cpp:239] Iteration 37080 (1.08325 iter/s, 9.23151s/10 iters), loss = 7.15325
I0524 05:26:14.427968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15325 (* 1 = 7.15325 loss)
I0524 05:26:14.427986 11654 sgd_solver.cpp:112] Iteration 37080, lr = 0.1
I0524 05:26:22.158316 11654 solver.cpp:239] Iteration 37090 (1.29365 iter/s, 7.73006s/10 iters), loss = 6.26698
I0524 05:26:22.158483 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26698 (* 1 = 6.26698 loss)
I0524 05:26:22.158529 11654 sgd_solver.cpp:112] Iteration 37090, lr = 0.1
I0524 05:26:30.259940 11654 solver.cpp:239] Iteration 37100 (1.2344 iter/s, 8.10113s/10 iters), loss = 6.51097
I0524 05:26:30.260007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51097 (* 1 = 6.51097 loss)
I0524 05:26:30.260023 11654 sgd_solver.cpp:112] Iteration 37100, lr = 0.1
I0524 05:26:36.691763 11654 solver.cpp:239] Iteration 37110 (1.55487 iter/s, 6.43142s/10 iters), loss = 6.39422
I0524 05:26:36.691886 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39422 (* 1 = 6.39422 loss)
I0524 05:26:36.692387 11654 sgd_solver.cpp:112] Iteration 37110, lr = 0.1
I0524 05:26:45.143893 11654 solver.cpp:239] Iteration 37120 (1.18319 iter/s, 8.45172s/10 iters), loss = 6.21876
I0524 05:26:45.143965 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21876 (* 1 = 6.21876 loss)
I0524 05:26:45.152339 11654 sgd_solver.cpp:112] Iteration 37120, lr = 0.1
I0524 05:26:52.660408 11654 solver.cpp:239] Iteration 37130 (1.33047 iter/s, 7.51616s/10 iters), loss = 5.02312
I0524 05:26:52.660666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.02312 (* 1 = 5.02312 loss)
I0524 05:26:52.660717 11654 sgd_solver.cpp:112] Iteration 37130, lr = 0.1
I0524 05:27:00.393990 11654 solver.cpp:239] Iteration 37140 (1.2932 iter/s, 7.73278s/10 iters), loss = 6.51782
I0524 05:27:00.394065 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51782 (* 1 = 6.51782 loss)
I0524 05:27:00.394137 11654 sgd_solver.cpp:112] Iteration 37140, lr = 0.1
I0524 05:27:08.870000 11654 solver.cpp:239] Iteration 37150 (1.17985 iter/s, 8.47563s/10 iters), loss = 5.90176
I0524 05:27:08.870050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90176 (* 1 = 5.90176 loss)
I0524 05:27:08.870065 11654 sgd_solver.cpp:112] Iteration 37150, lr = 0.1
I0524 05:27:18.064654 11654 solver.cpp:239] Iteration 37160 (1.08765 iter/s, 9.19417s/10 iters), loss = 5.68446
I0524 05:27:18.064744 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68446 (* 1 = 5.68446 loss)
I0524 05:27:18.064764 11654 sgd_solver.cpp:112] Iteration 37160, lr = 0.1
I0524 05:27:25.843514 11654 solver.cpp:239] Iteration 37170 (1.28561 iter/s, 7.77843s/10 iters), loss = 6.16975
I0524 05:27:25.843698 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16975 (* 1 = 6.16975 loss)
I0524 05:27:25.843868 11654 sgd_solver.cpp:112] Iteration 37170, lr = 0.1
I0524 05:27:34.877529 11654 solver.cpp:239] Iteration 37180 (1.10699 iter/s, 9.03347s/10 iters), loss = 5.34661
I0524 05:27:34.877586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.34661 (* 1 = 5.34661 loss)
I0524 05:27:34.877604 11654 sgd_solver.cpp:112] Iteration 37180, lr = 0.1
I0524 05:27:42.390162 11654 solver.cpp:239] Iteration 37190 (1.33126 iter/s, 7.51165s/10 iters), loss = 6.55847
I0524 05:27:42.390249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55847 (* 1 = 6.55847 loss)
I0524 05:27:42.390316 11654 sgd_solver.cpp:112] Iteration 37190, lr = 0.1
I0524 05:27:50.495203 11654 solver.cpp:239] Iteration 37200 (1.23386 iter/s, 8.10466s/10 iters), loss = 6.51712
I0524 05:27:50.495295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51712 (* 1 = 6.51712 loss)
I0524 05:27:51.301085 11654 sgd_solver.cpp:112] Iteration 37200, lr = 0.1
I0524 05:27:58.273116 11654 solver.cpp:239] Iteration 37210 (1.28576 iter/s, 7.77751s/10 iters), loss = 6.05862
I0524 05:27:58.273321 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05862 (* 1 = 6.05862 loss)
I0524 05:27:59.063555 11654 sgd_solver.cpp:112] Iteration 37210, lr = 0.1
I0524 05:28:06.878331 11654 solver.cpp:239] Iteration 37220 (1.16215 iter/s, 8.6047s/10 iters), loss = 5.65004
I0524 05:28:06.878386 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65004 (* 1 = 5.65004 loss)
I0524 05:28:06.878417 11654 sgd_solver.cpp:112] Iteration 37220, lr = 0.1
I0524 05:28:17.233156 11654 solver.cpp:239] Iteration 37230 (0.965777 iter/s, 10.3544s/10 iters), loss = 6.21547
I0524 05:28:17.233201 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21547 (* 1 = 6.21547 loss)
I0524 05:28:17.233217 11654 sgd_solver.cpp:112] Iteration 37230, lr = 0.1
I0524 05:28:23.712905 11654 solver.cpp:239] Iteration 37240 (1.54334 iter/s, 6.47945s/10 iters), loss = 6.52867
I0524 05:28:23.712990 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52867 (* 1 = 6.52867 loss)
I0524 05:28:24.389562 11654 sgd_solver.cpp:112] Iteration 37240, lr = 0.1
I0524 05:28:31.023697 11654 solver.cpp:239] Iteration 37250 (1.36791 iter/s, 7.31045s/10 iters), loss = 6.29471
I0524 05:28:31.023953 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29471 (* 1 = 6.29471 loss)
I0524 05:28:31.400154 11654 sgd_solver.cpp:112] Iteration 37250, lr = 0.1
I0524 05:28:40.206085 11654 solver.cpp:239] Iteration 37260 (1.08911 iter/s, 9.18182s/10 iters), loss = 6.25666
I0524 05:28:40.206132 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25666 (* 1 = 6.25666 loss)
I0524 05:28:40.228797 11654 sgd_solver.cpp:112] Iteration 37260, lr = 0.1
I0524 05:28:47.559485 11654 solver.cpp:239] Iteration 37270 (1.35998 iter/s, 7.35306s/10 iters), loss = 6.70507
I0524 05:28:47.559552 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70507 (* 1 = 6.70507 loss)
I0524 05:28:47.559572 11654 sgd_solver.cpp:112] Iteration 37270, lr = 0.1
I0524 05:28:54.219180 11654 solver.cpp:239] Iteration 37280 (1.50214 iter/s, 6.65718s/10 iters), loss = 6.55825
I0524 05:28:54.219292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55825 (* 1 = 6.55825 loss)
I0524 05:28:54.219353 11654 sgd_solver.cpp:112] Iteration 37280, lr = 0.1
I0524 05:29:02.090055 11654 solver.cpp:239] Iteration 37290 (1.27063 iter/s, 7.87012s/10 iters), loss = 5.74433
I0524 05:29:02.090253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74433 (* 1 = 5.74433 loss)
I0524 05:29:02.090420 11654 sgd_solver.cpp:112] Iteration 37290, lr = 0.1
I0524 05:29:08.355413 11654 solver.cpp:239] Iteration 37300 (1.5962 iter/s, 6.26489s/10 iters), loss = 7.22014
I0524 05:29:08.355485 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22014 (* 1 = 7.22014 loss)
I0524 05:29:08.395483 11654 sgd_solver.cpp:112] Iteration 37300, lr = 0.1
I0524 05:29:16.668653 11654 solver.cpp:239] Iteration 37310 (1.20297 iter/s, 8.31279s/10 iters), loss = 6.11909
I0524 05:29:16.668756 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11909 (* 1 = 6.11909 loss)
I0524 05:29:16.668792 11654 sgd_solver.cpp:112] Iteration 37310, lr = 0.1
I0524 05:29:24.446830 11654 solver.cpp:239] Iteration 37320 (1.28571 iter/s, 7.77778s/10 iters), loss = 6.41219
I0524 05:29:24.446926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41219 (* 1 = 6.41219 loss)
I0524 05:29:24.446952 11654 sgd_solver.cpp:112] Iteration 37320, lr = 0.1
I0524 05:29:31.594413 11654 solver.cpp:239] Iteration 37330 (1.39915 iter/s, 7.14719s/10 iters), loss = 7.06905
I0524 05:29:31.594480 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06905 (* 1 = 7.06905 loss)
I0524 05:29:31.836529 11654 sgd_solver.cpp:112] Iteration 37330, lr = 0.1
I0524 05:29:38.459036 11654 solver.cpp:239] Iteration 37340 (1.45682 iter/s, 6.86426s/10 iters), loss = 6.76993
I0524 05:29:38.459342 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76993 (* 1 = 6.76993 loss)
I0524 05:29:38.640460 11654 sgd_solver.cpp:112] Iteration 37340, lr = 0.1
I0524 05:29:46.466290 11654 solver.cpp:239] Iteration 37350 (1.24896 iter/s, 8.00667s/10 iters), loss = 6.22264
I0524 05:29:46.466339 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22264 (* 1 = 6.22264 loss)
I0524 05:29:46.466354 11654 sgd_solver.cpp:112] Iteration 37350, lr = 0.1
I0524 05:29:53.792994 11654 solver.cpp:239] Iteration 37360 (1.36495 iter/s, 7.32629s/10 iters), loss = 6.73687
I0524 05:29:53.793077 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73687 (* 1 = 6.73687 loss)
I0524 05:29:53.793251 11654 sgd_solver.cpp:112] Iteration 37360, lr = 0.1
I0524 05:30:02.896803 11654 solver.cpp:239] Iteration 37370 (1.09849 iter/s, 9.1034s/10 iters), loss = 5.91992
I0524 05:30:02.896868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91992 (* 1 = 5.91992 loss)
I0524 05:30:02.918732 11654 sgd_solver.cpp:112] Iteration 37370, lr = 0.1
I0524 05:30:11.485281 11654 solver.cpp:239] Iteration 37380 (1.1644 iter/s, 8.58809s/10 iters), loss = 5.8082
I0524 05:30:11.485527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8082 (* 1 = 5.8082 loss)
I0524 05:30:12.441135 11654 sgd_solver.cpp:112] Iteration 37380, lr = 0.1
I0524 05:30:18.496006 11654 solver.cpp:239] Iteration 37390 (1.42649 iter/s, 7.01023s/10 iters), loss = 6.49424
I0524 05:30:18.496093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49424 (* 1 = 6.49424 loss)
I0524 05:30:18.586941 11654 sgd_solver.cpp:112] Iteration 37390, lr = 0.1
I0524 05:30:27.848392 11654 solver.cpp:239] Iteration 37400 (1.0693 iter/s, 9.35193s/10 iters), loss = 6.52212
I0524 05:30:27.848484 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52212 (* 1 = 6.52212 loss)
I0524 05:30:27.848579 11654 sgd_solver.cpp:112] Iteration 37400, lr = 0.1
I0524 05:30:36.559263 11654 solver.cpp:239] Iteration 37410 (1.14805 iter/s, 8.71044s/10 iters), loss = 5.24473
I0524 05:30:36.559330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.24473 (* 1 = 5.24473 loss)
I0524 05:30:36.601902 11654 sgd_solver.cpp:112] Iteration 37410, lr = 0.1
I0524 05:30:43.235028 11654 solver.cpp:239] Iteration 37420 (1.49803 iter/s, 6.67545s/10 iters), loss = 6.95394
I0524 05:30:43.235218 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95394 (* 1 = 6.95394 loss)
I0524 05:30:43.235296 11654 sgd_solver.cpp:112] Iteration 37420, lr = 0.1
I0524 05:30:50.803220 11654 solver.cpp:239] Iteration 37430 (1.3214 iter/s, 7.56771s/10 iters), loss = 6.22064
I0524 05:30:50.803268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22064 (* 1 = 6.22064 loss)
I0524 05:30:50.803699 11654 sgd_solver.cpp:112] Iteration 37430, lr = 0.1
I0524 05:30:58.062897 11654 solver.cpp:239] Iteration 37440 (1.37754 iter/s, 7.25932s/10 iters), loss = 6.68802
I0524 05:30:58.062968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68802 (* 1 = 6.68802 loss)
I0524 05:30:58.062985 11654 sgd_solver.cpp:112] Iteration 37440, lr = 0.1
I0524 05:31:04.743427 11654 solver.cpp:239] Iteration 37450 (1.49696 iter/s, 6.68021s/10 iters), loss = 6.25464
I0524 05:31:04.743507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25464 (* 1 = 6.25464 loss)
I0524 05:31:04.743602 11654 sgd_solver.cpp:112] Iteration 37450, lr = 0.1
I0524 05:31:12.294489 11654 solver.cpp:239] Iteration 37460 (1.32439 iter/s, 7.55067s/10 iters), loss = 6.05972
I0524 05:31:12.294641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05972 (* 1 = 6.05972 loss)
I0524 05:31:12.309314 11654 sgd_solver.cpp:112] Iteration 37460, lr = 0.1
I0524 05:31:22.438745 11654 solver.cpp:239] Iteration 37470 (0.985834 iter/s, 10.1437s/10 iters), loss = 6.29407
I0524 05:31:22.439069 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29407 (* 1 = 6.29407 loss)
I0524 05:31:23.327013 11654 sgd_solver.cpp:112] Iteration 37470, lr = 0.1
I0524 05:31:30.612649 11654 solver.cpp:239] Iteration 37480 (1.2235 iter/s, 8.17331s/10 iters), loss = 4.85831
I0524 05:31:30.612768 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.85831 (* 1 = 4.85831 loss)
I0524 05:31:30.612800 11654 sgd_solver.cpp:112] Iteration 37480, lr = 0.1
I0524 05:31:37.096644 11654 solver.cpp:239] Iteration 37490 (1.54234 iter/s, 6.48367s/10 iters), loss = 5.60218
I0524 05:31:37.096711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60218 (* 1 = 5.60218 loss)
I0524 05:31:37.096753 11654 sgd_solver.cpp:112] Iteration 37490, lr = 0.1
I0524 05:31:43.977978 11654 solver.cpp:239] Iteration 37500 (1.45329 iter/s, 6.88096s/10 iters), loss = 6.52071
I0524 05:31:43.978067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52071 (* 1 = 6.52071 loss)
I0524 05:31:43.990664 11654 sgd_solver.cpp:112] Iteration 37500, lr = 0.1
I0524 05:31:51.069126 11654 solver.cpp:239] Iteration 37510 (1.41028 iter/s, 7.09078s/10 iters), loss = 6.29812
I0524 05:31:51.069186 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29812 (* 1 = 6.29812 loss)
I0524 05:31:51.069288 11654 sgd_solver.cpp:112] Iteration 37510, lr = 0.1
I0524 05:31:58.972090 11654 solver.cpp:239] Iteration 37520 (1.26541 iter/s, 7.90258s/10 iters), loss = 6.9918
I0524 05:31:58.972383 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9918 (* 1 = 6.9918 loss)
I0524 05:31:58.972438 11654 sgd_solver.cpp:112] Iteration 37520, lr = 0.1
I0524 05:32:06.727897 11654 solver.cpp:239] Iteration 37530 (1.28949 iter/s, 7.755s/10 iters), loss = 5.90512
I0524 05:32:06.727960 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90512 (* 1 = 5.90512 loss)
I0524 05:32:06.727977 11654 sgd_solver.cpp:112] Iteration 37530, lr = 0.1
I0524 05:32:15.340420 11654 solver.cpp:239] Iteration 37540 (1.16116 iter/s, 8.61207s/10 iters), loss = 5.76564
I0524 05:32:15.340497 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76564 (* 1 = 5.76564 loss)
I0524 05:32:15.653523 11654 sgd_solver.cpp:112] Iteration 37540, lr = 0.1
I0524 05:32:23.248159 11654 solver.cpp:239] Iteration 37550 (1.26465 iter/s, 7.90734s/10 iters), loss = 6.29372
I0524 05:32:23.248242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29372 (* 1 = 6.29372 loss)
I0524 05:32:23.248368 11654 sgd_solver.cpp:112] Iteration 37550, lr = 0.1
I0524 05:32:31.387900 11654 solver.cpp:239] Iteration 37560 (1.2286 iter/s, 8.13935s/10 iters), loss = 7.10003
I0524 05:32:31.388098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10003 (* 1 = 7.10003 loss)
I0524 05:32:31.388128 11654 sgd_solver.cpp:112] Iteration 37560, lr = 0.1
I0524 05:32:37.976223 11654 solver.cpp:239] Iteration 37570 (1.51795 iter/s, 6.58783s/10 iters), loss = 6.17679
I0524 05:32:37.976315 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17679 (* 1 = 6.17679 loss)
I0524 05:32:37.976409 11654 sgd_solver.cpp:112] Iteration 37570, lr = 0.1
I0524 05:32:45.059428 11654 solver.cpp:239] Iteration 37580 (1.41187 iter/s, 7.08283s/10 iters), loss = 6.87093
I0524 05:32:45.059496 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87093 (* 1 = 6.87093 loss)
I0524 05:32:45.221125 11654 sgd_solver.cpp:112] Iteration 37580, lr = 0.1
I0524 05:32:53.003252 11654 solver.cpp:239] Iteration 37590 (1.2589 iter/s, 7.94345s/10 iters), loss = 6.1864
I0524 05:32:53.003304 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1864 (* 1 = 6.1864 loss)
I0524 05:32:53.003424 11654 sgd_solver.cpp:112] Iteration 37590, lr = 0.1
I0524 05:32:59.472873 11654 solver.cpp:239] Iteration 37600 (1.54576 iter/s, 6.4693s/10 iters), loss = 5.93555
I0524 05:32:59.473000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93555 (* 1 = 5.93555 loss)
I0524 05:32:59.473094 11654 sgd_solver.cpp:112] Iteration 37600, lr = 0.1
I0524 05:33:06.449440 11654 solver.cpp:239] Iteration 37610 (1.43345 iter/s, 6.97619s/10 iters), loss = 6.6127
I0524 05:33:06.449694 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6127 (* 1 = 6.6127 loss)
I0524 05:33:06.449738 11654 sgd_solver.cpp:112] Iteration 37610, lr = 0.1
I0524 05:33:12.662140 11654 solver.cpp:239] Iteration 37620 (1.61028 iter/s, 6.21009s/10 iters), loss = 7.14037
I0524 05:33:12.662233 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14037 (* 1 = 7.14037 loss)
I0524 05:33:12.662529 11654 sgd_solver.cpp:112] Iteration 37620, lr = 0.1
I0524 05:33:19.384683 11654 solver.cpp:239] Iteration 37630 (1.48761 iter/s, 6.72218s/10 iters), loss = 7.33104
I0524 05:33:19.384762 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33104 (* 1 = 7.33104 loss)
I0524 05:33:19.385030 11654 sgd_solver.cpp:112] Iteration 37630, lr = 0.1
I0524 05:33:28.001020 11654 solver.cpp:239] Iteration 37640 (1.16064 iter/s, 8.61592s/10 iters), loss = 5.56538
I0524 05:33:28.001124 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56538 (* 1 = 5.56538 loss)
I0524 05:33:28.003352 11654 sgd_solver.cpp:112] Iteration 37640, lr = 0.1
I0524 05:33:36.392465 11654 solver.cpp:239] Iteration 37650 (1.19176 iter/s, 8.39097s/10 iters), loss = 5.78414
I0524 05:33:36.392601 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78414 (* 1 = 5.78414 loss)
I0524 05:33:36.392648 11654 sgd_solver.cpp:112] Iteration 37650, lr = 0.1
I0524 05:33:43.369297 11654 solver.cpp:239] Iteration 37660 (1.4334 iter/s, 6.97642s/10 iters), loss = 5.6068
I0524 05:33:43.369482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6068 (* 1 = 5.6068 loss)
I0524 05:33:44.223795 11654 sgd_solver.cpp:112] Iteration 37660, lr = 0.1
I0524 05:33:53.003687 11654 solver.cpp:239] Iteration 37670 (1.03801 iter/s, 9.63385s/10 iters), loss = 5.61004
I0524 05:33:53.003741 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61004 (* 1 = 5.61004 loss)
I0524 05:33:53.616644 11654 sgd_solver.cpp:112] Iteration 37670, lr = 0.1
I0524 05:34:02.702491 11654 solver.cpp:239] Iteration 37680 (1.03111 iter/s, 9.6983s/10 iters), loss = 6.10929
I0524 05:34:02.702785 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10929 (* 1 = 6.10929 loss)
I0524 05:34:02.702865 11654 sgd_solver.cpp:112] Iteration 37680, lr = 0.1
I0524 05:34:09.298135 11654 solver.cpp:239] Iteration 37690 (1.51624 iter/s, 6.59526s/10 iters), loss = 6.97946
I0524 05:34:09.298190 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97946 (* 1 = 6.97946 loss)
I0524 05:34:09.298329 11654 sgd_solver.cpp:112] Iteration 37690, lr = 0.1
I0524 05:34:16.832901 11654 solver.cpp:239] Iteration 37700 (1.32724 iter/s, 7.5344s/10 iters), loss = 6.89577
I0524 05:34:16.833163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89577 (* 1 = 6.89577 loss)
I0524 05:34:16.833209 11654 sgd_solver.cpp:112] Iteration 37700, lr = 0.1
I0524 05:34:24.301856 11654 solver.cpp:239] Iteration 37710 (1.33898 iter/s, 7.46839s/10 iters), loss = 5.5705
I0524 05:34:24.301939 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5705 (* 1 = 5.5705 loss)
I0524 05:34:24.490499 11654 sgd_solver.cpp:112] Iteration 37710, lr = 0.1
I0524 05:34:36.662854 11654 solver.cpp:239] Iteration 37720 (0.809031 iter/s, 12.3605s/10 iters), loss = 6.47941
I0524 05:34:36.662936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47941 (* 1 = 6.47941 loss)
I0524 05:34:37.213007 11654 sgd_solver.cpp:112] Iteration 37720, lr = 0.1
I0524 05:34:44.992857 11654 solver.cpp:239] Iteration 37730 (1.20054 iter/s, 8.32961s/10 iters), loss = 6.59807
I0524 05:34:44.992905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59807 (* 1 = 6.59807 loss)
I0524 05:34:45.266422 11654 sgd_solver.cpp:112] Iteration 37730, lr = 0.1
I0524 05:34:53.366943 11654 solver.cpp:239] Iteration 37740 (1.19422 iter/s, 8.3737s/10 iters), loss = 5.97964
I0524 05:34:53.367220 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97964 (* 1 = 5.97964 loss)
I0524 05:34:53.676121 11654 sgd_solver.cpp:112] Iteration 37740, lr = 0.1
I0524 05:35:01.712322 11654 solver.cpp:239] Iteration 37750 (1.19835 iter/s, 8.34479s/10 iters), loss = 5.60272
I0524 05:35:01.712445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60272 (* 1 = 5.60272 loss)
I0524 05:35:01.712486 11654 sgd_solver.cpp:112] Iteration 37750, lr = 0.1
I0524 05:35:08.916115 11654 solver.cpp:239] Iteration 37760 (1.38823 iter/s, 7.20341s/10 iters), loss = 5.65107
I0524 05:35:08.916194 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65107 (* 1 = 5.65107 loss)
I0524 05:35:08.916628 11654 sgd_solver.cpp:112] Iteration 37760, lr = 0.1
I0524 05:35:15.531383 11654 solver.cpp:239] Iteration 37770 (1.51173 iter/s, 6.61494s/10 iters), loss = 6.09903
I0524 05:35:15.531453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09903 (* 1 = 6.09903 loss)
I0524 05:35:15.531558 11654 sgd_solver.cpp:112] Iteration 37770, lr = 0.1
I0524 05:35:22.061367 11654 solver.cpp:239] Iteration 37780 (1.53148 iter/s, 6.52962s/10 iters), loss = 5.93697
I0524 05:35:22.061468 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93697 (* 1 = 5.93697 loss)
I0524 05:35:22.061560 11654 sgd_solver.cpp:112] Iteration 37780, lr = 0.1
I0524 05:35:28.172821 11654 solver.cpp:239] Iteration 37790 (1.63635 iter/s, 6.11115s/10 iters), loss = 6.76685
I0524 05:35:28.173068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76685 (* 1 = 6.76685 loss)
I0524 05:35:28.173149 11654 sgd_solver.cpp:112] Iteration 37790, lr = 0.1
I0524 05:35:35.714481 11654 solver.cpp:239] Iteration 37800 (1.32607 iter/s, 7.54108s/10 iters), loss = 5.70376
I0524 05:35:35.714542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70376 (* 1 = 5.70376 loss)
I0524 05:35:35.714560 11654 sgd_solver.cpp:112] Iteration 37800, lr = 0.1
I0524 05:35:44.018292 11654 solver.cpp:239] Iteration 37810 (1.20464 iter/s, 8.30123s/10 iters), loss = 6.22889
I0524 05:35:44.018402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22889 (* 1 = 6.22889 loss)
I0524 05:35:44.018450 11654 sgd_solver.cpp:112] Iteration 37810, lr = 0.1
I0524 05:35:54.066090 11654 solver.cpp:239] Iteration 37820 (0.995292 iter/s, 10.0473s/10 iters), loss = 5.92632
I0524 05:35:54.066145 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92632 (* 1 = 5.92632 loss)
I0524 05:35:54.066413 11654 sgd_solver.cpp:112] Iteration 37820, lr = 0.1
I0524 05:36:05.270454 11654 solver.cpp:239] Iteration 37830 (0.892549 iter/s, 11.2039s/10 iters), loss = 6.70362
I0524 05:36:05.270790 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70362 (* 1 = 6.70362 loss)
I0524 05:36:06.398939 11654 sgd_solver.cpp:112] Iteration 37830, lr = 0.1
I0524 05:36:13.214462 11654 solver.cpp:239] Iteration 37840 (1.25889 iter/s, 7.94348s/10 iters), loss = 6.71169
I0524 05:36:13.214538 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71169 (* 1 = 6.71169 loss)
I0524 05:36:13.214851 11654 sgd_solver.cpp:112] Iteration 37840, lr = 0.1
I0524 05:36:20.306095 11654 solver.cpp:239] Iteration 37850 (1.41018 iter/s, 7.0913s/10 iters), loss = 6.9153
I0524 05:36:20.306164 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9153 (* 1 = 6.9153 loss)
I0524 05:36:20.306330 11654 sgd_solver.cpp:112] Iteration 37850, lr = 0.1
I0524 05:36:26.654669 11654 solver.cpp:239] Iteration 37860 (1.57524 iter/s, 6.34823s/10 iters), loss = 6.19256
I0524 05:36:26.654758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19256 (* 1 = 6.19256 loss)
I0524 05:36:26.655100 11654 sgd_solver.cpp:112] Iteration 37860, lr = 0.1
I0524 05:36:33.815574 11654 solver.cpp:239] Iteration 37870 (1.39654 iter/s, 7.16054s/10 iters), loss = 7.25181
I0524 05:36:33.815637 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25181 (* 1 = 7.25181 loss)
I0524 05:36:33.815743 11654 sgd_solver.cpp:112] Iteration 37870, lr = 0.1
I0524 05:36:40.771550 11654 solver.cpp:239] Iteration 37880 (1.43768 iter/s, 6.95565s/10 iters), loss = 5.97342
I0524 05:36:40.771718 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97342 (* 1 = 5.97342 loss)
I0524 05:36:40.771740 11654 sgd_solver.cpp:112] Iteration 37880, lr = 0.1
I0524 05:36:50.029472 11654 solver.cpp:239] Iteration 37890 (1.08026 iter/s, 9.25706s/10 iters), loss = 5.93808
I0524 05:36:50.029567 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93808 (* 1 = 5.93808 loss)
I0524 05:36:50.029593 11654 sgd_solver.cpp:112] Iteration 37890, lr = 0.1
I0524 05:36:58.490645 11654 solver.cpp:239] Iteration 37900 (1.18194 iter/s, 8.4607s/10 iters), loss = 5.90988
I0524 05:36:58.490785 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90988 (* 1 = 5.90988 loss)
I0524 05:36:59.053690 11654 sgd_solver.cpp:112] Iteration 37900, lr = 0.1
I0524 05:37:05.865048 11654 solver.cpp:239] Iteration 37910 (1.35611 iter/s, 7.37401s/10 iters), loss = 7.17919
I0524 05:37:05.865118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17919 (* 1 = 7.17919 loss)
I0524 05:37:05.916966 11654 sgd_solver.cpp:112] Iteration 37910, lr = 0.1
I0524 05:37:14.033517 11654 solver.cpp:239] Iteration 37920 (1.22428 iter/s, 8.16807s/10 iters), loss = 5.49136
I0524 05:37:14.033730 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49136 (* 1 = 5.49136 loss)
I0524 05:37:14.309068 11654 sgd_solver.cpp:112] Iteration 37920, lr = 0.1
I0524 05:37:21.590422 11654 solver.cpp:239] Iteration 37930 (1.32338 iter/s, 7.55638s/10 iters), loss = 6.3725
I0524 05:37:21.590502 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3725 (* 1 = 6.3725 loss)
I0524 05:37:21.590773 11654 sgd_solver.cpp:112] Iteration 37930, lr = 0.1
I0524 05:37:31.670526 11654 solver.cpp:239] Iteration 37940 (0.992099 iter/s, 10.0796s/10 iters), loss = 6.01788
I0524 05:37:31.670591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01788 (* 1 = 6.01788 loss)
I0524 05:37:32.286605 11654 sgd_solver.cpp:112] Iteration 37940, lr = 0.1
I0524 05:37:40.347110 11654 solver.cpp:239] Iteration 37950 (1.15258 iter/s, 8.67618s/10 iters), loss = 6.17384
I0524 05:37:40.347154 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17384 (* 1 = 6.17384 loss)
I0524 05:37:40.347177 11654 sgd_solver.cpp:112] Iteration 37950, lr = 0.1
I0524 05:37:49.462414 11654 solver.cpp:239] Iteration 37960 (1.09711 iter/s, 9.1149s/10 iters), loss = 6.0102
I0524 05:37:49.462625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0102 (* 1 = 6.0102 loss)
I0524 05:37:49.462658 11654 sgd_solver.cpp:112] Iteration 37960, lr = 0.1
I0524 05:37:57.761771 11654 solver.cpp:239] Iteration 37970 (1.20506 iter/s, 8.29837s/10 iters), loss = 6.97239
I0524 05:37:57.761821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97239 (* 1 = 6.97239 loss)
I0524 05:37:58.722199 11654 sgd_solver.cpp:112] Iteration 37970, lr = 0.1
I0524 05:38:05.470135 11654 solver.cpp:239] Iteration 37980 (1.29735 iter/s, 7.70799s/10 iters), loss = 6.97544
I0524 05:38:05.470212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97544 (* 1 = 6.97544 loss)
I0524 05:38:05.470232 11654 sgd_solver.cpp:112] Iteration 37980, lr = 0.1
I0524 05:38:13.454186 11654 solver.cpp:239] Iteration 37990 (1.25265 iter/s, 7.98309s/10 iters), loss = 5.5524
I0524 05:38:13.454243 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5524 (* 1 = 5.5524 loss)
I0524 05:38:13.454259 11654 sgd_solver.cpp:112] Iteration 37990, lr = 0.1
I0524 05:38:20.282531 11654 solver.cpp:239] Iteration 38000 (1.46457 iter/s, 6.82796s/10 iters), loss = 6.20602
I0524 05:38:20.282732 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20602 (* 1 = 6.20602 loss)
I0524 05:38:20.282757 11654 sgd_solver.cpp:112] Iteration 38000, lr = 0.1
I0524 05:38:27.310883 11654 solver.cpp:239] Iteration 38010 (1.4229 iter/s, 7.02789s/10 iters), loss = 6.09897
I0524 05:38:27.310978 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09897 (* 1 = 6.09897 loss)
I0524 05:38:27.311074 11654 sgd_solver.cpp:112] Iteration 38010, lr = 0.1
I0524 05:38:33.877498 11654 solver.cpp:239] Iteration 38020 (1.52293 iter/s, 6.56629s/10 iters), loss = 6.05234
I0524 05:38:33.877542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05234 (* 1 = 6.05234 loss)
I0524 05:38:34.037813 11654 sgd_solver.cpp:112] Iteration 38020, lr = 0.1
I0524 05:38:41.557446 11654 solver.cpp:239] Iteration 38030 (1.30216 iter/s, 7.67954s/10 iters), loss = 5.5184
I0524 05:38:41.557610 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5184 (* 1 = 5.5184 loss)
I0524 05:38:41.557662 11654 sgd_solver.cpp:112] Iteration 38030, lr = 0.1
I0524 05:38:50.051226 11654 solver.cpp:239] Iteration 38040 (1.1774 iter/s, 8.49331s/10 iters), loss = 5.64356
I0524 05:38:50.051332 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64356 (* 1 = 5.64356 loss)
I0524 05:38:50.235182 11654 sgd_solver.cpp:112] Iteration 38040, lr = 0.1
I0524 05:38:57.150768 11654 solver.cpp:239] Iteration 38050 (1.40862 iter/s, 7.09915s/10 iters), loss = 5.56706
I0524 05:38:57.151027 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56706 (* 1 = 5.56706 loss)
I0524 05:38:57.151080 11654 sgd_solver.cpp:112] Iteration 38050, lr = 0.1
I0524 05:39:03.657217 11654 solver.cpp:239] Iteration 38060 (1.53757 iter/s, 6.50377s/10 iters), loss = 5.89158
I0524 05:39:03.657338 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89158 (* 1 = 5.89158 loss)
I0524 05:39:03.657378 11654 sgd_solver.cpp:112] Iteration 38060, lr = 0.1
I0524 05:39:10.046509 11654 solver.cpp:239] Iteration 38070 (1.56546 iter/s, 6.38788s/10 iters), loss = 6.59867
I0524 05:39:10.046571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59867 (* 1 = 6.59867 loss)
I0524 05:39:10.046591 11654 sgd_solver.cpp:112] Iteration 38070, lr = 0.1
I0524 05:39:17.526821 11654 solver.cpp:239] Iteration 38080 (1.33726 iter/s, 7.47799s/10 iters), loss = 5.43441
I0524 05:39:17.526881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.43441 (* 1 = 5.43441 loss)
I0524 05:39:17.526896 11654 sgd_solver.cpp:112] Iteration 38080, lr = 0.1
I0524 05:39:25.051512 11654 solver.cpp:239] Iteration 38090 (1.32907 iter/s, 7.52408s/10 iters), loss = 5.68477
I0524 05:39:25.051573 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68477 (* 1 = 5.68477 loss)
I0524 05:39:25.051723 11654 sgd_solver.cpp:112] Iteration 38090, lr = 0.1
I0524 05:39:31.580276 11654 solver.cpp:239] Iteration 38100 (1.53176 iter/s, 6.52844s/10 iters), loss = 6.56659
I0524 05:39:31.580435 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56659 (* 1 = 6.56659 loss)
I0524 05:39:31.580463 11654 sgd_solver.cpp:112] Iteration 38100, lr = 0.1
I0524 05:39:39.363200 11654 solver.cpp:239] Iteration 38110 (1.28494 iter/s, 7.78244s/10 iters), loss = 6.63707
I0524 05:39:39.363282 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63707 (* 1 = 6.63707 loss)
I0524 05:39:39.412497 11654 sgd_solver.cpp:112] Iteration 38110, lr = 0.1
I0524 05:39:47.294807 11654 solver.cpp:239] Iteration 38120 (1.26143 iter/s, 7.9275s/10 iters), loss = 6.81522
I0524 05:39:47.294904 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81522 (* 1 = 6.81522 loss)
I0524 05:39:47.294947 11654 sgd_solver.cpp:112] Iteration 38120, lr = 0.1
I0524 05:39:54.734993 11654 solver.cpp:239] Iteration 38130 (1.34413 iter/s, 7.43977s/10 iters), loss = 7.09588
I0524 05:39:54.735059 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09588 (* 1 = 7.09588 loss)
I0524 05:39:54.735435 11654 sgd_solver.cpp:112] Iteration 38130, lr = 0.1
I0524 05:40:02.024961 11654 solver.cpp:239] Iteration 38140 (1.37183 iter/s, 7.28954s/10 iters), loss = 5.67324
I0524 05:40:02.025279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67324 (* 1 = 5.67324 loss)
I0524 05:40:02.025326 11654 sgd_solver.cpp:112] Iteration 38140, lr = 0.1
I0524 05:40:09.645460 11654 solver.cpp:239] Iteration 38150 (1.31236 iter/s, 7.61989s/10 iters), loss = 6.91482
I0524 05:40:09.645515 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91482 (* 1 = 6.91482 loss)
I0524 05:40:09.645532 11654 sgd_solver.cpp:112] Iteration 38150, lr = 0.1
I0524 05:40:17.358513 11654 solver.cpp:239] Iteration 38160 (1.2966 iter/s, 7.71251s/10 iters), loss = 7.44673
I0524 05:40:17.358587 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.44673 (* 1 = 7.44673 loss)
I0524 05:40:17.908340 11654 sgd_solver.cpp:112] Iteration 38160, lr = 0.1
I0524 05:40:27.338436 11654 solver.cpp:239] Iteration 38170 (1.00206 iter/s, 9.97948s/10 iters), loss = 7.25503
I0524 05:40:27.338490 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25503 (* 1 = 7.25503 loss)
I0524 05:40:27.338510 11654 sgd_solver.cpp:112] Iteration 38170, lr = 0.1
I0524 05:40:33.985347 11654 solver.cpp:239] Iteration 38180 (1.50454 iter/s, 6.64654s/10 iters), loss = 6.17968
I0524 05:40:33.985587 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17968 (* 1 = 6.17968 loss)
I0524 05:40:34.725608 11654 sgd_solver.cpp:112] Iteration 38180, lr = 0.1
I0524 05:40:41.886226 11654 solver.cpp:239] Iteration 38190 (1.26576 iter/s, 7.90038s/10 iters), loss = 6.00883
I0524 05:40:41.886291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00883 (* 1 = 6.00883 loss)
I0524 05:40:41.886394 11654 sgd_solver.cpp:112] Iteration 38190, lr = 0.1
I0524 05:40:49.290438 11654 solver.cpp:239] Iteration 38200 (1.35066 iter/s, 7.40379s/10 iters), loss = 6.81726
I0524 05:40:49.290547 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81726 (* 1 = 6.81726 loss)
I0524 05:40:49.290580 11654 sgd_solver.cpp:112] Iteration 38200, lr = 0.1
I0524 05:40:56.055968 11654 solver.cpp:239] Iteration 38210 (1.47816 iter/s, 6.76515s/10 iters), loss = 6.39575
I0524 05:40:56.056033 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39575 (* 1 = 6.39575 loss)
I0524 05:40:56.056068 11654 sgd_solver.cpp:112] Iteration 38210, lr = 0.1
I0524 05:41:03.523427 11654 solver.cpp:239] Iteration 38220 (1.33921 iter/s, 7.46707s/10 iters), loss = 6.14191
I0524 05:41:03.523481 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14191 (* 1 = 6.14191 loss)
I0524 05:41:03.523645 11654 sgd_solver.cpp:112] Iteration 38220, lr = 0.1
I0524 05:41:09.999213 11654 solver.cpp:239] Iteration 38230 (1.5443 iter/s, 6.47544s/10 iters), loss = 6.62809
I0524 05:41:09.999387 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62809 (* 1 = 6.62809 loss)
I0524 05:41:09.999737 11654 sgd_solver.cpp:112] Iteration 38230, lr = 0.1
I0524 05:41:16.319530 11654 solver.cpp:239] Iteration 38240 (1.58231 iter/s, 6.31989s/10 iters), loss = 7.26212
I0524 05:41:16.319597 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26212 (* 1 = 7.26212 loss)
I0524 05:41:16.319617 11654 sgd_solver.cpp:112] Iteration 38240, lr = 0.1
I0524 05:41:21.595409 11654 solver.cpp:239] Iteration 38250 (1.89554 iter/s, 5.27554s/10 iters), loss = 5.65984
I0524 05:41:21.595477 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65984 (* 1 = 5.65984 loss)
I0524 05:41:21.595496 11654 sgd_solver.cpp:112] Iteration 38250, lr = 0.1
I0524 05:41:29.025220 11654 solver.cpp:239] Iteration 38260 (1.346 iter/s, 7.4294s/10 iters), loss = 5.90781
I0524 05:41:29.025259 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90781 (* 1 = 5.90781 loss)
I0524 05:41:29.026342 11654 sgd_solver.cpp:112] Iteration 38260, lr = 0.1
I0524 05:41:37.677260 11654 solver.cpp:239] Iteration 38270 (1.15585 iter/s, 8.65164s/10 iters), loss = 5.74403
I0524 05:41:37.677337 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74403 (* 1 = 5.74403 loss)
I0524 05:41:37.677356 11654 sgd_solver.cpp:112] Iteration 38270, lr = 0.1
I0524 05:41:44.669329 11654 solver.cpp:239] Iteration 38280 (1.43027 iter/s, 6.99171s/10 iters), loss = 5.96309
I0524 05:41:44.669523 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96309 (* 1 = 5.96309 loss)
I0524 05:41:44.669558 11654 sgd_solver.cpp:112] Iteration 38280, lr = 0.1
I0524 05:41:51.636939 11654 solver.cpp:239] Iteration 38290 (1.43531 iter/s, 6.96715s/10 iters), loss = 7.16816
I0524 05:41:51.636992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.16816 (* 1 = 7.16816 loss)
I0524 05:41:51.637008 11654 sgd_solver.cpp:112] Iteration 38290, lr = 0.1
I0524 05:41:59.555958 11654 solver.cpp:239] Iteration 38300 (1.26285 iter/s, 7.91859s/10 iters), loss = 5.91148
I0524 05:41:59.556037 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91148 (* 1 = 5.91148 loss)
I0524 05:42:00.568250 11654 sgd_solver.cpp:112] Iteration 38300, lr = 0.1
I0524 05:42:06.961693 11654 solver.cpp:239] Iteration 38310 (1.35037 iter/s, 7.40536s/10 iters), loss = 6.2495
I0524 05:42:06.961760 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2495 (* 1 = 6.2495 loss)
I0524 05:42:06.962039 11654 sgd_solver.cpp:112] Iteration 38310, lr = 0.1
I0524 05:42:14.497045 11654 solver.cpp:239] Iteration 38320 (1.32714 iter/s, 7.535s/10 iters), loss = 7.10921
I0524 05:42:14.497119 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10921 (* 1 = 7.10921 loss)
I0524 05:42:14.878340 11654 sgd_solver.cpp:112] Iteration 38320, lr = 0.1
I0524 05:42:22.533459 11654 solver.cpp:239] Iteration 38330 (1.24439 iter/s, 8.03606s/10 iters), loss = 5.98123
I0524 05:42:22.533536 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98123 (* 1 = 5.98123 loss)
I0524 05:42:23.259527 11654 sgd_solver.cpp:112] Iteration 38330, lr = 0.1
I0524 05:42:30.763509 11654 solver.cpp:239] Iteration 38340 (1.21512 iter/s, 8.22966s/10 iters), loss = 6.08439
I0524 05:42:30.763582 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08439 (* 1 = 6.08439 loss)
I0524 05:42:30.763680 11654 sgd_solver.cpp:112] Iteration 38340, lr = 0.1
I0524 05:42:39.564169 11654 solver.cpp:239] Iteration 38350 (1.13633 iter/s, 8.80027s/10 iters), loss = 6.25184
I0524 05:42:39.564210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25184 (* 1 = 6.25184 loss)
I0524 05:42:39.564234 11654 sgd_solver.cpp:112] Iteration 38350, lr = 0.1
I0524 05:42:46.586113 11654 solver.cpp:239] Iteration 38360 (1.42417 iter/s, 7.02162s/10 iters), loss = 6.43695
I0524 05:42:46.586455 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43695 (* 1 = 6.43695 loss)
I0524 05:42:47.885713 11654 sgd_solver.cpp:112] Iteration 38360, lr = 0.1
I0524 05:42:58.855310 11654 solver.cpp:239] Iteration 38370 (0.815095 iter/s, 12.2685s/10 iters), loss = 5.83517
I0524 05:42:58.855440 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83517 (* 1 = 5.83517 loss)
I0524 05:42:58.855468 11654 sgd_solver.cpp:112] Iteration 38370, lr = 0.1
I0524 05:43:05.435801 11654 solver.cpp:239] Iteration 38380 (1.51972 iter/s, 6.58014s/10 iters), loss = 6.23966
I0524 05:43:05.435866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23966 (* 1 = 6.23966 loss)
I0524 05:43:05.820627 11654 sgd_solver.cpp:112] Iteration 38380, lr = 0.1
I0524 05:43:12.968325 11654 solver.cpp:239] Iteration 38390 (1.32764 iter/s, 7.53219s/10 iters), loss = 6.57831
I0524 05:43:12.968370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57831 (* 1 = 6.57831 loss)
I0524 05:43:12.968384 11654 sgd_solver.cpp:112] Iteration 38390, lr = 0.1
I0524 05:43:20.046886 11654 solver.cpp:239] Iteration 38400 (1.4128 iter/s, 7.07815s/10 iters), loss = 6.69774
I0524 05:43:20.047067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69774 (* 1 = 6.69774 loss)
I0524 05:43:20.047093 11654 sgd_solver.cpp:112] Iteration 38400, lr = 0.1
I0524 05:43:28.265488 11654 solver.cpp:239] Iteration 38410 (1.21683 iter/s, 8.21805s/10 iters), loss = 5.72994
I0524 05:43:28.265571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72994 (* 1 = 5.72994 loss)
I0524 05:43:28.265727 11654 sgd_solver.cpp:112] Iteration 38410, lr = 0.1
I0524 05:43:36.854820 11654 solver.cpp:239] Iteration 38420 (1.16429 iter/s, 8.58894s/10 iters), loss = 6.52425
I0524 05:43:36.854877 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52425 (* 1 = 6.52425 loss)
I0524 05:43:37.313757 11654 sgd_solver.cpp:112] Iteration 38420, lr = 0.1
I0524 05:43:46.172418 11654 solver.cpp:239] Iteration 38430 (1.07329 iter/s, 9.31718s/10 iters), loss = 6.36908
I0524 05:43:46.172488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36908 (* 1 = 6.36908 loss)
I0524 05:43:46.172513 11654 sgd_solver.cpp:112] Iteration 38430, lr = 0.1
I0524 05:43:52.619535 11654 solver.cpp:239] Iteration 38440 (1.55117 iter/s, 6.44673s/10 iters), loss = 6.21394
I0524 05:43:52.619825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21394 (* 1 = 6.21394 loss)
I0524 05:43:52.676004 11654 sgd_solver.cpp:112] Iteration 38440, lr = 0.1
I0524 05:44:01.807919 11654 solver.cpp:239] Iteration 38450 (1.0884 iter/s, 9.18778s/10 iters), loss = 5.3334
I0524 05:44:01.807998 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3334 (* 1 = 5.3334 loss)
I0524 05:44:01.808027 11654 sgd_solver.cpp:112] Iteration 38450, lr = 0.1
I0524 05:44:08.690140 11654 solver.cpp:239] Iteration 38460 (1.45315 iter/s, 6.88161s/10 iters), loss = 6.69827
I0524 05:44:08.690196 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69827 (* 1 = 6.69827 loss)
I0524 05:44:08.690213 11654 sgd_solver.cpp:112] Iteration 38460, lr = 0.1
I0524 05:44:14.981397 11654 solver.cpp:239] Iteration 38470 (1.58964 iter/s, 6.29074s/10 iters), loss = 5.59822
I0524 05:44:14.981457 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59822 (* 1 = 5.59822 loss)
I0524 05:44:14.981667 11654 sgd_solver.cpp:112] Iteration 38470, lr = 0.1
I0524 05:44:22.401767 11654 solver.cpp:239] Iteration 38480 (1.3477 iter/s, 7.42003s/10 iters), loss = 6.79669
I0524 05:44:22.401823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79669 (* 1 = 6.79669 loss)
I0524 05:44:22.401970 11654 sgd_solver.cpp:112] Iteration 38480, lr = 0.1
I0524 05:44:30.060535 11654 solver.cpp:239] Iteration 38490 (1.30575 iter/s, 7.65841s/10 iters), loss = 6.53549
I0524 05:44:30.060706 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53549 (* 1 = 6.53549 loss)
I0524 05:44:30.724400 11654 sgd_solver.cpp:112] Iteration 38490, lr = 0.1
I0524 05:44:37.316385 11654 solver.cpp:239] Iteration 38500 (1.37829 iter/s, 7.25537s/10 iters), loss = 6.41541
I0524 05:44:37.316457 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41541 (* 1 = 6.41541 loss)
I0524 05:44:37.316501 11654 sgd_solver.cpp:112] Iteration 38500, lr = 0.1
I0524 05:44:45.512034 11654 solver.cpp:239] Iteration 38510 (1.22022 iter/s, 8.19528s/10 iters), loss = 6.59171
I0524 05:44:45.512099 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59171 (* 1 = 6.59171 loss)
I0524 05:44:45.628603 11654 sgd_solver.cpp:112] Iteration 38510, lr = 0.1
I0524 05:44:52.629770 11654 solver.cpp:239] Iteration 38520 (1.40501 iter/s, 7.1174s/10 iters), loss = 6.40747
I0524 05:44:52.629833 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40747 (* 1 = 6.40747 loss)
I0524 05:44:52.629851 11654 sgd_solver.cpp:112] Iteration 38520, lr = 0.1
I0524 05:44:59.462157 11654 solver.cpp:239] Iteration 38530 (1.4637 iter/s, 6.832s/10 iters), loss = 5.28026
I0524 05:44:59.462224 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28026 (* 1 = 5.28026 loss)
I0524 05:44:59.635692 11654 sgd_solver.cpp:112] Iteration 38530, lr = 0.1
I0524 05:45:05.734952 11654 solver.cpp:239] Iteration 38540 (1.59426 iter/s, 6.2725s/10 iters), loss = 5.63176
I0524 05:45:05.735144 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63176 (* 1 = 5.63176 loss)
I0524 05:45:05.735183 11654 sgd_solver.cpp:112] Iteration 38540, lr = 0.1
I0524 05:45:15.225021 11654 solver.cpp:239] Iteration 38550 (1.05403 iter/s, 9.48738s/10 iters), loss = 6.31039
I0524 05:45:15.225075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31039 (* 1 = 6.31039 loss)
I0524 05:45:15.753806 11654 sgd_solver.cpp:112] Iteration 38550, lr = 0.1
I0524 05:45:23.988149 11654 solver.cpp:239] Iteration 38560 (1.1412 iter/s, 8.76272s/10 iters), loss = 6.64958
I0524 05:45:23.988221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64958 (* 1 = 6.64958 loss)
I0524 05:45:24.058732 11654 sgd_solver.cpp:112] Iteration 38560, lr = 0.1
I0524 05:45:30.779312 11654 solver.cpp:239] Iteration 38570 (1.47257 iter/s, 6.79083s/10 iters), loss = 6.45497
I0524 05:45:30.779383 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45497 (* 1 = 6.45497 loss)
I0524 05:45:30.779408 11654 sgd_solver.cpp:112] Iteration 38570, lr = 0.1
I0524 05:45:38.576853 11654 solver.cpp:239] Iteration 38580 (1.28252 iter/s, 7.79717s/10 iters), loss = 6.27835
I0524 05:45:38.577118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27835 (* 1 = 6.27835 loss)
I0524 05:45:38.577172 11654 sgd_solver.cpp:112] Iteration 38580, lr = 0.1
I0524 05:45:47.620682 11654 solver.cpp:239] Iteration 38590 (1.1058 iter/s, 9.04322s/10 iters), loss = 5.87576
I0524 05:45:47.620728 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87576 (* 1 = 5.87576 loss)
I0524 05:45:47.620743 11654 sgd_solver.cpp:112] Iteration 38590, lr = 0.1
I0524 05:45:55.983295 11654 solver.cpp:239] Iteration 38600 (1.19587 iter/s, 8.36214s/10 iters), loss = 6.37924
I0524 05:45:55.983464 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37924 (* 1 = 6.37924 loss)
I0524 05:45:55.983505 11654 sgd_solver.cpp:112] Iteration 38600, lr = 0.1
I0524 05:46:03.120383 11654 solver.cpp:239] Iteration 38610 (1.40121 iter/s, 7.1367s/10 iters), loss = 5.29495
I0524 05:46:03.120437 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29495 (* 1 = 5.29495 loss)
I0524 05:46:03.120978 11654 sgd_solver.cpp:112] Iteration 38610, lr = 0.1
I0524 05:46:12.385468 11654 solver.cpp:239] Iteration 38620 (1.07937 iter/s, 9.26466s/10 iters), loss = 6.21332
I0524 05:46:12.385742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21332 (* 1 = 6.21332 loss)
I0524 05:46:13.444579 11654 sgd_solver.cpp:112] Iteration 38620, lr = 0.1
I0524 05:46:20.911417 11654 solver.cpp:239] Iteration 38630 (1.17297 iter/s, 8.52538s/10 iters), loss = 5.75142
I0524 05:46:20.911486 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75142 (* 1 = 5.75142 loss)
I0524 05:46:20.911505 11654 sgd_solver.cpp:112] Iteration 38630, lr = 0.1
I0524 05:46:31.089916 11654 solver.cpp:239] Iteration 38640 (0.98272 iter/s, 10.1758s/10 iters), loss = 6.45932
I0524 05:46:31.089984 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45932 (* 1 = 6.45932 loss)
I0524 05:46:31.090505 11654 sgd_solver.cpp:112] Iteration 38640, lr = 0.1
I0524 05:46:38.099222 11654 solver.cpp:239] Iteration 38650 (1.42674 iter/s, 7.00897s/10 iters), loss = 5.63772
I0524 05:46:38.099309 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63772 (* 1 = 5.63772 loss)
I0524 05:46:38.099354 11654 sgd_solver.cpp:112] Iteration 38650, lr = 0.1
I0524 05:46:44.353528 11654 solver.cpp:239] Iteration 38660 (1.59899 iter/s, 6.25396s/10 iters), loss = 5.6234
I0524 05:46:44.353746 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6234 (* 1 = 5.6234 loss)
I0524 05:46:44.353786 11654 sgd_solver.cpp:112] Iteration 38660, lr = 0.1
I0524 05:46:52.563078 11654 solver.cpp:239] Iteration 38670 (1.21817 iter/s, 8.20903s/10 iters), loss = 6.45999
I0524 05:46:52.563133 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45999 (* 1 = 6.45999 loss)
I0524 05:46:52.589495 11654 sgd_solver.cpp:112] Iteration 38670, lr = 0.1
I0524 05:47:01.657855 11654 solver.cpp:239] Iteration 38680 (1.09958 iter/s, 9.09436s/10 iters), loss = 6.22717
I0524 05:47:01.657937 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22717 (* 1 = 6.22717 loss)
I0524 05:47:02.681890 11654 sgd_solver.cpp:112] Iteration 38680, lr = 0.1
I0524 05:47:09.923691 11654 solver.cpp:239] Iteration 38690 (1.20986 iter/s, 8.26543s/10 iters), loss = 6.05798
I0524 05:47:09.923748 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05798 (* 1 = 6.05798 loss)
I0524 05:47:09.923769 11654 sgd_solver.cpp:112] Iteration 38690, lr = 0.1
I0524 05:47:18.172127 11654 solver.cpp:239] Iteration 38700 (1.21242 iter/s, 8.24798s/10 iters), loss = 6.85047
I0524 05:47:18.172320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85047 (* 1 = 6.85047 loss)
I0524 05:47:19.190843 11654 sgd_solver.cpp:112] Iteration 38700, lr = 0.1
I0524 05:47:25.497788 11654 solver.cpp:239] Iteration 38710 (1.36516 iter/s, 7.32517s/10 iters), loss = 6.35794
I0524 05:47:25.497843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35794 (* 1 = 6.35794 loss)
I0524 05:47:25.497869 11654 sgd_solver.cpp:112] Iteration 38710, lr = 0.1
I0524 05:47:33.540912 11654 solver.cpp:239] Iteration 38720 (1.24336 iter/s, 8.04275s/10 iters), loss = 5.69906
I0524 05:47:33.540976 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69906 (* 1 = 5.69906 loss)
I0524 05:47:34.432804 11654 sgd_solver.cpp:112] Iteration 38720, lr = 0.1
I0524 05:47:42.860180 11654 solver.cpp:239] Iteration 38730 (1.07309 iter/s, 9.31885s/10 iters), loss = 7.09066
I0524 05:47:42.860250 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09066 (* 1 = 7.09066 loss)
I0524 05:47:42.860270 11654 sgd_solver.cpp:112] Iteration 38730, lr = 0.1
I0524 05:47:49.592587 11654 solver.cpp:239] Iteration 38740 (1.48544 iter/s, 6.73203s/10 iters), loss = 6.11286
I0524 05:47:49.592875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11286 (* 1 = 6.11286 loss)
I0524 05:47:49.592950 11654 sgd_solver.cpp:112] Iteration 38740, lr = 0.1
I0524 05:47:56.910964 11654 solver.cpp:239] Iteration 38750 (1.36655 iter/s, 7.3177s/10 iters), loss = 6.69924
I0524 05:47:56.911079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69924 (* 1 = 6.69924 loss)
I0524 05:47:56.911119 11654 sgd_solver.cpp:112] Iteration 38750, lr = 0.1
I0524 05:48:04.079653 11654 solver.cpp:239] Iteration 38760 (1.39504 iter/s, 7.16826s/10 iters), loss = 7.13231
I0524 05:48:04.079711 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13231 (* 1 = 7.13231 loss)
I0524 05:48:04.079730 11654 sgd_solver.cpp:112] Iteration 38760, lr = 0.1
I0524 05:48:12.190377 11654 solver.cpp:239] Iteration 38770 (1.23333 iter/s, 8.10811s/10 iters), loss = 6.08518
I0524 05:48:12.190467 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08518 (* 1 = 6.08518 loss)
I0524 05:48:12.190624 11654 sgd_solver.cpp:112] Iteration 38770, lr = 0.1
I0524 05:48:18.594103 11654 solver.cpp:239] Iteration 38780 (1.56167 iter/s, 6.4034s/10 iters), loss = 6.19686
I0524 05:48:18.594146 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19686 (* 1 = 6.19686 loss)
I0524 05:48:18.594221 11654 sgd_solver.cpp:112] Iteration 38780, lr = 0.1
I0524 05:48:25.564941 11654 solver.cpp:239] Iteration 38790 (1.43462 iter/s, 6.97051s/10 iters), loss = 6.70471
I0524 05:48:25.565165 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70471 (* 1 = 6.70471 loss)
I0524 05:48:25.565219 11654 sgd_solver.cpp:112] Iteration 38790, lr = 0.1
I0524 05:48:33.407389 11654 solver.cpp:239] Iteration 38800 (1.2752 iter/s, 7.84193s/10 iters), loss = 7.14979
I0524 05:48:33.407480 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14979 (* 1 = 7.14979 loss)
I0524 05:48:33.407515 11654 sgd_solver.cpp:112] Iteration 38800, lr = 0.1
I0524 05:48:41.414198 11654 solver.cpp:239] Iteration 38810 (1.24901 iter/s, 8.00633s/10 iters), loss = 6.06705
I0524 05:48:41.414331 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06705 (* 1 = 6.06705 loss)
I0524 05:48:41.430738 11654 sgd_solver.cpp:112] Iteration 38810, lr = 0.1
I0524 05:48:47.531934 11654 solver.cpp:239] Iteration 38820 (1.63468 iter/s, 6.1174s/10 iters), loss = 5.9443
I0524 05:48:47.531996 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9443 (* 1 = 5.9443 loss)
I0524 05:48:47.532027 11654 sgd_solver.cpp:112] Iteration 38820, lr = 0.1
I0524 05:48:54.550485 11654 solver.cpp:239] Iteration 38830 (1.42487 iter/s, 7.01818s/10 iters), loss = 5.54781
I0524 05:48:54.550668 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54781 (* 1 = 5.54781 loss)
I0524 05:48:54.848983 11654 sgd_solver.cpp:112] Iteration 38830, lr = 0.1
I0524 05:49:01.180701 11654 solver.cpp:239] Iteration 38840 (1.50833 iter/s, 6.62985s/10 iters), loss = 6.13722
I0524 05:49:01.180909 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13722 (* 1 = 6.13722 loss)
I0524 05:49:01.341192 11654 sgd_solver.cpp:112] Iteration 38840, lr = 0.1
I0524 05:49:09.461174 11654 solver.cpp:239] Iteration 38850 (1.20774 iter/s, 8.27994s/10 iters), loss = 6.31753
I0524 05:49:09.461252 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31753 (* 1 = 6.31753 loss)
I0524 05:49:09.482251 11654 sgd_solver.cpp:112] Iteration 38850, lr = 0.1
I0524 05:49:17.830193 11654 solver.cpp:239] Iteration 38860 (1.19495 iter/s, 8.36855s/10 iters), loss = 6.26703
I0524 05:49:17.830384 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26703 (* 1 = 6.26703 loss)
I0524 05:49:17.830575 11654 sgd_solver.cpp:112] Iteration 38860, lr = 0.1
I0524 05:49:25.612917 11654 solver.cpp:239] Iteration 38870 (1.28497 iter/s, 7.78229s/10 iters), loss = 6.31302
I0524 05:49:25.613019 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31302 (* 1 = 6.31302 loss)
I0524 05:49:25.613044 11654 sgd_solver.cpp:112] Iteration 38870, lr = 0.1
I0524 05:49:32.338569 11654 solver.cpp:239] Iteration 38880 (1.48693 iter/s, 6.72526s/10 iters), loss = 5.63445
I0524 05:49:32.338876 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63445 (* 1 = 5.63445 loss)
I0524 05:49:32.338939 11654 sgd_solver.cpp:112] Iteration 38880, lr = 0.1
I0524 05:49:41.939286 11654 solver.cpp:239] Iteration 38890 (1.04166 iter/s, 9.60002s/10 iters), loss = 5.97648
I0524 05:49:41.939352 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97648 (* 1 = 5.97648 loss)
I0524 05:49:41.940711 11654 sgd_solver.cpp:112] Iteration 38890, lr = 0.1
I0524 05:49:51.340101 11654 solver.cpp:239] Iteration 38900 (1.06379 iter/s, 9.40038s/10 iters), loss = 6.29602
I0524 05:49:51.340174 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29602 (* 1 = 6.29602 loss)
I0524 05:49:51.340210 11654 sgd_solver.cpp:112] Iteration 38900, lr = 0.1
I0524 05:49:57.960402 11654 solver.cpp:239] Iteration 38910 (1.51059 iter/s, 6.61992s/10 iters), loss = 6.36291
I0524 05:49:57.960465 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36291 (* 1 = 6.36291 loss)
I0524 05:49:57.960553 11654 sgd_solver.cpp:112] Iteration 38910, lr = 0.1
I0524 05:50:04.643744 11654 solver.cpp:239] Iteration 38920 (1.49633 iter/s, 6.68301s/10 iters), loss = 6.7429
I0524 05:50:04.643977 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7429 (* 1 = 6.7429 loss)
I0524 05:50:04.644088 11654 sgd_solver.cpp:112] Iteration 38920, lr = 0.1
I0524 05:50:11.741194 11654 solver.cpp:239] Iteration 38930 (1.40905 iter/s, 7.09697s/10 iters), loss = 6.35204
I0524 05:50:11.741264 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35204 (* 1 = 6.35204 loss)
I0524 05:50:11.741299 11654 sgd_solver.cpp:112] Iteration 38930, lr = 0.1
I0524 05:50:19.250896 11654 solver.cpp:239] Iteration 38940 (1.33168 iter/s, 7.50931s/10 iters), loss = 5.12612
I0524 05:50:19.250949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.12612 (* 1 = 5.12612 loss)
I0524 05:50:19.250965 11654 sgd_solver.cpp:112] Iteration 38940, lr = 0.1
I0524 05:50:29.240023 11654 solver.cpp:239] Iteration 38950 (1.00113 iter/s, 9.98869s/10 iters), loss = 7.29601
I0524 05:50:29.240097 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29601 (* 1 = 7.29601 loss)
I0524 05:50:29.240115 11654 sgd_solver.cpp:112] Iteration 38950, lr = 0.1
I0524 05:50:38.489444 11654 solver.cpp:239] Iteration 38960 (1.08146 iter/s, 9.2468s/10 iters), loss = 6.20968
I0524 05:50:38.489615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20968 (* 1 = 6.20968 loss)
I0524 05:50:38.597327 11654 sgd_solver.cpp:112] Iteration 38960, lr = 0.1
I0524 05:50:44.955237 11654 solver.cpp:239] Iteration 38970 (1.5467 iter/s, 6.46538s/10 iters), loss = 6.94665
I0524 05:50:44.955302 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94665 (* 1 = 6.94665 loss)
I0524 05:50:44.955540 11654 sgd_solver.cpp:112] Iteration 38970, lr = 0.1
I0524 05:50:53.060485 11654 solver.cpp:239] Iteration 38980 (1.23383 iter/s, 8.10486s/10 iters), loss = 7.38991
I0524 05:50:53.060544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.38991 (* 1 = 7.38991 loss)
I0524 05:50:53.060714 11654 sgd_solver.cpp:112] Iteration 38980, lr = 0.1
I0524 05:51:02.594638 11654 solver.cpp:239] Iteration 38990 (1.04891 iter/s, 9.53371s/10 iters), loss = 5.97488
I0524 05:51:02.594745 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97488 (* 1 = 5.97488 loss)
I0524 05:51:02.594769 11654 sgd_solver.cpp:112] Iteration 38990, lr = 0.1
I0524 05:51:09.316054 11654 solver.cpp:239] Iteration 39000 (1.48786 iter/s, 6.72108s/10 iters), loss = 6.0908
I0524 05:51:09.316372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0908 (* 1 = 6.0908 loss)
I0524 05:51:09.316431 11654 sgd_solver.cpp:112] Iteration 39000, lr = 0.1
I0524 05:51:17.812831 11654 solver.cpp:239] Iteration 39010 (1.17713 iter/s, 8.49527s/10 iters), loss = 6.35775
I0524 05:51:17.812882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35775 (* 1 = 6.35775 loss)
I0524 05:51:17.812899 11654 sgd_solver.cpp:112] Iteration 39010, lr = 0.1
I0524 05:51:25.061223 11654 solver.cpp:239] Iteration 39020 (1.37968 iter/s, 7.24806s/10 iters), loss = 6.06828
I0524 05:51:25.061278 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06828 (* 1 = 6.06828 loss)
I0524 05:51:25.357625 11654 sgd_solver.cpp:112] Iteration 39020, lr = 0.1
I0524 05:51:33.292574 11654 solver.cpp:239] Iteration 39030 (1.21492 iter/s, 8.23098s/10 iters), loss = 5.27004
I0524 05:51:33.292628 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.27004 (* 1 = 5.27004 loss)
I0524 05:51:33.292717 11654 sgd_solver.cpp:112] Iteration 39030, lr = 0.1
I0524 05:51:40.117684 11654 solver.cpp:239] Iteration 39040 (1.46525 iter/s, 6.82479s/10 iters), loss = 5.69055
I0524 05:51:40.117880 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69055 (* 1 = 5.69055 loss)
I0524 05:51:40.118355 11654 sgd_solver.cpp:112] Iteration 39040, lr = 0.1
I0524 05:51:46.539846 11654 solver.cpp:239] Iteration 39050 (1.55721 iter/s, 6.42173s/10 iters), loss = 5.92652
I0524 05:51:46.539907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92652 (* 1 = 5.92652 loss)
I0524 05:51:46.574968 11654 sgd_solver.cpp:112] Iteration 39050, lr = 0.1
I0524 05:51:53.910858 11654 solver.cpp:239] Iteration 39060 (1.35673 iter/s, 7.37066s/10 iters), loss = 5.98688
I0524 05:51:53.910917 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98688 (* 1 = 5.98688 loss)
I0524 05:51:53.911167 11654 sgd_solver.cpp:112] Iteration 39060, lr = 0.1
I0524 05:52:02.476261 11654 solver.cpp:239] Iteration 39070 (1.16754 iter/s, 8.565s/10 iters), loss = 6.23564
I0524 05:52:02.476341 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23564 (* 1 = 6.23564 loss)
I0524 05:52:02.807304 11654 sgd_solver.cpp:112] Iteration 39070, lr = 0.1
I0524 05:52:11.977089 11654 solver.cpp:239] Iteration 39080 (1.05259 iter/s, 9.5004s/10 iters), loss = 5.77406
I0524 05:52:11.977505 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77406 (* 1 = 5.77406 loss)
I0524 05:52:11.977761 11654 sgd_solver.cpp:112] Iteration 39080, lr = 0.1
I0524 05:52:18.491269 11654 solver.cpp:239] Iteration 39090 (1.53523 iter/s, 6.51368s/10 iters), loss = 6.40426
I0524 05:52:18.491317 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40426 (* 1 = 6.40426 loss)
I0524 05:52:18.491333 11654 sgd_solver.cpp:112] Iteration 39090, lr = 0.1
I0524 05:52:24.758442 11654 solver.cpp:239] Iteration 39100 (1.59571 iter/s, 6.2668s/10 iters), loss = 5.56719
I0524 05:52:24.758510 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56719 (* 1 = 5.56719 loss)
I0524 05:52:24.758991 11654 sgd_solver.cpp:112] Iteration 39100, lr = 0.1
I0524 05:52:33.154386 11654 solver.cpp:239] Iteration 39110 (1.19111 iter/s, 8.39554s/10 iters), loss = 5.55662
I0524 05:52:33.154482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55662 (* 1 = 5.55662 loss)
I0524 05:52:33.154505 11654 sgd_solver.cpp:112] Iteration 39110, lr = 0.1
I0524 05:52:41.145215 11654 solver.cpp:239] Iteration 39120 (1.25159 iter/s, 7.98986s/10 iters), loss = 7.45089
I0524 05:52:41.145264 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.45089 (* 1 = 7.45089 loss)
I0524 05:52:41.145283 11654 sgd_solver.cpp:112] Iteration 39120, lr = 0.1
I0524 05:52:48.664516 11654 solver.cpp:239] Iteration 39130 (1.33037 iter/s, 7.51672s/10 iters), loss = 6.67897
I0524 05:52:48.664887 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67897 (* 1 = 6.67897 loss)
I0524 05:52:48.664944 11654 sgd_solver.cpp:112] Iteration 39130, lr = 0.1
I0524 05:52:55.268533 11654 solver.cpp:239] Iteration 39140 (1.51482 iter/s, 6.60144s/10 iters), loss = 6.15697
I0524 05:52:55.268579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15697 (* 1 = 6.15697 loss)
I0524 05:52:55.283596 11654 sgd_solver.cpp:112] Iteration 39140, lr = 0.1
I0524 05:53:01.737056 11654 solver.cpp:239] Iteration 39150 (1.54602 iter/s, 6.46821s/10 iters), loss = 7.19396
I0524 05:53:01.737119 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19396 (* 1 = 7.19396 loss)
I0524 05:53:01.737138 11654 sgd_solver.cpp:112] Iteration 39150, lr = 0.1
I0524 05:53:08.767112 11654 solver.cpp:239] Iteration 39160 (1.42254 iter/s, 7.02967s/10 iters), loss = 5.64974
I0524 05:53:08.767158 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64974 (* 1 = 5.64974 loss)
I0524 05:53:08.767259 11654 sgd_solver.cpp:112] Iteration 39160, lr = 0.1
I0524 05:53:16.496726 11654 solver.cpp:239] Iteration 39170 (1.29379 iter/s, 7.72925s/10 iters), loss = 5.51004
I0524 05:53:16.496805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51004 (* 1 = 5.51004 loss)
I0524 05:53:16.496938 11654 sgd_solver.cpp:112] Iteration 39170, lr = 0.1
I0524 05:53:24.394812 11654 solver.cpp:239] Iteration 39180 (1.26619 iter/s, 7.89771s/10 iters), loss = 7.09339
I0524 05:53:24.394994 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09339 (* 1 = 7.09339 loss)
I0524 05:53:24.395023 11654 sgd_solver.cpp:112] Iteration 39180, lr = 0.1
I0524 05:53:32.121899 11654 solver.cpp:239] Iteration 39190 (1.29423 iter/s, 7.7266s/10 iters), loss = 5.51731
I0524 05:53:32.121968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51731 (* 1 = 5.51731 loss)
I0524 05:53:32.893232 11654 sgd_solver.cpp:112] Iteration 39190, lr = 0.1
I0524 05:53:41.896987 11654 solver.cpp:239] Iteration 39200 (1.02305 iter/s, 9.77466s/10 iters), loss = 5.99604
I0524 05:53:41.897050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99604 (* 1 = 5.99604 loss)
I0524 05:53:41.897069 11654 sgd_solver.cpp:112] Iteration 39200, lr = 0.1
I0524 05:53:51.293320 11654 solver.cpp:239] Iteration 39210 (1.0643 iter/s, 9.39586s/10 iters), loss = 6.06386
I0524 05:53:51.293378 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06386 (* 1 = 6.06386 loss)
I0524 05:53:51.293398 11654 sgd_solver.cpp:112] Iteration 39210, lr = 0.1
I0524 05:53:57.612274 11654 solver.cpp:239] Iteration 39220 (1.58264 iter/s, 6.31858s/10 iters), loss = 6.30883
I0524 05:53:57.612433 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30883 (* 1 = 6.30883 loss)
I0524 05:53:57.612545 11654 sgd_solver.cpp:112] Iteration 39220, lr = 0.1
I0524 05:54:06.077862 11654 solver.cpp:239] Iteration 39230 (1.18132 iter/s, 8.4651s/10 iters), loss = 5.82015
I0524 05:54:06.077925 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82015 (* 1 = 5.82015 loss)
I0524 05:54:06.077944 11654 sgd_solver.cpp:112] Iteration 39230, lr = 0.1
I0524 05:54:14.951566 11654 solver.cpp:239] Iteration 39240 (1.12698 iter/s, 8.87331s/10 iters), loss = 6.55531
I0524 05:54:14.951607 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55531 (* 1 = 6.55531 loss)
I0524 05:54:15.224431 11654 sgd_solver.cpp:112] Iteration 39240, lr = 0.1
I0524 05:54:22.998781 11654 solver.cpp:239] Iteration 39250 (1.24273 iter/s, 8.04682s/10 iters), loss = 6.16452
I0524 05:54:22.998875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16452 (* 1 = 6.16452 loss)
I0524 05:54:22.999002 11654 sgd_solver.cpp:112] Iteration 39250, lr = 0.1
I0524 05:54:30.492313 11654 solver.cpp:239] Iteration 39260 (1.33455 iter/s, 7.49316s/10 iters), loss = 6.0177
I0524 05:54:30.492518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0177 (* 1 = 6.0177 loss)
I0524 05:54:30.492537 11654 sgd_solver.cpp:112] Iteration 39260, lr = 0.1
I0524 05:54:38.855109 11654 solver.cpp:239] Iteration 39270 (1.19585 iter/s, 8.36223s/10 iters), loss = 6.69473
I0524 05:54:38.855162 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69473 (* 1 = 6.69473 loss)
I0524 05:54:38.855551 11654 sgd_solver.cpp:112] Iteration 39270, lr = 0.1
I0524 05:54:45.563747 11654 solver.cpp:239] Iteration 39280 (1.49069 iter/s, 6.70832s/10 iters), loss = 6.60365
I0524 05:54:45.563824 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60365 (* 1 = 6.60365 loss)
I0524 05:54:45.563848 11654 sgd_solver.cpp:112] Iteration 39280, lr = 0.1
I0524 05:54:54.000779 11654 solver.cpp:239] Iteration 39290 (1.18532 iter/s, 8.43657s/10 iters), loss = 5.86277
I0524 05:54:54.000851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86277 (* 1 = 5.86277 loss)
I0524 05:54:54.000872 11654 sgd_solver.cpp:112] Iteration 39290, lr = 0.1
I0524 05:55:00.475672 11654 solver.cpp:239] Iteration 39300 (1.54485 iter/s, 6.47312s/10 iters), loss = 6.56145
I0524 05:55:00.475740 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56145 (* 1 = 6.56145 loss)
I0524 05:55:00.555387 11654 sgd_solver.cpp:112] Iteration 39300, lr = 0.1
I0524 05:55:08.853667 11654 solver.cpp:239] Iteration 39310 (1.19366 iter/s, 8.37759s/10 iters), loss = 5.30749
I0524 05:55:08.853741 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30749 (* 1 = 5.30749 loss)
I0524 05:55:08.854118 11654 sgd_solver.cpp:112] Iteration 39310, lr = 0.1
I0524 05:55:16.365669 11654 solver.cpp:239] Iteration 39320 (1.33127 iter/s, 7.51163s/10 iters), loss = 4.82864
I0524 05:55:16.365739 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.82864 (* 1 = 4.82864 loss)
I0524 05:55:16.365758 11654 sgd_solver.cpp:112] Iteration 39320, lr = 0.1
I0524 05:55:23.839051 11654 solver.cpp:239] Iteration 39330 (1.33816 iter/s, 7.47297s/10 iters), loss = 6.41757
I0524 05:55:23.839128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41757 (* 1 = 6.41757 loss)
I0524 05:55:23.839197 11654 sgd_solver.cpp:112] Iteration 39330, lr = 0.1
I0524 05:55:31.728503 11654 solver.cpp:239] Iteration 39340 (1.26758 iter/s, 7.88907s/10 iters), loss = 5.92683
I0524 05:55:31.728613 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92683 (* 1 = 5.92683 loss)
I0524 05:55:31.728633 11654 sgd_solver.cpp:112] Iteration 39340, lr = 0.1
I0524 05:55:38.145190 11654 solver.cpp:239] Iteration 39350 (1.55861 iter/s, 6.41597s/10 iters), loss = 6.05491
I0524 05:55:38.145231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05491 (* 1 = 6.05491 loss)
I0524 05:55:38.145246 11654 sgd_solver.cpp:112] Iteration 39350, lr = 0.1
I0524 05:55:45.235911 11654 solver.cpp:239] Iteration 39360 (1.41038 iter/s, 7.0903s/10 iters), loss = 6.75718
I0524 05:55:45.236001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75718 (* 1 = 6.75718 loss)
I0524 05:55:45.236038 11654 sgd_solver.cpp:112] Iteration 39360, lr = 0.1
I0524 05:55:54.571888 11654 solver.cpp:239] Iteration 39370 (1.07117 iter/s, 9.33555s/10 iters), loss = 5.82094
I0524 05:55:54.571961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82094 (* 1 = 5.82094 loss)
I0524 05:55:54.574012 11654 sgd_solver.cpp:112] Iteration 39370, lr = 0.1
I0524 05:56:01.404436 11654 solver.cpp:239] Iteration 39380 (1.46366 iter/s, 6.8322s/10 iters), loss = 6.12192
I0524 05:56:01.404494 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12192 (* 1 = 6.12192 loss)
I0524 05:56:01.404511 11654 sgd_solver.cpp:112] Iteration 39380, lr = 0.1
I0524 05:56:09.220530 11654 solver.cpp:239] Iteration 39390 (1.27948 iter/s, 7.8157s/10 iters), loss = 5.94341
I0524 05:56:09.220796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94341 (* 1 = 5.94341 loss)
I0524 05:56:09.220855 11654 sgd_solver.cpp:112] Iteration 39390, lr = 0.1
I0524 05:56:16.042203 11654 solver.cpp:239] Iteration 39400 (1.46603 iter/s, 6.82115s/10 iters), loss = 5.93477
I0524 05:56:16.042273 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93477 (* 1 = 5.93477 loss)
I0524 05:56:16.104938 11654 sgd_solver.cpp:112] Iteration 39400, lr = 0.1
I0524 05:56:23.755612 11654 solver.cpp:239] Iteration 39410 (1.29651 iter/s, 7.71301s/10 iters), loss = 6.9455
I0524 05:56:23.755729 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9455 (* 1 = 6.9455 loss)
I0524 05:56:23.755760 11654 sgd_solver.cpp:112] Iteration 39410, lr = 0.1
I0524 05:56:31.135614 11654 solver.cpp:239] Iteration 39420 (1.35547 iter/s, 7.3775s/10 iters), loss = 5.10849
I0524 05:56:31.135663 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.10849 (* 1 = 5.10849 loss)
I0524 05:56:32.428602 11654 sgd_solver.cpp:112] Iteration 39420, lr = 0.1
I0524 05:56:40.519948 11654 solver.cpp:239] Iteration 39430 (1.06565 iter/s, 9.38392s/10 iters), loss = 5.8875
I0524 05:56:40.520160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8875 (* 1 = 5.8875 loss)
I0524 05:56:40.520228 11654 sgd_solver.cpp:112] Iteration 39430, lr = 0.1
I0524 05:56:48.634845 11654 solver.cpp:239] Iteration 39440 (1.23237 iter/s, 8.11442s/10 iters), loss = 5.96898
I0524 05:56:48.634907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96898 (* 1 = 5.96898 loss)
I0524 05:56:48.634938 11654 sgd_solver.cpp:112] Iteration 39440, lr = 0.1
I0524 05:56:55.498579 11654 solver.cpp:239] Iteration 39450 (1.457 iter/s, 6.86342s/10 iters), loss = 6.8798
I0524 05:56:55.498626 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8798 (* 1 = 6.8798 loss)
I0524 05:56:55.498826 11654 sgd_solver.cpp:112] Iteration 39450, lr = 0.1
I0524 05:57:02.219274 11654 solver.cpp:239] Iteration 39460 (1.48802 iter/s, 6.72034s/10 iters), loss = 5.99687
I0524 05:57:02.219373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99687 (* 1 = 5.99687 loss)
I0524 05:57:02.219452 11654 sgd_solver.cpp:112] Iteration 39460, lr = 0.1
I0524 05:57:12.291095 11654 solver.cpp:239] Iteration 39470 (0.992914 iter/s, 10.0714s/10 iters), loss = 5.86438
I0524 05:57:12.291385 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86438 (* 1 = 5.86438 loss)
I0524 05:57:12.291446 11654 sgd_solver.cpp:112] Iteration 39470, lr = 0.1
I0524 05:57:19.197022 11654 solver.cpp:239] Iteration 39480 (1.44814 iter/s, 6.90541s/10 iters), loss = 7.05143
I0524 05:57:19.197088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05143 (* 1 = 7.05143 loss)
I0524 05:57:19.197285 11654 sgd_solver.cpp:112] Iteration 39480, lr = 0.1
I0524 05:57:26.844507 11654 solver.cpp:239] Iteration 39490 (1.30768 iter/s, 7.64711s/10 iters), loss = 6.24606
I0524 05:57:26.844604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24606 (* 1 = 6.24606 loss)
I0524 05:57:26.845389 11654 sgd_solver.cpp:112] Iteration 39490, lr = 0.1
I0524 05:57:34.677577 11654 solver.cpp:239] Iteration 39500 (1.27671 iter/s, 7.83266s/10 iters), loss = 5.64634
I0524 05:57:34.677641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64634 (* 1 = 5.64634 loss)
I0524 05:57:34.678148 11654 sgd_solver.cpp:112] Iteration 39500, lr = 0.1
I0524 05:57:41.852756 11654 solver.cpp:239] Iteration 39510 (1.39376 iter/s, 7.17482s/10 iters), loss = 5.19341
I0524 05:57:41.852821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.19341 (* 1 = 5.19341 loss)
I0524 05:57:41.904922 11654 sgd_solver.cpp:112] Iteration 39510, lr = 0.1
I0524 05:57:49.994463 11654 solver.cpp:239] Iteration 39520 (1.22831 iter/s, 8.1413s/10 iters), loss = 5.7486
I0524 05:57:49.994745 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.7486 (* 1 = 5.7486 loss)
I0524 05:57:49.994798 11654 sgd_solver.cpp:112] Iteration 39520, lr = 0.1
I0524 05:57:56.895915 11654 solver.cpp:239] Iteration 39530 (1.44908 iter/s, 6.90095s/10 iters), loss = 5.81271
I0524 05:57:56.896008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81271 (* 1 = 5.81271 loss)
I0524 05:57:56.896396 11654 sgd_solver.cpp:112] Iteration 39530, lr = 0.1
I0524 05:58:03.840024 11654 solver.cpp:239] Iteration 39540 (1.44014 iter/s, 6.94376s/10 iters), loss = 6.05593
I0524 05:58:03.840102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05593 (* 1 = 6.05593 loss)
I0524 05:58:03.840370 11654 sgd_solver.cpp:112] Iteration 39540, lr = 0.1
I0524 05:58:12.626857 11654 solver.cpp:239] Iteration 39550 (1.13812 iter/s, 8.78642s/10 iters), loss = 6.73305
I0524 05:58:12.626987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73305 (* 1 = 6.73305 loss)
I0524 05:58:12.627485 11654 sgd_solver.cpp:112] Iteration 39550, lr = 0.1
I0524 05:58:21.303429 11654 solver.cpp:239] Iteration 39560 (1.15258 iter/s, 8.67616s/10 iters), loss = 6.30492
I0524 05:58:21.303629 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30492 (* 1 = 6.30492 loss)
I0524 05:58:21.362051 11654 sgd_solver.cpp:112] Iteration 39560, lr = 0.1
I0524 05:58:28.341459 11654 solver.cpp:239] Iteration 39570 (1.42094 iter/s, 7.03757s/10 iters), loss = 5.30142
I0524 05:58:28.341547 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30142 (* 1 = 5.30142 loss)
I0524 05:58:28.341573 11654 sgd_solver.cpp:112] Iteration 39570, lr = 0.1
I0524 05:58:35.305042 11654 solver.cpp:239] Iteration 39580 (1.43612 iter/s, 6.96322s/10 iters), loss = 5.83143
I0524 05:58:35.305083 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83143 (* 1 = 5.83143 loss)
I0524 05:58:35.322149 11654 sgd_solver.cpp:112] Iteration 39580, lr = 0.1
I0524 05:58:43.474184 11654 solver.cpp:239] Iteration 39590 (1.22417 iter/s, 8.16878s/10 iters), loss = 6.27853
I0524 05:58:43.474253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27853 (* 1 = 6.27853 loss)
I0524 05:58:43.474272 11654 sgd_solver.cpp:112] Iteration 39590, lr = 0.1
I0524 05:58:49.639405 11654 solver.cpp:239] Iteration 39600 (1.62211 iter/s, 6.16479s/10 iters), loss = 6.4682
I0524 05:58:49.639500 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4682 (* 1 = 6.4682 loss)
I0524 05:58:49.639612 11654 sgd_solver.cpp:112] Iteration 39600, lr = 0.1
I0524 05:58:58.315739 11654 solver.cpp:239] Iteration 39610 (1.15262 iter/s, 8.6759s/10 iters), loss = 5.69714
I0524 05:58:58.316004 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69714 (* 1 = 5.69714 loss)
I0524 05:58:58.498514 11654 sgd_solver.cpp:112] Iteration 39610, lr = 0.1
I0524 05:59:05.153959 11654 solver.cpp:239] Iteration 39620 (1.46248 iter/s, 6.83771s/10 iters), loss = 7.61331
I0524 05:59:05.154011 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.61331 (* 1 = 7.61331 loss)
I0524 05:59:05.154863 11654 sgd_solver.cpp:112] Iteration 39620, lr = 0.1
I0524 05:59:16.381752 11654 solver.cpp:239] Iteration 39630 (0.890688 iter/s, 11.2273s/10 iters), loss = 6.84298
I0524 05:59:16.381824 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84298 (* 1 = 6.84298 loss)
I0524 05:59:16.647800 11654 sgd_solver.cpp:112] Iteration 39630, lr = 0.1
I0524 05:59:24.970191 11654 solver.cpp:239] Iteration 39640 (1.16441 iter/s, 8.58802s/10 iters), loss = 6.80949
I0524 05:59:24.970270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80949 (* 1 = 6.80949 loss)
I0524 05:59:25.068881 11654 sgd_solver.cpp:112] Iteration 39640, lr = 0.1
I0524 05:59:31.481631 11654 solver.cpp:239] Iteration 39650 (1.53584 iter/s, 6.51111s/10 iters), loss = 5.6106
I0524 05:59:31.481848 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6106 (* 1 = 5.6106 loss)
I0524 05:59:31.482059 11654 sgd_solver.cpp:112] Iteration 39650, lr = 0.1
I0524 05:59:39.307884 11654 solver.cpp:239] Iteration 39660 (1.27784 iter/s, 7.82573s/10 iters), loss = 7.05066
I0524 05:59:39.307946 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05066 (* 1 = 7.05066 loss)
I0524 05:59:39.307965 11654 sgd_solver.cpp:112] Iteration 39660, lr = 0.1
I0524 05:59:47.128624 11654 solver.cpp:239] Iteration 39670 (1.27872 iter/s, 7.82033s/10 iters), loss = 5.82152
I0524 05:59:47.128702 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82152 (* 1 = 5.82152 loss)
I0524 05:59:47.128723 11654 sgd_solver.cpp:112] Iteration 39670, lr = 0.1
I0524 05:59:54.503599 11654 solver.cpp:239] Iteration 39680 (1.35601 iter/s, 7.37457s/10 iters), loss = 6.36447
I0524 05:59:54.503654 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36447 (* 1 = 6.36447 loss)
I0524 05:59:54.503671 11654 sgd_solver.cpp:112] Iteration 39680, lr = 0.1
I0524 06:00:01.496206 11654 solver.cpp:239] Iteration 39690 (1.43017 iter/s, 6.9922s/10 iters), loss = 5.68325
I0524 06:00:01.496414 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68325 (* 1 = 5.68325 loss)
I0524 06:00:01.983554 11654 sgd_solver.cpp:112] Iteration 39690, lr = 0.1
I0524 06:00:10.030800 11654 solver.cpp:239] Iteration 39700 (1.17177 iter/s, 8.53408s/10 iters), loss = 6.29794
I0524 06:00:10.030858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29794 (* 1 = 6.29794 loss)
I0524 06:00:10.030884 11654 sgd_solver.cpp:112] Iteration 39700, lr = 0.1
I0524 06:00:17.582978 11654 solver.cpp:239] Iteration 39710 (1.32419 iter/s, 7.55177s/10 iters), loss = 6.57684
I0524 06:00:17.583027 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57684 (* 1 = 6.57684 loss)
I0524 06:00:17.583436 11654 sgd_solver.cpp:112] Iteration 39710, lr = 0.1
I0524 06:00:25.364737 11654 solver.cpp:239] Iteration 39720 (1.28513 iter/s, 7.78134s/10 iters), loss = 6.24086
I0524 06:00:25.364857 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24086 (* 1 = 6.24086 loss)
I0524 06:00:25.364893 11654 sgd_solver.cpp:112] Iteration 39720, lr = 0.1
I0524 06:00:32.178643 11654 solver.cpp:239] Iteration 39730 (1.46766 iter/s, 6.81355s/10 iters), loss = 6.15499
I0524 06:00:32.178889 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15499 (* 1 = 6.15499 loss)
I0524 06:00:32.179042 11654 sgd_solver.cpp:112] Iteration 39730, lr = 0.1
I0524 06:00:39.694792 11654 solver.cpp:239] Iteration 39740 (1.33056 iter/s, 7.51561s/10 iters), loss = 7.01162
I0524 06:00:39.694905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01162 (* 1 = 7.01162 loss)
I0524 06:00:41.171718 11654 sgd_solver.cpp:112] Iteration 39740, lr = 0.1
I0524 06:00:49.232564 11654 solver.cpp:239] Iteration 39750 (1.04851 iter/s, 9.53735s/10 iters), loss = 6.00014
I0524 06:00:49.232625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00014 (* 1 = 6.00014 loss)
I0524 06:00:49.232738 11654 sgd_solver.cpp:112] Iteration 39750, lr = 0.1
I0524 06:00:58.800324 11654 solver.cpp:239] Iteration 39760 (1.04523 iter/s, 9.5673s/10 iters), loss = 6.16707
I0524 06:00:58.800448 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16707 (* 1 = 6.16707 loss)
I0524 06:00:58.802256 11654 sgd_solver.cpp:112] Iteration 39760, lr = 0.1
I0524 06:01:09.466931 11654 solver.cpp:239] Iteration 39770 (0.937548 iter/s, 10.6661s/10 iters), loss = 5.16163
I0524 06:01:09.467131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.16163 (* 1 = 5.16163 loss)
I0524 06:01:09.618114 11654 sgd_solver.cpp:112] Iteration 39770, lr = 0.1
I0524 06:01:16.873467 11654 solver.cpp:239] Iteration 39780 (1.35025 iter/s, 7.40606s/10 iters), loss = 6.58752
I0524 06:01:16.873514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58752 (* 1 = 6.58752 loss)
I0524 06:01:16.873626 11654 sgd_solver.cpp:112] Iteration 39780, lr = 0.1
I0524 06:01:25.665274 11654 solver.cpp:239] Iteration 39790 (1.13747 iter/s, 8.79141s/10 iters), loss = 5.92118
I0524 06:01:25.665350 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92118 (* 1 = 5.92118 loss)
I0524 06:01:25.665369 11654 sgd_solver.cpp:112] Iteration 39790, lr = 0.1
I0524 06:01:32.626962 11654 solver.cpp:239] Iteration 39800 (1.4365 iter/s, 6.96136s/10 iters), loss = 6.54855
I0524 06:01:32.627033 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54855 (* 1 = 6.54855 loss)
I0524 06:01:33.705440 11654 sgd_solver.cpp:112] Iteration 39800, lr = 0.1
I0524 06:01:42.327879 11654 solver.cpp:239] Iteration 39810 (1.03088 iter/s, 9.70047s/10 iters), loss = 5.68753
I0524 06:01:42.328344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68753 (* 1 = 5.68753 loss)
I0524 06:01:42.328440 11654 sgd_solver.cpp:112] Iteration 39810, lr = 0.1
I0524 06:01:50.824937 11654 solver.cpp:239] Iteration 39820 (1.17723 iter/s, 8.49452s/10 iters), loss = 6.1631
I0524 06:01:50.825001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1631 (* 1 = 6.1631 loss)
I0524 06:01:50.825021 11654 sgd_solver.cpp:112] Iteration 39820, lr = 0.1
I0524 06:01:57.519263 11654 solver.cpp:239] Iteration 39830 (1.49389 iter/s, 6.69393s/10 iters), loss = 5.22571
I0524 06:01:57.519389 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.22571 (* 1 = 5.22571 loss)
I0524 06:01:57.519436 11654 sgd_solver.cpp:112] Iteration 39830, lr = 0.1
I0524 06:02:04.443964 11654 solver.cpp:239] Iteration 39840 (1.44418 iter/s, 6.92435s/10 iters), loss = 5.49165
I0524 06:02:04.444017 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49165 (* 1 = 5.49165 loss)
I0524 06:02:04.444142 11654 sgd_solver.cpp:112] Iteration 39840, lr = 0.1
I0524 06:02:11.739894 11654 solver.cpp:239] Iteration 39850 (1.37069 iter/s, 7.29558s/10 iters), loss = 7.09406
I0524 06:02:11.739987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09406 (* 1 = 7.09406 loss)
I0524 06:02:11.741649 11654 sgd_solver.cpp:112] Iteration 39850, lr = 0.1
I0524 06:02:18.616389 11654 solver.cpp:239] Iteration 39860 (1.4543 iter/s, 6.87615s/10 iters), loss = 6.04847
I0524 06:02:18.616734 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04847 (* 1 = 6.04847 loss)
I0524 06:02:19.026070 11654 sgd_solver.cpp:112] Iteration 39860, lr = 0.1
I0524 06:02:25.895364 11654 solver.cpp:239] Iteration 39870 (1.37392 iter/s, 7.27843s/10 iters), loss = 5.4632
I0524 06:02:25.895444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4632 (* 1 = 5.4632 loss)
I0524 06:02:26.934904 11654 sgd_solver.cpp:112] Iteration 39870, lr = 0.1
I0524 06:02:33.800235 11654 solver.cpp:239] Iteration 39880 (1.2651 iter/s, 7.9045s/10 iters), loss = 6.70868
I0524 06:02:33.800308 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70868 (* 1 = 6.70868 loss)
I0524 06:02:33.881108 11654 sgd_solver.cpp:112] Iteration 39880, lr = 0.1
I0524 06:02:41.181252 11654 solver.cpp:239] Iteration 39890 (1.3549 iter/s, 7.38063s/10 iters), loss = 6.09931
I0524 06:02:41.181391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09931 (* 1 = 6.09931 loss)
I0524 06:02:41.189190 11654 sgd_solver.cpp:112] Iteration 39890, lr = 0.1
I0524 06:02:47.988270 11654 solver.cpp:239] Iteration 39900 (1.46914 iter/s, 6.80668s/10 iters), loss = 6.79069
I0524 06:02:47.988329 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79069 (* 1 = 6.79069 loss)
I0524 06:02:47.988355 11654 sgd_solver.cpp:112] Iteration 39900, lr = 0.1
I0524 06:02:55.497640 11654 solver.cpp:239] Iteration 39910 (1.33173 iter/s, 7.509s/10 iters), loss = 6.26943
I0524 06:02:55.497822 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26943 (* 1 = 6.26943 loss)
I0524 06:02:55.497869 11654 sgd_solver.cpp:112] Iteration 39910, lr = 0.1
I0524 06:03:04.052983 11654 solver.cpp:239] Iteration 39920 (1.16898 iter/s, 8.55448s/10 iters), loss = 5.67381
I0524 06:03:04.053050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67381 (* 1 = 5.67381 loss)
I0524 06:03:04.053076 11654 sgd_solver.cpp:112] Iteration 39920, lr = 0.1
I0524 06:03:11.715886 11654 solver.cpp:239] Iteration 39930 (1.30506 iter/s, 7.66249s/10 iters), loss = 5.75609
I0524 06:03:11.715966 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75609 (* 1 = 5.75609 loss)
I0524 06:03:11.716243 11654 sgd_solver.cpp:112] Iteration 39930, lr = 0.1
I0524 06:03:19.288107 11654 solver.cpp:239] Iteration 39940 (1.32068 iter/s, 7.57186s/10 iters), loss = 6.08654
I0524 06:03:19.288189 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08654 (* 1 = 6.08654 loss)
I0524 06:03:19.359160 11654 sgd_solver.cpp:112] Iteration 39940, lr = 0.1
I0524 06:03:27.268141 11654 solver.cpp:239] Iteration 39950 (1.25319 iter/s, 7.97965s/10 iters), loss = 5.51015
I0524 06:03:27.268458 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51015 (* 1 = 5.51015 loss)
I0524 06:03:27.268501 11654 sgd_solver.cpp:112] Iteration 39950, lr = 0.1
I0524 06:03:35.832044 11654 solver.cpp:239] Iteration 39960 (1.16808 iter/s, 8.56109s/10 iters), loss = 5.97334
I0524 06:03:35.832152 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97334 (* 1 = 5.97334 loss)
I0524 06:03:36.343046 11654 sgd_solver.cpp:112] Iteration 39960, lr = 0.1
I0524 06:03:43.140900 11654 solver.cpp:239] Iteration 39970 (1.36827 iter/s, 7.30849s/10 iters), loss = 6.97819
I0524 06:03:43.140969 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97819 (* 1 = 6.97819 loss)
I0524 06:03:43.141113 11654 sgd_solver.cpp:112] Iteration 39970, lr = 0.1
I0524 06:03:50.539916 11654 solver.cpp:239] Iteration 39980 (1.35159 iter/s, 7.39867s/10 iters), loss = 5.61151
I0524 06:03:50.539969 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61151 (* 1 = 5.61151 loss)
I0524 06:03:50.540082 11654 sgd_solver.cpp:112] Iteration 39980, lr = 0.1
I0524 06:03:58.570027 11654 solver.cpp:239] Iteration 39990 (1.24537 iter/s, 8.02972s/10 iters), loss = 5.92257
I0524 06:03:58.570235 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92257 (* 1 = 5.92257 loss)
I0524 06:03:59.439834 11654 sgd_solver.cpp:112] Iteration 39990, lr = 0.1
I0524 06:04:05.639500 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_40000.caffemodel
I0524 06:04:05.869798 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_40000.solverstate
I0524 06:04:06.634050 11654 solver.cpp:239] Iteration 40000 (1.24016 iter/s, 8.0635s/10 iters), loss = 5.72287
I0524 06:04:06.634115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72287 (* 1 = 5.72287 loss)
I0524 06:04:06.634135 11654 sgd_solver.cpp:112] Iteration 40000, lr = 0.1
I0524 06:04:13.729089 11654 solver.cpp:239] Iteration 40010 (1.40951 iter/s, 7.09466s/10 iters), loss = 6.0742
I0524 06:04:13.729148 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0742 (* 1 = 6.0742 loss)
I0524 06:04:13.729161 11654 sgd_solver.cpp:112] Iteration 40010, lr = 0.1
I0524 06:04:20.564644 11654 solver.cpp:239] Iteration 40020 (1.46301 iter/s, 6.83523s/10 iters), loss = 6.39119
I0524 06:04:20.564702 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39119 (* 1 = 6.39119 loss)
I0524 06:04:21.662375 11654 sgd_solver.cpp:112] Iteration 40020, lr = 0.1
I0524 06:04:28.466410 11654 solver.cpp:239] Iteration 40030 (1.2656 iter/s, 7.90137s/10 iters), loss = 5.59655
I0524 06:04:28.466507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59655 (* 1 = 5.59655 loss)
I0524 06:04:29.053584 11654 sgd_solver.cpp:112] Iteration 40030, lr = 0.1
I0524 06:04:37.987843 11654 solver.cpp:239] Iteration 40040 (1.05031 iter/s, 9.52098s/10 iters), loss = 6.49129
I0524 06:04:37.987908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49129 (* 1 = 6.49129 loss)
I0524 06:04:37.987924 11654 sgd_solver.cpp:112] Iteration 40040, lr = 0.1
I0524 06:04:47.465536 11654 solver.cpp:239] Iteration 40050 (1.05515 iter/s, 9.47728s/10 iters), loss = 7.24831
I0524 06:04:47.465579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24831 (* 1 = 7.24831 loss)
I0524 06:04:47.465610 11654 sgd_solver.cpp:112] Iteration 40050, lr = 0.1
I0524 06:04:54.337096 11654 solver.cpp:239] Iteration 40060 (1.45535 iter/s, 6.87122s/10 iters), loss = 6.49941
I0524 06:04:54.337177 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49941 (* 1 = 6.49941 loss)
I0524 06:04:54.337496 11654 sgd_solver.cpp:112] Iteration 40060, lr = 0.1
I0524 06:05:00.900866 11654 solver.cpp:239] Iteration 40070 (1.52359 iter/s, 6.56343s/10 iters), loss = 6.88904
I0524 06:05:00.901113 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88904 (* 1 = 6.88904 loss)
I0524 06:05:00.907359 11654 sgd_solver.cpp:112] Iteration 40070, lr = 0.1
I0524 06:05:07.508625 11654 solver.cpp:239] Iteration 40080 (1.51349 iter/s, 6.60724s/10 iters), loss = 5.35097
I0524 06:05:07.508739 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.35097 (* 1 = 5.35097 loss)
I0524 06:05:08.551288 11654 sgd_solver.cpp:112] Iteration 40080, lr = 0.1
I0524 06:05:16.425024 11654 solver.cpp:239] Iteration 40090 (1.12159 iter/s, 8.91595s/10 iters), loss = 5.66309
I0524 06:05:16.425092 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66309 (* 1 = 5.66309 loss)
I0524 06:05:17.410647 11654 sgd_solver.cpp:112] Iteration 40090, lr = 0.1
I0524 06:05:26.021857 11654 solver.cpp:239] Iteration 40100 (1.04206 iter/s, 9.5964s/10 iters), loss = 5.92494
I0524 06:05:26.021927 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92494 (* 1 = 5.92494 loss)
I0524 06:05:26.361217 11654 sgd_solver.cpp:112] Iteration 40100, lr = 0.1
I0524 06:05:35.813309 11654 solver.cpp:239] Iteration 40110 (1.02134 iter/s, 9.79102s/10 iters), loss = 6.86116
I0524 06:05:35.813472 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86116 (* 1 = 6.86116 loss)
I0524 06:05:35.813509 11654 sgd_solver.cpp:112] Iteration 40110, lr = 0.1
I0524 06:05:44.062602 11654 solver.cpp:239] Iteration 40120 (1.2123 iter/s, 8.24877s/10 iters), loss = 6.50788
I0524 06:05:44.062687 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50788 (* 1 = 6.50788 loss)
I0524 06:05:44.062773 11654 sgd_solver.cpp:112] Iteration 40120, lr = 0.1
I0524 06:05:54.017091 11654 solver.cpp:239] Iteration 40130 (1.00462 iter/s, 9.95405s/10 iters), loss = 6.50778
I0524 06:05:54.017130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50778 (* 1 = 6.50778 loss)
I0524 06:05:54.017143 11654 sgd_solver.cpp:112] Iteration 40130, lr = 0.1
I0524 06:06:01.036394 11654 solver.cpp:239] Iteration 40140 (1.42472 iter/s, 7.01891s/10 iters), loss = 7.5677
I0524 06:06:01.036458 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.5677 (* 1 = 7.5677 loss)
I0524 06:06:01.036476 11654 sgd_solver.cpp:112] Iteration 40140, lr = 0.1
I0524 06:06:09.131122 11654 solver.cpp:239] Iteration 40150 (1.23544 iter/s, 8.09429s/10 iters), loss = 6.39461
I0524 06:06:09.131448 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39461 (* 1 = 6.39461 loss)
I0524 06:06:09.797508 11654 sgd_solver.cpp:112] Iteration 40150, lr = 0.1
I0524 06:06:17.545898 11654 solver.cpp:239] Iteration 40160 (1.18846 iter/s, 8.41427s/10 iters), loss = 5.18105
I0524 06:06:17.545939 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.18105 (* 1 = 5.18105 loss)
I0524 06:06:17.545955 11654 sgd_solver.cpp:112] Iteration 40160, lr = 0.1
I0524 06:06:25.606474 11654 solver.cpp:239] Iteration 40170 (1.24068 iter/s, 8.0601s/10 iters), loss = 6.69394
I0524 06:06:25.606570 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69394 (* 1 = 6.69394 loss)
I0524 06:06:25.606614 11654 sgd_solver.cpp:112] Iteration 40170, lr = 0.1
I0524 06:06:32.648887 11654 solver.cpp:239] Iteration 40180 (1.42046 iter/s, 7.03998s/10 iters), loss = 6.10415
I0524 06:06:32.648936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10415 (* 1 = 6.10415 loss)
I0524 06:06:32.649507 11654 sgd_solver.cpp:112] Iteration 40180, lr = 0.1
I0524 06:06:39.733902 11654 solver.cpp:239] Iteration 40190 (1.4115 iter/s, 7.08467s/10 iters), loss = 6.07501
I0524 06:06:39.734195 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07501 (* 1 = 6.07501 loss)
I0524 06:06:39.734248 11654 sgd_solver.cpp:112] Iteration 40190, lr = 0.1
I0524 06:06:47.782965 11654 solver.cpp:239] Iteration 40200 (1.24247 iter/s, 8.0485s/10 iters), loss = 6.58117
I0524 06:06:47.783022 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58117 (* 1 = 6.58117 loss)
I0524 06:06:47.783304 11654 sgd_solver.cpp:112] Iteration 40200, lr = 0.1
I0524 06:06:55.215905 11654 solver.cpp:239] Iteration 40210 (1.34543 iter/s, 7.43259s/10 iters), loss = 6.42991
I0524 06:06:55.215998 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42991 (* 1 = 6.42991 loss)
I0524 06:06:55.216091 11654 sgd_solver.cpp:112] Iteration 40210, lr = 0.1
I0524 06:07:02.558226 11654 solver.cpp:239] Iteration 40220 (1.36203 iter/s, 7.34197s/10 iters), loss = 5.82597
I0524 06:07:02.558307 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82597 (* 1 = 5.82597 loss)
I0524 06:07:02.558331 11654 sgd_solver.cpp:112] Iteration 40220, lr = 0.1
I0524 06:07:10.450912 11654 solver.cpp:239] Iteration 40230 (1.26706 iter/s, 7.89228s/10 iters), loss = 4.59062
I0524 06:07:10.451107 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.59062 (* 1 = 4.59062 loss)
I0524 06:07:10.453006 11654 sgd_solver.cpp:112] Iteration 40230, lr = 0.1
I0524 06:07:18.185297 11654 solver.cpp:239] Iteration 40240 (1.29302 iter/s, 7.73386s/10 iters), loss = 6.93866
I0524 06:07:18.185401 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93866 (* 1 = 6.93866 loss)
I0524 06:07:18.544227 11654 sgd_solver.cpp:112] Iteration 40240, lr = 0.1
I0524 06:07:24.948309 11654 solver.cpp:239] Iteration 40250 (1.47871 iter/s, 6.76267s/10 iters), loss = 6.14084
I0524 06:07:24.948375 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14084 (* 1 = 6.14084 loss)
I0524 06:07:24.948393 11654 sgd_solver.cpp:112] Iteration 40250, lr = 0.1
I0524 06:07:33.400982 11654 solver.cpp:239] Iteration 40260 (1.18311 iter/s, 8.45229s/10 iters), loss = 5.59692
I0524 06:07:33.401026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59692 (* 1 = 5.59692 loss)
I0524 06:07:33.405547 11654 sgd_solver.cpp:112] Iteration 40260, lr = 0.1
I0524 06:07:40.426740 11654 solver.cpp:239] Iteration 40270 (1.4234 iter/s, 7.02542s/10 iters), loss = 6.23044
I0524 06:07:40.426832 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23044 (* 1 = 6.23044 loss)
I0524 06:07:40.426856 11654 sgd_solver.cpp:112] Iteration 40270, lr = 0.1
I0524 06:07:50.259781 11654 solver.cpp:239] Iteration 40280 (1.01703 iter/s, 9.83252s/10 iters), loss = 6.27279
I0524 06:07:50.260030 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27279 (* 1 = 6.27279 loss)
I0524 06:07:50.260097 11654 sgd_solver.cpp:112] Iteration 40280, lr = 0.1
I0524 06:07:57.046892 11654 solver.cpp:239] Iteration 40290 (1.47369 iter/s, 6.7857s/10 iters), loss = 6.69713
I0524 06:07:57.046980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69713 (* 1 = 6.69713 loss)
I0524 06:07:57.047456 11654 sgd_solver.cpp:112] Iteration 40290, lr = 0.1
I0524 06:08:04.455193 11654 solver.cpp:239] Iteration 40300 (1.3499 iter/s, 7.40793s/10 iters), loss = 4.65532
I0524 06:08:04.455312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.65532 (* 1 = 4.65532 loss)
I0524 06:08:04.455343 11654 sgd_solver.cpp:112] Iteration 40300, lr = 0.1
I0524 06:08:12.703954 11654 solver.cpp:239] Iteration 40310 (1.21236 iter/s, 8.24834s/10 iters), loss = 5.22384
I0524 06:08:12.704021 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.22384 (* 1 = 5.22384 loss)
I0524 06:08:12.704038 11654 sgd_solver.cpp:112] Iteration 40310, lr = 0.1
I0524 06:08:20.289183 11654 solver.cpp:239] Iteration 40320 (1.31842 iter/s, 7.58483s/10 iters), loss = 5.45489
I0524 06:08:20.289408 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.45489 (* 1 = 5.45489 loss)
I0524 06:08:20.289471 11654 sgd_solver.cpp:112] Iteration 40320, lr = 0.1
I0524 06:08:26.496933 11654 solver.cpp:239] Iteration 40330 (1.61155 iter/s, 6.20519s/10 iters), loss = 5.93009
I0524 06:08:26.497015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93009 (* 1 = 5.93009 loss)
I0524 06:08:26.497195 11654 sgd_solver.cpp:112] Iteration 40330, lr = 0.1
I0524 06:08:36.572209 11654 solver.cpp:239] Iteration 40340 (0.992573 iter/s, 10.0748s/10 iters), loss = 6.52404
I0524 06:08:36.572269 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52404 (* 1 = 6.52404 loss)
I0524 06:08:36.867842 11654 sgd_solver.cpp:112] Iteration 40340, lr = 0.1
I0524 06:08:45.990954 11654 solver.cpp:239] Iteration 40350 (1.06176 iter/s, 9.41829s/10 iters), loss = 6.7106
I0524 06:08:45.991084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7106 (* 1 = 6.7106 loss)
I0524 06:08:45.991246 11654 sgd_solver.cpp:112] Iteration 40350, lr = 0.1
I0524 06:08:52.204005 11654 solver.cpp:239] Iteration 40360 (1.60961 iter/s, 6.2127s/10 iters), loss = 7.75165
I0524 06:08:52.204161 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.75165 (* 1 = 7.75165 loss)
I0524 06:08:52.204185 11654 sgd_solver.cpp:112] Iteration 40360, lr = 0.1
I0524 06:08:59.750917 11654 solver.cpp:239] Iteration 40370 (1.32528 iter/s, 7.5456s/10 iters), loss = 6.56418
I0524 06:08:59.750972 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56418 (* 1 = 6.56418 loss)
I0524 06:08:59.754837 11654 sgd_solver.cpp:112] Iteration 40370, lr = 0.1
I0524 06:09:06.203325 11654 solver.cpp:239] Iteration 40380 (1.54989 iter/s, 6.45208s/10 iters), loss = 6.73835
I0524 06:09:06.203425 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73835 (* 1 = 6.73835 loss)
I0524 06:09:06.203449 11654 sgd_solver.cpp:112] Iteration 40380, lr = 0.1
I0524 06:09:13.235536 11654 solver.cpp:239] Iteration 40390 (1.4221 iter/s, 7.03186s/10 iters), loss = 5.06244
I0524 06:09:13.235608 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.06244 (* 1 = 5.06244 loss)
I0524 06:09:13.908135 11654 sgd_solver.cpp:112] Iteration 40390, lr = 0.1
I0524 06:09:21.016602 11654 solver.cpp:239] Iteration 40400 (1.28523 iter/s, 7.78072s/10 iters), loss = 7.17411
I0524 06:09:21.016654 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17411 (* 1 = 7.17411 loss)
I0524 06:09:21.387614 11654 sgd_solver.cpp:112] Iteration 40400, lr = 0.1
I0524 06:09:28.364390 11654 solver.cpp:239] Iteration 40410 (1.36102 iter/s, 7.34745s/10 iters), loss = 6.03261
I0524 06:09:28.364593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03261 (* 1 = 6.03261 loss)
I0524 06:09:28.364881 11654 sgd_solver.cpp:112] Iteration 40410, lr = 0.1
I0524 06:09:37.711422 11654 solver.cpp:239] Iteration 40420 (1.06992 iter/s, 9.34648s/10 iters), loss = 5.28423
I0524 06:09:37.711475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28423 (* 1 = 5.28423 loss)
I0524 06:09:37.711504 11654 sgd_solver.cpp:112] Iteration 40420, lr = 0.1
I0524 06:09:44.711889 11654 solver.cpp:239] Iteration 40430 (1.42854 iter/s, 7.00014s/10 iters), loss = 5.30518
I0524 06:09:44.711935 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30518 (* 1 = 5.30518 loss)
I0524 06:09:44.757881 11654 sgd_solver.cpp:112] Iteration 40430, lr = 0.1
I0524 06:09:52.396253 11654 solver.cpp:239] Iteration 40440 (1.30141 iter/s, 7.68399s/10 iters), loss = 6.09806
I0524 06:09:52.396340 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09806 (* 1 = 6.09806 loss)
I0524 06:09:52.396360 11654 sgd_solver.cpp:112] Iteration 40440, lr = 0.1
I0524 06:09:58.665071 11654 solver.cpp:239] Iteration 40450 (1.5953 iter/s, 6.26842s/10 iters), loss = 6.4957
I0524 06:09:58.665307 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4957 (* 1 = 6.4957 loss)
I0524 06:09:59.599630 11654 sgd_solver.cpp:112] Iteration 40450, lr = 0.1
I0524 06:10:06.344890 11654 solver.cpp:239] Iteration 40460 (1.3022 iter/s, 7.67929s/10 iters), loss = 6.96417
I0524 06:10:06.344959 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96417 (* 1 = 6.96417 loss)
I0524 06:10:06.345048 11654 sgd_solver.cpp:112] Iteration 40460, lr = 0.1
I0524 06:10:13.750285 11654 solver.cpp:239] Iteration 40470 (1.35043 iter/s, 7.40503s/10 iters), loss = 5.76033
I0524 06:10:13.750372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76033 (* 1 = 5.76033 loss)
I0524 06:10:13.750877 11654 sgd_solver.cpp:112] Iteration 40470, lr = 0.1
I0524 06:10:20.560698 11654 solver.cpp:239] Iteration 40480 (1.46841 iter/s, 6.81008s/10 iters), loss = 7.46778
I0524 06:10:20.560762 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.46778 (* 1 = 7.46778 loss)
I0524 06:10:20.566936 11654 sgd_solver.cpp:112] Iteration 40480, lr = 0.1
I0524 06:10:28.111186 11654 solver.cpp:239] Iteration 40490 (1.32448 iter/s, 7.55012s/10 iters), loss = 4.94188
I0524 06:10:28.111277 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.94188 (* 1 = 4.94188 loss)
I0524 06:10:28.941537 11654 sgd_solver.cpp:112] Iteration 40490, lr = 0.1
I0524 06:10:36.728299 11654 solver.cpp:239] Iteration 40500 (1.16054 iter/s, 8.6167s/10 iters), loss = 6.18157
I0524 06:10:36.728348 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18157 (* 1 = 6.18157 loss)
I0524 06:10:36.728363 11654 sgd_solver.cpp:112] Iteration 40500, lr = 0.1
I0524 06:10:43.302981 11654 solver.cpp:239] Iteration 40510 (1.52107 iter/s, 6.57432s/10 iters), loss = 6.43264
I0524 06:10:43.303037 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43264 (* 1 = 6.43264 loss)
I0524 06:10:43.307875 11654 sgd_solver.cpp:112] Iteration 40510, lr = 0.1
I0524 06:10:50.637533 11654 solver.cpp:239] Iteration 40520 (1.36347 iter/s, 7.33422s/10 iters), loss = 7.27301
I0524 06:10:50.637575 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27301 (* 1 = 7.27301 loss)
I0524 06:10:50.637589 11654 sgd_solver.cpp:112] Iteration 40520, lr = 0.1
I0524 06:10:58.370120 11654 solver.cpp:239] Iteration 40530 (1.29329 iter/s, 7.73223s/10 iters), loss = 7.15591
I0524 06:10:58.370190 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.15591 (* 1 = 7.15591 loss)
I0524 06:10:58.370206 11654 sgd_solver.cpp:112] Iteration 40530, lr = 0.1
I0524 06:11:08.564252 11654 solver.cpp:239] Iteration 40540 (0.981011 iter/s, 10.1936s/10 iters), loss = 6.8174
I0524 06:11:08.564471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8174 (* 1 = 6.8174 loss)
I0524 06:11:08.614470 11654 sgd_solver.cpp:112] Iteration 40540, lr = 0.1
I0524 06:11:17.522348 11654 solver.cpp:239] Iteration 40550 (1.11638 iter/s, 8.95756s/10 iters), loss = 6.40416
I0524 06:11:17.522403 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40416 (* 1 = 6.40416 loss)
I0524 06:11:17.522429 11654 sgd_solver.cpp:112] Iteration 40550, lr = 0.1
I0524 06:11:24.843233 11654 solver.cpp:239] Iteration 40560 (1.36603 iter/s, 7.32048s/10 iters), loss = 6.65158
I0524 06:11:24.843281 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65158 (* 1 = 6.65158 loss)
I0524 06:11:24.843494 11654 sgd_solver.cpp:112] Iteration 40560, lr = 0.1
I0524 06:11:31.742002 11654 solver.cpp:239] Iteration 40570 (1.4496 iter/s, 6.89845s/10 iters), loss = 7.13315
I0524 06:11:31.742066 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13315 (* 1 = 7.13315 loss)
I0524 06:11:31.742082 11654 sgd_solver.cpp:112] Iteration 40570, lr = 0.1
I0524 06:11:38.255086 11654 solver.cpp:239] Iteration 40580 (1.53545 iter/s, 6.51277s/10 iters), loss = 6.00227
I0524 06:11:38.255163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00227 (* 1 = 6.00227 loss)
I0524 06:11:38.384001 11654 sgd_solver.cpp:112] Iteration 40580, lr = 0.1
I0524 06:11:47.270184 11654 solver.cpp:239] Iteration 40590 (1.1093 iter/s, 9.01468s/10 iters), loss = 5.53261
I0524 06:11:47.270457 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53261 (* 1 = 5.53261 loss)
I0524 06:11:47.311534 11654 sgd_solver.cpp:112] Iteration 40590, lr = 0.1
I0524 06:11:54.097396 11654 solver.cpp:239] Iteration 40600 (1.46483 iter/s, 6.82673s/10 iters), loss = 6.27817
I0524 06:11:54.097437 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27817 (* 1 = 6.27817 loss)
I0524 06:11:55.137631 11654 sgd_solver.cpp:112] Iteration 40600, lr = 0.1
I0524 06:12:02.458732 11654 solver.cpp:239] Iteration 40610 (1.19604 iter/s, 8.36096s/10 iters), loss = 5.12593
I0524 06:12:02.458793 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.12593 (* 1 = 5.12593 loss)
I0524 06:12:02.458811 11654 sgd_solver.cpp:112] Iteration 40610, lr = 0.1
I0524 06:12:09.541072 11654 solver.cpp:239] Iteration 40620 (1.41205 iter/s, 7.08188s/10 iters), loss = 5.7935
I0524 06:12:09.541151 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.7935 (* 1 = 5.7935 loss)
I0524 06:12:09.541173 11654 sgd_solver.cpp:112] Iteration 40620, lr = 0.1
I0524 06:12:16.069165 11654 solver.cpp:239] Iteration 40630 (1.53193 iter/s, 6.52772s/10 iters), loss = 5.89883
I0524 06:12:16.069250 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89883 (* 1 = 5.89883 loss)
I0524 06:12:16.069325 11654 sgd_solver.cpp:112] Iteration 40630, lr = 0.1
I0524 06:12:23.909221 11654 solver.cpp:239] Iteration 40640 (1.27556 iter/s, 7.83968s/10 iters), loss = 5.79422
I0524 06:12:23.909459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79422 (* 1 = 5.79422 loss)
I0524 06:12:24.171983 11654 sgd_solver.cpp:112] Iteration 40640, lr = 0.1
I0524 06:12:31.685318 11654 solver.cpp:239] Iteration 40650 (1.28609 iter/s, 7.77552s/10 iters), loss = 5.72874
I0524 06:12:31.685487 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72874 (* 1 = 5.72874 loss)
I0524 06:12:31.685596 11654 sgd_solver.cpp:112] Iteration 40650, lr = 0.1
I0524 06:12:38.780063 11654 solver.cpp:239] Iteration 40660 (1.40956 iter/s, 7.09439s/10 iters), loss = 6.3384
I0524 06:12:38.780123 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3384 (* 1 = 6.3384 loss)
I0524 06:12:39.054533 11654 sgd_solver.cpp:112] Iteration 40660, lr = 0.1
I0524 06:12:45.869381 11654 solver.cpp:239] Iteration 40670 (1.41066 iter/s, 7.08887s/10 iters), loss = 5.63654
I0524 06:12:45.869580 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63654 (* 1 = 5.63654 loss)
I0524 06:12:45.869823 11654 sgd_solver.cpp:112] Iteration 40670, lr = 0.1
I0524 06:12:53.398191 11654 solver.cpp:239] Iteration 40680 (1.3283 iter/s, 7.5284s/10 iters), loss = 7.05397
I0524 06:12:53.398257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05397 (* 1 = 7.05397 loss)
I0524 06:12:53.398273 11654 sgd_solver.cpp:112] Iteration 40680, lr = 0.1
I0524 06:13:00.084229 11654 solver.cpp:239] Iteration 40690 (1.49574 iter/s, 6.68565s/10 iters), loss = 5.96495
I0524 06:13:00.084439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96495 (* 1 = 5.96495 loss)
I0524 06:13:00.855764 11654 sgd_solver.cpp:112] Iteration 40690, lr = 0.1
I0524 06:13:08.618751 11654 solver.cpp:239] Iteration 40700 (1.17179 iter/s, 8.53394s/10 iters), loss = 6.91605
I0524 06:13:08.618821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91605 (* 1 = 6.91605 loss)
I0524 06:13:08.661319 11654 sgd_solver.cpp:112] Iteration 40700, lr = 0.1
I0524 06:13:17.919984 11654 solver.cpp:239] Iteration 40710 (1.07518 iter/s, 9.30081s/10 iters), loss = 6.02836
I0524 06:13:17.920039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02836 (* 1 = 6.02836 loss)
I0524 06:13:18.598557 11654 sgd_solver.cpp:112] Iteration 40710, lr = 0.1
I0524 06:13:26.181721 11654 solver.cpp:239] Iteration 40720 (1.21046 iter/s, 8.26136s/10 iters), loss = 5.70293
I0524 06:13:26.181823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70293 (* 1 = 5.70293 loss)
I0524 06:13:26.181869 11654 sgd_solver.cpp:112] Iteration 40720, lr = 0.1
I0524 06:13:34.486495 11654 solver.cpp:239] Iteration 40730 (1.20419 iter/s, 8.30437s/10 iters), loss = 5.47647
I0524 06:13:34.486730 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47647 (* 1 = 5.47647 loss)
I0524 06:13:34.486752 11654 sgd_solver.cpp:112] Iteration 40730, lr = 0.1
I0524 06:13:40.985759 11654 solver.cpp:239] Iteration 40740 (1.53874 iter/s, 6.49881s/10 iters), loss = 4.97437
I0524 06:13:40.985801 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.97437 (* 1 = 4.97437 loss)
I0524 06:13:41.748704 11654 sgd_solver.cpp:112] Iteration 40740, lr = 0.1
I0524 06:13:49.900310 11654 solver.cpp:239] Iteration 40750 (1.12181 iter/s, 8.91416s/10 iters), loss = 5.60989
I0524 06:13:49.900369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60989 (* 1 = 5.60989 loss)
I0524 06:13:50.138916 11654 sgd_solver.cpp:112] Iteration 40750, lr = 0.1
I0524 06:13:59.019084 11654 solver.cpp:239] Iteration 40760 (1.09669 iter/s, 9.11836s/10 iters), loss = 6.17762
I0524 06:13:59.019160 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17762 (* 1 = 6.17762 loss)
I0524 06:13:59.019184 11654 sgd_solver.cpp:112] Iteration 40760, lr = 0.1
I0524 06:14:08.388025 11654 solver.cpp:239] Iteration 40770 (1.06743 iter/s, 9.36825s/10 iters), loss = 6.33821
I0524 06:14:08.388242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33821 (* 1 = 6.33821 loss)
I0524 06:14:08.388545 11654 sgd_solver.cpp:112] Iteration 40770, lr = 0.1
I0524 06:14:17.056587 11654 solver.cpp:239] Iteration 40780 (1.15367 iter/s, 8.66799s/10 iters), loss = 5.25558
I0524 06:14:17.056676 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.25558 (* 1 = 5.25558 loss)
I0524 06:14:17.057148 11654 sgd_solver.cpp:112] Iteration 40780, lr = 0.1
I0524 06:14:26.255149 11654 solver.cpp:239] Iteration 40790 (1.08718 iter/s, 9.19811s/10 iters), loss = 5.50143
I0524 06:14:26.255252 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50143 (* 1 = 5.50143 loss)
I0524 06:14:26.255363 11654 sgd_solver.cpp:112] Iteration 40790, lr = 0.1
I0524 06:14:33.671885 11654 solver.cpp:239] Iteration 40800 (1.34837 iter/s, 7.41637s/10 iters), loss = 5.34975
I0524 06:14:33.672008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.34975 (* 1 = 5.34975 loss)
I0524 06:14:34.603508 11654 sgd_solver.cpp:112] Iteration 40800, lr = 0.1
I0524 06:14:42.488934 11654 solver.cpp:239] Iteration 40810 (1.13422 iter/s, 8.81664s/10 iters), loss = 5.99357
I0524 06:14:42.489215 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99357 (* 1 = 5.99357 loss)
I0524 06:14:42.489275 11654 sgd_solver.cpp:112] Iteration 40810, lr = 0.1
I0524 06:14:50.435124 11654 solver.cpp:239] Iteration 40820 (1.25889 iter/s, 7.94352s/10 iters), loss = 6.59991
I0524 06:14:50.435217 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59991 (* 1 = 6.59991 loss)
I0524 06:14:50.435237 11654 sgd_solver.cpp:112] Iteration 40820, lr = 0.1
I0524 06:14:57.043179 11654 solver.cpp:239] Iteration 40830 (1.51339 iter/s, 6.60767s/10 iters), loss = 6.74911
I0524 06:14:57.043272 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74911 (* 1 = 6.74911 loss)
I0524 06:14:57.043469 11654 sgd_solver.cpp:112] Iteration 40830, lr = 0.1
I0524 06:15:06.527351 11654 solver.cpp:239] Iteration 40840 (1.05444 iter/s, 9.48373s/10 iters), loss = 6.16074
I0524 06:15:06.527427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16074 (* 1 = 6.16074 loss)
I0524 06:15:06.527456 11654 sgd_solver.cpp:112] Iteration 40840, lr = 0.1
I0524 06:15:13.983747 11654 solver.cpp:239] Iteration 40850 (1.3412 iter/s, 7.45602s/10 iters), loss = 6.47369
I0524 06:15:13.983938 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47369 (* 1 = 6.47369 loss)
I0524 06:15:13.983966 11654 sgd_solver.cpp:112] Iteration 40850, lr = 0.1
I0524 06:15:21.105325 11654 solver.cpp:239] Iteration 40860 (1.40468 iter/s, 7.11905s/10 iters), loss = 5.73583
I0524 06:15:21.105376 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73583 (* 1 = 5.73583 loss)
I0524 06:15:21.105933 11654 sgd_solver.cpp:112] Iteration 40860, lr = 0.1
I0524 06:15:28.820787 11654 solver.cpp:239] Iteration 40870 (1.29616 iter/s, 7.7151s/10 iters), loss = 5.92909
I0524 06:15:28.820878 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92909 (* 1 = 5.92909 loss)
I0524 06:15:29.629092 11654 sgd_solver.cpp:112] Iteration 40870, lr = 0.1
I0524 06:15:35.851379 11654 solver.cpp:239] Iteration 40880 (1.42242 iter/s, 7.03026s/10 iters), loss = 5.70782
I0524 06:15:35.851423 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70782 (* 1 = 5.70782 loss)
I0524 06:15:35.851438 11654 sgd_solver.cpp:112] Iteration 40880, lr = 0.1
I0524 06:15:42.630501 11654 solver.cpp:239] Iteration 40890 (1.47522 iter/s, 6.77866s/10 iters), loss = 6.05106
I0524 06:15:42.630576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05106 (* 1 = 6.05106 loss)
I0524 06:15:42.963548 11654 sgd_solver.cpp:112] Iteration 40890, lr = 0.1
I0524 06:15:51.954208 11654 solver.cpp:239] Iteration 40900 (1.07259 iter/s, 9.32327s/10 iters), loss = 6.04704
I0524 06:15:51.954459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04704 (* 1 = 6.04704 loss)
I0524 06:15:52.123472 11654 sgd_solver.cpp:112] Iteration 40900, lr = 0.1
I0524 06:15:58.801904 11654 solver.cpp:239] Iteration 40910 (1.46045 iter/s, 6.84719s/10 iters), loss = 5.62833
I0524 06:15:58.801970 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62833 (* 1 = 5.62833 loss)
I0524 06:15:58.801986 11654 sgd_solver.cpp:112] Iteration 40910, lr = 0.1
I0524 06:16:05.771025 11654 solver.cpp:239] Iteration 40920 (1.43498 iter/s, 6.96876s/10 iters), loss = 5.49645
I0524 06:16:05.771092 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49645 (* 1 = 5.49645 loss)
I0524 06:16:06.406328 11654 sgd_solver.cpp:112] Iteration 40920, lr = 0.1
I0524 06:16:16.067320 11654 solver.cpp:239] Iteration 40930 (0.971267 iter/s, 10.2958s/10 iters), loss = 6.1932
I0524 06:16:16.067386 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1932 (* 1 = 6.1932 loss)
I0524 06:16:17.478055 11654 sgd_solver.cpp:112] Iteration 40930, lr = 0.1
I0524 06:16:25.318485 11654 solver.cpp:239] Iteration 40940 (1.08099 iter/s, 9.25074s/10 iters), loss = 5.80763
I0524 06:16:25.318639 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80763 (* 1 = 5.80763 loss)
I0524 06:16:25.346133 11654 sgd_solver.cpp:112] Iteration 40940, lr = 0.1
I0524 06:16:35.555454 11654 solver.cpp:239] Iteration 40950 (0.976904 iter/s, 10.2364s/10 iters), loss = 6.66219
I0524 06:16:35.555516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66219 (* 1 = 6.66219 loss)
I0524 06:16:35.560968 11654 sgd_solver.cpp:112] Iteration 40950, lr = 0.1
I0524 06:16:43.478435 11654 solver.cpp:239] Iteration 40960 (1.26221 iter/s, 7.92261s/10 iters), loss = 6.6789
I0524 06:16:43.478493 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6789 (* 1 = 6.6789 loss)
I0524 06:16:44.379024 11654 sgd_solver.cpp:112] Iteration 40960, lr = 0.1
I0524 06:16:51.254287 11654 solver.cpp:239] Iteration 40970 (1.28609 iter/s, 7.77549s/10 iters), loss = 6.37409
I0524 06:16:51.254374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37409 (* 1 = 6.37409 loss)
I0524 06:16:51.254621 11654 sgd_solver.cpp:112] Iteration 40970, lr = 0.1
I0524 06:17:00.409483 11654 solver.cpp:239] Iteration 40980 (1.09233 iter/s, 9.15478s/10 iters), loss = 5.9342
I0524 06:17:00.409660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9342 (* 1 = 5.9342 loss)
I0524 06:17:00.409771 11654 sgd_solver.cpp:112] Iteration 40980, lr = 0.1
I0524 06:17:06.879879 11654 solver.cpp:239] Iteration 40990 (1.5456 iter/s, 6.46998s/10 iters), loss = 6.12944
I0524 06:17:06.879957 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12944 (* 1 = 6.12944 loss)
I0524 06:17:06.880091 11654 sgd_solver.cpp:112] Iteration 40990, lr = 0.1
I0524 06:17:13.329044 11654 solver.cpp:239] Iteration 41000 (1.55066 iter/s, 6.44885s/10 iters), loss = 7.33258
I0524 06:17:13.329120 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.33258 (* 1 = 7.33258 loss)
I0524 06:17:13.329216 11654 sgd_solver.cpp:112] Iteration 41000, lr = 0.1
I0524 06:17:20.459089 11654 solver.cpp:239] Iteration 41010 (1.40258 iter/s, 7.1297s/10 iters), loss = 5.64012
I0524 06:17:20.459138 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64012 (* 1 = 5.64012 loss)
I0524 06:17:21.266772 11654 sgd_solver.cpp:112] Iteration 41010, lr = 0.1
I0524 06:17:28.469986 11654 solver.cpp:239] Iteration 41020 (1.24836 iter/s, 8.01054s/10 iters), loss = 6.39977
I0524 06:17:28.470041 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39977 (* 1 = 6.39977 loss)
I0524 06:17:28.470228 11654 sgd_solver.cpp:112] Iteration 41020, lr = 0.1
I0524 06:17:36.557915 11654 solver.cpp:239] Iteration 41030 (1.23647 iter/s, 8.08755s/10 iters), loss = 7.24069
I0524 06:17:36.558228 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.24069 (* 1 = 7.24069 loss)
I0524 06:17:36.570045 11654 sgd_solver.cpp:112] Iteration 41030, lr = 0.1
I0524 06:17:43.223258 11654 solver.cpp:239] Iteration 41040 (1.50042 iter/s, 6.6648s/10 iters), loss = 5.98077
I0524 06:17:43.223312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98077 (* 1 = 5.98077 loss)
I0524 06:17:43.223337 11654 sgd_solver.cpp:112] Iteration 41040, lr = 0.1
I0524 06:17:50.646230 11654 solver.cpp:239] Iteration 41050 (1.34723 iter/s, 7.42263s/10 iters), loss = 6.11463
I0524 06:17:50.646292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11463 (* 1 = 6.11463 loss)
I0524 06:17:50.646308 11654 sgd_solver.cpp:112] Iteration 41050, lr = 0.1
I0524 06:17:57.286620 11654 solver.cpp:239] Iteration 41060 (1.50644 iter/s, 6.63819s/10 iters), loss = 6.79815
I0524 06:17:57.286712 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79815 (* 1 = 6.79815 loss)
I0524 06:17:57.286746 11654 sgd_solver.cpp:112] Iteration 41060, lr = 0.1
I0524 06:18:04.931815 11654 solver.cpp:239] Iteration 41070 (1.3081 iter/s, 7.64466s/10 iters), loss = 7.26695
I0524 06:18:04.931948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26695 (* 1 = 7.26695 loss)
I0524 06:18:04.932004 11654 sgd_solver.cpp:112] Iteration 41070, lr = 0.1
I0524 06:18:11.786674 11654 solver.cpp:239] Iteration 41080 (1.45891 iter/s, 6.85445s/10 iters), loss = 6.84101
I0524 06:18:11.787019 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84101 (* 1 = 6.84101 loss)
I0524 06:18:11.787077 11654 sgd_solver.cpp:112] Iteration 41080, lr = 0.1
I0524 06:18:18.823799 11654 solver.cpp:239] Iteration 41090 (1.42122 iter/s, 7.03623s/10 iters), loss = 5.38391
I0524 06:18:18.823894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.38391 (* 1 = 5.38391 loss)
I0524 06:18:18.823913 11654 sgd_solver.cpp:112] Iteration 41090, lr = 0.1
I0524 06:18:26.381376 11654 solver.cpp:239] Iteration 41100 (1.32362 iter/s, 7.55502s/10 iters), loss = 7.58941
I0524 06:18:26.381465 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58941 (* 1 = 7.58941 loss)
I0524 06:18:26.381556 11654 sgd_solver.cpp:112] Iteration 41100, lr = 0.1
I0524 06:18:33.216964 11654 solver.cpp:239] Iteration 41110 (1.463 iter/s, 6.83525s/10 iters), loss = 6.52111
I0524 06:18:33.217013 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52111 (* 1 = 6.52111 loss)
I0524 06:18:33.217675 11654 sgd_solver.cpp:112] Iteration 41110, lr = 0.1
I0524 06:18:39.916057 11654 solver.cpp:239] Iteration 41120 (1.49281 iter/s, 6.69878s/10 iters), loss = 6.27249
I0524 06:18:39.916117 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27249 (* 1 = 6.27249 loss)
I0524 06:18:39.916169 11654 sgd_solver.cpp:112] Iteration 41120, lr = 0.1
I0524 06:18:48.412187 11654 solver.cpp:239] Iteration 41130 (1.17706 iter/s, 8.49576s/10 iters), loss = 7.02363
I0524 06:18:48.412423 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02363 (* 1 = 7.02363 loss)
I0524 06:18:48.412467 11654 sgd_solver.cpp:112] Iteration 41130, lr = 0.1
I0524 06:18:56.188297 11654 solver.cpp:239] Iteration 41140 (1.28608 iter/s, 7.77555s/10 iters), loss = 6.54234
I0524 06:18:56.188367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54234 (* 1 = 6.54234 loss)
I0524 06:18:56.188755 11654 sgd_solver.cpp:112] Iteration 41140, lr = 0.1
I0524 06:19:04.142675 11654 solver.cpp:239] Iteration 41150 (1.25723 iter/s, 7.95401s/10 iters), loss = 6.58979
I0524 06:19:04.142755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58979 (* 1 = 6.58979 loss)
I0524 06:19:05.168788 11654 sgd_solver.cpp:112] Iteration 41150, lr = 0.1
I0524 06:19:14.049135 11654 solver.cpp:239] Iteration 41160 (1.00949 iter/s, 9.906s/10 iters), loss = 5.71547
I0524 06:19:14.049211 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71547 (* 1 = 5.71547 loss)
I0524 06:19:14.049773 11654 sgd_solver.cpp:112] Iteration 41160, lr = 0.1
I0524 06:19:20.842459 11654 solver.cpp:239] Iteration 41170 (1.47211 iter/s, 6.79299s/10 iters), loss = 5.02133
I0524 06:19:20.842690 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.02133 (* 1 = 5.02133 loss)
I0524 06:19:21.351562 11654 sgd_solver.cpp:112] Iteration 41170, lr = 0.1
I0524 06:19:29.786772 11654 solver.cpp:239] Iteration 41180 (1.1181 iter/s, 8.94376s/10 iters), loss = 5.01039
I0524 06:19:29.786818 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.01039 (* 1 = 5.01039 loss)
I0524 06:19:29.786968 11654 sgd_solver.cpp:112] Iteration 41180, lr = 0.1
I0524 06:19:36.203434 11654 solver.cpp:239] Iteration 41190 (1.55852 iter/s, 6.41633s/10 iters), loss = 6.63308
I0524 06:19:36.203550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63308 (* 1 = 6.63308 loss)
I0524 06:19:36.203954 11654 sgd_solver.cpp:112] Iteration 41190, lr = 0.1
I0524 06:19:43.626263 11654 solver.cpp:239] Iteration 41200 (1.34726 iter/s, 7.42246s/10 iters), loss = 6.30652
I0524 06:19:43.626327 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30652 (* 1 = 6.30652 loss)
I0524 06:19:44.184427 11654 sgd_solver.cpp:112] Iteration 41200, lr = 0.1
I0524 06:19:53.054072 11654 solver.cpp:239] Iteration 41210 (1.06074 iter/s, 9.42735s/10 iters), loss = 5.94816
I0524 06:19:53.054288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94816 (* 1 = 5.94816 loss)
I0524 06:19:53.054318 11654 sgd_solver.cpp:112] Iteration 41210, lr = 0.1
I0524 06:19:59.614217 11654 solver.cpp:239] Iteration 41220 (1.52492 iter/s, 6.55771s/10 iters), loss = 6.89064
I0524 06:19:59.614274 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89064 (* 1 = 6.89064 loss)
I0524 06:19:59.614315 11654 sgd_solver.cpp:112] Iteration 41220, lr = 0.1
I0524 06:20:06.533206 11654 solver.cpp:239] Iteration 41230 (1.44538 iter/s, 6.91861s/10 iters), loss = 5.72249
I0524 06:20:06.533248 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72249 (* 1 = 5.72249 loss)
I0524 06:20:06.533262 11654 sgd_solver.cpp:112] Iteration 41230, lr = 0.1
I0524 06:20:15.862473 11654 solver.cpp:239] Iteration 41240 (1.07194 iter/s, 9.32886s/10 iters), loss = 5.88047
I0524 06:20:15.862527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88047 (* 1 = 5.88047 loss)
I0524 06:20:16.156486 11654 sgd_solver.cpp:112] Iteration 41240, lr = 0.1
I0524 06:20:24.068020 11654 solver.cpp:239] Iteration 41250 (1.21874 iter/s, 8.20517s/10 iters), loss = 6.60293
I0524 06:20:24.068245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60293 (* 1 = 6.60293 loss)
I0524 06:20:24.646661 11654 sgd_solver.cpp:112] Iteration 41250, lr = 0.1
I0524 06:20:32.019564 11654 solver.cpp:239] Iteration 41260 (1.2577 iter/s, 7.95105s/10 iters), loss = 6.90464
I0524 06:20:32.019614 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90464 (* 1 = 6.90464 loss)
I0524 06:20:32.019631 11654 sgd_solver.cpp:112] Iteration 41260, lr = 0.1
I0524 06:20:38.123569 11654 solver.cpp:239] Iteration 41270 (1.63836 iter/s, 6.10366s/10 iters), loss = 6.14773
I0524 06:20:38.123622 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14773 (* 1 = 6.14773 loss)
I0524 06:20:38.123639 11654 sgd_solver.cpp:112] Iteration 41270, lr = 0.1
I0524 06:20:46.466753 11654 solver.cpp:239] Iteration 41280 (1.19865 iter/s, 8.34272s/10 iters), loss = 6.57679
I0524 06:20:46.466838 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57679 (* 1 = 6.57679 loss)
I0524 06:20:46.467370 11654 sgd_solver.cpp:112] Iteration 41280, lr = 0.1
I0524 06:20:53.210157 11654 solver.cpp:239] Iteration 41290 (1.48301 iter/s, 6.74303s/10 iters), loss = 5.72029
I0524 06:20:53.210304 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72029 (* 1 = 5.72029 loss)
I0524 06:20:53.210500 11654 sgd_solver.cpp:112] Iteration 41290, lr = 0.1
I0524 06:21:01.288266 11654 solver.cpp:239] Iteration 41300 (1.23798 iter/s, 8.07769s/10 iters), loss = 6.08398
I0524 06:21:01.288525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08398 (* 1 = 6.08398 loss)
I0524 06:21:02.156181 11654 sgd_solver.cpp:112] Iteration 41300, lr = 0.1
I0524 06:21:10.177636 11654 solver.cpp:239] Iteration 41310 (1.12501 iter/s, 8.88879s/10 iters), loss = 5.68913
I0524 06:21:10.177723 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68913 (* 1 = 5.68913 loss)
I0524 06:21:10.177745 11654 sgd_solver.cpp:112] Iteration 41310, lr = 0.1
I0524 06:21:17.573113 11654 solver.cpp:239] Iteration 41320 (1.35224 iter/s, 7.39512s/10 iters), loss = 5.87758
I0524 06:21:17.573185 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87758 (* 1 = 5.87758 loss)
I0524 06:21:17.573537 11654 sgd_solver.cpp:112] Iteration 41320, lr = 0.1
I0524 06:21:23.917565 11654 solver.cpp:239] Iteration 41330 (1.57627 iter/s, 6.34411s/10 iters), loss = 6.67026
I0524 06:21:23.917644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67026 (* 1 = 6.67026 loss)
I0524 06:21:23.917667 11654 sgd_solver.cpp:112] Iteration 41330, lr = 0.1
I0524 06:21:31.580893 11654 solver.cpp:239] Iteration 41340 (1.30499 iter/s, 7.66292s/10 iters), loss = 6.44795
I0524 06:21:31.581207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44795 (* 1 = 6.44795 loss)
I0524 06:21:31.582741 11654 sgd_solver.cpp:112] Iteration 41340, lr = 0.1
I0524 06:21:39.706833 11654 solver.cpp:239] Iteration 41350 (1.23072 iter/s, 8.12535s/10 iters), loss = 6.38335
I0524 06:21:39.706912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38335 (* 1 = 6.38335 loss)
I0524 06:21:39.706935 11654 sgd_solver.cpp:112] Iteration 41350, lr = 0.1
I0524 06:21:47.764868 11654 solver.cpp:239] Iteration 41360 (1.24138 iter/s, 8.05553s/10 iters), loss = 6.49818
I0524 06:21:47.764935 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49818 (* 1 = 6.49818 loss)
I0524 06:21:48.104952 11654 sgd_solver.cpp:112] Iteration 41360, lr = 0.1
I0524 06:21:55.215710 11654 solver.cpp:239] Iteration 41370 (1.3422 iter/s, 7.45048s/10 iters), loss = 7.07373
I0524 06:21:55.215803 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07373 (* 1 = 7.07373 loss)
I0524 06:21:55.216120 11654 sgd_solver.cpp:112] Iteration 41370, lr = 0.1
I0524 06:22:03.759558 11654 solver.cpp:239] Iteration 41380 (1.17049 iter/s, 8.54346s/10 iters), loss = 6.26642
I0524 06:22:03.759754 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26642 (* 1 = 6.26642 loss)
I0524 06:22:03.759799 11654 sgd_solver.cpp:112] Iteration 41380, lr = 0.1
I0524 06:22:10.288606 11654 solver.cpp:239] Iteration 41390 (1.53185 iter/s, 6.52805s/10 iters), loss = 5.49391
I0524 06:22:10.288661 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49391 (* 1 = 5.49391 loss)
I0524 06:22:10.416198 11654 sgd_solver.cpp:112] Iteration 41390, lr = 0.1
I0524 06:22:18.350095 11654 solver.cpp:239] Iteration 41400 (1.24053 iter/s, 8.06106s/10 iters), loss = 5.91002
I0524 06:22:18.350163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91002 (* 1 = 5.91002 loss)
I0524 06:22:18.350188 11654 sgd_solver.cpp:112] Iteration 41400, lr = 0.1
I0524 06:22:25.995764 11654 solver.cpp:239] Iteration 41410 (1.30813 iter/s, 7.6445s/10 iters), loss = 6.25061
I0524 06:22:25.995823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25061 (* 1 = 6.25061 loss)
I0524 06:22:26.411478 11654 sgd_solver.cpp:112] Iteration 41410, lr = 0.1
I0524 06:22:38.169309 11654 solver.cpp:239] Iteration 41420 (0.821489 iter/s, 12.173s/10 iters), loss = 6.66211
I0524 06:22:38.169625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66211 (* 1 = 6.66211 loss)
I0524 06:22:38.169695 11654 sgd_solver.cpp:112] Iteration 41420, lr = 0.1
I0524 06:22:44.867686 11654 solver.cpp:239] Iteration 41430 (1.49303 iter/s, 6.69779s/10 iters), loss = 5.83651
I0524 06:22:44.867736 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83651 (* 1 = 5.83651 loss)
I0524 06:22:45.224578 11654 sgd_solver.cpp:112] Iteration 41430, lr = 0.1
I0524 06:22:53.828860 11654 solver.cpp:239] Iteration 41440 (1.11598 iter/s, 8.96076s/10 iters), loss = 7.01397
I0524 06:22:53.828929 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01397 (* 1 = 7.01397 loss)
I0524 06:22:53.829046 11654 sgd_solver.cpp:112] Iteration 41440, lr = 0.1
I0524 06:23:00.319293 11654 solver.cpp:239] Iteration 41450 (1.54081 iter/s, 6.49011s/10 iters), loss = 6.79438
I0524 06:23:00.319334 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79438 (* 1 = 6.79438 loss)
I0524 06:23:00.319350 11654 sgd_solver.cpp:112] Iteration 41450, lr = 0.1
I0524 06:23:07.816700 11654 solver.cpp:239] Iteration 41460 (1.33402 iter/s, 7.49612s/10 iters), loss = 5.58799
I0524 06:23:07.816774 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58799 (* 1 = 5.58799 loss)
I0524 06:23:07.816794 11654 sgd_solver.cpp:112] Iteration 41460, lr = 0.1
I0524 06:23:14.493036 11654 solver.cpp:239] Iteration 41470 (1.49791 iter/s, 6.67595s/10 iters), loss = 5.86388
I0524 06:23:14.493265 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86388 (* 1 = 5.86388 loss)
I0524 06:23:14.493333 11654 sgd_solver.cpp:112] Iteration 41470, lr = 0.1
I0524 06:23:20.776984 11654 solver.cpp:239] Iteration 41480 (1.59147 iter/s, 6.2835s/10 iters), loss = 5.63668
I0524 06:23:20.777056 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63668 (* 1 = 5.63668 loss)
I0524 06:23:20.777374 11654 sgd_solver.cpp:112] Iteration 41480, lr = 0.1
I0524 06:23:27.724056 11654 solver.cpp:239] Iteration 41490 (1.43952 iter/s, 6.94674s/10 iters), loss = 5.90915
I0524 06:23:27.724099 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90915 (* 1 = 5.90915 loss)
I0524 06:23:27.724287 11654 sgd_solver.cpp:112] Iteration 41490, lr = 0.1
I0524 06:23:34.272972 11654 solver.cpp:239] Iteration 41500 (1.52704 iter/s, 6.5486s/10 iters), loss = 6.02118
I0524 06:23:34.273039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02118 (* 1 = 6.02118 loss)
I0524 06:23:34.273264 11654 sgd_solver.cpp:112] Iteration 41500, lr = 0.1
I0524 06:23:41.195056 11654 solver.cpp:239] Iteration 41510 (1.44472 iter/s, 6.92175s/10 iters), loss = 6.35307
I0524 06:23:41.195116 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35307 (* 1 = 6.35307 loss)
I0524 06:23:41.195374 11654 sgd_solver.cpp:112] Iteration 41510, lr = 0.1
I0524 06:23:47.765734 11654 solver.cpp:239] Iteration 41520 (1.52199 iter/s, 6.57034s/10 iters), loss = 5.00816
I0524 06:23:47.765947 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.00816 (* 1 = 5.00816 loss)
I0524 06:23:47.766006 11654 sgd_solver.cpp:112] Iteration 41520, lr = 0.1
I0524 06:23:54.493927 11654 solver.cpp:239] Iteration 41530 (1.48683 iter/s, 6.72572s/10 iters), loss = 6.04099
I0524 06:23:54.493984 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04099 (* 1 = 6.04099 loss)
I0524 06:23:54.494587 11654 sgd_solver.cpp:112] Iteration 41530, lr = 0.1
I0524 06:24:02.164125 11654 solver.cpp:239] Iteration 41540 (1.30381 iter/s, 7.66985s/10 iters), loss = 5.43795
I0524 06:24:02.164168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.43795 (* 1 = 5.43795 loss)
I0524 06:24:02.491441 11654 sgd_solver.cpp:112] Iteration 41540, lr = 0.1
I0524 06:24:11.147094 11654 solver.cpp:239] Iteration 41550 (1.11327 iter/s, 8.98254s/10 iters), loss = 5.58754
I0524 06:24:11.147166 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58754 (* 1 = 5.58754 loss)
I0524 06:24:11.395792 11654 sgd_solver.cpp:112] Iteration 41550, lr = 0.1
I0524 06:24:19.474115 11654 solver.cpp:239] Iteration 41560 (1.20097 iter/s, 8.32663s/10 iters), loss = 6.00843
I0524 06:24:19.474362 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00843 (* 1 = 6.00843 loss)
I0524 06:24:19.474393 11654 sgd_solver.cpp:112] Iteration 41560, lr = 0.1
I0524 06:24:27.102869 11654 solver.cpp:239] Iteration 41570 (1.3111 iter/s, 7.62719s/10 iters), loss = 7.12043
I0524 06:24:27.102923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12043 (* 1 = 7.12043 loss)
I0524 06:24:27.466334 11654 sgd_solver.cpp:112] Iteration 41570, lr = 0.1
I0524 06:24:33.845530 11654 solver.cpp:239] Iteration 41580 (1.48317 iter/s, 6.74231s/10 iters), loss = 5.63598
I0524 06:24:33.845598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63598 (* 1 = 5.63598 loss)
I0524 06:24:33.845757 11654 sgd_solver.cpp:112] Iteration 41580, lr = 0.1
I0524 06:24:40.258937 11654 solver.cpp:239] Iteration 41590 (1.55931 iter/s, 6.41308s/10 iters), loss = 6.12454
I0524 06:24:40.259018 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12454 (* 1 = 6.12454 loss)
I0524 06:24:40.259199 11654 sgd_solver.cpp:112] Iteration 41590, lr = 0.1
I0524 06:24:47.087864 11654 solver.cpp:239] Iteration 41600 (1.46443 iter/s, 6.82858s/10 iters), loss = 6.08847
I0524 06:24:47.087923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08847 (* 1 = 6.08847 loss)
I0524 06:24:47.087940 11654 sgd_solver.cpp:112] Iteration 41600, lr = 0.1
I0524 06:24:53.964175 11654 solver.cpp:239] Iteration 41610 (1.45434 iter/s, 6.87596s/10 iters), loss = 5.50727
I0524 06:24:53.964332 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50727 (* 1 = 5.50727 loss)
I0524 06:24:53.964350 11654 sgd_solver.cpp:112] Iteration 41610, lr = 0.1
I0524 06:25:03.397698 11654 solver.cpp:239] Iteration 41620 (1.06011 iter/s, 9.43298s/10 iters), loss = 5.68454
I0524 06:25:03.397753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68454 (* 1 = 5.68454 loss)
I0524 06:25:03.397768 11654 sgd_solver.cpp:112] Iteration 41620, lr = 0.1
I0524 06:25:11.076205 11654 solver.cpp:239] Iteration 41630 (1.30239 iter/s, 7.67817s/10 iters), loss = 5.71442
I0524 06:25:11.076243 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71442 (* 1 = 5.71442 loss)
I0524 06:25:11.076256 11654 sgd_solver.cpp:112] Iteration 41630, lr = 0.1
I0524 06:25:19.083451 11654 solver.cpp:239] Iteration 41640 (1.24894 iter/s, 8.00681s/10 iters), loss = 5.6265
I0524 06:25:19.083509 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6265 (* 1 = 5.6265 loss)
I0524 06:25:19.083525 11654 sgd_solver.cpp:112] Iteration 41640, lr = 0.1
I0524 06:25:26.122637 11654 solver.cpp:239] Iteration 41650 (1.42074 iter/s, 7.03861s/10 iters), loss = 6.09272
I0524 06:25:26.122866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09272 (* 1 = 6.09272 loss)
I0524 06:25:26.122887 11654 sgd_solver.cpp:112] Iteration 41650, lr = 0.1
I0524 06:25:33.415590 11654 solver.cpp:239] Iteration 41660 (1.37128 iter/s, 7.29244s/10 iters), loss = 5.5824
I0524 06:25:33.415653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5824 (* 1 = 5.5824 loss)
I0524 06:25:33.415673 11654 sgd_solver.cpp:112] Iteration 41660, lr = 0.1
I0524 06:25:40.709401 11654 solver.cpp:239] Iteration 41670 (1.37109 iter/s, 7.29347s/10 iters), loss = 5.86155
I0524 06:25:40.709465 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86155 (* 1 = 5.86155 loss)
I0524 06:25:40.709607 11654 sgd_solver.cpp:112] Iteration 41670, lr = 0.1
I0524 06:25:47.935916 11654 solver.cpp:239] Iteration 41680 (1.38386 iter/s, 7.22617s/10 iters), loss = 6.08869
I0524 06:25:47.935983 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08869 (* 1 = 6.08869 loss)
I0524 06:25:47.936116 11654 sgd_solver.cpp:112] Iteration 41680, lr = 0.1
I0524 06:25:55.260570 11654 solver.cpp:239] Iteration 41690 (1.36532 iter/s, 7.3243s/10 iters), loss = 5.72925
I0524 06:25:55.260622 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72925 (* 1 = 5.72925 loss)
I0524 06:25:55.262122 11654 sgd_solver.cpp:112] Iteration 41690, lr = 0.1
I0524 06:26:02.393227 11654 solver.cpp:239] Iteration 41700 (1.40207 iter/s, 7.13231s/10 iters), loss = 6.50122
I0524 06:26:02.393436 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50122 (* 1 = 6.50122 loss)
I0524 06:26:02.393457 11654 sgd_solver.cpp:112] Iteration 41700, lr = 0.1
I0524 06:26:09.551935 11654 solver.cpp:239] Iteration 41710 (1.39704 iter/s, 7.158s/10 iters), loss = 6.51406
I0524 06:26:09.552021 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51406 (* 1 = 6.51406 loss)
I0524 06:26:09.552050 11654 sgd_solver.cpp:112] Iteration 41710, lr = 0.1
I0524 06:26:17.393386 11654 solver.cpp:239] Iteration 41720 (1.27534 iter/s, 7.84105s/10 iters), loss = 5.19783
I0524 06:26:17.393448 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.19783 (* 1 = 5.19783 loss)
I0524 06:26:17.393465 11654 sgd_solver.cpp:112] Iteration 41720, lr = 0.1
I0524 06:26:23.912322 11654 solver.cpp:239] Iteration 41730 (1.53457 iter/s, 6.51648s/10 iters), loss = 5.48909
I0524 06:26:23.912371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48909 (* 1 = 5.48909 loss)
I0524 06:26:23.912611 11654 sgd_solver.cpp:112] Iteration 41730, lr = 0.1
I0524 06:26:32.505214 11654 solver.cpp:239] Iteration 41740 (1.16381 iter/s, 8.59244s/10 iters), loss = 6.86406
I0524 06:26:32.505406 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86406 (* 1 = 6.86406 loss)
I0524 06:26:32.505558 11654 sgd_solver.cpp:112] Iteration 41740, lr = 0.1
I0524 06:26:38.952769 11654 solver.cpp:239] Iteration 41750 (1.55108 iter/s, 6.44712s/10 iters), loss = 5.19773
I0524 06:26:38.952827 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.19773 (* 1 = 5.19773 loss)
I0524 06:26:38.952848 11654 sgd_solver.cpp:112] Iteration 41750, lr = 0.1
I0524 06:26:45.887054 11654 solver.cpp:239] Iteration 41760 (1.4422 iter/s, 6.93386s/10 iters), loss = 6.33572
I0524 06:26:45.887106 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33572 (* 1 = 6.33572 loss)
I0524 06:26:45.887208 11654 sgd_solver.cpp:112] Iteration 41760, lr = 0.1
I0524 06:26:52.943728 11654 solver.cpp:239] Iteration 41770 (1.41717 iter/s, 7.05634s/10 iters), loss = 7.042
I0524 06:26:52.943789 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.042 (* 1 = 7.042 loss)
I0524 06:26:52.943966 11654 sgd_solver.cpp:112] Iteration 41770, lr = 0.1
I0524 06:26:59.632997 11654 solver.cpp:239] Iteration 41780 (1.495 iter/s, 6.68895s/10 iters), loss = 6.25837
I0524 06:26:59.633052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25837 (* 1 = 6.25837 loss)
I0524 06:26:59.642781 11654 sgd_solver.cpp:112] Iteration 41780, lr = 0.1
I0524 06:27:07.847463 11654 solver.cpp:239] Iteration 41790 (1.21742 iter/s, 8.21411s/10 iters), loss = 6.60327
I0524 06:27:07.847705 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60327 (* 1 = 6.60327 loss)
I0524 06:27:08.768273 11654 sgd_solver.cpp:112] Iteration 41790, lr = 0.1
I0524 06:27:19.174688 11654 solver.cpp:239] Iteration 41800 (0.882879 iter/s, 11.3266s/10 iters), loss = 5.78826
I0524 06:27:19.174775 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78826 (* 1 = 5.78826 loss)
I0524 06:27:19.174793 11654 sgd_solver.cpp:112] Iteration 41800, lr = 0.1
I0524 06:27:26.617038 11654 solver.cpp:239] Iteration 41810 (1.34373 iter/s, 7.44198s/10 iters), loss = 6.64292
I0524 06:27:26.617087 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64292 (* 1 = 6.64292 loss)
I0524 06:27:26.617105 11654 sgd_solver.cpp:112] Iteration 41810, lr = 0.1
I0524 06:27:34.196748 11654 solver.cpp:239] Iteration 41820 (1.31938 iter/s, 7.57935s/10 iters), loss = 6.5013
I0524 06:27:34.196830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5013 (* 1 = 6.5013 loss)
I0524 06:27:34.197016 11654 sgd_solver.cpp:112] Iteration 41820, lr = 0.1
I0524 06:27:40.645233 11654 solver.cpp:239] Iteration 41830 (1.55083 iter/s, 6.44817s/10 iters), loss = 5.68046
I0524 06:27:40.645507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68046 (* 1 = 5.68046 loss)
I0524 06:27:40.645560 11654 sgd_solver.cpp:112] Iteration 41830, lr = 0.1
I0524 06:27:48.341717 11654 solver.cpp:239] Iteration 41840 (1.29942 iter/s, 7.69575s/10 iters), loss = 6.01394
I0524 06:27:48.341771 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01394 (* 1 = 6.01394 loss)
I0524 06:27:48.360927 11654 sgd_solver.cpp:112] Iteration 41840, lr = 0.1
I0524 06:27:54.934597 11654 solver.cpp:239] Iteration 41850 (1.51686 iter/s, 6.59256s/10 iters), loss = 6.87535
I0524 06:27:54.934650 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87535 (* 1 = 6.87535 loss)
I0524 06:27:54.934666 11654 sgd_solver.cpp:112] Iteration 41850, lr = 0.1
I0524 06:28:01.617825 11654 solver.cpp:239] Iteration 41860 (1.49637 iter/s, 6.68285s/10 iters), loss = 5.76678
I0524 06:28:01.617913 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76678 (* 1 = 5.76678 loss)
I0524 06:28:01.618082 11654 sgd_solver.cpp:112] Iteration 41860, lr = 0.1
I0524 06:28:08.155313 11654 solver.cpp:239] Iteration 41870 (1.52971 iter/s, 6.53718s/10 iters), loss = 6.59958
I0524 06:28:08.155378 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59958 (* 1 = 6.59958 loss)
I0524 06:28:08.155396 11654 sgd_solver.cpp:112] Iteration 41870, lr = 0.1
I0524 06:28:14.999388 11654 solver.cpp:239] Iteration 41880 (1.4612 iter/s, 6.84369s/10 iters), loss = 5.20529
I0524 06:28:14.999691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.20529 (* 1 = 5.20529 loss)
I0524 06:28:14.999781 11654 sgd_solver.cpp:112] Iteration 41880, lr = 0.1
I0524 06:28:23.644237 11654 solver.cpp:239] Iteration 41890 (1.15684 iter/s, 8.64424s/10 iters), loss = 5.75804
I0524 06:28:23.644290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75804 (* 1 = 5.75804 loss)
I0524 06:28:23.682910 11654 sgd_solver.cpp:112] Iteration 41890, lr = 0.1
I0524 06:28:33.897119 11654 solver.cpp:239] Iteration 41900 (0.97538 iter/s, 10.2524s/10 iters), loss = 6.0474
I0524 06:28:33.897208 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0474 (* 1 = 6.0474 loss)
I0524 06:28:33.897244 11654 sgd_solver.cpp:112] Iteration 41900, lr = 0.1
I0524 06:28:41.898403 11654 solver.cpp:239] Iteration 41910 (1.24986 iter/s, 8.00087s/10 iters), loss = 6.18472
I0524 06:28:41.898471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18472 (* 1 = 6.18472 loss)
I0524 06:28:42.629024 11654 sgd_solver.cpp:112] Iteration 41910, lr = 0.1
I0524 06:28:49.402820 11654 solver.cpp:239] Iteration 41920 (1.33261 iter/s, 7.50404s/10 iters), loss = 5.77897
I0524 06:28:49.403082 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77897 (* 1 = 5.77897 loss)
I0524 06:28:49.484306 11654 sgd_solver.cpp:112] Iteration 41920, lr = 0.1
I0524 06:28:56.834049 11654 solver.cpp:239] Iteration 41930 (1.34577 iter/s, 7.4307s/10 iters), loss = 5.61263
I0524 06:28:56.834110 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61263 (* 1 = 5.61263 loss)
I0524 06:28:56.834125 11654 sgd_solver.cpp:112] Iteration 41930, lr = 0.1
I0524 06:29:03.112596 11654 solver.cpp:239] Iteration 41940 (1.59283 iter/s, 6.27814s/10 iters), loss = 6.27774
I0524 06:29:03.112677 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27774 (* 1 = 6.27774 loss)
I0524 06:29:03.112697 11654 sgd_solver.cpp:112] Iteration 41940, lr = 0.1
I0524 06:29:09.273476 11654 solver.cpp:239] Iteration 41950 (1.62324 iter/s, 6.1605s/10 iters), loss = 6.53444
I0524 06:29:09.273541 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53444 (* 1 = 6.53444 loss)
I0524 06:29:09.273620 11654 sgd_solver.cpp:112] Iteration 41950, lr = 0.1
I0524 06:29:16.501925 11654 solver.cpp:239] Iteration 41960 (1.38349 iter/s, 7.22811s/10 iters), loss = 6.58482
I0524 06:29:16.501977 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58482 (* 1 = 6.58482 loss)
I0524 06:29:17.368948 11654 sgd_solver.cpp:112] Iteration 41960, lr = 0.1
I0524 06:29:24.245100 11654 solver.cpp:239] Iteration 41970 (1.29152 iter/s, 7.74281s/10 iters), loss = 6.84985
I0524 06:29:24.245297 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84985 (* 1 = 6.84985 loss)
I0524 06:29:24.274698 11654 sgd_solver.cpp:112] Iteration 41970, lr = 0.1
I0524 06:29:31.401136 11654 solver.cpp:239] Iteration 41980 (1.39751 iter/s, 7.15557s/10 iters), loss = 6.58594
I0524 06:29:31.401201 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58594 (* 1 = 6.58594 loss)
I0524 06:29:31.401363 11654 sgd_solver.cpp:112] Iteration 41980, lr = 0.1
I0524 06:29:37.786880 11654 solver.cpp:239] Iteration 41990 (1.56607 iter/s, 6.38543s/10 iters), loss = 6.36141
I0524 06:29:37.786937 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36141 (* 1 = 6.36141 loss)
I0524 06:29:37.787117 11654 sgd_solver.cpp:112] Iteration 41990, lr = 0.1
I0524 06:29:46.700055 11654 solver.cpp:239] Iteration 42000 (1.12199 iter/s, 8.91277s/10 iters), loss = 7.4239
I0524 06:29:46.700129 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4239 (* 1 = 7.4239 loss)
I0524 06:29:46.700148 11654 sgd_solver.cpp:112] Iteration 42000, lr = 0.1
I0524 06:29:54.908630 11654 solver.cpp:239] Iteration 42010 (1.21833 iter/s, 8.20798s/10 iters), loss = 6.80573
I0524 06:29:54.908906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80573 (* 1 = 6.80573 loss)
I0524 06:29:55.323848 11654 sgd_solver.cpp:112] Iteration 42010, lr = 0.1
I0524 06:30:02.639112 11654 solver.cpp:239] Iteration 42020 (1.29367 iter/s, 7.72993s/10 iters), loss = 6.4563
I0524 06:30:02.639200 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4563 (* 1 = 6.4563 loss)
I0524 06:30:02.639598 11654 sgd_solver.cpp:112] Iteration 42020, lr = 0.1
I0524 06:30:11.178458 11654 solver.cpp:239] Iteration 42030 (1.17111 iter/s, 8.53894s/10 iters), loss = 7.14581
I0524 06:30:11.178542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14581 (* 1 = 7.14581 loss)
I0524 06:30:11.178712 11654 sgd_solver.cpp:112] Iteration 42030, lr = 0.1
I0524 06:30:18.046790 11654 solver.cpp:239] Iteration 42040 (1.45603 iter/s, 6.868s/10 iters), loss = 6.58492
I0524 06:30:18.046849 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58492 (* 1 = 6.58492 loss)
I0524 06:30:18.447371 11654 sgd_solver.cpp:112] Iteration 42040, lr = 0.1
I0524 06:30:25.176882 11654 solver.cpp:239] Iteration 42050 (1.40258 iter/s, 7.12973s/10 iters), loss = 5.88352
I0524 06:30:25.177048 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88352 (* 1 = 5.88352 loss)
I0524 06:30:25.177095 11654 sgd_solver.cpp:112] Iteration 42050, lr = 0.1
I0524 06:30:32.369869 11654 solver.cpp:239] Iteration 42060 (1.39033 iter/s, 7.19254s/10 iters), loss = 7.00165
I0524 06:30:32.369940 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00165 (* 1 = 7.00165 loss)
I0524 06:30:32.369957 11654 sgd_solver.cpp:112] Iteration 42060, lr = 0.1
I0524 06:30:40.215936 11654 solver.cpp:239] Iteration 42070 (1.27458 iter/s, 7.8457s/10 iters), loss = 6.37692
I0524 06:30:40.215986 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37692 (* 1 = 6.37692 loss)
I0524 06:30:40.216001 11654 sgd_solver.cpp:112] Iteration 42070, lr = 0.1
I0524 06:30:47.075574 11654 solver.cpp:239] Iteration 42080 (1.45787 iter/s, 6.85932s/10 iters), loss = 6.54008
I0524 06:30:47.075636 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54008 (* 1 = 6.54008 loss)
I0524 06:30:47.075778 11654 sgd_solver.cpp:112] Iteration 42080, lr = 0.1
I0524 06:30:54.296749 11654 solver.cpp:239] Iteration 42090 (1.38489 iter/s, 7.2208s/10 iters), loss = 5.70325
I0524 06:30:54.296830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70325 (* 1 = 5.70325 loss)
I0524 06:30:54.296850 11654 sgd_solver.cpp:112] Iteration 42090, lr = 0.1
I0524 06:31:02.554953 11654 solver.cpp:239] Iteration 42100 (1.21098 iter/s, 8.25776s/10 iters), loss = 8.26547
I0524 06:31:02.555177 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.26547 (* 1 = 8.26547 loss)
I0524 06:31:02.555208 11654 sgd_solver.cpp:112] Iteration 42100, lr = 0.1
I0524 06:31:11.997200 11654 solver.cpp:239] Iteration 42110 (1.05914 iter/s, 9.44166s/10 iters), loss = 6.04027
I0524 06:31:11.997257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04027 (* 1 = 6.04027 loss)
I0524 06:31:11.997294 11654 sgd_solver.cpp:112] Iteration 42110, lr = 0.1
I0524 06:31:18.926211 11654 solver.cpp:239] Iteration 42120 (1.44329 iter/s, 6.92861s/10 iters), loss = 6.35174
I0524 06:31:18.926288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35174 (* 1 = 6.35174 loss)
I0524 06:31:19.433459 11654 sgd_solver.cpp:112] Iteration 42120, lr = 0.1
I0524 06:31:26.978505 11654 solver.cpp:239] Iteration 42130 (1.24194 iter/s, 8.05192s/10 iters), loss = 6.38476
I0524 06:31:26.978564 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38476 (* 1 = 6.38476 loss)
I0524 06:31:26.978643 11654 sgd_solver.cpp:112] Iteration 42130, lr = 0.1
I0524 06:31:34.651026 11654 solver.cpp:239] Iteration 42140 (1.30341 iter/s, 7.67217s/10 iters), loss = 6.09552
I0524 06:31:34.651230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09552 (* 1 = 6.09552 loss)
I0524 06:31:34.651265 11654 sgd_solver.cpp:112] Iteration 42140, lr = 0.1
I0524 06:31:42.521142 11654 solver.cpp:239] Iteration 42150 (1.27071 iter/s, 7.86959s/10 iters), loss = 7.23421
I0524 06:31:42.521215 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23421 (* 1 = 7.23421 loss)
I0524 06:31:42.540592 11654 sgd_solver.cpp:112] Iteration 42150, lr = 0.1
I0524 06:31:51.738554 11654 solver.cpp:239] Iteration 42160 (1.08495 iter/s, 9.21698s/10 iters), loss = 6.66797
I0524 06:31:51.738663 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66797 (* 1 = 6.66797 loss)
I0524 06:31:52.322877 11654 sgd_solver.cpp:112] Iteration 42160, lr = 0.1
I0524 06:32:01.017408 11654 solver.cpp:239] Iteration 42170 (1.07777 iter/s, 9.27843s/10 iters), loss = 5.884
I0524 06:32:01.017465 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.884 (* 1 = 5.884 loss)
I0524 06:32:01.710889 11654 sgd_solver.cpp:112] Iteration 42170, lr = 0.1
I0524 06:32:10.932996 11654 solver.cpp:239] Iteration 42180 (1.00856 iter/s, 9.91515s/10 iters), loss = 6.7752
I0524 06:32:10.933161 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7752 (* 1 = 6.7752 loss)
I0524 06:32:10.933182 11654 sgd_solver.cpp:112] Iteration 42180, lr = 0.1
I0524 06:32:17.248771 11654 solver.cpp:239] Iteration 42190 (1.58349 iter/s, 6.31515s/10 iters), loss = 5.32072
I0524 06:32:17.248875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.32072 (* 1 = 5.32072 loss)
I0524 06:32:17.249019 11654 sgd_solver.cpp:112] Iteration 42190, lr = 0.1
I0524 06:32:23.455425 11654 solver.cpp:239] Iteration 42200 (1.61128 iter/s, 6.20623s/10 iters), loss = 7.22624
I0524 06:32:23.455544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22624 (* 1 = 7.22624 loss)
I0524 06:32:23.455582 11654 sgd_solver.cpp:112] Iteration 42200, lr = 0.1
I0524 06:32:29.799439 11654 solver.cpp:239] Iteration 42210 (1.57637 iter/s, 6.34369s/10 iters), loss = 6.60069
I0524 06:32:29.799481 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60069 (* 1 = 6.60069 loss)
I0524 06:32:29.799494 11654 sgd_solver.cpp:112] Iteration 42210, lr = 0.1
I0524 06:32:38.044589 11654 solver.cpp:239] Iteration 42220 (1.21321 iter/s, 8.2426s/10 iters), loss = 5.99291
I0524 06:32:38.044644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99291 (* 1 = 5.99291 loss)
I0524 06:32:38.044661 11654 sgd_solver.cpp:112] Iteration 42220, lr = 0.1
I0524 06:32:48.086555 11654 solver.cpp:239] Iteration 42230 (0.995874 iter/s, 10.0414s/10 iters), loss = 5.67749
I0524 06:32:48.086766 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67749 (* 1 = 5.67749 loss)
I0524 06:32:48.086794 11654 sgd_solver.cpp:112] Iteration 42230, lr = 0.1
I0524 06:32:57.767412 11654 solver.cpp:239] Iteration 42240 (1.03325 iter/s, 9.67818s/10 iters), loss = 6.83673
I0524 06:32:57.767478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83673 (* 1 = 6.83673 loss)
I0524 06:32:57.804167 11654 sgd_solver.cpp:112] Iteration 42240, lr = 0.1
I0524 06:33:06.128422 11654 solver.cpp:239] Iteration 42250 (1.19608 iter/s, 8.36063s/10 iters), loss = 6.82448
I0524 06:33:06.128463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82448 (* 1 = 6.82448 loss)
I0524 06:33:06.405041 11654 sgd_solver.cpp:112] Iteration 42250, lr = 0.1
I0524 06:33:15.029553 11654 solver.cpp:239] Iteration 42260 (1.1235 iter/s, 8.90074s/10 iters), loss = 6.32413
I0524 06:33:15.029615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32413 (* 1 = 6.32413 loss)
I0524 06:33:16.019147 11654 sgd_solver.cpp:112] Iteration 42260, lr = 0.1
I0524 06:33:24.355927 11654 solver.cpp:239] Iteration 42270 (1.07228 iter/s, 9.32596s/10 iters), loss = 6.85998
I0524 06:33:24.356163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85998 (* 1 = 6.85998 loss)
I0524 06:33:24.356197 11654 sgd_solver.cpp:112] Iteration 42270, lr = 0.1
I0524 06:33:32.344008 11654 solver.cpp:239] Iteration 42280 (1.25196 iter/s, 7.9875s/10 iters), loss = 5.58117
I0524 06:33:32.344192 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58117 (* 1 = 5.58117 loss)
I0524 06:33:33.027065 11654 sgd_solver.cpp:112] Iteration 42280, lr = 0.1
I0524 06:33:41.554805 11654 solver.cpp:239] Iteration 42290 (1.08573 iter/s, 9.21037s/10 iters), loss = 6.309
I0524 06:33:41.554852 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.309 (* 1 = 6.309 loss)
I0524 06:33:42.073766 11654 sgd_solver.cpp:112] Iteration 42290, lr = 0.1
I0524 06:33:49.942848 11654 solver.cpp:239] Iteration 42300 (1.19223 iter/s, 8.38766s/10 iters), loss = 6.26326
I0524 06:33:49.942906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26326 (* 1 = 6.26326 loss)
I0524 06:33:50.570273 11654 sgd_solver.cpp:112] Iteration 42300, lr = 0.1
I0524 06:33:58.215682 11654 solver.cpp:239] Iteration 42310 (1.20883 iter/s, 8.27244s/10 iters), loss = 6.56679
I0524 06:33:58.215930 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56679 (* 1 = 6.56679 loss)
I0524 06:33:58.215968 11654 sgd_solver.cpp:112] Iteration 42310, lr = 0.1
I0524 06:34:05.188783 11654 solver.cpp:239] Iteration 42320 (1.43419 iter/s, 6.97259s/10 iters), loss = 6.30713
I0524 06:34:05.188874 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30713 (* 1 = 6.30713 loss)
I0524 06:34:05.242713 11654 sgd_solver.cpp:112] Iteration 42320, lr = 0.1
I0524 06:34:12.491155 11654 solver.cpp:239] Iteration 42330 (1.36949 iter/s, 7.30201s/10 iters), loss = 5.67327
I0524 06:34:12.491245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67327 (* 1 = 5.67327 loss)
I0524 06:34:12.491349 11654 sgd_solver.cpp:112] Iteration 42330, lr = 0.1
I0524 06:34:19.794423 11654 solver.cpp:239] Iteration 42340 (1.36931 iter/s, 7.30294s/10 iters), loss = 5.9232
I0524 06:34:19.794476 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9232 (* 1 = 5.9232 loss)
I0524 06:34:20.131147 11654 sgd_solver.cpp:112] Iteration 42340, lr = 0.1
I0524 06:34:27.133610 11654 solver.cpp:239] Iteration 42350 (1.36261 iter/s, 7.33884s/10 iters), loss = 6.48488
I0524 06:34:27.133682 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48488 (* 1 = 6.48488 loss)
I0524 06:34:27.133707 11654 sgd_solver.cpp:112] Iteration 42350, lr = 0.1
I0524 06:34:33.745826 11654 solver.cpp:239] Iteration 42360 (1.51292 iter/s, 6.60973s/10 iters), loss = 6.21225
I0524 06:34:33.746052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21225 (* 1 = 6.21225 loss)
I0524 06:34:33.746100 11654 sgd_solver.cpp:112] Iteration 42360, lr = 0.1
I0524 06:34:40.175312 11654 solver.cpp:239] Iteration 42370 (1.55544 iter/s, 6.42905s/10 iters), loss = 5.24606
I0524 06:34:40.175377 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.24606 (* 1 = 5.24606 loss)
I0524 06:34:40.398020 11654 sgd_solver.cpp:112] Iteration 42370, lr = 0.1
I0524 06:34:47.688093 11654 solver.cpp:239] Iteration 42380 (1.33113 iter/s, 7.51241s/10 iters), loss = 5.53134
I0524 06:34:47.688154 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53134 (* 1 = 5.53134 loss)
I0524 06:34:47.688170 11654 sgd_solver.cpp:112] Iteration 42380, lr = 0.1
I0524 06:34:54.357159 11654 solver.cpp:239] Iteration 42390 (1.49954 iter/s, 6.66871s/10 iters), loss = 5.6746
I0524 06:34:54.357224 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6746 (* 1 = 5.6746 loss)
I0524 06:34:54.357252 11654 sgd_solver.cpp:112] Iteration 42390, lr = 0.1
I0524 06:35:02.654050 11654 solver.cpp:239] Iteration 42400 (1.20566 iter/s, 8.29422s/10 iters), loss = 5.72523
I0524 06:35:02.654212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72523 (* 1 = 5.72523 loss)
I0524 06:35:02.654247 11654 sgd_solver.cpp:112] Iteration 42400, lr = 0.1
I0524 06:35:09.382388 11654 solver.cpp:239] Iteration 42410 (1.48633 iter/s, 6.72797s/10 iters), loss = 6.52184
I0524 06:35:09.382637 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52184 (* 1 = 6.52184 loss)
I0524 06:35:09.382719 11654 sgd_solver.cpp:112] Iteration 42410, lr = 0.1
I0524 06:35:16.938969 11654 solver.cpp:239] Iteration 42420 (1.32344 iter/s, 7.55604s/10 iters), loss = 5.4847
I0524 06:35:16.939069 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4847 (* 1 = 5.4847 loss)
I0524 06:35:16.941062 11654 sgd_solver.cpp:112] Iteration 42420, lr = 0.1
I0524 06:35:28.891857 11654 solver.cpp:239] Iteration 42430 (0.836655 iter/s, 11.9524s/10 iters), loss = 6.70394
I0524 06:35:28.891918 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70394 (* 1 = 6.70394 loss)
I0524 06:35:28.920163 11654 sgd_solver.cpp:112] Iteration 42430, lr = 0.1
I0524 06:35:36.790446 11654 solver.cpp:239] Iteration 42440 (1.26611 iter/s, 7.89819s/10 iters), loss = 8.29316
I0524 06:35:36.790522 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.29316 (* 1 = 8.29316 loss)
I0524 06:35:37.083761 11654 sgd_solver.cpp:112] Iteration 42440, lr = 0.1
I0524 06:35:45.132603 11654 solver.cpp:239] Iteration 42450 (1.19879 iter/s, 8.34175s/10 iters), loss = 6.0608
I0524 06:35:45.132833 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0608 (* 1 = 6.0608 loss)
I0524 06:35:45.132879 11654 sgd_solver.cpp:112] Iteration 42450, lr = 0.1
I0524 06:35:51.597120 11654 solver.cpp:239] Iteration 42460 (1.54703 iter/s, 6.46401s/10 iters), loss = 5.9548
I0524 06:35:51.597193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9548 (* 1 = 5.9548 loss)
I0524 06:35:51.597527 11654 sgd_solver.cpp:112] Iteration 42460, lr = 0.1
I0524 06:35:57.996443 11654 solver.cpp:239] Iteration 42470 (1.56275 iter/s, 6.39898s/10 iters), loss = 6.20385
I0524 06:35:57.996543 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20385 (* 1 = 6.20385 loss)
I0524 06:35:58.010824 11654 sgd_solver.cpp:112] Iteration 42470, lr = 0.1
I0524 06:36:05.789501 11654 solver.cpp:239] Iteration 42480 (1.28326 iter/s, 7.79265s/10 iters), loss = 7.32133
I0524 06:36:05.789602 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.32133 (* 1 = 7.32133 loss)
I0524 06:36:05.789830 11654 sgd_solver.cpp:112] Iteration 42480, lr = 0.1
I0524 06:36:13.379138 11654 solver.cpp:239] Iteration 42490 (1.31765 iter/s, 7.58926s/10 iters), loss = 6.17911
I0524 06:36:13.379221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17911 (* 1 = 6.17911 loss)
I0524 06:36:13.379251 11654 sgd_solver.cpp:112] Iteration 42490, lr = 0.1
I0524 06:36:20.669700 11654 solver.cpp:239] Iteration 42500 (1.37184 iter/s, 7.2895s/10 iters), loss = 5.58272
I0524 06:36:20.669953 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58272 (* 1 = 5.58272 loss)
I0524 06:36:20.669997 11654 sgd_solver.cpp:112] Iteration 42500, lr = 0.1
I0524 06:36:27.445235 11654 solver.cpp:239] Iteration 42510 (1.47601 iter/s, 6.77504s/10 iters), loss = 5.2856
I0524 06:36:27.445292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.2856 (* 1 = 5.2856 loss)
I0524 06:36:27.496531 11654 sgd_solver.cpp:112] Iteration 42510, lr = 0.1
I0524 06:36:34.304611 11654 solver.cpp:239] Iteration 42520 (1.45793 iter/s, 6.85904s/10 iters), loss = 6.01189
I0524 06:36:34.304669 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01189 (* 1 = 6.01189 loss)
I0524 06:36:34.304831 11654 sgd_solver.cpp:112] Iteration 42520, lr = 0.1
I0524 06:36:40.687225 11654 solver.cpp:239] Iteration 42530 (1.56683 iter/s, 6.3823s/10 iters), loss = 5.79198
I0524 06:36:40.687291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79198 (* 1 = 5.79198 loss)
I0524 06:36:40.687408 11654 sgd_solver.cpp:112] Iteration 42530, lr = 0.1
I0524 06:36:47.331321 11654 solver.cpp:239] Iteration 42540 (1.50517 iter/s, 6.64377s/10 iters), loss = 6.0583
I0524 06:36:47.331396 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0583 (* 1 = 6.0583 loss)
I0524 06:36:47.365351 11654 sgd_solver.cpp:112] Iteration 42540, lr = 0.1
I0524 06:36:56.799001 11654 solver.cpp:239] Iteration 42550 (1.05627 iter/s, 9.46725s/10 iters), loss = 6.17632
I0524 06:36:56.799206 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17632 (* 1 = 6.17632 loss)
I0524 06:36:56.799252 11654 sgd_solver.cpp:112] Iteration 42550, lr = 0.1
I0524 06:37:03.019368 11654 solver.cpp:239] Iteration 42560 (1.60774 iter/s, 6.2199s/10 iters), loss = 5.80535
I0524 06:37:03.019438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80535 (* 1 = 5.80535 loss)
I0524 06:37:03.019464 11654 sgd_solver.cpp:112] Iteration 42560, lr = 0.1
I0524 06:37:09.875413 11654 solver.cpp:239] Iteration 42570 (1.45865 iter/s, 6.85566s/10 iters), loss = 6.48165
I0524 06:37:09.875488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48165 (* 1 = 6.48165 loss)
I0524 06:37:09.875596 11654 sgd_solver.cpp:112] Iteration 42570, lr = 0.1
I0524 06:37:18.648378 11654 solver.cpp:239] Iteration 42580 (1.13992 iter/s, 8.77255s/10 iters), loss = 6.27426
I0524 06:37:18.648435 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27426 (* 1 = 6.27426 loss)
I0524 06:37:18.648703 11654 sgd_solver.cpp:112] Iteration 42580, lr = 0.1
I0524 06:37:25.795244 11654 solver.cpp:239] Iteration 42590 (1.39928 iter/s, 7.14654s/10 iters), loss = 4.94931
I0524 06:37:25.795287 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.94931 (* 1 = 4.94931 loss)
I0524 06:37:25.795303 11654 sgd_solver.cpp:112] Iteration 42590, lr = 0.1
I0524 06:37:35.130491 11654 solver.cpp:239] Iteration 42600 (1.07126 iter/s, 9.33476s/10 iters), loss = 6.79318
I0524 06:37:35.130642 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79318 (* 1 = 6.79318 loss)
I0524 06:37:36.364370 11654 sgd_solver.cpp:112] Iteration 42600, lr = 0.1
I0524 06:37:43.290818 11654 solver.cpp:239] Iteration 42610 (1.22551 iter/s, 8.15985s/10 iters), loss = 5.90487
I0524 06:37:43.290874 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90487 (* 1 = 5.90487 loss)
I0524 06:37:43.366600 11654 sgd_solver.cpp:112] Iteration 42610, lr = 0.1
I0524 06:37:49.665948 11654 solver.cpp:239] Iteration 42620 (1.56867 iter/s, 6.37483s/10 iters), loss = 5.92625
I0524 06:37:49.666009 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92625 (* 1 = 5.92625 loss)
I0524 06:37:49.704901 11654 sgd_solver.cpp:112] Iteration 42620, lr = 0.1
I0524 06:37:56.159621 11654 solver.cpp:239] Iteration 42630 (1.54004 iter/s, 6.49335s/10 iters), loss = 6.8586
I0524 06:37:56.159710 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8586 (* 1 = 6.8586 loss)
I0524 06:37:56.160177 11654 sgd_solver.cpp:112] Iteration 42630, lr = 0.1
I0524 06:38:03.243525 11654 solver.cpp:239] Iteration 42640 (1.41172 iter/s, 7.08355s/10 iters), loss = 5.73799
I0524 06:38:03.243582 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73799 (* 1 = 5.73799 loss)
I0524 06:38:03.456320 11654 sgd_solver.cpp:112] Iteration 42640, lr = 0.1
I0524 06:38:09.881687 11654 solver.cpp:239] Iteration 42650 (1.50651 iter/s, 6.63784s/10 iters), loss = 6.89041
I0524 06:38:09.881963 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89041 (* 1 = 6.89041 loss)
I0524 06:38:10.869912 11654 sgd_solver.cpp:112] Iteration 42650, lr = 0.1
I0524 06:38:19.053876 11654 solver.cpp:239] Iteration 42660 (1.09033 iter/s, 9.17158s/10 iters), loss = 6.67914
I0524 06:38:19.053947 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67914 (* 1 = 6.67914 loss)
I0524 06:38:19.054491 11654 sgd_solver.cpp:112] Iteration 42660, lr = 0.1
I0524 06:38:26.040277 11654 solver.cpp:239] Iteration 42670 (1.43142 iter/s, 6.98605s/10 iters), loss = 6.67577
I0524 06:38:26.040369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67577 (* 1 = 6.67577 loss)
I0524 06:38:26.040398 11654 sgd_solver.cpp:112] Iteration 42670, lr = 0.1
I0524 06:38:34.311287 11654 solver.cpp:239] Iteration 42680 (1.20919 iter/s, 8.27001s/10 iters), loss = 7.14061
I0524 06:38:34.311337 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14061 (* 1 = 7.14061 loss)
I0524 06:38:34.316812 11654 sgd_solver.cpp:112] Iteration 42680, lr = 0.1
I0524 06:38:40.612843 11654 solver.cpp:239] Iteration 42690 (1.58699 iter/s, 6.30125s/10 iters), loss = 6.50357
I0524 06:38:40.613087 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50357 (* 1 = 6.50357 loss)
I0524 06:38:40.635815 11654 sgd_solver.cpp:112] Iteration 42690, lr = 0.1
I0524 06:38:48.523355 11654 solver.cpp:239] Iteration 42700 (1.26423 iter/s, 7.90997s/10 iters), loss = 5.71685
I0524 06:38:48.523447 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71685 (* 1 = 5.71685 loss)
I0524 06:38:48.523478 11654 sgd_solver.cpp:112] Iteration 42700, lr = 0.1
I0524 06:38:55.510622 11654 solver.cpp:239] Iteration 42710 (1.43126 iter/s, 6.98687s/10 iters), loss = 5.62494
I0524 06:38:55.510689 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62494 (* 1 = 5.62494 loss)
I0524 06:38:55.510720 11654 sgd_solver.cpp:112] Iteration 42710, lr = 0.1
I0524 06:39:03.560256 11654 solver.cpp:239] Iteration 42720 (1.24235 iter/s, 8.04926s/10 iters), loss = 6.03488
I0524 06:39:03.560314 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03488 (* 1 = 6.03488 loss)
I0524 06:39:03.560330 11654 sgd_solver.cpp:112] Iteration 42720, lr = 0.1
I0524 06:39:12.226800 11654 solver.cpp:239] Iteration 42730 (1.15392 iter/s, 8.66609s/10 iters), loss = 6.44103
I0524 06:39:12.226965 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44103 (* 1 = 6.44103 loss)
I0524 06:39:12.865056 11654 sgd_solver.cpp:112] Iteration 42730, lr = 0.1
I0524 06:39:20.567293 11654 solver.cpp:239] Iteration 42740 (1.19904 iter/s, 8.34s/10 iters), loss = 5.85458
I0524 06:39:20.567361 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85458 (* 1 = 5.85458 loss)
I0524 06:39:21.362881 11654 sgd_solver.cpp:112] Iteration 42740, lr = 0.1
I0524 06:39:29.050341 11654 solver.cpp:239] Iteration 42750 (1.17888 iter/s, 8.48266s/10 iters), loss = 6.94092
I0524 06:39:29.050393 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94092 (* 1 = 6.94092 loss)
I0524 06:39:29.050411 11654 sgd_solver.cpp:112] Iteration 42750, lr = 0.1
I0524 06:39:36.023211 11654 solver.cpp:239] Iteration 42760 (1.43421 iter/s, 6.97248s/10 iters), loss = 5.82838
I0524 06:39:36.023268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82838 (* 1 = 5.82838 loss)
I0524 06:39:36.023288 11654 sgd_solver.cpp:112] Iteration 42760, lr = 0.1
I0524 06:39:42.633718 11654 solver.cpp:239] Iteration 42770 (1.51283 iter/s, 6.61014s/10 iters), loss = 7.27226
I0524 06:39:42.633970 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27226 (* 1 = 7.27226 loss)
I0524 06:39:42.634033 11654 sgd_solver.cpp:112] Iteration 42770, lr = 0.1
I0524 06:39:50.618180 11654 solver.cpp:239] Iteration 42780 (1.25252 iter/s, 7.98393s/10 iters), loss = 6.03557
I0524 06:39:50.618235 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03557 (* 1 = 6.03557 loss)
I0524 06:39:51.065408 11654 sgd_solver.cpp:112] Iteration 42780, lr = 0.1
I0524 06:39:58.496753 11654 solver.cpp:239] Iteration 42790 (1.26932 iter/s, 7.87821s/10 iters), loss = 6.04959
I0524 06:39:58.496829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04959 (* 1 = 6.04959 loss)
I0524 06:39:58.693951 11654 sgd_solver.cpp:112] Iteration 42790, lr = 0.1
I0524 06:40:08.209708 11654 solver.cpp:239] Iteration 42800 (1.0296 iter/s, 9.71252s/10 iters), loss = 6.66269
I0524 06:40:08.209764 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66269 (* 1 = 6.66269 loss)
I0524 06:40:08.209944 11654 sgd_solver.cpp:112] Iteration 42800, lr = 0.1
I0524 06:40:15.053558 11654 solver.cpp:239] Iteration 42810 (1.46124 iter/s, 6.84352s/10 iters), loss = 5.33011
I0524 06:40:15.053769 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.33011 (* 1 = 5.33011 loss)
I0524 06:40:15.053791 11654 sgd_solver.cpp:112] Iteration 42810, lr = 0.1
I0524 06:40:21.535836 11654 solver.cpp:239] Iteration 42820 (1.54281 iter/s, 6.48169s/10 iters), loss = 5.4685
I0524 06:40:21.535894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4685 (* 1 = 5.4685 loss)
I0524 06:40:21.536033 11654 sgd_solver.cpp:112] Iteration 42820, lr = 0.1
I0524 06:40:30.398329 11654 solver.cpp:239] Iteration 42830 (1.1284 iter/s, 8.86209s/10 iters), loss = 5.94344
I0524 06:40:30.398387 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94344 (* 1 = 5.94344 loss)
I0524 06:40:30.511646 11654 sgd_solver.cpp:112] Iteration 42830, lr = 0.1
I0524 06:40:37.092972 11654 solver.cpp:239] Iteration 42840 (1.4938 iter/s, 6.69432s/10 iters), loss = 5.93536
I0524 06:40:37.093030 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93536 (* 1 = 5.93536 loss)
I0524 06:40:37.093181 11654 sgd_solver.cpp:112] Iteration 42840, lr = 0.1
I0524 06:40:44.396670 11654 solver.cpp:239] Iteration 42850 (1.36923 iter/s, 7.30336s/10 iters), loss = 6.41467
I0524 06:40:44.396724 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41467 (* 1 = 6.41467 loss)
I0524 06:40:44.411792 11654 sgd_solver.cpp:112] Iteration 42850, lr = 0.1
I0524 06:40:50.999307 11654 solver.cpp:239] Iteration 42860 (1.51462 iter/s, 6.60232s/10 iters), loss = 5.69349
I0524 06:40:50.999507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69349 (* 1 = 5.69349 loss)
I0524 06:40:50.999613 11654 sgd_solver.cpp:112] Iteration 42860, lr = 0.1
I0524 06:40:57.414566 11654 solver.cpp:239] Iteration 42870 (1.55889 iter/s, 6.41481s/10 iters), loss = 6.40046
I0524 06:40:57.414618 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40046 (* 1 = 6.40046 loss)
I0524 06:40:57.414638 11654 sgd_solver.cpp:112] Iteration 42870, lr = 0.1
I0524 06:41:05.995985 11654 solver.cpp:239] Iteration 42880 (1.16536 iter/s, 8.58102s/10 iters), loss = 6.11925
I0524 06:41:05.996058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11925 (* 1 = 6.11925 loss)
I0524 06:41:05.996187 11654 sgd_solver.cpp:112] Iteration 42880, lr = 0.1
I0524 06:41:13.299831 11654 solver.cpp:239] Iteration 42890 (1.36921 iter/s, 7.3035s/10 iters), loss = 7.14402
I0524 06:41:13.299882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.14402 (* 1 = 7.14402 loss)
I0524 06:41:13.299898 11654 sgd_solver.cpp:112] Iteration 42890, lr = 0.1
I0524 06:41:21.060904 11654 solver.cpp:239] Iteration 42900 (1.28854 iter/s, 7.76072s/10 iters), loss = 6.15198
I0524 06:41:21.061098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15198 (* 1 = 6.15198 loss)
I0524 06:41:21.646678 11654 sgd_solver.cpp:112] Iteration 42900, lr = 0.1
I0524 06:41:28.189927 11654 solver.cpp:239] Iteration 42910 (1.40281 iter/s, 7.12855s/10 iters), loss = 6.54554
I0524 06:41:28.190001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54554 (* 1 = 6.54554 loss)
I0524 06:41:28.190233 11654 sgd_solver.cpp:112] Iteration 42910, lr = 0.1
I0524 06:41:34.803045 11654 solver.cpp:239] Iteration 42920 (1.51222 iter/s, 6.61279s/10 iters), loss = 5.86924
I0524 06:41:34.803105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86924 (* 1 = 5.86924 loss)
I0524 06:41:34.803123 11654 sgd_solver.cpp:112] Iteration 42920, lr = 0.1
I0524 06:41:41.342028 11654 solver.cpp:239] Iteration 42930 (1.52938 iter/s, 6.5386s/10 iters), loss = 5.53146
I0524 06:41:41.342088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53146 (* 1 = 5.53146 loss)
I0524 06:41:41.428109 11654 sgd_solver.cpp:112] Iteration 42930, lr = 0.1
I0524 06:41:49.802999 11654 solver.cpp:239] Iteration 42940 (1.18195 iter/s, 8.46057s/10 iters), loss = 6.82001
I0524 06:41:49.803073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82001 (* 1 = 6.82001 loss)
I0524 06:41:49.960551 11654 sgd_solver.cpp:112] Iteration 42940, lr = 0.1
I0524 06:41:57.739372 11654 solver.cpp:239] Iteration 42950 (1.26008 iter/s, 7.936s/10 iters), loss = 6.79264
I0524 06:41:57.739634 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79264 (* 1 = 6.79264 loss)
I0524 06:41:57.795814 11654 sgd_solver.cpp:112] Iteration 42950, lr = 0.1
I0524 06:42:06.148124 11654 solver.cpp:239] Iteration 42960 (1.18932 iter/s, 8.40819s/10 iters), loss = 6.47544
I0524 06:42:06.148202 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47544 (* 1 = 6.47544 loss)
I0524 06:42:06.148223 11654 sgd_solver.cpp:112] Iteration 42960, lr = 0.1
I0524 06:42:15.046511 11654 solver.cpp:239] Iteration 42970 (1.12386 iter/s, 8.8979s/10 iters), loss = 5.5698
I0524 06:42:15.046581 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5698 (* 1 = 5.5698 loss)
I0524 06:42:15.046602 11654 sgd_solver.cpp:112] Iteration 42970, lr = 0.1
I0524 06:42:21.740947 11654 solver.cpp:239] Iteration 42980 (1.49434 iter/s, 6.69192s/10 iters), loss = 5.9906
I0524 06:42:21.741011 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9906 (* 1 = 5.9906 loss)
I0524 06:42:22.478224 11654 sgd_solver.cpp:112] Iteration 42980, lr = 0.1
I0524 06:42:29.425760 11654 solver.cpp:239] Iteration 42990 (1.30133 iter/s, 7.68446s/10 iters), loss = 6.83397
I0524 06:42:29.425905 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83397 (* 1 = 6.83397 loss)
I0524 06:42:29.425961 11654 sgd_solver.cpp:112] Iteration 42990, lr = 0.1
I0524 06:42:36.958633 11654 solver.cpp:239] Iteration 43000 (1.32759 iter/s, 7.53243s/10 iters), loss = 7.21728
I0524 06:42:36.958691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21728 (* 1 = 7.21728 loss)
I0524 06:42:36.958724 11654 sgd_solver.cpp:112] Iteration 43000, lr = 0.1
I0524 06:42:43.995371 11654 solver.cpp:239] Iteration 43010 (1.42118 iter/s, 7.0364s/10 iters), loss = 6.91927
I0524 06:42:43.995434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91927 (* 1 = 6.91927 loss)
I0524 06:42:44.114553 11654 sgd_solver.cpp:112] Iteration 43010, lr = 0.1
I0524 06:42:51.976613 11654 solver.cpp:239] Iteration 43020 (1.253 iter/s, 7.98085s/10 iters), loss = 7.67447
I0524 06:42:51.976701 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.67447 (* 1 = 7.67447 loss)
I0524 06:42:51.976734 11654 sgd_solver.cpp:112] Iteration 43020, lr = 0.1
I0524 06:42:58.953035 11654 solver.cpp:239] Iteration 43030 (1.43347 iter/s, 6.97608s/10 iters), loss = 6.0207
I0524 06:42:58.953096 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0207 (* 1 = 6.0207 loss)
I0524 06:42:58.953238 11654 sgd_solver.cpp:112] Iteration 43030, lr = 0.1
I0524 06:43:07.466987 11654 solver.cpp:239] Iteration 43040 (1.1746 iter/s, 8.51356s/10 iters), loss = 5.3969
I0524 06:43:07.467195 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3969 (* 1 = 5.3969 loss)
I0524 06:43:07.476753 11654 sgd_solver.cpp:112] Iteration 43040, lr = 0.1
I0524 06:43:14.386304 11654 solver.cpp:239] Iteration 43050 (1.44533 iter/s, 6.91885s/10 iters), loss = 4.97452
I0524 06:43:14.386364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.97452 (* 1 = 4.97452 loss)
I0524 06:43:14.386520 11654 sgd_solver.cpp:112] Iteration 43050, lr = 0.1
I0524 06:43:21.630760 11654 solver.cpp:239] Iteration 43060 (1.38044 iter/s, 7.24408s/10 iters), loss = 5.94516
I0524 06:43:21.630818 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94516 (* 1 = 5.94516 loss)
I0524 06:43:21.909176 11654 sgd_solver.cpp:112] Iteration 43060, lr = 0.1
I0524 06:43:28.640064 11654 solver.cpp:239] Iteration 43070 (1.42674 iter/s, 7.00897s/10 iters), loss = 5.3292
I0524 06:43:28.640136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3292 (* 1 = 5.3292 loss)
I0524 06:43:28.640285 11654 sgd_solver.cpp:112] Iteration 43070, lr = 0.1
I0524 06:43:35.953061 11654 solver.cpp:239] Iteration 43080 (1.3675 iter/s, 7.3126s/10 iters), loss = 6.89345
I0524 06:43:35.953209 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89345 (* 1 = 6.89345 loss)
I0524 06:43:36.712018 11654 sgd_solver.cpp:112] Iteration 43080, lr = 0.1
I0524 06:43:43.766470 11654 solver.cpp:239] Iteration 43090 (1.27992 iter/s, 7.81297s/10 iters), loss = 6.84443
I0524 06:43:43.766746 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84443 (* 1 = 6.84443 loss)
I0524 06:43:44.381990 11654 sgd_solver.cpp:112] Iteration 43090, lr = 0.1
I0524 06:43:50.853539 11654 solver.cpp:239] Iteration 43100 (1.41113 iter/s, 7.08654s/10 iters), loss = 5.28009
I0524 06:43:50.853658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28009 (* 1 = 5.28009 loss)
I0524 06:43:50.937340 11654 sgd_solver.cpp:112] Iteration 43100, lr = 0.1
I0524 06:43:57.363235 11654 solver.cpp:239] Iteration 43110 (1.53625 iter/s, 6.50936s/10 iters), loss = 6.31722
I0524 06:43:57.363277 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31722 (* 1 = 6.31722 loss)
I0524 06:43:57.363293 11654 sgd_solver.cpp:112] Iteration 43110, lr = 0.1
I0524 06:44:04.983680 11654 solver.cpp:239] Iteration 43120 (1.31233 iter/s, 7.62002s/10 iters), loss = 5.80937
I0524 06:44:04.983752 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80937 (* 1 = 5.80937 loss)
I0524 06:44:04.984235 11654 sgd_solver.cpp:112] Iteration 43120, lr = 0.1
I0524 06:44:13.681571 11654 solver.cpp:239] Iteration 43130 (1.14976 iter/s, 8.69745s/10 iters), loss = 6.1995
I0524 06:44:13.681633 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1995 (* 1 = 6.1995 loss)
I0524 06:44:13.681722 11654 sgd_solver.cpp:112] Iteration 43130, lr = 0.1
I0524 06:44:22.062690 11654 solver.cpp:239] Iteration 43140 (1.19322 iter/s, 8.38071s/10 iters), loss = 6.01362
I0524 06:44:22.062947 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01362 (* 1 = 6.01362 loss)
I0524 06:44:22.717316 11654 sgd_solver.cpp:112] Iteration 43140, lr = 0.1
I0524 06:44:29.533792 11654 solver.cpp:239] Iteration 43150 (1.33859 iter/s, 7.47057s/10 iters), loss = 6.3182
I0524 06:44:29.533875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3182 (* 1 = 6.3182 loss)
I0524 06:44:29.534071 11654 sgd_solver.cpp:112] Iteration 43150, lr = 0.1
I0524 06:44:36.010452 11654 solver.cpp:239] Iteration 43160 (1.54409 iter/s, 6.47632s/10 iters), loss = 5.8583
I0524 06:44:36.010526 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8583 (* 1 = 5.8583 loss)
I0524 06:44:36.010550 11654 sgd_solver.cpp:112] Iteration 43160, lr = 0.1
I0524 06:44:42.449390 11654 solver.cpp:239] Iteration 43170 (1.55314 iter/s, 6.43859s/10 iters), loss = 5.58372
I0524 06:44:42.449455 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58372 (* 1 = 5.58372 loss)
I0524 06:44:42.449573 11654 sgd_solver.cpp:112] Iteration 43170, lr = 0.1
I0524 06:44:51.402279 11654 solver.cpp:239] Iteration 43180 (1.11701 iter/s, 8.95249s/10 iters), loss = 5.54504
I0524 06:44:51.402349 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54504 (* 1 = 5.54504 loss)
I0524 06:44:51.441354 11654 sgd_solver.cpp:112] Iteration 43180, lr = 0.1
I0524 06:45:00.177088 11654 solver.cpp:239] Iteration 43190 (1.13968 iter/s, 8.77439s/10 iters), loss = 5.4457
I0524 06:45:00.177350 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4457 (* 1 = 5.4457 loss)
I0524 06:45:00.177399 11654 sgd_solver.cpp:112] Iteration 43190, lr = 0.1
I0524 06:45:10.481647 11654 solver.cpp:239] Iteration 43200 (0.970508 iter/s, 10.3039s/10 iters), loss = 5.77197
I0524 06:45:10.481732 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77197 (* 1 = 5.77197 loss)
I0524 06:45:10.481865 11654 sgd_solver.cpp:112] Iteration 43200, lr = 0.1
I0524 06:45:16.793457 11654 solver.cpp:239] Iteration 43210 (1.58441 iter/s, 6.3115s/10 iters), loss = 5.48747
I0524 06:45:16.793501 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48747 (* 1 = 5.48747 loss)
I0524 06:45:17.500777 11654 sgd_solver.cpp:112] Iteration 43210, lr = 0.1
I0524 06:45:23.737839 11654 solver.cpp:239] Iteration 43220 (1.44008 iter/s, 6.94405s/10 iters), loss = 6.76483
I0524 06:45:23.737907 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76483 (* 1 = 6.76483 loss)
I0524 06:45:23.738196 11654 sgd_solver.cpp:112] Iteration 43220, lr = 0.1
I0524 06:45:32.460626 11654 solver.cpp:239] Iteration 43230 (1.14647 iter/s, 8.72239s/10 iters), loss = 5.14831
I0524 06:45:32.460901 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.14831 (* 1 = 5.14831 loss)
I0524 06:45:32.460937 11654 sgd_solver.cpp:112] Iteration 43230, lr = 0.1
I0524 06:45:40.348044 11654 solver.cpp:239] Iteration 43240 (1.26797 iter/s, 7.8866s/10 iters), loss = 5.36125
I0524 06:45:40.348140 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.36125 (* 1 = 5.36125 loss)
I0524 06:45:40.348178 11654 sgd_solver.cpp:112] Iteration 43240, lr = 0.1
I0524 06:45:46.954903 11654 solver.cpp:239] Iteration 43250 (1.51365 iter/s, 6.60653s/10 iters), loss = 5.75617
I0524 06:45:46.954994 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75617 (* 1 = 5.75617 loss)
I0524 06:45:47.044613 11654 sgd_solver.cpp:112] Iteration 43250, lr = 0.1
I0524 06:45:56.245553 11654 solver.cpp:239] Iteration 43260 (1.0764 iter/s, 9.29021s/10 iters), loss = 6.29046
I0524 06:45:56.245615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29046 (* 1 = 6.29046 loss)
I0524 06:45:56.245635 11654 sgd_solver.cpp:112] Iteration 43260, lr = 0.1
I0524 06:46:02.712501 11654 solver.cpp:239] Iteration 43270 (1.54641 iter/s, 6.46658s/10 iters), loss = 6.16306
I0524 06:46:02.712762 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16306 (* 1 = 6.16306 loss)
I0524 06:46:02.712812 11654 sgd_solver.cpp:112] Iteration 43270, lr = 0.1
I0524 06:46:10.571293 11654 solver.cpp:239] Iteration 43280 (1.2726 iter/s, 7.8579s/10 iters), loss = 5.70807
I0524 06:46:10.571352 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70807 (* 1 = 5.70807 loss)
I0524 06:46:10.571368 11654 sgd_solver.cpp:112] Iteration 43280, lr = 0.1
I0524 06:46:19.941826 11654 solver.cpp:239] Iteration 43290 (1.06723 iter/s, 9.37002s/10 iters), loss = 6.62806
I0524 06:46:19.941890 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62806 (* 1 = 6.62806 loss)
I0524 06:46:19.941915 11654 sgd_solver.cpp:112] Iteration 43290, lr = 0.1
I0524 06:46:27.909015 11654 solver.cpp:239] Iteration 43300 (1.25521 iter/s, 7.96677s/10 iters), loss = 6.45336
I0524 06:46:27.909096 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45336 (* 1 = 6.45336 loss)
I0524 06:46:28.298358 11654 sgd_solver.cpp:112] Iteration 43300, lr = 0.1
I0524 06:46:36.040308 11654 solver.cpp:239] Iteration 43310 (1.22988 iter/s, 8.1309s/10 iters), loss = 5.65664
I0524 06:46:36.040500 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65664 (* 1 = 5.65664 loss)
I0524 06:46:36.040540 11654 sgd_solver.cpp:112] Iteration 43310, lr = 0.1
I0524 06:46:43.966542 11654 solver.cpp:239] Iteration 43320 (1.26172 iter/s, 7.92571s/10 iters), loss = 5.80275
I0524 06:46:43.966595 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80275 (* 1 = 5.80275 loss)
I0524 06:46:43.966611 11654 sgd_solver.cpp:112] Iteration 43320, lr = 0.1
I0524 06:46:50.969192 11654 solver.cpp:239] Iteration 43330 (1.42815 iter/s, 7.00209s/10 iters), loss = 5.86501
I0524 06:46:50.969238 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86501 (* 1 = 5.86501 loss)
I0524 06:46:50.969250 11654 sgd_solver.cpp:112] Iteration 43330, lr = 0.1
I0524 06:46:57.805541 11654 solver.cpp:239] Iteration 43340 (1.46297 iter/s, 6.83539s/10 iters), loss = 6.74051
I0524 06:46:57.805615 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74051 (* 1 = 6.74051 loss)
I0524 06:46:57.901551 11654 sgd_solver.cpp:112] Iteration 43340, lr = 0.1
I0524 06:47:07.356807 11654 solver.cpp:239] Iteration 43350 (1.04703 iter/s, 9.55082s/10 iters), loss = 6.06862
I0524 06:47:07.357122 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06862 (* 1 = 6.06862 loss)
I0524 06:47:08.473717 11654 sgd_solver.cpp:112] Iteration 43350, lr = 0.1
I0524 06:47:15.254230 11654 solver.cpp:239] Iteration 43360 (1.26634 iter/s, 7.8968s/10 iters), loss = 6.83375
I0524 06:47:15.254295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83375 (* 1 = 6.83375 loss)
I0524 06:47:15.745777 11654 sgd_solver.cpp:112] Iteration 43360, lr = 0.1
I0524 06:47:22.957948 11654 solver.cpp:239] Iteration 43370 (1.29814 iter/s, 7.70334s/10 iters), loss = 7.06784
I0524 06:47:22.958029 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06784 (* 1 = 7.06784 loss)
I0524 06:47:23.273524 11654 sgd_solver.cpp:112] Iteration 43370, lr = 0.1
I0524 06:47:31.470654 11654 solver.cpp:239] Iteration 43380 (1.17477 iter/s, 8.51232s/10 iters), loss = 7.63465
I0524 06:47:31.470716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.63465 (* 1 = 7.63465 loss)
I0524 06:47:31.506716 11654 sgd_solver.cpp:112] Iteration 43380, lr = 0.1
I0524 06:47:39.689152 11654 solver.cpp:239] Iteration 43390 (1.21683 iter/s, 8.21811s/10 iters), loss = 5.49746
I0524 06:47:39.689450 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49746 (* 1 = 5.49746 loss)
I0524 06:47:39.759970 11654 sgd_solver.cpp:112] Iteration 43390, lr = 0.1
I0524 06:47:48.378399 11654 solver.cpp:239] Iteration 43400 (1.15092 iter/s, 8.68868s/10 iters), loss = 7.08291
I0524 06:47:48.378453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08291 (* 1 = 7.08291 loss)
I0524 06:47:48.378473 11654 sgd_solver.cpp:112] Iteration 43400, lr = 0.1
I0524 06:47:54.791735 11654 solver.cpp:239] Iteration 43410 (1.55934 iter/s, 6.41298s/10 iters), loss = 6.94693
I0524 06:47:54.791895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94693 (* 1 = 6.94693 loss)
I0524 06:47:54.791941 11654 sgd_solver.cpp:112] Iteration 43410, lr = 0.1
I0524 06:48:01.537119 11654 solver.cpp:239] Iteration 43420 (1.48271 iter/s, 6.74439s/10 iters), loss = 6.53925
I0524 06:48:01.537189 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53925 (* 1 = 6.53925 loss)
I0524 06:48:01.537277 11654 sgd_solver.cpp:112] Iteration 43420, lr = 0.1
I0524 06:48:08.463341 11654 solver.cpp:239] Iteration 43430 (1.44386 iter/s, 6.92589s/10 iters), loss = 6.91615
I0524 06:48:08.463388 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91615 (* 1 = 6.91615 loss)
I0524 06:48:09.062104 11654 sgd_solver.cpp:112] Iteration 43430, lr = 0.1
I0524 06:48:16.310377 11654 solver.cpp:239] Iteration 43440 (1.27443 iter/s, 7.84665s/10 iters), loss = 6.66307
I0524 06:48:16.310498 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66307 (* 1 = 6.66307 loss)
I0524 06:48:16.869832 11654 sgd_solver.cpp:112] Iteration 43440, lr = 0.1
I0524 06:48:26.467007 11654 solver.cpp:239] Iteration 43450 (0.984626 iter/s, 10.1561s/10 iters), loss = 5.66009
I0524 06:48:26.467088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66009 (* 1 = 5.66009 loss)
I0524 06:48:26.473799 11654 sgd_solver.cpp:112] Iteration 43450, lr = 0.1
I0524 06:48:35.681622 11654 solver.cpp:239] Iteration 43460 (1.08528 iter/s, 9.21419s/10 iters), loss = 7.13292
I0524 06:48:35.681674 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13292 (* 1 = 7.13292 loss)
I0524 06:48:35.955884 11654 sgd_solver.cpp:112] Iteration 43460, lr = 0.1
I0524 06:48:44.355192 11654 solver.cpp:239] Iteration 43470 (1.15298 iter/s, 8.67317s/10 iters), loss = 6.03438
I0524 06:48:44.355267 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03438 (* 1 = 6.03438 loss)
I0524 06:48:44.386445 11654 sgd_solver.cpp:112] Iteration 43470, lr = 0.1
I0524 06:48:51.479326 11654 solver.cpp:239] Iteration 43480 (1.40375 iter/s, 7.12378s/10 iters), loss = 6.8045
I0524 06:48:51.479599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8045 (* 1 = 6.8045 loss)
I0524 06:48:51.479677 11654 sgd_solver.cpp:112] Iteration 43480, lr = 0.1
I0524 06:48:57.855362 11654 solver.cpp:239] Iteration 43490 (1.5685 iter/s, 6.37552s/10 iters), loss = 6.50339
I0524 06:48:57.855463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50339 (* 1 = 6.50339 loss)
I0524 06:48:57.863111 11654 sgd_solver.cpp:112] Iteration 43490, lr = 0.1
I0524 06:49:05.576500 11654 solver.cpp:239] Iteration 43500 (1.29521 iter/s, 7.72076s/10 iters), loss = 6.65691
I0524 06:49:05.576609 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65691 (* 1 = 6.65691 loss)
I0524 06:49:05.603436 11654 sgd_solver.cpp:112] Iteration 43500, lr = 0.1
I0524 06:49:14.305980 11654 solver.cpp:239] Iteration 43510 (1.1456 iter/s, 8.72903s/10 iters), loss = 6.09261
I0524 06:49:14.306130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09261 (* 1 = 6.09261 loss)
I0524 06:49:14.306174 11654 sgd_solver.cpp:112] Iteration 43510, lr = 0.1
I0524 06:49:20.942596 11654 solver.cpp:239] Iteration 43520 (1.50736 iter/s, 6.63412s/10 iters), loss = 6.0414
I0524 06:49:20.942634 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0414 (* 1 = 6.0414 loss)
I0524 06:49:21.372853 11654 sgd_solver.cpp:112] Iteration 43520, lr = 0.1
I0524 06:49:28.870133 11654 solver.cpp:239] Iteration 43530 (1.26148 iter/s, 7.92718s/10 iters), loss = 5.43405
I0524 06:49:28.870296 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.43405 (* 1 = 5.43405 loss)
I0524 06:49:28.870362 11654 sgd_solver.cpp:112] Iteration 43530, lr = 0.1
I0524 06:49:35.759788 11654 solver.cpp:239] Iteration 43540 (1.45155 iter/s, 6.8892s/10 iters), loss = 6.2458
I0524 06:49:35.759850 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2458 (* 1 = 6.2458 loss)
I0524 06:49:35.765357 11654 sgd_solver.cpp:112] Iteration 43540, lr = 0.1
I0524 06:49:43.833248 11654 solver.cpp:239] Iteration 43550 (1.23869 iter/s, 8.07306s/10 iters), loss = 6.75492
I0524 06:49:43.833312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75492 (* 1 = 6.75492 loss)
I0524 06:49:44.575664 11654 sgd_solver.cpp:112] Iteration 43550, lr = 0.1
I0524 06:49:51.219158 11654 solver.cpp:239] Iteration 43560 (1.35399 iter/s, 7.38556s/10 iters), loss = 6.73024
I0524 06:49:51.219266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73024 (* 1 = 6.73024 loss)
I0524 06:49:51.219286 11654 sgd_solver.cpp:112] Iteration 43560, lr = 0.1
I0524 06:49:58.289695 11654 solver.cpp:239] Iteration 43570 (1.41441 iter/s, 7.0701s/10 iters), loss = 4.90464
I0524 06:49:58.289764 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.90464 (* 1 = 4.90464 loss)
I0524 06:49:58.289980 11654 sgd_solver.cpp:112] Iteration 43570, lr = 0.1
I0524 06:50:04.587257 11654 solver.cpp:239] Iteration 43580 (1.58799 iter/s, 6.29725s/10 iters), loss = 6.91395
I0524 06:50:04.587498 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91395 (* 1 = 6.91395 loss)
I0524 06:50:04.587543 11654 sgd_solver.cpp:112] Iteration 43580, lr = 0.1
I0524 06:50:12.059079 11654 solver.cpp:239] Iteration 43590 (1.33855 iter/s, 7.4708s/10 iters), loss = 6.27299
I0524 06:50:12.059208 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27299 (* 1 = 6.27299 loss)
I0524 06:50:12.059245 11654 sgd_solver.cpp:112] Iteration 43590, lr = 0.1
I0524 06:50:21.302496 11654 solver.cpp:239] Iteration 43600 (1.0819 iter/s, 9.24296s/10 iters), loss = 5.81464
I0524 06:50:21.302565 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81464 (* 1 = 5.81464 loss)
I0524 06:50:21.302588 11654 sgd_solver.cpp:112] Iteration 43600, lr = 0.1
I0524 06:50:28.219293 11654 solver.cpp:239] Iteration 43610 (1.44583 iter/s, 6.91643s/10 iters), loss = 6.57449
I0524 06:50:28.219341 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57449 (* 1 = 6.57449 loss)
I0524 06:50:28.226259 11654 sgd_solver.cpp:112] Iteration 43610, lr = 0.1
I0524 06:50:35.627300 11654 solver.cpp:239] Iteration 43620 (1.34996 iter/s, 7.40764s/10 iters), loss = 5.50937
I0524 06:50:35.627614 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50937 (* 1 = 5.50937 loss)
I0524 06:50:35.627823 11654 sgd_solver.cpp:112] Iteration 43620, lr = 0.1
I0524 06:50:42.634347 11654 solver.cpp:239] Iteration 43630 (1.42724 iter/s, 7.00653s/10 iters), loss = 6.44691
I0524 06:50:42.634410 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44691 (* 1 = 6.44691 loss)
I0524 06:50:42.634428 11654 sgd_solver.cpp:112] Iteration 43630, lr = 0.1
I0524 06:50:52.036191 11654 solver.cpp:239] Iteration 43640 (1.06367 iter/s, 9.40142s/10 iters), loss = 6.02083
I0524 06:50:52.036258 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02083 (* 1 = 6.02083 loss)
I0524 06:50:52.036442 11654 sgd_solver.cpp:112] Iteration 43640, lr = 0.1
I0524 06:50:59.762233 11654 solver.cpp:239] Iteration 43650 (1.29438 iter/s, 7.72568s/10 iters), loss = 6.59653
I0524 06:50:59.762310 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59653 (* 1 = 6.59653 loss)
I0524 06:50:59.762430 11654 sgd_solver.cpp:112] Iteration 43650, lr = 0.1
I0524 06:51:07.424540 11654 solver.cpp:239] Iteration 43660 (1.30515 iter/s, 7.66196s/10 iters), loss = 6.81123
I0524 06:51:07.424697 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81123 (* 1 = 6.81123 loss)
I0524 06:51:07.424713 11654 sgd_solver.cpp:112] Iteration 43660, lr = 0.1
I0524 06:51:15.563820 11654 solver.cpp:239] Iteration 43670 (1.22869 iter/s, 8.13878s/10 iters), loss = 6.89447
I0524 06:51:15.563899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89447 (* 1 = 6.89447 loss)
I0524 06:51:15.715173 11654 sgd_solver.cpp:112] Iteration 43670, lr = 0.1
I0524 06:51:24.283028 11654 solver.cpp:239] Iteration 43680 (1.14695 iter/s, 8.71881s/10 iters), loss = 5.96789
I0524 06:51:24.283108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96789 (* 1 = 5.96789 loss)
I0524 06:51:24.283321 11654 sgd_solver.cpp:112] Iteration 43680, lr = 0.1
I0524 06:51:31.149607 11654 solver.cpp:239] Iteration 43690 (1.4564 iter/s, 6.86623s/10 iters), loss = 6.59863
I0524 06:51:31.149680 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59863 (* 1 = 6.59863 loss)
I0524 06:51:31.175055 11654 sgd_solver.cpp:112] Iteration 43690, lr = 0.1
I0524 06:51:37.753669 11654 solver.cpp:239] Iteration 43700 (1.5143 iter/s, 6.6037s/10 iters), loss = 6.30336
I0524 06:51:37.753906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30336 (* 1 = 6.30336 loss)
I0524 06:51:38.388742 11654 sgd_solver.cpp:112] Iteration 43700, lr = 0.1
I0524 06:51:45.147459 11654 solver.cpp:239] Iteration 43710 (1.35258 iter/s, 7.3933s/10 iters), loss = 6.57204
I0524 06:51:45.147526 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57204 (* 1 = 6.57204 loss)
I0524 06:51:45.444061 11654 sgd_solver.cpp:112] Iteration 43710, lr = 0.1
I0524 06:51:52.956025 11654 solver.cpp:239] Iteration 43720 (1.2807 iter/s, 7.80821s/10 iters), loss = 6.41043
I0524 06:51:52.956066 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41043 (* 1 = 6.41043 loss)
I0524 06:51:52.956343 11654 sgd_solver.cpp:112] Iteration 43720, lr = 0.1
I0524 06:52:01.012470 11654 solver.cpp:239] Iteration 43730 (1.2413 iter/s, 8.05606s/10 iters), loss = 6.21354
I0524 06:52:01.012603 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21354 (* 1 = 6.21354 loss)
I0524 06:52:01.012629 11654 sgd_solver.cpp:112] Iteration 43730, lr = 0.1
I0524 06:52:09.139861 11654 solver.cpp:239] Iteration 43740 (1.23047 iter/s, 8.12699s/10 iters), loss = 6.03036
I0524 06:52:09.140087 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03036 (* 1 = 6.03036 loss)
I0524 06:52:09.324623 11654 sgd_solver.cpp:112] Iteration 43740, lr = 0.1
I0524 06:52:16.611907 11654 solver.cpp:239] Iteration 43750 (1.33842 iter/s, 7.47151s/10 iters), loss = 5.74274
I0524 06:52:16.611974 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74274 (* 1 = 5.74274 loss)
I0524 06:52:16.659541 11654 sgd_solver.cpp:112] Iteration 43750, lr = 0.1
I0524 06:52:23.063822 11654 solver.cpp:239] Iteration 43760 (1.55001 iter/s, 6.45159s/10 iters), loss = 6.16741
I0524 06:52:23.063896 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16741 (* 1 = 6.16741 loss)
I0524 06:52:23.063920 11654 sgd_solver.cpp:112] Iteration 43760, lr = 0.1
I0524 06:52:31.543720 11654 solver.cpp:239] Iteration 43770 (1.17932 iter/s, 8.4795s/10 iters), loss = 5.78708
I0524 06:52:31.543795 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78708 (* 1 = 5.78708 loss)
I0524 06:52:31.543815 11654 sgd_solver.cpp:112] Iteration 43770, lr = 0.1
I0524 06:52:38.458537 11654 solver.cpp:239] Iteration 43780 (1.44626 iter/s, 6.9144s/10 iters), loss = 6.28823
I0524 06:52:38.458755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28823 (* 1 = 6.28823 loss)
I0524 06:52:38.458804 11654 sgd_solver.cpp:112] Iteration 43780, lr = 0.1
I0524 06:52:45.938261 11654 solver.cpp:239] Iteration 43790 (1.33702 iter/s, 7.47934s/10 iters), loss = 6.41167
I0524 06:52:45.938606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41167 (* 1 = 6.41167 loss)
I0524 06:52:45.938661 11654 sgd_solver.cpp:112] Iteration 43790, lr = 0.1
I0524 06:52:52.891551 11654 solver.cpp:239] Iteration 43800 (1.43828 iter/s, 6.95273s/10 iters), loss = 6.91541
I0524 06:52:52.891608 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91541 (* 1 = 6.91541 loss)
I0524 06:52:53.175323 11654 sgd_solver.cpp:112] Iteration 43800, lr = 0.1
I0524 06:53:00.448191 11654 solver.cpp:239] Iteration 43810 (1.32341 iter/s, 7.55626s/10 iters), loss = 6.79775
I0524 06:53:00.448338 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79775 (* 1 = 6.79775 loss)
I0524 06:53:00.448372 11654 sgd_solver.cpp:112] Iteration 43810, lr = 0.1
I0524 06:53:09.274718 11654 solver.cpp:239] Iteration 43820 (1.133 iter/s, 8.8261s/10 iters), loss = 6.94009
I0524 06:53:09.274791 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94009 (* 1 = 6.94009 loss)
I0524 06:53:09.274807 11654 sgd_solver.cpp:112] Iteration 43820, lr = 0.1
I0524 06:53:15.780097 11654 solver.cpp:239] Iteration 43830 (1.53728 iter/s, 6.50501s/10 iters), loss = 4.91373
I0524 06:53:15.780141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.91373 (* 1 = 4.91373 loss)
I0524 06:53:15.780380 11654 sgd_solver.cpp:112] Iteration 43830, lr = 0.1
I0524 06:53:24.952306 11654 solver.cpp:239] Iteration 43840 (1.0903 iter/s, 9.17179s/10 iters), loss = 5.66919
I0524 06:53:24.952420 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66919 (* 1 = 5.66919 loss)
I0524 06:53:24.952742 11654 sgd_solver.cpp:112] Iteration 43840, lr = 0.1
I0524 06:53:31.539813 11654 solver.cpp:239] Iteration 43850 (1.51811 iter/s, 6.58713s/10 iters), loss = 5.95929
I0524 06:53:31.539878 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95929 (* 1 = 5.95929 loss)
I0524 06:53:31.561269 11654 sgd_solver.cpp:112] Iteration 43850, lr = 0.1
I0524 06:53:39.905103 11654 solver.cpp:239] Iteration 43860 (1.19547 iter/s, 8.36491s/10 iters), loss = 5.36483
I0524 06:53:39.905185 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.36483 (* 1 = 5.36483 loss)
I0524 06:53:39.905210 11654 sgd_solver.cpp:112] Iteration 43860, lr = 0.1
I0524 06:53:46.139158 11654 solver.cpp:239] Iteration 43870 (1.60418 iter/s, 6.2337s/10 iters), loss = 5.89377
I0524 06:53:46.139238 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89377 (* 1 = 5.89377 loss)
I0524 06:53:46.139487 11654 sgd_solver.cpp:112] Iteration 43870, lr = 0.1
I0524 06:53:53.132746 11654 solver.cpp:239] Iteration 43880 (1.42995 iter/s, 6.99325s/10 iters), loss = 6.2997
I0524 06:53:53.132804 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2997 (* 1 = 6.2997 loss)
I0524 06:53:53.133018 11654 sgd_solver.cpp:112] Iteration 43880, lr = 0.1
I0524 06:54:00.141170 11654 solver.cpp:239] Iteration 43890 (1.42693 iter/s, 7.00807s/10 iters), loss = 5.84917
I0524 06:54:00.141417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84917 (* 1 = 5.84917 loss)
I0524 06:54:00.884568 11654 sgd_solver.cpp:112] Iteration 43890, lr = 0.1
I0524 06:54:08.287669 11654 solver.cpp:239] Iteration 43900 (1.22761 iter/s, 8.14592s/10 iters), loss = 7.20055
I0524 06:54:08.287808 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20055 (* 1 = 7.20055 loss)
I0524 06:54:08.287847 11654 sgd_solver.cpp:112] Iteration 43900, lr = 0.1
I0524 06:54:14.942317 11654 solver.cpp:239] Iteration 43910 (1.50327 iter/s, 6.65216s/10 iters), loss = 6.08738
I0524 06:54:14.942379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08738 (* 1 = 6.08738 loss)
I0524 06:54:14.942612 11654 sgd_solver.cpp:112] Iteration 43910, lr = 0.1
I0524 06:54:21.585999 11654 solver.cpp:239] Iteration 43920 (1.50526 iter/s, 6.64335s/10 iters), loss = 6.73147
I0524 06:54:21.586053 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73147 (* 1 = 6.73147 loss)
I0524 06:54:21.586184 11654 sgd_solver.cpp:112] Iteration 43920, lr = 0.1
I0524 06:54:28.908946 11654 solver.cpp:239] Iteration 43930 (1.36564 iter/s, 7.32256s/10 iters), loss = 6.40606
I0524 06:54:28.909050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40606 (* 1 = 6.40606 loss)
I0524 06:54:28.909150 11654 sgd_solver.cpp:112] Iteration 43930, lr = 0.1
I0524 06:54:35.853529 11654 solver.cpp:239] Iteration 43940 (1.44005 iter/s, 6.94421s/10 iters), loss = 6.51497
I0524 06:54:35.853672 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51497 (* 1 = 6.51497 loss)
I0524 06:54:35.854967 11654 sgd_solver.cpp:112] Iteration 43940, lr = 0.1
I0524 06:54:44.360061 11654 solver.cpp:239] Iteration 43950 (1.17563 iter/s, 8.50605s/10 iters), loss = 6.59763
I0524 06:54:44.360147 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59763 (* 1 = 6.59763 loss)
I0524 06:54:44.360206 11654 sgd_solver.cpp:112] Iteration 43950, lr = 0.1
I0524 06:54:50.576181 11654 solver.cpp:239] Iteration 43960 (1.6088 iter/s, 6.21582s/10 iters), loss = 6.01688
I0524 06:54:50.576249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01688 (* 1 = 6.01688 loss)
I0524 06:54:50.576508 11654 sgd_solver.cpp:112] Iteration 43960, lr = 0.1
I0524 06:54:58.397171 11654 solver.cpp:239] Iteration 43970 (1.27867 iter/s, 7.82062s/10 iters), loss = 6.38234
I0524 06:54:58.397228 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38234 (* 1 = 6.38234 loss)
I0524 06:54:58.398305 11654 sgd_solver.cpp:112] Iteration 43970, lr = 0.1
I0524 06:55:05.067009 11654 solver.cpp:239] Iteration 43980 (1.49936 iter/s, 6.66951s/10 iters), loss = 5.12549
I0524 06:55:05.067100 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.12549 (* 1 = 5.12549 loss)
I0524 06:55:05.067117 11654 sgd_solver.cpp:112] Iteration 43980, lr = 0.1
I0524 06:55:14.336324 11654 solver.cpp:239] Iteration 43990 (1.0789 iter/s, 9.2687s/10 iters), loss = 5.55621
I0524 06:55:14.336664 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55621 (* 1 = 5.55621 loss)
I0524 06:55:14.336735 11654 sgd_solver.cpp:112] Iteration 43990, lr = 0.1
I0524 06:55:23.298960 11654 solver.cpp:239] Iteration 44000 (1.11609 iter/s, 8.95989s/10 iters), loss = 6.85459
I0524 06:55:23.299008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85459 (* 1 = 6.85459 loss)
I0524 06:55:23.908056 11654 sgd_solver.cpp:112] Iteration 44000, lr = 0.1
I0524 06:55:31.180936 11654 solver.cpp:239] Iteration 44010 (1.26878 iter/s, 7.88161s/10 iters), loss = 6.56332
I0524 06:55:31.180985 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56332 (* 1 = 6.56332 loss)
I0524 06:55:31.181000 11654 sgd_solver.cpp:112] Iteration 44010, lr = 0.1
I0524 06:55:37.727140 11654 solver.cpp:239] Iteration 44020 (1.5277 iter/s, 6.5458s/10 iters), loss = 5.18494
I0524 06:55:37.727210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.18494 (* 1 = 5.18494 loss)
I0524 06:55:37.727298 11654 sgd_solver.cpp:112] Iteration 44020, lr = 0.1
I0524 06:55:45.117998 11654 solver.cpp:239] Iteration 44030 (1.35309 iter/s, 7.39051s/10 iters), loss = 6.47181
I0524 06:55:45.118306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47181 (* 1 = 6.47181 loss)
I0524 06:55:45.837297 11654 sgd_solver.cpp:112] Iteration 44030, lr = 0.1
I0524 06:55:53.487711 11654 solver.cpp:239] Iteration 44040 (1.19486 iter/s, 8.36915s/10 iters), loss = 5.54446
I0524 06:55:53.487777 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54446 (* 1 = 5.54446 loss)
I0524 06:55:53.488042 11654 sgd_solver.cpp:112] Iteration 44040, lr = 0.1
I0524 06:56:01.347857 11654 solver.cpp:239] Iteration 44050 (1.2723 iter/s, 7.85979s/10 iters), loss = 6.08368
I0524 06:56:01.347915 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08368 (* 1 = 6.08368 loss)
I0524 06:56:01.347929 11654 sgd_solver.cpp:112] Iteration 44050, lr = 0.1
I0524 06:56:09.615748 11654 solver.cpp:239] Iteration 44060 (1.20988 iter/s, 8.26525s/10 iters), loss = 6.35428
I0524 06:56:09.615916 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35428 (* 1 = 6.35428 loss)
I0524 06:56:09.615972 11654 sgd_solver.cpp:112] Iteration 44060, lr = 0.1
I0524 06:56:16.313808 11654 solver.cpp:239] Iteration 44070 (1.49305 iter/s, 6.6977s/10 iters), loss = 5.33783
I0524 06:56:16.313977 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.33783 (* 1 = 5.33783 loss)
I0524 06:56:16.357419 11654 sgd_solver.cpp:112] Iteration 44070, lr = 0.1
I0524 06:56:23.693274 11654 solver.cpp:239] Iteration 44080 (1.35519 iter/s, 7.37902s/10 iters), loss = 5.93045
I0524 06:56:23.693320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93045 (* 1 = 5.93045 loss)
I0524 06:56:23.693337 11654 sgd_solver.cpp:112] Iteration 44080, lr = 0.1
I0524 06:56:32.381763 11654 solver.cpp:239] Iteration 44090 (1.15122 iter/s, 8.68644s/10 iters), loss = 5.99022
I0524 06:56:32.381830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99022 (* 1 = 5.99022 loss)
I0524 06:56:32.381847 11654 sgd_solver.cpp:112] Iteration 44090, lr = 0.1
I0524 06:56:39.461187 11654 solver.cpp:239] Iteration 44100 (1.41305 iter/s, 7.07688s/10 iters), loss = 5.48805
I0524 06:56:39.461253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48805 (* 1 = 5.48805 loss)
I0524 06:56:39.989112 11654 sgd_solver.cpp:112] Iteration 44100, lr = 0.1
I0524 06:56:47.072602 11654 solver.cpp:239] Iteration 44110 (1.31388 iter/s, 7.61106s/10 iters), loss = 6.26915
I0524 06:56:47.072862 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26915 (* 1 = 6.26915 loss)
I0524 06:56:47.748356 11654 sgd_solver.cpp:112] Iteration 44110, lr = 0.1
I0524 06:56:56.320677 11654 solver.cpp:239] Iteration 44120 (1.08137 iter/s, 9.2475s/10 iters), loss = 6.02547
I0524 06:56:56.320744 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02547 (* 1 = 6.02547 loss)
I0524 06:56:56.321139 11654 sgd_solver.cpp:112] Iteration 44120, lr = 0.1
I0524 06:57:03.605540 11654 solver.cpp:239] Iteration 44130 (1.37277 iter/s, 7.28452s/10 iters), loss = 5.93075
I0524 06:57:03.605614 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93075 (* 1 = 5.93075 loss)
I0524 06:57:03.605633 11654 sgd_solver.cpp:112] Iteration 44130, lr = 0.1
I0524 06:57:13.943907 11654 solver.cpp:239] Iteration 44140 (0.96732 iter/s, 10.3378s/10 iters), loss = 6.41795
I0524 06:57:13.943976 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41795 (* 1 = 6.41795 loss)
I0524 06:57:13.943996 11654 sgd_solver.cpp:112] Iteration 44140, lr = 0.1
I0524 06:57:21.316601 11654 solver.cpp:239] Iteration 44150 (1.35643 iter/s, 7.37229s/10 iters), loss = 7.3189
I0524 06:57:21.316833 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.3189 (* 1 = 7.3189 loss)
I0524 06:57:21.317227 11654 sgd_solver.cpp:112] Iteration 44150, lr = 0.1
I0524 06:57:29.243683 11654 solver.cpp:239] Iteration 44160 (1.2616 iter/s, 7.92647s/10 iters), loss = 6.39215
I0524 06:57:29.243784 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39215 (* 1 = 6.39215 loss)
I0524 06:57:29.546222 11654 sgd_solver.cpp:112] Iteration 44160, lr = 0.1
I0524 06:57:36.303761 11654 solver.cpp:239] Iteration 44170 (1.41649 iter/s, 7.05971s/10 iters), loss = 6.69677
I0524 06:57:36.303846 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69677 (* 1 = 6.69677 loss)
I0524 06:57:36.304277 11654 sgd_solver.cpp:112] Iteration 44170, lr = 0.1
I0524 06:57:43.408351 11654 solver.cpp:239] Iteration 44180 (1.40761 iter/s, 7.10425s/10 iters), loss = 6.13627
I0524 06:57:43.408408 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13627 (* 1 = 6.13627 loss)
I0524 06:57:43.408608 11654 sgd_solver.cpp:112] Iteration 44180, lr = 0.1
I0524 06:57:51.243428 11654 solver.cpp:239] Iteration 44190 (1.27637 iter/s, 7.8347s/10 iters), loss = 5.34295
I0524 06:57:51.243515 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.34295 (* 1 = 5.34295 loss)
I0524 06:57:51.243536 11654 sgd_solver.cpp:112] Iteration 44190, lr = 0.1
I0524 06:57:57.767658 11654 solver.cpp:239] Iteration 44200 (1.53284 iter/s, 6.52385s/10 iters), loss = 5.49173
I0524 06:57:57.767884 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49173 (* 1 = 5.49173 loss)
I0524 06:57:57.767913 11654 sgd_solver.cpp:112] Iteration 44200, lr = 0.1
I0524 06:58:05.927590 11654 solver.cpp:239] Iteration 44210 (1.22559 iter/s, 8.15935s/10 iters), loss = 6.31036
I0524 06:58:05.927664 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31036 (* 1 = 6.31036 loss)
I0524 06:58:06.049675 11654 sgd_solver.cpp:112] Iteration 44210, lr = 0.1
I0524 06:58:14.419119 11654 solver.cpp:239] Iteration 44220 (1.1777 iter/s, 8.49112s/10 iters), loss = 6.21245
I0524 06:58:14.419169 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21245 (* 1 = 6.21245 loss)
I0524 06:58:14.838637 11654 sgd_solver.cpp:112] Iteration 44220, lr = 0.1
I0524 06:58:22.402520 11654 solver.cpp:239] Iteration 44230 (1.25266 iter/s, 7.98302s/10 iters), loss = 6.09464
I0524 06:58:22.402587 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09464 (* 1 = 6.09464 loss)
I0524 06:58:23.909828 11654 sgd_solver.cpp:112] Iteration 44230, lr = 0.1
I0524 06:58:30.635030 11654 solver.cpp:239] Iteration 44240 (1.21476 iter/s, 8.2321s/10 iters), loss = 5.66621
I0524 06:58:30.635284 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66621 (* 1 = 5.66621 loss)
I0524 06:58:30.635548 11654 sgd_solver.cpp:112] Iteration 44240, lr = 0.1
I0524 06:58:37.063766 11654 solver.cpp:239] Iteration 44250 (1.55563 iter/s, 6.42826s/10 iters), loss = 4.3075
I0524 06:58:37.063860 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.3075 (* 1 = 4.3075 loss)
I0524 06:58:37.064003 11654 sgd_solver.cpp:112] Iteration 44250, lr = 0.1
I0524 06:58:46.067870 11654 solver.cpp:239] Iteration 44260 (1.11066 iter/s, 9.00367s/10 iters), loss = 5.92195
I0524 06:58:46.067952 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92195 (* 1 = 5.92195 loss)
I0524 06:58:46.067993 11654 sgd_solver.cpp:112] Iteration 44260, lr = 0.1
I0524 06:58:54.221824 11654 solver.cpp:239] Iteration 44270 (1.22647 iter/s, 8.15348s/10 iters), loss = 7.4773
I0524 06:58:54.221926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.4773 (* 1 = 7.4773 loss)
I0524 06:58:54.403211 11654 sgd_solver.cpp:112] Iteration 44270, lr = 0.1
I0524 06:59:02.870340 11654 solver.cpp:239] Iteration 44280 (1.15633 iter/s, 8.64808s/10 iters), loss = 5.64778
I0524 06:59:02.870477 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64778 (* 1 = 5.64778 loss)
I0524 06:59:02.987017 11654 sgd_solver.cpp:112] Iteration 44280, lr = 0.1
I0524 06:59:11.290988 11654 solver.cpp:239] Iteration 44290 (1.18762 iter/s, 8.42021s/10 iters), loss = 6.2157
I0524 06:59:11.291043 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2157 (* 1 = 6.2157 loss)
I0524 06:59:11.318928 11654 sgd_solver.cpp:112] Iteration 44290, lr = 0.1
I0524 06:59:18.983119 11654 solver.cpp:239] Iteration 44300 (1.3001 iter/s, 7.69175s/10 iters), loss = 5.88508
I0524 06:59:18.983249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88508 (* 1 = 5.88508 loss)
I0524 06:59:19.214949 11654 sgd_solver.cpp:112] Iteration 44300, lr = 0.1
I0524 06:59:25.906471 11654 solver.cpp:239] Iteration 44310 (1.44446 iter/s, 6.92299s/10 iters), loss = 6.79456
I0524 06:59:25.906553 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79456 (* 1 = 6.79456 loss)
I0524 06:59:25.906574 11654 sgd_solver.cpp:112] Iteration 44310, lr = 0.1
I0524 06:59:33.392470 11654 solver.cpp:239] Iteration 44320 (1.3359 iter/s, 7.48562s/10 iters), loss = 6.54673
I0524 06:59:33.392691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54673 (* 1 = 6.54673 loss)
I0524 06:59:33.394177 11654 sgd_solver.cpp:112] Iteration 44320, lr = 0.1
I0524 06:59:41.043862 11654 solver.cpp:239] Iteration 44330 (1.30707 iter/s, 7.65071s/10 iters), loss = 5.69359
I0524 06:59:41.044165 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69359 (* 1 = 5.69359 loss)
I0524 06:59:41.044277 11654 sgd_solver.cpp:112] Iteration 44330, lr = 0.1
I0524 06:59:50.996594 11654 solver.cpp:239] Iteration 44340 (1.00483 iter/s, 9.95194s/10 iters), loss = 6.38712
I0524 06:59:50.996716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38712 (* 1 = 6.38712 loss)
I0524 06:59:50.996773 11654 sgd_solver.cpp:112] Iteration 44340, lr = 0.1
I0524 06:59:58.005192 11654 solver.cpp:239] Iteration 44350 (1.42691 iter/s, 7.00814s/10 iters), loss = 4.57105
I0524 06:59:58.005374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.57105 (* 1 = 4.57105 loss)
I0524 06:59:58.005575 11654 sgd_solver.cpp:112] Iteration 44350, lr = 0.1
I0524 07:00:09.152078 11654 solver.cpp:239] Iteration 44360 (0.897153 iter/s, 11.1464s/10 iters), loss = 5.96488
I0524 07:00:09.152248 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96488 (* 1 = 5.96488 loss)
I0524 07:00:09.152266 11654 sgd_solver.cpp:112] Iteration 44360, lr = 0.1
I0524 07:00:18.608414 11654 solver.cpp:239] Iteration 44370 (1.05756 iter/s, 9.45576s/10 iters), loss = 7.17272
I0524 07:00:18.608485 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17272 (* 1 = 7.17272 loss)
I0524 07:00:18.608794 11654 sgd_solver.cpp:112] Iteration 44370, lr = 0.1
I0524 07:00:25.399605 11654 solver.cpp:239] Iteration 44380 (1.47257 iter/s, 6.79086s/10 iters), loss = 5.76311
I0524 07:00:25.399662 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76311 (* 1 = 5.76311 loss)
I0524 07:00:25.751130 11654 sgd_solver.cpp:112] Iteration 44380, lr = 0.1
I0524 07:00:32.526304 11654 solver.cpp:239] Iteration 44390 (1.40325 iter/s, 7.12632s/10 iters), loss = 5.33983
I0524 07:00:32.526443 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.33983 (* 1 = 5.33983 loss)
I0524 07:00:32.526482 11654 sgd_solver.cpp:112] Iteration 44390, lr = 0.1
I0524 07:00:40.144479 11654 solver.cpp:239] Iteration 44400 (1.31272 iter/s, 7.61776s/10 iters), loss = 5.42425
I0524 07:00:40.144682 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42425 (* 1 = 5.42425 loss)
I0524 07:00:40.144717 11654 sgd_solver.cpp:112] Iteration 44400, lr = 0.1
I0524 07:00:46.474584 11654 solver.cpp:239] Iteration 44410 (1.58012 iter/s, 6.32861s/10 iters), loss = 6.00953
I0524 07:00:46.474656 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00953 (* 1 = 6.00953 loss)
I0524 07:00:46.569854 11654 sgd_solver.cpp:112] Iteration 44410, lr = 0.1
I0524 07:00:54.686985 11654 solver.cpp:239] Iteration 44420 (1.21773 iter/s, 8.21203s/10 iters), loss = 5.56679
I0524 07:00:54.687057 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56679 (* 1 = 5.56679 loss)
I0524 07:00:54.714733 11654 sgd_solver.cpp:112] Iteration 44420, lr = 0.1
I0524 07:01:02.141335 11654 solver.cpp:239] Iteration 44430 (1.34156 iter/s, 7.45401s/10 iters), loss = 5.58482
I0524 07:01:02.141381 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58482 (* 1 = 5.58482 loss)
I0524 07:01:02.141396 11654 sgd_solver.cpp:112] Iteration 44430, lr = 0.1
I0524 07:01:10.176671 11654 solver.cpp:239] Iteration 44440 (1.24456 iter/s, 8.03498s/10 iters), loss = 6.21743
I0524 07:01:10.176897 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21743 (* 1 = 6.21743 loss)
I0524 07:01:10.607079 11654 sgd_solver.cpp:112] Iteration 44440, lr = 0.1
I0524 07:01:17.868196 11654 solver.cpp:239] Iteration 44450 (1.30022 iter/s, 7.69101s/10 iters), loss = 6.00178
I0524 07:01:17.868284 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00178 (* 1 = 6.00178 loss)
I0524 07:01:17.868304 11654 sgd_solver.cpp:112] Iteration 44450, lr = 0.1
I0524 07:01:25.109843 11654 solver.cpp:239] Iteration 44460 (1.38097 iter/s, 7.24127s/10 iters), loss = 7.21765
I0524 07:01:25.109895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.21765 (* 1 = 7.21765 loss)
I0524 07:01:25.399947 11654 sgd_solver.cpp:112] Iteration 44460, lr = 0.1
I0524 07:01:32.292776 11654 solver.cpp:239] Iteration 44470 (1.39226 iter/s, 7.18255s/10 iters), loss = 6.1843
I0524 07:01:32.292876 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1843 (* 1 = 6.1843 loss)
I0524 07:01:32.292924 11654 sgd_solver.cpp:112] Iteration 44470, lr = 0.1
I0524 07:01:39.217991 11654 solver.cpp:239] Iteration 44480 (1.44451 iter/s, 6.92276s/10 iters), loss = 6.19874
I0524 07:01:39.218088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19874 (* 1 = 6.19874 loss)
I0524 07:01:39.219964 11654 sgd_solver.cpp:112] Iteration 44480, lr = 0.1
I0524 07:01:45.902403 11654 solver.cpp:239] Iteration 44490 (1.49609 iter/s, 6.68408s/10 iters), loss = 5.89644
I0524 07:01:45.902638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89644 (* 1 = 5.89644 loss)
I0524 07:01:45.903056 11654 sgd_solver.cpp:112] Iteration 44490, lr = 0.1
I0524 07:01:52.218739 11654 solver.cpp:239] Iteration 44500 (1.58332 iter/s, 6.31586s/10 iters), loss = 4.97022
I0524 07:01:52.218797 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.97022 (* 1 = 4.97022 loss)
I0524 07:01:52.219004 11654 sgd_solver.cpp:112] Iteration 44500, lr = 0.1
I0524 07:02:00.164044 11654 solver.cpp:239] Iteration 44510 (1.25866 iter/s, 7.94493s/10 iters), loss = 5.87519
I0524 07:02:00.164103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87519 (* 1 = 5.87519 loss)
I0524 07:02:00.164242 11654 sgd_solver.cpp:112] Iteration 44510, lr = 0.1
I0524 07:02:07.413116 11654 solver.cpp:239] Iteration 44520 (1.37955 iter/s, 7.24874s/10 iters), loss = 6.28656
I0524 07:02:07.413168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28656 (* 1 = 6.28656 loss)
I0524 07:02:07.413188 11654 sgd_solver.cpp:112] Iteration 44520, lr = 0.1
I0524 07:02:15.263520 11654 solver.cpp:239] Iteration 44530 (1.27389 iter/s, 7.84997s/10 iters), loss = 6.08206
I0524 07:02:15.263571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08206 (* 1 = 6.08206 loss)
I0524 07:02:15.263710 11654 sgd_solver.cpp:112] Iteration 44530, lr = 0.1
I0524 07:02:21.984128 11654 solver.cpp:239] Iteration 44540 (1.48803 iter/s, 6.72028s/10 iters), loss = 6.0944
I0524 07:02:21.984328 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0944 (* 1 = 6.0944 loss)
I0524 07:02:21.984351 11654 sgd_solver.cpp:112] Iteration 44540, lr = 0.1
I0524 07:02:29.084090 11654 solver.cpp:239] Iteration 44550 (1.40861 iter/s, 7.09917s/10 iters), loss = 6.28755
I0524 07:02:29.084159 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28755 (* 1 = 6.28755 loss)
I0524 07:02:30.148231 11654 sgd_solver.cpp:112] Iteration 44550, lr = 0.1
I0524 07:02:39.534462 11654 solver.cpp:239] Iteration 44560 (0.956947 iter/s, 10.4499s/10 iters), loss = 6.23724
I0524 07:02:39.534533 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23724 (* 1 = 6.23724 loss)
I0524 07:02:39.534552 11654 sgd_solver.cpp:112] Iteration 44560, lr = 0.1
I0524 07:02:48.823529 11654 solver.cpp:239] Iteration 44570 (1.07659 iter/s, 9.28861s/10 iters), loss = 7.1002
I0524 07:02:48.823583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1002 (* 1 = 7.1002 loss)
I0524 07:02:48.823599 11654 sgd_solver.cpp:112] Iteration 44570, lr = 0.1
I0524 07:02:55.961067 11654 solver.cpp:239] Iteration 44580 (1.40112 iter/s, 7.13715s/10 iters), loss = 5.9253
I0524 07:02:55.962088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9253 (* 1 = 5.9253 loss)
I0524 07:02:55.962107 11654 sgd_solver.cpp:112] Iteration 44580, lr = 0.1
I0524 07:03:05.048414 11654 solver.cpp:239] Iteration 44590 (1.1006 iter/s, 9.08594s/10 iters), loss = 7.29861
I0524 07:03:05.048470 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.29861 (* 1 = 7.29861 loss)
I0524 07:03:05.682369 11654 sgd_solver.cpp:112] Iteration 44590, lr = 0.1
I0524 07:03:12.847254 11654 solver.cpp:239] Iteration 44600 (1.2823 iter/s, 7.79848s/10 iters), loss = 5.37667
I0524 07:03:12.847312 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.37667 (* 1 = 5.37667 loss)
I0524 07:03:12.847329 11654 sgd_solver.cpp:112] Iteration 44600, lr = 0.1
I0524 07:03:20.168361 11654 solver.cpp:239] Iteration 44610 (1.36598 iter/s, 7.32076s/10 iters), loss = 5.66539
I0524 07:03:20.168426 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66539 (* 1 = 5.66539 loss)
I0524 07:03:20.168525 11654 sgd_solver.cpp:112] Iteration 44610, lr = 0.1
I0524 07:03:26.813043 11654 solver.cpp:239] Iteration 44620 (1.50505 iter/s, 6.64431s/10 iters), loss = 6.86749
I0524 07:03:26.813266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86749 (* 1 = 6.86749 loss)
I0524 07:03:26.813297 11654 sgd_solver.cpp:112] Iteration 44620, lr = 0.1
I0524 07:03:35.419508 11654 solver.cpp:239] Iteration 44630 (1.16201 iter/s, 8.60576s/10 iters), loss = 6.24009
I0524 07:03:35.419611 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24009 (* 1 = 6.24009 loss)
I0524 07:03:35.419632 11654 sgd_solver.cpp:112] Iteration 44630, lr = 0.1
I0524 07:03:43.885501 11654 solver.cpp:239] Iteration 44640 (1.18126 iter/s, 8.46555s/10 iters), loss = 5.77383
I0524 07:03:43.885562 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77383 (* 1 = 5.77383 loss)
I0524 07:03:43.885730 11654 sgd_solver.cpp:112] Iteration 44640, lr = 0.1
I0524 07:03:49.976728 11654 solver.cpp:239] Iteration 44650 (1.64179 iter/s, 6.0909s/10 iters), loss = 7.34004
I0524 07:03:49.976794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.34004 (* 1 = 7.34004 loss)
I0524 07:03:49.977152 11654 sgd_solver.cpp:112] Iteration 44650, lr = 0.1
I0524 07:03:58.236986 11654 solver.cpp:239] Iteration 44660 (1.21068 iter/s, 8.25985s/10 iters), loss = 6.83098
I0524 07:03:58.237143 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83098 (* 1 = 6.83098 loss)
I0524 07:03:58.237174 11654 sgd_solver.cpp:112] Iteration 44660, lr = 0.1
I0524 07:04:06.160912 11654 solver.cpp:239] Iteration 44670 (1.26241 iter/s, 7.92138s/10 iters), loss = 5.60694
I0524 07:04:06.161007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60694 (* 1 = 5.60694 loss)
I0524 07:04:06.244582 11654 sgd_solver.cpp:112] Iteration 44670, lr = 0.1
I0524 07:04:13.259238 11654 solver.cpp:239] Iteration 44680 (1.40885 iter/s, 7.09797s/10 iters), loss = 5.75629
I0524 07:04:13.259306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75629 (* 1 = 5.75629 loss)
I0524 07:04:14.423017 11654 sgd_solver.cpp:112] Iteration 44680, lr = 0.1
I0524 07:04:22.715036 11654 solver.cpp:239] Iteration 44690 (1.0576 iter/s, 9.45539s/10 iters), loss = 5.51306
I0524 07:04:22.715075 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51306 (* 1 = 5.51306 loss)
I0524 07:04:22.715306 11654 sgd_solver.cpp:112] Iteration 44690, lr = 0.1
I0524 07:04:30.267243 11654 solver.cpp:239] Iteration 44700 (1.32418 iter/s, 7.55187s/10 iters), loss = 6.31601
I0524 07:04:30.267522 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31601 (* 1 = 6.31601 loss)
I0524 07:04:30.267572 11654 sgd_solver.cpp:112] Iteration 44700, lr = 0.1
I0524 07:04:37.297979 11654 solver.cpp:239] Iteration 44710 (1.42244 iter/s, 7.03018s/10 iters), loss = 6.18513
I0524 07:04:37.298030 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18513 (* 1 = 6.18513 loss)
I0524 07:04:37.327087 11654 sgd_solver.cpp:112] Iteration 44710, lr = 0.1
I0524 07:04:44.819944 11654 solver.cpp:239] Iteration 44720 (1.3295 iter/s, 7.52161s/10 iters), loss = 6.51777
I0524 07:04:44.820000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51777 (* 1 = 6.51777 loss)
I0524 07:04:44.820101 11654 sgd_solver.cpp:112] Iteration 44720, lr = 0.1
I0524 07:04:53.950165 11654 solver.cpp:239] Iteration 44730 (1.09532 iter/s, 9.12978s/10 iters), loss = 6.58872
I0524 07:04:53.950244 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58872 (* 1 = 6.58872 loss)
I0524 07:04:53.950366 11654 sgd_solver.cpp:112] Iteration 44730, lr = 0.1
I0524 07:05:03.047981 11654 solver.cpp:239] Iteration 44740 (1.09921 iter/s, 9.09741s/10 iters), loss = 6.44442
I0524 07:05:03.048372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44442 (* 1 = 6.44442 loss)
I0524 07:05:03.048434 11654 sgd_solver.cpp:112] Iteration 44740, lr = 0.1
I0524 07:05:12.378047 11654 solver.cpp:239] Iteration 44750 (1.07226 iter/s, 9.32614s/10 iters), loss = 5.84561
I0524 07:05:12.378115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84561 (* 1 = 5.84561 loss)
I0524 07:05:12.378139 11654 sgd_solver.cpp:112] Iteration 44750, lr = 0.1
I0524 07:05:23.031790 11654 solver.cpp:239] Iteration 44760 (0.938684 iter/s, 10.6532s/10 iters), loss = 5.05776
I0524 07:05:23.031898 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.05776 (* 1 = 5.05776 loss)
I0524 07:05:24.259867 11654 sgd_solver.cpp:112] Iteration 44760, lr = 0.1
I0524 07:05:32.377914 11654 solver.cpp:239] Iteration 44770 (1.07001 iter/s, 9.34568s/10 iters), loss = 5.51432
I0524 07:05:32.377962 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51432 (* 1 = 5.51432 loss)
I0524 07:05:32.377976 11654 sgd_solver.cpp:112] Iteration 44770, lr = 0.1
I0524 07:05:39.781507 11654 solver.cpp:239] Iteration 44780 (1.35077 iter/s, 7.40319s/10 iters), loss = 6.28375
I0524 07:05:39.781714 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28375 (* 1 = 6.28375 loss)
I0524 07:05:39.781905 11654 sgd_solver.cpp:112] Iteration 44780, lr = 0.1
I0524 07:05:45.908311 11654 solver.cpp:239] Iteration 44790 (1.63228 iter/s, 6.12638s/10 iters), loss = 6.4293
I0524 07:05:45.908388 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4293 (* 1 = 6.4293 loss)
I0524 07:05:45.908447 11654 sgd_solver.cpp:112] Iteration 44790, lr = 0.1
I0524 07:05:55.359272 11654 solver.cpp:239] Iteration 44800 (1.05814 iter/s, 9.45053s/10 iters), loss = 6.1856
I0524 07:05:55.359323 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1856 (* 1 = 6.1856 loss)
I0524 07:05:55.359339 11654 sgd_solver.cpp:112] Iteration 44800, lr = 0.1
I0524 07:06:02.639320 11654 solver.cpp:239] Iteration 44810 (1.37368 iter/s, 7.27971s/10 iters), loss = 7.09602
I0524 07:06:02.639400 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09602 (* 1 = 7.09602 loss)
I0524 07:06:02.639420 11654 sgd_solver.cpp:112] Iteration 44810, lr = 0.1
I0524 07:06:11.641206 11654 solver.cpp:239] Iteration 44820 (1.11094 iter/s, 9.00138s/10 iters), loss = 6.32839
I0524 07:06:11.641444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32839 (* 1 = 6.32839 loss)
I0524 07:06:11.641793 11654 sgd_solver.cpp:112] Iteration 44820, lr = 0.1
I0524 07:06:21.681260 11654 solver.cpp:239] Iteration 44830 (0.996071 iter/s, 10.0394s/10 iters), loss = 6.69793
I0524 07:06:21.681370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69793 (* 1 = 6.69793 loss)
I0524 07:06:21.681406 11654 sgd_solver.cpp:112] Iteration 44830, lr = 0.1
I0524 07:06:28.435745 11654 solver.cpp:239] Iteration 44840 (1.48106 iter/s, 6.75191s/10 iters), loss = 5.52732
I0524 07:06:28.435886 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.52732 (* 1 = 5.52732 loss)
I0524 07:06:28.478562 11654 sgd_solver.cpp:112] Iteration 44840, lr = 0.1
I0524 07:06:36.477586 11654 solver.cpp:239] Iteration 44850 (1.24356 iter/s, 8.04142s/10 iters), loss = 6.30613
I0524 07:06:36.477666 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30613 (* 1 = 6.30613 loss)
I0524 07:06:36.477685 11654 sgd_solver.cpp:112] Iteration 44850, lr = 0.1
I0524 07:06:43.965688 11654 solver.cpp:239] Iteration 44860 (1.33552 iter/s, 7.4877s/10 iters), loss = 6.09255
I0524 07:06:43.965941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09255 (* 1 = 6.09255 loss)
I0524 07:06:43.965978 11654 sgd_solver.cpp:112] Iteration 44860, lr = 0.1
I0524 07:06:51.136559 11654 solver.cpp:239] Iteration 44870 (1.39464 iter/s, 7.17029s/10 iters), loss = 6.19254
I0524 07:06:51.136683 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19254 (* 1 = 6.19254 loss)
I0524 07:06:51.136734 11654 sgd_solver.cpp:112] Iteration 44870, lr = 0.1
I0524 07:06:58.178769 11654 solver.cpp:239] Iteration 44880 (1.42008 iter/s, 7.04183s/10 iters), loss = 5.86973
I0524 07:06:58.178884 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86973 (* 1 = 5.86973 loss)
I0524 07:06:58.178917 11654 sgd_solver.cpp:112] Iteration 44880, lr = 0.1
I0524 07:07:05.002779 11654 solver.cpp:239] Iteration 44890 (1.4655 iter/s, 6.82362s/10 iters), loss = 6.07887
I0524 07:07:05.002837 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07887 (* 1 = 6.07887 loss)
I0524 07:07:05.002853 11654 sgd_solver.cpp:112] Iteration 44890, lr = 0.1
I0524 07:07:14.025614 11654 solver.cpp:239] Iteration 44900 (1.10839 iter/s, 9.02207s/10 iters), loss = 6.81034
I0524 07:07:14.025707 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81034 (* 1 = 6.81034 loss)
I0524 07:07:14.025966 11654 sgd_solver.cpp:112] Iteration 44900, lr = 0.1
I0524 07:07:21.191462 11654 solver.cpp:239] Iteration 44910 (1.39558 iter/s, 7.16548s/10 iters), loss = 6.21978
I0524 07:07:21.191514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21978 (* 1 = 6.21978 loss)
I0524 07:07:21.191793 11654 sgd_solver.cpp:112] Iteration 44910, lr = 0.1
I0524 07:07:28.891613 11654 solver.cpp:239] Iteration 44920 (1.29874 iter/s, 7.69979s/10 iters), loss = 6.56104
I0524 07:07:28.891705 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56104 (* 1 = 6.56104 loss)
I0524 07:07:28.891755 11654 sgd_solver.cpp:112] Iteration 44920, lr = 0.1
I0524 07:07:35.123059 11654 solver.cpp:239] Iteration 44930 (1.60485 iter/s, 6.23112s/10 iters), loss = 6.91117
I0524 07:07:35.123116 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91117 (* 1 = 6.91117 loss)
I0524 07:07:35.123441 11654 sgd_solver.cpp:112] Iteration 44930, lr = 0.1
I0524 07:07:42.016855 11654 solver.cpp:239] Iteration 44940 (1.45065 iter/s, 6.89347s/10 iters), loss = 6.35805
I0524 07:07:42.016932 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35805 (* 1 = 6.35805 loss)
I0524 07:07:42.016952 11654 sgd_solver.cpp:112] Iteration 44940, lr = 0.1
I0524 07:07:49.520568 11654 solver.cpp:239] Iteration 44950 (1.33275 iter/s, 7.50331s/10 iters), loss = 6.20464
I0524 07:07:49.520908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20464 (* 1 = 6.20464 loss)
I0524 07:07:49.520979 11654 sgd_solver.cpp:112] Iteration 44950, lr = 0.1
I0524 07:07:56.650755 11654 solver.cpp:239] Iteration 44960 (1.40259 iter/s, 7.12964s/10 iters), loss = 6.7438
I0524 07:07:56.650830 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7438 (* 1 = 6.7438 loss)
I0524 07:07:56.651291 11654 sgd_solver.cpp:112] Iteration 44960, lr = 0.1
I0524 07:08:05.948016 11654 solver.cpp:239] Iteration 44970 (1.07563 iter/s, 9.29684s/10 iters), loss = 6.49134
I0524 07:08:05.948101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49134 (* 1 = 6.49134 loss)
I0524 07:08:06.466080 11654 sgd_solver.cpp:112] Iteration 44970, lr = 0.1
I0524 07:08:13.226518 11654 solver.cpp:239] Iteration 44980 (1.37397 iter/s, 7.27817s/10 iters), loss = 6.81422
I0524 07:08:13.226593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81422 (* 1 = 6.81422 loss)
I0524 07:08:13.226624 11654 sgd_solver.cpp:112] Iteration 44980, lr = 0.1
I0524 07:08:20.031602 11654 solver.cpp:239] Iteration 44990 (1.46958 iter/s, 6.80468s/10 iters), loss = 5.94171
I0524 07:08:20.031885 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94171 (* 1 = 5.94171 loss)
I0524 07:08:20.237095 11654 sgd_solver.cpp:112] Iteration 44990, lr = 0.1
I0524 07:08:26.480139 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_45000.caffemodel
I0524 07:08:27.121489 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_45000.solverstate
I0524 07:08:27.712036 11654 solver.cpp:239] Iteration 45000 (1.30211 iter/s, 7.67985s/10 iters), loss = 5.8439
I0524 07:08:27.712102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8439 (* 1 = 5.8439 loss)
I0524 07:08:27.712121 11654 sgd_solver.cpp:112] Iteration 45000, lr = 0.1
I0524 07:08:35.819299 11654 solver.cpp:239] Iteration 45010 (1.23384 iter/s, 8.10477s/10 iters), loss = 6.36428
I0524 07:08:35.819368 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36428 (* 1 = 6.36428 loss)
I0524 07:08:35.819409 11654 sgd_solver.cpp:112] Iteration 45010, lr = 0.1
I0524 07:08:43.330013 11654 solver.cpp:239] Iteration 45020 (1.33151 iter/s, 7.51029s/10 iters), loss = 6.53749
I0524 07:08:43.330090 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53749 (* 1 = 6.53749 loss)
I0524 07:08:43.330682 11654 sgd_solver.cpp:112] Iteration 45020, lr = 0.1
I0524 07:08:51.858974 11654 solver.cpp:239] Iteration 45030 (1.17253 iter/s, 8.52856s/10 iters), loss = 5.60858
I0524 07:08:51.859223 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60858 (* 1 = 5.60858 loss)
I0524 07:08:52.258955 11654 sgd_solver.cpp:112] Iteration 45030, lr = 0.1
I0524 07:09:00.875094 11654 solver.cpp:239] Iteration 45040 (1.1092 iter/s, 9.01554s/10 iters), loss = 5.83884
I0524 07:09:00.875231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83884 (* 1 = 5.83884 loss)
I0524 07:09:00.875279 11654 sgd_solver.cpp:112] Iteration 45040, lr = 0.1
I0524 07:09:08.159843 11654 solver.cpp:239] Iteration 45050 (1.3728 iter/s, 7.2844s/10 iters), loss = 6.23154
I0524 07:09:08.159904 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23154 (* 1 = 6.23154 loss)
I0524 07:09:08.537662 11654 sgd_solver.cpp:112] Iteration 45050, lr = 0.1
I0524 07:09:15.279806 11654 solver.cpp:239] Iteration 45060 (1.40457 iter/s, 7.11963s/10 iters), loss = 7.25809
I0524 07:09:15.279893 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25809 (* 1 = 7.25809 loss)
I0524 07:09:15.498250 11654 sgd_solver.cpp:112] Iteration 45060, lr = 0.1
I0524 07:09:21.743808 11654 solver.cpp:239] Iteration 45070 (1.5471 iter/s, 6.46369s/10 iters), loss = 5.32959
I0524 07:09:21.743851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.32959 (* 1 = 5.32959 loss)
I0524 07:09:21.743865 11654 sgd_solver.cpp:112] Iteration 45070, lr = 0.1
I0524 07:09:30.089247 11654 solver.cpp:239] Iteration 45080 (1.19848 iter/s, 8.34393s/10 iters), loss = 6.08668
I0524 07:09:30.089555 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08668 (* 1 = 6.08668 loss)
I0524 07:09:30.089609 11654 sgd_solver.cpp:112] Iteration 45080, lr = 0.1
I0524 07:09:37.121239 11654 solver.cpp:239] Iteration 45090 (1.42258 iter/s, 7.02949s/10 iters), loss = 5.18126
I0524 07:09:37.121279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.18126 (* 1 = 5.18126 loss)
I0524 07:09:37.121294 11654 sgd_solver.cpp:112] Iteration 45090, lr = 0.1
I0524 07:09:44.930320 11654 solver.cpp:239] Iteration 45100 (1.28063 iter/s, 7.80866s/10 iters), loss = 5.71518
I0524 07:09:44.930393 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71518 (* 1 = 5.71518 loss)
I0524 07:09:44.930426 11654 sgd_solver.cpp:112] Iteration 45100, lr = 0.1
I0524 07:09:53.192577 11654 solver.cpp:239] Iteration 45110 (1.21039 iter/s, 8.26181s/10 iters), loss = 5.80511
I0524 07:09:53.192682 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80511 (* 1 = 5.80511 loss)
I0524 07:09:53.192713 11654 sgd_solver.cpp:112] Iteration 45110, lr = 0.1
I0524 07:10:00.740989 11654 solver.cpp:239] Iteration 45120 (1.32486 iter/s, 7.54795s/10 iters), loss = 7.25194
I0524 07:10:00.741219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25194 (* 1 = 7.25194 loss)
I0524 07:10:00.741242 11654 sgd_solver.cpp:112] Iteration 45120, lr = 0.1
I0524 07:10:09.193388 11654 solver.cpp:239] Iteration 45130 (1.18318 iter/s, 8.45183s/10 iters), loss = 6.68914
I0524 07:10:09.193445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68914 (* 1 = 6.68914 loss)
I0524 07:10:09.193471 11654 sgd_solver.cpp:112] Iteration 45130, lr = 0.1
I0524 07:10:16.655565 11654 solver.cpp:239] Iteration 45140 (1.34016 iter/s, 7.46178s/10 iters), loss = 5.66286
I0524 07:10:16.655612 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66286 (* 1 = 5.66286 loss)
I0524 07:10:16.655625 11654 sgd_solver.cpp:112] Iteration 45140, lr = 0.1
I0524 07:10:22.990172 11654 solver.cpp:239] Iteration 45150 (1.57872 iter/s, 6.33424s/10 iters), loss = 6.93159
I0524 07:10:22.990212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93159 (* 1 = 6.93159 loss)
I0524 07:10:23.749361 11654 sgd_solver.cpp:112] Iteration 45150, lr = 0.1
I0524 07:10:33.115062 11654 solver.cpp:239] Iteration 45160 (0.987708 iter/s, 10.1244s/10 iters), loss = 6.08916
I0524 07:10:33.115306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08916 (* 1 = 6.08916 loss)
I0524 07:10:33.115350 11654 sgd_solver.cpp:112] Iteration 45160, lr = 0.1
I0524 07:10:40.371415 11654 solver.cpp:239] Iteration 45170 (1.37821 iter/s, 7.25576s/10 iters), loss = 5.9879
I0524 07:10:40.371479 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9879 (* 1 = 5.9879 loss)
I0524 07:10:40.644659 11654 sgd_solver.cpp:112] Iteration 45170, lr = 0.1
I0524 07:10:48.839797 11654 solver.cpp:239] Iteration 45180 (1.18092 iter/s, 8.46798s/10 iters), loss = 6.53492
I0524 07:10:48.839864 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53492 (* 1 = 6.53492 loss)
I0524 07:10:48.840258 11654 sgd_solver.cpp:112] Iteration 45180, lr = 0.1
I0524 07:10:57.701670 11654 solver.cpp:239] Iteration 45190 (1.12848 iter/s, 8.86144s/10 iters), loss = 5.86146
I0524 07:10:57.701723 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86146 (* 1 = 5.86146 loss)
I0524 07:10:57.701741 11654 sgd_solver.cpp:112] Iteration 45190, lr = 0.1
I0524 07:11:06.911530 11654 solver.cpp:239] Iteration 45200 (1.08584 iter/s, 9.20942s/10 iters), loss = 5.8375
I0524 07:11:06.911749 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8375 (* 1 = 5.8375 loss)
I0524 07:11:06.911800 11654 sgd_solver.cpp:112] Iteration 45200, lr = 0.1
I0524 07:11:13.554299 11654 solver.cpp:239] Iteration 45210 (1.50551 iter/s, 6.64228s/10 iters), loss = 6.18363
I0524 07:11:13.554363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18363 (* 1 = 6.18363 loss)
I0524 07:11:13.554638 11654 sgd_solver.cpp:112] Iteration 45210, lr = 0.1
I0524 07:11:22.936017 11654 solver.cpp:239] Iteration 45220 (1.06595 iter/s, 9.3813s/10 iters), loss = 6.30868
I0524 07:11:22.936081 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30868 (* 1 = 6.30868 loss)
I0524 07:11:22.936199 11654 sgd_solver.cpp:112] Iteration 45220, lr = 0.1
I0524 07:11:30.573269 11654 solver.cpp:239] Iteration 45230 (1.30943 iter/s, 7.6369s/10 iters), loss = 5.96848
I0524 07:11:30.573320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96848 (* 1 = 5.96848 loss)
I0524 07:11:31.413471 11654 sgd_solver.cpp:112] Iteration 45230, lr = 0.1
I0524 07:11:40.293162 11654 solver.cpp:239] Iteration 45240 (1.02887 iter/s, 9.71944s/10 iters), loss = 6.9105
I0524 07:11:40.293521 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9105 (* 1 = 6.9105 loss)
I0524 07:11:40.293560 11654 sgd_solver.cpp:112] Iteration 45240, lr = 0.1
I0524 07:11:49.320477 11654 solver.cpp:239] Iteration 45250 (1.10784 iter/s, 9.02654s/10 iters), loss = 5.97015
I0524 07:11:49.320528 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97015 (* 1 = 5.97015 loss)
I0524 07:11:49.320546 11654 sgd_solver.cpp:112] Iteration 45250, lr = 0.1
I0524 07:11:56.544811 11654 solver.cpp:239] Iteration 45260 (1.38429 iter/s, 7.22392s/10 iters), loss = 5.93222
I0524 07:11:56.544868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93222 (* 1 = 5.93222 loss)
I0524 07:11:56.545032 11654 sgd_solver.cpp:112] Iteration 45260, lr = 0.1
I0524 07:12:04.343183 11654 solver.cpp:239] Iteration 45270 (1.28238 iter/s, 7.798s/10 iters), loss = 5.17236
I0524 07:12:04.343245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.17236 (* 1 = 5.17236 loss)
I0524 07:12:04.368582 11654 sgd_solver.cpp:112] Iteration 45270, lr = 0.1
I0524 07:12:11.657968 11654 solver.cpp:239] Iteration 45280 (1.36716 iter/s, 7.31444s/10 iters), loss = 5.56818
I0524 07:12:11.658107 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56818 (* 1 = 5.56818 loss)
I0524 07:12:11.676476 11654 sgd_solver.cpp:112] Iteration 45280, lr = 0.1
I0524 07:12:19.784278 11654 solver.cpp:239] Iteration 45290 (1.23064 iter/s, 8.12586s/10 iters), loss = 6.38619
I0524 07:12:19.784320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38619 (* 1 = 6.38619 loss)
I0524 07:12:19.784334 11654 sgd_solver.cpp:112] Iteration 45290, lr = 0.1
I0524 07:12:26.986837 11654 solver.cpp:239] Iteration 45300 (1.38888 iter/s, 7.20006s/10 iters), loss = 6.54272
I0524 07:12:26.986891 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54272 (* 1 = 6.54272 loss)
I0524 07:12:26.995524 11654 sgd_solver.cpp:112] Iteration 45300, lr = 0.1
I0524 07:12:34.124245 11654 solver.cpp:239] Iteration 45310 (1.40114 iter/s, 7.13707s/10 iters), loss = 6.67305
I0524 07:12:34.124330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67305 (* 1 = 6.67305 loss)
I0524 07:12:34.124452 11654 sgd_solver.cpp:112] Iteration 45310, lr = 0.1
I0524 07:12:41.750772 11654 solver.cpp:239] Iteration 45320 (1.31128 iter/s, 7.62616s/10 iters), loss = 6.02439
I0524 07:12:41.751024 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02439 (* 1 = 6.02439 loss)
I0524 07:12:42.953611 11654 sgd_solver.cpp:112] Iteration 45320, lr = 0.1
I0524 07:12:49.978058 11654 solver.cpp:239] Iteration 45330 (1.21555 iter/s, 8.2267s/10 iters), loss = 5.57329
I0524 07:12:49.978124 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57329 (* 1 = 5.57329 loss)
I0524 07:12:49.978148 11654 sgd_solver.cpp:112] Iteration 45330, lr = 0.1
I0524 07:12:56.889324 11654 solver.cpp:239] Iteration 45340 (1.44698 iter/s, 6.91094s/10 iters), loss = 5.67365
I0524 07:12:56.889364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67365 (* 1 = 5.67365 loss)
I0524 07:12:56.889376 11654 sgd_solver.cpp:112] Iteration 45340, lr = 0.1
I0524 07:13:03.490316 11654 solver.cpp:239] Iteration 45350 (1.51504 iter/s, 6.60047s/10 iters), loss = 6.37273
I0524 07:13:03.490384 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37273 (* 1 = 6.37273 loss)
I0524 07:13:03.490448 11654 sgd_solver.cpp:112] Iteration 45350, lr = 0.1
I0524 07:13:10.662009 11654 solver.cpp:239] Iteration 45360 (1.39444 iter/s, 7.17135s/10 iters), loss = 6.92409
I0524 07:13:10.662062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92409 (* 1 = 6.92409 loss)
I0524 07:13:10.780297 11654 sgd_solver.cpp:112] Iteration 45360, lr = 0.1
I0524 07:13:20.422309 11654 solver.cpp:239] Iteration 45370 (1.0246 iter/s, 9.75986s/10 iters), loss = 4.65435
I0524 07:13:20.422562 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.65435 (* 1 = 4.65435 loss)
I0524 07:13:20.422629 11654 sgd_solver.cpp:112] Iteration 45370, lr = 0.1
I0524 07:13:29.266263 11654 solver.cpp:239] Iteration 45380 (1.13106 iter/s, 8.84127s/10 iters), loss = 5.38684
I0524 07:13:29.266321 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.38684 (* 1 = 5.38684 loss)
I0524 07:13:29.266337 11654 sgd_solver.cpp:112] Iteration 45380, lr = 0.1
I0524 07:13:37.086525 11654 solver.cpp:239] Iteration 45390 (1.2788 iter/s, 7.81981s/10 iters), loss = 6.05136
I0524 07:13:37.086597 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05136 (* 1 = 6.05136 loss)
I0524 07:13:37.086668 11654 sgd_solver.cpp:112] Iteration 45390, lr = 0.1
I0524 07:13:45.050073 11654 solver.cpp:239] Iteration 45400 (1.25578 iter/s, 7.96318s/10 iters), loss = 5.47847
I0524 07:13:45.050135 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47847 (* 1 = 5.47847 loss)
I0524 07:13:45.050156 11654 sgd_solver.cpp:112] Iteration 45400, lr = 0.1
I0524 07:13:54.419190 11654 solver.cpp:239] Iteration 45410 (1.0674 iter/s, 9.36859s/10 iters), loss = 5.84143
I0524 07:13:54.419440 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84143 (* 1 = 5.84143 loss)
I0524 07:13:54.419584 11654 sgd_solver.cpp:112] Iteration 45410, lr = 0.1
I0524 07:14:01.918987 11654 solver.cpp:239] Iteration 45420 (1.33347 iter/s, 7.49926s/10 iters), loss = 7.02956
I0524 07:14:01.919034 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02956 (* 1 = 7.02956 loss)
I0524 07:14:01.919055 11654 sgd_solver.cpp:112] Iteration 45420, lr = 0.1
I0524 07:14:08.761837 11654 solver.cpp:239] Iteration 45430 (1.46146 iter/s, 6.84245s/10 iters), loss = 5.44904
I0524 07:14:08.761925 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44904 (* 1 = 5.44904 loss)
I0524 07:14:08.909265 11654 sgd_solver.cpp:112] Iteration 45430, lr = 0.1
I0524 07:14:16.500821 11654 solver.cpp:239] Iteration 45440 (1.29222 iter/s, 7.73861s/10 iters), loss = 5.95111
I0524 07:14:16.500881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95111 (* 1 = 5.95111 loss)
I0524 07:14:16.501044 11654 sgd_solver.cpp:112] Iteration 45440, lr = 0.1
I0524 07:14:25.292539 11654 solver.cpp:239] Iteration 45450 (1.13749 iter/s, 8.79128s/10 iters), loss = 6.62667
I0524 07:14:25.292831 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62667 (* 1 = 6.62667 loss)
I0524 07:14:25.292891 11654 sgd_solver.cpp:112] Iteration 45450, lr = 0.1
I0524 07:14:33.874420 11654 solver.cpp:239] Iteration 45460 (1.16538 iter/s, 8.58088s/10 iters), loss = 5.86817
I0524 07:14:33.874488 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86817 (* 1 = 5.86817 loss)
I0524 07:14:33.874622 11654 sgd_solver.cpp:112] Iteration 45460, lr = 0.1
I0524 07:14:42.941207 11654 solver.cpp:239] Iteration 45470 (1.10298 iter/s, 9.06632s/10 iters), loss = 6.31063
I0524 07:14:42.941310 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31063 (* 1 = 6.31063 loss)
I0524 07:14:42.941337 11654 sgd_solver.cpp:112] Iteration 45470, lr = 0.1
I0524 07:14:52.363451 11654 solver.cpp:239] Iteration 45480 (1.06161 iter/s, 9.41966s/10 iters), loss = 6.17868
I0524 07:14:52.363509 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17868 (* 1 = 6.17868 loss)
I0524 07:14:52.363526 11654 sgd_solver.cpp:112] Iteration 45480, lr = 0.1
I0524 07:15:00.083485 11654 solver.cpp:239] Iteration 45490 (1.29577 iter/s, 7.71743s/10 iters), loss = 6.02669
I0524 07:15:00.083782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02669 (* 1 = 6.02669 loss)
I0524 07:15:00.135515 11654 sgd_solver.cpp:112] Iteration 45490, lr = 0.1
I0524 07:15:07.351454 11654 solver.cpp:239] Iteration 45500 (1.376 iter/s, 7.26744s/10 iters), loss = 5.74397
I0524 07:15:07.351521 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74397 (* 1 = 5.74397 loss)
I0524 07:15:07.739866 11654 sgd_solver.cpp:112] Iteration 45500, lr = 0.1
I0524 07:15:14.726845 11654 solver.cpp:239] Iteration 45510 (1.35593 iter/s, 7.37503s/10 iters), loss = 7.18266
I0524 07:15:14.726900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18266 (* 1 = 7.18266 loss)
I0524 07:15:14.727622 11654 sgd_solver.cpp:112] Iteration 45510, lr = 0.1
I0524 07:15:23.890077 11654 solver.cpp:239] Iteration 45520 (1.09137 iter/s, 9.16282s/10 iters), loss = 5.82919
I0524 07:15:23.890156 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82919 (* 1 = 5.82919 loss)
I0524 07:15:23.890175 11654 sgd_solver.cpp:112] Iteration 45520, lr = 0.1
I0524 07:15:30.614240 11654 solver.cpp:239] Iteration 45530 (1.48726 iter/s, 6.72377s/10 iters), loss = 6.08332
I0524 07:15:30.614504 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08332 (* 1 = 6.08332 loss)
I0524 07:15:30.614542 11654 sgd_solver.cpp:112] Iteration 45530, lr = 0.1
I0524 07:15:37.960024 11654 solver.cpp:239] Iteration 45540 (1.36183 iter/s, 7.34305s/10 iters), loss = 5.94942
I0524 07:15:37.960186 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94942 (* 1 = 5.94942 loss)
I0524 07:15:37.960937 11654 sgd_solver.cpp:112] Iteration 45540, lr = 0.1
I0524 07:15:45.117671 11654 solver.cpp:239] Iteration 45550 (1.39718 iter/s, 7.15725s/10 iters), loss = 5.94673
I0524 07:15:45.117729 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94673 (* 1 = 5.94673 loss)
I0524 07:15:45.118077 11654 sgd_solver.cpp:112] Iteration 45550, lr = 0.1
I0524 07:15:53.718284 11654 solver.cpp:239] Iteration 45560 (1.16276 iter/s, 8.60021s/10 iters), loss = 6.149
I0524 07:15:53.718372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.149 (* 1 = 6.149 loss)
I0524 07:15:53.718391 11654 sgd_solver.cpp:112] Iteration 45560, lr = 0.1
I0524 07:16:01.805161 11654 solver.cpp:239] Iteration 45570 (1.23697 iter/s, 8.08429s/10 iters), loss = 5.82613
I0524 07:16:01.805416 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82613 (* 1 = 5.82613 loss)
I0524 07:16:01.805472 11654 sgd_solver.cpp:112] Iteration 45570, lr = 0.1
I0524 07:16:08.322055 11654 solver.cpp:239] Iteration 45580 (1.5346 iter/s, 6.51636s/10 iters), loss = 6.16001
I0524 07:16:08.322171 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16001 (* 1 = 6.16001 loss)
I0524 07:16:08.322340 11654 sgd_solver.cpp:112] Iteration 45580, lr = 0.1
I0524 07:16:15.046128 11654 solver.cpp:239] Iteration 45590 (1.48728 iter/s, 6.7237s/10 iters), loss = 6.93863
I0524 07:16:15.046180 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93863 (* 1 = 6.93863 loss)
I0524 07:16:15.046322 11654 sgd_solver.cpp:112] Iteration 45590, lr = 0.1
I0524 07:16:24.231252 11654 solver.cpp:239] Iteration 45600 (1.08877 iter/s, 9.18472s/10 iters), loss = 6.60468
I0524 07:16:24.231317 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60468 (* 1 = 6.60468 loss)
I0524 07:16:24.231351 11654 sgd_solver.cpp:112] Iteration 45600, lr = 0.1
I0524 07:16:32.294260 11654 solver.cpp:239] Iteration 45610 (1.2403 iter/s, 8.06259s/10 iters), loss = 6.60847
I0524 07:16:32.294502 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60847 (* 1 = 6.60847 loss)
I0524 07:16:32.294551 11654 sgd_solver.cpp:112] Iteration 45610, lr = 0.1
I0524 07:16:40.034847 11654 solver.cpp:239] Iteration 45620 (1.29201 iter/s, 7.73988s/10 iters), loss = 6.78979
I0524 07:16:40.034942 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78979 (* 1 = 6.78979 loss)
I0524 07:16:40.034976 11654 sgd_solver.cpp:112] Iteration 45620, lr = 0.1
I0524 07:16:46.384778 11654 solver.cpp:239] Iteration 45630 (1.57491 iter/s, 6.34958s/10 iters), loss = 6.10167
I0524 07:16:46.384826 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10167 (* 1 = 6.10167 loss)
I0524 07:16:46.384945 11654 sgd_solver.cpp:112] Iteration 45630, lr = 0.1
I0524 07:16:54.016199 11654 solver.cpp:239] Iteration 45640 (1.31043 iter/s, 7.63107s/10 iters), loss = 6.48187
I0524 07:16:54.016268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48187 (* 1 = 6.48187 loss)
I0524 07:16:54.017038 11654 sgd_solver.cpp:112] Iteration 45640, lr = 0.1
I0524 07:17:01.925328 11654 solver.cpp:239] Iteration 45650 (1.26443 iter/s, 7.90873s/10 iters), loss = 5.48168
I0524 07:17:01.925391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48168 (* 1 = 5.48168 loss)
I0524 07:17:02.569947 11654 sgd_solver.cpp:112] Iteration 45650, lr = 0.1
I0524 07:17:10.037434 11654 solver.cpp:239] Iteration 45660 (1.23278 iter/s, 8.11173s/10 iters), loss = 5.48805
I0524 07:17:10.037494 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48805 (* 1 = 5.48805 loss)
I0524 07:17:10.102356 11654 sgd_solver.cpp:112] Iteration 45660, lr = 0.1
I0524 07:17:17.213351 11654 solver.cpp:239] Iteration 45670 (1.39362 iter/s, 7.17558s/10 iters), loss = 6.39634
I0524 07:17:17.213423 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39634 (* 1 = 6.39634 loss)
I0524 07:17:17.213438 11654 sgd_solver.cpp:112] Iteration 45670, lr = 0.1
I0524 07:17:23.732270 11654 solver.cpp:239] Iteration 45680 (1.53409 iter/s, 6.51852s/10 iters), loss = 5.95692
I0524 07:17:23.732373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95692 (* 1 = 5.95692 loss)
I0524 07:17:23.732394 11654 sgd_solver.cpp:112] Iteration 45680, lr = 0.1
I0524 07:17:30.187137 11654 solver.cpp:239] Iteration 45690 (1.54929 iter/s, 6.45455s/10 iters), loss = 7.01255
I0524 07:17:30.187204 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01255 (* 1 = 7.01255 loss)
I0524 07:17:30.187225 11654 sgd_solver.cpp:112] Iteration 45690, lr = 0.1
I0524 07:17:37.282764 11654 solver.cpp:239] Iteration 45700 (1.4094 iter/s, 7.09519s/10 iters), loss = 6.75509
I0524 07:17:37.283012 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75509 (* 1 = 6.75509 loss)
I0524 07:17:37.283162 11654 sgd_solver.cpp:112] Iteration 45700, lr = 0.1
I0524 07:17:44.578794 11654 solver.cpp:239] Iteration 45710 (1.37071 iter/s, 7.29551s/10 iters), loss = 5.60274
I0524 07:17:44.578851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60274 (* 1 = 5.60274 loss)
I0524 07:17:44.578999 11654 sgd_solver.cpp:112] Iteration 45710, lr = 0.1
I0524 07:17:52.178550 11654 solver.cpp:239] Iteration 45720 (1.3159 iter/s, 7.59936s/10 iters), loss = 6.16487
I0524 07:17:52.178637 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16487 (* 1 = 6.16487 loss)
I0524 07:17:52.178668 11654 sgd_solver.cpp:112] Iteration 45720, lr = 0.1
I0524 07:17:58.671888 11654 solver.cpp:239] Iteration 45730 (1.54012 iter/s, 6.493s/10 iters), loss = 6.8057
I0524 07:17:58.671947 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8057 (* 1 = 6.8057 loss)
I0524 07:17:58.672147 11654 sgd_solver.cpp:112] Iteration 45730, lr = 0.1
I0524 07:18:07.488600 11654 solver.cpp:239] Iteration 45740 (1.13426 iter/s, 8.81629s/10 iters), loss = 5.85008
I0524 07:18:07.488857 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85008 (* 1 = 5.85008 loss)
I0524 07:18:07.527221 11654 sgd_solver.cpp:112] Iteration 45740, lr = 0.1
I0524 07:18:14.957554 11654 solver.cpp:239] Iteration 45750 (1.33898 iter/s, 7.4684s/10 iters), loss = 5.88251
I0524 07:18:14.957633 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88251 (* 1 = 5.88251 loss)
I0524 07:18:15.409210 11654 sgd_solver.cpp:112] Iteration 45750, lr = 0.1
I0524 07:18:23.262128 11654 solver.cpp:239] Iteration 45760 (1.20421 iter/s, 8.30417s/10 iters), loss = 6.46467
I0524 07:18:23.262243 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46467 (* 1 = 6.46467 loss)
I0524 07:18:23.262295 11654 sgd_solver.cpp:112] Iteration 45760, lr = 0.1
I0524 07:18:31.250679 11654 solver.cpp:239] Iteration 45770 (1.25195 iter/s, 7.98751s/10 iters), loss = 6.65578
I0524 07:18:31.250741 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65578 (* 1 = 6.65578 loss)
I0524 07:18:31.250763 11654 sgd_solver.cpp:112] Iteration 45770, lr = 0.1
I0524 07:18:38.863234 11654 solver.cpp:239] Iteration 45780 (1.31368 iter/s, 7.6122s/10 iters), loss = 6.10213
I0524 07:18:38.863477 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10213 (* 1 = 6.10213 loss)
I0524 07:18:38.863523 11654 sgd_solver.cpp:112] Iteration 45780, lr = 0.1
I0524 07:18:47.904435 11654 solver.cpp:239] Iteration 45790 (1.10612 iter/s, 9.04061s/10 iters), loss = 5.97263
I0524 07:18:47.904538 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97263 (* 1 = 5.97263 loss)
I0524 07:18:47.904569 11654 sgd_solver.cpp:112] Iteration 45790, lr = 0.1
I0524 07:18:56.754274 11654 solver.cpp:239] Iteration 45800 (1.13001 iter/s, 8.84944s/10 iters), loss = 5.9599
I0524 07:18:56.754333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9599 (* 1 = 5.9599 loss)
I0524 07:18:56.754359 11654 sgd_solver.cpp:112] Iteration 45800, lr = 0.1
I0524 07:19:04.182144 11654 solver.cpp:239] Iteration 45810 (1.34675 iter/s, 7.4253s/10 iters), loss = 6.70101
I0524 07:19:04.182245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70101 (* 1 = 6.70101 loss)
I0524 07:19:04.182279 11654 sgd_solver.cpp:112] Iteration 45810, lr = 0.1
I0524 07:19:12.336612 11654 solver.cpp:239] Iteration 45820 (1.22638 iter/s, 8.15409s/10 iters), loss = 5.97778
I0524 07:19:12.336911 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97778 (* 1 = 5.97778 loss)
I0524 07:19:12.338620 11654 sgd_solver.cpp:112] Iteration 45820, lr = 0.1
I0524 07:19:19.365121 11654 solver.cpp:239] Iteration 45830 (1.42289 iter/s, 7.02796s/10 iters), loss = 5.29313
I0524 07:19:19.365183 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29313 (* 1 = 5.29313 loss)
I0524 07:19:19.365253 11654 sgd_solver.cpp:112] Iteration 45830, lr = 0.1
I0524 07:19:26.486335 11654 solver.cpp:239] Iteration 45840 (1.40432 iter/s, 7.12088s/10 iters), loss = 6.19177
I0524 07:19:26.486412 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19177 (* 1 = 6.19177 loss)
I0524 07:19:26.492341 11654 sgd_solver.cpp:112] Iteration 45840, lr = 0.1
I0524 07:19:35.720311 11654 solver.cpp:239] Iteration 45850 (1.08301 iter/s, 9.23353s/10 iters), loss = 6.74171
I0524 07:19:35.720369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74171 (* 1 = 6.74171 loss)
I0524 07:19:35.720630 11654 sgd_solver.cpp:112] Iteration 45850, lr = 0.1
I0524 07:19:43.742367 11654 solver.cpp:239] Iteration 45860 (1.24662 iter/s, 8.02169s/10 iters), loss = 5.5852
I0524 07:19:43.742599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5852 (* 1 = 5.5852 loss)
I0524 07:19:43.742658 11654 sgd_solver.cpp:112] Iteration 45860, lr = 0.1
I0524 07:19:51.452731 11654 solver.cpp:239] Iteration 45870 (1.29704 iter/s, 7.70985s/10 iters), loss = 5.79543
I0524 07:19:51.452785 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79543 (* 1 = 5.79543 loss)
I0524 07:19:51.452801 11654 sgd_solver.cpp:112] Iteration 45870, lr = 0.1
I0524 07:19:57.979935 11654 solver.cpp:239] Iteration 45880 (1.53212 iter/s, 6.5269s/10 iters), loss = 6.36116
I0524 07:19:57.980008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36116 (* 1 = 6.36116 loss)
I0524 07:19:57.980029 11654 sgd_solver.cpp:112] Iteration 45880, lr = 0.1
I0524 07:20:04.750133 11654 solver.cpp:239] Iteration 45890 (1.47727 iter/s, 6.76925s/10 iters), loss = 7.50285
I0524 07:20:04.750182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.50285 (* 1 = 7.50285 loss)
I0524 07:20:04.750198 11654 sgd_solver.cpp:112] Iteration 45890, lr = 0.1
I0524 07:20:11.329732 11654 solver.cpp:239] Iteration 45900 (1.51993 iter/s, 6.57923s/10 iters), loss = 6.90844
I0524 07:20:11.329783 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90844 (* 1 = 6.90844 loss)
I0524 07:20:11.329800 11654 sgd_solver.cpp:112] Iteration 45900, lr = 0.1
I0524 07:20:20.616741 11654 solver.cpp:239] Iteration 45910 (1.07684 iter/s, 9.28647s/10 iters), loss = 6.36053
I0524 07:20:20.616924 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36053 (* 1 = 6.36053 loss)
I0524 07:20:20.632431 11654 sgd_solver.cpp:112] Iteration 45910, lr = 0.1
I0524 07:20:28.339566 11654 solver.cpp:239] Iteration 45920 (1.29494 iter/s, 7.72235s/10 iters), loss = 7.10221
I0524 07:20:28.339653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.10221 (* 1 = 7.10221 loss)
I0524 07:20:29.192750 11654 sgd_solver.cpp:112] Iteration 45920, lr = 0.1
I0524 07:20:35.725006 11654 solver.cpp:239] Iteration 45930 (1.35408 iter/s, 7.38509s/10 iters), loss = 6.63302
I0524 07:20:35.725072 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63302 (* 1 = 6.63302 loss)
I0524 07:20:35.725092 11654 sgd_solver.cpp:112] Iteration 45930, lr = 0.1
I0524 07:20:42.250586 11654 solver.cpp:239] Iteration 45940 (1.53253 iter/s, 6.52518s/10 iters), loss = 6.47952
I0524 07:20:42.250633 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47952 (* 1 = 6.47952 loss)
I0524 07:20:42.250649 11654 sgd_solver.cpp:112] Iteration 45940, lr = 0.1
I0524 07:20:49.827800 11654 solver.cpp:239] Iteration 45950 (1.31981 iter/s, 7.57686s/10 iters), loss = 6.96153
I0524 07:20:49.827857 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96153 (* 1 = 6.96153 loss)
I0524 07:20:49.827874 11654 sgd_solver.cpp:112] Iteration 45950, lr = 0.1
I0524 07:21:00.914450 11654 solver.cpp:239] Iteration 45960 (0.90203 iter/s, 11.0861s/10 iters), loss = 6.68033
I0524 07:21:00.914827 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68033 (* 1 = 6.68033 loss)
I0524 07:21:00.914932 11654 sgd_solver.cpp:112] Iteration 45960, lr = 0.1
I0524 07:21:07.511873 11654 solver.cpp:239] Iteration 45970 (1.51586 iter/s, 6.59691s/10 iters), loss = 6.0849
I0524 07:21:07.511927 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0849 (* 1 = 6.0849 loss)
I0524 07:21:07.597931 11654 sgd_solver.cpp:112] Iteration 45970, lr = 0.1
I0524 07:21:15.441280 11654 solver.cpp:239] Iteration 45980 (1.26119 iter/s, 7.92904s/10 iters), loss = 6.02682
I0524 07:21:15.441345 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02682 (* 1 = 6.02682 loss)
I0524 07:21:15.441365 11654 sgd_solver.cpp:112] Iteration 45980, lr = 0.1
I0524 07:21:22.367645 11654 solver.cpp:239] Iteration 45990 (1.44384 iter/s, 6.92596s/10 iters), loss = 5.48351
I0524 07:21:22.367713 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48351 (* 1 = 5.48351 loss)
I0524 07:21:22.367738 11654 sgd_solver.cpp:112] Iteration 45990, lr = 0.1
I0524 07:21:28.722046 11654 solver.cpp:239] Iteration 46000 (1.5738 iter/s, 6.35405s/10 iters), loss = 5.66879
I0524 07:21:28.722095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66879 (* 1 = 5.66879 loss)
I0524 07:21:28.722204 11654 sgd_solver.cpp:112] Iteration 46000, lr = 0.1
I0524 07:21:36.302536 11654 solver.cpp:239] Iteration 46010 (1.31924 iter/s, 7.58012s/10 iters), loss = 6.11125
I0524 07:21:36.302809 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11125 (* 1 = 6.11125 loss)
I0524 07:21:36.303135 11654 sgd_solver.cpp:112] Iteration 46010, lr = 0.1
I0524 07:21:43.124831 11654 solver.cpp:239] Iteration 46020 (1.4659 iter/s, 6.82174s/10 iters), loss = 6.13918
I0524 07:21:43.124902 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13918 (* 1 = 6.13918 loss)
I0524 07:21:43.124967 11654 sgd_solver.cpp:112] Iteration 46020, lr = 0.1
I0524 07:21:51.818524 11654 solver.cpp:239] Iteration 46030 (1.15031 iter/s, 8.69329s/10 iters), loss = 6.04074
I0524 07:21:51.818608 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04074 (* 1 = 6.04074 loss)
I0524 07:21:51.994809 11654 sgd_solver.cpp:112] Iteration 46030, lr = 0.1
I0524 07:21:58.696894 11654 solver.cpp:239] Iteration 46040 (1.4539 iter/s, 6.87805s/10 iters), loss = 6.83993
I0524 07:21:58.696938 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83993 (* 1 = 6.83993 loss)
I0524 07:21:59.221487 11654 sgd_solver.cpp:112] Iteration 46040, lr = 0.1
I0524 07:22:06.855159 11654 solver.cpp:239] Iteration 46050 (1.22581 iter/s, 8.1579s/10 iters), loss = 5.75957
I0524 07:22:06.855396 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75957 (* 1 = 5.75957 loss)
I0524 07:22:06.855448 11654 sgd_solver.cpp:112] Iteration 46050, lr = 0.1
I0524 07:22:13.735299 11654 solver.cpp:239] Iteration 46060 (1.45356 iter/s, 6.87966s/10 iters), loss = 5.95076
I0524 07:22:13.735381 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95076 (* 1 = 5.95076 loss)
I0524 07:22:13.736603 11654 sgd_solver.cpp:112] Iteration 46060, lr = 0.1
I0524 07:22:20.476377 11654 solver.cpp:239] Iteration 46070 (1.48352 iter/s, 6.74074s/10 iters), loss = 5.58386
I0524 07:22:20.476439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58386 (* 1 = 5.58386 loss)
I0524 07:22:20.476461 11654 sgd_solver.cpp:112] Iteration 46070, lr = 0.1
I0524 07:22:27.209306 11654 solver.cpp:239] Iteration 46080 (1.48532 iter/s, 6.73255s/10 iters), loss = 6.51235
I0524 07:22:27.209419 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51235 (* 1 = 6.51235 loss)
I0524 07:22:27.209440 11654 sgd_solver.cpp:112] Iteration 46080, lr = 0.1
I0524 07:22:34.515542 11654 solver.cpp:239] Iteration 46090 (1.36876 iter/s, 7.30588s/10 iters), loss = 6.4727
I0524 07:22:34.515590 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4727 (* 1 = 6.4727 loss)
I0524 07:22:34.603658 11654 sgd_solver.cpp:112] Iteration 46090, lr = 0.1
I0524 07:22:41.088332 11654 solver.cpp:239] Iteration 46100 (1.5215 iter/s, 6.57244s/10 iters), loss = 6.74821
I0524 07:22:41.088644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74821 (* 1 = 6.74821 loss)
I0524 07:22:41.088732 11654 sgd_solver.cpp:112] Iteration 46100, lr = 0.1
I0524 07:22:48.785511 11654 solver.cpp:239] Iteration 46110 (1.29963 iter/s, 7.69453s/10 iters), loss = 6.42401
I0524 07:22:48.785564 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42401 (* 1 = 6.42401 loss)
I0524 07:22:48.785581 11654 sgd_solver.cpp:112] Iteration 46110, lr = 0.1
I0524 07:22:56.601969 11654 solver.cpp:239] Iteration 46120 (1.27978 iter/s, 7.81386s/10 iters), loss = 5.24621
I0524 07:22:56.602066 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.24621 (* 1 = 5.24621 loss)
I0524 07:22:56.602160 11654 sgd_solver.cpp:112] Iteration 46120, lr = 0.1
I0524 07:23:04.504842 11654 solver.cpp:239] Iteration 46130 (1.26543 iter/s, 7.90247s/10 iters), loss = 6.38466
I0524 07:23:04.504994 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38466 (* 1 = 6.38466 loss)
I0524 07:23:04.505039 11654 sgd_solver.cpp:112] Iteration 46130, lr = 0.1
I0524 07:23:12.384434 11654 solver.cpp:239] Iteration 46140 (1.26917 iter/s, 7.87916s/10 iters), loss = 6.12522
I0524 07:23:12.384681 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12522 (* 1 = 6.12522 loss)
I0524 07:23:12.384727 11654 sgd_solver.cpp:112] Iteration 46140, lr = 0.1
I0524 07:23:19.411281 11654 solver.cpp:239] Iteration 46150 (1.42322 iter/s, 7.02631s/10 iters), loss = 5.62247
I0524 07:23:19.411417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62247 (* 1 = 5.62247 loss)
I0524 07:23:19.669694 11654 sgd_solver.cpp:112] Iteration 46150, lr = 0.1
I0524 07:23:27.000784 11654 solver.cpp:239] Iteration 46160 (1.31767 iter/s, 7.58913s/10 iters), loss = 5.76988
I0524 07:23:27.000844 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76988 (* 1 = 5.76988 loss)
I0524 07:23:27.039327 11654 sgd_solver.cpp:112] Iteration 46160, lr = 0.1
I0524 07:23:36.786413 11654 solver.cpp:239] Iteration 46170 (1.02195 iter/s, 9.7852s/10 iters), loss = 6.46856
I0524 07:23:36.786471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46856 (* 1 = 6.46856 loss)
I0524 07:23:36.786516 11654 sgd_solver.cpp:112] Iteration 46170, lr = 0.1
I0524 07:23:43.602850 11654 solver.cpp:239] Iteration 46180 (1.46726 iter/s, 6.81543s/10 iters), loss = 5.49253
I0524 07:23:43.605047 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49253 (* 1 = 5.49253 loss)
I0524 07:23:44.043246 11654 sgd_solver.cpp:112] Iteration 46180, lr = 0.1
I0524 07:23:50.894608 11654 solver.cpp:239] Iteration 46190 (1.37213 iter/s, 7.28795s/10 iters), loss = 6.18713
I0524 07:23:50.894732 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18713 (* 1 = 6.18713 loss)
I0524 07:23:50.894816 11654 sgd_solver.cpp:112] Iteration 46190, lr = 0.1
I0524 07:23:57.186830 11654 solver.cpp:239] Iteration 46200 (1.58935 iter/s, 6.2919s/10 iters), loss = 6.04938
I0524 07:23:57.186872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04938 (* 1 = 6.04938 loss)
I0524 07:23:57.186887 11654 sgd_solver.cpp:112] Iteration 46200, lr = 0.1
I0524 07:24:03.919286 11654 solver.cpp:239] Iteration 46210 (1.48544 iter/s, 6.73203s/10 iters), loss = 5.16099
I0524 07:24:03.919379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.16099 (* 1 = 5.16099 loss)
I0524 07:24:03.919412 11654 sgd_solver.cpp:112] Iteration 46210, lr = 0.1
I0524 07:24:13.139035 11654 solver.cpp:239] Iteration 46220 (1.08493 iter/s, 9.21721s/10 iters), loss = 5.52089
I0524 07:24:13.139107 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.52089 (* 1 = 5.52089 loss)
I0524 07:24:13.139207 11654 sgd_solver.cpp:112] Iteration 46220, lr = 0.1
I0524 07:24:23.635215 11654 solver.cpp:239] Iteration 46230 (0.952772 iter/s, 10.4957s/10 iters), loss = 5.48071
I0524 07:24:23.635471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48071 (* 1 = 5.48071 loss)
I0524 07:24:23.635530 11654 sgd_solver.cpp:112] Iteration 46230, lr = 0.1
I0524 07:24:32.415920 11654 solver.cpp:239] Iteration 46240 (1.13896 iter/s, 8.77994s/10 iters), loss = 5.56636
I0524 07:24:32.415980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56636 (* 1 = 5.56636 loss)
I0524 07:24:32.415998 11654 sgd_solver.cpp:112] Iteration 46240, lr = 0.1
I0524 07:24:38.880187 11654 solver.cpp:239] Iteration 46250 (1.54705 iter/s, 6.46392s/10 iters), loss = 5.16762
I0524 07:24:38.880252 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.16762 (* 1 = 5.16762 loss)
I0524 07:24:38.880720 11654 sgd_solver.cpp:112] Iteration 46250, lr = 0.1
I0524 07:24:46.186362 11654 solver.cpp:239] Iteration 46260 (1.36877 iter/s, 7.30582s/10 iters), loss = 5.78315
I0524 07:24:46.186429 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78315 (* 1 = 5.78315 loss)
I0524 07:24:46.186448 11654 sgd_solver.cpp:112] Iteration 46260, lr = 0.1
I0524 07:24:52.541900 11654 solver.cpp:239] Iteration 46270 (1.57351 iter/s, 6.35523s/10 iters), loss = 6.18189
I0524 07:24:52.541961 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18189 (* 1 = 6.18189 loss)
I0524 07:24:52.542237 11654 sgd_solver.cpp:112] Iteration 46270, lr = 0.1
I0524 07:24:59.353617 11654 solver.cpp:239] Iteration 46280 (1.46814 iter/s, 6.81136s/10 iters), loss = 5.64469
I0524 07:24:59.353899 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64469 (* 1 = 5.64469 loss)
I0524 07:24:59.405812 11654 sgd_solver.cpp:112] Iteration 46280, lr = 0.1
I0524 07:25:06.960511 11654 solver.cpp:239] Iteration 46290 (1.31469 iter/s, 7.60635s/10 iters), loss = 6.22279
I0524 07:25:06.960570 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22279 (* 1 = 6.22279 loss)
I0524 07:25:06.960592 11654 sgd_solver.cpp:112] Iteration 46290, lr = 0.1
I0524 07:25:14.313973 11654 solver.cpp:239] Iteration 46300 (1.36037 iter/s, 7.35092s/10 iters), loss = 6.03558
I0524 07:25:14.314033 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03558 (* 1 = 6.03558 loss)
I0524 07:25:14.314203 11654 sgd_solver.cpp:112] Iteration 46300, lr = 0.1
I0524 07:25:20.909530 11654 solver.cpp:239] Iteration 46310 (1.51624 iter/s, 6.59525s/10 iters), loss = 6.81439
I0524 07:25:20.909598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81439 (* 1 = 6.81439 loss)
I0524 07:25:20.909616 11654 sgd_solver.cpp:112] Iteration 46310, lr = 0.1
I0524 07:25:28.069001 11654 solver.cpp:239] Iteration 46320 (1.39685 iter/s, 7.15896s/10 iters), loss = 5.551
I0524 07:25:28.069041 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.551 (* 1 = 5.551 loss)
I0524 07:25:28.069052 11654 sgd_solver.cpp:112] Iteration 46320, lr = 0.1
I0524 07:25:34.742612 11654 solver.cpp:239] Iteration 46330 (1.49851 iter/s, 6.67331s/10 iters), loss = 6.21984
I0524 07:25:34.742823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21984 (* 1 = 6.21984 loss)
I0524 07:25:34.746345 11654 sgd_solver.cpp:112] Iteration 46330, lr = 0.1
I0524 07:25:43.542474 11654 solver.cpp:239] Iteration 46340 (1.13645 iter/s, 8.79932s/10 iters), loss = 6.43962
I0524 07:25:43.542526 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43962 (* 1 = 6.43962 loss)
I0524 07:25:44.240391 11654 sgd_solver.cpp:112] Iteration 46340, lr = 0.1
I0524 07:25:51.726109 11654 solver.cpp:239] Iteration 46350 (1.22201 iter/s, 8.18327s/10 iters), loss = 5.1882
I0524 07:25:51.726163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.1882 (* 1 = 5.1882 loss)
I0524 07:25:52.318341 11654 sgd_solver.cpp:112] Iteration 46350, lr = 0.1
I0524 07:25:59.506256 11654 solver.cpp:239] Iteration 46360 (1.28538 iter/s, 7.77979s/10 iters), loss = 5.32398
I0524 07:25:59.506319 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.32398 (* 1 = 5.32398 loss)
I0524 07:25:59.506337 11654 sgd_solver.cpp:112] Iteration 46360, lr = 0.1
I0524 07:26:05.895468 11654 solver.cpp:239] Iteration 46370 (1.56576 iter/s, 6.38669s/10 iters), loss = 6.88236
I0524 07:26:05.895676 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88236 (* 1 = 6.88236 loss)
I0524 07:26:06.211975 11654 sgd_solver.cpp:112] Iteration 46370, lr = 0.1
I0524 07:26:13.559494 11654 solver.cpp:239] Iteration 46380 (1.30488 iter/s, 7.66353s/10 iters), loss = 5.82413
I0524 07:26:13.559556 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82413 (* 1 = 5.82413 loss)
I0524 07:26:13.559661 11654 sgd_solver.cpp:112] Iteration 46380, lr = 0.1
I0524 07:26:21.988493 11654 solver.cpp:239] Iteration 46390 (1.18644 iter/s, 8.4286s/10 iters), loss = 7.26034
I0524 07:26:21.988564 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26034 (* 1 = 7.26034 loss)
I0524 07:26:21.988585 11654 sgd_solver.cpp:112] Iteration 46390, lr = 0.1
I0524 07:26:28.610992 11654 solver.cpp:239] Iteration 46400 (1.51008 iter/s, 6.62215s/10 iters), loss = 5.13804
I0524 07:26:28.611042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.13804 (* 1 = 5.13804 loss)
I0524 07:26:28.611263 11654 sgd_solver.cpp:112] Iteration 46400, lr = 0.1
I0524 07:26:37.030685 11654 solver.cpp:239] Iteration 46410 (1.18775 iter/s, 8.4193s/10 iters), loss = 6.27576
I0524 07:26:37.031025 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27576 (* 1 = 6.27576 loss)
I0524 07:26:37.031117 11654 sgd_solver.cpp:112] Iteration 46410, lr = 0.1
I0524 07:26:45.272029 11654 solver.cpp:239] Iteration 46420 (1.21348 iter/s, 8.24077s/10 iters), loss = 7.01671
I0524 07:26:45.272099 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01671 (* 1 = 7.01671 loss)
I0524 07:26:45.272119 11654 sgd_solver.cpp:112] Iteration 46420, lr = 0.1
I0524 07:26:51.659974 11654 solver.cpp:239] Iteration 46430 (1.56606 iter/s, 6.38544s/10 iters), loss = 5.92799
I0524 07:26:51.660028 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92799 (* 1 = 5.92799 loss)
I0524 07:26:51.660311 11654 sgd_solver.cpp:112] Iteration 46430, lr = 0.1
I0524 07:27:01.173733 11654 solver.cpp:239] Iteration 46440 (1.05116 iter/s, 9.5133s/10 iters), loss = 5.6401
I0524 07:27:01.173805 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6401 (* 1 = 5.6401 loss)
I0524 07:27:01.173828 11654 sgd_solver.cpp:112] Iteration 46440, lr = 0.1
I0524 07:27:09.088182 11654 solver.cpp:239] Iteration 46450 (1.26358 iter/s, 7.91403s/10 iters), loss = 6.52938
I0524 07:27:09.088372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52938 (* 1 = 6.52938 loss)
I0524 07:27:09.088409 11654 sgd_solver.cpp:112] Iteration 46450, lr = 0.1
I0524 07:27:16.564805 11654 solver.cpp:239] Iteration 46460 (1.33759 iter/s, 7.47615s/10 iters), loss = 6.46686
I0524 07:27:16.564868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46686 (* 1 = 6.46686 loss)
I0524 07:27:16.569398 11654 sgd_solver.cpp:112] Iteration 46460, lr = 0.1
I0524 07:27:23.281090 11654 solver.cpp:239] Iteration 46470 (1.48901 iter/s, 6.71589s/10 iters), loss = 5.92525
I0524 07:27:23.281280 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92525 (* 1 = 5.92525 loss)
I0524 07:27:23.281316 11654 sgd_solver.cpp:112] Iteration 46470, lr = 0.1
I0524 07:27:34.322933 11654 solver.cpp:239] Iteration 46480 (0.905688 iter/s, 11.0413s/10 iters), loss = 6.58615
I0524 07:27:34.323001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58615 (* 1 = 6.58615 loss)
I0524 07:27:34.328402 11654 sgd_solver.cpp:112] Iteration 46480, lr = 0.1
I0524 07:27:42.306836 11654 solver.cpp:239] Iteration 46490 (1.25258 iter/s, 7.98352s/10 iters), loss = 5.47023
I0524 07:27:42.307152 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47023 (* 1 = 5.47023 loss)
I0524 07:27:42.307220 11654 sgd_solver.cpp:112] Iteration 46490, lr = 0.1
I0524 07:27:49.474413 11654 solver.cpp:239] Iteration 46500 (1.39568 iter/s, 7.16497s/10 iters), loss = 6.30156
I0524 07:27:49.474500 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30156 (* 1 = 6.30156 loss)
I0524 07:27:49.479691 11654 sgd_solver.cpp:112] Iteration 46500, lr = 0.1
I0524 07:27:57.650750 11654 solver.cpp:239] Iteration 46510 (1.2231 iter/s, 8.17595s/10 iters), loss = 6.20344
I0524 07:27:57.650810 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20344 (* 1 = 6.20344 loss)
I0524 07:27:57.651051 11654 sgd_solver.cpp:112] Iteration 46510, lr = 0.1
I0524 07:28:06.055533 11654 solver.cpp:239] Iteration 46520 (1.18985 iter/s, 8.40439s/10 iters), loss = 6.53607
I0524 07:28:06.055588 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53607 (* 1 = 6.53607 loss)
I0524 07:28:06.055605 11654 sgd_solver.cpp:112] Iteration 46520, lr = 0.1
I0524 07:28:14.957361 11654 solver.cpp:239] Iteration 46530 (1.12342 iter/s, 8.90138s/10 iters), loss = 5.66838
I0524 07:28:14.957641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66838 (* 1 = 5.66838 loss)
I0524 07:28:15.242928 11654 sgd_solver.cpp:112] Iteration 46530, lr = 0.1
I0524 07:28:22.684774 11654 solver.cpp:239] Iteration 46540 (1.29419 iter/s, 7.72686s/10 iters), loss = 6.04513
I0524 07:28:22.684864 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04513 (* 1 = 6.04513 loss)
I0524 07:28:22.684895 11654 sgd_solver.cpp:112] Iteration 46540, lr = 0.1
I0524 07:28:29.804147 11654 solver.cpp:239] Iteration 46550 (1.40469 iter/s, 7.11902s/10 iters), loss = 6.45864
I0524 07:28:29.804230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45864 (* 1 = 6.45864 loss)
I0524 07:28:29.804260 11654 sgd_solver.cpp:112] Iteration 46550, lr = 0.1
I0524 07:28:38.645252 11654 solver.cpp:239] Iteration 46560 (1.13114 iter/s, 8.84065s/10 iters), loss = 5.62312
I0524 07:28:38.645313 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62312 (* 1 = 5.62312 loss)
I0524 07:28:38.646430 11654 sgd_solver.cpp:112] Iteration 46560, lr = 0.1
I0524 07:28:47.686241 11654 solver.cpp:239] Iteration 46570 (1.10613 iter/s, 9.04056s/10 iters), loss = 6.18015
I0524 07:28:47.686470 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18015 (* 1 = 6.18015 loss)
I0524 07:28:47.686516 11654 sgd_solver.cpp:112] Iteration 46570, lr = 0.1
I0524 07:28:56.139966 11654 solver.cpp:239] Iteration 46580 (1.18299 iter/s, 8.45318s/10 iters), loss = 5.84071
I0524 07:28:56.140027 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84071 (* 1 = 5.84071 loss)
I0524 07:28:56.140138 11654 sgd_solver.cpp:112] Iteration 46580, lr = 0.1
I0524 07:29:04.158145 11654 solver.cpp:239] Iteration 46590 (1.24722 iter/s, 8.01782s/10 iters), loss = 5.70545
I0524 07:29:04.158207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70545 (* 1 = 5.70545 loss)
I0524 07:29:04.158226 11654 sgd_solver.cpp:112] Iteration 46590, lr = 0.1
I0524 07:29:12.330111 11654 solver.cpp:239] Iteration 46600 (1.22376 iter/s, 8.17153s/10 iters), loss = 6.22251
I0524 07:29:12.330178 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22251 (* 1 = 6.22251 loss)
I0524 07:29:12.330200 11654 sgd_solver.cpp:112] Iteration 46600, lr = 0.1
I0524 07:29:19.105887 11654 solver.cpp:239] Iteration 46610 (1.4764 iter/s, 6.77325s/10 iters), loss = 6.60836
I0524 07:29:19.106115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60836 (* 1 = 6.60836 loss)
I0524 07:29:19.208238 11654 sgd_solver.cpp:112] Iteration 46610, lr = 0.1
I0524 07:29:27.344818 11654 solver.cpp:239] Iteration 46620 (1.21383 iter/s, 8.2384s/10 iters), loss = 5.42075
I0524 07:29:27.344873 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42075 (* 1 = 5.42075 loss)
I0524 07:29:27.347663 11654 sgd_solver.cpp:112] Iteration 46620, lr = 0.1
I0524 07:29:37.381074 11654 solver.cpp:239] Iteration 46630 (0.996431 iter/s, 10.0358s/10 iters), loss = 7.12526
I0524 07:29:37.381134 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.12526 (* 1 = 7.12526 loss)
I0524 07:29:37.381723 11654 sgd_solver.cpp:112] Iteration 46630, lr = 0.1
I0524 07:29:44.379099 11654 solver.cpp:239] Iteration 46640 (1.42904 iter/s, 6.99768s/10 iters), loss = 6.14328
I0524 07:29:44.379156 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14328 (* 1 = 6.14328 loss)
I0524 07:29:44.379173 11654 sgd_solver.cpp:112] Iteration 46640, lr = 0.1
I0524 07:29:50.852289 11654 solver.cpp:239] Iteration 46650 (1.54492 iter/s, 6.47281s/10 iters), loss = 6.21537
I0524 07:29:50.852587 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21537 (* 1 = 6.21537 loss)
I0524 07:29:50.852635 11654 sgd_solver.cpp:112] Iteration 46650, lr = 0.1
I0524 07:29:57.372385 11654 solver.cpp:239] Iteration 46660 (1.53385 iter/s, 6.51955s/10 iters), loss = 5.95454
I0524 07:29:57.372428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95454 (* 1 = 5.95454 loss)
I0524 07:29:57.372442 11654 sgd_solver.cpp:112] Iteration 46660, lr = 0.1
I0524 07:30:04.175256 11654 solver.cpp:239] Iteration 46670 (1.47052 iter/s, 6.80033s/10 iters), loss = 6.14012
I0524 07:30:04.175320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14012 (* 1 = 6.14012 loss)
I0524 07:30:04.175446 11654 sgd_solver.cpp:112] Iteration 46670, lr = 0.1
I0524 07:30:10.565678 11654 solver.cpp:239] Iteration 46680 (1.56492 iter/s, 6.39011s/10 iters), loss = 6.27029
I0524 07:30:10.565749 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27029 (* 1 = 6.27029 loss)
I0524 07:30:10.584935 11654 sgd_solver.cpp:112] Iteration 46680, lr = 0.1
I0524 07:30:18.426195 11654 solver.cpp:239] Iteration 46690 (1.27224 iter/s, 7.86013s/10 iters), loss = 5.79516
I0524 07:30:18.426265 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79516 (* 1 = 5.79516 loss)
I0524 07:30:18.426288 11654 sgd_solver.cpp:112] Iteration 46690, lr = 0.1
I0524 07:30:24.935981 11654 solver.cpp:239] Iteration 46700 (1.53623 iter/s, 6.50944s/10 iters), loss = 7.23434
I0524 07:30:24.936272 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23434 (* 1 = 7.23434 loss)
I0524 07:30:24.974242 11654 sgd_solver.cpp:112] Iteration 46700, lr = 0.1
I0524 07:30:32.930580 11654 solver.cpp:239] Iteration 46710 (1.25092 iter/s, 7.99409s/10 iters), loss = 4.62475
I0524 07:30:32.930644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.62475 (* 1 = 4.62475 loss)
I0524 07:30:32.930851 11654 sgd_solver.cpp:112] Iteration 46710, lr = 0.1
I0524 07:30:39.480726 11654 solver.cpp:239] Iteration 46720 (1.52676 iter/s, 6.54982s/10 iters), loss = 6.43132
I0524 07:30:39.480796 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43132 (* 1 = 6.43132 loss)
I0524 07:30:39.913363 11654 sgd_solver.cpp:112] Iteration 46720, lr = 0.1
I0524 07:30:50.388993 11654 solver.cpp:239] Iteration 46730 (0.916778 iter/s, 10.9078s/10 iters), loss = 6.7383
I0524 07:30:50.389041 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7383 (* 1 = 6.7383 loss)
I0524 07:30:50.389207 11654 sgd_solver.cpp:112] Iteration 46730, lr = 0.1
I0524 07:30:58.955391 11654 solver.cpp:239] Iteration 46740 (1.16741 iter/s, 8.56596s/10 iters), loss = 5.42549
I0524 07:30:58.955654 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42549 (* 1 = 5.42549 loss)
I0524 07:30:58.985105 11654 sgd_solver.cpp:112] Iteration 46740, lr = 0.1
I0524 07:31:06.617836 11654 solver.cpp:239] Iteration 46750 (1.30516 iter/s, 7.6619s/10 iters), loss = 5.2115
I0524 07:31:06.617900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.2115 (* 1 = 5.2115 loss)
I0524 07:31:06.618923 11654 sgd_solver.cpp:112] Iteration 46750, lr = 0.1
I0524 07:31:13.289052 11654 solver.cpp:239] Iteration 46760 (1.49906 iter/s, 6.67084s/10 iters), loss = 6.49899
I0524 07:31:13.289201 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49899 (* 1 = 6.49899 loss)
I0524 07:31:14.377970 11654 sgd_solver.cpp:112] Iteration 46760, lr = 0.1
I0524 07:31:22.361966 11654 solver.cpp:239] Iteration 46770 (1.10223 iter/s, 9.07248s/10 iters), loss = 6.56955
I0524 07:31:22.362035 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56955 (* 1 = 6.56955 loss)
I0524 07:31:22.851433 11654 sgd_solver.cpp:112] Iteration 46770, lr = 0.1
I0524 07:31:29.539433 11654 solver.cpp:239] Iteration 46780 (1.39332 iter/s, 7.1771s/10 iters), loss = 5.40786
I0524 07:31:29.539736 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40786 (* 1 = 5.40786 loss)
I0524 07:31:29.539806 11654 sgd_solver.cpp:112] Iteration 46780, lr = 0.1
I0524 07:31:36.768062 11654 solver.cpp:239] Iteration 46790 (1.38349 iter/s, 7.2281s/10 iters), loss = 6.03515
I0524 07:31:36.768182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03515 (* 1 = 6.03515 loss)
I0524 07:31:36.768206 11654 sgd_solver.cpp:112] Iteration 46790, lr = 0.1
I0524 07:31:44.173246 11654 solver.cpp:239] Iteration 46800 (1.35048 iter/s, 7.40476s/10 iters), loss = 5.54416
I0524 07:31:44.173326 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54416 (* 1 = 5.54416 loss)
I0524 07:31:44.304286 11654 sgd_solver.cpp:112] Iteration 46800, lr = 0.1
I0524 07:31:50.934404 11654 solver.cpp:239] Iteration 46810 (1.47912 iter/s, 6.76079s/10 iters), loss = 6.09482
I0524 07:31:50.934476 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09482 (* 1 = 6.09482 loss)
I0524 07:31:50.940424 11654 sgd_solver.cpp:112] Iteration 46810, lr = 0.1
I0524 07:31:58.327102 11654 solver.cpp:239] Iteration 46820 (1.35275 iter/s, 7.39235s/10 iters), loss = 6.49002
I0524 07:31:58.327142 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49002 (* 1 = 6.49002 loss)
I0524 07:31:58.327174 11654 sgd_solver.cpp:112] Iteration 46820, lr = 0.1
I0524 07:32:05.218324 11654 solver.cpp:239] Iteration 46830 (1.45119 iter/s, 6.8909s/10 iters), loss = 5.76779
I0524 07:32:05.218575 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76779 (* 1 = 5.76779 loss)
I0524 07:32:05.218605 11654 sgd_solver.cpp:112] Iteration 46830, lr = 0.1
I0524 07:32:14.103952 11654 solver.cpp:239] Iteration 46840 (1.12552 iter/s, 8.88479s/10 iters), loss = 6.02001
I0524 07:32:14.104007 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02001 (* 1 = 6.02001 loss)
I0524 07:32:14.826090 11654 sgd_solver.cpp:112] Iteration 46840, lr = 0.1
I0524 07:32:21.317780 11654 solver.cpp:239] Iteration 46850 (1.38629 iter/s, 7.21348s/10 iters), loss = 5.88715
I0524 07:32:21.317858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88715 (* 1 = 5.88715 loss)
I0524 07:32:21.318066 11654 sgd_solver.cpp:112] Iteration 46850, lr = 0.1
I0524 07:32:27.798179 11654 solver.cpp:239] Iteration 46860 (1.54319 iter/s, 6.48007s/10 iters), loss = 6.35324
I0524 07:32:27.798267 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35324 (* 1 = 6.35324 loss)
I0524 07:32:27.798297 11654 sgd_solver.cpp:112] Iteration 46860, lr = 0.1
I0524 07:32:36.408908 11654 solver.cpp:239] Iteration 46870 (1.1614 iter/s, 8.61028s/10 iters), loss = 5.63685
I0524 07:32:36.409080 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63685 (* 1 = 5.63685 loss)
I0524 07:32:37.118913 11654 sgd_solver.cpp:112] Iteration 46870, lr = 0.1
I0524 07:32:45.055846 11654 solver.cpp:239] Iteration 46880 (1.15654 iter/s, 8.64645s/10 iters), loss = 7.1253
I0524 07:32:45.055888 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.1253 (* 1 = 7.1253 loss)
I0524 07:32:45.055900 11654 sgd_solver.cpp:112] Iteration 46880, lr = 0.1
I0524 07:32:52.873705 11654 solver.cpp:239] Iteration 46890 (1.27928 iter/s, 7.81687s/10 iters), loss = 5.83399
I0524 07:32:52.873778 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83399 (* 1 = 5.83399 loss)
I0524 07:32:52.874325 11654 sgd_solver.cpp:112] Iteration 46890, lr = 0.1
I0524 07:32:59.585440 11654 solver.cpp:239] Iteration 46900 (1.49 iter/s, 6.71141s/10 iters), loss = 5.85285
I0524 07:32:59.585494 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85285 (* 1 = 5.85285 loss)
I0524 07:32:59.585510 11654 sgd_solver.cpp:112] Iteration 46900, lr = 0.1
I0524 07:33:07.708143 11654 solver.cpp:239] Iteration 46910 (1.23119 iter/s, 8.12224s/10 iters), loss = 4.93174
I0524 07:33:07.708427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.93174 (* 1 = 4.93174 loss)
I0524 07:33:07.708461 11654 sgd_solver.cpp:112] Iteration 46910, lr = 0.1
I0524 07:33:16.160001 11654 solver.cpp:239] Iteration 46920 (1.18355 iter/s, 8.44914s/10 iters), loss = 5.85016
I0524 07:33:16.160068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85016 (* 1 = 5.85016 loss)
I0524 07:33:16.160092 11654 sgd_solver.cpp:112] Iteration 46920, lr = 0.1
I0524 07:33:23.597811 11654 solver.cpp:239] Iteration 46930 (1.34455 iter/s, 7.43745s/10 iters), loss = 6.23127
I0524 07:33:23.597896 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23127 (* 1 = 6.23127 loss)
I0524 07:33:23.597919 11654 sgd_solver.cpp:112] Iteration 46930, lr = 0.1
I0524 07:33:30.151345 11654 solver.cpp:239] Iteration 46940 (1.52598 iter/s, 6.55317s/10 iters), loss = 6.19614
I0524 07:33:30.151404 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19614 (* 1 = 6.19614 loss)
I0524 07:33:30.151772 11654 sgd_solver.cpp:112] Iteration 46940, lr = 0.1
I0524 07:33:37.116609 11654 solver.cpp:239] Iteration 46950 (1.43576 iter/s, 6.96494s/10 iters), loss = 5.26991
I0524 07:33:37.116654 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26991 (* 1 = 5.26991 loss)
I0524 07:33:37.116669 11654 sgd_solver.cpp:112] Iteration 46950, lr = 0.1
I0524 07:33:43.564268 11654 solver.cpp:239] Iteration 46960 (1.55117 iter/s, 6.44674s/10 iters), loss = 6.36872
I0524 07:33:43.564527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36872 (* 1 = 6.36872 loss)
I0524 07:33:43.564574 11654 sgd_solver.cpp:112] Iteration 46960, lr = 0.1
I0524 07:33:50.656288 11654 solver.cpp:239] Iteration 46970 (1.41014 iter/s, 7.09148s/10 iters), loss = 5.63526
I0524 07:33:50.656353 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63526 (* 1 = 5.63526 loss)
I0524 07:33:50.656453 11654 sgd_solver.cpp:112] Iteration 46970, lr = 0.1
I0524 07:33:58.470717 11654 solver.cpp:239] Iteration 46980 (1.27975 iter/s, 7.81402s/10 iters), loss = 5.46259
I0524 07:33:58.470799 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46259 (* 1 = 5.46259 loss)
I0524 07:33:58.470823 11654 sgd_solver.cpp:112] Iteration 46980, lr = 0.1
I0524 07:34:05.286006 11654 solver.cpp:239] Iteration 46990 (1.46749 iter/s, 6.81438s/10 iters), loss = 6.73724
I0524 07:34:05.286056 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73724 (* 1 = 6.73724 loss)
I0524 07:34:05.286074 11654 sgd_solver.cpp:112] Iteration 46990, lr = 0.1
I0524 07:34:12.619282 11654 solver.cpp:239] Iteration 47000 (1.36412 iter/s, 7.33076s/10 iters), loss = 6.21688
I0524 07:34:12.619359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21688 (* 1 = 6.21688 loss)
I0524 07:34:12.619379 11654 sgd_solver.cpp:112] Iteration 47000, lr = 0.1
I0524 07:34:19.903884 11654 solver.cpp:239] Iteration 47010 (1.37324 iter/s, 7.28206s/10 iters), loss = 6.15841
I0524 07:34:19.904040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15841 (* 1 = 6.15841 loss)
I0524 07:34:19.904059 11654 sgd_solver.cpp:112] Iteration 47010, lr = 0.1
I0524 07:34:27.869046 11654 solver.cpp:239] Iteration 47020 (1.25589 iter/s, 7.96249s/10 iters), loss = 5.67638
I0524 07:34:27.869117 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67638 (* 1 = 5.67638 loss)
I0524 07:34:27.869263 11654 sgd_solver.cpp:112] Iteration 47020, lr = 0.1
I0524 07:34:34.075124 11654 solver.cpp:239] Iteration 47030 (1.61141 iter/s, 6.20576s/10 iters), loss = 5.55073
I0524 07:34:34.075198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55073 (* 1 = 5.55073 loss)
I0524 07:34:34.075219 11654 sgd_solver.cpp:112] Iteration 47030, lr = 0.1
I0524 07:34:41.686064 11654 solver.cpp:239] Iteration 47040 (1.31396 iter/s, 7.61058s/10 iters), loss = 6.12175
I0524 07:34:41.686120 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12175 (* 1 = 6.12175 loss)
I0524 07:34:41.686136 11654 sgd_solver.cpp:112] Iteration 47040, lr = 0.1
I0524 07:34:48.362874 11654 solver.cpp:239] Iteration 47050 (1.4978 iter/s, 6.67644s/10 iters), loss = 6.61373
I0524 07:34:48.362920 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61373 (* 1 = 6.61373 loss)
I0524 07:34:48.363016 11654 sgd_solver.cpp:112] Iteration 47050, lr = 0.1
I0524 07:34:55.387073 11654 solver.cpp:239] Iteration 47060 (1.42372 iter/s, 7.02386s/10 iters), loss = 6.13955
I0524 07:34:55.387382 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13955 (* 1 = 6.13955 loss)
I0524 07:34:56.070724 11654 sgd_solver.cpp:112] Iteration 47060, lr = 0.1
I0524 07:35:02.747099 11654 solver.cpp:239] Iteration 47070 (1.3588 iter/s, 7.35946s/10 iters), loss = 6.95195
I0524 07:35:02.747215 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95195 (* 1 = 6.95195 loss)
I0524 07:35:02.747246 11654 sgd_solver.cpp:112] Iteration 47070, lr = 0.1
I0524 07:35:12.086220 11654 solver.cpp:239] Iteration 47080 (1.07082 iter/s, 9.33864s/10 iters), loss = 5.82174
I0524 07:35:12.086261 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82174 (* 1 = 5.82174 loss)
I0524 07:35:12.086462 11654 sgd_solver.cpp:112] Iteration 47080, lr = 0.1
I0524 07:35:20.716593 11654 solver.cpp:239] Iteration 47090 (1.15875 iter/s, 8.62999s/10 iters), loss = 6.84599
I0524 07:35:20.716650 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84599 (* 1 = 6.84599 loss)
I0524 07:35:20.774835 11654 sgd_solver.cpp:112] Iteration 47090, lr = 0.1
I0524 07:35:27.207880 11654 solver.cpp:239] Iteration 47100 (1.54061 iter/s, 6.49096s/10 iters), loss = 6.60068
I0524 07:35:27.208094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60068 (* 1 = 6.60068 loss)
I0524 07:35:27.208189 11654 sgd_solver.cpp:112] Iteration 47100, lr = 0.1
I0524 07:35:35.323024 11654 solver.cpp:239] Iteration 47110 (1.23234 iter/s, 8.11465s/10 iters), loss = 6.6949
I0524 07:35:35.323098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6949 (* 1 = 6.6949 loss)
I0524 07:35:35.357753 11654 sgd_solver.cpp:112] Iteration 47110, lr = 0.1
I0524 07:35:45.252193 11654 solver.cpp:239] Iteration 47120 (1.00718 iter/s, 9.9287s/10 iters), loss = 6.80496
I0524 07:35:45.252282 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80496 (* 1 = 6.80496 loss)
I0524 07:35:45.252300 11654 sgd_solver.cpp:112] Iteration 47120, lr = 0.1
I0524 07:35:53.603559 11654 solver.cpp:239] Iteration 47130 (1.19747 iter/s, 8.35096s/10 iters), loss = 6.03593
I0524 07:35:53.603618 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03593 (* 1 = 6.03593 loss)
I0524 07:35:53.603749 11654 sgd_solver.cpp:112] Iteration 47130, lr = 0.1
I0524 07:36:00.711844 11654 solver.cpp:239] Iteration 47140 (1.40687 iter/s, 7.10796s/10 iters), loss = 5.478
I0524 07:36:00.712055 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.478 (* 1 = 5.478 loss)
I0524 07:36:00.712090 11654 sgd_solver.cpp:112] Iteration 47140, lr = 0.1
I0524 07:36:07.191865 11654 solver.cpp:239] Iteration 47150 (1.54332 iter/s, 6.47952s/10 iters), loss = 5.63034
I0524 07:36:07.191931 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63034 (* 1 = 5.63034 loss)
I0524 07:36:07.192073 11654 sgd_solver.cpp:112] Iteration 47150, lr = 0.1
I0524 07:36:14.184113 11654 solver.cpp:239] Iteration 47160 (1.43023 iter/s, 6.9919s/10 iters), loss = 6.45637
I0524 07:36:14.184191 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45637 (* 1 = 6.45637 loss)
I0524 07:36:14.184507 11654 sgd_solver.cpp:112] Iteration 47160, lr = 0.1
I0524 07:36:20.604193 11654 solver.cpp:239] Iteration 47170 (1.55769 iter/s, 6.41975s/10 iters), loss = 6.18378
I0524 07:36:20.604259 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18378 (* 1 = 6.18378 loss)
I0524 07:36:20.604279 11654 sgd_solver.cpp:112] Iteration 47170, lr = 0.1
I0524 07:36:27.197299 11654 solver.cpp:239] Iteration 47180 (1.51681 iter/s, 6.59278s/10 iters), loss = 5.58969
I0524 07:36:27.197371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58969 (* 1 = 5.58969 loss)
I0524 07:36:27.224480 11654 sgd_solver.cpp:112] Iteration 47180, lr = 0.1
I0524 07:36:33.911311 11654 solver.cpp:239] Iteration 47190 (1.48949 iter/s, 6.71369s/10 iters), loss = 6.35515
I0524 07:36:33.911604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35515 (* 1 = 6.35515 loss)
I0524 07:36:33.911653 11654 sgd_solver.cpp:112] Iteration 47190, lr = 0.1
I0524 07:36:41.080907 11654 solver.cpp:239] Iteration 47200 (1.39489 iter/s, 7.16904s/10 iters), loss = 5.54334
I0524 07:36:41.080947 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54334 (* 1 = 5.54334 loss)
I0524 07:36:41.099525 11654 sgd_solver.cpp:112] Iteration 47200, lr = 0.1
I0524 07:36:48.072757 11654 solver.cpp:239] Iteration 47210 (1.43031 iter/s, 6.99147s/10 iters), loss = 6.43382
I0524 07:36:48.072865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43382 (* 1 = 6.43382 loss)
I0524 07:36:48.830862 11654 sgd_solver.cpp:112] Iteration 47210, lr = 0.1
I0524 07:36:56.712313 11654 solver.cpp:239] Iteration 47220 (1.15752 iter/s, 8.63915s/10 iters), loss = 6.68173
I0524 07:36:56.712368 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68173 (* 1 = 6.68173 loss)
I0524 07:36:57.029500 11654 sgd_solver.cpp:112] Iteration 47220, lr = 0.1
I0524 07:37:03.901840 11654 solver.cpp:239] Iteration 47230 (1.39098 iter/s, 7.18918s/10 iters), loss = 5.2609
I0524 07:37:03.901955 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.2609 (* 1 = 5.2609 loss)
I0524 07:37:03.902034 11654 sgd_solver.cpp:112] Iteration 47230, lr = 0.1
I0524 07:37:10.592056 11654 solver.cpp:239] Iteration 47240 (1.49479 iter/s, 6.68988s/10 iters), loss = 5.68839
I0524 07:37:10.592216 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68839 (* 1 = 5.68839 loss)
I0524 07:37:11.268121 11654 sgd_solver.cpp:112] Iteration 47240, lr = 0.1
I0524 07:37:18.013679 11654 solver.cpp:239] Iteration 47250 (1.34749 iter/s, 7.42121s/10 iters), loss = 6.09014
I0524 07:37:18.013720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09014 (* 1 = 6.09014 loss)
I0524 07:37:18.518534 11654 sgd_solver.cpp:112] Iteration 47250, lr = 0.1
I0524 07:37:27.484400 11654 solver.cpp:239] Iteration 47260 (1.05594 iter/s, 9.47027s/10 iters), loss = 6.3228
I0524 07:37:27.484510 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3228 (* 1 = 6.3228 loss)
I0524 07:37:28.216992 11654 sgd_solver.cpp:112] Iteration 47260, lr = 0.1
I0524 07:37:36.471602 11654 solver.cpp:239] Iteration 47270 (1.11275 iter/s, 8.98677s/10 iters), loss = 5.22503
I0524 07:37:36.471676 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.22503 (* 1 = 5.22503 loss)
I0524 07:37:36.471698 11654 sgd_solver.cpp:112] Iteration 47270, lr = 0.1
I0524 07:37:44.090039 11654 solver.cpp:239] Iteration 47280 (1.31304 iter/s, 7.61592s/10 iters), loss = 6.68746
I0524 07:37:44.090314 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68746 (* 1 = 6.68746 loss)
I0524 07:37:44.090418 11654 sgd_solver.cpp:112] Iteration 47280, lr = 0.1
I0524 07:37:53.165307 11654 solver.cpp:239] Iteration 47290 (1.10197 iter/s, 9.0747s/10 iters), loss = 6.3516
I0524 07:37:53.165361 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3516 (* 1 = 6.3516 loss)
I0524 07:37:53.165385 11654 sgd_solver.cpp:112] Iteration 47290, lr = 0.1
I0524 07:38:01.201324 11654 solver.cpp:239] Iteration 47300 (1.24447 iter/s, 8.03555s/10 iters), loss = 4.39604
I0524 07:38:01.201396 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.39604 (* 1 = 4.39604 loss)
I0524 07:38:01.201784 11654 sgd_solver.cpp:112] Iteration 47300, lr = 0.1
I0524 07:38:07.470324 11654 solver.cpp:239] Iteration 47310 (1.59523 iter/s, 6.26869s/10 iters), loss = 5.99819
I0524 07:38:07.470376 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99819 (* 1 = 5.99819 loss)
I0524 07:38:07.899145 11654 sgd_solver.cpp:112] Iteration 47310, lr = 0.1
I0524 07:38:14.142146 11654 solver.cpp:239] Iteration 47320 (1.49891 iter/s, 6.6715s/10 iters), loss = 6.24149
I0524 07:38:14.142406 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24149 (* 1 = 6.24149 loss)
I0524 07:38:14.142441 11654 sgd_solver.cpp:112] Iteration 47320, lr = 0.1
I0524 07:38:23.266520 11654 solver.cpp:239] Iteration 47330 (1.09603 iter/s, 9.1238s/10 iters), loss = 6.32203
I0524 07:38:23.266607 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32203 (* 1 = 6.32203 loss)
I0524 07:38:23.266983 11654 sgd_solver.cpp:112] Iteration 47330, lr = 0.1
I0524 07:38:30.668992 11654 solver.cpp:239] Iteration 47340 (1.35096 iter/s, 7.40212s/10 iters), loss = 5.63818
I0524 07:38:30.669070 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63818 (* 1 = 5.63818 loss)
I0524 07:38:30.669250 11654 sgd_solver.cpp:112] Iteration 47340, lr = 0.1
I0524 07:38:40.184506 11654 solver.cpp:239] Iteration 47350 (1.05097 iter/s, 9.51506s/10 iters), loss = 6.87588
I0524 07:38:40.184597 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87588 (* 1 = 6.87588 loss)
I0524 07:38:40.184618 11654 sgd_solver.cpp:112] Iteration 47350, lr = 0.1
I0524 07:38:47.106490 11654 solver.cpp:239] Iteration 47360 (1.44474 iter/s, 6.92166s/10 iters), loss = 6.90181
I0524 07:38:47.106673 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90181 (* 1 = 6.90181 loss)
I0524 07:38:47.106712 11654 sgd_solver.cpp:112] Iteration 47360, lr = 0.1
I0524 07:38:55.198514 11654 solver.cpp:239] Iteration 47370 (1.23587 iter/s, 8.09148s/10 iters), loss = 6.226
I0524 07:38:55.198583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.226 (* 1 = 6.226 loss)
I0524 07:38:55.445662 11654 sgd_solver.cpp:112] Iteration 47370, lr = 0.1
I0524 07:39:03.777958 11654 solver.cpp:239] Iteration 47380 (1.16563 iter/s, 8.57904s/10 iters), loss = 6.15862
I0524 07:39:03.778034 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15862 (* 1 = 6.15862 loss)
I0524 07:39:03.778407 11654 sgd_solver.cpp:112] Iteration 47380, lr = 0.1
I0524 07:39:11.312150 11654 solver.cpp:239] Iteration 47390 (1.32735 iter/s, 7.53384s/10 iters), loss = 7.09256
I0524 07:39:11.312211 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.09256 (* 1 = 7.09256 loss)
I0524 07:39:11.312243 11654 sgd_solver.cpp:112] Iteration 47390, lr = 0.1
I0524 07:39:19.395987 11654 solver.cpp:239] Iteration 47400 (1.2371 iter/s, 8.08342s/10 iters), loss = 6.73119
I0524 07:39:19.396114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73119 (* 1 = 6.73119 loss)
I0524 07:39:19.994557 11654 sgd_solver.cpp:112] Iteration 47400, lr = 0.1
I0524 07:39:26.952186 11654 solver.cpp:239] Iteration 47410 (1.32349 iter/s, 7.55578s/10 iters), loss = 5.81532
I0524 07:39:26.952261 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81532 (* 1 = 5.81532 loss)
I0524 07:39:26.956698 11654 sgd_solver.cpp:112] Iteration 47410, lr = 0.1
I0524 07:39:34.073689 11654 solver.cpp:239] Iteration 47420 (1.40426 iter/s, 7.12117s/10 iters), loss = 6.26777
I0524 07:39:34.073734 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26777 (* 1 = 6.26777 loss)
I0524 07:39:34.211640 11654 sgd_solver.cpp:112] Iteration 47420, lr = 0.1
I0524 07:39:41.220527 11654 solver.cpp:239] Iteration 47430 (1.39928 iter/s, 7.14651s/10 iters), loss = 6.12165
I0524 07:39:41.220588 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12165 (* 1 = 6.12165 loss)
I0524 07:39:41.220612 11654 sgd_solver.cpp:112] Iteration 47430, lr = 0.1
I0524 07:39:48.405210 11654 solver.cpp:239] Iteration 47440 (1.39191 iter/s, 7.18435s/10 iters), loss = 6.21111
I0524 07:39:48.405261 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21111 (* 1 = 6.21111 loss)
I0524 07:39:49.095914 11654 sgd_solver.cpp:112] Iteration 47440, lr = 0.1
I0524 07:39:57.712913 11654 solver.cpp:239] Iteration 47450 (1.07443 iter/s, 9.30728s/10 iters), loss = 6.50137
I0524 07:39:57.713172 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50137 (* 1 = 6.50137 loss)
I0524 07:39:57.713421 11654 sgd_solver.cpp:112] Iteration 47450, lr = 0.1
I0524 07:40:05.563427 11654 solver.cpp:239] Iteration 47460 (1.27389 iter/s, 7.84997s/10 iters), loss = 6.9053
I0524 07:40:05.563549 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9053 (* 1 = 6.9053 loss)
I0524 07:40:05.563585 11654 sgd_solver.cpp:112] Iteration 47460, lr = 0.1
I0524 07:40:13.982452 11654 solver.cpp:239] Iteration 47470 (1.18784 iter/s, 8.41862s/10 iters), loss = 5.38682
I0524 07:40:13.982537 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.38682 (* 1 = 5.38682 loss)
I0524 07:40:13.982568 11654 sgd_solver.cpp:112] Iteration 47470, lr = 0.1
I0524 07:40:21.671902 11654 solver.cpp:239] Iteration 47480 (1.30055 iter/s, 7.68907s/10 iters), loss = 6.46333
I0524 07:40:21.671988 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46333 (* 1 = 6.46333 loss)
I0524 07:40:21.991673 11654 sgd_solver.cpp:112] Iteration 47480, lr = 0.1
I0524 07:40:29.524171 11654 solver.cpp:239] Iteration 47490 (1.27358 iter/s, 7.85191s/10 iters), loss = 5.79364
I0524 07:40:29.524267 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79364 (* 1 = 5.79364 loss)
I0524 07:40:29.524281 11654 sgd_solver.cpp:112] Iteration 47490, lr = 0.1
I0524 07:40:37.161999 11654 solver.cpp:239] Iteration 47500 (1.30934 iter/s, 7.63741s/10 iters), loss = 6.8969
I0524 07:40:37.162065 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8969 (* 1 = 6.8969 loss)
I0524 07:40:37.162215 11654 sgd_solver.cpp:112] Iteration 47500, lr = 0.1
I0524 07:40:44.366892 11654 solver.cpp:239] Iteration 47510 (1.38801 iter/s, 7.20454s/10 iters), loss = 5.24038
I0524 07:40:44.366960 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.24038 (* 1 = 5.24038 loss)
I0524 07:40:44.378576 11654 sgd_solver.cpp:112] Iteration 47510, lr = 0.1
I0524 07:40:50.888429 11654 solver.cpp:239] Iteration 47520 (1.53346 iter/s, 6.5212s/10 iters), loss = 6.66009
I0524 07:40:50.888499 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66009 (* 1 = 6.66009 loss)
I0524 07:40:50.888519 11654 sgd_solver.cpp:112] Iteration 47520, lr = 0.1
I0524 07:40:57.292508 11654 solver.cpp:239] Iteration 47530 (1.56158 iter/s, 6.40376s/10 iters), loss = 5.49857
I0524 07:40:57.292598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49857 (* 1 = 5.49857 loss)
I0524 07:40:57.294498 11654 sgd_solver.cpp:112] Iteration 47530, lr = 0.1
I0524 07:41:04.641849 11654 solver.cpp:239] Iteration 47540 (1.36073 iter/s, 7.34898s/10 iters), loss = 5.90566
I0524 07:41:04.642083 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90566 (* 1 = 5.90566 loss)
I0524 07:41:04.775494 11654 sgd_solver.cpp:112] Iteration 47540, lr = 0.1
I0524 07:41:16.427974 11654 solver.cpp:239] Iteration 47550 (0.848505 iter/s, 11.7854s/10 iters), loss = 5.59473
I0524 07:41:16.428095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59473 (* 1 = 5.59473 loss)
I0524 07:41:17.564553 11654 sgd_solver.cpp:112] Iteration 47550, lr = 0.1
I0524 07:41:24.168179 11654 solver.cpp:239] Iteration 47560 (1.29202 iter/s, 7.7398s/10 iters), loss = 5.75292
I0524 07:41:24.168303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75292 (* 1 = 5.75292 loss)
I0524 07:41:24.168339 11654 sgd_solver.cpp:112] Iteration 47560, lr = 0.1
I0524 07:41:31.307433 11654 solver.cpp:239] Iteration 47570 (1.40079 iter/s, 7.13884s/10 iters), loss = 5.25686
I0524 07:41:31.307507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.25686 (* 1 = 5.25686 loss)
I0524 07:41:31.307525 11654 sgd_solver.cpp:112] Iteration 47570, lr = 0.1
I0524 07:41:37.780019 11654 solver.cpp:239] Iteration 47580 (1.54558 iter/s, 6.47007s/10 iters), loss = 5.79026
I0524 07:41:37.780292 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79026 (* 1 = 5.79026 loss)
I0524 07:41:37.780517 11654 sgd_solver.cpp:112] Iteration 47580, lr = 0.1
I0524 07:41:44.801771 11654 solver.cpp:239] Iteration 47590 (1.42425 iter/s, 7.02123s/10 iters), loss = 5.67604
I0524 07:41:44.801833 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67604 (* 1 = 5.67604 loss)
I0524 07:41:44.801962 11654 sgd_solver.cpp:112] Iteration 47590, lr = 0.1
I0524 07:41:51.373659 11654 solver.cpp:239] Iteration 47600 (1.52171 iter/s, 6.57157s/10 iters), loss = 5.89593
I0524 07:41:51.373719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89593 (* 1 = 5.89593 loss)
I0524 07:41:51.373736 11654 sgd_solver.cpp:112] Iteration 47600, lr = 0.1
I0524 07:41:58.734517 11654 solver.cpp:239] Iteration 47610 (1.35861 iter/s, 7.36044s/10 iters), loss = 6.42119
I0524 07:41:58.734583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42119 (* 1 = 6.42119 loss)
I0524 07:41:58.734730 11654 sgd_solver.cpp:112] Iteration 47610, lr = 0.1
I0524 07:42:06.333608 11654 solver.cpp:239] Iteration 47620 (1.31601 iter/s, 7.59874s/10 iters), loss = 6.53734
I0524 07:42:06.333674 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53734 (* 1 = 6.53734 loss)
I0524 07:42:06.333865 11654 sgd_solver.cpp:112] Iteration 47620, lr = 0.1
I0524 07:42:13.393033 11654 solver.cpp:239] Iteration 47630 (1.41661 iter/s, 7.05909s/10 iters), loss = 5.31113
I0524 07:42:13.393281 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.31113 (* 1 = 5.31113 loss)
I0524 07:42:13.393334 11654 sgd_solver.cpp:112] Iteration 47630, lr = 0.1
I0524 07:42:20.952708 11654 solver.cpp:239] Iteration 47640 (1.32289 iter/s, 7.55919s/10 iters), loss = 6.01472
I0524 07:42:20.952759 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01472 (* 1 = 6.01472 loss)
I0524 07:42:20.952776 11654 sgd_solver.cpp:112] Iteration 47640, lr = 0.1
I0524 07:42:31.334731 11654 solver.cpp:239] Iteration 47650 (0.963252 iter/s, 10.3815s/10 iters), loss = 6.44797
I0524 07:42:31.334787 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44797 (* 1 = 6.44797 loss)
I0524 07:42:32.169518 11654 sgd_solver.cpp:112] Iteration 47650, lr = 0.1
I0524 07:42:40.234320 11654 solver.cpp:239] Iteration 47660 (1.1237 iter/s, 8.89917s/10 iters), loss = 6.32926
I0524 07:42:40.234367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32926 (* 1 = 6.32926 loss)
I0524 07:42:40.234464 11654 sgd_solver.cpp:112] Iteration 47660, lr = 0.1
I0524 07:42:47.884179 11654 solver.cpp:239] Iteration 47670 (1.30728 iter/s, 7.64948s/10 iters), loss = 6.46382
I0524 07:42:47.884410 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46382 (* 1 = 6.46382 loss)
I0524 07:42:48.375208 11654 sgd_solver.cpp:112] Iteration 47670, lr = 0.1
I0524 07:42:54.958087 11654 solver.cpp:239] Iteration 47680 (1.41374 iter/s, 7.07344s/10 iters), loss = 5.33898
I0524 07:42:54.958148 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.33898 (* 1 = 5.33898 loss)
I0524 07:42:55.011036 11654 sgd_solver.cpp:112] Iteration 47680, lr = 0.1
I0524 07:43:02.152213 11654 solver.cpp:239] Iteration 47690 (1.39009 iter/s, 7.19379s/10 iters), loss = 5.34138
I0524 07:43:02.152278 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.34138 (* 1 = 5.34138 loss)
I0524 07:43:02.152369 11654 sgd_solver.cpp:112] Iteration 47690, lr = 0.1
I0524 07:43:09.045007 11654 solver.cpp:239] Iteration 47700 (1.45086 iter/s, 6.89246s/10 iters), loss = 5.76244
I0524 07:43:09.045068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76244 (* 1 = 5.76244 loss)
I0524 07:43:09.045084 11654 sgd_solver.cpp:112] Iteration 47700, lr = 0.1
I0524 07:43:16.521520 11654 solver.cpp:239] Iteration 47710 (1.33758 iter/s, 7.47617s/10 iters), loss = 6.43713
I0524 07:43:16.521601 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43713 (* 1 = 6.43713 loss)
I0524 07:43:16.521620 11654 sgd_solver.cpp:112] Iteration 47710, lr = 0.1
I0524 07:43:24.199056 11654 solver.cpp:239] Iteration 47720 (1.30257 iter/s, 7.67712s/10 iters), loss = 5.98899
I0524 07:43:24.199321 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98899 (* 1 = 5.98899 loss)
I0524 07:43:24.199368 11654 sgd_solver.cpp:112] Iteration 47720, lr = 0.1
I0524 07:43:33.357162 11654 solver.cpp:239] Iteration 47730 (1.09203 iter/s, 9.15728s/10 iters), loss = 5.71584
I0524 07:43:33.357257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71584 (* 1 = 5.71584 loss)
I0524 07:43:33.357300 11654 sgd_solver.cpp:112] Iteration 47730, lr = 0.1
I0524 07:43:41.349676 11654 solver.cpp:239] Iteration 47740 (1.25123 iter/s, 7.99214s/10 iters), loss = 6.42453
I0524 07:43:41.349730 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42453 (* 1 = 6.42453 loss)
I0524 07:43:41.381538 11654 sgd_solver.cpp:112] Iteration 47740, lr = 0.1
I0524 07:43:48.258755 11654 solver.cpp:239] Iteration 47750 (1.44744 iter/s, 6.90874s/10 iters), loss = 6.23701
I0524 07:43:48.258859 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23701 (* 1 = 6.23701 loss)
I0524 07:43:48.259290 11654 sgd_solver.cpp:112] Iteration 47750, lr = 0.1
I0524 07:43:54.638872 11654 solver.cpp:239] Iteration 47760 (1.56746 iter/s, 6.37974s/10 iters), loss = 6.65054
I0524 07:43:54.639132 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65054 (* 1 = 6.65054 loss)
I0524 07:43:54.639176 11654 sgd_solver.cpp:112] Iteration 47760, lr = 0.1
I0524 07:43:59.296821 11654 solver.cpp:239] Iteration 47770 (2.14718 iter/s, 4.65727s/10 iters), loss = 5.93491
I0524 07:43:59.296933 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93491 (* 1 = 5.93491 loss)
I0524 07:43:59.298806 11654 sgd_solver.cpp:112] Iteration 47770, lr = 0.1
I0524 07:44:06.467317 11654 solver.cpp:239] Iteration 47780 (1.39467 iter/s, 7.17013s/10 iters), loss = 6.60347
I0524 07:44:06.467391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60347 (* 1 = 6.60347 loss)
I0524 07:44:06.467547 11654 sgd_solver.cpp:112] Iteration 47780, lr = 0.1
I0524 07:44:14.514247 11654 solver.cpp:239] Iteration 47790 (1.24277 iter/s, 8.04655s/10 iters), loss = 5.54882
I0524 07:44:14.514334 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54882 (* 1 = 5.54882 loss)
I0524 07:44:14.514358 11654 sgd_solver.cpp:112] Iteration 47790, lr = 0.1
I0524 07:44:21.562623 11654 solver.cpp:239] Iteration 47800 (1.41884 iter/s, 7.04802s/10 iters), loss = 6.97813
I0524 07:44:21.562686 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97813 (* 1 = 6.97813 loss)
I0524 07:44:21.563087 11654 sgd_solver.cpp:112] Iteration 47800, lr = 0.1
I0524 07:44:29.220340 11654 solver.cpp:239] Iteration 47810 (1.30593 iter/s, 7.65735s/10 iters), loss = 6.34936
I0524 07:44:29.220592 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34936 (* 1 = 6.34936 loss)
I0524 07:44:29.220664 11654 sgd_solver.cpp:112] Iteration 47810, lr = 0.1
I0524 07:44:36.145355 11654 solver.cpp:239] Iteration 47820 (1.44415 iter/s, 6.9245s/10 iters), loss = 4.91983
I0524 07:44:36.145438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.91983 (* 1 = 4.91983 loss)
I0524 07:44:36.145464 11654 sgd_solver.cpp:112] Iteration 47820, lr = 0.1
I0524 07:44:44.355351 11654 solver.cpp:239] Iteration 47830 (1.21842 iter/s, 8.20738s/10 iters), loss = 6.43756
I0524 07:44:44.355413 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43756 (* 1 = 6.43756 loss)
I0524 07:44:44.535773 11654 sgd_solver.cpp:112] Iteration 47830, lr = 0.1
I0524 07:44:51.785473 11654 solver.cpp:239] Iteration 47840 (1.34594 iter/s, 7.42976s/10 iters), loss = 5.62575
I0524 07:44:51.785545 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62575 (* 1 = 5.62575 loss)
I0524 07:44:51.785718 11654 sgd_solver.cpp:112] Iteration 47840, lr = 0.1
I0524 07:44:58.245982 11654 solver.cpp:239] Iteration 47850 (1.54794 iter/s, 6.4602s/10 iters), loss = 5.53169
I0524 07:44:58.246042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53169 (* 1 = 5.53169 loss)
I0524 07:44:58.246202 11654 sgd_solver.cpp:112] Iteration 47850, lr = 0.1
I0524 07:45:05.300290 11654 solver.cpp:239] Iteration 47860 (1.41764 iter/s, 7.05397s/10 iters), loss = 6.52105
I0524 07:45:05.300583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52105 (* 1 = 6.52105 loss)
I0524 07:45:05.300633 11654 sgd_solver.cpp:112] Iteration 47860, lr = 0.1
I0524 07:45:12.211395 11654 solver.cpp:239] Iteration 47870 (1.4475 iter/s, 6.90848s/10 iters), loss = 5.82877
I0524 07:45:12.211495 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82877 (* 1 = 5.82877 loss)
I0524 07:45:12.211767 11654 sgd_solver.cpp:112] Iteration 47870, lr = 0.1
I0524 07:45:19.301040 11654 solver.cpp:239] Iteration 47880 (1.41058 iter/s, 7.08929s/10 iters), loss = 7.26176
I0524 07:45:19.301106 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26176 (* 1 = 7.26176 loss)
I0524 07:45:19.301125 11654 sgd_solver.cpp:112] Iteration 47880, lr = 0.1
I0524 07:45:26.894450 11654 solver.cpp:239] Iteration 47890 (1.31699 iter/s, 7.59305s/10 iters), loss = 5.82433
I0524 07:45:26.894529 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82433 (* 1 = 5.82433 loss)
I0524 07:45:26.894548 11654 sgd_solver.cpp:112] Iteration 47890, lr = 0.1
I0524 07:45:34.062115 11654 solver.cpp:239] Iteration 47900 (1.39565 iter/s, 7.16513s/10 iters), loss = 6.39757
I0524 07:45:34.062193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39757 (* 1 = 6.39757 loss)
I0524 07:45:34.062324 11654 sgd_solver.cpp:112] Iteration 47900, lr = 0.1
I0524 07:45:41.876121 11654 solver.cpp:239] Iteration 47910 (1.27982 iter/s, 7.8136s/10 iters), loss = 6.15224
I0524 07:45:41.876391 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15224 (* 1 = 6.15224 loss)
I0524 07:45:41.876446 11654 sgd_solver.cpp:112] Iteration 47910, lr = 0.1
I0524 07:45:51.617209 11654 solver.cpp:239] Iteration 47920 (1.02685 iter/s, 9.73847s/10 iters), loss = 6.69436
I0524 07:45:51.617280 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69436 (* 1 = 6.69436 loss)
I0524 07:45:51.617401 11654 sgd_solver.cpp:112] Iteration 47920, lr = 0.1
I0524 07:46:02.717564 11654 solver.cpp:239] Iteration 47930 (0.900912 iter/s, 11.0999s/10 iters), loss = 6.5181
I0524 07:46:02.717640 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5181 (* 1 = 6.5181 loss)
I0524 07:46:02.797322 11654 sgd_solver.cpp:112] Iteration 47930, lr = 0.1
I0524 07:46:09.483304 11654 solver.cpp:239] Iteration 47940 (1.47811 iter/s, 6.76541s/10 iters), loss = 5.94017
I0524 07:46:09.483377 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94017 (* 1 = 5.94017 loss)
I0524 07:46:09.871052 11654 sgd_solver.cpp:112] Iteration 47940, lr = 0.1
I0524 07:46:17.448688 11654 solver.cpp:239] Iteration 47950 (1.25549 iter/s, 7.96502s/10 iters), loss = 5.82639
I0524 07:46:17.448917 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82639 (* 1 = 5.82639 loss)
I0524 07:46:17.448947 11654 sgd_solver.cpp:112] Iteration 47950, lr = 0.1
I0524 07:46:25.043922 11654 solver.cpp:239] Iteration 47960 (1.3167 iter/s, 7.59472s/10 iters), loss = 6.28324
I0524 07:46:25.043978 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28324 (* 1 = 6.28324 loss)
I0524 07:46:25.044042 11654 sgd_solver.cpp:112] Iteration 47960, lr = 0.1
I0524 07:46:33.036469 11654 solver.cpp:239] Iteration 47970 (1.25122 iter/s, 7.99218s/10 iters), loss = 6.07159
I0524 07:46:33.036552 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07159 (* 1 = 6.07159 loss)
I0524 07:46:33.036578 11654 sgd_solver.cpp:112] Iteration 47970, lr = 0.1
I0524 07:46:41.021500 11654 solver.cpp:239] Iteration 47980 (1.25241 iter/s, 7.98462s/10 iters), loss = 5.00303
I0524 07:46:41.021539 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.00303 (* 1 = 5.00303 loss)
I0524 07:46:41.021554 11654 sgd_solver.cpp:112] Iteration 47980, lr = 0.1
I0524 07:46:48.010476 11654 solver.cpp:239] Iteration 47990 (1.4309 iter/s, 6.98859s/10 iters), loss = 7.20366
I0524 07:46:48.010807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20366 (* 1 = 7.20366 loss)
I0524 07:46:48.284935 11654 sgd_solver.cpp:112] Iteration 47990, lr = 0.1
I0524 07:46:56.194859 11654 solver.cpp:239] Iteration 48000 (1.22192 iter/s, 8.18383s/10 iters), loss = 6.05202
I0524 07:46:56.194922 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05202 (* 1 = 6.05202 loss)
I0524 07:46:56.195359 11654 sgd_solver.cpp:112] Iteration 48000, lr = 0.1
I0524 07:47:02.524981 11654 solver.cpp:239] Iteration 48010 (1.57983 iter/s, 6.3298s/10 iters), loss = 6.85787
I0524 07:47:02.525051 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85787 (* 1 = 6.85787 loss)
I0524 07:47:02.568452 11654 sgd_solver.cpp:112] Iteration 48010, lr = 0.1
I0524 07:47:09.240847 11654 solver.cpp:239] Iteration 48020 (1.48908 iter/s, 6.71554s/10 iters), loss = 6.12581
I0524 07:47:09.240931 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12581 (* 1 = 6.12581 loss)
I0524 07:47:09.241004 11654 sgd_solver.cpp:112] Iteration 48020, lr = 0.1
I0524 07:47:15.892088 11654 solver.cpp:239] Iteration 48030 (1.50355 iter/s, 6.65091s/10 iters), loss = 7.28101
I0524 07:47:15.892192 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28101 (* 1 = 7.28101 loss)
I0524 07:47:15.892221 11654 sgd_solver.cpp:112] Iteration 48030, lr = 0.1
I0524 07:47:23.251313 11654 solver.cpp:239] Iteration 48040 (1.35891 iter/s, 7.35884s/10 iters), loss = 5.62434
I0524 07:47:23.251505 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62434 (* 1 = 5.62434 loss)
I0524 07:47:23.251531 11654 sgd_solver.cpp:112] Iteration 48040, lr = 0.1
I0524 07:47:29.982506 11654 solver.cpp:239] Iteration 48050 (1.4858 iter/s, 6.7304s/10 iters), loss = 7.42771
I0524 07:47:29.982568 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.42771 (* 1 = 7.42771 loss)
I0524 07:47:29.982656 11654 sgd_solver.cpp:112] Iteration 48050, lr = 0.1
I0524 07:47:37.595945 11654 solver.cpp:239] Iteration 48060 (1.31353 iter/s, 7.61307s/10 iters), loss = 5.42949
I0524 07:47:37.596025 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42949 (* 1 = 5.42949 loss)
I0524 07:47:38.989410 11654 sgd_solver.cpp:112] Iteration 48060, lr = 0.1
I0524 07:47:47.117797 11654 solver.cpp:239] Iteration 48070 (1.05027 iter/s, 9.5214s/10 iters), loss = 6.36639
I0524 07:47:47.117873 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36639 (* 1 = 6.36639 loss)
I0524 07:47:47.119849 11654 sgd_solver.cpp:112] Iteration 48070, lr = 0.1
I0524 07:47:53.309533 11654 solver.cpp:239] Iteration 48080 (1.61513 iter/s, 6.19144s/10 iters), loss = 5.84332
I0524 07:47:53.309689 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84332 (* 1 = 5.84332 loss)
I0524 07:47:53.309792 11654 sgd_solver.cpp:112] Iteration 48080, lr = 0.1
I0524 07:48:00.073235 11654 solver.cpp:239] Iteration 48090 (1.47858 iter/s, 6.76326s/10 iters), loss = 5.89835
I0524 07:48:00.073313 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89835 (* 1 = 5.89835 loss)
I0524 07:48:00.073721 11654 sgd_solver.cpp:112] Iteration 48090, lr = 0.1
I0524 07:48:06.774811 11654 solver.cpp:239] Iteration 48100 (1.49226 iter/s, 6.70123s/10 iters), loss = 6.39599
I0524 07:48:06.774873 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39599 (* 1 = 6.39599 loss)
I0524 07:48:06.775324 11654 sgd_solver.cpp:112] Iteration 48100, lr = 0.1
I0524 07:48:14.827533 11654 solver.cpp:239] Iteration 48110 (1.24187 iter/s, 8.05235s/10 iters), loss = 6.32583
I0524 07:48:14.827589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32583 (* 1 = 6.32583 loss)
I0524 07:48:14.874508 11654 sgd_solver.cpp:112] Iteration 48110, lr = 0.1
I0524 07:48:22.560717 11654 solver.cpp:239] Iteration 48120 (1.29319 iter/s, 7.73282s/10 iters), loss = 6.43063
I0524 07:48:22.560786 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43063 (* 1 = 6.43063 loss)
I0524 07:48:22.560883 11654 sgd_solver.cpp:112] Iteration 48120, lr = 0.1
I0524 07:48:29.823249 11654 solver.cpp:239] Iteration 48130 (1.377 iter/s, 7.26217s/10 iters), loss = 6.23878
I0524 07:48:29.823498 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23878 (* 1 = 6.23878 loss)
I0524 07:48:29.823685 11654 sgd_solver.cpp:112] Iteration 48130, lr = 0.1
I0524 07:48:36.833456 11654 solver.cpp:239] Iteration 48140 (1.4266 iter/s, 7.00968s/10 iters), loss = 5.99137
I0524 07:48:36.833567 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99137 (* 1 = 5.99137 loss)
I0524 07:48:36.833598 11654 sgd_solver.cpp:112] Iteration 48140, lr = 0.1
I0524 07:48:44.561309 11654 solver.cpp:239] Iteration 48150 (1.29409 iter/s, 7.72743s/10 iters), loss = 6.36167
I0524 07:48:44.561363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36167 (* 1 = 6.36167 loss)
I0524 07:48:44.561383 11654 sgd_solver.cpp:112] Iteration 48150, lr = 0.1
I0524 07:48:53.989984 11654 solver.cpp:239] Iteration 48160 (1.06065 iter/s, 9.42819s/10 iters), loss = 5.46748
I0524 07:48:53.990062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46748 (* 1 = 5.46748 loss)
I0524 07:48:53.990169 11654 sgd_solver.cpp:112] Iteration 48160, lr = 0.1
I0524 07:49:01.364261 11654 solver.cpp:239] Iteration 48170 (1.35614 iter/s, 7.37387s/10 iters), loss = 5.73045
I0524 07:49:01.364512 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73045 (* 1 = 5.73045 loss)
I0524 07:49:01.364580 11654 sgd_solver.cpp:112] Iteration 48170, lr = 0.1
I0524 07:49:08.722421 11654 solver.cpp:239] Iteration 48180 (1.35913 iter/s, 7.35765s/10 iters), loss = 4.90829
I0524 07:49:08.722527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.90829 (* 1 = 4.90829 loss)
I0524 07:49:09.095340 11654 sgd_solver.cpp:112] Iteration 48180, lr = 0.1
I0524 07:49:16.829670 11654 solver.cpp:239] Iteration 48190 (1.23352 iter/s, 8.10685s/10 iters), loss = 6.80863
I0524 07:49:16.829718 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80863 (* 1 = 6.80863 loss)
I0524 07:49:16.829736 11654 sgd_solver.cpp:112] Iteration 48190, lr = 0.1
I0524 07:49:22.869262 11654 solver.cpp:239] Iteration 48200 (1.65584 iter/s, 6.03925s/10 iters), loss = 6.46503
I0524 07:49:22.869313 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46503 (* 1 = 6.46503 loss)
I0524 07:49:22.869468 11654 sgd_solver.cpp:112] Iteration 48200, lr = 0.1
I0524 07:49:30.308152 11654 solver.cpp:239] Iteration 48210 (1.34435 iter/s, 7.43853s/10 iters), loss = 5.57745
I0524 07:49:30.308226 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57745 (* 1 = 5.57745 loss)
I0524 07:49:30.308253 11654 sgd_solver.cpp:112] Iteration 48210, lr = 0.1
I0524 07:49:38.314472 11654 solver.cpp:239] Iteration 48220 (1.24907 iter/s, 8.00594s/10 iters), loss = 6.92593
I0524 07:49:38.314724 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92593 (* 1 = 6.92593 loss)
I0524 07:49:39.612282 11654 sgd_solver.cpp:112] Iteration 48220, lr = 0.1
I0524 07:49:46.592386 11654 solver.cpp:239] Iteration 48230 (1.20811 iter/s, 8.2774s/10 iters), loss = 7.06966
I0524 07:49:46.592427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06966 (* 1 = 7.06966 loss)
I0524 07:49:47.597949 11654 sgd_solver.cpp:112] Iteration 48230, lr = 0.1
I0524 07:49:54.664999 11654 solver.cpp:239] Iteration 48240 (1.23881 iter/s, 8.07223s/10 iters), loss = 6.67883
I0524 07:49:54.665069 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67883 (* 1 = 6.67883 loss)
I0524 07:49:55.548265 11654 sgd_solver.cpp:112] Iteration 48240, lr = 0.1
I0524 07:50:02.318099 11654 solver.cpp:239] Iteration 48250 (1.30673 iter/s, 7.65267s/10 iters), loss = 5.57001
I0524 07:50:02.318262 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57001 (* 1 = 5.57001 loss)
I0524 07:50:02.318342 11654 sgd_solver.cpp:112] Iteration 48250, lr = 0.1
I0524 07:50:08.863684 11654 solver.cpp:239] Iteration 48260 (1.52782 iter/s, 6.54526s/10 iters), loss = 5.92735
I0524 07:50:08.863971 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92735 (* 1 = 5.92735 loss)
I0524 07:50:08.864017 11654 sgd_solver.cpp:112] Iteration 48260, lr = 0.1
I0524 07:50:16.355595 11654 solver.cpp:239] Iteration 48270 (1.33501 iter/s, 7.49056s/10 iters), loss = 5.61831
I0524 07:50:16.355681 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61831 (* 1 = 5.61831 loss)
I0524 07:50:16.355904 11654 sgd_solver.cpp:112] Iteration 48270, lr = 0.1
I0524 07:50:23.133121 11654 solver.cpp:239] Iteration 48280 (1.47554 iter/s, 6.77718s/10 iters), loss = 6.92908
I0524 07:50:23.133199 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92908 (* 1 = 6.92908 loss)
I0524 07:50:23.137449 11654 sgd_solver.cpp:112] Iteration 48280, lr = 0.1
I0524 07:50:30.243749 11654 solver.cpp:239] Iteration 48290 (1.40641 iter/s, 7.1103s/10 iters), loss = 5.54144
I0524 07:50:30.243865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54144 (* 1 = 5.54144 loss)
I0524 07:50:30.570730 11654 sgd_solver.cpp:112] Iteration 48290, lr = 0.1
I0524 07:50:37.642069 11654 solver.cpp:239] Iteration 48300 (1.35172 iter/s, 7.39796s/10 iters), loss = 5.96712
I0524 07:50:37.642132 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96712 (* 1 = 5.96712 loss)
I0524 07:50:37.642673 11654 sgd_solver.cpp:112] Iteration 48300, lr = 0.1
I0524 07:50:46.082499 11654 solver.cpp:239] Iteration 48310 (1.18483 iter/s, 8.44005s/10 iters), loss = 6.93473
I0524 07:50:46.082764 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.93473 (* 1 = 6.93473 loss)
I0524 07:50:46.082805 11654 sgd_solver.cpp:112] Iteration 48310, lr = 0.1
I0524 07:50:52.649369 11654 solver.cpp:239] Iteration 48320 (1.52339 iter/s, 6.5643s/10 iters), loss = 5.41091
I0524 07:50:52.649421 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.41091 (* 1 = 5.41091 loss)
I0524 07:50:52.649780 11654 sgd_solver.cpp:112] Iteration 48320, lr = 0.1
I0524 07:51:00.650646 11654 solver.cpp:239] Iteration 48330 (1.24986 iter/s, 8.00091s/10 iters), loss = 5.76338
I0524 07:51:00.650722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76338 (* 1 = 5.76338 loss)
I0524 07:51:00.749797 11654 sgd_solver.cpp:112] Iteration 48330, lr = 0.1
I0524 07:51:07.214399 11654 solver.cpp:239] Iteration 48340 (1.52359 iter/s, 6.56344s/10 iters), loss = 5.61084
I0524 07:51:07.214489 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61084 (* 1 = 5.61084 loss)
I0524 07:51:07.214663 11654 sgd_solver.cpp:112] Iteration 48340, lr = 0.1
I0524 07:51:14.227448 11654 solver.cpp:239] Iteration 48350 (1.42598 iter/s, 7.01272s/10 iters), loss = 6.0905
I0524 07:51:14.227510 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0905 (* 1 = 6.0905 loss)
I0524 07:51:14.230998 11654 sgd_solver.cpp:112] Iteration 48350, lr = 0.1
I0524 07:51:20.595710 11654 solver.cpp:239] Iteration 48360 (1.57037 iter/s, 6.36795s/10 iters), loss = 5.72127
I0524 07:51:20.595880 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72127 (* 1 = 5.72127 loss)
I0524 07:51:20.595897 11654 sgd_solver.cpp:112] Iteration 48360, lr = 0.1
I0524 07:51:28.601033 11654 solver.cpp:239] Iteration 48370 (1.24925 iter/s, 8.00482s/10 iters), loss = 5.88557
I0524 07:51:28.601115 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88557 (* 1 = 5.88557 loss)
I0524 07:51:28.601143 11654 sgd_solver.cpp:112] Iteration 48370, lr = 0.1
I0524 07:51:35.169174 11654 solver.cpp:239] Iteration 48380 (1.52307 iter/s, 6.5657s/10 iters), loss = 6.36006
I0524 07:51:35.169248 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36006 (* 1 = 6.36006 loss)
I0524 07:51:35.169266 11654 sgd_solver.cpp:112] Iteration 48380, lr = 0.1
I0524 07:51:43.924566 11654 solver.cpp:239] Iteration 48390 (1.14222 iter/s, 8.75488s/10 iters), loss = 5.46257
I0524 07:51:43.924610 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46257 (* 1 = 5.46257 loss)
I0524 07:51:43.924624 11654 sgd_solver.cpp:112] Iteration 48390, lr = 0.1
I0524 07:51:50.571481 11654 solver.cpp:239] Iteration 48400 (1.50454 iter/s, 6.64653s/10 iters), loss = 5.35304
I0524 07:51:50.571542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.35304 (* 1 = 5.35304 loss)
I0524 07:51:50.571561 11654 sgd_solver.cpp:112] Iteration 48400, lr = 0.1
I0524 07:51:57.185674 11654 solver.cpp:239] Iteration 48410 (1.51248 iter/s, 6.61166s/10 iters), loss = 6.54834
I0524 07:51:57.185977 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54834 (* 1 = 6.54834 loss)
I0524 07:51:57.186034 11654 sgd_solver.cpp:112] Iteration 48410, lr = 0.1
I0524 07:52:05.693459 11654 solver.cpp:239] Iteration 48420 (1.17549 iter/s, 8.50707s/10 iters), loss = 5.73969
I0524 07:52:05.693516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73969 (* 1 = 5.73969 loss)
I0524 07:52:05.980479 11654 sgd_solver.cpp:112] Iteration 48420, lr = 0.1
I0524 07:52:14.367765 11654 solver.cpp:239] Iteration 48430 (1.15288 iter/s, 8.6739s/10 iters), loss = 5.21148
I0524 07:52:14.367820 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.21148 (* 1 = 5.21148 loss)
I0524 07:52:14.388582 11654 sgd_solver.cpp:112] Iteration 48430, lr = 0.1
I0524 07:52:20.907402 11654 solver.cpp:239] Iteration 48440 (1.52921 iter/s, 6.53933s/10 iters), loss = 6.20376
I0524 07:52:20.907461 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20376 (* 1 = 6.20376 loss)
I0524 07:52:20.907934 11654 sgd_solver.cpp:112] Iteration 48440, lr = 0.1
I0524 07:52:29.814811 11654 solver.cpp:239] Iteration 48450 (1.12271 iter/s, 8.90701s/10 iters), loss = 6.6137
I0524 07:52:29.815062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6137 (* 1 = 6.6137 loss)
I0524 07:52:29.815100 11654 sgd_solver.cpp:112] Iteration 48450, lr = 0.1
I0524 07:52:36.688910 11654 solver.cpp:239] Iteration 48460 (1.4553 iter/s, 6.87144s/10 iters), loss = 5.99699
I0524 07:52:36.689028 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99699 (* 1 = 5.99699 loss)
I0524 07:52:36.689070 11654 sgd_solver.cpp:112] Iteration 48460, lr = 0.1
I0524 07:52:42.923391 11654 solver.cpp:239] Iteration 48470 (1.60407 iter/s, 6.23414s/10 iters), loss = 6.63374
I0524 07:52:42.923460 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63374 (* 1 = 6.63374 loss)
I0524 07:52:42.923728 11654 sgd_solver.cpp:112] Iteration 48470, lr = 0.1
I0524 07:52:51.418787 11654 solver.cpp:239] Iteration 48480 (1.17717 iter/s, 8.49496s/10 iters), loss = 5.5525
I0524 07:52:51.418889 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5525 (* 1 = 5.5525 loss)
I0524 07:52:51.452347 11654 sgd_solver.cpp:112] Iteration 48480, lr = 0.1
I0524 07:52:58.211273 11654 solver.cpp:239] Iteration 48490 (1.4723 iter/s, 6.79209s/10 iters), loss = 6.00921
I0524 07:52:58.211354 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00921 (* 1 = 6.00921 loss)
I0524 07:52:58.250279 11654 sgd_solver.cpp:112] Iteration 48490, lr = 0.1
I0524 07:53:07.638141 11654 solver.cpp:239] Iteration 48500 (1.06085 iter/s, 9.42642s/10 iters), loss = 7.57201
I0524 07:53:07.638375 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.57201 (* 1 = 7.57201 loss)
I0524 07:53:07.643453 11654 sgd_solver.cpp:112] Iteration 48500, lr = 0.1
I0524 07:53:15.552824 11654 solver.cpp:239] Iteration 48510 (1.26356 iter/s, 7.91415s/10 iters), loss = 6.26542
I0524 07:53:15.552911 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26542 (* 1 = 6.26542 loss)
I0524 07:53:15.553081 11654 sgd_solver.cpp:112] Iteration 48510, lr = 0.1
I0524 07:53:23.664983 11654 solver.cpp:239] Iteration 48520 (1.23277 iter/s, 8.11178s/10 iters), loss = 5.83431
I0524 07:53:23.665040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83431 (* 1 = 5.83431 loss)
I0524 07:53:23.665117 11654 sgd_solver.cpp:112] Iteration 48520, lr = 0.1
I0524 07:53:30.400833 11654 solver.cpp:239] Iteration 48530 (1.48467 iter/s, 6.73549s/10 iters), loss = 5.61983
I0524 07:53:30.400919 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61983 (* 1 = 5.61983 loss)
I0524 07:53:30.401010 11654 sgd_solver.cpp:112] Iteration 48530, lr = 0.1
I0524 07:53:37.497150 11654 solver.cpp:239] Iteration 48540 (1.40925 iter/s, 7.09595s/10 iters), loss = 5.77234
I0524 07:53:37.497200 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77234 (* 1 = 5.77234 loss)
I0524 07:53:38.021981 11654 sgd_solver.cpp:112] Iteration 48540, lr = 0.1
I0524 07:53:44.496197 11654 solver.cpp:239] Iteration 48550 (1.42884 iter/s, 6.99868s/10 iters), loss = 6.42614
I0524 07:53:44.496263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42614 (* 1 = 6.42614 loss)
I0524 07:53:45.617133 11654 sgd_solver.cpp:112] Iteration 48550, lr = 0.1
I0524 07:53:53.863732 11654 solver.cpp:239] Iteration 48560 (1.06757 iter/s, 9.3671s/10 iters), loss = 6.87842
I0524 07:53:53.863782 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87842 (* 1 = 6.87842 loss)
I0524 07:53:53.864028 11654 sgd_solver.cpp:112] Iteration 48560, lr = 0.1
I0524 07:54:01.532096 11654 solver.cpp:239] Iteration 48570 (1.30412 iter/s, 7.66801s/10 iters), loss = 5.61167
I0524 07:54:01.532177 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61167 (* 1 = 5.61167 loss)
I0524 07:54:01.532202 11654 sgd_solver.cpp:112] Iteration 48570, lr = 0.1
I0524 07:54:11.740816 11654 solver.cpp:239] Iteration 48580 (0.979598 iter/s, 10.2083s/10 iters), loss = 5.07659
I0524 07:54:11.741086 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.07659 (* 1 = 5.07659 loss)
I0524 07:54:11.741132 11654 sgd_solver.cpp:112] Iteration 48580, lr = 0.1
I0524 07:54:20.002600 11654 solver.cpp:239] Iteration 48590 (1.21049 iter/s, 8.2611s/10 iters), loss = 5.85547
I0524 07:54:20.002651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85547 (* 1 = 5.85547 loss)
I0524 07:54:20.002666 11654 sgd_solver.cpp:112] Iteration 48590, lr = 0.1
I0524 07:54:28.956364 11654 solver.cpp:239] Iteration 48600 (1.11691 iter/s, 8.95326s/10 iters), loss = 7.05682
I0524 07:54:28.956434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05682 (* 1 = 7.05682 loss)
I0524 07:54:28.956574 11654 sgd_solver.cpp:112] Iteration 48600, lr = 0.1
I0524 07:54:35.727218 11654 solver.cpp:239] Iteration 48610 (1.47699 iter/s, 6.77051s/10 iters), loss = 5.86138
I0524 07:54:35.727283 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86138 (* 1 = 5.86138 loss)
I0524 07:54:36.268721 11654 sgd_solver.cpp:112] Iteration 48610, lr = 0.1
I0524 07:54:43.799162 11654 solver.cpp:239] Iteration 48620 (1.23892 iter/s, 8.07155s/10 iters), loss = 6.1971
I0524 07:54:43.799437 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1971 (* 1 = 6.1971 loss)
I0524 07:54:44.370245 11654 sgd_solver.cpp:112] Iteration 48620, lr = 0.1
I0524 07:54:51.082587 11654 solver.cpp:239] Iteration 48630 (1.37308 iter/s, 7.28288s/10 iters), loss = 6.07718
I0524 07:54:51.082651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07718 (* 1 = 6.07718 loss)
I0524 07:54:51.083017 11654 sgd_solver.cpp:112] Iteration 48630, lr = 0.1
I0524 07:54:58.977363 11654 solver.cpp:239] Iteration 48640 (1.26672 iter/s, 7.89439s/10 iters), loss = 6.65398
I0524 07:54:58.977461 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65398 (* 1 = 6.65398 loss)
I0524 07:54:58.977687 11654 sgd_solver.cpp:112] Iteration 48640, lr = 0.1
I0524 07:55:06.226238 11654 solver.cpp:239] Iteration 48650 (1.37959 iter/s, 7.24851s/10 iters), loss = 6.74058
I0524 07:55:06.226290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74058 (* 1 = 6.74058 loss)
I0524 07:55:06.409256 11654 sgd_solver.cpp:112] Iteration 48650, lr = 0.1
I0524 07:55:16.408566 11654 solver.cpp:239] Iteration 48660 (0.982137 iter/s, 10.1819s/10 iters), loss = 5.83094
I0524 07:55:16.408844 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83094 (* 1 = 5.83094 loss)
I0524 07:55:16.603389 11654 sgd_solver.cpp:112] Iteration 48660, lr = 0.1
I0524 07:55:23.792896 11654 solver.cpp:239] Iteration 48670 (1.35432 iter/s, 7.3838s/10 iters), loss = 4.9374
I0524 07:55:23.793040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.9374 (* 1 = 4.9374 loss)
I0524 07:55:23.793076 11654 sgd_solver.cpp:112] Iteration 48670, lr = 0.1
I0524 07:55:31.995859 11654 solver.cpp:239] Iteration 48680 (1.21938 iter/s, 8.2009s/10 iters), loss = 6.81445
I0524 07:55:31.995966 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81445 (* 1 = 6.81445 loss)
I0524 07:55:32.402674 11654 sgd_solver.cpp:112] Iteration 48680, lr = 0.1
I0524 07:55:39.707275 11654 solver.cpp:239] Iteration 48690 (1.29684 iter/s, 7.71104s/10 iters), loss = 5.90851
I0524 07:55:39.707350 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90851 (* 1 = 5.90851 loss)
I0524 07:55:39.707502 11654 sgd_solver.cpp:112] Iteration 48690, lr = 0.1
I0524 07:55:46.480595 11654 solver.cpp:239] Iteration 48700 (1.47645 iter/s, 6.77299s/10 iters), loss = 5.41549
I0524 07:55:46.480834 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.41549 (* 1 = 5.41549 loss)
I0524 07:55:46.480867 11654 sgd_solver.cpp:112] Iteration 48700, lr = 0.1
I0524 07:55:54.134254 11654 solver.cpp:239] Iteration 48710 (1.30667 iter/s, 7.65306s/10 iters), loss = 5.66591
I0524 07:55:54.134366 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66591 (* 1 = 5.66591 loss)
I0524 07:55:54.134407 11654 sgd_solver.cpp:112] Iteration 48710, lr = 0.1
I0524 07:56:02.145063 11654 solver.cpp:239] Iteration 48720 (1.24838 iter/s, 8.0104s/10 iters), loss = 5.87298
I0524 07:56:02.145103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87298 (* 1 = 5.87298 loss)
I0524 07:56:02.981384 11654 sgd_solver.cpp:112] Iteration 48720, lr = 0.1
I0524 07:56:10.637475 11654 solver.cpp:239] Iteration 48730 (1.17758 iter/s, 8.49202s/10 iters), loss = 7.08462
I0524 07:56:10.637555 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08462 (* 1 = 7.08462 loss)
I0524 07:56:10.638206 11654 sgd_solver.cpp:112] Iteration 48730, lr = 0.1
I0524 07:56:19.470491 11654 solver.cpp:239] Iteration 48740 (1.13217 iter/s, 8.8326s/10 iters), loss = 6.152
I0524 07:56:19.470722 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.152 (* 1 = 6.152 loss)
I0524 07:56:19.470989 11654 sgd_solver.cpp:112] Iteration 48740, lr = 0.1
I0524 07:56:25.817171 11654 solver.cpp:239] Iteration 48750 (1.57574 iter/s, 6.34623s/10 iters), loss = 5.86489
I0524 07:56:25.817221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86489 (* 1 = 5.86489 loss)
I0524 07:56:26.304877 11654 sgd_solver.cpp:112] Iteration 48750, lr = 0.1
I0524 07:56:34.139262 11654 solver.cpp:239] Iteration 48760 (1.20168 iter/s, 8.3217s/10 iters), loss = 6.15312
I0524 07:56:34.139328 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15312 (* 1 = 6.15312 loss)
I0524 07:56:34.139346 11654 sgd_solver.cpp:112] Iteration 48760, lr = 0.1
I0524 07:56:43.002398 11654 solver.cpp:239] Iteration 48770 (1.12832 iter/s, 8.86272s/10 iters), loss = 5.92612
I0524 07:56:43.002517 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92612 (* 1 = 5.92612 loss)
I0524 07:56:43.004266 11654 sgd_solver.cpp:112] Iteration 48770, lr = 0.1
I0524 07:56:50.028400 11654 solver.cpp:239] Iteration 48780 (1.42336 iter/s, 7.02563s/10 iters), loss = 5.89214
I0524 07:56:50.028620 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89214 (* 1 = 5.89214 loss)
I0524 07:56:50.028664 11654 sgd_solver.cpp:112] Iteration 48780, lr = 0.1
I0524 07:56:58.957384 11654 solver.cpp:239] Iteration 48790 (1.12011 iter/s, 8.92772s/10 iters), loss = 6.459
I0524 07:56:58.957442 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.459 (* 1 = 6.459 loss)
I0524 07:56:58.963966 11654 sgd_solver.cpp:112] Iteration 48790, lr = 0.1
I0524 07:57:05.884265 11654 solver.cpp:239] Iteration 48800 (1.44372 iter/s, 6.92656s/10 iters), loss = 5.86127
I0524 07:57:05.884305 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86127 (* 1 = 5.86127 loss)
I0524 07:57:06.860095 11654 sgd_solver.cpp:112] Iteration 48800, lr = 0.1
I0524 07:57:17.287190 11654 solver.cpp:239] Iteration 48810 (0.877006 iter/s, 11.4024s/10 iters), loss = 5.94957
I0524 07:57:17.287271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94957 (* 1 = 5.94957 loss)
I0524 07:57:17.406888 11654 sgd_solver.cpp:112] Iteration 48810, lr = 0.1
I0524 07:57:25.578110 11654 solver.cpp:239] Iteration 48820 (1.2062 iter/s, 8.29047s/10 iters), loss = 6.05593
I0524 07:57:25.578413 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05593 (* 1 = 6.05593 loss)
I0524 07:57:26.004657 11654 sgd_solver.cpp:112] Iteration 48820, lr = 0.1
I0524 07:57:33.942495 11654 solver.cpp:239] Iteration 48830 (1.19563 iter/s, 8.36379s/10 iters), loss = 5.48871
I0524 07:57:33.942534 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48871 (* 1 = 5.48871 loss)
I0524 07:57:33.942638 11654 sgd_solver.cpp:112] Iteration 48830, lr = 0.1
I0524 07:57:40.561353 11654 solver.cpp:239] Iteration 48840 (1.51091 iter/s, 6.61853s/10 iters), loss = 5.93097
I0524 07:57:40.561435 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93097 (* 1 = 5.93097 loss)
I0524 07:57:40.570015 11654 sgd_solver.cpp:112] Iteration 48840, lr = 0.1
I0524 07:57:46.921908 11654 solver.cpp:239] Iteration 48850 (1.57227 iter/s, 6.36022s/10 iters), loss = 6.11995
I0524 07:57:46.921988 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11995 (* 1 = 6.11995 loss)
I0524 07:57:46.922008 11654 sgd_solver.cpp:112] Iteration 48850, lr = 0.1
I0524 07:57:53.497606 11654 solver.cpp:239] Iteration 48860 (1.52097 iter/s, 6.57475s/10 iters), loss = 5.84474
I0524 07:57:53.497649 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84474 (* 1 = 5.84474 loss)
I0524 07:57:53.662477 11654 sgd_solver.cpp:112] Iteration 48860, lr = 0.1
I0524 07:58:00.624191 11654 solver.cpp:239] Iteration 48870 (1.40326 iter/s, 7.12625s/10 iters), loss = 5.66307
I0524 07:58:00.624333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66307 (* 1 = 5.66307 loss)
I0524 07:58:00.732026 11654 sgd_solver.cpp:112] Iteration 48870, lr = 0.1
I0524 07:58:06.946382 11654 solver.cpp:239] Iteration 48880 (1.58183 iter/s, 6.32181s/10 iters), loss = 6.44906
I0524 07:58:06.946444 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44906 (* 1 = 6.44906 loss)
I0524 07:58:06.946501 11654 sgd_solver.cpp:112] Iteration 48880, lr = 0.1
I0524 07:58:16.135617 11654 solver.cpp:239] Iteration 48890 (1.08828 iter/s, 9.18883s/10 iters), loss = 5.76919
I0524 07:58:16.135658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76919 (* 1 = 5.76919 loss)
I0524 07:58:17.453909 11654 sgd_solver.cpp:112] Iteration 48890, lr = 0.1
I0524 07:58:23.566519 11654 solver.cpp:239] Iteration 48900 (1.34579 iter/s, 7.43057s/10 iters), loss = 5.84159
I0524 07:58:23.566586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84159 (* 1 = 5.84159 loss)
I0524 07:58:23.566800 11654 sgd_solver.cpp:112] Iteration 48900, lr = 0.1
I0524 07:58:31.892335 11654 solver.cpp:239] Iteration 48910 (1.20114 iter/s, 8.32544s/10 iters), loss = 6.28239
I0524 07:58:31.892498 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28239 (* 1 = 6.28239 loss)
I0524 07:58:31.892518 11654 sgd_solver.cpp:112] Iteration 48910, lr = 0.1
I0524 07:58:38.320618 11654 solver.cpp:239] Iteration 48920 (1.55625 iter/s, 6.42569s/10 iters), loss = 6.2375
I0524 07:58:38.320688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2375 (* 1 = 6.2375 loss)
I0524 07:58:38.320760 11654 sgd_solver.cpp:112] Iteration 48920, lr = 0.1
I0524 07:58:47.618335 11654 solver.cpp:239] Iteration 48930 (1.07558 iter/s, 9.2973s/10 iters), loss = 5.88157
I0524 07:58:47.618389 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88157 (* 1 = 5.88157 loss)
I0524 07:58:48.550267 11654 sgd_solver.cpp:112] Iteration 48930, lr = 0.1
I0524 07:58:55.704783 11654 solver.cpp:239] Iteration 48940 (1.23669 iter/s, 8.08608s/10 iters), loss = 6.14156
I0524 07:58:55.704839 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14156 (* 1 = 6.14156 loss)
I0524 07:58:55.914126 11654 sgd_solver.cpp:112] Iteration 48940, lr = 0.1
I0524 07:59:04.543413 11654 solver.cpp:239] Iteration 48950 (1.13145 iter/s, 8.83824s/10 iters), loss = 6.60079
I0524 07:59:04.543709 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60079 (* 1 = 6.60079 loss)
I0524 07:59:05.338937 11654 sgd_solver.cpp:112] Iteration 48950, lr = 0.1
I0524 07:59:12.791373 11654 solver.cpp:239] Iteration 48960 (1.21251 iter/s, 8.24736s/10 iters), loss = 6.10597
I0524 07:59:12.791437 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10597 (* 1 = 6.10597 loss)
I0524 07:59:12.791836 11654 sgd_solver.cpp:112] Iteration 48960, lr = 0.1
I0524 07:59:21.704277 11654 solver.cpp:239] Iteration 48970 (1.12202 iter/s, 8.9125s/10 iters), loss = 6.17756
I0524 07:59:21.704336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17756 (* 1 = 6.17756 loss)
I0524 07:59:21.704354 11654 sgd_solver.cpp:112] Iteration 48970, lr = 0.1
I0524 07:59:29.962921 11654 solver.cpp:239] Iteration 48980 (1.21091 iter/s, 8.25827s/10 iters), loss = 5.22568
I0524 07:59:29.962980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.22568 (* 1 = 5.22568 loss)
I0524 07:59:29.962996 11654 sgd_solver.cpp:112] Iteration 48980, lr = 0.1
I0524 07:59:37.785131 11654 solver.cpp:239] Iteration 48990 (1.27848 iter/s, 7.82178s/10 iters), loss = 6.32832
I0524 07:59:37.785336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32832 (* 1 = 6.32832 loss)
I0524 07:59:37.785365 11654 sgd_solver.cpp:112] Iteration 48990, lr = 0.1
I0524 07:59:46.675760 11654 solver.cpp:239] Iteration 49000 (1.12496 iter/s, 8.88918s/10 iters), loss = 6.34514
I0524 07:59:46.675822 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34514 (* 1 = 6.34514 loss)
I0524 07:59:46.675843 11654 sgd_solver.cpp:112] Iteration 49000, lr = 0.1
I0524 07:59:55.284618 11654 solver.cpp:239] Iteration 49010 (1.16165 iter/s, 8.60842s/10 iters), loss = 6.01863
I0524 07:59:55.284670 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01863 (* 1 = 6.01863 loss)
I0524 07:59:55.612877 11654 sgd_solver.cpp:112] Iteration 49010, lr = 0.1
I0524 08:00:02.284296 11654 solver.cpp:239] Iteration 49020 (1.42871 iter/s, 6.99934s/10 iters), loss = 5.45969
I0524 08:00:02.284363 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.45969 (* 1 = 5.45969 loss)
I0524 08:00:02.284575 11654 sgd_solver.cpp:112] Iteration 49020, lr = 0.1
I0524 08:00:08.647302 11654 solver.cpp:239] Iteration 49030 (1.57167 iter/s, 6.36264s/10 iters), loss = 5.80438
I0524 08:00:08.647732 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80438 (* 1 = 5.80438 loss)
I0524 08:00:08.647758 11654 sgd_solver.cpp:112] Iteration 49030, lr = 0.1
I0524 08:00:14.958531 11654 solver.cpp:239] Iteration 49040 (1.58511 iter/s, 6.3087s/10 iters), loss = 5.01494
I0524 08:00:14.958590 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.01494 (* 1 = 5.01494 loss)
I0524 08:00:14.958618 11654 sgd_solver.cpp:112] Iteration 49040, lr = 0.1
I0524 08:00:23.498206 11654 solver.cpp:239] Iteration 49050 (1.17111 iter/s, 8.53892s/10 iters), loss = 6.05713
I0524 08:00:23.498270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05713 (* 1 = 6.05713 loss)
I0524 08:00:23.498332 11654 sgd_solver.cpp:112] Iteration 49050, lr = 0.1
I0524 08:00:32.320996 11654 solver.cpp:239] Iteration 49060 (1.13348 iter/s, 8.82237s/10 iters), loss = 6.37614
I0524 08:00:32.321066 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37614 (* 1 = 6.37614 loss)
I0524 08:00:32.321087 11654 sgd_solver.cpp:112] Iteration 49060, lr = 0.1
I0524 08:00:39.457410 11654 solver.cpp:239] Iteration 49070 (1.40134 iter/s, 7.13603s/10 iters), loss = 5.86149
I0524 08:00:39.457669 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86149 (* 1 = 5.86149 loss)
I0524 08:00:39.958719 11654 sgd_solver.cpp:112] Iteration 49070, lr = 0.1
I0524 08:00:46.164028 11654 solver.cpp:239] Iteration 49080 (1.49117 iter/s, 6.70615s/10 iters), loss = 6.87007
I0524 08:00:46.164108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87007 (* 1 = 6.87007 loss)
I0524 08:00:46.164180 11654 sgd_solver.cpp:112] Iteration 49080, lr = 0.1
I0524 08:00:54.775022 11654 solver.cpp:239] Iteration 49090 (1.16136 iter/s, 8.61061s/10 iters), loss = 6.7393
I0524 08:00:54.775058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7393 (* 1 = 6.7393 loss)
I0524 08:00:56.163892 11654 sgd_solver.cpp:112] Iteration 49090, lr = 0.1
I0524 08:01:03.578008 11654 solver.cpp:239] Iteration 49100 (1.13603 iter/s, 8.80259s/10 iters), loss = 5.8272
I0524 08:01:03.578073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8272 (* 1 = 5.8272 loss)
I0524 08:01:03.583693 11654 sgd_solver.cpp:112] Iteration 49100, lr = 0.1
I0524 08:01:11.562760 11654 solver.cpp:239] Iteration 49110 (1.25245 iter/s, 7.98437s/10 iters), loss = 5.66435
I0524 08:01:11.563026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66435 (* 1 = 5.66435 loss)
I0524 08:01:12.498692 11654 sgd_solver.cpp:112] Iteration 49110, lr = 0.1
I0524 08:01:21.177037 11654 solver.cpp:239] Iteration 49120 (1.04019 iter/s, 9.61366s/10 iters), loss = 6.0639
I0524 08:01:21.177112 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0639 (* 1 = 6.0639 loss)
I0524 08:01:21.177129 11654 sgd_solver.cpp:112] Iteration 49120, lr = 0.1
I0524 08:01:30.011050 11654 solver.cpp:239] Iteration 49130 (1.13204 iter/s, 8.83361s/10 iters), loss = 6.25612
I0524 08:01:30.011116 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25612 (* 1 = 6.25612 loss)
I0524 08:01:30.449970 11654 sgd_solver.cpp:112] Iteration 49130, lr = 0.1
I0524 08:01:36.965850 11654 solver.cpp:239] Iteration 49140 (1.43792 iter/s, 6.95447s/10 iters), loss = 5.28646
I0524 08:01:36.965900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28646 (* 1 = 5.28646 loss)
I0524 08:01:36.966066 11654 sgd_solver.cpp:112] Iteration 49140, lr = 0.1
I0524 08:01:44.438567 11654 solver.cpp:239] Iteration 49150 (1.33826 iter/s, 7.47237s/10 iters), loss = 6.04152
I0524 08:01:44.438794 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04152 (* 1 = 6.04152 loss)
I0524 08:01:44.440728 11654 sgd_solver.cpp:112] Iteration 49150, lr = 0.1
I0524 08:01:51.153131 11654 solver.cpp:239] Iteration 49160 (1.4894 iter/s, 6.71411s/10 iters), loss = 6.7494
I0524 08:01:51.153193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7494 (* 1 = 6.7494 loss)
I0524 08:01:51.279109 11654 sgd_solver.cpp:112] Iteration 49160, lr = 0.1
I0524 08:01:58.741482 11654 solver.cpp:239] Iteration 49170 (1.31787 iter/s, 7.588s/10 iters), loss = 5.30859
I0524 08:01:58.741554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30859 (* 1 = 5.30859 loss)
I0524 08:01:59.272191 11654 sgd_solver.cpp:112] Iteration 49170, lr = 0.1
I0524 08:02:08.102270 11654 solver.cpp:239] Iteration 49180 (1.06833 iter/s, 9.36038s/10 iters), loss = 6.06472
I0524 08:02:08.102320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06472 (* 1 = 6.06472 loss)
I0524 08:02:08.102737 11654 sgd_solver.cpp:112] Iteration 49180, lr = 0.1
I0524 08:02:16.084931 11654 solver.cpp:239] Iteration 49190 (1.25277 iter/s, 7.98228s/10 iters), loss = 6.82948
I0524 08:02:16.085088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82948 (* 1 = 6.82948 loss)
I0524 08:02:16.085105 11654 sgd_solver.cpp:112] Iteration 49190, lr = 0.1
I0524 08:02:24.176472 11654 solver.cpp:239] Iteration 49200 (1.23594 iter/s, 8.09104s/10 iters), loss = 6.31597
I0524 08:02:24.176542 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31597 (* 1 = 6.31597 loss)
I0524 08:02:24.176565 11654 sgd_solver.cpp:112] Iteration 49200, lr = 0.1
I0524 08:02:31.942183 11654 solver.cpp:239] Iteration 49210 (1.28814 iter/s, 7.76313s/10 iters), loss = 7.35213
I0524 08:02:31.942245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.35213 (* 1 = 7.35213 loss)
I0524 08:02:31.942306 11654 sgd_solver.cpp:112] Iteration 49210, lr = 0.1
I0524 08:02:39.182590 11654 solver.cpp:239] Iteration 49220 (1.3812 iter/s, 7.24007s/10 iters), loss = 6.24437
I0524 08:02:39.182641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24437 (* 1 = 6.24437 loss)
I0524 08:02:39.516248 11654 sgd_solver.cpp:112] Iteration 49220, lr = 0.1
I0524 08:02:46.923353 11654 solver.cpp:239] Iteration 49230 (1.29192 iter/s, 7.74041s/10 iters), loss = 6.27435
I0524 08:02:46.923477 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27435 (* 1 = 6.27435 loss)
I0524 08:02:46.923493 11654 sgd_solver.cpp:112] Iteration 49230, lr = 0.1
I0524 08:02:56.078816 11654 solver.cpp:239] Iteration 49240 (1.09234 iter/s, 9.15463s/10 iters), loss = 6.30369
I0524 08:02:56.078872 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30369 (* 1 = 6.30369 loss)
I0524 08:02:56.731091 11654 sgd_solver.cpp:112] Iteration 49240, lr = 0.1
I0524 08:03:04.417822 11654 solver.cpp:239] Iteration 49250 (1.19924 iter/s, 8.33863s/10 iters), loss = 5.90231
I0524 08:03:04.417876 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90231 (* 1 = 5.90231 loss)
I0524 08:03:04.417891 11654 sgd_solver.cpp:112] Iteration 49250, lr = 0.1
I0524 08:03:13.245736 11654 solver.cpp:239] Iteration 49260 (1.13282 iter/s, 8.82751s/10 iters), loss = 7.08901
I0524 08:03:13.245792 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08901 (* 1 = 7.08901 loss)
I0524 08:03:13.245945 11654 sgd_solver.cpp:112] Iteration 49260, lr = 0.1
I0524 08:03:19.951815 11654 solver.cpp:239] Iteration 49270 (1.49126 iter/s, 6.70575s/10 iters), loss = 5.72452
I0524 08:03:19.951992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72452 (* 1 = 5.72452 loss)
I0524 08:03:20.212018 11654 sgd_solver.cpp:112] Iteration 49270, lr = 0.1
I0524 08:03:28.512912 11654 solver.cpp:239] Iteration 49280 (1.16814 iter/s, 8.56059s/10 iters), loss = 6.30564
I0524 08:03:28.512977 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30564 (* 1 = 6.30564 loss)
I0524 08:03:29.197872 11654 sgd_solver.cpp:112] Iteration 49280, lr = 0.1
I0524 08:03:35.804169 11654 solver.cpp:239] Iteration 49290 (1.37157 iter/s, 7.2909s/10 iters), loss = 5.53395
I0524 08:03:35.804244 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53395 (* 1 = 5.53395 loss)
I0524 08:03:35.857247 11654 sgd_solver.cpp:112] Iteration 49290, lr = 0.1
I0524 08:03:44.045410 11654 solver.cpp:239] Iteration 49300 (1.21347 iter/s, 8.24085s/10 iters), loss = 6.5376
I0524 08:03:44.045469 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5376 (* 1 = 6.5376 loss)
I0524 08:03:44.045511 11654 sgd_solver.cpp:112] Iteration 49300, lr = 0.1
I0524 08:03:51.090229 11654 solver.cpp:239] Iteration 49310 (1.41956 iter/s, 7.04445s/10 iters), loss = 7.17838
I0524 08:03:51.090414 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.17838 (* 1 = 7.17838 loss)
I0524 08:03:51.090464 11654 sgd_solver.cpp:112] Iteration 49310, lr = 0.1
I0524 08:04:02.158709 11654 solver.cpp:239] Iteration 49320 (0.903517 iter/s, 11.0679s/10 iters), loss = 6.43318
I0524 08:04:02.158762 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43318 (* 1 = 6.43318 loss)
I0524 08:04:02.158779 11654 sgd_solver.cpp:112] Iteration 49320, lr = 0.1
I0524 08:04:10.394544 11654 solver.cpp:239] Iteration 49330 (1.21427 iter/s, 8.2354s/10 iters), loss = 6.23068
I0524 08:04:10.394599 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23068 (* 1 = 6.23068 loss)
I0524 08:04:10.472920 11654 sgd_solver.cpp:112] Iteration 49330, lr = 0.1
I0524 08:04:18.913761 11654 solver.cpp:239] Iteration 49340 (1.17387 iter/s, 8.51884s/10 iters), loss = 6.85236
I0524 08:04:18.913806 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85236 (* 1 = 6.85236 loss)
I0524 08:04:19.282467 11654 sgd_solver.cpp:112] Iteration 49340, lr = 0.1
I0524 08:04:26.901612 11654 solver.cpp:239] Iteration 49350 (1.25196 iter/s, 7.98748s/10 iters), loss = 5.70782
I0524 08:04:26.901875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70782 (* 1 = 5.70782 loss)
I0524 08:04:26.901952 11654 sgd_solver.cpp:112] Iteration 49350, lr = 0.1
I0524 08:04:34.193773 11654 solver.cpp:239] Iteration 49360 (1.37146 iter/s, 7.2915s/10 iters), loss = 6.4733
I0524 08:04:34.193817 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4733 (* 1 = 6.4733 loss)
I0524 08:04:34.193902 11654 sgd_solver.cpp:112] Iteration 49360, lr = 0.1
I0524 08:04:41.447266 11654 solver.cpp:239] Iteration 49370 (1.37871 iter/s, 7.25314s/10 iters), loss = 4.57581
I0524 08:04:41.447335 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.57581 (* 1 = 4.57581 loss)
I0524 08:04:41.966382 11654 sgd_solver.cpp:112] Iteration 49370, lr = 0.1
I0524 08:04:48.874517 11654 solver.cpp:239] Iteration 49380 (1.34646 iter/s, 7.42689s/10 iters), loss = 6.63568
I0524 08:04:48.874635 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63568 (* 1 = 6.63568 loss)
I0524 08:04:48.874661 11654 sgd_solver.cpp:112] Iteration 49380, lr = 0.1
I0524 08:04:56.232987 11654 solver.cpp:239] Iteration 49390 (1.35945 iter/s, 7.35591s/10 iters), loss = 6.28659
I0524 08:04:56.233039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28659 (* 1 = 6.28659 loss)
I0524 08:04:56.233491 11654 sgd_solver.cpp:112] Iteration 49390, lr = 0.1
I0524 08:05:03.381207 11654 solver.cpp:239] Iteration 49400 (1.39902 iter/s, 7.14789s/10 iters), loss = 6.29362
I0524 08:05:03.381417 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29362 (* 1 = 6.29362 loss)
I0524 08:05:03.955389 11654 sgd_solver.cpp:112] Iteration 49400, lr = 0.1
I0524 08:05:13.911898 11654 solver.cpp:239] Iteration 49410 (0.949659 iter/s, 10.5301s/10 iters), loss = 6.40487
I0524 08:05:13.911950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40487 (* 1 = 6.40487 loss)
I0524 08:05:13.911968 11654 sgd_solver.cpp:112] Iteration 49410, lr = 0.1
I0524 08:05:20.528764 11654 solver.cpp:239] Iteration 49420 (1.51138 iter/s, 6.61646s/10 iters), loss = 6.09435
I0524 08:05:20.528841 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09435 (* 1 = 6.09435 loss)
I0524 08:05:20.529024 11654 sgd_solver.cpp:112] Iteration 49420, lr = 0.1
I0524 08:05:27.188138 11654 solver.cpp:239] Iteration 49430 (1.50172 iter/s, 6.65904s/10 iters), loss = 6.14248
I0524 08:05:27.188204 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14248 (* 1 = 6.14248 loss)
I0524 08:05:27.188275 11654 sgd_solver.cpp:112] Iteration 49430, lr = 0.1
I0524 08:05:34.115844 11654 solver.cpp:239] Iteration 49440 (1.44355 iter/s, 6.92738s/10 iters), loss = 5.75677
I0524 08:05:34.116138 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75677 (* 1 = 5.75677 loss)
I0524 08:05:34.116328 11654 sgd_solver.cpp:112] Iteration 49440, lr = 0.1
I0524 08:05:40.990458 11654 solver.cpp:239] Iteration 49450 (1.45474 iter/s, 6.87408s/10 iters), loss = 7.04932
I0524 08:05:40.990523 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.04932 (* 1 = 7.04932 loss)
I0524 08:05:40.990808 11654 sgd_solver.cpp:112] Iteration 49450, lr = 0.1
I0524 08:05:47.324075 11654 solver.cpp:239] Iteration 49460 (1.57895 iter/s, 6.33331s/10 iters), loss = 5.8271
I0524 08:05:47.324131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8271 (* 1 = 5.8271 loss)
I0524 08:05:47.324494 11654 sgd_solver.cpp:112] Iteration 49460, lr = 0.1
I0524 08:05:55.189649 11654 solver.cpp:239] Iteration 49470 (1.27142 iter/s, 7.86521s/10 iters), loss = 6.77757
I0524 08:05:55.189723 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77757 (* 1 = 6.77757 loss)
I0524 08:05:55.189741 11654 sgd_solver.cpp:112] Iteration 49470, lr = 0.1
I0524 08:06:03.427871 11654 solver.cpp:239] Iteration 49480 (1.21392 iter/s, 8.23779s/10 iters), loss = 6.58941
I0524 08:06:03.427928 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58941 (* 1 = 6.58941 loss)
I0524 08:06:03.427959 11654 sgd_solver.cpp:112] Iteration 49480, lr = 0.1
I0524 08:06:11.030102 11654 solver.cpp:239] Iteration 49490 (1.31548 iter/s, 7.6018s/10 iters), loss = 6.09436
I0524 08:06:11.030300 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09436 (* 1 = 6.09436 loss)
I0524 08:06:11.030336 11654 sgd_solver.cpp:112] Iteration 49490, lr = 0.1
I0524 08:06:17.955524 11654 solver.cpp:239] Iteration 49500 (1.44405 iter/s, 6.92496s/10 iters), loss = 6.20125
I0524 08:06:17.955586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20125 (* 1 = 6.20125 loss)
I0524 08:06:17.955677 11654 sgd_solver.cpp:112] Iteration 49500, lr = 0.1
I0524 08:06:25.651064 11654 solver.cpp:239] Iteration 49510 (1.29951 iter/s, 7.69518s/10 iters), loss = 6.51441
I0524 08:06:25.651118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51441 (* 1 = 6.51441 loss)
I0524 08:06:25.652674 11654 sgd_solver.cpp:112] Iteration 49510, lr = 0.1
I0524 08:06:32.319362 11654 solver.cpp:239] Iteration 49520 (1.4997 iter/s, 6.66799s/10 iters), loss = 6.04267
I0524 08:06:32.319412 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04267 (* 1 = 6.04267 loss)
I0524 08:06:32.319427 11654 sgd_solver.cpp:112] Iteration 49520, lr = 0.1
I0524 08:06:39.842820 11654 solver.cpp:239] Iteration 49530 (1.32925 iter/s, 7.52304s/10 iters), loss = 7.07798
I0524 08:06:39.842885 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07798 (* 1 = 7.07798 loss)
I0524 08:06:39.846235 11654 sgd_solver.cpp:112] Iteration 49530, lr = 0.1
I0524 08:06:47.470995 11654 solver.cpp:239] Iteration 49540 (1.31099 iter/s, 7.62782s/10 iters), loss = 6.76594
I0524 08:06:47.471298 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76594 (* 1 = 6.76594 loss)
I0524 08:06:47.471346 11654 sgd_solver.cpp:112] Iteration 49540, lr = 0.1
I0524 08:06:55.232604 11654 solver.cpp:239] Iteration 49550 (1.28849 iter/s, 7.76101s/10 iters), loss = 6.42126
I0524 08:06:55.232717 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42126 (* 1 = 6.42126 loss)
I0524 08:06:55.232762 11654 sgd_solver.cpp:112] Iteration 49550, lr = 0.1
I0524 08:07:01.550259 11654 solver.cpp:239] Iteration 49560 (1.5835 iter/s, 6.31514s/10 iters), loss = 6.32589
I0524 08:07:01.550364 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32589 (* 1 = 6.32589 loss)
I0524 08:07:01.550501 11654 sgd_solver.cpp:112] Iteration 49560, lr = 0.1
I0524 08:07:09.809671 11654 solver.cpp:239] Iteration 49570 (1.2108 iter/s, 8.25902s/10 iters), loss = 6.47239
I0524 08:07:09.809720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47239 (* 1 = 6.47239 loss)
I0524 08:07:09.809736 11654 sgd_solver.cpp:112] Iteration 49570, lr = 0.1
I0524 08:07:16.095835 11654 solver.cpp:239] Iteration 49580 (1.59089 iter/s, 6.2858s/10 iters), loss = 5.71382
I0524 08:07:16.095948 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71382 (* 1 = 5.71382 loss)
I0524 08:07:16.096148 11654 sgd_solver.cpp:112] Iteration 49580, lr = 0.1
I0524 08:07:22.910346 11654 solver.cpp:239] Iteration 49590 (1.46753 iter/s, 6.81419s/10 iters), loss = 6.29389
I0524 08:07:22.910550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29389 (* 1 = 6.29389 loss)
I0524 08:07:22.994705 11654 sgd_solver.cpp:112] Iteration 49590, lr = 0.1
I0524 08:07:31.087942 11654 solver.cpp:239] Iteration 49600 (1.22293 iter/s, 8.17709s/10 iters), loss = 6.73791
I0524 08:07:31.088001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73791 (* 1 = 6.73791 loss)
I0524 08:07:31.088017 11654 sgd_solver.cpp:112] Iteration 49600, lr = 0.1
I0524 08:07:37.380023 11654 solver.cpp:239] Iteration 49610 (1.58938 iter/s, 6.29176s/10 iters), loss = 5.89372
I0524 08:07:37.380101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89372 (* 1 = 5.89372 loss)
I0524 08:07:37.571954 11654 sgd_solver.cpp:112] Iteration 49610, lr = 0.1
I0524 08:07:47.399394 11654 solver.cpp:239] Iteration 49620 (0.998113 iter/s, 10.0189s/10 iters), loss = 7.47948
I0524 08:07:47.399448 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.47948 (* 1 = 7.47948 loss)
I0524 08:07:47.399463 11654 sgd_solver.cpp:112] Iteration 49620, lr = 0.1
I0524 08:07:53.832597 11654 solver.cpp:239] Iteration 49630 (1.55452 iter/s, 6.43284s/10 iters), loss = 6.28618
I0524 08:07:53.832929 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28618 (* 1 = 6.28618 loss)
I0524 08:07:53.851809 11654 sgd_solver.cpp:112] Iteration 49630, lr = 0.1
I0524 08:08:01.063993 11654 solver.cpp:239] Iteration 49640 (1.38296 iter/s, 7.23085s/10 iters), loss = 5.90339
I0524 08:08:01.064056 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90339 (* 1 = 5.90339 loss)
I0524 08:08:01.098619 11654 sgd_solver.cpp:112] Iteration 49640, lr = 0.1
I0524 08:08:08.243785 11654 solver.cpp:239] Iteration 49650 (1.39287 iter/s, 7.17941s/10 iters), loss = 5.79695
I0524 08:08:08.243860 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79695 (* 1 = 5.79695 loss)
I0524 08:08:08.244033 11654 sgd_solver.cpp:112] Iteration 49650, lr = 0.1
I0524 08:08:15.556363 11654 solver.cpp:239] Iteration 49660 (1.36757 iter/s, 7.31222s/10 iters), loss = 6.89297
I0524 08:08:15.556422 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.89297 (* 1 = 6.89297 loss)
I0524 08:08:16.272866 11654 sgd_solver.cpp:112] Iteration 49660, lr = 0.1
I0524 08:08:23.207732 11654 solver.cpp:239] Iteration 49670 (1.30702 iter/s, 7.651s/10 iters), loss = 5.3166
I0524 08:08:23.207825 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3166 (* 1 = 5.3166 loss)
I0524 08:08:23.207846 11654 sgd_solver.cpp:112] Iteration 49670, lr = 0.1
I0524 08:08:32.695379 11654 solver.cpp:239] Iteration 49680 (1.05406 iter/s, 9.48717s/10 iters), loss = 4.9392
I0524 08:08:32.695667 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.9392 (* 1 = 4.9392 loss)
I0524 08:08:32.695715 11654 sgd_solver.cpp:112] Iteration 49680, lr = 0.1
I0524 08:08:39.416780 11654 solver.cpp:239] Iteration 49690 (1.48791 iter/s, 6.72085s/10 iters), loss = 6.13757
I0524 08:08:39.416847 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13757 (* 1 = 6.13757 loss)
I0524 08:08:39.493677 11654 sgd_solver.cpp:112] Iteration 49690, lr = 0.1
I0524 08:08:49.326181 11654 solver.cpp:239] Iteration 49700 (1.00919 iter/s, 9.90896s/10 iters), loss = 6.56985
I0524 08:08:49.326256 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56985 (* 1 = 6.56985 loss)
I0524 08:08:49.326272 11654 sgd_solver.cpp:112] Iteration 49700, lr = 0.1
I0524 08:08:56.275490 11654 solver.cpp:239] Iteration 49710 (1.43907 iter/s, 6.94891s/10 iters), loss = 7.19001
I0524 08:08:56.275562 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19001 (* 1 = 7.19001 loss)
I0524 08:08:56.275691 11654 sgd_solver.cpp:112] Iteration 49710, lr = 0.1
I0524 08:09:03.679791 11654 solver.cpp:239] Iteration 49720 (1.35063 iter/s, 7.40396s/10 iters), loss = 6.30565
I0524 08:09:03.680016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30565 (* 1 = 6.30565 loss)
I0524 08:09:03.682356 11654 sgd_solver.cpp:112] Iteration 49720, lr = 0.1
I0524 08:09:10.390606 11654 solver.cpp:239] Iteration 49730 (1.49024 iter/s, 6.71031s/10 iters), loss = 5.83666
I0524 08:09:10.390753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83666 (* 1 = 5.83666 loss)
I0524 08:09:10.390805 11654 sgd_solver.cpp:112] Iteration 49730, lr = 0.1
I0524 08:09:16.837893 11654 solver.cpp:239] Iteration 49740 (1.55113 iter/s, 6.44691s/10 iters), loss = 5.88538
I0524 08:09:16.837951 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88538 (* 1 = 5.88538 loss)
I0524 08:09:16.838152 11654 sgd_solver.cpp:112] Iteration 49740, lr = 0.1
I0524 08:09:25.049690 11654 solver.cpp:239] Iteration 49750 (1.21782 iter/s, 8.2114s/10 iters), loss = 6.48981
I0524 08:09:25.049769 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48981 (* 1 = 6.48981 loss)
I0524 08:09:25.050285 11654 sgd_solver.cpp:112] Iteration 49750, lr = 0.1
I0524 08:09:32.085177 11654 solver.cpp:239] Iteration 49760 (1.42144 iter/s, 7.03513s/10 iters), loss = 6.14361
I0524 08:09:32.085275 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14361 (* 1 = 6.14361 loss)
I0524 08:09:32.085305 11654 sgd_solver.cpp:112] Iteration 49760, lr = 0.1
I0524 08:09:41.133231 11654 solver.cpp:239] Iteration 49770 (1.10553 iter/s, 9.04542s/10 iters), loss = 6.55815
I0524 08:09:41.133507 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55815 (* 1 = 6.55815 loss)
I0524 08:09:41.133553 11654 sgd_solver.cpp:112] Iteration 49770, lr = 0.1
I0524 08:09:47.860721 11654 solver.cpp:239] Iteration 49780 (1.48656 iter/s, 6.72696s/10 iters), loss = 5.92956
I0524 08:09:47.860765 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92956 (* 1 = 5.92956 loss)
I0524 08:09:47.860780 11654 sgd_solver.cpp:112] Iteration 49780, lr = 0.1
I0524 08:09:54.051468 11654 solver.cpp:239] Iteration 49790 (1.6154 iter/s, 6.19043s/10 iters), loss = 6.84214
I0524 08:09:54.051575 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84214 (* 1 = 6.84214 loss)
I0524 08:09:54.051595 11654 sgd_solver.cpp:112] Iteration 49790, lr = 0.1
I0524 08:10:00.765116 11654 solver.cpp:239] Iteration 49800 (1.48958 iter/s, 6.71332s/10 iters), loss = 5.85505
I0524 08:10:00.765219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85505 (* 1 = 5.85505 loss)
I0524 08:10:00.905659 11654 sgd_solver.cpp:112] Iteration 49800, lr = 0.1
I0524 08:10:09.620497 11654 solver.cpp:239] Iteration 49810 (1.12931 iter/s, 8.85496s/10 iters), loss = 6.92148
I0524 08:10:09.620543 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92148 (* 1 = 6.92148 loss)
I0524 08:10:10.609623 11654 sgd_solver.cpp:112] Iteration 49810, lr = 0.1
I0524 08:10:18.579572 11654 solver.cpp:239] Iteration 49820 (1.11624 iter/s, 8.95867s/10 iters), loss = 6.86806
I0524 08:10:18.579766 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86806 (* 1 = 6.86806 loss)
I0524 08:10:18.916687 11654 sgd_solver.cpp:112] Iteration 49820, lr = 0.1
I0524 08:10:25.762189 11654 solver.cpp:239] Iteration 49830 (1.39234 iter/s, 7.18216s/10 iters), loss = 5.84297
I0524 08:10:25.762238 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84297 (* 1 = 5.84297 loss)
I0524 08:10:25.762253 11654 sgd_solver.cpp:112] Iteration 49830, lr = 0.1
I0524 08:10:33.423856 11654 solver.cpp:239] Iteration 49840 (1.30527 iter/s, 7.66126s/10 iters), loss = 6.13224
I0524 08:10:33.423918 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13224 (* 1 = 6.13224 loss)
I0524 08:10:33.423938 11654 sgd_solver.cpp:112] Iteration 49840, lr = 0.1
I0524 08:10:42.367281 11654 solver.cpp:239] Iteration 49850 (1.11846 iter/s, 8.94084s/10 iters), loss = 6.2032
I0524 08:10:42.367336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2032 (* 1 = 6.2032 loss)
I0524 08:10:42.641959 11654 sgd_solver.cpp:112] Iteration 49850, lr = 0.1
I0524 08:10:49.337111 11654 solver.cpp:239] Iteration 49860 (1.43483 iter/s, 6.96949s/10 iters), loss = 5.56971
I0524 08:10:49.337342 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56971 (* 1 = 5.56971 loss)
I0524 08:10:49.337381 11654 sgd_solver.cpp:112] Iteration 49860, lr = 0.1
I0524 08:10:57.543385 11654 solver.cpp:239] Iteration 49870 (1.21898 iter/s, 8.2036s/10 iters), loss = 6.23095
I0524 08:10:57.543476 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23095 (* 1 = 6.23095 loss)
I0524 08:10:57.543819 11654 sgd_solver.cpp:112] Iteration 49870, lr = 0.1
I0524 08:11:04.874303 11654 solver.cpp:239] Iteration 49880 (1.36415 iter/s, 7.33055s/10 iters), loss = 6.19858
I0524 08:11:04.874356 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19858 (* 1 = 6.19858 loss)
I0524 08:11:04.874370 11654 sgd_solver.cpp:112] Iteration 49880, lr = 0.1
I0524 08:11:13.811553 11654 solver.cpp:239] Iteration 49890 (1.11896 iter/s, 8.93684s/10 iters), loss = 5.30788
I0524 08:11:13.811616 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30788 (* 1 = 5.30788 loss)
I0524 08:11:14.591462 11654 sgd_solver.cpp:112] Iteration 49890, lr = 0.1
I0524 08:11:24.418134 11654 solver.cpp:239] Iteration 49900 (0.94286 iter/s, 10.606s/10 iters), loss = 5.3073
I0524 08:11:24.418453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3073 (* 1 = 5.3073 loss)
I0524 08:11:24.418623 11654 sgd_solver.cpp:112] Iteration 49900, lr = 0.1
I0524 08:11:32.471343 11654 solver.cpp:239] Iteration 49910 (1.24183 iter/s, 8.05262s/10 iters), loss = 6.17005
I0524 08:11:32.471420 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17005 (* 1 = 6.17005 loss)
I0524 08:11:32.471936 11654 sgd_solver.cpp:112] Iteration 49910, lr = 0.1
I0524 08:11:39.055047 11654 solver.cpp:239] Iteration 49920 (1.51898 iter/s, 6.58338s/10 iters), loss = 6.56618
I0524 08:11:39.055104 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56618 (* 1 = 6.56618 loss)
I0524 08:11:39.055526 11654 sgd_solver.cpp:112] Iteration 49920, lr = 0.1
I0524 08:11:47.628525 11654 solver.cpp:239] Iteration 49930 (1.16645 iter/s, 8.57305s/10 iters), loss = 6.06679
I0524 08:11:47.628638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06679 (* 1 = 6.06679 loss)
I0524 08:11:47.628887 11654 sgd_solver.cpp:112] Iteration 49930, lr = 0.1
I0524 08:11:55.343204 11654 solver.cpp:239] Iteration 49940 (1.2963 iter/s, 7.71429s/10 iters), loss = 5.68488
I0524 08:11:55.343482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68488 (* 1 = 5.68488 loss)
I0524 08:11:55.991487 11654 sgd_solver.cpp:112] Iteration 49940, lr = 0.1
I0524 08:12:03.994557 11654 solver.cpp:239] Iteration 49950 (1.15597 iter/s, 8.65077s/10 iters), loss = 6.94915
I0524 08:12:03.994616 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94915 (* 1 = 6.94915 loss)
I0524 08:12:04.032943 11654 sgd_solver.cpp:112] Iteration 49950, lr = 0.1
I0524 08:12:12.800215 11654 solver.cpp:239] Iteration 49960 (1.13568 iter/s, 8.80526s/10 iters), loss = 6.30346
I0524 08:12:12.800284 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30346 (* 1 = 6.30346 loss)
I0524 08:12:13.760852 11654 sgd_solver.cpp:112] Iteration 49960, lr = 0.1
I0524 08:12:20.792546 11654 solver.cpp:239] Iteration 49970 (1.25126 iter/s, 7.99195s/10 iters), loss = 6.50871
I0524 08:12:20.792596 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50871 (* 1 = 6.50871 loss)
I0524 08:12:20.792654 11654 sgd_solver.cpp:112] Iteration 49970, lr = 0.1
I0524 08:12:28.284942 11654 solver.cpp:239] Iteration 49980 (1.33475 iter/s, 7.49204s/10 iters), loss = 5.30158
I0524 08:12:28.285199 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30158 (* 1 = 5.30158 loss)
I0524 08:12:28.285244 11654 sgd_solver.cpp:112] Iteration 49980, lr = 0.1
I0524 08:12:35.696451 11654 solver.cpp:239] Iteration 49990 (1.34938 iter/s, 7.41081s/10 iters), loss = 6.43113
I0524 08:12:35.696512 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43113 (* 1 = 6.43113 loss)
I0524 08:12:35.696651 11654 sgd_solver.cpp:112] Iteration 49990, lr = 0.1
I0524 08:12:44.096853 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_50000.caffemodel
I0524 08:12:46.618929 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_50000.solverstate
I0524 08:12:47.314565 11654 solver.cpp:239] Iteration 50000 (0.860761 iter/s, 11.6176s/10 iters), loss = 6.53645
I0524 08:12:47.314607 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53645 (* 1 = 6.53645 loss)
I0524 08:12:48.173377 11654 sgd_solver.cpp:112] Iteration 50000, lr = 0.1
I0524 08:12:56.050267 11654 solver.cpp:239] Iteration 50010 (1.14478 iter/s, 8.73531s/10 iters), loss = 6.20562
I0524 08:12:56.050334 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20562 (* 1 = 6.20562 loss)
I0524 08:12:56.050748 11654 sgd_solver.cpp:112] Iteration 50010, lr = 0.1
I0524 08:13:03.343896 11654 solver.cpp:239] Iteration 50020 (1.37112 iter/s, 7.29329s/10 iters), loss = 5.82892
I0524 08:13:03.344101 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82892 (* 1 = 5.82892 loss)
I0524 08:13:03.344139 11654 sgd_solver.cpp:112] Iteration 50020, lr = 0.1
I0524 08:13:10.557554 11654 solver.cpp:239] Iteration 50030 (1.38674 iter/s, 7.21118s/10 iters), loss = 5.50373
I0524 08:13:10.557605 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50373 (* 1 = 5.50373 loss)
I0524 08:13:10.557621 11654 sgd_solver.cpp:112] Iteration 50030, lr = 0.1
I0524 08:13:19.178421 11654 solver.cpp:239] Iteration 50040 (1.16004 iter/s, 8.62042s/10 iters), loss = 6.80685
I0524 08:13:19.178474 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80685 (* 1 = 6.80685 loss)
I0524 08:13:19.178491 11654 sgd_solver.cpp:112] Iteration 50040, lr = 0.1
I0524 08:13:26.827963 11654 solver.cpp:239] Iteration 50050 (1.30738 iter/s, 7.64888s/10 iters), loss = 6.54356
I0524 08:13:26.828035 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54356 (* 1 = 6.54356 loss)
I0524 08:13:27.133999 11654 sgd_solver.cpp:112] Iteration 50050, lr = 0.1
I0524 08:13:36.007035 11654 solver.cpp:239] Iteration 50060 (1.08949 iter/s, 9.17865s/10 iters), loss = 6.64828
I0524 08:13:36.007344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64828 (* 1 = 6.64828 loss)
I0524 08:13:36.009112 11654 sgd_solver.cpp:112] Iteration 50060, lr = 0.1
I0524 08:13:43.899293 11654 solver.cpp:239] Iteration 50070 (1.26716 iter/s, 7.89166s/10 iters), loss = 6.94683
I0524 08:13:43.899349 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94683 (* 1 = 6.94683 loss)
I0524 08:13:44.997565 11654 sgd_solver.cpp:112] Iteration 50070, lr = 0.1
I0524 08:13:51.792592 11654 solver.cpp:239] Iteration 50080 (1.26696 iter/s, 7.89288s/10 iters), loss = 5.29065
I0524 08:13:51.792665 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29065 (* 1 = 5.29065 loss)
I0524 08:13:51.792686 11654 sgd_solver.cpp:112] Iteration 50080, lr = 0.1
I0524 08:14:00.463024 11654 solver.cpp:239] Iteration 50090 (1.1534 iter/s, 8.67003s/10 iters), loss = 6.3124
I0524 08:14:00.463086 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3124 (* 1 = 6.3124 loss)
I0524 08:14:00.463104 11654 sgd_solver.cpp:112] Iteration 50090, lr = 0.1
I0524 08:14:07.846648 11654 solver.cpp:239] Iteration 50100 (1.35453 iter/s, 7.38264s/10 iters), loss = 5.64281
I0524 08:14:07.846843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64281 (* 1 = 5.64281 loss)
I0524 08:14:08.080502 11654 sgd_solver.cpp:112] Iteration 50100, lr = 0.1
I0524 08:14:16.284457 11654 solver.cpp:239] Iteration 50110 (1.18522 iter/s, 8.43725s/10 iters), loss = 6.58467
I0524 08:14:16.284534 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58467 (* 1 = 6.58467 loss)
I0524 08:14:16.284586 11654 sgd_solver.cpp:112] Iteration 50110, lr = 0.1
I0524 08:14:23.781989 11654 solver.cpp:239] Iteration 50120 (1.33384 iter/s, 7.49716s/10 iters), loss = 5.57813
I0524 08:14:23.782058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57813 (* 1 = 5.57813 loss)
I0524 08:14:23.782169 11654 sgd_solver.cpp:112] Iteration 50120, lr = 0.1
I0524 08:14:31.955281 11654 solver.cpp:239] Iteration 50130 (1.22356 iter/s, 8.17289s/10 iters), loss = 7.75218
I0524 08:14:31.955351 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.75218 (* 1 = 7.75218 loss)
I0524 08:14:31.955376 11654 sgd_solver.cpp:112] Iteration 50130, lr = 0.1
I0524 08:14:40.761437 11654 solver.cpp:239] Iteration 50140 (1.1357 iter/s, 8.80512s/10 iters), loss = 6.40947
I0524 08:14:40.761723 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40947 (* 1 = 6.40947 loss)
I0524 08:14:41.688745 11654 sgd_solver.cpp:112] Iteration 50140, lr = 0.1
I0524 08:14:50.009191 11654 solver.cpp:239] Iteration 50150 (1.08142 iter/s, 9.24712s/10 iters), loss = 5.89384
I0524 08:14:50.009347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89384 (* 1 = 5.89384 loss)
I0524 08:14:50.230306 11654 sgd_solver.cpp:112] Iteration 50150, lr = 0.1
I0524 08:14:57.550562 11654 solver.cpp:239] Iteration 50160 (1.32609 iter/s, 7.54095s/10 iters), loss = 5.52805
I0524 08:14:57.550716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.52805 (* 1 = 5.52805 loss)
I0524 08:14:58.309716 11654 sgd_solver.cpp:112] Iteration 50160, lr = 0.1
I0524 08:15:05.659593 11654 solver.cpp:239] Iteration 50170 (1.23325 iter/s, 8.10864s/10 iters), loss = 6.55437
I0524 08:15:05.659656 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55437 (* 1 = 6.55437 loss)
I0524 08:15:05.659674 11654 sgd_solver.cpp:112] Iteration 50170, lr = 0.1
I0524 08:15:13.199973 11654 solver.cpp:239] Iteration 50180 (1.32664 iter/s, 7.53786s/10 iters), loss = 5.71705
I0524 08:15:13.200336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71705 (* 1 = 5.71705 loss)
I0524 08:15:13.200394 11654 sgd_solver.cpp:112] Iteration 50180, lr = 0.1
I0524 08:15:20.279477 11654 solver.cpp:239] Iteration 50190 (1.41275 iter/s, 7.07841s/10 iters), loss = 6.20387
I0524 08:15:20.279549 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20387 (* 1 = 6.20387 loss)
I0524 08:15:20.279574 11654 sgd_solver.cpp:112] Iteration 50190, lr = 0.1
I0524 08:15:27.809978 11654 solver.cpp:239] Iteration 50200 (1.328 iter/s, 7.53013s/10 iters), loss = 6.04646
I0524 08:15:27.810084 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04646 (* 1 = 6.04646 loss)
I0524 08:15:27.810127 11654 sgd_solver.cpp:112] Iteration 50200, lr = 0.1
I0524 08:15:35.176651 11654 solver.cpp:239] Iteration 50210 (1.35754 iter/s, 7.36626s/10 iters), loss = 6.18662
I0524 08:15:35.176733 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18662 (* 1 = 6.18662 loss)
I0524 08:15:35.177105 11654 sgd_solver.cpp:112] Iteration 50210, lr = 0.1
I0524 08:15:42.830559 11654 solver.cpp:239] Iteration 50220 (1.30659 iter/s, 7.65354s/10 iters), loss = 6.25848
I0524 08:15:42.830607 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25848 (* 1 = 6.25848 loss)
I0524 08:15:42.849659 11654 sgd_solver.cpp:112] Iteration 50220, lr = 0.1
I0524 08:15:50.593672 11654 solver.cpp:239] Iteration 50230 (1.28821 iter/s, 7.76272s/10 iters), loss = 5.86856
I0524 08:15:50.593926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86856 (* 1 = 5.86856 loss)
I0524 08:15:51.037137 11654 sgd_solver.cpp:112] Iteration 50230, lr = 0.1
I0524 08:15:57.226302 11654 solver.cpp:239] Iteration 50240 (1.5078 iter/s, 6.63218s/10 iters), loss = 6.23535
I0524 08:15:57.226347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23535 (* 1 = 6.23535 loss)
I0524 08:15:57.226409 11654 sgd_solver.cpp:112] Iteration 50240, lr = 0.1
I0524 08:16:05.987924 11654 solver.cpp:239] Iteration 50250 (1.14139 iter/s, 8.76123s/10 iters), loss = 6.77846
I0524 08:16:05.987996 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77846 (* 1 = 6.77846 loss)
I0524 08:16:05.988041 11654 sgd_solver.cpp:112] Iteration 50250, lr = 0.1
I0524 08:16:12.840298 11654 solver.cpp:239] Iteration 50260 (1.45942 iter/s, 6.85204s/10 iters), loss = 6.14137
I0524 08:16:12.840374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14137 (* 1 = 6.14137 loss)
I0524 08:16:12.840817 11654 sgd_solver.cpp:112] Iteration 50260, lr = 0.1
I0524 08:16:21.441714 11654 solver.cpp:239] Iteration 50270 (1.16266 iter/s, 8.60095s/10 iters), loss = 6.25766
I0524 08:16:21.441951 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25766 (* 1 = 6.25766 loss)
I0524 08:16:21.478762 11654 sgd_solver.cpp:112] Iteration 50270, lr = 0.1
I0524 08:16:29.770072 11654 solver.cpp:239] Iteration 50280 (1.20079 iter/s, 8.32783s/10 iters), loss = 6.46634
I0524 08:16:29.770134 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46634 (* 1 = 6.46634 loss)
I0524 08:16:29.770169 11654 sgd_solver.cpp:112] Iteration 50280, lr = 0.1
I0524 08:16:36.302486 11654 solver.cpp:239] Iteration 50290 (1.5309 iter/s, 6.5321s/10 iters), loss = 5.63802
I0524 08:16:36.302573 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63802 (* 1 = 5.63802 loss)
I0524 08:16:36.321682 11654 sgd_solver.cpp:112] Iteration 50290, lr = 0.1
I0524 08:16:42.824405 11654 solver.cpp:239] Iteration 50300 (1.53337 iter/s, 6.52158s/10 iters), loss = 6.74971
I0524 08:16:42.824463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74971 (* 1 = 6.74971 loss)
I0524 08:16:42.824515 11654 sgd_solver.cpp:112] Iteration 50300, lr = 0.1
I0524 08:16:53.252913 11654 solver.cpp:239] Iteration 50310 (0.958951 iter/s, 10.4281s/10 iters), loss = 6.4498
I0524 08:16:53.253188 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4498 (* 1 = 6.4498 loss)
I0524 08:16:53.253244 11654 sgd_solver.cpp:112] Iteration 50310, lr = 0.1
I0524 08:17:01.988562 11654 solver.cpp:239] Iteration 50320 (1.14481 iter/s, 8.73505s/10 iters), loss = 5.88587
I0524 08:17:01.988625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88587 (* 1 = 5.88587 loss)
I0524 08:17:01.988643 11654 sgd_solver.cpp:112] Iteration 50320, lr = 0.1
I0524 08:17:10.048301 11654 solver.cpp:239] Iteration 50330 (1.2408 iter/s, 8.05929s/10 iters), loss = 5.81683
I0524 08:17:10.048367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81683 (* 1 = 5.81683 loss)
I0524 08:17:10.048599 11654 sgd_solver.cpp:112] Iteration 50330, lr = 0.1
I0524 08:17:17.668644 11654 solver.cpp:239] Iteration 50340 (1.31235 iter/s, 7.61994s/10 iters), loss = 6.19724
I0524 08:17:17.668717 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19724 (* 1 = 6.19724 loss)
I0524 08:17:17.920578 11654 sgd_solver.cpp:112] Iteration 50340, lr = 0.1
I0524 08:17:25.401212 11654 solver.cpp:239] Iteration 50350 (1.2933 iter/s, 7.73218s/10 iters), loss = 6.97523
I0524 08:17:25.401453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.97523 (* 1 = 6.97523 loss)
I0524 08:17:25.401517 11654 sgd_solver.cpp:112] Iteration 50350, lr = 0.1
I0524 08:17:32.746974 11654 solver.cpp:239] Iteration 50360 (1.36183 iter/s, 7.34305s/10 iters), loss = 6.23715
I0524 08:17:32.747027 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23715 (* 1 = 6.23715 loss)
I0524 08:17:32.747046 11654 sgd_solver.cpp:112] Iteration 50360, lr = 0.1
I0524 08:17:38.902420 11654 solver.cpp:239] Iteration 50370 (1.62468 iter/s, 6.15507s/10 iters), loss = 5.64763
I0524 08:17:38.902465 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64763 (* 1 = 5.64763 loss)
I0524 08:17:38.902482 11654 sgd_solver.cpp:112] Iteration 50370, lr = 0.1
I0524 08:17:45.519173 11654 solver.cpp:239] Iteration 50380 (1.51141 iter/s, 6.61633s/10 iters), loss = 6.24974
I0524 08:17:45.519242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.24974 (* 1 = 6.24974 loss)
I0524 08:17:45.520267 11654 sgd_solver.cpp:112] Iteration 50380, lr = 0.1
I0524 08:17:53.773875 11654 solver.cpp:239] Iteration 50390 (1.21149 iter/s, 8.25433s/10 iters), loss = 6.69503
I0524 08:17:53.773941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69503 (* 1 = 6.69503 loss)
I0524 08:17:53.774039 11654 sgd_solver.cpp:112] Iteration 50390, lr = 0.1
I0524 08:18:00.633708 11654 solver.cpp:239] Iteration 50400 (1.45784 iter/s, 6.85947s/10 iters), loss = 7.11138
I0524 08:18:00.633945 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.11138 (* 1 = 7.11138 loss)
I0524 08:18:01.338227 11654 sgd_solver.cpp:112] Iteration 50400, lr = 0.1
I0524 08:18:08.883294 11654 solver.cpp:239] Iteration 50410 (1.21226 iter/s, 8.24903s/10 iters), loss = 5.19787
I0524 08:18:08.883361 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.19787 (* 1 = 5.19787 loss)
I0524 08:18:08.883610 11654 sgd_solver.cpp:112] Iteration 50410, lr = 0.1
I0524 08:18:15.802011 11654 solver.cpp:239] Iteration 50420 (1.44543 iter/s, 6.91835s/10 iters), loss = 4.66879
I0524 08:18:15.802095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.66879 (* 1 = 4.66879 loss)
I0524 08:18:15.802587 11654 sgd_solver.cpp:112] Iteration 50420, lr = 0.1
I0524 08:18:22.198536 11654 solver.cpp:239] Iteration 50430 (1.56343 iter/s, 6.39621s/10 iters), loss = 6.67809
I0524 08:18:22.198595 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67809 (* 1 = 6.67809 loss)
I0524 08:18:22.198614 11654 sgd_solver.cpp:112] Iteration 50430, lr = 0.1
I0524 08:18:28.534482 11654 solver.cpp:239] Iteration 50440 (1.57839 iter/s, 6.33559s/10 iters), loss = 6.554
I0524 08:18:28.534518 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.554 (* 1 = 6.554 loss)
I0524 08:18:28.788259 11654 sgd_solver.cpp:112] Iteration 50440, lr = 0.1
I0524 08:18:35.800937 11654 solver.cpp:239] Iteration 50450 (1.37625 iter/s, 7.26613s/10 iters), loss = 6.5027
I0524 08:18:35.801154 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5027 (* 1 = 6.5027 loss)
I0524 08:18:35.801232 11654 sgd_solver.cpp:112] Iteration 50450, lr = 0.1
I0524 08:18:43.195832 11654 solver.cpp:239] Iteration 50460 (1.35238 iter/s, 7.3944s/10 iters), loss = 5.98125
I0524 08:18:43.195894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98125 (* 1 = 5.98125 loss)
I0524 08:18:44.095981 11654 sgd_solver.cpp:112] Iteration 50460, lr = 0.1
I0524 08:18:51.002190 11654 solver.cpp:239] Iteration 50470 (1.28107 iter/s, 7.80597s/10 iters), loss = 5.59812
I0524 08:18:51.002259 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59812 (* 1 = 5.59812 loss)
I0524 08:18:51.002279 11654 sgd_solver.cpp:112] Iteration 50470, lr = 0.1
I0524 08:19:00.306535 11654 solver.cpp:239] Iteration 50480 (1.07481 iter/s, 9.30393s/10 iters), loss = 5.67398
I0524 08:19:00.306591 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67398 (* 1 = 5.67398 loss)
I0524 08:19:00.306612 11654 sgd_solver.cpp:112] Iteration 50480, lr = 0.1
I0524 08:19:09.228694 11654 solver.cpp:239] Iteration 50490 (1.12086 iter/s, 8.9217s/10 iters), loss = 5.65967
I0524 08:19:09.228950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65967 (* 1 = 5.65967 loss)
I0524 08:19:09.395545 11654 sgd_solver.cpp:112] Iteration 50490, lr = 0.1
I0524 08:19:17.886979 11654 solver.cpp:239] Iteration 50500 (1.15504 iter/s, 8.65772s/10 iters), loss = 5.74895
I0524 08:19:17.887037 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74895 (* 1 = 5.74895 loss)
I0524 08:19:18.792129 11654 sgd_solver.cpp:112] Iteration 50500, lr = 0.1
I0524 08:19:27.124897 11654 solver.cpp:239] Iteration 50510 (1.08254 iter/s, 9.2375s/10 iters), loss = 6.43942
I0524 08:19:27.124949 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43942 (* 1 = 6.43942 loss)
I0524 08:19:27.124967 11654 sgd_solver.cpp:112] Iteration 50510, lr = 0.1
I0524 08:19:33.842089 11654 solver.cpp:239] Iteration 50520 (1.4888 iter/s, 6.7168s/10 iters), loss = 5.69478
I0524 08:19:33.842139 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69478 (* 1 = 5.69478 loss)
I0524 08:19:33.842157 11654 sgd_solver.cpp:112] Iteration 50520, lr = 0.1
I0524 08:19:43.085811 11654 solver.cpp:239] Iteration 50530 (1.08187 iter/s, 9.24329s/10 iters), loss = 6.43799
I0524 08:19:43.086279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43799 (* 1 = 6.43799 loss)
I0524 08:19:43.663221 11654 sgd_solver.cpp:112] Iteration 50530, lr = 0.1
I0524 08:19:50.303335 11654 solver.cpp:239] Iteration 50540 (1.38566 iter/s, 7.21679s/10 iters), loss = 5.80465
I0524 08:19:50.303433 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80465 (* 1 = 5.80465 loss)
I0524 08:19:50.313212 11654 sgd_solver.cpp:112] Iteration 50540, lr = 0.1
I0524 08:19:59.801995 11654 solver.cpp:239] Iteration 50550 (1.05283 iter/s, 9.49821s/10 iters), loss = 5.70755
I0524 08:19:59.802062 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70755 (* 1 = 5.70755 loss)
I0524 08:19:59.802198 11654 sgd_solver.cpp:112] Iteration 50550, lr = 0.1
I0524 08:20:07.976161 11654 solver.cpp:239] Iteration 50560 (1.22342 iter/s, 8.17378s/10 iters), loss = 5.71592
I0524 08:20:07.976223 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71592 (* 1 = 5.71592 loss)
I0524 08:20:07.976349 11654 sgd_solver.cpp:112] Iteration 50560, lr = 0.1
I0524 08:20:14.612176 11654 solver.cpp:239] Iteration 50570 (1.50701 iter/s, 6.63565s/10 iters), loss = 7.0115
I0524 08:20:14.612653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0115 (* 1 = 7.0115 loss)
I0524 08:20:14.612783 11654 sgd_solver.cpp:112] Iteration 50570, lr = 0.1
I0524 08:20:21.913502 11654 solver.cpp:239] Iteration 50580 (1.36974 iter/s, 7.30067s/10 iters), loss = 5.46977
I0524 08:20:21.913561 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46977 (* 1 = 5.46977 loss)
I0524 08:20:21.913578 11654 sgd_solver.cpp:112] Iteration 50580, lr = 0.1
I0524 08:20:28.718011 11654 solver.cpp:239] Iteration 50590 (1.46971 iter/s, 6.80408s/10 iters), loss = 6.10245
I0524 08:20:28.718091 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10245 (* 1 = 6.10245 loss)
I0524 08:20:28.718580 11654 sgd_solver.cpp:112] Iteration 50590, lr = 0.1
I0524 08:20:35.875263 11654 solver.cpp:239] Iteration 50600 (1.39726 iter/s, 7.15688s/10 iters), loss = 6.10358
I0524 08:20:35.875365 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10358 (* 1 = 6.10358 loss)
I0524 08:20:35.876667 11654 sgd_solver.cpp:112] Iteration 50600, lr = 0.1
I0524 08:20:43.501643 11654 solver.cpp:239] Iteration 50610 (1.31131 iter/s, 7.62598s/10 iters), loss = 6.48005
I0524 08:20:43.501735 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48005 (* 1 = 6.48005 loss)
I0524 08:20:43.501762 11654 sgd_solver.cpp:112] Iteration 50610, lr = 0.1
I0524 08:20:50.492465 11654 solver.cpp:239] Iteration 50620 (1.43053 iter/s, 6.99044s/10 iters), loss = 6.42489
I0524 08:20:50.492715 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42489 (* 1 = 6.42489 loss)
I0524 08:20:51.305199 11654 sgd_solver.cpp:112] Iteration 50620, lr = 0.1
I0524 08:20:58.732481 11654 solver.cpp:239] Iteration 50630 (1.21368 iter/s, 8.23944s/10 iters), loss = 5.02102
I0524 08:20:58.732540 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.02102 (* 1 = 5.02102 loss)
I0524 08:20:58.734589 11654 sgd_solver.cpp:112] Iteration 50630, lr = 0.1
I0524 08:21:05.122521 11654 solver.cpp:239] Iteration 50640 (1.56501 iter/s, 6.38973s/10 iters), loss = 5.39351
I0524 08:21:05.122596 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.39351 (* 1 = 5.39351 loss)
I0524 08:21:05.122617 11654 sgd_solver.cpp:112] Iteration 50640, lr = 0.1
I0524 08:21:13.484271 11654 solver.cpp:239] Iteration 50650 (1.19598 iter/s, 8.36132s/10 iters), loss = 5.92026
I0524 08:21:13.484328 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92026 (* 1 = 5.92026 loss)
I0524 08:21:13.484345 11654 sgd_solver.cpp:112] Iteration 50650, lr = 0.1
I0524 08:21:19.777202 11654 solver.cpp:239] Iteration 50660 (1.58919 iter/s, 6.29252s/10 iters), loss = 6.15511
I0524 08:21:19.777323 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15511 (* 1 = 6.15511 loss)
I0524 08:21:19.777781 11654 sgd_solver.cpp:112] Iteration 50660, lr = 0.1
I0524 08:21:26.726627 11654 solver.cpp:239] Iteration 50670 (1.43904 iter/s, 6.94907s/10 iters), loss = 5.54504
I0524 08:21:26.726840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54504 (* 1 = 5.54504 loss)
I0524 08:21:26.726881 11654 sgd_solver.cpp:112] Iteration 50670, lr = 0.1
I0524 08:21:33.109452 11654 solver.cpp:239] Iteration 50680 (1.56682 iter/s, 6.38234s/10 iters), loss = 6.77203
I0524 08:21:33.109516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77203 (* 1 = 6.77203 loss)
I0524 08:21:33.109789 11654 sgd_solver.cpp:112] Iteration 50680, lr = 0.1
I0524 08:21:41.267236 11654 solver.cpp:239] Iteration 50690 (1.22588 iter/s, 8.15741s/10 iters), loss = 7.30289
I0524 08:21:41.267298 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30289 (* 1 = 7.30289 loss)
I0524 08:21:41.267318 11654 sgd_solver.cpp:112] Iteration 50690, lr = 0.1
I0524 08:21:49.326472 11654 solver.cpp:239] Iteration 50700 (1.24088 iter/s, 8.05882s/10 iters), loss = 6.34639
I0524 08:21:49.326514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34639 (* 1 = 6.34639 loss)
I0524 08:21:49.326529 11654 sgd_solver.cpp:112] Iteration 50700, lr = 0.1
I0524 08:21:56.580830 11654 solver.cpp:239] Iteration 50710 (1.37854 iter/s, 7.25403s/10 iters), loss = 5.71129
I0524 08:21:56.580893 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71129 (* 1 = 5.71129 loss)
I0524 08:21:56.581475 11654 sgd_solver.cpp:112] Iteration 50710, lr = 0.1
I0524 08:22:04.823429 11654 solver.cpp:239] Iteration 50720 (1.21327 iter/s, 8.2422s/10 iters), loss = 5.04092
I0524 08:22:04.823720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.04092 (* 1 = 5.04092 loss)
I0524 08:22:05.314775 11654 sgd_solver.cpp:112] Iteration 50720, lr = 0.1
I0524 08:22:11.614326 11654 solver.cpp:239] Iteration 50730 (1.47267 iter/s, 6.79038s/10 iters), loss = 7.07891
I0524 08:22:11.614372 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.07891 (* 1 = 7.07891 loss)
I0524 08:22:11.614722 11654 sgd_solver.cpp:112] Iteration 50730, lr = 0.1
I0524 08:22:17.955502 11654 solver.cpp:239] Iteration 50740 (1.57708 iter/s, 6.34083s/10 iters), loss = 6.11545
I0524 08:22:17.955611 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11545 (* 1 = 6.11545 loss)
I0524 08:22:17.985136 11654 sgd_solver.cpp:112] Iteration 50740, lr = 0.1
I0524 08:22:26.282593 11654 solver.cpp:239] Iteration 50750 (1.20096 iter/s, 8.32668s/10 iters), loss = 6.43883
I0524 08:22:26.282691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43883 (* 1 = 6.43883 loss)
I0524 08:22:27.104624 11654 sgd_solver.cpp:112] Iteration 50750, lr = 0.1
I0524 08:22:36.101965 11654 solver.cpp:239] Iteration 50760 (1.01844 iter/s, 9.81893s/10 iters), loss = 6.81729
I0524 08:22:36.102118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81729 (* 1 = 6.81729 loss)
I0524 08:22:36.116261 11654 sgd_solver.cpp:112] Iteration 50760, lr = 0.1
I0524 08:22:43.538529 11654 solver.cpp:239] Iteration 50770 (1.34479 iter/s, 7.4361s/10 iters), loss = 5.41383
I0524 08:22:43.538600 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.41383 (* 1 = 5.41383 loss)
I0524 08:22:43.538717 11654 sgd_solver.cpp:112] Iteration 50770, lr = 0.1
I0524 08:22:51.240516 11654 solver.cpp:239] Iteration 50780 (1.29843 iter/s, 7.70161s/10 iters), loss = 5.53672
I0524 08:22:51.240645 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53672 (* 1 = 5.53672 loss)
I0524 08:22:51.240731 11654 sgd_solver.cpp:112] Iteration 50780, lr = 0.1
I0524 08:23:01.435129 11654 solver.cpp:239] Iteration 50790 (0.980957 iter/s, 10.1941s/10 iters), loss = 6.31341
I0524 08:23:01.435210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31341 (* 1 = 6.31341 loss)
I0524 08:23:01.435237 11654 sgd_solver.cpp:112] Iteration 50790, lr = 0.1
I0524 08:23:10.723757 11654 solver.cpp:239] Iteration 50800 (1.07664 iter/s, 9.28817s/10 iters), loss = 5.92873
I0524 08:23:10.724004 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92873 (* 1 = 5.92873 loss)
I0524 08:23:10.724046 11654 sgd_solver.cpp:112] Iteration 50800, lr = 0.1
I0524 08:23:17.712194 11654 solver.cpp:239] Iteration 50810 (1.43104 iter/s, 6.98791s/10 iters), loss = 5.54838
I0524 08:23:17.712234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54838 (* 1 = 5.54838 loss)
I0524 08:23:17.712497 11654 sgd_solver.cpp:112] Iteration 50810, lr = 0.1
I0524 08:23:26.330198 11654 solver.cpp:239] Iteration 50820 (1.16041 iter/s, 8.61761s/10 iters), loss = 5.50804
I0524 08:23:26.330256 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50804 (* 1 = 5.50804 loss)
I0524 08:23:26.533354 11654 sgd_solver.cpp:112] Iteration 50820, lr = 0.1
I0524 08:23:35.523949 11654 solver.cpp:239] Iteration 50830 (1.08774 iter/s, 9.19335s/10 iters), loss = 6.35772
I0524 08:23:35.524015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35772 (* 1 = 6.35772 loss)
I0524 08:23:36.080525 11654 sgd_solver.cpp:112] Iteration 50830, lr = 0.1
I0524 08:23:42.946784 11654 solver.cpp:239] Iteration 50840 (1.34726 iter/s, 7.42249s/10 iters), loss = 6.29444
I0524 08:23:42.946980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29444 (* 1 = 6.29444 loss)
I0524 08:23:42.947007 11654 sgd_solver.cpp:112] Iteration 50840, lr = 0.1
I0524 08:23:49.408304 11654 solver.cpp:239] Iteration 50850 (1.54827 iter/s, 6.45883s/10 iters), loss = 6.64635
I0524 08:23:49.408368 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64635 (* 1 = 6.64635 loss)
I0524 08:23:49.408715 11654 sgd_solver.cpp:112] Iteration 50850, lr = 0.1
I0524 08:23:56.419713 11654 solver.cpp:239] Iteration 50860 (1.42632 iter/s, 7.01106s/10 iters), loss = 6.05912
I0524 08:23:56.419783 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05912 (* 1 = 6.05912 loss)
I0524 08:23:57.505281 11654 sgd_solver.cpp:112] Iteration 50860, lr = 0.1
I0524 08:24:05.416714 11654 solver.cpp:239] Iteration 50870 (1.11154 iter/s, 8.99655s/10 iters), loss = 5.84219
I0524 08:24:05.416887 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84219 (* 1 = 5.84219 loss)
I0524 08:24:05.416935 11654 sgd_solver.cpp:112] Iteration 50870, lr = 0.1
I0524 08:24:12.017817 11654 solver.cpp:239] Iteration 50880 (1.515 iter/s, 6.60065s/10 iters), loss = 6.03734
I0524 08:24:12.017879 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03734 (* 1 = 6.03734 loss)
I0524 08:24:12.018110 11654 sgd_solver.cpp:112] Iteration 50880, lr = 0.1
I0524 08:24:19.180009 11654 solver.cpp:239] Iteration 50890 (1.39629 iter/s, 7.16183s/10 iters), loss = 7.05604
I0524 08:24:19.180269 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.05604 (* 1 = 7.05604 loss)
I0524 08:24:19.246747 11654 sgd_solver.cpp:112] Iteration 50890, lr = 0.1
I0524 08:24:27.969384 11654 solver.cpp:239] Iteration 50900 (1.13781 iter/s, 8.78878s/10 iters), loss = 5.84571
I0524 08:24:27.969493 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84571 (* 1 = 5.84571 loss)
I0524 08:24:27.969521 11654 sgd_solver.cpp:112] Iteration 50900, lr = 0.1
I0524 08:24:36.547760 11654 solver.cpp:239] Iteration 50910 (1.16587 iter/s, 8.5773s/10 iters), loss = 6.09136
I0524 08:24:36.547832 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09136 (* 1 = 6.09136 loss)
I0524 08:24:36.548092 11654 sgd_solver.cpp:112] Iteration 50910, lr = 0.1
I0524 08:24:43.218433 11654 solver.cpp:239] Iteration 50920 (1.49917 iter/s, 6.67034s/10 iters), loss = 5.37206
I0524 08:24:43.218472 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.37206 (* 1 = 5.37206 loss)
I0524 08:24:43.970423 11654 sgd_solver.cpp:112] Iteration 50920, lr = 0.1
I0524 08:24:51.006572 11654 solver.cpp:239] Iteration 50930 (1.28406 iter/s, 7.78778s/10 iters), loss = 6.30233
I0524 08:24:51.006855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30233 (* 1 = 6.30233 loss)
I0524 08:24:51.006902 11654 sgd_solver.cpp:112] Iteration 50930, lr = 0.1
I0524 08:24:57.919541 11654 solver.cpp:239] Iteration 50940 (1.44667 iter/s, 6.91242s/10 iters), loss = 6.80977
I0524 08:24:57.919605 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80977 (* 1 = 6.80977 loss)
I0524 08:24:57.919682 11654 sgd_solver.cpp:112] Iteration 50940, lr = 0.1
I0524 08:25:04.969493 11654 solver.cpp:239] Iteration 50950 (1.41852 iter/s, 7.04961s/10 iters), loss = 5.78573
I0524 08:25:04.969573 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78573 (* 1 = 5.78573 loss)
I0524 08:25:04.969594 11654 sgd_solver.cpp:112] Iteration 50950, lr = 0.1
I0524 08:25:12.607092 11654 solver.cpp:239] Iteration 50960 (1.30974 iter/s, 7.63508s/10 iters), loss = 5.83917
I0524 08:25:12.607141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83917 (* 1 = 5.83917 loss)
I0524 08:25:12.607311 11654 sgd_solver.cpp:112] Iteration 50960, lr = 0.1
I0524 08:25:20.372676 11654 solver.cpp:239] Iteration 50970 (1.28779 iter/s, 7.76522s/10 iters), loss = 5.64938
I0524 08:25:20.372745 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64938 (* 1 = 5.64938 loss)
I0524 08:25:20.372772 11654 sgd_solver.cpp:112] Iteration 50970, lr = 0.1
I0524 08:25:28.802726 11654 solver.cpp:239] Iteration 50980 (1.18629 iter/s, 8.42964s/10 iters), loss = 6.27033
I0524 08:25:28.802875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27033 (* 1 = 6.27033 loss)
I0524 08:25:28.802893 11654 sgd_solver.cpp:112] Iteration 50980, lr = 0.1
I0524 08:25:37.363263 11654 solver.cpp:239] Iteration 50990 (1.16822 iter/s, 8.56003s/10 iters), loss = 6.60073
I0524 08:25:37.363320 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60073 (* 1 = 6.60073 loss)
I0524 08:25:37.363349 11654 sgd_solver.cpp:112] Iteration 50990, lr = 0.1
I0524 08:25:44.356776 11654 solver.cpp:239] Iteration 51000 (1.42996 iter/s, 6.99319s/10 iters), loss = 5.44672
I0524 08:25:44.356837 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44672 (* 1 = 5.44672 loss)
I0524 08:25:44.356853 11654 sgd_solver.cpp:112] Iteration 51000, lr = 0.1
I0524 08:25:51.400768 11654 solver.cpp:239] Iteration 51010 (1.41973 iter/s, 7.0436s/10 iters), loss = 6.45507
I0524 08:25:51.400818 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45507 (* 1 = 6.45507 loss)
I0524 08:25:51.400838 11654 sgd_solver.cpp:112] Iteration 51010, lr = 0.1
I0524 08:25:59.567670 11654 solver.cpp:239] Iteration 51020 (1.22452 iter/s, 8.16645s/10 iters), loss = 5.90655
I0524 08:25:59.567971 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90655 (* 1 = 5.90655 loss)
I0524 08:25:59.568030 11654 sgd_solver.cpp:112] Iteration 51020, lr = 0.1
I0524 08:26:05.970948 11654 solver.cpp:239] Iteration 51030 (1.56235 iter/s, 6.40061s/10 iters), loss = 6.19421
I0524 08:26:05.971009 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.19421 (* 1 = 6.19421 loss)
I0524 08:26:05.971117 11654 sgd_solver.cpp:112] Iteration 51030, lr = 0.1
I0524 08:26:14.680876 11654 solver.cpp:239] Iteration 51040 (1.14817 iter/s, 8.70954s/10 iters), loss = 6.60839
I0524 08:26:14.680939 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60839 (* 1 = 6.60839 loss)
I0524 08:26:14.680956 11654 sgd_solver.cpp:112] Iteration 51040, lr = 0.1
I0524 08:26:23.126811 11654 solver.cpp:239] Iteration 51050 (1.18405 iter/s, 8.44555s/10 iters), loss = 5.55767
I0524 08:26:23.126866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55767 (* 1 = 5.55767 loss)
I0524 08:26:23.139267 11654 sgd_solver.cpp:112] Iteration 51050, lr = 0.1
I0524 08:26:31.470857 11654 solver.cpp:239] Iteration 51060 (1.19851 iter/s, 8.34367s/10 iters), loss = 6.71349
I0524 08:26:31.471122 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71349 (* 1 = 6.71349 loss)
I0524 08:26:31.471173 11654 sgd_solver.cpp:112] Iteration 51060, lr = 0.1
I0524 08:26:38.897337 11654 solver.cpp:239] Iteration 51070 (1.34663 iter/s, 7.42594s/10 iters), loss = 5.45978
I0524 08:26:38.897511 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.45978 (* 1 = 5.45978 loss)
I0524 08:26:38.897559 11654 sgd_solver.cpp:112] Iteration 51070, lr = 0.1
I0524 08:26:46.555773 11654 solver.cpp:239] Iteration 51080 (1.30618 iter/s, 7.65591s/10 iters), loss = 7.36504
I0524 08:26:46.555840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36504 (* 1 = 7.36504 loss)
I0524 08:26:46.556033 11654 sgd_solver.cpp:112] Iteration 51080, lr = 0.1
I0524 08:26:54.628212 11654 solver.cpp:239] Iteration 51090 (1.23884 iter/s, 8.07207s/10 iters), loss = 6.78427
I0524 08:26:54.628257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78427 (* 1 = 6.78427 loss)
I0524 08:26:54.630453 11654 sgd_solver.cpp:112] Iteration 51090, lr = 0.1
I0524 08:27:02.667001 11654 solver.cpp:239] Iteration 51100 (1.24402 iter/s, 8.03843s/10 iters), loss = 5.81828
I0524 08:27:02.667219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81828 (* 1 = 5.81828 loss)
I0524 08:27:02.667244 11654 sgd_solver.cpp:112] Iteration 51100, lr = 0.1
I0524 08:27:09.670974 11654 solver.cpp:239] Iteration 51110 (1.42785 iter/s, 7.00352s/10 iters), loss = 6.32325
I0524 08:27:09.671020 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32325 (* 1 = 6.32325 loss)
I0524 08:27:09.671034 11654 sgd_solver.cpp:112] Iteration 51110, lr = 0.1
I0524 08:27:17.739643 11654 solver.cpp:239] Iteration 51120 (1.23975 iter/s, 8.06615s/10 iters), loss = 5.32492
I0524 08:27:17.739699 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.32492 (* 1 = 5.32492 loss)
I0524 08:27:18.955896 11654 sgd_solver.cpp:112] Iteration 51120, lr = 0.1
I0524 08:27:28.019361 11654 solver.cpp:239] Iteration 51130 (0.972833 iter/s, 10.2793s/10 iters), loss = 5.50212
I0524 08:27:28.019446 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50212 (* 1 = 5.50212 loss)
I0524 08:27:28.541087 11654 sgd_solver.cpp:112] Iteration 51130, lr = 0.1
I0524 08:27:36.027082 11654 solver.cpp:239] Iteration 51140 (1.24886 iter/s, 8.00733s/10 iters), loss = 5.80401
I0524 08:27:36.027304 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80401 (* 1 = 5.80401 loss)
I0524 08:27:36.027549 11654 sgd_solver.cpp:112] Iteration 51140, lr = 0.1
I0524 08:27:42.663484 11654 solver.cpp:239] Iteration 51150 (1.50694 iter/s, 6.63596s/10 iters), loss = 5.81276
I0524 08:27:42.663561 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81276 (* 1 = 5.81276 loss)
I0524 08:27:42.832027 11654 sgd_solver.cpp:112] Iteration 51150, lr = 0.1
I0524 08:27:49.344692 11654 solver.cpp:239] Iteration 51160 (1.49681 iter/s, 6.68087s/10 iters), loss = 6.06999
I0524 08:27:49.344753 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06999 (* 1 = 6.06999 loss)
I0524 08:27:49.344832 11654 sgd_solver.cpp:112] Iteration 51160, lr = 0.1
I0524 08:27:55.749933 11654 solver.cpp:239] Iteration 51170 (1.5613 iter/s, 6.40492s/10 iters), loss = 6.22249
I0524 08:27:55.749999 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22249 (* 1 = 6.22249 loss)
I0524 08:27:55.750025 11654 sgd_solver.cpp:112] Iteration 51170, lr = 0.1
I0524 08:28:03.779999 11654 solver.cpp:239] Iteration 51180 (1.24538 iter/s, 8.02968s/10 iters), loss = 5.81424
I0524 08:28:03.780055 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81424 (* 1 = 5.81424 loss)
I0524 08:28:03.780948 11654 sgd_solver.cpp:112] Iteration 51180, lr = 0.1
I0524 08:28:13.227478 11654 solver.cpp:239] Iteration 51190 (1.05853 iter/s, 9.44705s/10 iters), loss = 6.1197
I0524 08:28:13.227670 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1197 (* 1 = 6.1197 loss)
I0524 08:28:13.228798 11654 sgd_solver.cpp:112] Iteration 51190, lr = 0.1
I0524 08:28:22.400964 11654 solver.cpp:239] Iteration 51200 (1.09016 iter/s, 9.17297s/10 iters), loss = 5.87613
I0524 08:28:22.401043 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87613 (* 1 = 5.87613 loss)
I0524 08:28:22.401063 11654 sgd_solver.cpp:112] Iteration 51200, lr = 0.1
I0524 08:28:29.568511 11654 solver.cpp:239] Iteration 51210 (1.39526 iter/s, 7.16712s/10 iters), loss = 5.5664
I0524 08:28:29.568576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.5664 (* 1 = 5.5664 loss)
I0524 08:28:29.568598 11654 sgd_solver.cpp:112] Iteration 51210, lr = 0.1
I0524 08:28:37.341508 11654 solver.cpp:239] Iteration 51220 (1.28661 iter/s, 7.77234s/10 iters), loss = 6.14315
I0524 08:28:37.341588 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14315 (* 1 = 6.14315 loss)
I0524 08:28:37.342118 11654 sgd_solver.cpp:112] Iteration 51220, lr = 0.1
I0524 08:28:44.255226 11654 solver.cpp:239] Iteration 51230 (1.44647 iter/s, 6.91339s/10 iters), loss = 5.6886
I0524 08:28:44.255463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6886 (* 1 = 5.6886 loss)
I0524 08:28:44.263986 11654 sgd_solver.cpp:112] Iteration 51230, lr = 0.1
I0524 08:28:52.091908 11654 solver.cpp:239] Iteration 51240 (1.27613 iter/s, 7.83618s/10 iters), loss = 7.00918
I0524 08:28:52.091979 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00918 (* 1 = 7.00918 loss)
I0524 08:28:52.657763 11654 sgd_solver.cpp:112] Iteration 51240, lr = 0.1
I0524 08:29:00.959853 11654 solver.cpp:239] Iteration 51250 (1.12771 iter/s, 8.86755s/10 iters), loss = 6.48013
I0524 08:29:00.959921 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48013 (* 1 = 6.48013 loss)
I0524 08:29:00.960021 11654 sgd_solver.cpp:112] Iteration 51250, lr = 0.1
I0524 08:29:07.444684 11654 solver.cpp:239] Iteration 51260 (1.54214 iter/s, 6.48452s/10 iters), loss = 6.34339
I0524 08:29:07.444743 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34339 (* 1 = 6.34339 loss)
I0524 08:29:08.021589 11654 sgd_solver.cpp:112] Iteration 51260, lr = 0.1
I0524 08:29:14.572468 11654 solver.cpp:239] Iteration 51270 (1.40303 iter/s, 7.12744s/10 iters), loss = 6.5999
I0524 08:29:14.572703 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5999 (* 1 = 6.5999 loss)
I0524 08:29:14.572731 11654 sgd_solver.cpp:112] Iteration 51270, lr = 0.1
I0524 08:29:21.929319 11654 solver.cpp:239] Iteration 51280 (1.35947 iter/s, 7.35583s/10 iters), loss = 6.14824
I0524 08:29:21.929373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14824 (* 1 = 6.14824 loss)
I0524 08:29:22.417825 11654 sgd_solver.cpp:112] Iteration 51280, lr = 0.1
I0524 08:29:29.361982 11654 solver.cpp:239] Iteration 51290 (1.34548 iter/s, 7.43231s/10 iters), loss = 7.27731
I0524 08:29:29.362059 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.27731 (* 1 = 7.27731 loss)
I0524 08:29:29.362082 11654 sgd_solver.cpp:112] Iteration 51290, lr = 0.1
I0524 08:29:36.126201 11654 solver.cpp:239] Iteration 51300 (1.47892 iter/s, 6.7617s/10 iters), loss = 5.73869
I0524 08:29:36.126251 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73869 (* 1 = 5.73869 loss)
I0524 08:29:36.126626 11654 sgd_solver.cpp:112] Iteration 51300, lr = 0.1
I0524 08:29:45.981506 11654 solver.cpp:239] Iteration 51310 (1.01473 iter/s, 9.85483s/10 iters), loss = 5.18198
I0524 08:29:45.981756 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.18198 (* 1 = 5.18198 loss)
I0524 08:29:45.981783 11654 sgd_solver.cpp:112] Iteration 51310, lr = 0.1
I0524 08:29:53.047796 11654 solver.cpp:239] Iteration 51320 (1.41529 iter/s, 7.06569s/10 iters), loss = 6.72646
I0524 08:29:53.047869 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72646 (* 1 = 6.72646 loss)
I0524 08:29:53.047922 11654 sgd_solver.cpp:112] Iteration 51320, lr = 0.1
I0524 08:30:00.941100 11654 solver.cpp:239] Iteration 51330 (1.26695 iter/s, 7.89294s/10 iters), loss = 5.08693
I0524 08:30:00.941165 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.08693 (* 1 = 5.08693 loss)
I0524 08:30:00.941184 11654 sgd_solver.cpp:112] Iteration 51330, lr = 0.1
I0524 08:30:08.390858 11654 solver.cpp:239] Iteration 51340 (1.3424 iter/s, 7.44935s/10 iters), loss = 6.39597
I0524 08:30:08.390925 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39597 (* 1 = 6.39597 loss)
I0524 08:30:08.391012 11654 sgd_solver.cpp:112] Iteration 51340, lr = 0.1
I0524 08:30:14.465137 11654 solver.cpp:239] Iteration 51350 (1.64638 iter/s, 6.07395s/10 iters), loss = 6.67711
I0524 08:30:14.465206 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67711 (* 1 = 6.67711 loss)
I0524 08:30:14.465391 11654 sgd_solver.cpp:112] Iteration 51350, lr = 0.1
I0524 08:30:21.788157 11654 solver.cpp:239] Iteration 51360 (1.36563 iter/s, 7.32264s/10 iters), loss = 6.3413
I0524 08:30:21.788370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3413 (* 1 = 6.3413 loss)
I0524 08:30:21.826659 11654 sgd_solver.cpp:112] Iteration 51360, lr = 0.1
I0524 08:30:28.534471 11654 solver.cpp:239] Iteration 51370 (1.48239 iter/s, 6.74585s/10 iters), loss = 6.39177
I0524 08:30:28.534548 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39177 (* 1 = 6.39177 loss)
I0524 08:30:28.534566 11654 sgd_solver.cpp:112] Iteration 51370, lr = 0.1
I0524 08:30:36.148530 11654 solver.cpp:239] Iteration 51380 (1.31343 iter/s, 7.61365s/10 iters), loss = 6.54642
I0524 08:30:36.148589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54642 (* 1 = 6.54642 loss)
I0524 08:30:36.148607 11654 sgd_solver.cpp:112] Iteration 51380, lr = 0.1
I0524 08:30:45.388615 11654 solver.cpp:239] Iteration 51390 (1.0823 iter/s, 9.2396s/10 iters), loss = 6.32676
I0524 08:30:45.388829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32676 (* 1 = 6.32676 loss)
I0524 08:30:45.389037 11654 sgd_solver.cpp:112] Iteration 51390, lr = 0.1
I0524 08:30:54.684706 11654 solver.cpp:239] Iteration 51400 (1.07577 iter/s, 9.29564s/10 iters), loss = 6.30688
I0524 08:30:54.684974 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30688 (* 1 = 6.30688 loss)
I0524 08:30:54.685030 11654 sgd_solver.cpp:112] Iteration 51400, lr = 0.1
I0524 08:31:01.170320 11654 solver.cpp:239] Iteration 51410 (1.54199 iter/s, 6.48512s/10 iters), loss = 6.15743
I0524 08:31:01.170399 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15743 (* 1 = 6.15743 loss)
I0524 08:31:01.170419 11654 sgd_solver.cpp:112] Iteration 51410, lr = 0.1
I0524 08:31:07.570114 11654 solver.cpp:239] Iteration 51420 (1.56316 iter/s, 6.39728s/10 iters), loss = 6.73701
I0524 08:31:07.570168 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73701 (* 1 = 6.73701 loss)
I0524 08:31:07.570191 11654 sgd_solver.cpp:112] Iteration 51420, lr = 0.1
I0524 08:31:15.062202 11654 solver.cpp:239] Iteration 51430 (1.33482 iter/s, 7.49167s/10 iters), loss = 6.04482
I0524 08:31:15.062280 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04482 (* 1 = 6.04482 loss)
I0524 08:31:15.062412 11654 sgd_solver.cpp:112] Iteration 51430, lr = 0.1
I0524 08:31:22.280977 11654 solver.cpp:239] Iteration 51440 (1.38535 iter/s, 7.2184s/10 iters), loss = 7.0124
I0524 08:31:22.281131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0124 (* 1 = 7.0124 loss)
I0524 08:31:22.281165 11654 sgd_solver.cpp:112] Iteration 51440, lr = 0.1
I0524 08:31:31.051266 11654 solver.cpp:239] Iteration 51450 (1.14027 iter/s, 8.76986s/10 iters), loss = 5.86046
I0524 08:31:31.051421 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86046 (* 1 = 5.86046 loss)
I0524 08:31:31.051476 11654 sgd_solver.cpp:112] Iteration 51450, lr = 0.1
I0524 08:31:37.270162 11654 solver.cpp:239] Iteration 51460 (1.60811 iter/s, 6.21849s/10 iters), loss = 6.36433
I0524 08:31:37.270223 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36433 (* 1 = 6.36433 loss)
I0524 08:31:37.270303 11654 sgd_solver.cpp:112] Iteration 51460, lr = 0.1
I0524 08:31:44.552112 11654 solver.cpp:239] Iteration 51470 (1.37333 iter/s, 7.28159s/10 iters), loss = 5.54524
I0524 08:31:44.552171 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54524 (* 1 = 5.54524 loss)
I0524 08:31:44.552187 11654 sgd_solver.cpp:112] Iteration 51470, lr = 0.1
I0524 08:31:51.940711 11654 solver.cpp:239] Iteration 51480 (1.3535 iter/s, 7.38826s/10 iters), loss = 6.73948
I0524 08:31:51.940788 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73948 (* 1 = 6.73948 loss)
I0524 08:31:51.940809 11654 sgd_solver.cpp:112] Iteration 51480, lr = 0.1
I0524 08:31:59.327924 11654 solver.cpp:239] Iteration 51490 (1.35376 iter/s, 7.38686s/10 iters), loss = 6.31443
I0524 08:31:59.328001 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31443 (* 1 = 6.31443 loss)
I0524 08:31:59.328425 11654 sgd_solver.cpp:112] Iteration 51490, lr = 0.1
I0524 08:32:06.501960 11654 solver.cpp:239] Iteration 51500 (1.39398 iter/s, 7.17369s/10 iters), loss = 5.78751
I0524 08:32:06.502136 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78751 (* 1 = 5.78751 loss)
I0524 08:32:06.502158 11654 sgd_solver.cpp:112] Iteration 51500, lr = 0.1
I0524 08:32:13.563833 11654 solver.cpp:239] Iteration 51510 (1.41658 iter/s, 7.05927s/10 iters), loss = 6.33447
I0524 08:32:13.563902 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33447 (* 1 = 6.33447 loss)
I0524 08:32:13.564009 11654 sgd_solver.cpp:112] Iteration 51510, lr = 0.1
I0524 08:32:22.488286 11654 solver.cpp:239] Iteration 51520 (1.12057 iter/s, 8.92405s/10 iters), loss = 6.23625
I0524 08:32:22.488343 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23625 (* 1 = 6.23625 loss)
I0524 08:32:22.488361 11654 sgd_solver.cpp:112] Iteration 51520, lr = 0.1
I0524 08:32:29.327680 11654 solver.cpp:239] Iteration 51530 (1.4622 iter/s, 6.83899s/10 iters), loss = 5.69572
I0524 08:32:29.327751 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69572 (* 1 = 5.69572 loss)
I0524 08:32:29.383323 11654 sgd_solver.cpp:112] Iteration 51530, lr = 0.1
I0524 08:32:36.228574 11654 solver.cpp:239] Iteration 51540 (1.44916 iter/s, 6.90056s/10 iters), loss = 6.6268
I0524 08:32:36.228636 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6268 (* 1 = 6.6268 loss)
I0524 08:32:36.516399 11654 sgd_solver.cpp:112] Iteration 51540, lr = 0.1
I0524 08:32:43.484709 11654 solver.cpp:239] Iteration 51550 (1.37821 iter/s, 7.25578s/10 iters), loss = 5.39972
I0524 08:32:43.484779 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.39972 (* 1 = 5.39972 loss)
I0524 08:32:43.486459 11654 sgd_solver.cpp:112] Iteration 51550, lr = 0.1
I0524 08:32:51.796080 11654 solver.cpp:239] Iteration 51560 (1.20323 iter/s, 8.31098s/10 iters), loss = 6.59042
I0524 08:32:51.796138 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59042 (* 1 = 6.59042 loss)
I0524 08:32:51.796689 11654 sgd_solver.cpp:112] Iteration 51560, lr = 0.1
I0524 08:32:58.800626 11654 solver.cpp:239] Iteration 51570 (1.42771 iter/s, 7.00422s/10 iters), loss = 6.90371
I0524 08:32:58.800683 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90371 (* 1 = 6.90371 loss)
I0524 08:32:58.800740 11654 sgd_solver.cpp:112] Iteration 51570, lr = 0.1
I0524 08:33:06.771339 11654 solver.cpp:239] Iteration 51580 (1.25465 iter/s, 7.97035s/10 iters), loss = 5.61381
I0524 08:33:06.771574 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61381 (* 1 = 5.61381 loss)
I0524 08:33:06.771622 11654 sgd_solver.cpp:112] Iteration 51580, lr = 0.1
I0524 08:33:13.201117 11654 solver.cpp:239] Iteration 51590 (1.55587 iter/s, 6.42726s/10 iters), loss = 6.28666
I0524 08:33:13.201179 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28666 (* 1 = 6.28666 loss)
I0524 08:33:13.542481 11654 sgd_solver.cpp:112] Iteration 51590, lr = 0.1
I0524 08:33:23.774085 11654 solver.cpp:239] Iteration 51600 (0.945852 iter/s, 10.5725s/10 iters), loss = 6.87292
I0524 08:33:23.774129 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87292 (* 1 = 6.87292 loss)
I0524 08:33:24.278671 11654 sgd_solver.cpp:112] Iteration 51600, lr = 0.1
I0524 08:33:32.876791 11654 solver.cpp:239] Iteration 51610 (1.09863 iter/s, 9.10228s/10 iters), loss = 6.885
I0524 08:33:32.876868 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.885 (* 1 = 6.885 loss)
I0524 08:33:32.876888 11654 sgd_solver.cpp:112] Iteration 51610, lr = 0.1
I0524 08:33:39.621429 11654 solver.cpp:239] Iteration 51620 (1.48274 iter/s, 6.74427s/10 iters), loss = 7.28544
I0524 08:33:39.621759 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28544 (* 1 = 7.28544 loss)
I0524 08:33:39.621825 11654 sgd_solver.cpp:112] Iteration 51620, lr = 0.1
I0524 08:33:47.731030 11654 solver.cpp:239] Iteration 51630 (1.23319 iter/s, 8.10905s/10 iters), loss = 6.47903
I0524 08:33:47.731082 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47903 (* 1 = 6.47903 loss)
I0524 08:33:48.206075 11654 sgd_solver.cpp:112] Iteration 51630, lr = 0.1
I0524 08:33:56.458935 11654 solver.cpp:239] Iteration 51640 (1.1458 iter/s, 8.72751s/10 iters), loss = 5.3763
I0524 08:33:56.459024 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3763 (* 1 = 5.3763 loss)
I0524 08:33:56.926729 11654 sgd_solver.cpp:112] Iteration 51640, lr = 0.1
I0524 08:34:04.463796 11654 solver.cpp:239] Iteration 51650 (1.2493 iter/s, 8.00448s/10 iters), loss = 6.06256
I0524 08:34:04.463873 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06256 (* 1 = 6.06256 loss)
I0524 08:34:04.463904 11654 sgd_solver.cpp:112] Iteration 51650, lr = 0.1
I0524 08:34:12.158360 11654 solver.cpp:239] Iteration 51660 (1.29969 iter/s, 7.69415s/10 iters), loss = 6.21616
I0524 08:34:12.158597 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21616 (* 1 = 6.21616 loss)
I0524 08:34:12.158675 11654 sgd_solver.cpp:112] Iteration 51660, lr = 0.1
I0524 08:34:22.163599 11654 solver.cpp:239] Iteration 51670 (0.999538 iter/s, 10.0046s/10 iters), loss = 6.14326
I0524 08:34:22.163748 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14326 (* 1 = 6.14326 loss)
I0524 08:34:22.163786 11654 sgd_solver.cpp:112] Iteration 51670, lr = 0.1
I0524 08:34:28.542284 11654 solver.cpp:239] Iteration 51680 (1.56781 iter/s, 6.37833s/10 iters), loss = 7.68629
I0524 08:34:28.542336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.68629 (* 1 = 7.68629 loss)
I0524 08:34:28.542553 11654 sgd_solver.cpp:112] Iteration 51680, lr = 0.1
I0524 08:34:38.193967 11654 solver.cpp:239] Iteration 51690 (1.03613 iter/s, 9.65125s/10 iters), loss = 5.53775
I0524 08:34:38.194039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53775 (* 1 = 5.53775 loss)
I0524 08:34:38.943815 11654 sgd_solver.cpp:112] Iteration 51690, lr = 0.1
I0524 08:34:47.541553 11654 solver.cpp:239] Iteration 51700 (1.06985 iter/s, 9.34714s/10 iters), loss = 5.82999
I0524 08:34:47.541918 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82999 (* 1 = 5.82999 loss)
I0524 08:34:47.919984 11654 sgd_solver.cpp:112] Iteration 51700, lr = 0.1
I0524 08:34:54.797577 11654 solver.cpp:239] Iteration 51710 (1.37828 iter/s, 7.2554s/10 iters), loss = 5.99728
I0524 08:34:54.797684 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99728 (* 1 = 5.99728 loss)
I0524 08:34:54.797853 11654 sgd_solver.cpp:112] Iteration 51710, lr = 0.1
I0524 08:35:02.350069 11654 solver.cpp:239] Iteration 51720 (1.32413 iter/s, 7.55212s/10 iters), loss = 5.61469
I0524 08:35:02.350128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61469 (* 1 = 5.61469 loss)
I0524 08:35:02.350147 11654 sgd_solver.cpp:112] Iteration 51720, lr = 0.1
I0524 08:35:08.830159 11654 solver.cpp:239] Iteration 51730 (1.54332 iter/s, 6.47953s/10 iters), loss = 5.44588
I0524 08:35:08.830235 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44588 (* 1 = 5.44588 loss)
I0524 08:35:08.830381 11654 sgd_solver.cpp:112] Iteration 51730, lr = 0.1
I0524 08:35:16.662322 11654 solver.cpp:239] Iteration 51740 (1.27685 iter/s, 7.83179s/10 iters), loss = 6.03485
I0524 08:35:16.662370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03485 (* 1 = 6.03485 loss)
I0524 08:35:17.083640 11654 sgd_solver.cpp:112] Iteration 51740, lr = 0.1
I0524 08:35:25.894773 11654 solver.cpp:239] Iteration 51750 (1.08318 iter/s, 9.23204s/10 iters), loss = 6.83457
I0524 08:35:25.895071 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83457 (* 1 = 6.83457 loss)
I0524 08:35:25.903426 11654 sgd_solver.cpp:112] Iteration 51750, lr = 0.1
I0524 08:35:33.762508 11654 solver.cpp:239] Iteration 51760 (1.27109 iter/s, 7.86724s/10 iters), loss = 6.46704
I0524 08:35:33.762560 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46704 (* 1 = 6.46704 loss)
I0524 08:35:33.762576 11654 sgd_solver.cpp:112] Iteration 51760, lr = 0.1
I0524 08:35:41.061503 11654 solver.cpp:239] Iteration 51770 (1.37013 iter/s, 7.29856s/10 iters), loss = 5.53266
I0524 08:35:41.061569 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53266 (* 1 = 5.53266 loss)
I0524 08:35:41.061586 11654 sgd_solver.cpp:112] Iteration 51770, lr = 0.1
I0524 08:35:48.951398 11654 solver.cpp:239] Iteration 51780 (1.26751 iter/s, 7.88949s/10 iters), loss = 7.03342
I0524 08:35:48.951447 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03342 (* 1 = 7.03342 loss)
I0524 08:35:49.242640 11654 sgd_solver.cpp:112] Iteration 51780, lr = 0.1
I0524 08:35:56.230829 11654 solver.cpp:239] Iteration 51790 (1.3738 iter/s, 7.2791s/10 iters), loss = 6.56376
I0524 08:35:56.231065 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56376 (* 1 = 6.56376 loss)
I0524 08:35:56.960649 11654 sgd_solver.cpp:112] Iteration 51790, lr = 0.1
I0524 08:36:04.910931 11654 solver.cpp:239] Iteration 51800 (1.15213 iter/s, 8.67954s/10 iters), loss = 6.57644
I0524 08:36:04.911015 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57644 (* 1 = 6.57644 loss)
I0524 08:36:04.911061 11654 sgd_solver.cpp:112] Iteration 51800, lr = 0.1
I0524 08:36:11.783838 11654 solver.cpp:239] Iteration 51810 (1.45552 iter/s, 6.8704s/10 iters), loss = 6.79136
I0524 08:36:11.783879 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79136 (* 1 = 6.79136 loss)
I0524 08:36:12.128618 11654 sgd_solver.cpp:112] Iteration 51810, lr = 0.1
I0524 08:36:19.602210 11654 solver.cpp:239] Iteration 51820 (1.2791 iter/s, 7.81802s/10 iters), loss = 6.08241
I0524 08:36:19.602322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08241 (* 1 = 6.08241 loss)
I0524 08:36:19.603301 11654 sgd_solver.cpp:112] Iteration 51820, lr = 0.1
I0524 08:36:27.892472 11654 solver.cpp:239] Iteration 51830 (1.20629 iter/s, 8.28985s/10 iters), loss = 6.8348
I0524 08:36:27.892726 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8348 (* 1 = 6.8348 loss)
I0524 08:36:27.892760 11654 sgd_solver.cpp:112] Iteration 51830, lr = 0.1
I0524 08:36:34.196422 11654 solver.cpp:239] Iteration 51840 (1.58644 iter/s, 6.30343s/10 iters), loss = 6.80091
I0524 08:36:34.196486 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80091 (* 1 = 6.80091 loss)
I0524 08:36:34.196821 11654 sgd_solver.cpp:112] Iteration 51840, lr = 0.1
I0524 08:36:41.454197 11654 solver.cpp:239] Iteration 51850 (1.37791 iter/s, 7.25736s/10 iters), loss = 6.80071
I0524 08:36:41.454285 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80071 (* 1 = 6.80071 loss)
I0524 08:36:41.454367 11654 sgd_solver.cpp:112] Iteration 51850, lr = 0.1
I0524 08:36:48.777876 11654 solver.cpp:239] Iteration 51860 (1.3655 iter/s, 7.3233s/10 iters), loss = 5.79393
I0524 08:36:48.777964 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79393 (* 1 = 5.79393 loss)
I0524 08:36:48.778164 11654 sgd_solver.cpp:112] Iteration 51860, lr = 0.1
I0524 08:36:55.724032 11654 solver.cpp:239] Iteration 51870 (1.43971 iter/s, 6.94582s/10 iters), loss = 4.759
I0524 08:36:55.724079 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.759 (* 1 = 4.759 loss)
I0524 08:36:55.724093 11654 sgd_solver.cpp:112] Iteration 51870, lr = 0.1
I0524 08:37:01.943387 11654 solver.cpp:239] Iteration 51880 (1.60796 iter/s, 6.21905s/10 iters), loss = 5.57592
I0524 08:37:01.943680 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57592 (* 1 = 5.57592 loss)
I0524 08:37:01.943846 11654 sgd_solver.cpp:112] Iteration 51880, lr = 0.1
I0524 08:37:08.782775 11654 solver.cpp:239] Iteration 51890 (1.46223 iter/s, 6.83887s/10 iters), loss = 6.17105
I0524 08:37:08.782843 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17105 (* 1 = 6.17105 loss)
I0524 08:37:08.783110 11654 sgd_solver.cpp:112] Iteration 51890, lr = 0.1
I0524 08:37:19.022791 11654 solver.cpp:239] Iteration 51900 (0.976604 iter/s, 10.2396s/10 iters), loss = 5.59775
I0524 08:37:19.022848 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59775 (* 1 = 5.59775 loss)
I0524 08:37:19.022873 11654 sgd_solver.cpp:112] Iteration 51900, lr = 0.1
I0524 08:37:25.897209 11654 solver.cpp:239] Iteration 51910 (1.45474 iter/s, 6.87409s/10 iters), loss = 6.12408
I0524 08:37:25.897291 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12408 (* 1 = 6.12408 loss)
I0524 08:37:25.897572 11654 sgd_solver.cpp:112] Iteration 51910, lr = 0.1
I0524 08:37:33.547832 11654 solver.cpp:239] Iteration 51920 (1.30715 iter/s, 7.65022s/10 iters), loss = 5.4216
I0524 08:37:33.548125 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4216 (* 1 = 5.4216 loss)
I0524 08:37:33.548164 11654 sgd_solver.cpp:112] Iteration 51920, lr = 0.1
I0524 08:37:40.966226 11654 solver.cpp:239] Iteration 51930 (1.34826 iter/s, 7.41696s/10 iters), loss = 5.70373
I0524 08:37:40.966274 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70373 (* 1 = 5.70373 loss)
I0524 08:37:40.966523 11654 sgd_solver.cpp:112] Iteration 51930, lr = 0.1
I0524 08:37:50.033448 11654 solver.cpp:239] Iteration 51940 (1.10292 iter/s, 9.06682s/10 iters), loss = 6.10555
I0524 08:37:50.033510 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10555 (* 1 = 6.10555 loss)
I0524 08:37:50.624958 11654 sgd_solver.cpp:112] Iteration 51940, lr = 0.1
I0524 08:37:59.839924 11654 solver.cpp:239] Iteration 51950 (1.01978 iter/s, 9.80603s/10 iters), loss = 5.30719
I0524 08:37:59.840003 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30719 (* 1 = 5.30719 loss)
I0524 08:37:59.840062 11654 sgd_solver.cpp:112] Iteration 51950, lr = 0.1
I0524 08:38:09.107197 11654 solver.cpp:239] Iteration 51960 (1.07912 iter/s, 9.26678s/10 iters), loss = 6.80442
I0524 08:38:09.108606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80442 (* 1 = 6.80442 loss)
I0524 08:38:09.108641 11654 sgd_solver.cpp:112] Iteration 51960, lr = 0.1
I0524 08:38:16.783869 11654 solver.cpp:239] Iteration 51970 (1.30294 iter/s, 7.67493s/10 iters), loss = 5.99328
I0524 08:38:16.783922 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99328 (* 1 = 5.99328 loss)
I0524 08:38:16.783995 11654 sgd_solver.cpp:112] Iteration 51970, lr = 0.1
I0524 08:38:23.291316 11654 solver.cpp:239] Iteration 51980 (1.53677 iter/s, 6.50714s/10 iters), loss = 6.34691
I0524 08:38:23.291369 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34691 (* 1 = 6.34691 loss)
I0524 08:38:23.291394 11654 sgd_solver.cpp:112] Iteration 51980, lr = 0.1
I0524 08:38:30.372498 11654 solver.cpp:239] Iteration 51990 (1.41226 iter/s, 7.08084s/10 iters), loss = 5.71833
I0524 08:38:30.372555 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71833 (* 1 = 5.71833 loss)
I0524 08:38:30.372571 11654 sgd_solver.cpp:112] Iteration 51990, lr = 0.1
I0524 08:38:37.456737 11654 solver.cpp:239] Iteration 52000 (1.41165 iter/s, 7.08391s/10 iters), loss = 5.50721
I0524 08:38:37.456776 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50721 (* 1 = 5.50721 loss)
I0524 08:38:37.456789 11654 sgd_solver.cpp:112] Iteration 52000, lr = 0.1
I0524 08:38:44.267899 11654 solver.cpp:239] Iteration 52010 (1.46825 iter/s, 6.81085s/10 iters), loss = 5.79752
I0524 08:38:44.268155 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79752 (* 1 = 5.79752 loss)
I0524 08:38:44.354534 11654 sgd_solver.cpp:112] Iteration 52010, lr = 0.1
I0524 08:38:51.519763 11654 solver.cpp:239] Iteration 52020 (1.37905 iter/s, 7.25137s/10 iters), loss = 7.2028
I0524 08:38:51.519875 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2028 (* 1 = 7.2028 loss)
I0524 08:38:51.519908 11654 sgd_solver.cpp:112] Iteration 52020, lr = 0.1
I0524 08:38:59.080145 11654 solver.cpp:239] Iteration 52030 (1.32313 iter/s, 7.55783s/10 iters), loss = 4.93317
I0524 08:38:59.080198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.93317 (* 1 = 4.93317 loss)
I0524 08:38:59.404629 11654 sgd_solver.cpp:112] Iteration 52030, lr = 0.1
I0524 08:39:06.221802 11654 solver.cpp:239] Iteration 52040 (1.4003 iter/s, 7.14133s/10 iters), loss = 6.75621
I0524 08:39:06.221839 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75621 (* 1 = 6.75621 loss)
I0524 08:39:07.038069 11654 sgd_solver.cpp:112] Iteration 52040, lr = 0.1
I0524 08:39:16.152495 11654 solver.cpp:239] Iteration 52050 (1.00702 iter/s, 9.93026s/10 iters), loss = 6.05263
I0524 08:39:16.152761 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05263 (* 1 = 6.05263 loss)
I0524 08:39:16.203424 11654 sgd_solver.cpp:112] Iteration 52050, lr = 0.1
I0524 08:39:24.191380 11654 solver.cpp:239] Iteration 52060 (1.24403 iter/s, 8.03837s/10 iters), loss = 5.3828
I0524 08:39:24.191419 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3828 (* 1 = 5.3828 loss)
I0524 08:39:24.308259 11654 sgd_solver.cpp:112] Iteration 52060, lr = 0.1
I0524 08:39:31.225025 11654 solver.cpp:239] Iteration 52070 (1.4218 iter/s, 7.03332s/10 iters), loss = 6.2494
I0524 08:39:31.225087 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2494 (* 1 = 6.2494 loss)
I0524 08:39:31.225106 11654 sgd_solver.cpp:112] Iteration 52070, lr = 0.1
I0524 08:39:38.366281 11654 solver.cpp:239] Iteration 52080 (1.40038 iter/s, 7.14092s/10 iters), loss = 6.46255
I0524 08:39:38.366343 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46255 (* 1 = 6.46255 loss)
I0524 08:39:38.382871 11654 sgd_solver.cpp:112] Iteration 52080, lr = 0.1
I0524 08:39:46.786716 11654 solver.cpp:239] Iteration 52090 (1.18764 iter/s, 8.42005s/10 iters), loss = 6.72297
I0524 08:39:46.786967 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72297 (* 1 = 6.72297 loss)
I0524 08:39:46.787003 11654 sgd_solver.cpp:112] Iteration 52090, lr = 0.1
I0524 08:39:55.281440 11654 solver.cpp:239] Iteration 52100 (1.17731 iter/s, 8.49392s/10 iters), loss = 6.75356
I0524 08:39:55.281508 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75356 (* 1 = 6.75356 loss)
I0524 08:39:55.904412 11654 sgd_solver.cpp:112] Iteration 52100, lr = 0.1
I0524 08:40:04.402726 11654 solver.cpp:239] Iteration 52110 (1.09638 iter/s, 9.12088s/10 iters), loss = 6.78963
I0524 08:40:04.402786 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78963 (* 1 = 6.78963 loss)
I0524 08:40:05.155138 11654 sgd_solver.cpp:112] Iteration 52110, lr = 0.1
I0524 08:40:11.615481 11654 solver.cpp:239] Iteration 52120 (1.3865 iter/s, 7.2124s/10 iters), loss = 6.54722
I0524 08:40:11.615537 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54722 (* 1 = 6.54722 loss)
I0524 08:40:11.615556 11654 sgd_solver.cpp:112] Iteration 52120, lr = 0.1
I0524 08:40:17.897887 11654 solver.cpp:239] Iteration 52130 (1.59199 iter/s, 6.28146s/10 iters), loss = 5.89872
I0524 08:40:17.898175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89872 (* 1 = 5.89872 loss)
I0524 08:40:17.898227 11654 sgd_solver.cpp:112] Iteration 52130, lr = 0.1
I0524 08:40:28.159173 11654 solver.cpp:239] Iteration 52140 (0.974603 iter/s, 10.2606s/10 iters), loss = 6.1453
I0524 08:40:28.159229 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1453 (* 1 = 6.1453 loss)
I0524 08:40:28.159507 11654 sgd_solver.cpp:112] Iteration 52140, lr = 0.1
I0524 08:40:36.385730 11654 solver.cpp:239] Iteration 52150 (1.21564 iter/s, 8.22612s/10 iters), loss = 6.25446
I0524 08:40:36.385821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25446 (* 1 = 6.25446 loss)
I0524 08:40:37.066633 11654 sgd_solver.cpp:112] Iteration 52150, lr = 0.1
I0524 08:40:43.791986 11654 solver.cpp:239] Iteration 52160 (1.35028 iter/s, 7.40589s/10 iters), loss = 6.06538
I0524 08:40:43.792048 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06538 (* 1 = 6.06538 loss)
I0524 08:40:43.792066 11654 sgd_solver.cpp:112] Iteration 52160, lr = 0.1
I0524 08:40:50.844408 11654 solver.cpp:239] Iteration 52170 (1.41846 iter/s, 7.04991s/10 iters), loss = 6.01187
I0524 08:40:50.844651 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01187 (* 1 = 6.01187 loss)
I0524 08:40:50.844681 11654 sgd_solver.cpp:112] Iteration 52170, lr = 0.1
I0524 08:40:57.958503 11654 solver.cpp:239] Iteration 52180 (1.40576 iter/s, 7.11357s/10 iters), loss = 5.89566
I0524 08:40:57.958554 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89566 (* 1 = 5.89566 loss)
I0524 08:40:58.123819 11654 sgd_solver.cpp:112] Iteration 52180, lr = 0.1
I0524 08:41:06.345293 11654 solver.cpp:239] Iteration 52190 (1.19241 iter/s, 8.38638s/10 iters), loss = 5.90604
I0524 08:41:06.345357 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90604 (* 1 = 5.90604 loss)
I0524 08:41:06.745224 11654 sgd_solver.cpp:112] Iteration 52190, lr = 0.1
I0524 08:41:13.695360 11654 solver.cpp:239] Iteration 52200 (1.3606 iter/s, 7.34972s/10 iters), loss = 6.55174
I0524 08:41:13.695416 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55174 (* 1 = 6.55174 loss)
I0524 08:41:13.695446 11654 sgd_solver.cpp:112] Iteration 52200, lr = 0.1
I0524 08:41:20.373278 11654 solver.cpp:239] Iteration 52210 (1.49754 iter/s, 6.67761s/10 iters), loss = 5.70932
I0524 08:41:20.373330 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70932 (* 1 = 5.70932 loss)
I0524 08:41:20.373347 11654 sgd_solver.cpp:112] Iteration 52210, lr = 0.1
I0524 08:41:30.180774 11654 solver.cpp:239] Iteration 52220 (1.01967 iter/s, 9.80707s/10 iters), loss = 6.27259
I0524 08:41:30.181082 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27259 (* 1 = 6.27259 loss)
I0524 08:41:30.181131 11654 sgd_solver.cpp:112] Iteration 52220, lr = 0.1
I0524 08:41:38.466538 11654 solver.cpp:239] Iteration 52230 (1.207 iter/s, 8.285s/10 iters), loss = 5.67857
I0524 08:41:38.466629 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67857 (* 1 = 5.67857 loss)
I0524 08:41:38.467155 11654 sgd_solver.cpp:112] Iteration 52230, lr = 0.1
I0524 08:41:47.597213 11654 solver.cpp:239] Iteration 52240 (1.09527 iter/s, 9.1302s/10 iters), loss = 6.4138
I0524 08:41:47.597286 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4138 (* 1 = 6.4138 loss)
I0524 08:41:47.599926 11654 sgd_solver.cpp:112] Iteration 52240, lr = 0.1
I0524 08:41:57.385285 11654 solver.cpp:239] Iteration 52250 (1.0217 iter/s, 9.78762s/10 iters), loss = 6.00865
I0524 08:41:57.385356 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00865 (* 1 = 6.00865 loss)
I0524 08:41:57.385378 11654 sgd_solver.cpp:112] Iteration 52250, lr = 0.1
I0524 08:42:05.319399 11654 solver.cpp:239] Iteration 52260 (1.26045 iter/s, 7.93368s/10 iters), loss = 4.99215
I0524 08:42:05.319653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.99215 (* 1 = 4.99215 loss)
I0524 08:42:05.320797 11654 sgd_solver.cpp:112] Iteration 52260, lr = 0.1
I0524 08:42:14.875113 11654 solver.cpp:239] Iteration 52270 (1.04656 iter/s, 9.55511s/10 iters), loss = 5.42278
I0524 08:42:14.875174 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42278 (* 1 = 5.42278 loss)
I0524 08:42:14.875192 11654 sgd_solver.cpp:112] Iteration 52270, lr = 0.1
I0524 08:42:23.593039 11654 solver.cpp:239] Iteration 52280 (1.14712 iter/s, 8.71745s/10 iters), loss = 6.88558
I0524 08:42:23.593111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.88558 (* 1 = 6.88558 loss)
I0524 08:42:23.593483 11654 sgd_solver.cpp:112] Iteration 52280, lr = 0.1
I0524 08:42:33.454272 11654 solver.cpp:239] Iteration 52290 (1.01412 iter/s, 9.86077s/10 iters), loss = 6.80246
I0524 08:42:33.454344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80246 (* 1 = 6.80246 loss)
I0524 08:42:33.454360 11654 sgd_solver.cpp:112] Iteration 52290, lr = 0.1
I0524 08:42:41.518354 11654 solver.cpp:239] Iteration 52300 (1.24014 iter/s, 8.06362s/10 iters), loss = 6.66024
I0524 08:42:41.518604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66024 (* 1 = 6.66024 loss)
I0524 08:42:41.518685 11654 sgd_solver.cpp:112] Iteration 52300, lr = 0.1
I0524 08:42:48.280684 11654 solver.cpp:239] Iteration 52310 (1.47889 iter/s, 6.76181s/10 iters), loss = 5.06735
I0524 08:42:48.280779 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.06735 (* 1 = 5.06735 loss)
I0524 08:42:48.280808 11654 sgd_solver.cpp:112] Iteration 52310, lr = 0.1
I0524 08:42:55.729640 11654 solver.cpp:239] Iteration 52320 (1.34253 iter/s, 7.44861s/10 iters), loss = 6.40824
I0524 08:42:55.729688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40824 (* 1 = 6.40824 loss)
I0524 08:42:56.267395 11654 sgd_solver.cpp:112] Iteration 52320, lr = 0.1
I0524 08:43:03.747572 11654 solver.cpp:239] Iteration 52330 (1.24727 iter/s, 8.01748s/10 iters), loss = 6.74414
I0524 08:43:03.747673 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74414 (* 1 = 6.74414 loss)
I0524 08:43:03.747704 11654 sgd_solver.cpp:112] Iteration 52330, lr = 0.1
I0524 08:43:10.800433 11654 solver.cpp:239] Iteration 52340 (1.41796 iter/s, 7.0524s/10 iters), loss = 6.94707
I0524 08:43:10.800506 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.94707 (* 1 = 6.94707 loss)
I0524 08:43:10.800665 11654 sgd_solver.cpp:112] Iteration 52340, lr = 0.1
I0524 08:43:16.970099 11654 solver.cpp:239] Iteration 52350 (1.62092 iter/s, 6.16933s/10 iters), loss = 6.31738
I0524 08:43:16.970214 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31738 (* 1 = 6.31738 loss)
I0524 08:43:16.970342 11654 sgd_solver.cpp:112] Iteration 52350, lr = 0.1
I0524 08:43:26.014334 11654 solver.cpp:239] Iteration 52360 (1.10574 iter/s, 9.04376s/10 iters), loss = 5.70832
I0524 08:43:26.014402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70832 (* 1 = 5.70832 loss)
I0524 08:43:26.014433 11654 sgd_solver.cpp:112] Iteration 52360, lr = 0.1
I0524 08:43:32.546735 11654 solver.cpp:239] Iteration 52370 (1.53091 iter/s, 6.53207s/10 iters), loss = 5.54875
I0524 08:43:32.546788 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54875 (* 1 = 5.54875 loss)
I0524 08:43:32.546816 11654 sgd_solver.cpp:112] Iteration 52370, lr = 0.1
I0524 08:43:39.695673 11654 solver.cpp:239] Iteration 52380 (1.39931 iter/s, 7.14639s/10 iters), loss = 6.06865
I0524 08:43:39.695735 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06865 (* 1 = 6.06865 loss)
I0524 08:43:39.695893 11654 sgd_solver.cpp:112] Iteration 52380, lr = 0.1
I0524 08:43:47.742358 11654 solver.cpp:239] Iteration 52390 (1.24281 iter/s, 8.04628s/10 iters), loss = 6.02579
I0524 08:43:47.742660 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02579 (* 1 = 6.02579 loss)
I0524 08:43:47.742687 11654 sgd_solver.cpp:112] Iteration 52390, lr = 0.1
I0524 08:43:56.730495 11654 solver.cpp:239] Iteration 52400 (1.11292 iter/s, 8.98537s/10 iters), loss = 5.90948
I0524 08:43:56.730568 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90948 (* 1 = 5.90948 loss)
I0524 08:43:56.864912 11654 sgd_solver.cpp:112] Iteration 52400, lr = 0.1
I0524 08:44:06.500491 11654 solver.cpp:239] Iteration 52410 (1.02359 iter/s, 9.76957s/10 iters), loss = 6.68838
I0524 08:44:06.500540 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68838 (* 1 = 6.68838 loss)
I0524 08:44:07.348489 11654 sgd_solver.cpp:112] Iteration 52410, lr = 0.1
I0524 08:44:14.083132 11654 solver.cpp:239] Iteration 52420 (1.31886 iter/s, 7.58229s/10 iters), loss = 6.05463
I0524 08:44:14.083180 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05463 (* 1 = 6.05463 loss)
I0524 08:44:14.083196 11654 sgd_solver.cpp:112] Iteration 52420, lr = 0.1
I0524 08:44:21.348528 11654 solver.cpp:239] Iteration 52430 (1.37646 iter/s, 7.265s/10 iters), loss = 6.06224
I0524 08:44:21.348760 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06224 (* 1 = 6.06224 loss)
I0524 08:44:21.348803 11654 sgd_solver.cpp:112] Iteration 52430, lr = 0.1
I0524 08:44:28.287129 11654 solver.cpp:239] Iteration 52440 (1.44131 iter/s, 6.93812s/10 iters), loss = 5.26621
I0524 08:44:28.287184 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26621 (* 1 = 5.26621 loss)
I0524 08:44:28.854179 11654 sgd_solver.cpp:112] Iteration 52440, lr = 0.1
I0524 08:44:35.556692 11654 solver.cpp:239] Iteration 52450 (1.37567 iter/s, 7.26917s/10 iters), loss = 5.81977
I0524 08:44:35.556749 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81977 (* 1 = 5.81977 loss)
I0524 08:44:35.556773 11654 sgd_solver.cpp:112] Iteration 52450, lr = 0.1
I0524 08:44:41.972025 11654 solver.cpp:239] Iteration 52460 (1.55884 iter/s, 6.41503s/10 iters), loss = 6.08168
I0524 08:44:41.972072 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08168 (* 1 = 6.08168 loss)
I0524 08:44:41.972087 11654 sgd_solver.cpp:112] Iteration 52460, lr = 0.1
I0524 08:44:50.285603 11654 solver.cpp:239] Iteration 52470 (1.20291 iter/s, 8.31318s/10 iters), loss = 6.39001
I0524 08:44:50.285665 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39001 (* 1 = 6.39001 loss)
I0524 08:44:50.285687 11654 sgd_solver.cpp:112] Iteration 52470, lr = 0.1
I0524 08:44:57.577654 11654 solver.cpp:239] Iteration 52480 (1.37142 iter/s, 7.29171s/10 iters), loss = 5.28688
I0524 08:44:57.577785 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28688 (* 1 = 5.28688 loss)
I0524 08:44:58.189568 11654 sgd_solver.cpp:112] Iteration 52480, lr = 0.1
I0524 08:45:05.288075 11654 solver.cpp:239] Iteration 52490 (1.29702 iter/s, 7.70999s/10 iters), loss = 6.51812
I0524 08:45:05.288131 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51812 (* 1 = 6.51812 loss)
I0524 08:45:05.291646 11654 sgd_solver.cpp:112] Iteration 52490, lr = 0.1
I0524 08:45:11.582188 11654 solver.cpp:239] Iteration 52500 (1.58887 iter/s, 6.29377s/10 iters), loss = 5.95776
I0524 08:45:11.582263 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95776 (* 1 = 5.95776 loss)
I0524 08:45:11.582362 11654 sgd_solver.cpp:112] Iteration 52500, lr = 0.1
I0524 08:45:21.132427 11654 solver.cpp:239] Iteration 52510 (1.04715 iter/s, 9.54977s/10 iters), loss = 6.53964
I0524 08:45:21.132525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53964 (* 1 = 6.53964 loss)
I0524 08:45:21.133046 11654 sgd_solver.cpp:112] Iteration 52510, lr = 0.1
I0524 08:45:27.625572 11654 solver.cpp:239] Iteration 52520 (1.54016 iter/s, 6.49282s/10 iters), loss = 7.18115
I0524 08:45:27.625778 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.18115 (* 1 = 7.18115 loss)
I0524 08:45:27.625979 11654 sgd_solver.cpp:112] Iteration 52520, lr = 0.1
I0524 08:45:35.862334 11654 solver.cpp:239] Iteration 52530 (1.21415 iter/s, 8.23623s/10 iters), loss = 5.3592
I0524 08:45:35.862388 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3592 (* 1 = 5.3592 loss)
I0524 08:45:35.862404 11654 sgd_solver.cpp:112] Iteration 52530, lr = 0.1
I0524 08:45:42.815847 11654 solver.cpp:239] Iteration 52540 (1.43864 iter/s, 6.951s/10 iters), loss = 7.08643
I0524 08:45:42.815958 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08643 (* 1 = 7.08643 loss)
I0524 08:45:42.815989 11654 sgd_solver.cpp:112] Iteration 52540, lr = 0.1
I0524 08:45:49.514768 11654 solver.cpp:239] Iteration 52550 (1.49308 iter/s, 6.69755s/10 iters), loss = 6.44281
I0524 08:45:49.514839 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44281 (* 1 = 6.44281 loss)
I0524 08:45:49.514858 11654 sgd_solver.cpp:112] Iteration 52550, lr = 0.1
I0524 08:45:56.039127 11654 solver.cpp:239] Iteration 52560 (1.53279 iter/s, 6.52405s/10 iters), loss = 5.69969
I0524 08:45:56.039170 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69969 (* 1 = 5.69969 loss)
I0524 08:45:56.039186 11654 sgd_solver.cpp:112] Iteration 52560, lr = 0.1
I0524 08:46:02.505563 11654 solver.cpp:239] Iteration 52570 (1.54657 iter/s, 6.46592s/10 iters), loss = 5.29734
I0524 08:46:02.505779 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29734 (* 1 = 5.29734 loss)
I0524 08:46:02.505812 11654 sgd_solver.cpp:112] Iteration 52570, lr = 0.1
I0524 08:46:09.431257 11654 solver.cpp:239] Iteration 52580 (1.44442 iter/s, 6.92318s/10 iters), loss = 5.54125
I0524 08:46:09.431296 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54125 (* 1 = 5.54125 loss)
I0524 08:46:09.529088 11654 sgd_solver.cpp:112] Iteration 52580, lr = 0.1
I0524 08:46:16.496893 11654 solver.cpp:239] Iteration 52590 (1.41536 iter/s, 7.06532s/10 iters), loss = 5.32834
I0524 08:46:16.496958 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.32834 (* 1 = 5.32834 loss)
I0524 08:46:16.496984 11654 sgd_solver.cpp:112] Iteration 52590, lr = 0.1
I0524 08:46:22.865468 11654 solver.cpp:239] Iteration 52600 (1.57028 iter/s, 6.36827s/10 iters), loss = 5.66834
I0524 08:46:22.865530 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66834 (* 1 = 5.66834 loss)
I0524 08:46:22.865792 11654 sgd_solver.cpp:112] Iteration 52600, lr = 0.1
I0524 08:46:30.706602 11654 solver.cpp:239] Iteration 52610 (1.27538 iter/s, 7.84077s/10 iters), loss = 6.16447
I0524 08:46:30.706661 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16447 (* 1 = 6.16447 loss)
I0524 08:46:30.706960 11654 sgd_solver.cpp:112] Iteration 52610, lr = 0.1
I0524 08:46:37.907367 11654 solver.cpp:239] Iteration 52620 (1.38881 iter/s, 7.20043s/10 iters), loss = 6.37129
I0524 08:46:37.907636 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37129 (* 1 = 6.37129 loss)
I0524 08:46:37.907707 11654 sgd_solver.cpp:112] Iteration 52620, lr = 0.1
I0524 08:46:47.791417 11654 solver.cpp:239] Iteration 52630 (1.01202 iter/s, 9.88123s/10 iters), loss = 6.22535
I0524 08:46:47.791537 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22535 (* 1 = 6.22535 loss)
I0524 08:46:47.805135 11654 sgd_solver.cpp:112] Iteration 52630, lr = 0.1
I0524 08:46:55.149849 11654 solver.cpp:239] Iteration 52640 (1.35905 iter/s, 7.35809s/10 iters), loss = 6.1852
I0524 08:46:55.149900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1852 (* 1 = 6.1852 loss)
I0524 08:46:55.150043 11654 sgd_solver.cpp:112] Iteration 52640, lr = 0.1
I0524 08:47:01.791139 11654 solver.cpp:239] Iteration 52650 (1.5058 iter/s, 6.64097s/10 iters), loss = 5.77711
I0524 08:47:01.791203 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.77711 (* 1 = 5.77711 loss)
I0524 08:47:02.168411 11654 sgd_solver.cpp:112] Iteration 52650, lr = 0.1
I0524 08:47:09.344154 11654 solver.cpp:239] Iteration 52660 (1.32404 iter/s, 7.55265s/10 iters), loss = 6.53817
I0524 08:47:09.344440 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53817 (* 1 = 6.53817 loss)
I0524 08:47:09.344547 11654 sgd_solver.cpp:112] Iteration 52660, lr = 0.1
I0524 08:47:17.089486 11654 solver.cpp:239] Iteration 52670 (1.29119 iter/s, 7.74479s/10 iters), loss = 5.37
I0524 08:47:17.089579 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.37 (* 1 = 5.37 loss)
I0524 08:47:17.089613 11654 sgd_solver.cpp:112] Iteration 52670, lr = 0.1
I0524 08:47:23.587700 11654 solver.cpp:239] Iteration 52680 (1.53898 iter/s, 6.49781s/10 iters), loss = 5.07758
I0524 08:47:23.587826 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.07758 (* 1 = 5.07758 loss)
I0524 08:47:23.588945 11654 sgd_solver.cpp:112] Iteration 52680, lr = 0.1
I0524 08:47:31.049593 11654 solver.cpp:239] Iteration 52690 (1.34021 iter/s, 7.46152s/10 iters), loss = 5.68994
I0524 08:47:31.049655 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68994 (* 1 = 5.68994 loss)
I0524 08:47:31.049675 11654 sgd_solver.cpp:112] Iteration 52690, lr = 0.1
I0524 08:47:37.364863 11654 solver.cpp:239] Iteration 52700 (1.58409 iter/s, 6.31278s/10 iters), loss = 5.90675
I0524 08:47:37.364914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90675 (* 1 = 5.90675 loss)
I0524 08:47:37.365108 11654 sgd_solver.cpp:112] Iteration 52700, lr = 0.1
I0524 08:47:45.965559 11654 solver.cpp:239] Iteration 52710 (1.16275 iter/s, 8.60028s/10 iters), loss = 5.67015
I0524 08:47:45.965857 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67015 (* 1 = 5.67015 loss)
I0524 08:47:45.965907 11654 sgd_solver.cpp:112] Iteration 52710, lr = 0.1
I0524 08:47:52.279587 11654 solver.cpp:239] Iteration 52720 (1.5839 iter/s, 6.31354s/10 iters), loss = 6.14174
I0524 08:47:52.279656 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14174 (* 1 = 6.14174 loss)
I0524 08:47:52.342512 11654 sgd_solver.cpp:112] Iteration 52720, lr = 0.1
I0524 08:48:01.556522 11654 solver.cpp:239] Iteration 52730 (1.07799 iter/s, 9.27649s/10 iters), loss = 5.89078
I0524 08:48:01.556586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89078 (* 1 = 5.89078 loss)
I0524 08:48:01.787516 11654 sgd_solver.cpp:112] Iteration 52730, lr = 0.1
I0524 08:48:10.013636 11654 solver.cpp:239] Iteration 52740 (1.18249 iter/s, 8.45673s/10 iters), loss = 7.08734
I0524 08:48:10.013710 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08734 (* 1 = 7.08734 loss)
I0524 08:48:10.013965 11654 sgd_solver.cpp:112] Iteration 52740, lr = 0.1
I0524 08:48:17.619379 11654 solver.cpp:239] Iteration 52750 (1.31486 iter/s, 7.60539s/10 iters), loss = 5.49933
I0524 08:48:17.619537 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49933 (* 1 = 5.49933 loss)
I0524 08:48:17.619626 11654 sgd_solver.cpp:112] Iteration 52750, lr = 0.1
I0524 08:48:25.261180 11654 solver.cpp:239] Iteration 52760 (1.30867 iter/s, 7.64133s/10 iters), loss = 6.00889
I0524 08:48:25.261257 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00889 (* 1 = 6.00889 loss)
I0524 08:48:25.457574 11654 sgd_solver.cpp:112] Iteration 52760, lr = 0.1
I0524 08:48:33.783557 11654 solver.cpp:239] Iteration 52770 (1.17344 iter/s, 8.52194s/10 iters), loss = 5.76429
I0524 08:48:33.783625 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76429 (* 1 = 5.76429 loss)
I0524 08:48:33.784056 11654 sgd_solver.cpp:112] Iteration 52770, lr = 0.1
I0524 08:48:40.228345 11654 solver.cpp:239] Iteration 52780 (1.55172 iter/s, 6.44447s/10 iters), loss = 5.08182
I0524 08:48:40.228411 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.08182 (* 1 = 5.08182 loss)
I0524 08:48:40.228688 11654 sgd_solver.cpp:112] Iteration 52780, lr = 0.1
I0524 08:48:46.976912 11654 solver.cpp:239] Iteration 52790 (1.48187 iter/s, 6.74822s/10 iters), loss = 6.14714
I0524 08:48:46.976980 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14714 (* 1 = 6.14714 loss)
I0524 08:48:46.977118 11654 sgd_solver.cpp:112] Iteration 52790, lr = 0.1
I0524 08:48:54.129825 11654 solver.cpp:239] Iteration 52800 (1.3981 iter/s, 7.15257s/10 iters), loss = 5.80925
I0524 08:48:54.130080 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80925 (* 1 = 5.80925 loss)
I0524 08:48:54.134991 11654 sgd_solver.cpp:112] Iteration 52800, lr = 0.1
I0524 08:49:02.692389 11654 solver.cpp:239] Iteration 52810 (1.16795 iter/s, 8.56198s/10 iters), loss = 6.34106
I0524 08:49:02.692464 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34106 (* 1 = 6.34106 loss)
I0524 08:49:02.692514 11654 sgd_solver.cpp:112] Iteration 52810, lr = 0.1
I0524 08:49:10.301761 11654 solver.cpp:239] Iteration 52820 (1.31424 iter/s, 7.60899s/10 iters), loss = 6.25125
I0524 08:49:10.301877 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25125 (* 1 = 6.25125 loss)
I0524 08:49:10.301937 11654 sgd_solver.cpp:112] Iteration 52820, lr = 0.1
I0524 08:49:17.759290 11654 solver.cpp:239] Iteration 52830 (1.34099 iter/s, 7.45716s/10 iters), loss = 5.72509
I0524 08:49:17.759332 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72509 (* 1 = 5.72509 loss)
I0524 08:49:17.801664 11654 sgd_solver.cpp:112] Iteration 52830, lr = 0.1
I0524 08:49:24.472831 11654 solver.cpp:239] Iteration 52840 (1.4896 iter/s, 6.71323s/10 iters), loss = 6.56488
I0524 08:49:24.473094 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56488 (* 1 = 6.56488 loss)
I0524 08:49:24.473111 11654 sgd_solver.cpp:112] Iteration 52840, lr = 0.1
I0524 08:49:31.239715 11654 solver.cpp:239] Iteration 52850 (1.4779 iter/s, 6.76635s/10 iters), loss = 5.90519
I0524 08:49:31.239773 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90519 (* 1 = 5.90519 loss)
I0524 08:49:31.240099 11654 sgd_solver.cpp:112] Iteration 52850, lr = 0.1
I0524 08:49:37.921880 11654 solver.cpp:239] Iteration 52860 (1.49659 iter/s, 6.68184s/10 iters), loss = 6.3695
I0524 08:49:37.921947 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3695 (* 1 = 6.3695 loss)
I0524 08:49:37.922333 11654 sgd_solver.cpp:112] Iteration 52860, lr = 0.1
I0524 08:49:44.499545 11654 solver.cpp:239] Iteration 52870 (1.52037 iter/s, 6.57734s/10 iters), loss = 6.56851
I0524 08:49:44.499611 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56851 (* 1 = 6.56851 loss)
I0524 08:49:44.499742 11654 sgd_solver.cpp:112] Iteration 52870, lr = 0.1
I0524 08:49:53.005789 11654 solver.cpp:239] Iteration 52880 (1.17566 iter/s, 8.50584s/10 iters), loss = 6.56583
I0524 08:49:53.005851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56583 (* 1 = 6.56583 loss)
I0524 08:49:53.005935 11654 sgd_solver.cpp:112] Iteration 52880, lr = 0.1
I0524 08:49:59.766986 11654 solver.cpp:239] Iteration 52890 (1.4791 iter/s, 6.76087s/10 iters), loss = 6.5526
I0524 08:49:59.767175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5526 (* 1 = 6.5526 loss)
I0524 08:49:59.767204 11654 sgd_solver.cpp:112] Iteration 52890, lr = 0.1
I0524 08:50:08.326031 11654 solver.cpp:239] Iteration 52900 (1.16843 iter/s, 8.55851s/10 iters), loss = 6.1066
I0524 08:50:08.326102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1066 (* 1 = 6.1066 loss)
I0524 08:50:08.326210 11654 sgd_solver.cpp:112] Iteration 52900, lr = 0.1
I0524 08:50:15.716831 11654 solver.cpp:239] Iteration 52910 (1.3531 iter/s, 7.39045s/10 iters), loss = 6.18968
I0524 08:50:15.716886 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18968 (* 1 = 6.18968 loss)
I0524 08:50:16.421458 11654 sgd_solver.cpp:112] Iteration 52910, lr = 0.1
I0524 08:50:23.092213 11654 solver.cpp:239] Iteration 52920 (1.35593 iter/s, 7.37503s/10 iters), loss = 5.65756
I0524 08:50:23.092277 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65756 (* 1 = 5.65756 loss)
I0524 08:50:23.092389 11654 sgd_solver.cpp:112] Iteration 52920, lr = 0.1
I0524 08:50:30.472770 11654 solver.cpp:239] Iteration 52930 (1.35498 iter/s, 7.38021s/10 iters), loss = 5.40307
I0524 08:50:30.472993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40307 (* 1 = 5.40307 loss)
I0524 08:50:30.473023 11654 sgd_solver.cpp:112] Iteration 52930, lr = 0.1
I0524 08:50:36.814538 11654 solver.cpp:239] Iteration 52940 (1.57698 iter/s, 6.34124s/10 iters), loss = 5.60307
I0524 08:50:36.814611 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60307 (* 1 = 5.60307 loss)
I0524 08:50:36.814751 11654 sgd_solver.cpp:112] Iteration 52940, lr = 0.1
I0524 08:50:44.650041 11654 solver.cpp:239] Iteration 52950 (1.2763 iter/s, 7.83512s/10 iters), loss = 5.81332
I0524 08:50:44.650102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81332 (* 1 = 5.81332 loss)
I0524 08:50:44.650215 11654 sgd_solver.cpp:112] Iteration 52950, lr = 0.1
I0524 08:50:52.780961 11654 solver.cpp:239] Iteration 52960 (1.22993 iter/s, 8.13052s/10 iters), loss = 5.79285
I0524 08:50:52.781033 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79285 (* 1 = 5.79285 loss)
I0524 08:50:52.781055 11654 sgd_solver.cpp:112] Iteration 52960, lr = 0.1
I0524 08:51:00.210172 11654 solver.cpp:239] Iteration 52970 (1.34611 iter/s, 7.42884s/10 iters), loss = 6.87355
I0524 08:51:00.210239 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.87355 (* 1 = 6.87355 loss)
I0524 08:51:00.210295 11654 sgd_solver.cpp:112] Iteration 52970, lr = 0.1
I0524 08:51:07.148947 11654 solver.cpp:239] Iteration 52980 (1.44125 iter/s, 6.93844s/10 iters), loss = 5.83524
I0524 08:51:07.149132 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83524 (* 1 = 5.83524 loss)
I0524 08:51:07.205176 11654 sgd_solver.cpp:112] Iteration 52980, lr = 0.1
I0524 08:51:16.993404 11654 solver.cpp:239] Iteration 52990 (1.01586 iter/s, 9.84388s/10 iters), loss = 5.62568
I0524 08:51:16.993544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62568 (* 1 = 5.62568 loss)
I0524 08:51:16.993584 11654 sgd_solver.cpp:112] Iteration 52990, lr = 0.1
I0524 08:51:23.868680 11654 solver.cpp:239] Iteration 53000 (1.45457 iter/s, 6.8749s/10 iters), loss = 5.54562
I0524 08:51:23.868731 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.54562 (* 1 = 5.54562 loss)
I0524 08:51:23.868875 11654 sgd_solver.cpp:112] Iteration 53000, lr = 0.1
I0524 08:51:30.139225 11654 solver.cpp:239] Iteration 53010 (1.59484 iter/s, 6.27024s/10 iters), loss = 6.20321
I0524 08:51:30.139302 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20321 (* 1 = 6.20321 loss)
I0524 08:51:30.139412 11654 sgd_solver.cpp:112] Iteration 53010, lr = 0.1
I0524 08:51:36.411026 11654 solver.cpp:239] Iteration 53020 (1.59452 iter/s, 6.27148s/10 iters), loss = 6.68603
I0524 08:51:36.411128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68603 (* 1 = 6.68603 loss)
I0524 08:51:36.411162 11654 sgd_solver.cpp:112] Iteration 53020, lr = 0.1
I0524 08:51:44.235469 11654 solver.cpp:239] Iteration 53030 (1.27811 iter/s, 7.82406s/10 iters), loss = 5.46371
I0524 08:51:44.235769 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46371 (* 1 = 5.46371 loss)
I0524 08:51:44.401965 11654 sgd_solver.cpp:112] Iteration 53030, lr = 0.1
I0524 08:51:51.175546 11654 solver.cpp:239] Iteration 53040 (1.44101 iter/s, 6.93957s/10 iters), loss = 6.26364
I0524 08:51:51.175659 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26364 (* 1 = 6.26364 loss)
I0524 08:51:51.175729 11654 sgd_solver.cpp:112] Iteration 53040, lr = 0.1
I0524 08:51:59.364907 11654 solver.cpp:239] Iteration 53050 (1.22115 iter/s, 8.18899s/10 iters), loss = 5.63675
I0524 08:51:59.364964 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63675 (* 1 = 5.63675 loss)
I0524 08:51:59.364992 11654 sgd_solver.cpp:112] Iteration 53050, lr = 0.1
I0524 08:52:06.035773 11654 solver.cpp:239] Iteration 53060 (1.49915 iter/s, 6.67046s/10 iters), loss = 7.42894
I0524 08:52:06.035871 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.42894 (* 1 = 7.42894 loss)
I0524 08:52:06.035946 11654 sgd_solver.cpp:112] Iteration 53060, lr = 0.1
I0524 08:52:12.555064 11654 solver.cpp:239] Iteration 53070 (1.53399 iter/s, 6.51894s/10 iters), loss = 6.1925
I0524 08:52:12.555236 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1925 (* 1 = 6.1925 loss)
I0524 08:52:12.559490 11654 sgd_solver.cpp:112] Iteration 53070, lr = 0.1
I0524 08:52:19.830673 11654 solver.cpp:239] Iteration 53080 (1.37453 iter/s, 7.27522s/10 iters), loss = 6.15843
I0524 08:52:19.830926 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15843 (* 1 = 6.15843 loss)
I0524 08:52:19.831565 11654 sgd_solver.cpp:112] Iteration 53080, lr = 0.1
I0524 08:52:27.693681 11654 solver.cpp:239] Iteration 53090 (1.27187 iter/s, 7.86246s/10 iters), loss = 6.01299
I0524 08:52:27.693725 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01299 (* 1 = 6.01299 loss)
I0524 08:52:28.040526 11654 sgd_solver.cpp:112] Iteration 53090, lr = 0.1
I0524 08:52:34.627209 11654 solver.cpp:239] Iteration 53100 (1.44234 iter/s, 6.93316s/10 iters), loss = 5.61478
I0524 08:52:34.627275 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61478 (* 1 = 5.61478 loss)
I0524 08:52:35.585853 11654 sgd_solver.cpp:112] Iteration 53100, lr = 0.1
I0524 08:52:42.505551 11654 solver.cpp:239] Iteration 53110 (1.26936 iter/s, 7.87797s/10 iters), loss = 7.2135
I0524 08:52:42.505602 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.2135 (* 1 = 7.2135 loss)
I0524 08:52:42.553151 11654 sgd_solver.cpp:112] Iteration 53110, lr = 0.1
I0524 08:52:48.818286 11654 solver.cpp:239] Iteration 53120 (1.58418 iter/s, 6.31242s/10 iters), loss = 5.61738
I0524 08:52:48.818349 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61738 (* 1 = 5.61738 loss)
I0524 08:52:49.335912 11654 sgd_solver.cpp:112] Iteration 53120, lr = 0.1
I0524 08:52:55.786020 11654 solver.cpp:239] Iteration 53130 (1.43525 iter/s, 6.9674s/10 iters), loss = 6.68709
I0524 08:52:55.786202 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68709 (* 1 = 6.68709 loss)
I0524 08:52:55.786223 11654 sgd_solver.cpp:112] Iteration 53130, lr = 0.1
I0524 08:53:04.791132 11654 solver.cpp:239] Iteration 53140 (1.11054 iter/s, 9.00459s/10 iters), loss = 6.51682
I0524 08:53:04.791199 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51682 (* 1 = 6.51682 loss)
I0524 08:53:04.791220 11654 sgd_solver.cpp:112] Iteration 53140, lr = 0.1
I0524 08:53:12.503012 11654 solver.cpp:239] Iteration 53150 (1.29677 iter/s, 7.71145s/10 iters), loss = 7.54104
I0524 08:53:12.503103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.54104 (* 1 = 7.54104 loss)
I0524 08:53:12.504313 11654 sgd_solver.cpp:112] Iteration 53150, lr = 0.1
I0524 08:53:19.411461 11654 solver.cpp:239] Iteration 53160 (1.44758 iter/s, 6.9081s/10 iters), loss = 5.61901
I0524 08:53:19.411528 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61901 (* 1 = 5.61901 loss)
I0524 08:53:19.411550 11654 sgd_solver.cpp:112] Iteration 53160, lr = 0.1
I0524 08:53:25.990569 11654 solver.cpp:239] Iteration 53170 (1.52005 iter/s, 6.57871s/10 iters), loss = 5.71508
I0524 08:53:25.990895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71508 (* 1 = 5.71508 loss)
I0524 08:53:25.990950 11654 sgd_solver.cpp:112] Iteration 53170, lr = 0.1
I0524 08:53:33.911669 11654 solver.cpp:239] Iteration 53180 (1.2627 iter/s, 7.91955s/10 iters), loss = 6.52426
I0524 08:53:33.911721 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52426 (* 1 = 6.52426 loss)
I0524 08:53:34.401425 11654 sgd_solver.cpp:112] Iteration 53180, lr = 0.1
I0524 08:53:40.835923 11654 solver.cpp:239] Iteration 53190 (1.44427 iter/s, 6.92389s/10 iters), loss = 6.32434
I0524 08:53:40.836037 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32434 (* 1 = 6.32434 loss)
I0524 08:53:40.836154 11654 sgd_solver.cpp:112] Iteration 53190, lr = 0.1
I0524 08:53:49.644322 11654 solver.cpp:239] Iteration 53200 (1.13534 iter/s, 8.80795s/10 iters), loss = 6.51423
I0524 08:53:49.644426 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51423 (* 1 = 6.51423 loss)
I0524 08:53:49.644467 11654 sgd_solver.cpp:112] Iteration 53200, lr = 0.1
I0524 08:53:57.093380 11654 solver.cpp:239] Iteration 53210 (1.34253 iter/s, 7.44863s/10 iters), loss = 6.09763
I0524 08:53:57.093694 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09763 (* 1 = 6.09763 loss)
I0524 08:53:57.093772 11654 sgd_solver.cpp:112] Iteration 53210, lr = 0.1
I0524 08:54:04.332160 11654 solver.cpp:239] Iteration 53220 (1.38198 iter/s, 7.23601s/10 iters), loss = 7.00842
I0524 08:54:04.332207 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00842 (* 1 = 7.00842 loss)
I0524 08:54:04.332434 11654 sgd_solver.cpp:112] Iteration 53220, lr = 0.1
I0524 08:54:10.561919 11654 solver.cpp:239] Iteration 53230 (1.6053 iter/s, 6.22937s/10 iters), loss = 6.20301
I0524 08:54:10.562103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20301 (* 1 = 6.20301 loss)
I0524 08:54:10.734666 11654 sgd_solver.cpp:112] Iteration 53230, lr = 0.1
I0524 08:54:17.658725 11654 solver.cpp:239] Iteration 53240 (1.40916 iter/s, 7.09641s/10 iters), loss = 6.12358
I0524 08:54:17.658764 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12358 (* 1 = 6.12358 loss)
I0524 08:54:17.658790 11654 sgd_solver.cpp:112] Iteration 53240, lr = 0.1
I0524 08:54:25.565831 11654 solver.cpp:239] Iteration 53250 (1.26474 iter/s, 7.90675s/10 iters), loss = 5.85529
I0524 08:54:25.565940 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85529 (* 1 = 5.85529 loss)
I0524 08:54:25.566299 11654 sgd_solver.cpp:112] Iteration 53250, lr = 0.1
I0524 08:54:36.251901 11654 solver.cpp:239] Iteration 53260 (0.935839 iter/s, 10.6856s/10 iters), loss = 6.3931
I0524 08:54:36.252105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3931 (* 1 = 6.3931 loss)
I0524 08:54:36.252135 11654 sgd_solver.cpp:112] Iteration 53260, lr = 0.1
I0524 08:54:45.292798 11654 solver.cpp:239] Iteration 53270 (1.10615 iter/s, 9.04034s/10 iters), loss = 6.26316
I0524 08:54:45.292855 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26316 (* 1 = 6.26316 loss)
I0524 08:54:45.392676 11654 sgd_solver.cpp:112] Iteration 53270, lr = 0.1
I0524 08:54:52.324100 11654 solver.cpp:239] Iteration 53280 (1.42228 iter/s, 7.03097s/10 iters), loss = 6.64051
I0524 08:54:52.324151 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64051 (* 1 = 6.64051 loss)
I0524 08:54:52.917906 11654 sgd_solver.cpp:112] Iteration 53280, lr = 0.1
I0524 08:55:01.363883 11654 solver.cpp:239] Iteration 53290 (1.10627 iter/s, 9.03937s/10 iters), loss = 5.28979
I0524 08:55:01.363941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28979 (* 1 = 5.28979 loss)
I0524 08:55:01.364157 11654 sgd_solver.cpp:112] Iteration 53290, lr = 0.1
I0524 08:55:08.176815 11654 solver.cpp:239] Iteration 53300 (1.46787 iter/s, 6.81261s/10 iters), loss = 6.74562
I0524 08:55:08.177088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74562 (* 1 = 6.74562 loss)
I0524 08:55:08.177150 11654 sgd_solver.cpp:112] Iteration 53300, lr = 0.1
I0524 08:55:15.724665 11654 solver.cpp:239] Iteration 53310 (1.32532 iter/s, 7.54534s/10 iters), loss = 6.26991
I0524 08:55:15.724721 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26991 (* 1 = 6.26991 loss)
I0524 08:55:15.724738 11654 sgd_solver.cpp:112] Iteration 53310, lr = 0.1
I0524 08:55:23.506573 11654 solver.cpp:239] Iteration 53320 (1.2851 iter/s, 7.78149s/10 iters), loss = 5.71464
I0524 08:55:23.506613 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71464 (* 1 = 5.71464 loss)
I0524 08:55:23.506626 11654 sgd_solver.cpp:112] Iteration 53320, lr = 0.1
I0524 08:55:30.723816 11654 solver.cpp:239] Iteration 53330 (1.38564 iter/s, 7.2169s/10 iters), loss = 6.95318
I0524 08:55:30.723889 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.95318 (* 1 = 6.95318 loss)
I0524 08:55:30.724020 11654 sgd_solver.cpp:112] Iteration 53330, lr = 0.1
I0524 08:55:37.332216 11654 solver.cpp:239] Iteration 53340 (1.51331 iter/s, 6.60805s/10 iters), loss = 6.49022
I0524 08:55:37.332290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49022 (* 1 = 6.49022 loss)
I0524 08:55:37.408947 11654 sgd_solver.cpp:112] Iteration 53340, lr = 0.1
I0524 08:55:45.332502 11654 solver.cpp:239] Iteration 53350 (1.25002 iter/s, 7.99988s/10 iters), loss = 5.75711
I0524 08:55:45.332942 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75711 (* 1 = 5.75711 loss)
I0524 08:55:45.332973 11654 sgd_solver.cpp:112] Iteration 53350, lr = 0.1
I0524 08:55:51.914433 11654 solver.cpp:239] Iteration 53360 (1.51947 iter/s, 6.58124s/10 iters), loss = 7.28775
I0524 08:55:51.914489 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.28775 (* 1 = 7.28775 loss)
I0524 08:55:51.914616 11654 sgd_solver.cpp:112] Iteration 53360, lr = 0.1
I0524 08:56:01.881425 11654 solver.cpp:239] Iteration 53370 (1.00336 iter/s, 9.96656s/10 iters), loss = 6.39582
I0524 08:56:01.881475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39582 (* 1 = 6.39582 loss)
I0524 08:56:01.881491 11654 sgd_solver.cpp:112] Iteration 53370, lr = 0.1
I0524 08:56:08.259255 11654 solver.cpp:239] Iteration 53380 (1.56805 iter/s, 6.37736s/10 iters), loss = 6.65159
I0524 08:56:08.259325 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65159 (* 1 = 6.65159 loss)
I0524 08:56:08.616700 11654 sgd_solver.cpp:112] Iteration 53380, lr = 0.1
I0524 08:56:16.957896 11654 solver.cpp:239] Iteration 53390 (1.14966 iter/s, 8.69824s/10 iters), loss = 5.92354
I0524 08:56:16.958264 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92354 (* 1 = 5.92354 loss)
I0524 08:56:17.066344 11654 sgd_solver.cpp:112] Iteration 53390, lr = 0.1
I0524 08:56:26.047755 11654 solver.cpp:239] Iteration 53400 (1.1002 iter/s, 9.08928s/10 iters), loss = 6.35703
I0524 08:56:26.047829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35703 (* 1 = 6.35703 loss)
I0524 08:56:26.048029 11654 sgd_solver.cpp:112] Iteration 53400, lr = 0.1
I0524 08:56:32.617673 11654 solver.cpp:239] Iteration 53410 (1.52216 iter/s, 6.5696s/10 iters), loss = 5.81257
I0524 08:56:32.617728 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81257 (* 1 = 5.81257 loss)
I0524 08:56:32.617748 11654 sgd_solver.cpp:112] Iteration 53410, lr = 0.1
I0524 08:56:39.725173 11654 solver.cpp:239] Iteration 53420 (1.40705 iter/s, 7.10709s/10 iters), loss = 6.5351
I0524 08:56:39.725270 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5351 (* 1 = 6.5351 loss)
I0524 08:56:39.725384 11654 sgd_solver.cpp:112] Iteration 53420, lr = 0.1
I0524 08:56:46.001250 11654 solver.cpp:239] Iteration 53430 (1.59343 iter/s, 6.27577s/10 iters), loss = 5.17143
I0524 08:56:46.001293 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.17143 (* 1 = 5.17143 loss)
I0524 08:56:46.001610 11654 sgd_solver.cpp:112] Iteration 53430, lr = 0.1
I0524 08:56:53.255334 11654 solver.cpp:239] Iteration 53440 (1.3786 iter/s, 7.25375s/10 iters), loss = 5.99297
I0524 08:56:53.255604 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99297 (* 1 = 5.99297 loss)
I0524 08:56:53.307576 11654 sgd_solver.cpp:112] Iteration 53440, lr = 0.1
I0524 08:57:02.343536 11654 solver.cpp:239] Iteration 53450 (1.1004 iter/s, 9.08764s/10 iters), loss = 6.27173
I0524 08:57:02.343592 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27173 (* 1 = 6.27173 loss)
I0524 08:57:03.129891 11654 sgd_solver.cpp:112] Iteration 53450, lr = 0.1
I0524 08:57:10.754155 11654 solver.cpp:239] Iteration 53460 (1.18903 iter/s, 8.41024s/10 iters), loss = 5.3028
I0524 08:57:10.754212 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3028 (* 1 = 5.3028 loss)
I0524 08:57:10.760937 11654 sgd_solver.cpp:112] Iteration 53460, lr = 0.1
I0524 08:57:17.262848 11654 solver.cpp:239] Iteration 53470 (1.53648 iter/s, 6.50838s/10 iters), loss = 5.93006
I0524 08:57:17.262920 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.93006 (* 1 = 5.93006 loss)
I0524 08:57:17.262940 11654 sgd_solver.cpp:112] Iteration 53470, lr = 0.1
I0524 08:57:24.636034 11654 solver.cpp:239] Iteration 53480 (1.35634 iter/s, 7.37278s/10 iters), loss = 6.31843
I0524 08:57:24.636322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31843 (* 1 = 6.31843 loss)
I0524 08:57:25.664856 11654 sgd_solver.cpp:112] Iteration 53480, lr = 0.1
I0524 08:57:32.697715 11654 solver.cpp:239] Iteration 53490 (1.24053 iter/s, 8.06107s/10 iters), loss = 6.30808
I0524 08:57:32.697834 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30808 (* 1 = 6.30808 loss)
I0524 08:57:33.179095 11654 sgd_solver.cpp:112] Iteration 53490, lr = 0.1
I0524 08:57:41.109441 11654 solver.cpp:239] Iteration 53500 (1.18887 iter/s, 8.41134s/10 iters), loss = 5.96792
I0524 08:57:41.109483 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96792 (* 1 = 5.96792 loss)
I0524 08:57:41.392323 11654 sgd_solver.cpp:112] Iteration 53500, lr = 0.1
I0524 08:57:48.210654 11654 solver.cpp:239] Iteration 53510 (1.40828 iter/s, 7.10088s/10 iters), loss = 6.53246
I0524 08:57:48.210729 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53246 (* 1 = 6.53246 loss)
I0524 08:57:48.210808 11654 sgd_solver.cpp:112] Iteration 53510, lr = 0.1
I0524 08:57:56.055007 11654 solver.cpp:239] Iteration 53520 (1.27486 iter/s, 7.84398s/10 iters), loss = 6.46629
I0524 08:57:56.055269 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46629 (* 1 = 6.46629 loss)
I0524 08:57:56.055590 11654 sgd_solver.cpp:112] Iteration 53520, lr = 0.1
I0524 08:58:03.493615 11654 solver.cpp:239] Iteration 53530 (1.34443 iter/s, 7.4381s/10 iters), loss = 6.58802
I0524 08:58:03.493686 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58802 (* 1 = 6.58802 loss)
I0524 08:58:03.493809 11654 sgd_solver.cpp:112] Iteration 53530, lr = 0.1
I0524 08:58:12.199012 11654 solver.cpp:239] Iteration 53540 (1.14877 iter/s, 8.70497s/10 iters), loss = 6.17909
I0524 08:58:12.199110 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17909 (* 1 = 6.17909 loss)
I0524 08:58:12.199167 11654 sgd_solver.cpp:112] Iteration 53540, lr = 0.1
I0524 08:58:19.248356 11654 solver.cpp:239] Iteration 53550 (1.41864 iter/s, 7.04901s/10 iters), loss = 7.86653
I0524 08:58:19.248422 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.86653 (* 1 = 7.86653 loss)
I0524 08:58:19.248647 11654 sgd_solver.cpp:112] Iteration 53550, lr = 0.1
I0524 08:58:25.900343 11654 solver.cpp:239] Iteration 53560 (1.50338 iter/s, 6.65167s/10 iters), loss = 6.38274
I0524 08:58:25.900403 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38274 (* 1 = 6.38274 loss)
I0524 08:58:25.900434 11654 sgd_solver.cpp:112] Iteration 53560, lr = 0.1
I0524 08:58:33.561756 11654 solver.cpp:239] Iteration 53570 (1.30567 iter/s, 7.65891s/10 iters), loss = 6.70241
I0524 08:58:33.562068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70241 (* 1 = 6.70241 loss)
I0524 08:58:33.562132 11654 sgd_solver.cpp:112] Iteration 53570, lr = 0.1
I0524 08:58:40.051127 11654 solver.cpp:239] Iteration 53580 (1.54121 iter/s, 6.48842s/10 iters), loss = 6.74429
I0524 08:58:40.051173 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74429 (* 1 = 6.74429 loss)
I0524 08:58:40.804983 11654 sgd_solver.cpp:112] Iteration 53580, lr = 0.1
I0524 08:58:47.049007 11654 solver.cpp:239] Iteration 53590 (1.42907 iter/s, 6.99756s/10 iters), loss = 6.53254
I0524 08:58:47.049059 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53254 (* 1 = 6.53254 loss)
I0524 08:58:47.049183 11654 sgd_solver.cpp:112] Iteration 53590, lr = 0.1
I0524 08:58:54.839483 11654 solver.cpp:239] Iteration 53600 (1.28368 iter/s, 7.79012s/10 iters), loss = 7.06305
I0524 08:58:54.839556 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.06305 (* 1 = 7.06305 loss)
I0524 08:58:54.839624 11654 sgd_solver.cpp:112] Iteration 53600, lr = 0.1
I0524 08:59:02.444274 11654 solver.cpp:239] Iteration 53610 (1.31502 iter/s, 7.60445s/10 iters), loss = 5.99114
I0524 08:59:02.444316 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99114 (* 1 = 5.99114 loss)
I0524 08:59:03.539647 11654 sgd_solver.cpp:112] Iteration 53610, lr = 0.1
I0524 08:59:12.574839 11654 solver.cpp:239] Iteration 53620 (0.987154 iter/s, 10.1301s/10 iters), loss = 6.78678
I0524 08:59:12.575150 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.78678 (* 1 = 6.78678 loss)
I0524 08:59:12.575208 11654 sgd_solver.cpp:112] Iteration 53620, lr = 0.1
I0524 08:59:18.965581 11654 solver.cpp:239] Iteration 53630 (1.56539 iter/s, 6.3882s/10 iters), loss = 5.99099
I0524 08:59:18.965626 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99099 (* 1 = 5.99099 loss)
I0524 08:59:19.144558 11654 sgd_solver.cpp:112] Iteration 53630, lr = 0.1
I0524 08:59:27.135320 11654 solver.cpp:239] Iteration 53640 (1.22409 iter/s, 8.16937s/10 iters), loss = 4.62223
I0524 08:59:27.135382 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.62223 (* 1 = 4.62223 loss)
I0524 08:59:27.135437 11654 sgd_solver.cpp:112] Iteration 53640, lr = 0.1
I0524 08:59:34.576002 11654 solver.cpp:239] Iteration 53650 (1.34403 iter/s, 7.44034s/10 iters), loss = 6.56001
I0524 08:59:34.576074 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.56001 (* 1 = 6.56001 loss)
I0524 08:59:34.576092 11654 sgd_solver.cpp:112] Iteration 53650, lr = 0.1
I0524 08:59:42.712803 11654 solver.cpp:239] Iteration 53660 (1.22937 iter/s, 8.13423s/10 iters), loss = 6.54589
I0524 08:59:42.713035 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54589 (* 1 = 6.54589 loss)
I0524 08:59:42.713099 11654 sgd_solver.cpp:112] Iteration 53660, lr = 0.1
I0524 08:59:48.958004 11654 solver.cpp:239] Iteration 53670 (1.6019 iter/s, 6.2426s/10 iters), loss = 6.40946
I0524 08:59:48.958061 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40946 (* 1 = 6.40946 loss)
I0524 08:59:48.958077 11654 sgd_solver.cpp:112] Iteration 53670, lr = 0.1
I0524 08:59:55.043022 11654 solver.cpp:239] Iteration 53680 (1.64376 iter/s, 6.08362s/10 iters), loss = 5.62403
I0524 08:59:55.043097 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62403 (* 1 = 5.62403 loss)
I0524 08:59:55.043135 11654 sgd_solver.cpp:112] Iteration 53680, lr = 0.1
I0524 09:00:02.571250 11654 solver.cpp:239] Iteration 53690 (1.3284 iter/s, 7.52787s/10 iters), loss = 5.29979
I0524 09:00:02.571290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29979 (* 1 = 5.29979 loss)
I0524 09:00:02.571303 11654 sgd_solver.cpp:112] Iteration 53690, lr = 0.1
I0524 09:00:09.230238 11654 solver.cpp:239] Iteration 53700 (1.5018 iter/s, 6.65868s/10 iters), loss = 7.36941
I0524 09:00:09.230288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.36941 (* 1 = 7.36941 loss)
I0524 09:00:09.230304 11654 sgd_solver.cpp:112] Iteration 53700, lr = 0.1
I0524 09:00:16.585264 11654 solver.cpp:239] Iteration 53710 (1.35969 iter/s, 7.35462s/10 iters), loss = 6.15062
I0524 09:00:16.585357 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15062 (* 1 = 6.15062 loss)
I0524 09:00:17.264719 11654 sgd_solver.cpp:112] Iteration 53710, lr = 0.1
I0524 09:00:28.702272 11654 solver.cpp:239] Iteration 53720 (0.825325 iter/s, 12.1164s/10 iters), loss = 6.38369
I0524 09:00:28.702328 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38369 (* 1 = 6.38369 loss)
I0524 09:00:28.702344 11654 sgd_solver.cpp:112] Iteration 53720, lr = 0.1
I0524 09:00:35.604275 11654 solver.cpp:239] Iteration 53730 (1.44939 iter/s, 6.89945s/10 iters), loss = 6.01823
I0524 09:00:35.604337 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01823 (* 1 = 6.01823 loss)
I0524 09:00:35.604380 11654 sgd_solver.cpp:112] Iteration 53730, lr = 0.1
I0524 09:00:44.476686 11654 solver.cpp:239] Iteration 53740 (1.12714 iter/s, 8.87201s/10 iters), loss = 6.50588
I0524 09:00:44.476768 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50588 (* 1 = 6.50588 loss)
I0524 09:00:44.476799 11654 sgd_solver.cpp:112] Iteration 53740, lr = 0.1
I0524 09:00:51.886279 11654 solver.cpp:239] Iteration 53750 (1.34967 iter/s, 7.40924s/10 iters), loss = 5.81607
I0524 09:00:51.886659 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81607 (* 1 = 5.81607 loss)
I0524 09:00:51.907212 11654 sgd_solver.cpp:112] Iteration 53750, lr = 0.1
I0524 09:00:59.566479 11654 solver.cpp:239] Iteration 53760 (1.30214 iter/s, 7.67964s/10 iters), loss = 6.59874
I0524 09:00:59.566536 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.59874 (* 1 = 6.59874 loss)
I0524 09:00:59.949132 11654 sgd_solver.cpp:112] Iteration 53760, lr = 0.1
I0524 09:01:06.275764 11654 solver.cpp:239] Iteration 53770 (1.49054 iter/s, 6.70897s/10 iters), loss = 6.84188
I0524 09:01:06.275811 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84188 (* 1 = 6.84188 loss)
I0524 09:01:06.276026 11654 sgd_solver.cpp:112] Iteration 53770, lr = 0.1
I0524 09:01:16.123383 11654 solver.cpp:239] Iteration 53780 (1.01552 iter/s, 9.84717s/10 iters), loss = 6.64172
I0524 09:01:16.123463 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64172 (* 1 = 6.64172 loss)
I0524 09:01:16.656687 11654 sgd_solver.cpp:112] Iteration 53780, lr = 0.1
I0524 09:01:23.708186 11654 solver.cpp:239] Iteration 53790 (1.31849 iter/s, 7.58443s/10 iters), loss = 6.92415
I0524 09:01:23.708379 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.92415 (* 1 = 6.92415 loss)
I0524 09:01:23.708603 11654 sgd_solver.cpp:112] Iteration 53790, lr = 0.1
I0524 09:01:29.807519 11654 solver.cpp:239] Iteration 53800 (1.63965 iter/s, 6.09888s/10 iters), loss = 6.40932
I0524 09:01:29.807598 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40932 (* 1 = 6.40932 loss)
I0524 09:01:29.807624 11654 sgd_solver.cpp:112] Iteration 53800, lr = 0.1
I0524 09:01:37.720299 11654 solver.cpp:239] Iteration 53810 (1.26386 iter/s, 7.91226s/10 iters), loss = 5.88876
I0524 09:01:37.720355 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88876 (* 1 = 5.88876 loss)
I0524 09:01:37.720371 11654 sgd_solver.cpp:112] Iteration 53810, lr = 0.1
I0524 09:01:44.219866 11654 solver.cpp:239] Iteration 53820 (1.53866 iter/s, 6.49917s/10 iters), loss = 6.6525
I0524 09:01:44.219956 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6525 (* 1 = 6.6525 loss)
I0524 09:01:44.220098 11654 sgd_solver.cpp:112] Iteration 53820, lr = 0.1
I0524 09:01:51.861912 11654 solver.cpp:239] Iteration 53830 (1.30861 iter/s, 7.64167s/10 iters), loss = 6.0817
I0524 09:01:51.861999 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0817 (* 1 = 6.0817 loss)
I0524 09:01:51.862102 11654 sgd_solver.cpp:112] Iteration 53830, lr = 0.1
I0524 09:01:59.717720 11654 solver.cpp:239] Iteration 53840 (1.273 iter/s, 7.85543s/10 iters), loss = 5.40148
I0524 09:01:59.717892 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40148 (* 1 = 5.40148 loss)
I0524 09:01:59.862732 11654 sgd_solver.cpp:112] Iteration 53840, lr = 0.1
I0524 09:02:08.758760 11654 solver.cpp:239] Iteration 53850 (1.10613 iter/s, 9.04053s/10 iters), loss = 6.98484
I0524 09:02:08.758826 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98484 (* 1 = 6.98484 loss)
I0524 09:02:08.758970 11654 sgd_solver.cpp:112] Iteration 53850, lr = 0.1
I0524 09:02:16.610688 11654 solver.cpp:239] Iteration 53860 (1.27363 iter/s, 7.85156s/10 iters), loss = 5.83336
I0524 09:02:16.610761 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83336 (* 1 = 5.83336 loss)
I0524 09:02:16.610781 11654 sgd_solver.cpp:112] Iteration 53860, lr = 0.1
I0524 09:02:24.894213 11654 solver.cpp:239] Iteration 53870 (1.2076 iter/s, 8.28087s/10 iters), loss = 5.3743
I0524 09:02:24.894284 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3743 (* 1 = 5.3743 loss)
I0524 09:02:24.894304 11654 sgd_solver.cpp:112] Iteration 53870, lr = 0.1
I0524 09:02:31.626005 11654 solver.cpp:239] Iteration 53880 (1.48603 iter/s, 6.72932s/10 iters), loss = 5.98691
I0524 09:02:31.626281 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98691 (* 1 = 5.98691 loss)
I0524 09:02:31.626346 11654 sgd_solver.cpp:112] Iteration 53880, lr = 0.1
I0524 09:02:38.674150 11654 solver.cpp:239] Iteration 53890 (1.41893 iter/s, 7.04759s/10 iters), loss = 5.63902
I0524 09:02:38.674238 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63902 (* 1 = 5.63902 loss)
I0524 09:02:38.674420 11654 sgd_solver.cpp:112] Iteration 53890, lr = 0.1
I0524 09:02:45.481880 11654 solver.cpp:239] Iteration 53900 (1.46899 iter/s, 6.8074s/10 iters), loss = 5.94756
I0524 09:02:45.481930 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94756 (* 1 = 5.94756 loss)
I0524 09:02:45.481945 11654 sgd_solver.cpp:112] Iteration 53900, lr = 0.1
I0524 09:02:51.899272 11654 solver.cpp:239] Iteration 53910 (1.55834 iter/s, 6.41709s/10 iters), loss = 4.89445
I0524 09:02:51.899345 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.89445 (* 1 = 4.89445 loss)
I0524 09:02:52.363577 11654 sgd_solver.cpp:112] Iteration 53910, lr = 0.1
I0524 09:02:59.996062 11654 solver.cpp:239] Iteration 53920 (1.23512 iter/s, 8.09639s/10 iters), loss = 6.02188
I0524 09:02:59.996141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02188 (* 1 = 6.02188 loss)
I0524 09:02:59.996165 11654 sgd_solver.cpp:112] Iteration 53920, lr = 0.1
I0524 09:03:08.407135 11654 solver.cpp:239] Iteration 53930 (1.18928 iter/s, 8.40847s/10 iters), loss = 5.88863
I0524 09:03:08.407356 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88863 (* 1 = 5.88863 loss)
I0524 09:03:08.407394 11654 sgd_solver.cpp:112] Iteration 53930, lr = 0.1
I0524 09:03:15.675676 11654 solver.cpp:239] Iteration 53940 (1.37589 iter/s, 7.26803s/10 iters), loss = 7.22883
I0524 09:03:15.675783 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22883 (* 1 = 7.22883 loss)
I0524 09:03:15.742463 11654 sgd_solver.cpp:112] Iteration 53940, lr = 0.1
I0524 09:03:22.845350 11654 solver.cpp:239] Iteration 53950 (1.39484 iter/s, 7.16926s/10 iters), loss = 6.48047
I0524 09:03:22.845453 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48047 (* 1 = 6.48047 loss)
I0524 09:03:22.845484 11654 sgd_solver.cpp:112] Iteration 53950, lr = 0.1
I0524 09:03:29.798301 11654 solver.cpp:239] Iteration 53960 (1.43831 iter/s, 6.95259s/10 iters), loss = 6.41403
I0524 09:03:29.798388 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41403 (* 1 = 6.41403 loss)
I0524 09:03:29.798444 11654 sgd_solver.cpp:112] Iteration 53960, lr = 0.1
I0524 09:03:36.815685 11654 solver.cpp:239] Iteration 53970 (1.4251 iter/s, 7.01705s/10 iters), loss = 5.69637
I0524 09:03:36.815728 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69637 (* 1 = 5.69637 loss)
I0524 09:03:37.045202 11654 sgd_solver.cpp:112] Iteration 53970, lr = 0.1
I0524 09:03:44.802494 11654 solver.cpp:239] Iteration 53980 (1.25212 iter/s, 7.98644s/10 iters), loss = 7.13241
I0524 09:03:44.802814 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13241 (* 1 = 7.13241 loss)
I0524 09:03:45.554363 11654 sgd_solver.cpp:112] Iteration 53980, lr = 0.1
I0524 09:03:52.329260 11654 solver.cpp:239] Iteration 53990 (1.32869 iter/s, 7.5262s/10 iters), loss = 5.21314
I0524 09:03:52.329331 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.21314 (* 1 = 5.21314 loss)
I0524 09:03:52.329352 11654 sgd_solver.cpp:112] Iteration 53990, lr = 0.1
I0524 09:04:03.109040 11654 solver.cpp:239] Iteration 54000 (0.92771 iter/s, 10.7792s/10 iters), loss = 5.41165
I0524 09:04:03.109102 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.41165 (* 1 = 5.41165 loss)
I0524 09:04:03.708559 11654 sgd_solver.cpp:112] Iteration 54000, lr = 0.1
I0524 09:04:12.289153 11654 solver.cpp:239] Iteration 54010 (1.08936 iter/s, 9.17967s/10 iters), loss = 6.27168
I0524 09:04:12.289244 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27168 (* 1 = 6.27168 loss)
I0524 09:04:12.289278 11654 sgd_solver.cpp:112] Iteration 54010, lr = 0.1
I0524 09:04:18.803622 11654 solver.cpp:239] Iteration 54020 (1.53564 iter/s, 6.51194s/10 iters), loss = 6.73361
I0524 09:04:18.803840 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.73361 (* 1 = 6.73361 loss)
I0524 09:04:18.804075 11654 sgd_solver.cpp:112] Iteration 54020, lr = 0.1
I0524 09:04:24.785750 11654 solver.cpp:239] Iteration 54030 (1.67178 iter/s, 5.98165s/10 iters), loss = 5.97758
I0524 09:04:24.785826 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97758 (* 1 = 5.97758 loss)
I0524 09:04:24.786044 11654 sgd_solver.cpp:112] Iteration 54030, lr = 0.1
I0524 09:04:32.836093 11654 solver.cpp:239] Iteration 54040 (1.24224 iter/s, 8.04996s/10 iters), loss = 6.07638
I0524 09:04:32.836167 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07638 (* 1 = 6.07638 loss)
I0524 09:04:32.911222 11654 sgd_solver.cpp:112] Iteration 54040, lr = 0.1
I0524 09:04:40.270670 11654 solver.cpp:239] Iteration 54050 (1.34513 iter/s, 7.43422s/10 iters), loss = 5.94744
I0524 09:04:40.270758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.94744 (* 1 = 5.94744 loss)
I0524 09:04:40.553400 11654 sgd_solver.cpp:112] Iteration 54050, lr = 0.1
I0524 09:04:49.017066 11654 solver.cpp:239] Iteration 54060 (1.14338 iter/s, 8.74597s/10 iters), loss = 6.2508
I0524 09:04:49.017426 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2508 (* 1 = 6.2508 loss)
I0524 09:04:49.017534 11654 sgd_solver.cpp:112] Iteration 54060, lr = 0.1
I0524 09:04:55.761973 11654 solver.cpp:239] Iteration 54070 (1.48271 iter/s, 6.74441s/10 iters), loss = 6.90401
I0524 09:04:55.762069 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90401 (* 1 = 6.90401 loss)
I0524 09:04:55.762097 11654 sgd_solver.cpp:112] Iteration 54070, lr = 0.1
I0524 09:05:03.642431 11654 solver.cpp:239] Iteration 54080 (1.26937 iter/s, 7.8779s/10 iters), loss = 6.20473
I0524 09:05:03.642490 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20473 (* 1 = 6.20473 loss)
I0524 09:05:03.652496 11654 sgd_solver.cpp:112] Iteration 54080, lr = 0.1
I0524 09:05:12.098953 11654 solver.cpp:239] Iteration 54090 (1.18257 iter/s, 8.45614s/10 iters), loss = 6.35467
I0524 09:05:12.099028 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35467 (* 1 = 6.35467 loss)
I0524 09:05:12.099056 11654 sgd_solver.cpp:112] Iteration 54090, lr = 0.1
I0524 09:05:19.215284 11654 solver.cpp:239] Iteration 54100 (1.40529 iter/s, 7.11596s/10 iters), loss = 6.1606
I0524 09:05:19.215489 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1606 (* 1 = 6.1606 loss)
I0524 09:05:19.215540 11654 sgd_solver.cpp:112] Iteration 54100, lr = 0.1
I0524 09:05:27.794317 11654 solver.cpp:239] Iteration 54110 (1.16598 iter/s, 8.57646s/10 iters), loss = 5.60751
I0524 09:05:27.794389 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60751 (* 1 = 5.60751 loss)
I0524 09:05:27.794407 11654 sgd_solver.cpp:112] Iteration 54110, lr = 0.1
I0524 09:05:36.924180 11654 solver.cpp:239] Iteration 54120 (1.09538 iter/s, 9.12928s/10 iters), loss = 6.04538
I0524 09:05:36.924340 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04538 (* 1 = 6.04538 loss)
I0524 09:05:36.925040 11654 sgd_solver.cpp:112] Iteration 54120, lr = 0.1
I0524 09:05:43.777837 11654 solver.cpp:239] Iteration 54130 (1.45915 iter/s, 6.85329s/10 iters), loss = 6.28456
I0524 09:05:43.777894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28456 (* 1 = 6.28456 loss)
I0524 09:05:43.778153 11654 sgd_solver.cpp:112] Iteration 54130, lr = 0.1
I0524 09:05:51.513967 11654 solver.cpp:239] Iteration 54140 (1.2927 iter/s, 7.73574s/10 iters), loss = 6.09039
I0524 09:05:51.514185 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09039 (* 1 = 6.09039 loss)
I0524 09:05:51.570574 11654 sgd_solver.cpp:112] Iteration 54140, lr = 0.1
I0524 09:05:58.374111 11654 solver.cpp:239] Iteration 54150 (1.4578 iter/s, 6.85967s/10 iters), loss = 6.55685
I0524 09:05:58.374174 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55685 (* 1 = 6.55685 loss)
I0524 09:05:58.426041 11654 sgd_solver.cpp:112] Iteration 54150, lr = 0.1
I0524 09:06:05.752864 11654 solver.cpp:239] Iteration 54160 (1.35531 iter/s, 7.37839s/10 iters), loss = 6.63429
I0524 09:06:05.752923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63429 (* 1 = 6.63429 loss)
I0524 09:06:05.752943 11654 sgd_solver.cpp:112] Iteration 54160, lr = 0.1
I0524 09:06:13.397100 11654 solver.cpp:239] Iteration 54170 (1.30862 iter/s, 7.64167s/10 iters), loss = 6.36161
I0524 09:06:13.397186 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36161 (* 1 = 6.36161 loss)
I0524 09:06:13.645002 11654 sgd_solver.cpp:112] Iteration 54170, lr = 0.1
I0524 09:06:23.632238 11654 solver.cpp:239] Iteration 54180 (0.977071 iter/s, 10.2347s/10 iters), loss = 5.55445
I0524 09:06:23.632408 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55445 (* 1 = 5.55445 loss)
I0524 09:06:24.404530 11654 sgd_solver.cpp:112] Iteration 54180, lr = 0.1
I0524 09:06:33.537258 11654 solver.cpp:239] Iteration 54190 (1.00965 iter/s, 9.90446s/10 iters), loss = 6.15752
I0524 09:06:33.537322 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15752 (* 1 = 6.15752 loss)
I0524 09:06:34.824404 11654 sgd_solver.cpp:112] Iteration 54190, lr = 0.1
I0524 09:06:43.115128 11654 solver.cpp:239] Iteration 54200 (1.04412 iter/s, 9.57743s/10 iters), loss = 5.63561
I0524 09:06:43.115167 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63561 (* 1 = 5.63561 loss)
I0524 09:06:43.132974 11654 sgd_solver.cpp:112] Iteration 54200, lr = 0.1
I0524 09:06:51.835490 11654 solver.cpp:239] Iteration 54210 (1.14679 iter/s, 8.71997s/10 iters), loss = 7.58805
I0524 09:06:51.835558 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58805 (* 1 = 7.58805 loss)
I0524 09:06:51.836544 11654 sgd_solver.cpp:112] Iteration 54210, lr = 0.1
I0524 09:06:59.187336 11654 solver.cpp:239] Iteration 54220 (1.36027 iter/s, 7.3515s/10 iters), loss = 6.03616
I0524 09:06:59.187589 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03616 (* 1 = 6.03616 loss)
I0524 09:07:00.012692 11654 sgd_solver.cpp:112] Iteration 54220, lr = 0.1
I0524 09:07:08.131924 11654 solver.cpp:239] Iteration 54230 (1.11806 iter/s, 8.94403s/10 iters), loss = 6.13836
I0524 09:07:08.132000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13836 (* 1 = 6.13836 loss)
I0524 09:07:08.132022 11654 sgd_solver.cpp:112] Iteration 54230, lr = 0.1
I0524 09:07:14.886822 11654 solver.cpp:239] Iteration 54240 (1.48048 iter/s, 6.75454s/10 iters), loss = 6.98428
I0524 09:07:14.886894 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.98428 (* 1 = 6.98428 loss)
I0524 09:07:14.887187 11654 sgd_solver.cpp:112] Iteration 54240, lr = 0.1
I0524 09:07:23.062942 11654 solver.cpp:239] Iteration 54250 (1.22314 iter/s, 8.17569s/10 iters), loss = 5.26354
I0524 09:07:23.063040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26354 (* 1 = 5.26354 loss)
I0524 09:07:23.064765 11654 sgd_solver.cpp:112] Iteration 54250, lr = 0.1
I0524 09:07:31.264514 11654 solver.cpp:239] Iteration 54260 (1.21934 iter/s, 8.20116s/10 iters), loss = 5.38904
I0524 09:07:31.264663 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.38904 (* 1 = 5.38904 loss)
I0524 09:07:31.264705 11654 sgd_solver.cpp:112] Iteration 54260, lr = 0.1
I0524 09:07:38.838686 11654 solver.cpp:239] Iteration 54270 (1.32035 iter/s, 7.57373s/10 iters), loss = 6.7767
I0524 09:07:38.838752 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7767 (* 1 = 6.7767 loss)
I0524 09:07:39.255667 11654 sgd_solver.cpp:112] Iteration 54270, lr = 0.1
I0524 09:07:46.151262 11654 solver.cpp:239] Iteration 54280 (1.36758 iter/s, 7.31221s/10 iters), loss = 6.28536
I0524 09:07:46.151367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28536 (* 1 = 6.28536 loss)
I0524 09:07:46.151401 11654 sgd_solver.cpp:112] Iteration 54280, lr = 0.1
I0524 09:07:53.429481 11654 solver.cpp:239] Iteration 54290 (1.37404 iter/s, 7.27781s/10 iters), loss = 5.96948
I0524 09:07:53.429534 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96948 (* 1 = 5.96948 loss)
I0524 09:07:54.074301 11654 sgd_solver.cpp:112] Iteration 54290, lr = 0.1
I0524 09:08:01.897575 11654 solver.cpp:239] Iteration 54300 (1.18097 iter/s, 8.46764s/10 iters), loss = 5.85323
I0524 09:08:01.897895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85323 (* 1 = 5.85323 loss)
I0524 09:08:01.925324 11654 sgd_solver.cpp:112] Iteration 54300, lr = 0.1
I0524 09:08:08.613243 11654 solver.cpp:239] Iteration 54310 (1.48918 iter/s, 6.71509s/10 iters), loss = 5.01344
I0524 09:08:08.613306 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.01344 (* 1 = 5.01344 loss)
I0524 09:08:08.613344 11654 sgd_solver.cpp:112] Iteration 54310, lr = 0.1
I0524 09:08:18.242007 11654 solver.cpp:239] Iteration 54320 (1.0386 iter/s, 9.62831s/10 iters), loss = 5.30483
I0524 09:08:18.242058 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30483 (* 1 = 5.30483 loss)
I0524 09:08:18.242081 11654 sgd_solver.cpp:112] Iteration 54320, lr = 0.1
I0524 09:08:26.215656 11654 solver.cpp:239] Iteration 54330 (1.2542 iter/s, 7.97323s/10 iters), loss = 6.10568
I0524 09:08:26.215731 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10568 (* 1 = 6.10568 loss)
I0524 09:08:26.217449 11654 sgd_solver.cpp:112] Iteration 54330, lr = 0.1
I0524 09:08:36.006450 11654 solver.cpp:239] Iteration 54340 (1.02141 iter/s, 9.79036s/10 iters), loss = 6.66155
I0524 09:08:36.006685 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66155 (* 1 = 6.66155 loss)
I0524 09:08:36.006753 11654 sgd_solver.cpp:112] Iteration 54340, lr = 0.1
I0524 09:08:42.901222 11654 solver.cpp:239] Iteration 54350 (1.45048 iter/s, 6.89428s/10 iters), loss = 5.98327
I0524 09:08:42.901266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98327 (* 1 = 5.98327 loss)
I0524 09:08:42.901422 11654 sgd_solver.cpp:112] Iteration 54350, lr = 0.1
I0524 09:08:50.316427 11654 solver.cpp:239] Iteration 54360 (1.34864 iter/s, 7.41487s/10 iters), loss = 6.75181
I0524 09:08:50.316499 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.75181 (* 1 = 6.75181 loss)
I0524 09:08:50.316519 11654 sgd_solver.cpp:112] Iteration 54360, lr = 0.1
I0524 09:08:56.861062 11654 solver.cpp:239] Iteration 54370 (1.52805 iter/s, 6.54427s/10 iters), loss = 6.39857
I0524 09:08:56.861114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39857 (* 1 = 6.39857 loss)
I0524 09:08:56.861299 11654 sgd_solver.cpp:112] Iteration 54370, lr = 0.1
I0524 09:09:03.856230 11654 solver.cpp:239] Iteration 54380 (1.42963 iter/s, 6.99484s/10 iters), loss = 4.43957
I0524 09:09:03.856288 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.43957 (* 1 = 4.43957 loss)
I0524 09:09:03.905751 11654 sgd_solver.cpp:112] Iteration 54380, lr = 0.1
I0524 09:09:10.171044 11654 solver.cpp:239] Iteration 54390 (1.58365 iter/s, 6.31451s/10 iters), loss = 6.08903
I0524 09:09:10.171211 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08903 (* 1 = 6.08903 loss)
I0524 09:09:10.279469 11654 sgd_solver.cpp:112] Iteration 54390, lr = 0.1
I0524 09:09:18.252727 11654 solver.cpp:239] Iteration 54400 (1.23744 iter/s, 8.08121s/10 iters), loss = 6.03725
I0524 09:09:18.252774 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.03725 (* 1 = 6.03725 loss)
I0524 09:09:18.501554 11654 sgd_solver.cpp:112] Iteration 54400, lr = 0.1
I0524 09:09:28.104856 11654 solver.cpp:239] Iteration 54410 (1.01505 iter/s, 9.85169s/10 iters), loss = 7.58068
I0524 09:09:28.104912 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.58068 (* 1 = 7.58068 loss)
I0524 09:09:28.104930 11654 sgd_solver.cpp:112] Iteration 54410, lr = 0.1
I0524 09:09:35.511651 11654 solver.cpp:239] Iteration 54420 (1.35018 iter/s, 7.40639s/10 iters), loss = 5.95369
I0524 09:09:35.511705 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95369 (* 1 = 5.95369 loss)
I0524 09:09:35.511869 11654 sgd_solver.cpp:112] Iteration 54420, lr = 0.1
I0524 09:09:41.771335 11654 solver.cpp:239] Iteration 54430 (1.5976 iter/s, 6.25937s/10 iters), loss = 6.33448
I0524 09:09:41.771571 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33448 (* 1 = 6.33448 loss)
I0524 09:09:41.771643 11654 sgd_solver.cpp:112] Iteration 54430, lr = 0.1
I0524 09:09:48.449229 11654 solver.cpp:239] Iteration 54440 (1.49759 iter/s, 6.67739s/10 iters), loss = 5.6939
I0524 09:09:48.449295 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6939 (* 1 = 5.6939 loss)
I0524 09:09:48.449404 11654 sgd_solver.cpp:112] Iteration 54440, lr = 0.1
I0524 09:09:55.624995 11654 solver.cpp:239] Iteration 54450 (1.39365 iter/s, 7.17542s/10 iters), loss = 6.33819
I0524 09:09:55.625068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33819 (* 1 = 6.33819 loss)
I0524 09:09:55.625381 11654 sgd_solver.cpp:112] Iteration 54450, lr = 0.1
I0524 09:10:03.591203 11654 solver.cpp:239] Iteration 54460 (1.25536 iter/s, 7.96584s/10 iters), loss = 6.28186
I0524 09:10:03.591249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28186 (* 1 = 6.28186 loss)
I0524 09:10:03.591264 11654 sgd_solver.cpp:112] Iteration 54460, lr = 0.1
I0524 09:10:12.464221 11654 solver.cpp:239] Iteration 54470 (1.12707 iter/s, 8.87254s/10 iters), loss = 6.28504
I0524 09:10:12.464483 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28504 (* 1 = 6.28504 loss)
I0524 09:10:12.515024 11654 sgd_solver.cpp:112] Iteration 54470, lr = 0.1
I0524 09:10:19.558943 11654 solver.cpp:239] Iteration 54480 (1.4096 iter/s, 7.09422s/10 iters), loss = 5.89485
I0524 09:10:19.559000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89485 (* 1 = 5.89485 loss)
I0524 09:10:19.559018 11654 sgd_solver.cpp:112] Iteration 54480, lr = 0.1
I0524 09:10:27.219419 11654 solver.cpp:239] Iteration 54490 (1.30548 iter/s, 7.66004s/10 iters), loss = 6.3062
I0524 09:10:27.219514 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.3062 (* 1 = 6.3062 loss)
I0524 09:10:27.219558 11654 sgd_solver.cpp:112] Iteration 54490, lr = 0.1
I0524 09:10:33.425734 11654 solver.cpp:239] Iteration 54500 (1.61189 iter/s, 6.20388s/10 iters), loss = 6.35105
I0524 09:10:33.425801 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.35105 (* 1 = 6.35105 loss)
I0524 09:10:33.426151 11654 sgd_solver.cpp:112] Iteration 54500, lr = 0.1
I0524 09:10:41.478592 11654 solver.cpp:239] Iteration 54510 (1.24185 iter/s, 8.05247s/10 iters), loss = 5.00691
I0524 09:10:41.478663 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.00691 (* 1 = 5.00691 loss)
I0524 09:10:41.892618 11654 sgd_solver.cpp:112] Iteration 54510, lr = 0.1
I0524 09:10:48.223778 11654 solver.cpp:239] Iteration 54520 (1.48261 iter/s, 6.74486s/10 iters), loss = 5.36806
I0524 09:10:48.224012 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.36806 (* 1 = 5.36806 loss)
I0524 09:10:48.224071 11654 sgd_solver.cpp:112] Iteration 54520, lr = 0.1
I0524 09:10:55.417582 11654 solver.cpp:239] Iteration 54530 (1.39018 iter/s, 7.1933s/10 iters), loss = 6.37179
I0524 09:10:55.417632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37179 (* 1 = 6.37179 loss)
I0524 09:10:55.417680 11654 sgd_solver.cpp:112] Iteration 54530, lr = 0.1
I0524 09:11:02.778569 11654 solver.cpp:239] Iteration 54540 (1.35858 iter/s, 7.36064s/10 iters), loss = 6.23736
I0524 09:11:02.778662 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23736 (* 1 = 6.23736 loss)
I0524 09:11:02.778805 11654 sgd_solver.cpp:112] Iteration 54540, lr = 0.1
I0524 09:11:11.294409 11654 solver.cpp:239] Iteration 54550 (1.17434 iter/s, 8.51542s/10 iters), loss = 6.43765
I0524 09:11:11.294482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43765 (* 1 = 6.43765 loss)
I0524 09:11:11.295600 11654 sgd_solver.cpp:112] Iteration 54550, lr = 0.1
I0524 09:11:18.254557 11654 solver.cpp:239] Iteration 54560 (1.43682 iter/s, 6.9598s/10 iters), loss = 5.39577
I0524 09:11:18.254770 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.39577 (* 1 = 5.39577 loss)
I0524 09:11:18.289193 11654 sgd_solver.cpp:112] Iteration 54560, lr = 0.1
I0524 09:11:24.912744 11654 solver.cpp:239] Iteration 54570 (1.50202 iter/s, 6.65772s/10 iters), loss = 6.02566
I0524 09:11:24.912832 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02566 (* 1 = 6.02566 loss)
I0524 09:11:24.913079 11654 sgd_solver.cpp:112] Iteration 54570, lr = 0.1
I0524 09:11:31.669175 11654 solver.cpp:239] Iteration 54580 (1.48014 iter/s, 6.75611s/10 iters), loss = 5.66579
I0524 09:11:31.669224 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66579 (* 1 = 5.66579 loss)
I0524 09:11:31.669370 11654 sgd_solver.cpp:112] Iteration 54580, lr = 0.1
I0524 09:11:38.417114 11654 solver.cpp:239] Iteration 54590 (1.48201 iter/s, 6.74759s/10 iters), loss = 6.46559
I0524 09:11:38.417186 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46559 (* 1 = 6.46559 loss)
I0524 09:11:38.417527 11654 sgd_solver.cpp:112] Iteration 54590, lr = 0.1
I0524 09:11:44.788121 11654 solver.cpp:239] Iteration 54600 (1.56969 iter/s, 6.37069s/10 iters), loss = 6.07936
I0524 09:11:44.788187 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07936 (* 1 = 6.07936 loss)
I0524 09:11:44.788357 11654 sgd_solver.cpp:112] Iteration 54600, lr = 0.1
I0524 09:11:51.100919 11654 solver.cpp:239] Iteration 54610 (1.58416 iter/s, 6.31248s/10 iters), loss = 6.07285
I0524 09:11:51.101083 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.07285 (* 1 = 6.07285 loss)
I0524 09:11:51.101117 11654 sgd_solver.cpp:112] Iteration 54610, lr = 0.1
I0524 09:11:58.866077 11654 solver.cpp:239] Iteration 54620 (1.28788 iter/s, 7.7647s/10 iters), loss = 6.63333
I0524 09:11:58.866130 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63333 (* 1 = 6.63333 loss)
I0524 09:11:58.866207 11654 sgd_solver.cpp:112] Iteration 54620, lr = 0.1
I0524 09:12:08.145407 11654 solver.cpp:239] Iteration 54630 (1.07771 iter/s, 9.27892s/10 iters), loss = 5.73132
I0524 09:12:08.145470 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73132 (* 1 = 5.73132 loss)
I0524 09:12:08.253648 11654 sgd_solver.cpp:112] Iteration 54630, lr = 0.1
I0524 09:12:16.299150 11654 solver.cpp:239] Iteration 54640 (1.22649 iter/s, 8.15337s/10 iters), loss = 7.00488
I0524 09:12:16.299193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.00488 (* 1 = 7.00488 loss)
I0524 09:12:17.157438 11654 sgd_solver.cpp:112] Iteration 54640, lr = 0.1
I0524 09:12:25.147943 11654 solver.cpp:239] Iteration 54650 (1.13015 iter/s, 8.84838s/10 iters), loss = 5.95484
I0524 09:12:25.148116 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95484 (* 1 = 5.95484 loss)
I0524 09:12:25.148138 11654 sgd_solver.cpp:112] Iteration 54650, lr = 0.1
I0524 09:12:32.698396 11654 solver.cpp:239] Iteration 54660 (1.32451 iter/s, 7.54997s/10 iters), loss = 5.38935
I0524 09:12:32.698442 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.38935 (* 1 = 5.38935 loss)
I0524 09:12:32.698457 11654 sgd_solver.cpp:112] Iteration 54660, lr = 0.1
I0524 09:12:39.574990 11654 solver.cpp:239] Iteration 54670 (1.45429 iter/s, 6.87621s/10 iters), loss = 6.45149
I0524 09:12:39.575042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45149 (* 1 = 6.45149 loss)
I0524 09:12:39.643437 11654 sgd_solver.cpp:112] Iteration 54670, lr = 0.1
I0524 09:12:47.768801 11654 solver.cpp:239] Iteration 54680 (1.22049 iter/s, 8.19343s/10 iters), loss = 6.8466
I0524 09:12:47.768908 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.8466 (* 1 = 6.8466 loss)
I0524 09:12:47.768932 11654 sgd_solver.cpp:112] Iteration 54680, lr = 0.1
I0524 09:12:55.148205 11654 solver.cpp:239] Iteration 54690 (1.3552 iter/s, 7.37897s/10 iters), loss = 5.88735
I0524 09:12:55.148459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88735 (* 1 = 5.88735 loss)
I0524 09:12:55.148502 11654 sgd_solver.cpp:112] Iteration 54690, lr = 0.1
I0524 09:13:02.979171 11654 solver.cpp:239] Iteration 54700 (1.27708 iter/s, 7.83038s/10 iters), loss = 6.4241
I0524 09:13:02.979233 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4241 (* 1 = 6.4241 loss)
I0524 09:13:02.979302 11654 sgd_solver.cpp:112] Iteration 54700, lr = 0.1
I0524 09:13:11.115226 11654 solver.cpp:239] Iteration 54710 (1.22916 iter/s, 8.13562s/10 iters), loss = 5.48373
I0524 09:13:11.115314 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.48373 (* 1 = 5.48373 loss)
I0524 09:13:11.115337 11654 sgd_solver.cpp:112] Iteration 54710, lr = 0.1
I0524 09:13:19.015599 11654 solver.cpp:239] Iteration 54720 (1.26588 iter/s, 7.89965s/10 iters), loss = 6.05709
I0524 09:13:19.015668 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.05709 (* 1 = 6.05709 loss)
I0524 09:13:19.650933 11654 sgd_solver.cpp:112] Iteration 54720, lr = 0.1
I0524 09:13:26.801189 11654 solver.cpp:239] Iteration 54730 (1.28449 iter/s, 7.78521s/10 iters), loss = 5.61864
I0524 09:13:26.801383 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61864 (* 1 = 5.61864 loss)
I0524 09:13:27.077458 11654 sgd_solver.cpp:112] Iteration 54730, lr = 0.1
I0524 09:13:34.408216 11654 solver.cpp:239] Iteration 54740 (1.31465 iter/s, 7.60656s/10 iters), loss = 5.02594
I0524 09:13:34.408285 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.02594 (* 1 = 5.02594 loss)
I0524 09:13:34.408396 11654 sgd_solver.cpp:112] Iteration 54740, lr = 0.1
I0524 09:13:40.863824 11654 solver.cpp:239] Iteration 54750 (1.54912 iter/s, 6.45529s/10 iters), loss = 6.84347
I0524 09:13:40.863879 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84347 (* 1 = 6.84347 loss)
I0524 09:13:41.130066 11654 sgd_solver.cpp:112] Iteration 54750, lr = 0.1
I0524 09:13:49.054224 11654 solver.cpp:239] Iteration 54760 (1.221 iter/s, 8.18999s/10 iters), loss = 7.22721
I0524 09:13:49.054335 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22721 (* 1 = 7.22721 loss)
I0524 09:13:49.778110 11654 sgd_solver.cpp:112] Iteration 54760, lr = 0.1
I0524 09:13:57.991997 11654 solver.cpp:239] Iteration 54770 (1.1189 iter/s, 8.93737s/10 iters), loss = 5.44829
I0524 09:13:57.992146 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44829 (* 1 = 5.44829 loss)
I0524 09:13:57.992177 11654 sgd_solver.cpp:112] Iteration 54770, lr = 0.1
I0524 09:14:05.145473 11654 solver.cpp:239] Iteration 54780 (1.39801 iter/s, 7.15302s/10 iters), loss = 7.48329
I0524 09:14:05.145556 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.48329 (* 1 = 7.48329 loss)
I0524 09:14:05.145898 11654 sgd_solver.cpp:112] Iteration 54780, lr = 0.1
I0524 09:14:12.719106 11654 solver.cpp:239] Iteration 54790 (1.32044 iter/s, 7.57325s/10 iters), loss = 6.17507
I0524 09:14:12.719193 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17507 (* 1 = 6.17507 loss)
I0524 09:14:12.719642 11654 sgd_solver.cpp:112] Iteration 54790, lr = 0.1
I0524 09:14:20.510097 11654 solver.cpp:239] Iteration 54800 (1.2836 iter/s, 7.79062s/10 iters), loss = 6.57322
I0524 09:14:20.510150 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.57322 (* 1 = 6.57322 loss)
I0524 09:14:20.510166 11654 sgd_solver.cpp:112] Iteration 54800, lr = 0.1
I0524 09:14:29.235409 11654 solver.cpp:239] Iteration 54810 (1.14614 iter/s, 8.7249s/10 iters), loss = 5.18426
I0524 09:14:29.235584 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.18426 (* 1 = 5.18426 loss)
I0524 09:14:29.236181 11654 sgd_solver.cpp:112] Iteration 54810, lr = 0.1
I0524 09:14:37.361873 11654 solver.cpp:239] Iteration 54820 (1.23062 iter/s, 8.12598s/10 iters), loss = 5.6603
I0524 09:14:37.361935 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6603 (* 1 = 5.6603 loss)
I0524 09:14:37.386235 11654 sgd_solver.cpp:112] Iteration 54820, lr = 0.1
I0524 09:14:44.458578 11654 solver.cpp:239] Iteration 54830 (1.40917 iter/s, 7.09637s/10 iters), loss = 6.40765
I0524 09:14:44.458640 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40765 (* 1 = 6.40765 loss)
I0524 09:14:44.458678 11654 sgd_solver.cpp:112] Iteration 54830, lr = 0.1
I0524 09:14:51.874972 11654 solver.cpp:239] Iteration 54840 (1.34883 iter/s, 7.41383s/10 iters), loss = 6.29488
I0524 09:14:51.875061 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29488 (* 1 = 6.29488 loss)
I0524 09:14:51.875149 11654 sgd_solver.cpp:112] Iteration 54840, lr = 0.1
I0524 09:14:58.129138 11654 solver.cpp:239] Iteration 54850 (1.59902 iter/s, 6.25381s/10 iters), loss = 5.84035
I0524 09:14:58.129271 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84035 (* 1 = 5.84035 loss)
I0524 09:14:58.158537 11654 sgd_solver.cpp:112] Iteration 54850, lr = 0.1
I0524 09:15:06.822016 11654 solver.cpp:239] Iteration 54860 (1.15043 iter/s, 8.69243s/10 iters), loss = 5.63598
I0524 09:15:06.822274 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63598 (* 1 = 5.63598 loss)
I0524 09:15:07.075206 11654 sgd_solver.cpp:112] Iteration 54860, lr = 0.1
I0524 09:15:14.642042 11654 solver.cpp:239] Iteration 54870 (1.27886 iter/s, 7.81944s/10 iters), loss = 5.95376
I0524 09:15:14.642166 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95376 (* 1 = 5.95376 loss)
I0524 09:15:14.642262 11654 sgd_solver.cpp:112] Iteration 54870, lr = 0.1
I0524 09:15:21.105557 11654 solver.cpp:239] Iteration 54880 (1.54722 iter/s, 6.46319s/10 iters), loss = 5.42145
I0524 09:15:21.105624 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42145 (* 1 = 5.42145 loss)
I0524 09:15:21.796973 11654 sgd_solver.cpp:112] Iteration 54880, lr = 0.1
I0524 09:15:29.294140 11654 solver.cpp:239] Iteration 54890 (1.22127 iter/s, 8.1882s/10 iters), loss = 6.25066
I0524 09:15:29.294183 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25066 (* 1 = 6.25066 loss)
I0524 09:15:29.294212 11654 sgd_solver.cpp:112] Iteration 54890, lr = 0.1
I0524 09:15:35.633663 11654 solver.cpp:239] Iteration 54900 (1.57748 iter/s, 6.33922s/10 iters), loss = 6.18251
I0524 09:15:35.633730 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18251 (* 1 = 6.18251 loss)
I0524 09:15:35.633750 11654 sgd_solver.cpp:112] Iteration 54900, lr = 0.1
I0524 09:15:45.615175 11654 solver.cpp:239] Iteration 54910 (1.0019 iter/s, 9.981s/10 iters), loss = 5.98732
I0524 09:15:45.615427 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98732 (* 1 = 5.98732 loss)
I0524 09:15:45.615490 11654 sgd_solver.cpp:112] Iteration 54910, lr = 0.1
I0524 09:15:52.048133 11654 solver.cpp:239] Iteration 54920 (1.5551 iter/s, 6.43045s/10 iters), loss = 5.59078
I0524 09:15:52.048182 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59078 (* 1 = 5.59078 loss)
I0524 09:15:52.048395 11654 sgd_solver.cpp:112] Iteration 54920, lr = 0.1
I0524 09:16:01.148201 11654 solver.cpp:239] Iteration 54930 (1.09894 iter/s, 9.09967s/10 iters), loss = 6.20245
I0524 09:16:01.148250 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20245 (* 1 = 6.20245 loss)
I0524 09:16:01.148290 11654 sgd_solver.cpp:112] Iteration 54930, lr = 0.1
I0524 09:16:07.910357 11654 solver.cpp:239] Iteration 54940 (1.47889 iter/s, 6.76185s/10 iters), loss = 5.49823
I0524 09:16:07.910428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49823 (* 1 = 5.49823 loss)
I0524 09:16:08.144786 11654 sgd_solver.cpp:112] Iteration 54940, lr = 0.1
I0524 09:16:16.497040 11654 solver.cpp:239] Iteration 54950 (1.16465 iter/s, 8.58629s/10 iters), loss = 6.44142
I0524 09:16:16.497244 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44142 (* 1 = 6.44142 loss)
I0524 09:16:16.497282 11654 sgd_solver.cpp:112] Iteration 54950, lr = 0.1
I0524 09:16:25.370317 11654 solver.cpp:239] Iteration 54960 (1.12707 iter/s, 8.87255s/10 iters), loss = 6.38167
I0524 09:16:25.370380 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38167 (* 1 = 6.38167 loss)
I0524 09:16:25.370399 11654 sgd_solver.cpp:112] Iteration 54960, lr = 0.1
I0524 09:16:32.049576 11654 solver.cpp:239] Iteration 54970 (1.49738 iter/s, 6.67832s/10 iters), loss = 5.87142
I0524 09:16:32.049621 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87142 (* 1 = 5.87142 loss)
I0524 09:16:32.049638 11654 sgd_solver.cpp:112] Iteration 54970, lr = 0.1
I0524 09:16:39.124140 11654 solver.cpp:239] Iteration 54980 (1.41402 iter/s, 7.07202s/10 iters), loss = 6.60564
I0524 09:16:39.124198 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60564 (* 1 = 6.60564 loss)
I0524 09:16:39.131489 11654 sgd_solver.cpp:112] Iteration 54980, lr = 0.1
I0524 09:16:46.930481 11654 solver.cpp:239] Iteration 54990 (1.28107 iter/s, 7.80597s/10 iters), loss = 7.23895
I0524 09:16:46.930727 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.23895 (* 1 = 7.23895 loss)
I0524 09:16:46.930892 11654 sgd_solver.cpp:112] Iteration 54990, lr = 0.1
I0524 09:16:53.657111 11654 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_55000.caffemodel
I0524 09:16:54.589128 11654 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMImageCdata/AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn/2018-05-23_AMImageCdata-b0.3s30_fc_0.35_112x96_b+FaceAdd_MobileFaceNet-bn_zkx_iter_55000.solverstate
I0524 09:16:55.297894 11654 solver.cpp:239] Iteration 55000 (1.19519 iter/s, 8.36688s/10 iters), loss = 6.2737
I0524 09:16:55.297937 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.2737 (* 1 = 6.2737 loss)
I0524 09:16:55.740330 11654 sgd_solver.cpp:112] Iteration 55000, lr = 0.1
I0524 09:17:04.368410 11654 solver.cpp:239] Iteration 55010 (1.10252 iter/s, 9.07011s/10 iters), loss = 6.39934
I0524 09:17:04.368468 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39934 (* 1 = 6.39934 loss)
I0524 09:17:04.368484 11654 sgd_solver.cpp:112] Iteration 55010, lr = 0.1
I0524 09:17:10.856724 11654 solver.cpp:239] Iteration 55020 (1.54183 iter/s, 6.48581s/10 iters), loss = 6.68344
I0524 09:17:10.856776 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68344 (* 1 = 6.68344 loss)
I0524 09:17:10.874155 11654 sgd_solver.cpp:112] Iteration 55020, lr = 0.1
I0524 09:17:19.652276 11654 solver.cpp:239] Iteration 55030 (1.13699 iter/s, 8.79515s/10 iters), loss = 8.05728
I0524 09:17:19.652499 11654 solver.cpp:258]     Train net output #0: softmax_loss = 8.05728 (* 1 = 8.05728 loss)
I0524 09:17:19.652529 11654 sgd_solver.cpp:112] Iteration 55030, lr = 0.1
I0524 09:17:29.514159 11654 solver.cpp:239] Iteration 55040 (1.01412 iter/s, 9.86073s/10 iters), loss = 5.96592
I0524 09:17:29.514221 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96592 (* 1 = 5.96592 loss)
I0524 09:17:29.903699 11654 sgd_solver.cpp:112] Iteration 55040, lr = 0.1
I0524 09:17:37.003540 11654 solver.cpp:239] Iteration 55050 (1.33529 iter/s, 7.48899s/10 iters), loss = 5.99338
I0524 09:17:37.003623 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99338 (* 1 = 5.99338 loss)
I0524 09:17:37.003736 11654 sgd_solver.cpp:112] Iteration 55050, lr = 0.1
I0524 09:17:44.194996 11654 solver.cpp:239] Iteration 55060 (1.39061 iter/s, 7.19109s/10 iters), loss = 5.87689
I0524 09:17:44.195057 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87689 (* 1 = 5.87689 loss)
I0524 09:17:44.195081 11654 sgd_solver.cpp:112] Iteration 55060, lr = 0.1
I0524 09:17:52.547865 11654 solver.cpp:239] Iteration 55070 (1.19725 iter/s, 8.35249s/10 iters), loss = 6.55901
I0524 09:17:52.548133 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55901 (* 1 = 6.55901 loss)
I0524 09:17:52.801326 11654 sgd_solver.cpp:112] Iteration 55070, lr = 0.1
I0524 09:18:01.064319 11654 solver.cpp:239] Iteration 55080 (1.17428 iter/s, 8.51588s/10 iters), loss = 6.26968
I0524 09:18:01.064373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26968 (* 1 = 6.26968 loss)
I0524 09:18:01.117846 11654 sgd_solver.cpp:112] Iteration 55080, lr = 0.1
I0524 09:18:10.100808 11654 solver.cpp:239] Iteration 55090 (1.10668 iter/s, 9.03602s/10 iters), loss = 5.83343
I0524 09:18:10.100984 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83343 (* 1 = 5.83343 loss)
I0524 09:18:10.258666 11654 sgd_solver.cpp:112] Iteration 55090, lr = 0.1
I0524 09:18:19.688031 11654 solver.cpp:239] Iteration 55100 (1.0431 iter/s, 9.58678s/10 iters), loss = 5.7731
I0524 09:18:19.688088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.7731 (* 1 = 5.7731 loss)
I0524 09:18:19.688105 11654 sgd_solver.cpp:112] Iteration 55100, lr = 0.1
I0524 09:18:28.242439 11654 solver.cpp:239] Iteration 55110 (1.16905 iter/s, 8.55392s/10 iters), loss = 5.91278
I0524 09:18:28.242717 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91278 (* 1 = 5.91278 loss)
I0524 09:18:28.306814 11654 sgd_solver.cpp:112] Iteration 55110, lr = 0.1
I0524 09:18:34.461768 11654 solver.cpp:239] Iteration 55120 (1.60803 iter/s, 6.21881s/10 iters), loss = 5.89929
I0524 09:18:34.461848 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89929 (* 1 = 5.89929 loss)
I0524 09:18:34.461895 11654 sgd_solver.cpp:112] Iteration 55120, lr = 0.1
I0524 09:18:40.970948 11654 solver.cpp:239] Iteration 55130 (1.53637 iter/s, 6.50885s/10 iters), loss = 6.46873
I0524 09:18:40.971042 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46873 (* 1 = 6.46873 loss)
I0524 09:18:40.971081 11654 sgd_solver.cpp:112] Iteration 55130, lr = 0.1
I0524 09:18:50.936944 11654 solver.cpp:239] Iteration 55140 (1.00346 iter/s, 9.96555s/10 iters), loss = 5.84407
I0524 09:18:50.937010 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84407 (* 1 = 5.84407 loss)
I0524 09:18:50.937038 11654 sgd_solver.cpp:112] Iteration 55140, lr = 0.1
I0524 09:18:57.288637 11654 solver.cpp:239] Iteration 55150 (1.57448 iter/s, 6.35132s/10 iters), loss = 5.19019
I0524 09:18:57.288720 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.19019 (* 1 = 5.19019 loss)
I0524 09:18:57.394275 11654 sgd_solver.cpp:112] Iteration 55150, lr = 0.1
I0524 09:19:03.701795 11654 solver.cpp:239] Iteration 55160 (1.55938 iter/s, 6.4128s/10 iters), loss = 6.81449
I0524 09:19:03.702095 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81449 (* 1 = 6.81449 loss)
I0524 09:19:03.702145 11654 sgd_solver.cpp:112] Iteration 55160, lr = 0.1
I0524 09:19:11.713043 11654 solver.cpp:239] Iteration 55170 (1.24833 iter/s, 8.01069s/10 iters), loss = 6.28752
I0524 09:19:11.713117 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28752 (* 1 = 6.28752 loss)
I0524 09:19:11.713137 11654 sgd_solver.cpp:112] Iteration 55170, lr = 0.1
I0524 09:19:23.413725 11654 solver.cpp:239] Iteration 55180 (0.854695 iter/s, 11.7001s/10 iters), loss = 5.506
I0524 09:19:23.413874 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.506 (* 1 = 5.506 loss)
I0524 09:19:23.413910 11654 sgd_solver.cpp:112] Iteration 55180, lr = 0.1
I0524 09:19:30.332043 11654 solver.cpp:239] Iteration 55190 (1.44596 iter/s, 6.91581s/10 iters), loss = 5.60769
I0524 09:19:30.332134 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60769 (* 1 = 5.60769 loss)
I0524 09:19:30.332329 11654 sgd_solver.cpp:112] Iteration 55190, lr = 0.1
I0524 09:19:36.260192 11654 solver.cpp:239] Iteration 55200 (1.68695 iter/s, 5.92785s/10 iters), loss = 5.51222
I0524 09:19:36.260416 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.51222 (* 1 = 5.51222 loss)
I0524 09:19:36.260447 11654 sgd_solver.cpp:112] Iteration 55200, lr = 0.1
I0524 09:19:43.934406 11654 solver.cpp:239] Iteration 55210 (1.30351 iter/s, 7.67159s/10 iters), loss = 6.11911
I0524 09:19:43.934468 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11911 (* 1 = 6.11911 loss)
I0524 09:19:44.151326 11654 sgd_solver.cpp:112] Iteration 55210, lr = 0.1
I0524 09:19:52.819290 11654 solver.cpp:239] Iteration 55220 (1.12556 iter/s, 8.88447s/10 iters), loss = 6.55444
I0524 09:19:52.819358 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.55444 (* 1 = 6.55444 loss)
I0524 09:19:52.819377 11654 sgd_solver.cpp:112] Iteration 55220, lr = 0.1
I0524 09:19:59.806962 11654 solver.cpp:239] Iteration 55230 (1.43117 iter/s, 6.98731s/10 iters), loss = 6.25421
I0524 09:19:59.807040 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25421 (* 1 = 6.25421 loss)
I0524 09:19:59.807224 11654 sgd_solver.cpp:112] Iteration 55230, lr = 0.1
I0524 09:20:06.236924 11654 solver.cpp:239] Iteration 55240 (1.5553 iter/s, 6.42962s/10 iters), loss = 5.23475
I0524 09:20:06.237016 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.23475 (* 1 = 5.23475 loss)
I0524 09:20:06.237404 11654 sgd_solver.cpp:112] Iteration 55240, lr = 0.1
I0524 09:20:13.731374 11654 solver.cpp:239] Iteration 55250 (1.33439 iter/s, 7.49408s/10 iters), loss = 6.38902
I0524 09:20:13.731596 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38902 (* 1 = 6.38902 loss)
I0524 09:20:14.470716 11654 sgd_solver.cpp:112] Iteration 55250, lr = 0.1
I0524 09:20:23.739279 11654 solver.cpp:239] Iteration 55260 (0.999269 iter/s, 10.0073s/10 iters), loss = 6.00398
I0524 09:20:23.739359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00398 (* 1 = 6.00398 loss)
I0524 09:20:23.739774 11654 sgd_solver.cpp:112] Iteration 55260, lr = 0.1
I0524 09:20:32.749020 11654 solver.cpp:239] Iteration 55270 (1.10996 iter/s, 9.00933s/10 iters), loss = 6.61147
I0524 09:20:32.749078 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.61147 (* 1 = 6.61147 loss)
I0524 09:20:32.749096 11654 sgd_solver.cpp:112] Iteration 55270, lr = 0.1
I0524 09:20:41.161484 11654 solver.cpp:239] Iteration 55280 (1.18878 iter/s, 8.41202s/10 iters), loss = 5.69441
I0524 09:20:41.161552 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69441 (* 1 = 5.69441 loss)
I0524 09:20:41.162012 11654 sgd_solver.cpp:112] Iteration 55280, lr = 0.1
I0524 09:20:49.658759 11654 solver.cpp:239] Iteration 55290 (1.1769 iter/s, 8.49688s/10 iters), loss = 7.22672
I0524 09:20:49.658936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22672 (* 1 = 7.22672 loss)
I0524 09:20:49.658957 11654 sgd_solver.cpp:112] Iteration 55290, lr = 0.1
I0524 09:20:56.662003 11654 solver.cpp:239] Iteration 55300 (1.428 iter/s, 7.0028s/10 iters), loss = 6.53584
I0524 09:20:56.662052 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53584 (* 1 = 6.53584 loss)
I0524 09:20:56.662068 11654 sgd_solver.cpp:112] Iteration 55300, lr = 0.1
I0524 09:21:06.131947 11654 solver.cpp:239] Iteration 55310 (1.05603 iter/s, 9.46946s/10 iters), loss = 5.78837
I0524 09:21:06.131995 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78837 (* 1 = 5.78837 loss)
I0524 09:21:06.132012 11654 sgd_solver.cpp:112] Iteration 55310, lr = 0.1
I0524 09:21:13.980469 11654 solver.cpp:239] Iteration 55320 (1.27418 iter/s, 7.84817s/10 iters), loss = 4.66963
I0524 09:21:13.980521 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.66963 (* 1 = 4.66963 loss)
I0524 09:21:14.420358 11654 sgd_solver.cpp:112] Iteration 55320, lr = 0.1
I0524 09:21:22.228761 11654 solver.cpp:239] Iteration 55330 (1.21243 iter/s, 8.24792s/10 iters), loss = 6.49612
I0524 09:21:22.228902 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49612 (* 1 = 6.49612 loss)
I0524 09:21:22.228986 11654 sgd_solver.cpp:112] Iteration 55330, lr = 0.1
I0524 09:21:28.818158 11654 solver.cpp:239] Iteration 55340 (1.51769 iter/s, 6.58898s/10 iters), loss = 5.91564
I0524 09:21:28.818228 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91564 (* 1 = 5.91564 loss)
I0524 09:21:28.818300 11654 sgd_solver.cpp:112] Iteration 55340, lr = 0.1
I0524 09:21:36.691893 11654 solver.cpp:239] Iteration 55350 (1.27011 iter/s, 7.87336s/10 iters), loss = 6.37613
I0524 09:21:36.691967 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37613 (* 1 = 6.37613 loss)
I0524 09:21:36.692070 11654 sgd_solver.cpp:112] Iteration 55350, lr = 0.1
I0524 09:21:44.120404 11654 solver.cpp:239] Iteration 55360 (1.34623 iter/s, 7.42815s/10 iters), loss = 7.20184
I0524 09:21:44.120466 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.20184 (* 1 = 7.20184 loss)
I0524 09:21:44.120492 11654 sgd_solver.cpp:112] Iteration 55360, lr = 0.1
I0524 09:21:50.758836 11654 solver.cpp:239] Iteration 55370 (1.50647 iter/s, 6.63805s/10 iters), loss = 5.60163
I0524 09:21:50.758898 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60163 (* 1 = 5.60163 loss)
I0524 09:21:50.759166 11654 sgd_solver.cpp:112] Iteration 55370, lr = 0.1
I0524 09:21:58.971644 11654 solver.cpp:239] Iteration 55380 (1.21767 iter/s, 8.21241s/10 iters), loss = 6.09196
I0524 09:21:58.971881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09196 (* 1 = 6.09196 loss)
I0524 09:21:58.971901 11654 sgd_solver.cpp:112] Iteration 55380, lr = 0.1
I0524 09:22:05.907980 11654 solver.cpp:239] Iteration 55390 (1.44199 iter/s, 6.93486s/10 iters), loss = 5.03861
I0524 09:22:05.908026 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.03861 (* 1 = 5.03861 loss)
I0524 09:22:06.354017 11654 sgd_solver.cpp:112] Iteration 55390, lr = 0.1
I0524 09:22:14.537541 11654 solver.cpp:239] Iteration 55400 (1.15886 iter/s, 8.62917s/10 iters), loss = 6.6454
I0524 09:22:14.537606 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6454 (* 1 = 6.6454 loss)
I0524 09:22:15.061130 11654 sgd_solver.cpp:112] Iteration 55400, lr = 0.1
I0524 09:22:22.827038 11654 solver.cpp:239] Iteration 55410 (1.2064 iter/s, 8.28909s/10 iters), loss = 7.01918
I0524 09:22:22.827111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01918 (* 1 = 7.01918 loss)
I0524 09:22:22.827132 11654 sgd_solver.cpp:112] Iteration 55410, lr = 0.1
I0524 09:22:30.243891 11654 solver.cpp:239] Iteration 55420 (1.34875 iter/s, 7.41426s/10 iters), loss = 6.30805
I0524 09:22:30.244210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30805 (* 1 = 6.30805 loss)
I0524 09:22:30.244294 11654 sgd_solver.cpp:112] Iteration 55420, lr = 0.1
I0524 09:22:39.307956 11654 solver.cpp:239] Iteration 55430 (1.10359 iter/s, 9.06133s/10 iters), loss = 5.91391
I0524 09:22:39.308032 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91391 (* 1 = 5.91391 loss)
I0524 09:22:39.355087 11654 sgd_solver.cpp:112] Iteration 55430, lr = 0.1
I0524 09:22:46.573115 11654 solver.cpp:239] Iteration 55440 (1.3765 iter/s, 7.26483s/10 iters), loss = 5.76813
I0524 09:22:46.573153 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76813 (* 1 = 5.76813 loss)
I0524 09:22:46.726858 11654 sgd_solver.cpp:112] Iteration 55440, lr = 0.1
I0524 09:22:53.440007 11654 solver.cpp:239] Iteration 55450 (1.45633 iter/s, 6.86657s/10 iters), loss = 6.6657
I0524 09:22:53.440088 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6657 (* 1 = 6.6657 loss)
I0524 09:22:53.440629 11654 sgd_solver.cpp:112] Iteration 55450, lr = 0.1
I0524 09:23:00.206326 11654 solver.cpp:239] Iteration 55460 (1.47799 iter/s, 6.76596s/10 iters), loss = 6.08995
I0524 09:23:00.206440 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08995 (* 1 = 6.08995 loss)
I0524 09:23:00.372268 11654 sgd_solver.cpp:112] Iteration 55460, lr = 0.1
I0524 09:23:07.958941 11654 solver.cpp:239] Iteration 55470 (1.28995 iter/s, 7.75224s/10 iters), loss = 5.89148
I0524 09:23:07.958992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89148 (* 1 = 5.89148 loss)
I0524 09:23:07.959415 11654 sgd_solver.cpp:112] Iteration 55470, lr = 0.1
I0524 09:23:14.908854 11654 solver.cpp:239] Iteration 55480 (1.43893 iter/s, 6.94959s/10 iters), loss = 5.65339
I0524 09:23:14.908910 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65339 (* 1 = 5.65339 loss)
I0524 09:23:14.908927 11654 sgd_solver.cpp:112] Iteration 55480, lr = 0.1
I0524 09:23:22.433187 11654 solver.cpp:239] Iteration 55490 (1.3291 iter/s, 7.52391s/10 iters), loss = 6.6219
I0524 09:23:22.433251 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.6219 (* 1 = 6.6219 loss)
I0524 09:23:22.433331 11654 sgd_solver.cpp:112] Iteration 55490, lr = 0.1
I0524 09:23:30.474006 11654 solver.cpp:239] Iteration 55500 (1.24371 iter/s, 8.04044s/10 iters), loss = 5.83622
I0524 09:23:30.474351 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83622 (* 1 = 5.83622 loss)
I0524 09:23:30.516844 11654 sgd_solver.cpp:112] Iteration 55500, lr = 0.1
I0524 09:23:36.978871 11654 solver.cpp:239] Iteration 55510 (1.53744 iter/s, 6.50433s/10 iters), loss = 5.40138
I0524 09:23:36.978943 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.40138 (* 1 = 5.40138 loss)
I0524 09:23:36.986841 11654 sgd_solver.cpp:112] Iteration 55510, lr = 0.1
I0524 09:23:44.342525 11654 solver.cpp:239] Iteration 55520 (1.35809 iter/s, 7.36329s/10 iters), loss = 6.99988
I0524 09:23:44.342581 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99988 (* 1 = 6.99988 loss)
I0524 09:23:44.342607 11654 sgd_solver.cpp:112] Iteration 55520, lr = 0.1
I0524 09:23:51.875871 11654 solver.cpp:239] Iteration 55530 (1.32788 iter/s, 7.53078s/10 iters), loss = 6.09791
I0524 09:23:51.875923 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09791 (* 1 = 6.09791 loss)
I0524 09:23:51.875938 11654 sgd_solver.cpp:112] Iteration 55530, lr = 0.1
I0524 09:23:59.178170 11654 solver.cpp:239] Iteration 55540 (1.36992 iter/s, 7.29969s/10 iters), loss = 6.90264
I0524 09:23:59.178234 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90264 (* 1 = 6.90264 loss)
I0524 09:23:59.178458 11654 sgd_solver.cpp:112] Iteration 55540, lr = 0.1
I0524 09:24:07.652626 11654 solver.cpp:239] Iteration 55550 (1.18007 iter/s, 8.47405s/10 iters), loss = 6.9533
I0524 09:24:07.652814 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.9533 (* 1 = 6.9533 loss)
I0524 09:24:07.652842 11654 sgd_solver.cpp:112] Iteration 55550, lr = 0.1
I0524 09:24:15.456693 11654 solver.cpp:239] Iteration 55560 (1.28147 iter/s, 7.80355s/10 iters), loss = 6.51552
I0524 09:24:15.456758 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51552 (* 1 = 6.51552 loss)
I0524 09:24:15.456828 11654 sgd_solver.cpp:112] Iteration 55560, lr = 0.1
I0524 09:24:24.051635 11654 solver.cpp:239] Iteration 55570 (1.16353 iter/s, 8.59456s/10 iters), loss = 6.36526
I0524 09:24:24.051719 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36526 (* 1 = 6.36526 loss)
I0524 09:24:25.204787 11654 sgd_solver.cpp:112] Iteration 55570, lr = 0.1
I0524 09:24:34.091406 11654 solver.cpp:239] Iteration 55580 (0.996086 iter/s, 10.0393s/10 iters), loss = 5.8826
I0524 09:24:34.091567 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8826 (* 1 = 5.8826 loss)
I0524 09:24:34.091609 11654 sgd_solver.cpp:112] Iteration 55580, lr = 0.1
I0524 09:24:41.450479 11654 solver.cpp:239] Iteration 55590 (1.35894 iter/s, 7.35866s/10 iters), loss = 6.40535
I0524 09:24:41.450644 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40535 (* 1 = 6.40535 loss)
I0524 09:24:41.450769 11654 sgd_solver.cpp:112] Iteration 55590, lr = 0.1
I0524 09:24:48.547073 11654 solver.cpp:239] Iteration 55600 (1.40921 iter/s, 7.09616s/10 iters), loss = 5.81636
I0524 09:24:48.547133 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81636 (* 1 = 5.81636 loss)
I0524 09:24:48.547161 11654 sgd_solver.cpp:112] Iteration 55600, lr = 0.1
I0524 09:24:56.762341 11654 solver.cpp:239] Iteration 55610 (1.21731 iter/s, 8.21484s/10 iters), loss = 5.89192
I0524 09:24:56.762447 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89192 (* 1 = 5.89192 loss)
I0524 09:24:57.367944 11654 sgd_solver.cpp:112] Iteration 55610, lr = 0.1
I0524 09:25:05.347908 11654 solver.cpp:239] Iteration 55620 (1.1648 iter/s, 8.58514s/10 iters), loss = 6.36474
I0524 09:25:05.347987 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36474 (* 1 = 6.36474 loss)
I0524 09:25:05.348031 11654 sgd_solver.cpp:112] Iteration 55620, lr = 0.1
I0524 09:25:13.857306 11654 solver.cpp:239] Iteration 55630 (1.17523 iter/s, 8.50895s/10 iters), loss = 6.52748
I0524 09:25:13.857586 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52748 (* 1 = 6.52748 loss)
I0524 09:25:13.857638 11654 sgd_solver.cpp:112] Iteration 55630, lr = 0.1
I0524 09:25:21.953714 11654 solver.cpp:239] Iteration 55640 (1.2352 iter/s, 8.09585s/10 iters), loss = 5.42144
I0524 09:25:21.953771 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.42144 (* 1 = 5.42144 loss)
I0524 09:25:21.953992 11654 sgd_solver.cpp:112] Iteration 55640, lr = 0.1
I0524 09:25:28.261263 11654 solver.cpp:239] Iteration 55650 (1.58548 iter/s, 6.30725s/10 iters), loss = 7.38845
I0524 09:25:28.261317 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.38845 (* 1 = 7.38845 loss)
I0524 09:25:28.261500 11654 sgd_solver.cpp:112] Iteration 55650, lr = 0.1
I0524 09:25:35.033458 11654 solver.cpp:239] Iteration 55660 (1.4767 iter/s, 6.77186s/10 iters), loss = 5.58295
I0524 09:25:35.033524 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58295 (* 1 = 5.58295 loss)
I0524 09:25:35.033547 11654 sgd_solver.cpp:112] Iteration 55660, lr = 0.1
I0524 09:25:41.670056 11654 solver.cpp:239] Iteration 55670 (1.50737 iter/s, 6.63407s/10 iters), loss = 7.08841
I0524 09:25:41.670128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.08841 (* 1 = 7.08841 loss)
I0524 09:25:41.670265 11654 sgd_solver.cpp:112] Iteration 55670, lr = 0.1
I0524 09:25:48.095160 11654 solver.cpp:239] Iteration 55680 (1.55647 iter/s, 6.4248s/10 iters), loss = 5.50474
I0524 09:25:48.095353 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50474 (* 1 = 5.50474 loss)
I0524 09:25:48.095391 11654 sgd_solver.cpp:112] Iteration 55680, lr = 0.1
I0524 09:25:55.554759 11654 solver.cpp:239] Iteration 55690 (1.34064 iter/s, 7.45913s/10 iters), loss = 6.18913
I0524 09:25:55.554821 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18913 (* 1 = 6.18913 loss)
I0524 09:25:55.555305 11654 sgd_solver.cpp:112] Iteration 55690, lr = 0.1
I0524 09:26:04.048902 11654 solver.cpp:239] Iteration 55700 (1.17734 iter/s, 8.49375s/10 iters), loss = 6.14263
I0524 09:26:04.048960 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14263 (* 1 = 6.14263 loss)
I0524 09:26:04.048990 11654 sgd_solver.cpp:112] Iteration 55700, lr = 0.1
I0524 09:26:10.653188 11654 solver.cpp:239] Iteration 55710 (1.51426 iter/s, 6.60387s/10 iters), loss = 6.14173
I0524 09:26:10.653242 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.14173 (* 1 = 6.14173 loss)
I0524 09:26:11.162659 11654 sgd_solver.cpp:112] Iteration 55710, lr = 0.1
I0524 09:26:18.245328 11654 solver.cpp:239] Iteration 55720 (1.31721 iter/s, 7.59179s/10 iters), loss = 5.53247
I0524 09:26:18.245538 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.53247 (* 1 = 5.53247 loss)
I0524 09:26:18.245571 11654 sgd_solver.cpp:112] Iteration 55720, lr = 0.1
I0524 09:26:26.905076 11654 solver.cpp:239] Iteration 55730 (1.15487 iter/s, 8.65895s/10 iters), loss = 5.91437
I0524 09:26:26.905205 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91437 (* 1 = 5.91437 loss)
I0524 09:26:27.476009 11654 sgd_solver.cpp:112] Iteration 55730, lr = 0.1
I0524 09:26:34.034417 11654 solver.cpp:239] Iteration 55740 (1.40272 iter/s, 7.12901s/10 iters), loss = 6.23723
I0524 09:26:34.034471 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23723 (* 1 = 6.23723 loss)
I0524 09:26:34.034487 11654 sgd_solver.cpp:112] Iteration 55740, lr = 0.1
I0524 09:26:42.013597 11654 solver.cpp:239] Iteration 55750 (1.25332 iter/s, 7.97882s/10 iters), loss = 6.26098
I0524 09:26:42.013702 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26098 (* 1 = 6.26098 loss)
I0524 09:26:42.013725 11654 sgd_solver.cpp:112] Iteration 55750, lr = 0.1
I0524 09:26:50.303079 11654 solver.cpp:239] Iteration 55760 (1.20641 iter/s, 8.28904s/10 iters), loss = 6.45976
I0524 09:26:50.303333 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45976 (* 1 = 6.45976 loss)
I0524 09:26:50.303591 11654 sgd_solver.cpp:112] Iteration 55760, lr = 0.1
I0524 09:26:57.773659 11654 solver.cpp:239] Iteration 55770 (1.33867 iter/s, 7.47009s/10 iters), loss = 6.38965
I0524 09:26:57.773699 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38965 (* 1 = 6.38965 loss)
I0524 09:26:57.773726 11654 sgd_solver.cpp:112] Iteration 55770, lr = 0.1
I0524 09:27:04.869294 11654 solver.cpp:239] Iteration 55780 (1.40983 iter/s, 7.09306s/10 iters), loss = 6.22305
I0524 09:27:04.869371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22305 (* 1 = 6.22305 loss)
I0524 09:27:04.869390 11654 sgd_solver.cpp:112] Iteration 55780, lr = 0.1
I0524 09:27:11.982401 11654 solver.cpp:239] Iteration 55790 (1.40604 iter/s, 7.11217s/10 iters), loss = 5.97752
I0524 09:27:11.982450 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97752 (* 1 = 5.97752 loss)
I0524 09:27:11.982467 11654 sgd_solver.cpp:112] Iteration 55790, lr = 0.1
I0524 09:27:19.582054 11654 solver.cpp:239] Iteration 55800 (1.31592 iter/s, 7.59923s/10 iters), loss = 6.58174
I0524 09:27:19.582108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.58174 (* 1 = 6.58174 loss)
I0524 09:27:19.582514 11654 sgd_solver.cpp:112] Iteration 55800, lr = 0.1
I0524 09:27:27.883201 11654 solver.cpp:239] Iteration 55810 (1.20472 iter/s, 8.30071s/10 iters), loss = 7.01537
I0524 09:27:27.883534 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.01537 (* 1 = 7.01537 loss)
I0524 09:27:27.883716 11654 sgd_solver.cpp:112] Iteration 55810, lr = 0.1
I0524 09:27:35.199594 11654 solver.cpp:239] Iteration 55820 (1.3669 iter/s, 7.3158s/10 iters), loss = 7.03898
I0524 09:27:35.199682 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03898 (* 1 = 7.03898 loss)
I0524 09:27:35.964840 11654 sgd_solver.cpp:112] Iteration 55820, lr = 0.1
I0524 09:27:44.832273 11654 solver.cpp:239] Iteration 55830 (1.03818 iter/s, 9.63223s/10 iters), loss = 5.3561
I0524 09:27:44.832351 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3561 (* 1 = 5.3561 loss)
I0524 09:27:44.832696 11654 sgd_solver.cpp:112] Iteration 55830, lr = 0.1
I0524 09:27:53.453519 11654 solver.cpp:239] Iteration 55840 (1.15998 iter/s, 8.62082s/10 iters), loss = 4.94872
I0524 09:27:53.453593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.94872 (* 1 = 4.94872 loss)
I0524 09:27:53.453704 11654 sgd_solver.cpp:112] Iteration 55840, lr = 0.1
I0524 09:28:00.397634 11654 solver.cpp:239] Iteration 55850 (1.44014 iter/s, 6.94378s/10 iters), loss = 7.0885
I0524 09:28:00.397797 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.0885 (* 1 = 7.0885 loss)
I0524 09:28:00.397832 11654 sgd_solver.cpp:112] Iteration 55850, lr = 0.1
I0524 09:28:08.280778 11654 solver.cpp:239] Iteration 55860 (1.2686 iter/s, 7.88269s/10 iters), loss = 5.97662
I0524 09:28:08.280831 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97662 (* 1 = 5.97662 loss)
I0524 09:28:08.281154 11654 sgd_solver.cpp:112] Iteration 55860, lr = 0.1
I0524 09:28:15.113562 11654 solver.cpp:239] Iteration 55870 (1.4636 iter/s, 6.83245s/10 iters), loss = 5.60295
I0524 09:28:15.113664 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60295 (* 1 = 5.60295 loss)
I0524 09:28:15.113698 11654 sgd_solver.cpp:112] Iteration 55870, lr = 0.1
I0524 09:28:23.285457 11654 solver.cpp:239] Iteration 55880 (1.22379 iter/s, 8.17134s/10 iters), loss = 5.25969
I0524 09:28:23.285516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.25969 (* 1 = 5.25969 loss)
I0524 09:28:23.290952 11654 sgd_solver.cpp:112] Iteration 55880, lr = 0.1
I0524 09:28:31.371155 11654 solver.cpp:239] Iteration 55890 (1.23681 iter/s, 8.08533s/10 iters), loss = 5.52612
I0524 09:28:31.371403 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.52612 (* 1 = 5.52612 loss)
I0524 09:28:31.626911 11654 sgd_solver.cpp:112] Iteration 55890, lr = 0.1
I0524 09:28:38.276132 11654 solver.cpp:239] Iteration 55900 (1.44833 iter/s, 6.90449s/10 iters), loss = 5.89733
I0524 09:28:38.276175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89733 (* 1 = 5.89733 loss)
I0524 09:28:38.276458 11654 sgd_solver.cpp:112] Iteration 55900, lr = 0.1
I0524 09:28:45.740468 11654 solver.cpp:239] Iteration 55910 (1.33977 iter/s, 7.46399s/10 iters), loss = 6.52812
I0524 09:28:45.740530 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52812 (* 1 = 6.52812 loss)
I0524 09:28:45.740613 11654 sgd_solver.cpp:112] Iteration 55910, lr = 0.1
I0524 09:28:52.721114 11654 solver.cpp:239] Iteration 55920 (1.43261 iter/s, 6.98029s/10 iters), loss = 6.45012
I0524 09:28:52.721192 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45012 (* 1 = 6.45012 loss)
I0524 09:28:52.728996 11654 sgd_solver.cpp:112] Iteration 55920, lr = 0.1
I0524 09:29:00.225597 11654 solver.cpp:239] Iteration 55930 (1.33261 iter/s, 7.50409s/10 iters), loss = 6.06947
I0524 09:29:00.225739 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06947 (* 1 = 6.06947 loss)
I0524 09:29:00.225790 11654 sgd_solver.cpp:112] Iteration 55930, lr = 0.1
I0524 09:29:06.724479 11654 solver.cpp:239] Iteration 55940 (1.53892 iter/s, 6.49805s/10 iters), loss = 5.99879
I0524 09:29:06.724691 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99879 (* 1 = 5.99879 loss)
I0524 09:29:06.724735 11654 sgd_solver.cpp:112] Iteration 55940, lr = 0.1
I0524 09:29:15.507563 11654 solver.cpp:239] Iteration 55950 (1.13863 iter/s, 8.7825s/10 iters), loss = 6.90887
I0524 09:29:15.507609 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90887 (* 1 = 6.90887 loss)
I0524 09:29:15.507894 11654 sgd_solver.cpp:112] Iteration 55950, lr = 0.1
I0524 09:29:23.845662 11654 solver.cpp:239] Iteration 55960 (1.19937 iter/s, 8.33772s/10 iters), loss = 7.13255
I0524 09:29:23.845731 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.13255 (* 1 = 7.13255 loss)
I0524 09:29:23.845752 11654 sgd_solver.cpp:112] Iteration 55960, lr = 0.1
I0524 09:29:31.470062 11654 solver.cpp:239] Iteration 55970 (1.31165 iter/s, 7.62399s/10 iters), loss = 5.31112
I0524 09:29:31.470147 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.31112 (* 1 = 5.31112 loss)
I0524 09:29:31.470438 11654 sgd_solver.cpp:112] Iteration 55970, lr = 0.1
I0524 09:29:39.718816 11654 solver.cpp:239] Iteration 55980 (1.21236 iter/s, 8.24836s/10 iters), loss = 6.09868
I0524 09:29:39.719081 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.09868 (* 1 = 6.09868 loss)
I0524 09:29:39.719116 11654 sgd_solver.cpp:112] Iteration 55980, lr = 0.1
I0524 09:29:47.340499 11654 solver.cpp:239] Iteration 55990 (1.31251 iter/s, 7.61897s/10 iters), loss = 5.8542
I0524 09:29:47.340565 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8542 (* 1 = 5.8542 loss)
I0524 09:29:47.342579 11654 sgd_solver.cpp:112] Iteration 55990, lr = 0.1
I0524 09:29:55.764780 11654 solver.cpp:239] Iteration 56000 (1.1871 iter/s, 8.4239s/10 iters), loss = 6.39143
I0524 09:29:55.764847 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39143 (* 1 = 6.39143 loss)
I0524 09:29:55.765276 11654 sgd_solver.cpp:112] Iteration 56000, lr = 0.1
I0524 09:30:03.038317 11654 solver.cpp:239] Iteration 56010 (1.37491 iter/s, 7.27319s/10 iters), loss = 6.79435
I0524 09:30:03.038374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.79435 (* 1 = 6.79435 loss)
I0524 09:30:03.482271 11654 sgd_solver.cpp:112] Iteration 56010, lr = 0.1
I0524 09:30:09.716118 11654 solver.cpp:239] Iteration 56020 (1.49757 iter/s, 6.67749s/10 iters), loss = 6.13822
I0524 09:30:09.716163 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13822 (* 1 = 6.13822 loss)
I0524 09:30:09.786348 11654 sgd_solver.cpp:112] Iteration 56020, lr = 0.1
I0524 09:30:16.886072 11654 solver.cpp:239] Iteration 56030 (1.39477 iter/s, 7.16962s/10 iters), loss = 5.61933
I0524 09:30:16.886121 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.61933 (* 1 = 5.61933 loss)
I0524 09:30:16.888346 11654 sgd_solver.cpp:112] Iteration 56030, lr = 0.1
I0524 09:30:24.487224 11654 solver.cpp:239] Iteration 56040 (1.31565 iter/s, 7.6008s/10 iters), loss = 5.96107
I0524 09:30:24.487299 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96107 (* 1 = 5.96107 loss)
I0524 09:30:24.487532 11654 sgd_solver.cpp:112] Iteration 56040, lr = 0.1
I0524 09:30:32.303944 11654 solver.cpp:239] Iteration 56050 (1.27937 iter/s, 7.81636s/10 iters), loss = 5.90435
I0524 09:30:32.303982 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90435 (* 1 = 5.90435 loss)
I0524 09:30:32.305069 11654 sgd_solver.cpp:112] Iteration 56050, lr = 0.1
I0524 09:30:38.718708 11654 solver.cpp:239] Iteration 56060 (1.55899 iter/s, 6.41441s/10 iters), loss = 5.26411
I0524 09:30:38.718780 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26411 (* 1 = 5.26411 loss)
I0524 09:30:38.718960 11654 sgd_solver.cpp:112] Iteration 56060, lr = 0.1
I0524 09:30:45.240728 11654 solver.cpp:239] Iteration 56070 (1.53334 iter/s, 6.5217s/10 iters), loss = 5.81252
I0524 09:30:45.241060 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81252 (* 1 = 5.81252 loss)
I0524 09:30:45.241112 11654 sgd_solver.cpp:112] Iteration 56070, lr = 0.1
I0524 09:30:52.444375 11654 solver.cpp:239] Iteration 56080 (1.38833 iter/s, 7.20291s/10 iters), loss = 5.47498
I0524 09:30:52.444438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47498 (* 1 = 5.47498 loss)
I0524 09:30:52.448601 11654 sgd_solver.cpp:112] Iteration 56080, lr = 0.1
I0524 09:30:58.779520 11654 solver.cpp:239] Iteration 56090 (1.57857 iter/s, 6.33483s/10 iters), loss = 6.4972
I0524 09:30:58.779588 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4972 (* 1 = 6.4972 loss)
I0524 09:30:58.779927 11654 sgd_solver.cpp:112] Iteration 56090, lr = 0.1
I0524 09:31:06.762246 11654 solver.cpp:239] Iteration 56100 (1.25276 iter/s, 7.98235s/10 iters), loss = 6.49444
I0524 09:31:06.762298 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49444 (* 1 = 6.49444 loss)
I0524 09:31:06.762329 11654 sgd_solver.cpp:112] Iteration 56100, lr = 0.1
I0524 09:31:14.243997 11654 solver.cpp:239] Iteration 56110 (1.33665 iter/s, 7.48139s/10 iters), loss = 5.66078
I0524 09:31:14.244082 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66078 (* 1 = 5.66078 loss)
I0524 09:31:14.245942 11654 sgd_solver.cpp:112] Iteration 56110, lr = 0.1
I0524 09:31:20.645200 11654 solver.cpp:239] Iteration 56120 (1.56228 iter/s, 6.40089s/10 iters), loss = 6.52942
I0524 09:31:20.645596 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52942 (* 1 = 6.52942 loss)
I0524 09:31:20.735615 11654 sgd_solver.cpp:112] Iteration 56120, lr = 0.1
I0524 09:31:28.323971 11654 solver.cpp:239] Iteration 56130 (1.30239 iter/s, 7.67819s/10 iters), loss = 6.33657
I0524 09:31:28.324076 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33657 (* 1 = 6.33657 loss)
I0524 09:31:28.324203 11654 sgd_solver.cpp:112] Iteration 56130, lr = 0.1
I0524 09:31:35.541385 11654 solver.cpp:239] Iteration 56140 (1.3856 iter/s, 7.21708s/10 iters), loss = 6.25395
I0524 09:31:35.541446 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25395 (* 1 = 6.25395 loss)
I0524 09:31:35.554363 11654 sgd_solver.cpp:112] Iteration 56140, lr = 0.1
I0524 09:31:43.135112 11654 solver.cpp:239] Iteration 56150 (1.31694 iter/s, 7.59336s/10 iters), loss = 6.45429
I0524 09:31:43.135215 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45429 (* 1 = 6.45429 loss)
I0524 09:31:43.135350 11654 sgd_solver.cpp:112] Iteration 56150, lr = 0.1
I0524 09:31:50.998844 11654 solver.cpp:239] Iteration 56160 (1.27173 iter/s, 7.86333s/10 iters), loss = 5.96967
I0524 09:31:50.999140 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96967 (* 1 = 5.96967 loss)
I0524 09:31:50.999194 11654 sgd_solver.cpp:112] Iteration 56160, lr = 0.1
I0524 09:31:58.766129 11654 solver.cpp:239] Iteration 56170 (1.28755 iter/s, 7.7667s/10 iters), loss = 5.73372
I0524 09:31:58.766202 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73372 (* 1 = 5.73372 loss)
I0524 09:31:58.766305 11654 sgd_solver.cpp:112] Iteration 56170, lr = 0.1
I0524 09:32:06.778489 11654 solver.cpp:239] Iteration 56180 (1.24813 iter/s, 8.01197s/10 iters), loss = 6.63652
I0524 09:32:06.778573 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63652 (* 1 = 6.63652 loss)
I0524 09:32:06.778599 11654 sgd_solver.cpp:112] Iteration 56180, lr = 0.1
I0524 09:32:15.808480 11654 solver.cpp:239] Iteration 56190 (1.10747 iter/s, 9.02955s/10 iters), loss = 6.1274
I0524 09:32:15.808521 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1274 (* 1 = 6.1274 loss)
I0524 09:32:16.021204 11654 sgd_solver.cpp:112] Iteration 56190, lr = 0.1
I0524 09:32:22.974056 11654 solver.cpp:239] Iteration 56200 (1.39563 iter/s, 7.16524s/10 iters), loss = 6.12731
I0524 09:32:22.974370 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12731 (* 1 = 6.12731 loss)
I0524 09:32:22.984151 11654 sgd_solver.cpp:112] Iteration 56200, lr = 0.1
I0524 09:32:30.766543 11654 solver.cpp:239] Iteration 56210 (1.28339 iter/s, 7.79189s/10 iters), loss = 6.53514
I0524 09:32:30.766669 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53514 (* 1 = 6.53514 loss)
I0524 09:32:31.659880 11654 sgd_solver.cpp:112] Iteration 56210, lr = 0.1
I0524 09:32:40.071496 11654 solver.cpp:239] Iteration 56220 (1.07475 iter/s, 9.30453s/10 iters), loss = 6.15429
I0524 09:32:40.071547 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15429 (* 1 = 6.15429 loss)
I0524 09:32:40.071563 11654 sgd_solver.cpp:112] Iteration 56220, lr = 0.1
I0524 09:32:47.715559 11654 solver.cpp:239] Iteration 56230 (1.30828 iter/s, 7.64363s/10 iters), loss = 6.39017
I0524 09:32:47.715667 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39017 (* 1 = 6.39017 loss)
I0524 09:32:47.715697 11654 sgd_solver.cpp:112] Iteration 56230, lr = 0.1
I0524 09:32:55.229383 11654 solver.cpp:239] Iteration 56240 (1.33095 iter/s, 7.51346s/10 iters), loss = 6.50421
I0524 09:32:55.229576 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50421 (* 1 = 6.50421 loss)
I0524 09:32:55.229602 11654 sgd_solver.cpp:112] Iteration 56240, lr = 0.1
I0524 09:33:02.671576 11654 solver.cpp:239] Iteration 56250 (1.34382 iter/s, 7.44146s/10 iters), loss = 7.26548
I0524 09:33:02.671638 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26548 (* 1 = 7.26548 loss)
I0524 09:33:02.733728 11654 sgd_solver.cpp:112] Iteration 56250, lr = 0.1
I0524 09:33:11.146492 11654 solver.cpp:239] Iteration 56260 (1.18001 iter/s, 8.47453s/10 iters), loss = 5.76068
I0524 09:33:11.146584 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.76068 (* 1 = 5.76068 loss)
I0524 09:33:11.147047 11654 sgd_solver.cpp:112] Iteration 56260, lr = 0.1
I0524 09:33:18.241178 11654 solver.cpp:239] Iteration 56270 (1.40957 iter/s, 7.09434s/10 iters), loss = 6.27011
I0524 09:33:18.241248 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27011 (* 1 = 6.27011 loss)
I0524 09:33:18.368804 11654 sgd_solver.cpp:112] Iteration 56270, lr = 0.1
I0524 09:33:26.104434 11654 solver.cpp:239] Iteration 56280 (1.2718 iter/s, 7.86289s/10 iters), loss = 5.47253
I0524 09:33:26.104784 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47253 (* 1 = 5.47253 loss)
I0524 09:33:26.104861 11654 sgd_solver.cpp:112] Iteration 56280, lr = 0.1
I0524 09:33:32.790012 11654 solver.cpp:239] Iteration 56290 (1.49597 iter/s, 6.68462s/10 iters), loss = 6.60231
I0524 09:33:32.790066 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.60231 (* 1 = 6.60231 loss)
I0524 09:33:33.553514 11654 sgd_solver.cpp:112] Iteration 56290, lr = 0.1
I0524 09:33:40.070472 11654 solver.cpp:239] Iteration 56300 (1.37361 iter/s, 7.2801s/10 iters), loss = 5.4123
I0524 09:33:40.070562 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4123 (* 1 = 5.4123 loss)
I0524 09:33:40.070588 11654 sgd_solver.cpp:112] Iteration 56300, lr = 0.1
I0524 09:33:47.606346 11654 solver.cpp:239] Iteration 56310 (1.32705 iter/s, 7.5355s/10 iters), loss = 6.27972
I0524 09:33:47.606421 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27972 (* 1 = 6.27972 loss)
I0524 09:33:47.610939 11654 sgd_solver.cpp:112] Iteration 56310, lr = 0.1
I0524 09:33:56.522439 11654 solver.cpp:239] Iteration 56320 (1.12162 iter/s, 8.9157s/10 iters), loss = 5.02292
I0524 09:33:56.522780 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.02292 (* 1 = 5.02292 loss)
I0524 09:33:56.522828 11654 sgd_solver.cpp:112] Iteration 56320, lr = 0.1
I0524 09:34:03.645915 11654 solver.cpp:239] Iteration 56330 (1.40433 iter/s, 7.12085s/10 iters), loss = 5.71468
I0524 09:34:03.646014 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.71468 (* 1 = 5.71468 loss)
I0524 09:34:03.646201 11654 sgd_solver.cpp:112] Iteration 56330, lr = 0.1
I0524 09:34:11.003818 11654 solver.cpp:239] Iteration 56340 (1.35916 iter/s, 7.3575s/10 iters), loss = 6.20963
I0524 09:34:11.003888 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20963 (* 1 = 6.20963 loss)
I0524 09:34:11.003906 11654 sgd_solver.cpp:112] Iteration 56340, lr = 0.1
I0524 09:34:17.460925 11654 solver.cpp:239] Iteration 56350 (1.54878 iter/s, 6.45671s/10 iters), loss = 5.89521
I0524 09:34:17.461096 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.89521 (* 1 = 5.89521 loss)
I0524 09:34:17.461150 11654 sgd_solver.cpp:112] Iteration 56350, lr = 0.1
I0524 09:34:24.431756 11654 solver.cpp:239] Iteration 56360 (1.43463 iter/s, 6.97045s/10 iters), loss = 5.30911
I0524 09:34:24.431833 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30911 (* 1 = 5.30911 loss)
I0524 09:34:24.431995 11654 sgd_solver.cpp:112] Iteration 56360, lr = 0.1
I0524 09:34:32.306257 11654 solver.cpp:239] Iteration 56370 (1.26998 iter/s, 7.87413s/10 iters), loss = 5.97589
I0524 09:34:32.306439 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97589 (* 1 = 5.97589 loss)
I0524 09:34:32.306463 11654 sgd_solver.cpp:112] Iteration 56370, lr = 0.1
I0524 09:34:38.973685 11654 solver.cpp:239] Iteration 56380 (1.49994 iter/s, 6.66695s/10 iters), loss = 4.99096
I0524 09:34:38.973728 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.99096 (* 1 = 4.99096 loss)
I0524 09:34:38.973865 11654 sgd_solver.cpp:112] Iteration 56380, lr = 0.1
I0524 09:34:45.927937 11654 solver.cpp:239] Iteration 56390 (1.43803 iter/s, 6.95394s/10 iters), loss = 6.37157
I0524 09:34:45.927994 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.37157 (* 1 = 6.37157 loss)
I0524 09:34:45.958873 11654 sgd_solver.cpp:112] Iteration 56390, lr = 0.1
I0524 09:34:55.078745 11654 solver.cpp:239] Iteration 56400 (1.09285 iter/s, 9.15036s/10 iters), loss = 5.08892
I0524 09:34:55.078858 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.08892 (* 1 = 5.08892 loss)
I0524 09:34:55.078883 11654 sgd_solver.cpp:112] Iteration 56400, lr = 0.1
I0524 09:35:01.440280 11654 solver.cpp:239] Iteration 56410 (1.57257 iter/s, 6.35902s/10 iters), loss = 6.00867
I0524 09:35:01.440336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00867 (* 1 = 6.00867 loss)
I0524 09:35:01.440354 11654 sgd_solver.cpp:112] Iteration 56410, lr = 0.1
I0524 09:35:08.506851 11654 solver.cpp:239] Iteration 56420 (1.41526 iter/s, 7.06583s/10 iters), loss = 6.53769
I0524 09:35:08.507119 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53769 (* 1 = 6.53769 loss)
I0524 09:35:08.528870 11654 sgd_solver.cpp:112] Iteration 56420, lr = 0.1
I0524 09:35:17.580437 11654 solver.cpp:239] Iteration 56430 (1.10217 iter/s, 9.07303s/10 iters), loss = 6.86311
I0524 09:35:17.580489 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.86311 (* 1 = 6.86311 loss)
I0524 09:35:17.998040 11654 sgd_solver.cpp:112] Iteration 56430, lr = 0.1
I0524 09:35:25.990316 11654 solver.cpp:239] Iteration 56440 (1.18913 iter/s, 8.4095s/10 iters), loss = 5.37746
I0524 09:35:25.990371 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.37746 (* 1 = 5.37746 loss)
I0524 09:35:25.990530 11654 sgd_solver.cpp:112] Iteration 56440, lr = 0.1
I0524 09:35:33.884883 11654 solver.cpp:239] Iteration 56450 (1.26676 iter/s, 7.89419s/10 iters), loss = 6.74754
I0524 09:35:33.884945 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74754 (* 1 = 6.74754 loss)
I0524 09:35:33.885042 11654 sgd_solver.cpp:112] Iteration 56450, lr = 0.1
I0524 09:35:43.415390 11654 solver.cpp:239] Iteration 56460 (1.04931 iter/s, 9.53006s/10 iters), loss = 6.18111
I0524 09:35:43.415668 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18111 (* 1 = 6.18111 loss)
I0524 09:35:43.780074 11654 sgd_solver.cpp:112] Iteration 56460, lr = 0.1
I0524 09:35:53.234797 11654 solver.cpp:239] Iteration 56470 (1.01846 iter/s, 9.81879s/10 iters), loss = 6.50212
I0524 09:35:53.234854 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50212 (* 1 = 6.50212 loss)
I0524 09:35:53.254250 11654 sgd_solver.cpp:112] Iteration 56470, lr = 0.1
I0524 09:36:02.854293 11654 solver.cpp:239] Iteration 56480 (1.0396 iter/s, 9.61908s/10 iters), loss = 6.16836
I0524 09:36:02.854336 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16836 (* 1 = 6.16836 loss)
I0524 09:36:02.854349 11654 sgd_solver.cpp:112] Iteration 56480, lr = 0.1
I0524 09:36:11.151425 11654 solver.cpp:239] Iteration 56490 (1.20529 iter/s, 8.29676s/10 iters), loss = 6.34467
I0524 09:36:11.151479 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34467 (* 1 = 6.34467 loss)
I0524 09:36:11.151510 11654 sgd_solver.cpp:112] Iteration 56490, lr = 0.1
I0524 09:36:19.346732 11654 solver.cpp:239] Iteration 56500 (1.22028 iter/s, 8.19486s/10 iters), loss = 6.40806
I0524 09:36:19.346936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40806 (* 1 = 6.40806 loss)
I0524 09:36:20.031266 11654 sgd_solver.cpp:112] Iteration 56500, lr = 0.1
I0524 09:36:27.749595 11654 solver.cpp:239] Iteration 56510 (1.19014 iter/s, 8.40235s/10 iters), loss = 6.82619
I0524 09:36:27.749657 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82619 (* 1 = 6.82619 loss)
I0524 09:36:27.896255 11654 sgd_solver.cpp:112] Iteration 56510, lr = 0.1
I0524 09:36:36.885294 11654 solver.cpp:239] Iteration 56520 (1.09466 iter/s, 9.13526s/10 iters), loss = 6.76635
I0524 09:36:36.885365 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.76635 (* 1 = 6.76635 loss)
I0524 09:36:36.885444 11654 sgd_solver.cpp:112] Iteration 56520, lr = 0.1
I0524 09:36:44.191321 11654 solver.cpp:239] Iteration 56530 (1.3688 iter/s, 7.30567s/10 iters), loss = 6.52348
I0524 09:36:44.191380 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52348 (* 1 = 6.52348 loss)
I0524 09:36:44.390130 11654 sgd_solver.cpp:112] Iteration 56530, lr = 0.1
I0524 09:36:50.993126 11654 solver.cpp:239] Iteration 56540 (1.47027 iter/s, 6.80148s/10 iters), loss = 5.45748
I0524 09:36:50.993374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.45748 (* 1 = 5.45748 loss)
I0524 09:36:50.993476 11654 sgd_solver.cpp:112] Iteration 56540, lr = 0.1
I0524 09:36:57.294417 11654 solver.cpp:239] Iteration 56550 (1.58709 iter/s, 6.30084s/10 iters), loss = 6.20811
I0524 09:36:57.294478 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20811 (* 1 = 6.20811 loss)
I0524 09:36:57.294620 11654 sgd_solver.cpp:112] Iteration 56550, lr = 0.1
I0524 09:37:03.838748 11654 solver.cpp:239] Iteration 56560 (1.52812 iter/s, 6.544s/10 iters), loss = 5.73341
I0524 09:37:03.838809 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.73341 (* 1 = 5.73341 loss)
I0524 09:37:04.203059 11654 sgd_solver.cpp:112] Iteration 56560, lr = 0.1
I0524 09:37:11.572594 11654 solver.cpp:239] Iteration 56570 (1.29308 iter/s, 7.73348s/10 iters), loss = 5.90892
I0524 09:37:11.572649 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.90892 (* 1 = 5.90892 loss)
I0524 09:37:11.575767 11654 sgd_solver.cpp:112] Iteration 56570, lr = 0.1
I0524 09:37:19.459904 11654 solver.cpp:239] Iteration 56580 (1.26792 iter/s, 7.88695s/10 iters), loss = 6.84678
I0524 09:37:19.459954 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.84678 (* 1 = 6.84678 loss)
I0524 09:37:19.460098 11654 sgd_solver.cpp:112] Iteration 56580, lr = 0.1
I0524 09:37:27.238605 11654 solver.cpp:239] Iteration 56590 (1.28562 iter/s, 7.77834s/10 iters), loss = 6.32473
I0524 09:37:27.238883 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.32473 (* 1 = 6.32473 loss)
I0524 09:37:27.238991 11654 sgd_solver.cpp:112] Iteration 56590, lr = 0.1
I0524 09:37:33.957141 11654 solver.cpp:239] Iteration 56600 (1.48854 iter/s, 6.718s/10 iters), loss = 4.82936
I0524 09:37:33.957206 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.82936 (* 1 = 4.82936 loss)
I0524 09:37:34.064637 11654 sgd_solver.cpp:112] Iteration 56600, lr = 0.1
I0524 09:37:40.621947 11654 solver.cpp:239] Iteration 56610 (1.50049 iter/s, 6.66448s/10 iters), loss = 6.65059
I0524 09:37:40.622011 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65059 (* 1 = 6.65059 loss)
I0524 09:37:40.622056 11654 sgd_solver.cpp:112] Iteration 56610, lr = 0.1
I0524 09:37:50.026727 11654 solver.cpp:239] Iteration 56620 (1.06334 iter/s, 9.40436s/10 iters), loss = 5.11651
I0524 09:37:50.026785 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.11651 (* 1 = 5.11651 loss)
I0524 09:37:50.026803 11654 sgd_solver.cpp:112] Iteration 56620, lr = 0.1
I0524 09:37:58.536564 11654 solver.cpp:239] Iteration 56630 (1.17517 iter/s, 8.50939s/10 iters), loss = 6.36786
I0524 09:37:58.536738 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.36786 (* 1 = 6.36786 loss)
I0524 09:37:58.536756 11654 sgd_solver.cpp:112] Iteration 56630, lr = 0.1
I0524 09:38:06.450675 11654 solver.cpp:239] Iteration 56640 (1.26364 iter/s, 7.91362s/10 iters), loss = 5.97241
I0524 09:38:06.450760 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97241 (* 1 = 5.97241 loss)
I0524 09:38:06.450783 11654 sgd_solver.cpp:112] Iteration 56640, lr = 0.1
I0524 09:38:14.350093 11654 solver.cpp:239] Iteration 56650 (1.26599 iter/s, 7.89897s/10 iters), loss = 6.20966
I0524 09:38:14.350148 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20966 (* 1 = 6.20966 loss)
I0524 09:38:14.611716 11654 sgd_solver.cpp:112] Iteration 56650, lr = 0.1
I0524 09:38:22.468858 11654 solver.cpp:239] Iteration 56660 (1.23177 iter/s, 8.11839s/10 iters), loss = 5.62022
I0524 09:38:22.468914 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62022 (* 1 = 5.62022 loss)
I0524 09:38:22.469065 11654 sgd_solver.cpp:112] Iteration 56660, lr = 0.1
I0524 09:38:30.552148 11654 solver.cpp:239] Iteration 56670 (1.23718 iter/s, 8.08292s/10 iters), loss = 6.25067
I0524 09:38:30.552459 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25067 (* 1 = 6.25067 loss)
I0524 09:38:30.552534 11654 sgd_solver.cpp:112] Iteration 56670, lr = 0.1
I0524 09:38:40.435925 11654 solver.cpp:239] Iteration 56680 (1.01203 iter/s, 9.88114s/10 iters), loss = 5.19973
I0524 09:38:40.435989 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.19973 (* 1 = 5.19973 loss)
I0524 09:38:40.436041 11654 sgd_solver.cpp:112] Iteration 56680, lr = 0.1
I0524 09:38:46.876263 11654 solver.cpp:239] Iteration 56690 (1.55279 iter/s, 6.44002s/10 iters), loss = 6.1858
I0524 09:38:46.876355 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1858 (* 1 = 6.1858 loss)
I0524 09:38:46.876382 11654 sgd_solver.cpp:112] Iteration 56690, lr = 0.1
I0524 09:38:53.319852 11654 solver.cpp:239] Iteration 56700 (1.5521 iter/s, 6.44287s/10 iters), loss = 6.64112
I0524 09:38:53.319921 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64112 (* 1 = 6.64112 loss)
I0524 09:38:53.320019 11654 sgd_solver.cpp:112] Iteration 56700, lr = 0.1
I0524 09:39:00.970974 11654 solver.cpp:239] Iteration 56710 (1.30706 iter/s, 7.65077s/10 iters), loss = 5.29137
I0524 09:39:00.971118 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.29137 (* 1 = 5.29137 loss)
I0524 09:39:00.971138 11654 sgd_solver.cpp:112] Iteration 56710, lr = 0.1
I0524 09:39:08.291940 11654 solver.cpp:239] Iteration 56720 (1.36603 iter/s, 7.32051s/10 iters), loss = 6.22241
I0524 09:39:08.291992 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.22241 (* 1 = 6.22241 loss)
I0524 09:39:08.292008 11654 sgd_solver.cpp:112] Iteration 56720, lr = 0.1
I0524 09:39:15.306609 11654 solver.cpp:239] Iteration 56730 (1.42609 iter/s, 7.01217s/10 iters), loss = 5.26291
I0524 09:39:15.306689 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26291 (* 1 = 5.26291 loss)
I0524 09:39:15.397845 11654 sgd_solver.cpp:112] Iteration 56730, lr = 0.1
I0524 09:39:21.922874 11654 solver.cpp:239] Iteration 56740 (1.5115 iter/s, 6.61593s/10 iters), loss = 7.19018
I0524 09:39:21.922950 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19018 (* 1 = 7.19018 loss)
I0524 09:39:21.922971 11654 sgd_solver.cpp:112] Iteration 56740, lr = 0.1
I0524 09:39:29.818461 11654 solver.cpp:239] Iteration 56750 (1.26659 iter/s, 7.89523s/10 iters), loss = 6.13545
I0524 09:39:29.818511 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13545 (* 1 = 6.13545 loss)
I0524 09:39:29.822404 11654 sgd_solver.cpp:112] Iteration 56750, lr = 0.1
I0524 09:39:36.928056 11654 solver.cpp:239] Iteration 56760 (1.40662 iter/s, 7.10926s/10 iters), loss = 6.12569
I0524 09:39:36.928277 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12569 (* 1 = 6.12569 loss)
I0524 09:39:36.928302 11654 sgd_solver.cpp:112] Iteration 56760, lr = 0.1
I0524 09:39:43.791189 11654 solver.cpp:239] Iteration 56770 (1.4576 iter/s, 6.8606s/10 iters), loss = 6.31087
I0524 09:39:43.791239 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31087 (* 1 = 6.31087 loss)
I0524 09:39:43.791590 11654 sgd_solver.cpp:112] Iteration 56770, lr = 0.1
I0524 09:39:50.848183 11654 solver.cpp:239] Iteration 56780 (1.4171 iter/s, 7.05665s/10 iters), loss = 6.21627
I0524 09:39:50.848253 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21627 (* 1 = 6.21627 loss)
I0524 09:39:50.951454 11654 sgd_solver.cpp:112] Iteration 56780, lr = 0.1
I0524 09:39:57.616654 11654 solver.cpp:239] Iteration 56790 (1.47752 iter/s, 6.76811s/10 iters), loss = 5.46913
I0524 09:39:57.616727 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46913 (* 1 = 5.46913 loss)
I0524 09:39:57.667969 11654 sgd_solver.cpp:112] Iteration 56790, lr = 0.1
I0524 09:40:06.186674 11654 solver.cpp:239] Iteration 56800 (1.16692 iter/s, 8.5696s/10 iters), loss = 5.31083
I0524 09:40:06.186784 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.31083 (* 1 = 5.31083 loss)
I0524 09:40:06.187239 11654 sgd_solver.cpp:112] Iteration 56800, lr = 0.1
I0524 09:40:12.900565 11654 solver.cpp:239] Iteration 56810 (1.48953 iter/s, 6.71352s/10 iters), loss = 6.53384
I0524 09:40:12.900873 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53384 (* 1 = 6.53384 loss)
I0524 09:40:12.900935 11654 sgd_solver.cpp:112] Iteration 56810, lr = 0.1
I0524 09:40:19.359591 11654 solver.cpp:239] Iteration 56820 (1.54859 iter/s, 6.45749s/10 iters), loss = 6.54437
I0524 09:40:19.359668 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.54437 (* 1 = 6.54437 loss)
I0524 09:40:20.076287 11654 sgd_solver.cpp:112] Iteration 56820, lr = 0.1
I0524 09:40:27.081871 11654 solver.cpp:239] Iteration 56830 (1.29502 iter/s, 7.72191s/10 iters), loss = 6.20728
I0524 09:40:27.081943 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20728 (* 1 = 6.20728 loss)
I0524 09:40:27.082036 11654 sgd_solver.cpp:112] Iteration 56830, lr = 0.1
I0524 09:40:34.540834 11654 solver.cpp:239] Iteration 56840 (1.34073 iter/s, 7.4586s/10 iters), loss = 5.55428
I0524 09:40:34.540920 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55428 (* 1 = 5.55428 loss)
I0524 09:40:34.541040 11654 sgd_solver.cpp:112] Iteration 56840, lr = 0.1
I0524 09:40:41.280285 11654 solver.cpp:239] Iteration 56850 (1.48387 iter/s, 6.73912s/10 iters), loss = 5.9846
I0524 09:40:41.280347 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.9846 (* 1 = 5.9846 loss)
I0524 09:40:41.280921 11654 sgd_solver.cpp:112] Iteration 56850, lr = 0.1
I0524 09:40:48.816232 11654 solver.cpp:239] Iteration 56860 (1.32703 iter/s, 7.5356s/10 iters), loss = 6.72984
I0524 09:40:48.816583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72984 (* 1 = 6.72984 loss)
I0524 09:40:48.818258 11654 sgd_solver.cpp:112] Iteration 56860, lr = 0.1
I0524 09:40:55.602053 11654 solver.cpp:239] Iteration 56870 (1.47376 iter/s, 6.78535s/10 iters), loss = 6.77588
I0524 09:40:55.602108 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77588 (* 1 = 6.77588 loss)
I0524 09:40:55.602128 11654 sgd_solver.cpp:112] Iteration 56870, lr = 0.1
I0524 09:41:02.683559 11654 solver.cpp:239] Iteration 56880 (1.4122 iter/s, 7.08117s/10 iters), loss = 6.45768
I0524 09:41:02.683647 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45768 (* 1 = 6.45768 loss)
I0524 09:41:02.683665 11654 sgd_solver.cpp:112] Iteration 56880, lr = 0.1
I0524 09:41:10.301234 11654 solver.cpp:239] Iteration 56890 (1.31281 iter/s, 7.61723s/10 iters), loss = 5.62334
I0524 09:41:10.301313 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62334 (* 1 = 5.62334 loss)
I0524 09:41:10.301442 11654 sgd_solver.cpp:112] Iteration 56890, lr = 0.1
I0524 09:41:18.598364 11654 solver.cpp:239] Iteration 56900 (1.20529 iter/s, 8.29675s/10 iters), loss = 5.8506
I0524 09:41:18.598434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8506 (* 1 = 5.8506 loss)
I0524 09:41:18.624498 11654 sgd_solver.cpp:112] Iteration 56900, lr = 0.1
I0524 09:41:27.249819 11654 solver.cpp:239] Iteration 56910 (1.15593 iter/s, 8.65105s/10 iters), loss = 6.02495
I0524 09:41:27.254603 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02495 (* 1 = 6.02495 loss)
I0524 09:41:27.254637 11654 sgd_solver.cpp:112] Iteration 56910, lr = 0.1
I0524 09:41:34.430829 11654 solver.cpp:239] Iteration 56920 (1.39394 iter/s, 7.1739s/10 iters), loss = 5.26308
I0524 09:41:34.430876 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.26308 (* 1 = 5.26308 loss)
I0524 09:41:34.430891 11654 sgd_solver.cpp:112] Iteration 56920, lr = 0.1
I0524 09:41:44.259124 11654 solver.cpp:239] Iteration 56930 (1.01752 iter/s, 9.82785s/10 iters), loss = 4.93145
I0524 09:41:44.259196 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.93145 (* 1 = 4.93145 loss)
I0524 09:41:44.260752 11654 sgd_solver.cpp:112] Iteration 56930, lr = 0.1
I0524 09:41:52.111820 11654 solver.cpp:239] Iteration 56940 (1.27351 iter/s, 7.85229s/10 iters), loss = 6.26163
I0524 09:41:52.111953 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.26163 (* 1 = 6.26163 loss)
I0524 09:41:52.112030 11654 sgd_solver.cpp:112] Iteration 56940, lr = 0.1
I0524 09:42:01.662004 11654 solver.cpp:239] Iteration 56950 (1.04715 iter/s, 9.54972s/10 iters), loss = 5.49727
I0524 09:42:01.662210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49727 (* 1 = 5.49727 loss)
I0524 09:42:01.662539 11654 sgd_solver.cpp:112] Iteration 56950, lr = 0.1
I0524 09:42:08.435533 11654 solver.cpp:239] Iteration 56960 (1.47644 iter/s, 6.77305s/10 iters), loss = 6.34458
I0524 09:42:08.435634 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.34458 (* 1 = 6.34458 loss)
I0524 09:42:08.477360 11654 sgd_solver.cpp:112] Iteration 56960, lr = 0.1
I0524 09:42:15.129228 11654 solver.cpp:239] Iteration 56970 (1.49402 iter/s, 6.69337s/10 iters), loss = 6.82599
I0524 09:42:15.129293 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82599 (* 1 = 6.82599 loss)
I0524 09:42:15.129348 11654 sgd_solver.cpp:112] Iteration 56970, lr = 0.1
I0524 09:42:23.220330 11654 solver.cpp:239] Iteration 56980 (1.23598 iter/s, 8.09072s/10 iters), loss = 5.60219
I0524 09:42:23.220402 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60219 (* 1 = 5.60219 loss)
I0524 09:42:23.220430 11654 sgd_solver.cpp:112] Iteration 56980, lr = 0.1
I0524 09:42:30.147472 11654 solver.cpp:239] Iteration 56990 (1.44368 iter/s, 6.92676s/10 iters), loss = 5.60896
I0524 09:42:30.147531 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.60896 (* 1 = 5.60896 loss)
I0524 09:42:30.148011 11654 sgd_solver.cpp:112] Iteration 56990, lr = 0.1
I0524 09:42:36.839694 11654 solver.cpp:239] Iteration 57000 (1.49434 iter/s, 6.6919s/10 iters), loss = 5.0334
I0524 09:42:36.839993 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.0334 (* 1 = 5.0334 loss)
I0524 09:42:37.322099 11654 sgd_solver.cpp:112] Iteration 57000, lr = 0.1
I0524 09:42:46.326706 11654 solver.cpp:239] Iteration 57010 (1.05414 iter/s, 9.4864s/10 iters), loss = 6.80119
I0524 09:42:46.326823 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.80119 (* 1 = 6.80119 loss)
I0524 09:42:46.955557 11654 sgd_solver.cpp:112] Iteration 57010, lr = 0.1
I0524 09:42:53.541713 11654 solver.cpp:239] Iteration 57020 (1.38607 iter/s, 7.21466s/10 iters), loss = 5.25838
I0524 09:42:53.541769 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.25838 (* 1 = 5.25838 loss)
I0524 09:42:53.684664 11654 sgd_solver.cpp:112] Iteration 57020, lr = 0.1
I0524 09:43:01.654738 11654 solver.cpp:239] Iteration 57030 (1.23264 iter/s, 8.11264s/10 iters), loss = 6.21545
I0524 09:43:01.654856 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21545 (* 1 = 6.21545 loss)
I0524 09:43:01.654881 11654 sgd_solver.cpp:112] Iteration 57030, lr = 0.1
I0524 09:43:10.742388 11654 solver.cpp:239] Iteration 57040 (1.10071 iter/s, 9.08503s/10 iters), loss = 5.75203
I0524 09:43:10.742658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75203 (* 1 = 5.75203 loss)
I0524 09:43:10.742708 11654 sgd_solver.cpp:112] Iteration 57040, lr = 0.1
I0524 09:43:17.888948 11654 solver.cpp:239] Iteration 57050 (1.39958 iter/s, 7.145s/10 iters), loss = 6.33896
I0524 09:43:17.889050 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.33896 (* 1 = 6.33896 loss)
I0524 09:43:17.889185 11654 sgd_solver.cpp:112] Iteration 57050, lr = 0.1
I0524 09:43:25.552345 11654 solver.cpp:239] Iteration 57060 (1.30498 iter/s, 7.66296s/10 iters), loss = 5.81885
I0524 09:43:25.552480 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81885 (* 1 = 5.81885 loss)
I0524 09:43:25.586441 11654 sgd_solver.cpp:112] Iteration 57060, lr = 0.1
I0524 09:43:33.868365 11654 solver.cpp:239] Iteration 57070 (1.20256 iter/s, 8.3156s/10 iters), loss = 5.97397
I0524 09:43:33.868443 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97397 (* 1 = 5.97397 loss)
I0524 09:43:33.868703 11654 sgd_solver.cpp:112] Iteration 57070, lr = 0.1
I0524 09:43:40.296223 11654 solver.cpp:239] Iteration 57080 (1.55581 iter/s, 6.42751s/10 iters), loss = 5.99039
I0524 09:43:40.296344 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.99039 (* 1 = 5.99039 loss)
I0524 09:43:40.296448 11654 sgd_solver.cpp:112] Iteration 57080, lr = 0.1
I0524 09:43:48.319870 11654 solver.cpp:239] Iteration 57090 (1.24638 iter/s, 8.02324s/10 iters), loss = 6.42941
I0524 09:43:48.320127 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.42941 (* 1 = 6.42941 loss)
I0524 09:43:48.964594 11654 sgd_solver.cpp:112] Iteration 57090, lr = 0.1
I0524 09:43:55.626354 11654 solver.cpp:239] Iteration 57100 (1.36876 iter/s, 7.3059s/10 iters), loss = 5.35088
I0524 09:43:55.626447 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.35088 (* 1 = 5.35088 loss)
I0524 09:43:55.626513 11654 sgd_solver.cpp:112] Iteration 57100, lr = 0.1
I0524 09:44:03.929581 11654 solver.cpp:239] Iteration 57110 (1.20441 iter/s, 8.30283s/10 iters), loss = 7.03189
I0524 09:44:03.929632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.03189 (* 1 = 7.03189 loss)
I0524 09:44:03.935578 11654 sgd_solver.cpp:112] Iteration 57110, lr = 0.1
I0524 09:44:10.502955 11654 solver.cpp:239] Iteration 57120 (1.52136 iter/s, 6.57306s/10 iters), loss = 4.93959
I0524 09:44:10.503060 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.93959 (* 1 = 4.93959 loss)
I0524 09:44:10.503098 11654 sgd_solver.cpp:112] Iteration 57120, lr = 0.1
I0524 09:44:17.325814 11654 solver.cpp:239] Iteration 57130 (1.46574 iter/s, 6.82248s/10 iters), loss = 5.7236
I0524 09:44:17.325968 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.7236 (* 1 = 5.7236 loss)
I0524 09:44:17.326014 11654 sgd_solver.cpp:112] Iteration 57130, lr = 0.1
I0524 09:44:25.507705 11654 solver.cpp:239] Iteration 57140 (1.22228 iter/s, 8.18142s/10 iters), loss = 6.82908
I0524 09:44:25.507932 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82908 (* 1 = 6.82908 loss)
I0524 09:44:25.507954 11654 sgd_solver.cpp:112] Iteration 57140, lr = 0.1
I0524 09:44:34.801182 11654 solver.cpp:239] Iteration 57150 (1.07615 iter/s, 9.29241s/10 iters), loss = 6.90529
I0524 09:44:34.801249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.90529 (* 1 = 6.90529 loss)
I0524 09:44:34.801285 11654 sgd_solver.cpp:112] Iteration 57150, lr = 0.1
I0524 09:44:42.748587 11654 solver.cpp:239] Iteration 57160 (1.25834 iter/s, 7.94697s/10 iters), loss = 6.0034
I0524 09:44:42.748647 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0034 (* 1 = 6.0034 loss)
I0524 09:44:42.748666 11654 sgd_solver.cpp:112] Iteration 57160, lr = 0.1
I0524 09:44:50.521420 11654 solver.cpp:239] Iteration 57170 (1.28659 iter/s, 7.77246s/10 iters), loss = 5.65754
I0524 09:44:50.521520 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.65754 (* 1 = 5.65754 loss)
I0524 09:44:50.521551 11654 sgd_solver.cpp:112] Iteration 57170, lr = 0.1
I0524 09:44:59.963498 11654 solver.cpp:239] Iteration 57180 (1.05914 iter/s, 9.4416s/10 iters), loss = 5.91423
I0524 09:44:59.963742 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91423 (* 1 = 5.91423 loss)
I0524 09:44:59.963791 11654 sgd_solver.cpp:112] Iteration 57180, lr = 0.1
I0524 09:45:06.691877 11654 solver.cpp:239] Iteration 57190 (1.48635 iter/s, 6.72787s/10 iters), loss = 6.45533
I0524 09:45:06.691985 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45533 (* 1 = 6.45533 loss)
I0524 09:45:06.692006 11654 sgd_solver.cpp:112] Iteration 57190, lr = 0.1
I0524 09:45:13.384027 11654 solver.cpp:239] Iteration 57200 (1.4946 iter/s, 6.69076s/10 iters), loss = 5.20968
I0524 09:45:13.384106 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.20968 (* 1 = 5.20968 loss)
I0524 09:45:13.384255 11654 sgd_solver.cpp:112] Iteration 57200, lr = 0.1
I0524 09:45:19.372339 11654 solver.cpp:239] Iteration 57210 (1.67001 iter/s, 5.98799s/10 iters), loss = 5.41544
I0524 09:45:19.372406 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.41544 (* 1 = 5.41544 loss)
I0524 09:45:19.372426 11654 sgd_solver.cpp:112] Iteration 57210, lr = 0.1
I0524 09:45:29.025146 11654 solver.cpp:239] Iteration 57220 (1.03602 iter/s, 9.65231s/10 iters), loss = 6.28796
I0524 09:45:29.025219 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28796 (* 1 = 6.28796 loss)
I0524 09:45:29.025770 11654 sgd_solver.cpp:112] Iteration 57220, lr = 0.1
I0524 09:45:37.003033 11654 solver.cpp:239] Iteration 57230 (1.25352 iter/s, 7.97751s/10 iters), loss = 6.82136
I0524 09:45:37.003335 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82136 (* 1 = 6.82136 loss)
I0524 09:45:37.003383 11654 sgd_solver.cpp:112] Iteration 57230, lr = 0.1
I0524 09:45:45.616614 11654 solver.cpp:239] Iteration 57240 (1.16132 iter/s, 8.61087s/10 iters), loss = 6.48249
I0524 09:45:45.616696 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48249 (* 1 = 6.48249 loss)
I0524 09:45:45.616725 11654 sgd_solver.cpp:112] Iteration 57240, lr = 0.1
I0524 09:45:51.944783 11654 solver.cpp:239] Iteration 57250 (1.58032 iter/s, 6.32782s/10 iters), loss = 6.02464
I0524 09:45:51.944906 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02464 (* 1 = 6.02464 loss)
I0524 09:45:51.944977 11654 sgd_solver.cpp:112] Iteration 57250, lr = 0.1
I0524 09:45:59.638404 11654 solver.cpp:239] Iteration 57260 (1.29984 iter/s, 7.69326s/10 iters), loss = 5.97862
I0524 09:45:59.638466 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97862 (* 1 = 5.97862 loss)
I0524 09:45:59.638622 11654 sgd_solver.cpp:112] Iteration 57260, lr = 0.1
I0524 09:46:07.907749 11654 solver.cpp:239] Iteration 57270 (1.20935 iter/s, 8.26892s/10 iters), loss = 5.96219
I0524 09:46:07.908073 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96219 (* 1 = 5.96219 loss)
I0524 09:46:07.908123 11654 sgd_solver.cpp:112] Iteration 57270, lr = 0.1
I0524 09:46:14.321490 11654 solver.cpp:239] Iteration 57280 (1.55928 iter/s, 6.41322s/10 iters), loss = 6.23526
I0524 09:46:14.321544 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.23526 (* 1 = 6.23526 loss)
I0524 09:46:14.321620 11654 sgd_solver.cpp:112] Iteration 57280, lr = 0.1
I0524 09:46:21.977830 11654 solver.cpp:239] Iteration 57290 (1.30617 iter/s, 7.65598s/10 iters), loss = 5.04652
I0524 09:46:21.977900 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.04652 (* 1 = 5.04652 loss)
I0524 09:46:21.978117 11654 sgd_solver.cpp:112] Iteration 57290, lr = 0.1
I0524 09:46:29.445850 11654 solver.cpp:239] Iteration 57300 (1.33911 iter/s, 7.46767s/10 iters), loss = 5.88539
I0524 09:46:29.445911 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88539 (* 1 = 5.88539 loss)
I0524 09:46:29.445928 11654 sgd_solver.cpp:112] Iteration 57300, lr = 0.1
I0524 09:46:36.892343 11654 solver.cpp:239] Iteration 57310 (1.34299 iter/s, 7.44609s/10 iters), loss = 5.66533
I0524 09:46:36.892386 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66533 (* 1 = 5.66533 loss)
I0524 09:46:37.514678 11654 sgd_solver.cpp:112] Iteration 57310, lr = 0.1
I0524 09:46:44.616369 11654 solver.cpp:239] Iteration 57320 (1.29472 iter/s, 7.72366s/10 iters), loss = 6.13288
I0524 09:46:44.616572 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13288 (* 1 = 6.13288 loss)
I0524 09:46:44.616964 11654 sgd_solver.cpp:112] Iteration 57320, lr = 0.1
I0524 09:46:52.819211 11654 solver.cpp:239] Iteration 57330 (1.21916 iter/s, 8.20234s/10 iters), loss = 5.63992
I0524 09:46:52.819275 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63992 (* 1 = 5.63992 loss)
I0524 09:46:52.819293 11654 sgd_solver.cpp:112] Iteration 57330, lr = 0.1
I0524 09:47:00.869354 11654 solver.cpp:239] Iteration 57340 (1.24228 iter/s, 8.0497s/10 iters), loss = 6.83614
I0524 09:47:00.869419 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.83614 (* 1 = 6.83614 loss)
I0524 09:47:00.869753 11654 sgd_solver.cpp:112] Iteration 57340, lr = 0.1
I0524 09:47:08.682380 11654 solver.cpp:239] Iteration 57350 (1.27997 iter/s, 7.81267s/10 iters), loss = 5.75371
I0524 09:47:08.682441 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.75371 (* 1 = 5.75371 loss)
I0524 09:47:09.072217 11654 sgd_solver.cpp:112] Iteration 57350, lr = 0.1
I0524 09:47:15.685794 11654 solver.cpp:239] Iteration 57360 (1.42794 iter/s, 7.00308s/10 iters), loss = 6.17436
I0524 09:47:15.686010 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17436 (* 1 = 6.17436 loss)
I0524 09:47:15.686043 11654 sgd_solver.cpp:112] Iteration 57360, lr = 0.1
I0524 09:47:22.686658 11654 solver.cpp:239] Iteration 57370 (1.42849 iter/s, 7.00039s/10 iters), loss = 7.26698
I0524 09:47:22.686769 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.26698 (* 1 = 7.26698 loss)
I0524 09:47:23.202056 11654 sgd_solver.cpp:112] Iteration 57370, lr = 0.1
I0524 09:47:30.883986 11654 solver.cpp:239] Iteration 57380 (1.21997 iter/s, 8.19691s/10 iters), loss = 5.69292
I0524 09:47:30.884039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.69292 (* 1 = 5.69292 loss)
I0524 09:47:30.884057 11654 sgd_solver.cpp:112] Iteration 57380, lr = 0.1
I0524 09:47:38.091971 11654 solver.cpp:239] Iteration 57390 (1.38742 iter/s, 7.20764s/10 iters), loss = 5.58847
I0524 09:47:38.092039 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.58847 (* 1 = 5.58847 loss)
I0524 09:47:38.092157 11654 sgd_solver.cpp:112] Iteration 57390, lr = 0.1
I0524 09:47:46.090498 11654 solver.cpp:239] Iteration 57400 (1.25029 iter/s, 7.99814s/10 iters), loss = 6.82008
I0524 09:47:46.090688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82008 (* 1 = 6.82008 loss)
I0524 09:47:46.090734 11654 sgd_solver.cpp:112] Iteration 57400, lr = 0.1
I0524 09:47:53.793972 11654 solver.cpp:239] Iteration 57410 (1.29824 iter/s, 7.70271s/10 iters), loss = 5.64014
I0524 09:47:53.794045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64014 (* 1 = 5.64014 loss)
I0524 09:47:53.794064 11654 sgd_solver.cpp:112] Iteration 57410, lr = 0.1
I0524 09:48:00.648808 11654 solver.cpp:239] Iteration 57420 (1.45889 iter/s, 6.85451s/10 iters), loss = 4.72121
I0524 09:48:00.648869 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.72121 (* 1 = 4.72121 loss)
I0524 09:48:00.648885 11654 sgd_solver.cpp:112] Iteration 57420, lr = 0.1
I0524 09:48:08.095605 11654 solver.cpp:239] Iteration 57430 (1.34292 iter/s, 7.44646s/10 iters), loss = 6.47392
I0524 09:48:08.095667 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.47392 (* 1 = 6.47392 loss)
I0524 09:48:08.401113 11654 sgd_solver.cpp:112] Iteration 57430, lr = 0.1
I0524 09:48:15.620375 11654 solver.cpp:239] Iteration 57440 (1.32901 iter/s, 7.52443s/10 iters), loss = 5.78786
I0524 09:48:15.620438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78786 (* 1 = 5.78786 loss)
I0524 09:48:16.277168 11654 sgd_solver.cpp:112] Iteration 57440, lr = 0.1
I0524 09:48:24.598812 11654 solver.cpp:239] Iteration 57450 (1.11383 iter/s, 8.97803s/10 iters), loss = 6.06274
I0524 09:48:24.598866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06274 (* 1 = 6.06274 loss)
I0524 09:48:24.599206 11654 sgd_solver.cpp:112] Iteration 57450, lr = 0.1
I0524 09:48:32.237318 11654 solver.cpp:239] Iteration 57460 (1.30922 iter/s, 7.63814s/10 iters), loss = 5.82722
I0524 09:48:32.237397 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82722 (* 1 = 5.82722 loss)
I0524 09:48:32.237416 11654 sgd_solver.cpp:112] Iteration 57460, lr = 0.1
I0524 09:48:38.787840 11654 solver.cpp:239] Iteration 57470 (1.52668 iter/s, 6.55016s/10 iters), loss = 6.17858
I0524 09:48:38.787891 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17858 (* 1 = 6.17858 loss)
I0524 09:48:38.788236 11654 sgd_solver.cpp:112] Iteration 57470, lr = 0.1
I0524 09:48:45.116303 11654 solver.cpp:239] Iteration 57480 (1.58024 iter/s, 6.32816s/10 iters), loss = 6.15873
I0524 09:48:45.116359 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15873 (* 1 = 6.15873 loss)
I0524 09:48:45.116376 11654 sgd_solver.cpp:112] Iteration 57480, lr = 0.1
I0524 09:48:52.233405 11654 solver.cpp:239] Iteration 57490 (1.40513 iter/s, 7.11677s/10 iters), loss = 5.63417
I0524 09:48:52.233572 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.63417 (* 1 = 5.63417 loss)
I0524 09:48:52.234038 11654 sgd_solver.cpp:112] Iteration 57490, lr = 0.1
I0524 09:48:59.014652 11654 solver.cpp:239] Iteration 57500 (1.47475 iter/s, 6.7808s/10 iters), loss = 5.56442
I0524 09:48:59.014727 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.56442 (* 1 = 5.56442 loss)
I0524 09:48:59.014883 11654 sgd_solver.cpp:112] Iteration 57500, lr = 0.1
I0524 09:49:06.921705 11654 solver.cpp:239] Iteration 57510 (1.26476 iter/s, 7.90665s/10 iters), loss = 5.66219
I0524 09:49:06.921752 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66219 (* 1 = 5.66219 loss)
I0524 09:49:06.922142 11654 sgd_solver.cpp:112] Iteration 57510, lr = 0.1
I0524 09:49:15.456192 11654 solver.cpp:239] Iteration 57520 (1.17177 iter/s, 8.53408s/10 iters), loss = 6.67979
I0524 09:49:15.456266 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.67979 (* 1 = 6.67979 loss)
I0524 09:49:15.456287 11654 sgd_solver.cpp:112] Iteration 57520, lr = 0.1
I0524 09:49:23.404362 11654 solver.cpp:239] Iteration 57530 (1.25821 iter/s, 7.9478s/10 iters), loss = 6.18557
I0524 09:49:23.404593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.18557 (* 1 = 6.18557 loss)
I0524 09:49:23.404631 11654 sgd_solver.cpp:112] Iteration 57530, lr = 0.1
I0524 09:49:31.946727 11654 solver.cpp:239] Iteration 57540 (1.17072 iter/s, 8.54177s/10 iters), loss = 5.84821
I0524 09:49:31.946804 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84821 (* 1 = 5.84821 loss)
I0524 09:49:31.946833 11654 sgd_solver.cpp:112] Iteration 57540, lr = 0.1
I0524 09:49:38.944708 11654 solver.cpp:239] Iteration 57550 (1.42907 iter/s, 6.99755s/10 iters), loss = 6.4729
I0524 09:49:38.944772 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4729 (* 1 = 6.4729 loss)
I0524 09:49:38.946298 11654 sgd_solver.cpp:112] Iteration 57550, lr = 0.1
I0524 09:49:45.633911 11654 solver.cpp:239] Iteration 57560 (1.49502 iter/s, 6.68888s/10 iters), loss = 4.69082
I0524 09:49:45.634003 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.69082 (* 1 = 4.69082 loss)
I0524 09:49:45.634027 11654 sgd_solver.cpp:112] Iteration 57560, lr = 0.1
I0524 09:49:52.607894 11654 solver.cpp:239] Iteration 57570 (1.43397 iter/s, 6.97365s/10 iters), loss = 5.67689
I0524 09:49:52.607975 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.67689 (* 1 = 5.67689 loss)
I0524 09:49:52.663949 11654 sgd_solver.cpp:112] Iteration 57570, lr = 0.1
I0524 09:50:01.034057 11654 solver.cpp:239] Iteration 57580 (1.18684 iter/s, 8.42575s/10 iters), loss = 5.59182
I0524 09:50:01.034278 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.59182 (* 1 = 5.59182 loss)
I0524 09:50:01.034307 11654 sgd_solver.cpp:112] Iteration 57580, lr = 0.1
I0524 09:50:07.363029 11654 solver.cpp:239] Iteration 57590 (1.5802 iter/s, 6.32831s/10 iters), loss = 6.4877
I0524 09:50:07.363080 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4877 (* 1 = 6.4877 loss)
I0524 09:50:07.363260 11654 sgd_solver.cpp:112] Iteration 57590, lr = 0.1
I0524 09:50:15.927489 11654 solver.cpp:239] Iteration 57600 (1.16767 iter/s, 8.56407s/10 iters), loss = 5.64113
I0524 09:50:15.927551 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64113 (* 1 = 5.64113 loss)
I0524 09:50:16.936558 11654 sgd_solver.cpp:112] Iteration 57600, lr = 0.1
I0524 09:50:23.566000 11654 solver.cpp:239] Iteration 57610 (1.30922 iter/s, 7.63815s/10 iters), loss = 6.31262
I0524 09:50:23.566048 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.31262 (* 1 = 6.31262 loss)
I0524 09:50:23.566382 11654 sgd_solver.cpp:112] Iteration 57610, lr = 0.1
I0524 09:50:31.359066 11654 solver.cpp:239] Iteration 57620 (1.28325 iter/s, 7.79269s/10 iters), loss = 6.29484
I0524 09:50:31.359311 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.29484 (* 1 = 6.29484 loss)
I0524 09:50:31.359359 11654 sgd_solver.cpp:112] Iteration 57620, lr = 0.1
I0524 09:50:38.073413 11654 solver.cpp:239] Iteration 57630 (1.48989 iter/s, 6.7119s/10 iters), loss = 5.37512
I0524 09:50:38.073470 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.37512 (* 1 = 5.37512 loss)
I0524 09:50:38.073643 11654 sgd_solver.cpp:112] Iteration 57630, lr = 0.1
I0524 09:50:44.758667 11654 solver.cpp:239] Iteration 57640 (1.4959 iter/s, 6.68493s/10 iters), loss = 6.20481
I0524 09:50:44.758759 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.20481 (* 1 = 6.20481 loss)
I0524 09:50:44.947387 11654 sgd_solver.cpp:112] Iteration 57640, lr = 0.1
I0524 09:50:52.111795 11654 solver.cpp:239] Iteration 57650 (1.36003 iter/s, 7.35276s/10 iters), loss = 5.91335
I0524 09:50:52.111838 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.91335 (* 1 = 5.91335 loss)
I0524 09:50:52.111853 11654 sgd_solver.cpp:112] Iteration 57650, lr = 0.1
I0524 09:50:58.970101 11654 solver.cpp:239] Iteration 57660 (1.45816 iter/s, 6.85794s/10 iters), loss = 5.78098
I0524 09:50:58.970227 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78098 (* 1 = 5.78098 loss)
I0524 09:50:58.970258 11654 sgd_solver.cpp:112] Iteration 57660, lr = 0.1
I0524 09:51:06.668758 11654 solver.cpp:239] Iteration 57670 (1.29906 iter/s, 7.69789s/10 iters), loss = 6.48287
I0524 09:51:06.669067 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.48287 (* 1 = 6.48287 loss)
I0524 09:51:06.669154 11654 sgd_solver.cpp:112] Iteration 57670, lr = 0.1
I0524 09:51:14.195664 11654 solver.cpp:239] Iteration 57680 (1.32877 iter/s, 7.52576s/10 iters), loss = 6.01718
I0524 09:51:14.195755 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.01718 (* 1 = 6.01718 loss)
I0524 09:51:14.195778 11654 sgd_solver.cpp:112] Iteration 57680, lr = 0.1
I0524 09:51:22.560300 11654 solver.cpp:239] Iteration 57690 (1.19599 iter/s, 8.36129s/10 iters), loss = 6.43288
I0524 09:51:22.560461 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43288 (* 1 = 6.43288 loss)
I0524 09:51:22.560521 11654 sgd_solver.cpp:112] Iteration 57690, lr = 0.1
I0524 09:51:28.993518 11654 solver.cpp:239] Iteration 57700 (1.55489 iter/s, 6.43132s/10 iters), loss = 5.49885
I0524 09:51:28.993577 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49885 (* 1 = 5.49885 loss)
I0524 09:51:29.324914 11654 sgd_solver.cpp:112] Iteration 57700, lr = 0.1
I0524 09:51:35.954128 11654 solver.cpp:239] Iteration 57710 (1.43673 iter/s, 6.96026s/10 iters), loss = 5.705
I0524 09:51:35.954205 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.705 (* 1 = 5.705 loss)
I0524 09:51:35.954231 11654 sgd_solver.cpp:112] Iteration 57710, lr = 0.1
I0524 09:51:42.441190 11654 solver.cpp:239] Iteration 57720 (1.54161 iter/s, 6.48674s/10 iters), loss = 6.50907
I0524 09:51:42.441639 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50907 (* 1 = 6.50907 loss)
I0524 09:51:42.441722 11654 sgd_solver.cpp:112] Iteration 57720, lr = 0.1
I0524 09:51:50.214025 11654 solver.cpp:239] Iteration 57730 (1.28696 iter/s, 7.77026s/10 iters), loss = 5.55558
I0524 09:51:50.214093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.55558 (* 1 = 5.55558 loss)
I0524 09:51:50.214112 11654 sgd_solver.cpp:112] Iteration 57730, lr = 0.1
I0524 09:51:58.460397 11654 solver.cpp:239] Iteration 57740 (1.21272 iter/s, 8.24593s/10 iters), loss = 6.25012
I0524 09:51:58.460455 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25012 (* 1 = 6.25012 loss)
I0524 09:51:58.461279 11654 sgd_solver.cpp:112] Iteration 57740, lr = 0.1
I0524 09:52:06.874686 11654 solver.cpp:239] Iteration 57750 (1.18851 iter/s, 8.41389s/10 iters), loss = 5.13631
I0524 09:52:06.874820 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.13631 (* 1 = 5.13631 loss)
I0524 09:52:06.874855 11654 sgd_solver.cpp:112] Iteration 57750, lr = 0.1
I0524 09:52:14.607539 11654 solver.cpp:239] Iteration 57760 (1.29324 iter/s, 7.73249s/10 iters), loss = 6.65618
I0524 09:52:14.607764 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65618 (* 1 = 6.65618 loss)
I0524 09:52:14.607805 11654 sgd_solver.cpp:112] Iteration 57760, lr = 0.1
I0524 09:52:23.364783 11654 solver.cpp:239] Iteration 57770 (1.14201 iter/s, 8.7565s/10 iters), loss = 6.69426
I0524 09:52:23.364881 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69426 (* 1 = 6.69426 loss)
I0524 09:52:23.364912 11654 sgd_solver.cpp:112] Iteration 57770, lr = 0.1
I0524 09:52:30.365990 11654 solver.cpp:239] Iteration 57780 (1.4284 iter/s, 7.00082s/10 iters), loss = 6.72328
I0524 09:52:30.366055 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.72328 (* 1 = 6.72328 loss)
I0524 09:52:30.366247 11654 sgd_solver.cpp:112] Iteration 57780, lr = 0.1
I0524 09:52:39.384052 11654 solver.cpp:239] Iteration 57790 (1.10894 iter/s, 9.01766s/10 iters), loss = 6.96782
I0524 09:52:39.384110 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96782 (* 1 = 6.96782 loss)
I0524 09:52:39.384127 11654 sgd_solver.cpp:112] Iteration 57790, lr = 0.1
I0524 09:52:47.262830 11654 solver.cpp:239] Iteration 57800 (1.2693 iter/s, 7.87835s/10 iters), loss = 6.85315
I0524 09:52:47.263098 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85315 (* 1 = 6.85315 loss)
I0524 09:52:47.314882 11654 sgd_solver.cpp:112] Iteration 57800, lr = 0.1
I0524 09:52:53.605437 11654 solver.cpp:239] Iteration 57810 (1.57676 iter/s, 6.34213s/10 iters), loss = 5.57694
I0524 09:52:53.605489 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.57694 (* 1 = 5.57694 loss)
I0524 09:52:53.605605 11654 sgd_solver.cpp:112] Iteration 57810, lr = 0.1
I0524 09:53:02.818893 11654 solver.cpp:239] Iteration 57820 (1.08542 iter/s, 9.21304s/10 iters), loss = 5.80217
I0524 09:53:02.818965 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.80217 (* 1 = 5.80217 loss)
I0524 09:53:02.818986 11654 sgd_solver.cpp:112] Iteration 57820, lr = 0.1
I0524 09:53:09.639631 11654 solver.cpp:239] Iteration 57830 (1.4662 iter/s, 6.82036s/10 iters), loss = 6.5926
I0524 09:53:09.639703 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5926 (* 1 = 6.5926 loss)
I0524 09:53:09.704912 11654 sgd_solver.cpp:112] Iteration 57830, lr = 0.1
I0524 09:53:19.345439 11654 solver.cpp:239] Iteration 57840 (1.03036 iter/s, 9.70535s/10 iters), loss = 6.51381
I0524 09:53:19.345716 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.51381 (* 1 = 6.51381 loss)
I0524 09:53:20.123268 11654 sgd_solver.cpp:112] Iteration 57840, lr = 0.1
I0524 09:53:29.485553 11654 solver.cpp:239] Iteration 57850 (0.986244 iter/s, 10.1395s/10 iters), loss = 6.00286
I0524 09:53:29.485641 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.00286 (* 1 = 6.00286 loss)
I0524 09:53:29.486135 11654 sgd_solver.cpp:112] Iteration 57850, lr = 0.1
I0524 09:53:35.704047 11654 solver.cpp:239] Iteration 57860 (1.60819 iter/s, 6.21817s/10 iters), loss = 6.0933
I0524 09:53:35.704111 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.0933 (* 1 = 6.0933 loss)
I0524 09:53:36.211341 11654 sgd_solver.cpp:112] Iteration 57860, lr = 0.1
I0524 09:53:42.608134 11654 solver.cpp:239] Iteration 57870 (1.44849 iter/s, 6.90375s/10 iters), loss = 6.16124
I0524 09:53:42.608223 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.16124 (* 1 = 6.16124 loss)
I0524 09:53:42.608337 11654 sgd_solver.cpp:112] Iteration 57870, lr = 0.1
I0524 09:53:49.125830 11654 solver.cpp:239] Iteration 57880 (1.53436 iter/s, 6.51738s/10 iters), loss = 5.454
I0524 09:53:49.125895 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.454 (* 1 = 5.454 loss)
I0524 09:53:49.126036 11654 sgd_solver.cpp:112] Iteration 57880, lr = 0.1
I0524 09:53:56.837291 11654 solver.cpp:239] Iteration 57890 (1.29684 iter/s, 7.71106s/10 iters), loss = 5.41416
I0524 09:53:56.837517 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.41416 (* 1 = 5.41416 loss)
I0524 09:53:56.837572 11654 sgd_solver.cpp:112] Iteration 57890, lr = 0.1
I0524 09:54:04.922133 11654 solver.cpp:239] Iteration 57900 (1.23696 iter/s, 8.0843s/10 iters), loss = 5.82308
I0524 09:54:04.922199 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.82308 (* 1 = 5.82308 loss)
I0524 09:54:04.922583 11654 sgd_solver.cpp:112] Iteration 57900, lr = 0.1
I0524 09:54:12.683396 11654 solver.cpp:239] Iteration 57910 (1.28851 iter/s, 7.76088s/10 iters), loss = 5.64904
I0524 09:54:12.683445 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.64904 (* 1 = 5.64904 loss)
I0524 09:54:12.683463 11654 sgd_solver.cpp:112] Iteration 57910, lr = 0.1
I0524 09:54:21.541249 11654 solver.cpp:239] Iteration 57920 (1.129 iter/s, 8.85741s/10 iters), loss = 6.63808
I0524 09:54:21.541329 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63808 (* 1 = 6.63808 loss)
I0524 09:54:21.896886 11654 sgd_solver.cpp:112] Iteration 57920, lr = 0.1
I0524 09:54:28.634052 11654 solver.cpp:239] Iteration 57930 (1.40996 iter/s, 7.09241s/10 iters), loss = 6.74123
I0524 09:54:28.634315 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74123 (* 1 = 6.74123 loss)
I0524 09:54:28.634587 11654 sgd_solver.cpp:112] Iteration 57930, lr = 0.1
I0524 09:54:37.151933 11654 solver.cpp:239] Iteration 57940 (1.17408 iter/s, 8.51732s/10 iters), loss = 5.98811
I0524 09:54:37.151973 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.98811 (* 1 = 5.98811 loss)
I0524 09:54:37.509697 11654 sgd_solver.cpp:112] Iteration 57940, lr = 0.1
I0524 09:54:43.806481 11654 solver.cpp:239] Iteration 57950 (1.5028 iter/s, 6.65423s/10 iters), loss = 5.97627
I0524 09:54:43.806540 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97627 (* 1 = 5.97627 loss)
I0524 09:54:44.796599 11654 sgd_solver.cpp:112] Iteration 57950, lr = 0.1
I0524 09:54:50.997798 11654 solver.cpp:239] Iteration 57960 (1.39063 iter/s, 7.19098s/10 iters), loss = 5.84326
I0524 09:54:50.997850 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.84326 (* 1 = 5.84326 loss)
I0524 09:54:50.997865 11654 sgd_solver.cpp:112] Iteration 57960, lr = 0.1
I0524 09:54:59.512177 11654 solver.cpp:239] Iteration 57970 (1.17455 iter/s, 8.51391s/10 iters), loss = 6.11626
I0524 09:54:59.512482 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.11626 (* 1 = 6.11626 loss)
I0524 09:54:59.512524 11654 sgd_solver.cpp:112] Iteration 57970, lr = 0.1
I0524 09:55:07.682121 11654 solver.cpp:239] Iteration 57980 (1.22423 iter/s, 8.16839s/10 iters), loss = 6.12791
I0524 09:55:07.682240 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12791 (* 1 = 6.12791 loss)
I0524 09:55:07.682279 11654 sgd_solver.cpp:112] Iteration 57980, lr = 0.1
I0524 09:55:15.128219 11654 solver.cpp:239] Iteration 57990 (1.34305 iter/s, 7.44572s/10 iters), loss = 5.44214
I0524 09:55:15.128260 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.44214 (* 1 = 5.44214 loss)
I0524 09:55:15.397084 11654 sgd_solver.cpp:112] Iteration 57990, lr = 0.1
I0524 09:55:23.147301 11654 solver.cpp:239] Iteration 58000 (1.24708 iter/s, 8.01872s/10 iters), loss = 6.28031
I0524 09:55:23.147374 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.28031 (* 1 = 6.28031 loss)
I0524 09:55:23.147483 11654 sgd_solver.cpp:112] Iteration 58000, lr = 0.1
I0524 09:55:30.338335 11654 solver.cpp:239] Iteration 58010 (1.39069 iter/s, 7.19069s/10 iters), loss = 6.27028
I0524 09:55:30.338649 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.27028 (* 1 = 6.27028 loss)
I0524 09:55:30.338745 11654 sgd_solver.cpp:112] Iteration 58010, lr = 0.1
I0524 09:55:38.158555 11654 solver.cpp:239] Iteration 58020 (1.27884 iter/s, 7.8196s/10 iters), loss = 6.91658
I0524 09:55:38.158602 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.91658 (* 1 = 6.91658 loss)
I0524 09:55:38.158624 11654 sgd_solver.cpp:112] Iteration 58020, lr = 0.1
I0524 09:55:45.126348 11654 solver.cpp:239] Iteration 58030 (1.43526 iter/s, 6.96737s/10 iters), loss = 6.06049
I0524 09:55:45.126431 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06049 (* 1 = 6.06049 loss)
I0524 09:55:45.126538 11654 sgd_solver.cpp:112] Iteration 58030, lr = 0.1
I0524 09:55:52.775991 11654 solver.cpp:239] Iteration 58040 (1.30731 iter/s, 7.64928s/10 iters), loss = 5.97306
I0524 09:55:52.776059 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.97306 (* 1 = 5.97306 loss)
I0524 09:55:52.825451 11654 sgd_solver.cpp:112] Iteration 58040, lr = 0.1
I0524 09:56:00.587348 11654 solver.cpp:239] Iteration 58050 (1.28025 iter/s, 7.81097s/10 iters), loss = 5.87975
I0524 09:56:00.587618 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.87975 (* 1 = 5.87975 loss)
I0524 09:56:00.635011 11654 sgd_solver.cpp:112] Iteration 58050, lr = 0.1
I0524 09:56:08.540613 11654 solver.cpp:239] Iteration 58060 (1.25743 iter/s, 7.95272s/10 iters), loss = 7.62847
I0524 09:56:08.540688 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.62847 (* 1 = 7.62847 loss)
I0524 09:56:08.541290 11654 sgd_solver.cpp:112] Iteration 58060, lr = 0.1
I0524 09:56:16.913575 11654 solver.cpp:239] Iteration 58070 (1.19438 iter/s, 8.37257s/10 iters), loss = 6.50545
I0524 09:56:16.913653 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.50545 (* 1 = 6.50545 loss)
I0524 09:56:17.637246 11654 sgd_solver.cpp:112] Iteration 58070, lr = 0.1
I0524 09:56:25.822221 11654 solver.cpp:239] Iteration 58080 (1.12256 iter/s, 8.90823s/10 iters), loss = 5.68529
I0524 09:56:25.822265 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68529 (* 1 = 5.68529 loss)
I0524 09:56:25.978957 11654 sgd_solver.cpp:112] Iteration 58080, lr = 0.1
I0524 09:56:32.882747 11654 solver.cpp:239] Iteration 58090 (1.41639 iter/s, 7.06018s/10 iters), loss = 5.34548
I0524 09:56:32.883008 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.34548 (* 1 = 5.34548 loss)
I0524 09:56:32.883083 11654 sgd_solver.cpp:112] Iteration 58090, lr = 0.1
I0524 09:56:40.042604 11654 solver.cpp:239] Iteration 58100 (1.39686 iter/s, 7.15891s/10 iters), loss = 6.06686
I0524 09:56:40.042680 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06686 (* 1 = 6.06686 loss)
I0524 09:56:41.062099 11654 sgd_solver.cpp:112] Iteration 58100, lr = 0.1
I0524 09:56:49.900426 11654 solver.cpp:239] Iteration 58110 (1.01447 iter/s, 9.85739s/10 iters), loss = 6.17316
I0524 09:56:49.900516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17316 (* 1 = 6.17316 loss)
I0524 09:56:49.900540 11654 sgd_solver.cpp:112] Iteration 58110, lr = 0.1
I0524 09:56:57.283798 11654 solver.cpp:239] Iteration 58120 (1.35446 iter/s, 7.38302s/10 iters), loss = 6.46273
I0524 09:56:57.283870 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.46273 (* 1 = 6.46273 loss)
I0524 09:56:57.283897 11654 sgd_solver.cpp:112] Iteration 58120, lr = 0.1
I0524 09:57:07.444917 11654 solver.cpp:239] Iteration 58130 (0.984405 iter/s, 10.1584s/10 iters), loss = 6.38307
I0524 09:57:07.445231 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.38307 (* 1 = 6.38307 loss)
I0524 09:57:08.207813 11654 sgd_solver.cpp:112] Iteration 58130, lr = 0.1
I0524 09:57:15.022665 11654 solver.cpp:239] Iteration 58140 (1.31975 iter/s, 7.57719s/10 iters), loss = 6.7703
I0524 09:57:15.022727 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.7703 (* 1 = 6.7703 loss)
I0524 09:57:15.022743 11654 sgd_solver.cpp:112] Iteration 58140, lr = 0.1
I0524 09:57:21.667039 11654 solver.cpp:239] Iteration 58150 (1.50511 iter/s, 6.64403s/10 iters), loss = 6.45923
I0524 09:57:21.667105 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.45923 (* 1 = 6.45923 loss)
I0524 09:57:21.667480 11654 sgd_solver.cpp:112] Iteration 58150, lr = 0.1
I0524 09:57:30.111459 11654 solver.cpp:239] Iteration 58160 (1.18427 iter/s, 8.444s/10 iters), loss = 5.79062
I0524 09:57:30.111527 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.79062 (* 1 = 5.79062 loss)
I0524 09:57:30.112327 11654 sgd_solver.cpp:112] Iteration 58160, lr = 0.1
I0524 09:57:36.872506 11654 solver.cpp:239] Iteration 58170 (1.47913 iter/s, 6.76072s/10 iters), loss = 5.12996
I0524 09:57:36.872548 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.12996 (* 1 = 5.12996 loss)
I0524 09:57:36.872565 11654 sgd_solver.cpp:112] Iteration 58170, lr = 0.1
I0524 09:57:45.794879 11654 solver.cpp:239] Iteration 58180 (1.1211 iter/s, 8.91982s/10 iters), loss = 5.37429
I0524 09:57:45.795114 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.37429 (* 1 = 5.37429 loss)
I0524 09:57:45.795150 11654 sgd_solver.cpp:112] Iteration 58180, lr = 0.1
I0524 09:57:52.666683 11654 solver.cpp:239] Iteration 58190 (1.45576 iter/s, 6.86925s/10 iters), loss = 6.70034
I0524 09:57:52.666766 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.70034 (* 1 = 6.70034 loss)
I0524 09:57:52.666877 11654 sgd_solver.cpp:112] Iteration 58190, lr = 0.1
I0524 09:57:59.697906 11654 solver.cpp:239] Iteration 58200 (1.4223 iter/s, 7.03087s/10 iters), loss = 5.8353
I0524 09:57:59.698005 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8353 (* 1 = 5.8353 loss)
I0524 09:57:59.698256 11654 sgd_solver.cpp:112] Iteration 58200, lr = 0.1
I0524 09:58:10.043552 11654 solver.cpp:239] Iteration 58210 (0.966633 iter/s, 10.3452s/10 iters), loss = 6.046
I0524 09:58:10.043620 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.046 (* 1 = 6.046 loss)
I0524 09:58:10.043651 11654 sgd_solver.cpp:112] Iteration 58210, lr = 0.1
I0524 09:58:16.636934 11654 solver.cpp:239] Iteration 58220 (1.51676 iter/s, 6.59299s/10 iters), loss = 6.74741
I0524 09:58:16.637290 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74741 (* 1 = 6.74741 loss)
I0524 09:58:16.637354 11654 sgd_solver.cpp:112] Iteration 58220, lr = 0.1
I0524 09:58:24.749915 11654 solver.cpp:239] Iteration 58230 (1.233 iter/s, 8.11031s/10 iters), loss = 5.72339
I0524 09:58:24.749969 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72339 (* 1 = 5.72339 loss)
I0524 09:58:24.749984 11654 sgd_solver.cpp:112] Iteration 58230, lr = 0.1
I0524 09:58:33.199810 11654 solver.cpp:239] Iteration 58240 (1.18382 iter/s, 8.44726s/10 iters), loss = 5.92759
I0524 09:58:33.199851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.92759 (* 1 = 5.92759 loss)
I0524 09:58:33.199889 11654 sgd_solver.cpp:112] Iteration 58240, lr = 0.1
I0524 09:58:40.242208 11654 solver.cpp:239] Iteration 58250 (1.42004 iter/s, 7.04205s/10 iters), loss = 6.39521
I0524 09:58:40.242307 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39521 (* 1 = 6.39521 loss)
I0524 09:58:40.242534 11654 sgd_solver.cpp:112] Iteration 58250, lr = 0.1
I0524 09:58:47.341681 11654 solver.cpp:239] Iteration 58260 (1.40863 iter/s, 7.09911s/10 iters), loss = 6.71168
I0524 09:58:47.346807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.71168 (* 1 = 6.71168 loss)
I0524 09:58:47.346851 11654 sgd_solver.cpp:112] Iteration 58260, lr = 0.1
I0524 09:58:55.024605 11654 solver.cpp:239] Iteration 58270 (1.30251 iter/s, 7.67751s/10 iters), loss = 5.81856
I0524 09:58:55.024658 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.81856 (* 1 = 5.81856 loss)
I0524 09:58:55.102651 11654 sgd_solver.cpp:112] Iteration 58270, lr = 0.1
I0524 09:59:02.895118 11654 solver.cpp:239] Iteration 58280 (1.27062 iter/s, 7.87014s/10 iters), loss = 5.70092
I0524 09:59:02.895175 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.70092 (* 1 = 5.70092 loss)
I0524 09:59:02.924616 11654 sgd_solver.cpp:112] Iteration 58280, lr = 0.1
I0524 09:59:10.072058 11654 solver.cpp:239] Iteration 58290 (1.39341 iter/s, 7.17661s/10 iters), loss = 7.02885
I0524 09:59:10.072093 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.02885 (* 1 = 7.02885 loss)
I0524 09:59:10.072108 11654 sgd_solver.cpp:112] Iteration 58290, lr = 0.1
I0524 09:59:21.639645 11654 solver.cpp:239] Iteration 58300 (0.864521 iter/s, 11.5671s/10 iters), loss = 5.45362
I0524 09:59:21.639919 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.45362 (* 1 = 5.45362 loss)
I0524 09:59:22.676554 11654 sgd_solver.cpp:112] Iteration 58300, lr = 0.1
I0524 09:59:29.812785 11654 solver.cpp:239] Iteration 58310 (1.2236 iter/s, 8.17261s/10 iters), loss = 6.62885
I0524 09:59:29.812851 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62885 (* 1 = 6.62885 loss)
I0524 09:59:29.813009 11654 sgd_solver.cpp:112] Iteration 58310, lr = 0.1
I0524 09:59:36.711874 11654 solver.cpp:239] Iteration 58320 (1.44954 iter/s, 6.89873s/10 iters), loss = 5.24845
I0524 09:59:36.711941 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.24845 (* 1 = 5.24845 loss)
I0524 09:59:36.711962 11654 sgd_solver.cpp:112] Iteration 58320, lr = 0.1
I0524 09:59:43.745070 11654 solver.cpp:239] Iteration 58330 (1.4219 iter/s, 7.03283s/10 iters), loss = 6.52696
I0524 09:59:43.745128 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52696 (* 1 = 6.52696 loss)
I0524 09:59:43.751413 11654 sgd_solver.cpp:112] Iteration 58330, lr = 0.1
I0524 09:59:50.025493 11654 solver.cpp:239] Iteration 58340 (1.59233 iter/s, 6.2801s/10 iters), loss = 7.19321
I0524 09:59:50.025593 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.19321 (* 1 = 7.19321 loss)
I0524 09:59:50.200909 11654 sgd_solver.cpp:112] Iteration 58340, lr = 0.1
I0524 09:59:56.672945 11654 solver.cpp:239] Iteration 58350 (1.50441 iter/s, 6.6471s/10 iters), loss = 5.49015
I0524 09:59:56.673213 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49015 (* 1 = 5.49015 loss)
I0524 09:59:56.678339 11654 sgd_solver.cpp:112] Iteration 58350, lr = 0.1
I0524 10:00:06.380726 11654 solver.cpp:239] Iteration 58360 (1.03016 iter/s, 9.70719s/10 iters), loss = 6.49719
I0524 10:00:06.380775 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.49719 (* 1 = 6.49719 loss)
I0524 10:00:06.380980 11654 sgd_solver.cpp:112] Iteration 58360, lr = 0.1
I0524 10:00:13.993561 11654 solver.cpp:239] Iteration 58370 (1.31363 iter/s, 7.61248s/10 iters), loss = 6.96796
I0524 10:00:13.993620 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.96796 (* 1 = 6.96796 loss)
I0524 10:00:13.997972 11654 sgd_solver.cpp:112] Iteration 58370, lr = 0.1
I0524 10:00:23.053894 11654 solver.cpp:239] Iteration 58380 (1.10376 iter/s, 9.05992s/10 iters), loss = 6.41264
I0524 10:00:23.053983 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41264 (* 1 = 6.41264 loss)
I0524 10:00:23.174810 11654 sgd_solver.cpp:112] Iteration 58380, lr = 0.1
I0524 10:00:30.049110 11654 solver.cpp:239] Iteration 58390 (1.42962 iter/s, 6.99489s/10 iters), loss = 5.49943
I0524 10:00:30.049404 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.49943 (* 1 = 5.49943 loss)
I0524 10:00:30.596907 11654 sgd_solver.cpp:112] Iteration 58390, lr = 0.1
I0524 10:00:37.948213 11654 solver.cpp:239] Iteration 58400 (1.26606 iter/s, 7.8985s/10 iters), loss = 4.94798
I0524 10:00:37.948299 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.94798 (* 1 = 4.94798 loss)
I0524 10:00:37.948395 11654 sgd_solver.cpp:112] Iteration 58400, lr = 0.1
I0524 10:00:44.084714 11654 solver.cpp:239] Iteration 58410 (1.62969 iter/s, 6.13613s/10 iters), loss = 5.50874
I0524 10:00:44.084792 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.50874 (* 1 = 5.50874 loss)
I0524 10:00:44.085194 11654 sgd_solver.cpp:112] Iteration 58410, lr = 0.1
I0524 10:00:51.158450 11654 solver.cpp:239] Iteration 58420 (1.41376 iter/s, 7.07332s/10 iters), loss = 5.569
I0524 10:00:51.158550 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.569 (* 1 = 5.569 loss)
I0524 10:00:51.161651 11654 sgd_solver.cpp:112] Iteration 58420, lr = 0.1
I0524 10:00:57.734485 11654 solver.cpp:239] Iteration 58430 (1.52076 iter/s, 6.57567s/10 iters), loss = 6.293
I0524 10:00:57.734525 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.293 (* 1 = 6.293 loss)
I0524 10:00:57.738890 11654 sgd_solver.cpp:112] Iteration 58430, lr = 0.1
I0524 10:01:05.047262 11654 solver.cpp:239] Iteration 58440 (1.36753 iter/s, 7.31243s/10 iters), loss = 6.06216
I0524 10:01:05.047438 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.06216 (* 1 = 6.06216 loss)
I0524 10:01:05.047469 11654 sgd_solver.cpp:112] Iteration 58440, lr = 0.1
I0524 10:01:12.350554 11654 solver.cpp:239] Iteration 58450 (1.36973 iter/s, 7.30073s/10 iters), loss = 5.83297
I0524 10:01:12.350632 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.83297 (* 1 = 5.83297 loss)
I0524 10:01:12.350783 11654 sgd_solver.cpp:112] Iteration 58450, lr = 0.1
I0524 10:01:19.211644 11654 solver.cpp:239] Iteration 58460 (1.45757 iter/s, 6.86075s/10 iters), loss = 5.85949
I0524 10:01:19.211704 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.85949 (* 1 = 5.85949 loss)
I0524 10:01:19.211779 11654 sgd_solver.cpp:112] Iteration 58460, lr = 0.1
I0524 10:01:26.127353 11654 solver.cpp:239] Iteration 58470 (1.44605 iter/s, 6.91539s/10 iters), loss = 6.10306
I0524 10:01:26.127415 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.10306 (* 1 = 6.10306 loss)
I0524 10:01:26.142376 11654 sgd_solver.cpp:112] Iteration 58470, lr = 0.1
I0524 10:01:32.661487 11654 solver.cpp:239] Iteration 58480 (1.5305 iter/s, 6.5338s/10 iters), loss = 5.6891
I0524 10:01:32.661537 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.6891 (* 1 = 5.6891 loss)
I0524 10:01:32.661677 11654 sgd_solver.cpp:112] Iteration 58480, lr = 0.1
I0524 10:01:39.798032 11654 solver.cpp:239] Iteration 58490 (1.40131 iter/s, 7.1362s/10 iters), loss = 5.2283
I0524 10:01:39.798310 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.2283 (* 1 = 5.2283 loss)
I0524 10:01:39.798357 11654 sgd_solver.cpp:112] Iteration 58490, lr = 0.1
I0524 10:01:46.199069 11654 solver.cpp:239] Iteration 58500 (1.56244 iter/s, 6.40023s/10 iters), loss = 5.86825
I0524 10:01:46.199141 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.86825 (* 1 = 5.86825 loss)
I0524 10:01:46.823643 11654 sgd_solver.cpp:112] Iteration 58500, lr = 0.1
I0524 10:01:57.699795 11654 solver.cpp:239] Iteration 58510 (0.86955 iter/s, 11.5002s/10 iters), loss = 5.41659
I0524 10:01:57.699836 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.41659 (* 1 = 5.41659 loss)
I0524 10:01:57.699851 11654 sgd_solver.cpp:112] Iteration 58510, lr = 0.1
I0524 10:02:04.717866 11654 solver.cpp:239] Iteration 58520 (1.42497 iter/s, 7.01769s/10 iters), loss = 5.62318
I0524 10:02:04.717936 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.62318 (* 1 = 5.62318 loss)
I0524 10:02:04.717957 11654 sgd_solver.cpp:112] Iteration 58520, lr = 0.1
I0524 10:02:11.620919 11654 solver.cpp:239] Iteration 58530 (1.44916 iter/s, 6.90054s/10 iters), loss = 5.78355
I0524 10:02:11.621217 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.78355 (* 1 = 5.78355 loss)
I0524 10:02:11.621266 11654 sgd_solver.cpp:112] Iteration 58530, lr = 0.1
I0524 10:02:19.064177 11654 solver.cpp:239] Iteration 58540 (1.34361 iter/s, 7.44265s/10 iters), loss = 6.21744
I0524 10:02:19.064249 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.21744 (* 1 = 6.21744 loss)
I0524 10:02:19.064358 11654 sgd_solver.cpp:112] Iteration 58540, lr = 0.1
I0524 10:02:25.983932 11654 solver.cpp:239] Iteration 58550 (1.44521 iter/s, 6.91942s/10 iters), loss = 5.74649
I0524 10:02:25.983991 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74649 (* 1 = 5.74649 loss)
I0524 10:02:25.984030 11654 sgd_solver.cpp:112] Iteration 58550, lr = 0.1
I0524 10:02:32.895929 11654 solver.cpp:239] Iteration 58560 (1.44684 iter/s, 6.9116s/10 iters), loss = 5.30858
I0524 10:02:32.895990 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30858 (* 1 = 5.30858 loss)
I0524 10:02:33.138897 11654 sgd_solver.cpp:112] Iteration 58560, lr = 0.1
I0524 10:02:44.127916 11654 solver.cpp:239] Iteration 58570 (0.890354 iter/s, 11.2315s/10 iters), loss = 7.22745
I0524 10:02:44.128185 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.22745 (* 1 = 7.22745 loss)
I0524 10:02:44.128231 11654 sgd_solver.cpp:112] Iteration 58570, lr = 0.1
I0524 10:02:51.421042 11654 solver.cpp:239] Iteration 58580 (1.37125 iter/s, 7.2926s/10 iters), loss = 6.44348
I0524 10:02:51.421103 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44348 (* 1 = 6.44348 loss)
I0524 10:02:51.678164 11654 sgd_solver.cpp:112] Iteration 58580, lr = 0.1
I0524 10:02:59.764195 11654 solver.cpp:239] Iteration 58590 (1.19864 iter/s, 8.34276s/10 iters), loss = 6.25812
I0524 10:02:59.764245 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25812 (* 1 = 6.25812 loss)
I0524 10:02:59.773193 11654 sgd_solver.cpp:112] Iteration 58590, lr = 0.1
I0524 10:03:08.356622 11654 solver.cpp:239] Iteration 58600 (1.16387 iter/s, 8.59204s/10 iters), loss = 5.95443
I0524 10:03:08.356678 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.95443 (* 1 = 5.95443 loss)
I0524 10:03:08.816905 11654 sgd_solver.cpp:112] Iteration 58600, lr = 0.1
I0524 10:03:16.467667 11654 solver.cpp:239] Iteration 58610 (1.23294 iter/s, 8.11068s/10 iters), loss = 6.15447
I0524 10:03:16.467909 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.15447 (* 1 = 6.15447 loss)
I0524 10:03:17.109180 11654 sgd_solver.cpp:112] Iteration 58610, lr = 0.1
I0524 10:03:24.389222 11654 solver.cpp:239] Iteration 58620 (1.26246 iter/s, 7.92105s/10 iters), loss = 6.02025
I0524 10:03:24.389279 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.02025 (* 1 = 6.02025 loss)
I0524 10:03:24.389297 11654 sgd_solver.cpp:112] Iteration 58620, lr = 0.1
I0524 10:03:31.876514 11654 solver.cpp:239] Iteration 58630 (1.33567 iter/s, 7.48688s/10 iters), loss = 6.13516
I0524 10:03:31.876583 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.13516 (* 1 = 6.13516 loss)
I0524 10:03:31.876674 11654 sgd_solver.cpp:112] Iteration 58630, lr = 0.1
I0524 10:03:41.541213 11654 solver.cpp:239] Iteration 58640 (1.03474 iter/s, 9.66425s/10 iters), loss = 7.25683
I0524 10:03:41.541303 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.25683 (* 1 = 7.25683 loss)
I0524 10:03:41.541491 11654 sgd_solver.cpp:112] Iteration 58640, lr = 0.1
I0524 10:03:48.423169 11654 solver.cpp:239] Iteration 58650 (1.45315 iter/s, 6.88162s/10 iters), loss = 7.30946
I0524 10:03:48.423475 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.30946 (* 1 = 7.30946 loss)
I0524 10:03:48.423523 11654 sgd_solver.cpp:112] Iteration 58650, lr = 0.1
I0524 10:03:55.565296 11654 solver.cpp:239] Iteration 58660 (1.40026 iter/s, 7.14152s/10 iters), loss = 7.60434
I0524 10:03:55.565394 11654 solver.cpp:258]     Train net output #0: softmax_loss = 7.60434 (* 1 = 7.60434 loss)
I0524 10:03:55.565446 11654 sgd_solver.cpp:112] Iteration 58660, lr = 0.1
I0524 10:04:03.611683 11654 solver.cpp:239] Iteration 58670 (1.24286 iter/s, 8.04597s/10 iters), loss = 6.64616
I0524 10:04:03.611747 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.64616 (* 1 = 6.64616 loss)
I0524 10:04:03.644497 11654 sgd_solver.cpp:112] Iteration 58670, lr = 0.1
I0524 10:04:12.086547 11654 solver.cpp:239] Iteration 58680 (1.18001 iter/s, 8.47449s/10 iters), loss = 6.85004
I0524 10:04:12.086596 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.85004 (* 1 = 6.85004 loss)
I0524 10:04:12.087026 11654 sgd_solver.cpp:112] Iteration 58680, lr = 0.1
I0524 10:04:19.077006 11654 solver.cpp:239] Iteration 58690 (1.43059 iter/s, 6.99012s/10 iters), loss = 5.96169
I0524 10:04:19.077230 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96169 (* 1 = 5.96169 loss)
I0524 10:04:19.077288 11654 sgd_solver.cpp:112] Iteration 58690, lr = 0.1
I0524 10:04:27.994459 11654 solver.cpp:239] Iteration 58700 (1.12149 iter/s, 8.91669s/10 iters), loss = 6.74495
I0524 10:04:27.994513 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.74495 (* 1 = 6.74495 loss)
I0524 10:04:28.122342 11654 sgd_solver.cpp:112] Iteration 58700, lr = 0.1
I0524 10:04:35.980777 11654 solver.cpp:239] Iteration 58710 (1.2522 iter/s, 7.98596s/10 iters), loss = 6.99032
I0524 10:04:35.980829 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.99032 (* 1 = 6.99032 loss)
I0524 10:04:35.980844 11654 sgd_solver.cpp:112] Iteration 58710, lr = 0.1
I0524 10:04:43.295780 11654 solver.cpp:239] Iteration 58720 (1.36713 iter/s, 7.31458s/10 iters), loss = 6.4673
I0524 10:04:43.295866 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4673 (* 1 = 6.4673 loss)
I0524 10:04:43.394582 11654 sgd_solver.cpp:112] Iteration 58720, lr = 0.1
I0524 10:04:50.668788 11654 solver.cpp:239] Iteration 58730 (1.35636 iter/s, 7.37266s/10 iters), loss = 5.88361
I0524 10:04:50.669023 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.88361 (* 1 = 5.88361 loss)
I0524 10:04:50.669081 11654 sgd_solver.cpp:112] Iteration 58730, lr = 0.1
I0524 10:05:01.186308 11654 solver.cpp:239] Iteration 58740 (0.950892 iter/s, 10.5164s/10 iters), loss = 6.41864
I0524 10:05:01.186367 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.41864 (* 1 = 6.41864 loss)
I0524 10:05:01.186388 11654 sgd_solver.cpp:112] Iteration 58740, lr = 0.1
I0524 10:05:08.627921 11654 solver.cpp:239] Iteration 58750 (1.34416 iter/s, 7.43956s/10 iters), loss = 5.47268
I0524 10:05:08.627995 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.47268 (* 1 = 5.47268 loss)
I0524 10:05:08.628047 11654 sgd_solver.cpp:112] Iteration 58750, lr = 0.1
I0524 10:05:15.534407 11654 solver.cpp:239] Iteration 58760 (1.44799 iter/s, 6.90611s/10 iters), loss = 6.63311
I0524 10:05:15.534494 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.63311 (* 1 = 6.63311 loss)
I0524 10:05:16.407867 11654 sgd_solver.cpp:112] Iteration 58760, lr = 0.1
I0524 10:05:26.072600 11654 solver.cpp:239] Iteration 58770 (0.948973 iter/s, 10.5377s/10 iters), loss = 6.81192
I0524 10:05:26.073068 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.81192 (* 1 = 6.81192 loss)
I0524 10:05:26.073096 11654 sgd_solver.cpp:112] Iteration 58770, lr = 0.1
I0524 10:05:32.984935 11654 solver.cpp:239] Iteration 58780 (1.44687 iter/s, 6.91147s/10 iters), loss = 6.77316
I0524 10:05:32.985113 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.77316 (* 1 = 6.77316 loss)
I0524 10:05:32.985157 11654 sgd_solver.cpp:112] Iteration 58780, lr = 0.1
I0524 10:05:42.517238 11654 solver.cpp:239] Iteration 58790 (1.04919 iter/s, 9.53119s/10 iters), loss = 5.28572
I0524 10:05:42.517316 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.28572 (* 1 = 5.28572 loss)
I0524 10:05:42.517343 11654 sgd_solver.cpp:112] Iteration 58790, lr = 0.1
I0524 10:05:48.857928 11654 solver.cpp:239] Iteration 58800 (1.5772 iter/s, 6.34034s/10 iters), loss = 4.9457
I0524 10:05:48.857997 11654 solver.cpp:258]     Train net output #0: softmax_loss = 4.9457 (* 1 = 4.9457 loss)
I0524 10:05:49.252413 11654 sgd_solver.cpp:112] Iteration 58800, lr = 0.1
I0524 10:05:58.132674 11654 solver.cpp:239] Iteration 58810 (1.07825 iter/s, 9.27432s/10 iters), loss = 6.53205
I0524 10:05:58.132966 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.53205 (* 1 = 6.53205 loss)
I0524 10:05:58.133005 11654 sgd_solver.cpp:112] Iteration 58810, lr = 0.1
I0524 10:06:04.752316 11654 solver.cpp:239] Iteration 58820 (1.51081 iter/s, 6.61895s/10 iters), loss = 6.25786
I0524 10:06:04.752399 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.25786 (* 1 = 6.25786 loss)
I0524 10:06:04.956660 11654 sgd_solver.cpp:112] Iteration 58820, lr = 0.1
I0524 10:06:12.807106 11654 solver.cpp:239] Iteration 58830 (1.24156 iter/s, 8.05437s/10 iters), loss = 6.65075
I0524 10:06:12.807222 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.65075 (* 1 = 6.65075 loss)
I0524 10:06:12.807258 11654 sgd_solver.cpp:112] Iteration 58830, lr = 0.1
I0524 10:06:19.563765 11654 solver.cpp:239] Iteration 58840 (1.4801 iter/s, 6.7563s/10 iters), loss = 6.66002
I0524 10:06:19.563828 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.66002 (* 1 = 6.66002 loss)
I0524 10:06:19.563881 11654 sgd_solver.cpp:112] Iteration 58840, lr = 0.1
I0524 10:06:27.468089 11654 solver.cpp:239] Iteration 58850 (1.26519 iter/s, 7.90396s/10 iters), loss = 6.30156
I0524 10:06:27.468145 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.30156 (* 1 = 6.30156 loss)
I0524 10:06:27.468161 11654 sgd_solver.cpp:112] Iteration 58850, lr = 0.1
I0524 10:06:34.211541 11654 solver.cpp:239] Iteration 58860 (1.483 iter/s, 6.74307s/10 iters), loss = 6.04603
I0524 10:06:34.211799 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.04603 (* 1 = 6.04603 loss)
I0524 10:06:34.211870 11654 sgd_solver.cpp:112] Iteration 58860, lr = 0.1
I0524 10:06:41.542538 11654 solver.cpp:239] Iteration 58870 (1.36417 iter/s, 7.33046s/10 iters), loss = 5.7172
I0524 10:06:41.542594 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.7172 (* 1 = 5.7172 loss)
I0524 10:06:42.290530 11654 sgd_solver.cpp:112] Iteration 58870, lr = 0.1
I0524 10:06:50.360303 11654 solver.cpp:239] Iteration 58880 (1.13413 iter/s, 8.81737s/10 iters), loss = 5.8628
I0524 10:06:50.360373 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.8628 (* 1 = 5.8628 loss)
I0524 10:06:51.179913 11654 sgd_solver.cpp:112] Iteration 58880, lr = 0.1
I0524 10:06:59.323631 11654 solver.cpp:239] Iteration 58890 (1.11571 iter/s, 8.96292s/10 iters), loss = 6.69833
I0524 10:06:59.323701 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.69833 (* 1 = 6.69833 loss)
I0524 10:06:59.323741 11654 sgd_solver.cpp:112] Iteration 58890, lr = 0.1
I0524 10:07:06.355928 11654 solver.cpp:239] Iteration 58900 (1.4222 iter/s, 7.03135s/10 iters), loss = 6.08653
I0524 10:07:06.356046 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.08653 (* 1 = 6.08653 loss)
I0524 10:07:06.356202 11654 sgd_solver.cpp:112] Iteration 58900, lr = 0.1
I0524 10:07:16.164795 11654 solver.cpp:239] Iteration 58910 (1.01954 iter/s, 9.80837s/10 iters), loss = 5.68106
I0524 10:07:16.164865 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.68106 (* 1 = 5.68106 loss)
I0524 10:07:16.766865 11654 sgd_solver.cpp:112] Iteration 58910, lr = 0.1
I0524 10:07:23.773931 11654 solver.cpp:239] Iteration 58920 (1.31427 iter/s, 7.60876s/10 iters), loss = 6.52326
I0524 10:07:23.773998 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.52326 (* 1 = 6.52326 loss)
I0524 10:07:23.774098 11654 sgd_solver.cpp:112] Iteration 58920, lr = 0.1
I0524 10:07:31.897074 11654 solver.cpp:239] Iteration 58930 (1.23111 iter/s, 8.12274s/10 iters), loss = 6.5888
I0524 10:07:31.897140 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.5888 (* 1 = 6.5888 loss)
I0524 10:07:31.897157 11654 sgd_solver.cpp:112] Iteration 58930, lr = 0.1
I0524 10:07:38.433171 11654 solver.cpp:239] Iteration 58940 (1.53006 iter/s, 6.53569s/10 iters), loss = 5.05029
I0524 10:07:38.433428 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.05029 (* 1 = 5.05029 loss)
I0524 10:07:38.929304 11654 sgd_solver.cpp:112] Iteration 58940, lr = 0.1
I0524 10:07:46.418479 11654 solver.cpp:239] Iteration 58950 (1.25239 iter/s, 7.98471s/10 iters), loss = 5.22764
I0524 10:07:46.418629 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.22764 (* 1 = 5.22764 loss)
I0524 10:07:46.418747 11654 sgd_solver.cpp:112] Iteration 58950, lr = 0.1
I0524 10:07:56.165352 11654 solver.cpp:239] Iteration 58960 (1.02602 iter/s, 9.74642s/10 iters), loss = 5.72255
I0524 10:07:56.165410 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.72255 (* 1 = 5.72255 loss)
I0524 10:07:56.389709 11654 sgd_solver.cpp:112] Iteration 58960, lr = 0.1
I0524 10:08:03.330713 11654 solver.cpp:239] Iteration 58970 (1.39568 iter/s, 7.16498s/10 iters), loss = 5.74508
I0524 10:08:03.330817 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74508 (* 1 = 5.74508 loss)
I0524 10:08:03.330848 11654 sgd_solver.cpp:112] Iteration 58970, lr = 0.1
I0524 10:08:11.601229 11654 solver.cpp:239] Iteration 58980 (1.20918 iter/s, 8.2701s/10 iters), loss = 5.4076
I0524 10:08:11.601516 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.4076 (* 1 = 5.4076 loss)
I0524 10:08:11.601857 11654 sgd_solver.cpp:112] Iteration 58980, lr = 0.1
I0524 10:08:20.708662 11654 solver.cpp:239] Iteration 58990 (1.09808 iter/s, 9.10683s/10 iters), loss = 5.74451
I0524 10:08:20.708744 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74451 (* 1 = 5.74451 loss)
I0524 10:08:20.708778 11654 sgd_solver.cpp:112] Iteration 58990, lr = 0.1
I0524 10:08:28.848067 11654 solver.cpp:239] Iteration 59000 (1.22865 iter/s, 8.13903s/10 iters), loss = 6.4084
I0524 10:08:28.848126 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.4084 (* 1 = 6.4084 loss)
I0524 10:08:28.848145 11654 sgd_solver.cpp:112] Iteration 59000, lr = 0.1
I0524 10:08:37.216925 11654 solver.cpp:239] Iteration 59010 (1.19497 iter/s, 8.36841s/10 iters), loss = 6.40714
I0524 10:08:37.216979 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.40714 (* 1 = 6.40714 loss)
I0524 10:08:37.252862 11654 sgd_solver.cpp:112] Iteration 59010, lr = 0.1
I0524 10:08:46.064980 11654 solver.cpp:239] Iteration 59020 (1.13024 iter/s, 8.84766s/10 iters), loss = 6.62682
I0524 10:08:46.065268 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.62682 (* 1 = 6.62682 loss)
I0524 10:08:46.065335 11654 sgd_solver.cpp:112] Iteration 59020, lr = 0.1
I0524 10:08:53.000185 11654 solver.cpp:239] Iteration 59030 (1.44243 iter/s, 6.93272s/10 iters), loss = 6.43636
I0524 10:08:53.000260 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.43636 (* 1 = 6.43636 loss)
I0524 10:08:53.000479 11654 sgd_solver.cpp:112] Iteration 59030, lr = 0.1
I0524 10:09:00.467372 11654 solver.cpp:239] Iteration 59040 (1.33925 iter/s, 7.46684s/10 iters), loss = 6.82568
I0524 10:09:00.467429 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.82568 (* 1 = 6.82568 loss)
I0524 10:09:00.483911 11654 sgd_solver.cpp:112] Iteration 59040, lr = 0.1
I0524 10:09:09.265959 11654 solver.cpp:239] Iteration 59050 (1.1366 iter/s, 8.79819s/10 iters), loss = 6.17315
I0524 10:09:09.266000 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.17315 (* 1 = 6.17315 loss)
I0524 10:09:09.774477 11654 sgd_solver.cpp:112] Iteration 59050, lr = 0.1
I0524 10:09:17.256650 11654 solver.cpp:239] Iteration 59060 (1.25151 iter/s, 7.99033s/10 iters), loss = 6.1482
I0524 10:09:17.256882 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.1482 (* 1 = 6.1482 loss)
I0524 10:09:17.460409 11654 sgd_solver.cpp:112] Iteration 59060, lr = 0.1
I0524 10:09:24.558738 11654 solver.cpp:239] Iteration 59070 (1.36957 iter/s, 7.30158s/10 iters), loss = 5.96805
I0524 10:09:24.558807 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96805 (* 1 = 5.96805 loss)
I0524 10:09:24.559303 11654 sgd_solver.cpp:112] Iteration 59070, lr = 0.1
I0524 10:09:32.147523 11654 solver.cpp:239] Iteration 59080 (1.3178 iter/s, 7.58843s/10 iters), loss = 5.3896
I0524 10:09:32.147580 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.3896 (* 1 = 5.3896 loss)
I0524 10:09:32.147678 11654 sgd_solver.cpp:112] Iteration 59080, lr = 0.1
I0524 10:09:38.711001 11654 solver.cpp:239] Iteration 59090 (1.52365 iter/s, 6.56318s/10 iters), loss = 5.46836
I0524 10:09:38.711045 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.46836 (* 1 = 5.46836 loss)
I0524 10:09:39.028686 11654 sgd_solver.cpp:112] Iteration 59090, lr = 0.1
I0524 10:09:46.615118 11654 solver.cpp:239] Iteration 59100 (1.26522 iter/s, 7.90376s/10 iters), loss = 6.12083
I0524 10:09:46.615195 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.12083 (* 1 = 6.12083 loss)
I0524 10:09:46.615212 11654 sgd_solver.cpp:112] Iteration 59100, lr = 0.1
I0524 10:09:54.898216 11654 solver.cpp:239] Iteration 59110 (1.20735 iter/s, 8.28263s/10 iters), loss = 5.66687
I0524 10:09:54.898521 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.66687 (* 1 = 5.66687 loss)
I0524 10:09:54.898730 11654 sgd_solver.cpp:112] Iteration 59110, lr = 0.1
I0524 10:10:02.431151 11654 solver.cpp:239] Iteration 59120 (1.32759 iter/s, 7.53243s/10 iters), loss = 6.44626
I0524 10:10:02.431210 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.44626 (* 1 = 6.44626 loss)
I0524 10:10:03.290042 11654 sgd_solver.cpp:112] Iteration 59120, lr = 0.1
I0524 10:10:10.016139 11654 solver.cpp:239] Iteration 59130 (1.31846 iter/s, 7.58463s/10 iters), loss = 6.68851
I0524 10:10:10.016206 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.68851 (* 1 = 6.68851 loss)
I0524 10:10:11.087635 11654 sgd_solver.cpp:112] Iteration 59130, lr = 0.1
I0524 10:10:18.732044 11654 solver.cpp:239] Iteration 59140 (1.14738 iter/s, 8.71549s/10 iters), loss = 5.74108
I0524 10:10:18.732122 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.74108 (* 1 = 5.74108 loss)
I0524 10:10:18.732143 11654 sgd_solver.cpp:112] Iteration 59140, lr = 0.1
I0524 10:10:26.958370 11654 solver.cpp:239] Iteration 59150 (1.21582 iter/s, 8.22488s/10 iters), loss = 5.30225
I0524 10:10:26.958602 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.30225 (* 1 = 5.30225 loss)
I0524 10:10:26.958642 11654 sgd_solver.cpp:112] Iteration 59150, lr = 0.1
I0524 10:10:34.630367 11654 solver.cpp:239] Iteration 59160 (1.30353 iter/s, 7.67148s/10 iters), loss = 6.39584
I0524 10:10:34.630434 11654 solver.cpp:258]     Train net output #0: softmax_loss = 6.39584 (* 1 = 6.39584 loss)
I0524 10:10:34.935745 11654 sgd_solver.cpp:112] Iteration 59160, lr = 0.1
I0524 10:10:43.389955 11654 solver.cpp:239] Iteration 59170 (1.14166 iter/s, 8.75917s/10 iters), loss = 5.96951
I0524 10:10:43.390030 11654 solver.cpp:258]     Train net output #0: softmax_loss = 5.96951 (* 1 = 5.96951 loss)
I0524 10:10:43.390210 11654 sgd_solver.cpp:112] Iteration 59170, lr = 0.1
