./build/tools/caffe: /home/zkx/anaconda2/lib/libtiff.so.5: no version information available (required by /home/zkx/env/opencv/lib/libopencv_highgui.so.2.4)
I0522 21:55:23.050196 34819 upgrade_proto.cpp:1084] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': models/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/solver.prototxt
I0522 21:55:23.050509 34819 upgrade_proto.cpp:1091] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0522 21:55:23.050521 34819 upgrade_proto.cpp:1093] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0522 21:55:23.050686 34819 caffe.cpp:204] Using GPUs 0, 1, 2, 3
I0522 21:55:23.075093 34819 caffe.cpp:209] GPU 0: TITAN Xp
I0522 21:55:23.075773 34819 caffe.cpp:209] GPU 1: TITAN Xp
I0522 21:55:23.076452 34819 caffe.cpp:209] GPU 2: TITAN Xp
I0522 21:55:23.077126 34819 caffe.cpp:209] GPU 3: TITAN Xp
I0522 21:55:25.150806 34819 solver.cpp:45] Initializing solver from parameters: 
base_lr: 0.01
display: 10
max_iter: 500000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx"
solver_mode: GPU
device_id: 0
net: "models/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/train.prototxt"
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
stepvalue: 150000
stepvalue: 300000
iter_size: 1
type: "SGD"
I0522 21:55:25.150984 34819 solver.cpp:102] Creating training net from net file: models/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/train.prototxt
I0522 21:55:25.152549 34819 net.cpp:51] Initializing net from parameters: 
name: "2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  data_param {
    source: "/home/zkx/Data_sdb/TrainData/Data_sdc/Patches/lmdb/fc_0.35_112x96_base_ZheD_Cmul-beid_cap10_Asia-train-encode-shufflelmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "PReLU"
  bottom: "conv1_1"
  top: "conv1_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "conv1_3"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_3"
  type: "PReLU"
  bottom: "conv1_3"
  top: "conv1_3"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res1_3"
  type: "Eltwise"
  bottom: "conv1_1"
  bottom: "conv1_3"
  top: "res1_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res1_3_reduce"
  type: "Convolution"
  bottom: "res1_3"
  top: "res1_3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "res1_3_reduce"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "res1_3"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res1_3_p"
  type: "Eltwise"
  bottom: "pool1"
  bottom: "conv2_1"
  top: "res1_3_p"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3"
  type: "Convolution"
  bottom: "res1_3_p"
  top: "conv2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_3"
  type: "PReLU"
  bottom: "conv2_3"
  top: "conv2_3"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res2_3"
  type: "Eltwise"
  bottom: "res1_3_p"
  bottom: "conv2_3"
  top: "res2_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_5"
  type: "Convolution"
  bottom: "res2_3"
  top: "conv2_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_5"
  type: "PReLU"
  bottom: "conv2_5"
  top: "conv2_5"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res2_5"
  type: "Eltwise"
  bottom: "res2_3"
  bottom: "conv2_5"
  top: "res2_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2_5_reduce"
  type: "Convolution"
  bottom: "res2_5"
  top: "res2_5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 72
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2_5_reduce"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "res2_5"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 72
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res2_5_p"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "conv3_1"
  top: "res2_5_p"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "res2_5_p"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 72
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res3_3"
  type: "Eltwise"
  bottom: "res2_5_p"
  bottom: "conv3_3"
  top: "res3_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "res3_3"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 72
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "PReLU"
  bottom: "conv3_5"
  top: "conv3_5"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res3_5"
  type: "Eltwise"
  bottom: "res3_3"
  bottom: "conv3_5"
  top: "res3_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3_5_reduce"
  type: "Convolution"
  bottom: "res3_5"
  top: "res3_5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3_5_reduce"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "res3_5"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res3_5_p"
  type: "Eltwise"
  bottom: "pool3"
  bottom: "conv4_1"
  top: "res3_5_p"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "res3_5_p"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
  prelu_param {
    filler {
      type: "gaussian"
      std: 0.03
    }
  }
}
layer {
  name: "res4_3"
  type: "Eltwise"
  bottom: "res3_5_p"
  bottom: "conv4_3"
  top: "res4_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res4_3"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc5_bn"
  type: "BatchNorm"
  bottom: "fc5"
  top: "fc5"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "norm1"
  type: "Normalize"
  bottom: "fc5"
  top: "norm1"
}
layer {
  name: "fc-6_l2"
  type: "InnerProduct"
  bottom: "norm1"
  top: "fc-6_l2"
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 54547
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    normalize: true
  }
}
layer {
  name: "fc-6_margin"
  type: "LabelSpecificAdd"
  bottom: "fc-6_l2"
  bottom: "label"
  top: "fc-6_margin"
  label_specific_add_param {
    bias: -0.35
  }
}
layer {
  name: "fc-6_margin_scale"
  type: "Scale"
  bottom: "fc-6_margin"
  top: "fc-6_margin_scale"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      type: "constant"
      value: 30
    }
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc-6_margin_scale"
  bottom: "label"
  top: "softmax_loss"
}
I0522 21:55:25.152890 34819 layer_factory.hpp:77] Creating layer data
I0522 21:55:25.153050 34819 db_lmdb.cpp:35] Opened lmdb /home/zkx/Data_sdb/TrainData/Data_sdc/Patches/lmdb/fc_0.35_112x96_base_ZheD_Cmul-beid_cap10_Asia-train-encode-shufflelmdb
I0522 21:55:25.153092 34819 net.cpp:84] Creating Layer data
I0522 21:55:25.153100 34819 net.cpp:380] data -> data
I0522 21:55:25.153120 34819 net.cpp:380] data -> label
I0522 21:55:25.155023 34819 data_layer.cpp:45] output data size: 64,3,112,96
I0522 21:55:25.184463 34819 net.cpp:122] Setting up data
I0522 21:55:25.184517 34819 net.cpp:129] Top shape: 64 3 112 96 (2064384)
I0522 21:55:25.184563 34819 net.cpp:129] Top shape: 64 (64)
I0522 21:55:25.184567 34819 net.cpp:137] Memory required for data: 8257792
I0522 21:55:25.184583 34819 layer_factory.hpp:77] Creating layer label_data_1_split
I0522 21:55:25.184608 34819 net.cpp:84] Creating Layer label_data_1_split
I0522 21:55:25.184617 34819 net.cpp:406] label_data_1_split <- label
I0522 21:55:25.184628 34819 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0522 21:55:25.184641 34819 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0522 21:55:25.184904 34819 net.cpp:122] Setting up label_data_1_split
I0522 21:55:25.185006 34819 net.cpp:129] Top shape: 64 (64)
I0522 21:55:25.185019 34819 net.cpp:129] Top shape: 64 (64)
I0522 21:55:25.185037 34819 net.cpp:137] Memory required for data: 8258304
I0522 21:55:25.185046 34819 layer_factory.hpp:77] Creating layer conv1_1
I0522 21:55:25.185101 34819 net.cpp:84] Creating Layer conv1_1
I0522 21:55:25.185117 34819 net.cpp:406] conv1_1 <- data
I0522 21:55:25.185139 34819 net.cpp:380] conv1_1 -> conv1_1
I0522 21:55:25.821107 34819 net.cpp:122] Setting up conv1_1
I0522 21:55:25.821158 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.821164 34819 net.cpp:137] Memory required for data: 24773376
I0522 21:55:25.821192 34819 layer_factory.hpp:77] Creating layer relu1_1
I0522 21:55:25.821223 34819 net.cpp:84] Creating Layer relu1_1
I0522 21:55:25.821228 34819 net.cpp:406] relu1_1 <- conv1_1
I0522 21:55:25.821236 34819 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0522 21:55:25.822865 34819 net.cpp:122] Setting up relu1_1
I0522 21:55:25.822885 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.822899 34819 net.cpp:137] Memory required for data: 41288448
I0522 21:55:25.822909 34819 layer_factory.hpp:77] Creating layer conv1_1_relu1_1_0_split
I0522 21:55:25.822921 34819 net.cpp:84] Creating Layer conv1_1_relu1_1_0_split
I0522 21:55:25.822932 34819 net.cpp:406] conv1_1_relu1_1_0_split <- conv1_1
I0522 21:55:25.822939 34819 net.cpp:380] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_0
I0522 21:55:25.822948 34819 net.cpp:380] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_1
I0522 21:55:25.823006 34819 net.cpp:122] Setting up conv1_1_relu1_1_0_split
I0522 21:55:25.823015 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.823021 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.823024 34819 net.cpp:137] Memory required for data: 74318592
I0522 21:55:25.823029 34819 layer_factory.hpp:77] Creating layer conv1_3
I0522 21:55:25.823043 34819 net.cpp:84] Creating Layer conv1_3
I0522 21:55:25.823050 34819 net.cpp:406] conv1_3 <- conv1_1_relu1_1_0_split_0
I0522 21:55:25.823056 34819 net.cpp:380] conv1_3 -> conv1_3
I0522 21:55:25.826083 34819 net.cpp:122] Setting up conv1_3
I0522 21:55:25.826103 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.826118 34819 net.cpp:137] Memory required for data: 90833664
I0522 21:55:25.826129 34819 layer_factory.hpp:77] Creating layer relu1_3
I0522 21:55:25.826140 34819 net.cpp:84] Creating Layer relu1_3
I0522 21:55:25.826144 34819 net.cpp:406] relu1_3 <- conv1_3
I0522 21:55:25.826151 34819 net.cpp:367] relu1_3 -> conv1_3 (in-place)
I0522 21:55:25.826310 34819 net.cpp:122] Setting up relu1_3
I0522 21:55:25.826321 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.826325 34819 net.cpp:137] Memory required for data: 107348736
I0522 21:55:25.826333 34819 layer_factory.hpp:77] Creating layer res1_3
I0522 21:55:25.826341 34819 net.cpp:84] Creating Layer res1_3
I0522 21:55:25.826346 34819 net.cpp:406] res1_3 <- conv1_1_relu1_1_0_split_1
I0522 21:55:25.826351 34819 net.cpp:406] res1_3 <- conv1_3
I0522 21:55:25.826357 34819 net.cpp:380] res1_3 -> res1_3
I0522 21:55:25.826390 34819 net.cpp:122] Setting up res1_3
I0522 21:55:25.826397 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.826401 34819 net.cpp:137] Memory required for data: 123863808
I0522 21:55:25.826406 34819 layer_factory.hpp:77] Creating layer res1_3_res1_3_0_split
I0522 21:55:25.826437 34819 net.cpp:84] Creating Layer res1_3_res1_3_0_split
I0522 21:55:25.826445 34819 net.cpp:406] res1_3_res1_3_0_split <- res1_3
I0522 21:55:25.826452 34819 net.cpp:380] res1_3_res1_3_0_split -> res1_3_res1_3_0_split_0
I0522 21:55:25.826458 34819 net.cpp:380] res1_3_res1_3_0_split -> res1_3_res1_3_0_split_1
I0522 21:55:25.826495 34819 net.cpp:122] Setting up res1_3_res1_3_0_split
I0522 21:55:25.826503 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.826508 34819 net.cpp:129] Top shape: 64 24 56 48 (4128768)
I0522 21:55:25.826511 34819 net.cpp:137] Memory required for data: 156893952
I0522 21:55:25.826515 34819 layer_factory.hpp:77] Creating layer res1_3_reduce
I0522 21:55:25.826526 34819 net.cpp:84] Creating Layer res1_3_reduce
I0522 21:55:25.826532 34819 net.cpp:406] res1_3_reduce <- res1_3_res1_3_0_split_0
I0522 21:55:25.826539 34819 net.cpp:380] res1_3_reduce -> res1_3_reduce
I0522 21:55:25.827390 34819 net.cpp:122] Setting up res1_3_reduce
I0522 21:55:25.827406 34819 net.cpp:129] Top shape: 64 48 56 48 (8257536)
I0522 21:55:25.827411 34819 net.cpp:137] Memory required for data: 189924096
I0522 21:55:25.827419 34819 layer_factory.hpp:77] Creating layer pool1
I0522 21:55:25.827431 34819 net.cpp:84] Creating Layer pool1
I0522 21:55:25.827436 34819 net.cpp:406] pool1 <- res1_3_reduce
I0522 21:55:25.827443 34819 net.cpp:380] pool1 -> pool1
I0522 21:55:25.827504 34819 net.cpp:122] Setting up pool1
I0522 21:55:25.827513 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.827517 34819 net.cpp:137] Memory required for data: 198181632
I0522 21:55:25.827522 34819 layer_factory.hpp:77] Creating layer conv2_1
I0522 21:55:25.827533 34819 net.cpp:84] Creating Layer conv2_1
I0522 21:55:25.827538 34819 net.cpp:406] conv2_1 <- res1_3_res1_3_0_split_1
I0522 21:55:25.827545 34819 net.cpp:380] conv2_1 -> conv2_1
I0522 21:55:25.829159 34819 net.cpp:122] Setting up conv2_1
I0522 21:55:25.829177 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.829182 34819 net.cpp:137] Memory required for data: 206439168
I0522 21:55:25.829195 34819 layer_factory.hpp:77] Creating layer relu2_1
I0522 21:55:25.829203 34819 net.cpp:84] Creating Layer relu2_1
I0522 21:55:25.829208 34819 net.cpp:406] relu2_1 <- conv2_1
I0522 21:55:25.829215 34819 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0522 21:55:25.829341 34819 net.cpp:122] Setting up relu2_1
I0522 21:55:25.829351 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.829355 34819 net.cpp:137] Memory required for data: 214696704
I0522 21:55:25.829361 34819 layer_factory.hpp:77] Creating layer res1_3_p
I0522 21:55:25.829368 34819 net.cpp:84] Creating Layer res1_3_p
I0522 21:55:25.829372 34819 net.cpp:406] res1_3_p <- pool1
I0522 21:55:25.829377 34819 net.cpp:406] res1_3_p <- conv2_1
I0522 21:55:25.829383 34819 net.cpp:380] res1_3_p -> res1_3_p
I0522 21:55:25.829409 34819 net.cpp:122] Setting up res1_3_p
I0522 21:55:25.829417 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.829421 34819 net.cpp:137] Memory required for data: 222954240
I0522 21:55:25.829425 34819 layer_factory.hpp:77] Creating layer res1_3_p_res1_3_p_0_split
I0522 21:55:25.829432 34819 net.cpp:84] Creating Layer res1_3_p_res1_3_p_0_split
I0522 21:55:25.829437 34819 net.cpp:406] res1_3_p_res1_3_p_0_split <- res1_3_p
I0522 21:55:25.829442 34819 net.cpp:380] res1_3_p_res1_3_p_0_split -> res1_3_p_res1_3_p_0_split_0
I0522 21:55:25.829449 34819 net.cpp:380] res1_3_p_res1_3_p_0_split -> res1_3_p_res1_3_p_0_split_1
I0522 21:55:25.829484 34819 net.cpp:122] Setting up res1_3_p_res1_3_p_0_split
I0522 21:55:25.829493 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.829497 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.829501 34819 net.cpp:137] Memory required for data: 239469312
I0522 21:55:25.829504 34819 layer_factory.hpp:77] Creating layer conv2_3
I0522 21:55:25.829515 34819 net.cpp:84] Creating Layer conv2_3
I0522 21:55:25.829519 34819 net.cpp:406] conv2_3 <- res1_3_p_res1_3_p_0_split_0
I0522 21:55:25.829526 34819 net.cpp:380] conv2_3 -> conv2_3
I0522 21:55:25.831401 34819 net.cpp:122] Setting up conv2_3
I0522 21:55:25.831420 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.831429 34819 net.cpp:137] Memory required for data: 247726848
I0522 21:55:25.831437 34819 layer_factory.hpp:77] Creating layer relu2_3
I0522 21:55:25.831449 34819 net.cpp:84] Creating Layer relu2_3
I0522 21:55:25.831454 34819 net.cpp:406] relu2_3 <- conv2_3
I0522 21:55:25.831459 34819 net.cpp:367] relu2_3 -> conv2_3 (in-place)
I0522 21:55:25.831590 34819 net.cpp:122] Setting up relu2_3
I0522 21:55:25.831601 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.831605 34819 net.cpp:137] Memory required for data: 255984384
I0522 21:55:25.831611 34819 layer_factory.hpp:77] Creating layer res2_3
I0522 21:55:25.831619 34819 net.cpp:84] Creating Layer res2_3
I0522 21:55:25.831622 34819 net.cpp:406] res2_3 <- res1_3_p_res1_3_p_0_split_1
I0522 21:55:25.831629 34819 net.cpp:406] res2_3 <- conv2_3
I0522 21:55:25.831634 34819 net.cpp:380] res2_3 -> res2_3
I0522 21:55:25.831660 34819 net.cpp:122] Setting up res2_3
I0522 21:55:25.831668 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.831672 34819 net.cpp:137] Memory required for data: 264241920
I0522 21:55:25.831676 34819 layer_factory.hpp:77] Creating layer res2_3_res2_3_0_split
I0522 21:55:25.831681 34819 net.cpp:84] Creating Layer res2_3_res2_3_0_split
I0522 21:55:25.831686 34819 net.cpp:406] res2_3_res2_3_0_split <- res2_3
I0522 21:55:25.831691 34819 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_0
I0522 21:55:25.831698 34819 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_1
I0522 21:55:25.831733 34819 net.cpp:122] Setting up res2_3_res2_3_0_split
I0522 21:55:25.831742 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.831746 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.831749 34819 net.cpp:137] Memory required for data: 280756992
I0522 21:55:25.831753 34819 layer_factory.hpp:77] Creating layer conv2_5
I0522 21:55:25.831763 34819 net.cpp:84] Creating Layer conv2_5
I0522 21:55:25.831768 34819 net.cpp:406] conv2_5 <- res2_3_res2_3_0_split_0
I0522 21:55:25.831774 34819 net.cpp:380] conv2_5 -> conv2_5
I0522 21:55:25.833274 34819 net.cpp:122] Setting up conv2_5
I0522 21:55:25.833303 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.833308 34819 net.cpp:137] Memory required for data: 289014528
I0522 21:55:25.833315 34819 layer_factory.hpp:77] Creating layer relu2_5
I0522 21:55:25.833323 34819 net.cpp:84] Creating Layer relu2_5
I0522 21:55:25.833328 34819 net.cpp:406] relu2_5 <- conv2_5
I0522 21:55:25.833335 34819 net.cpp:367] relu2_5 -> conv2_5 (in-place)
I0522 21:55:25.833456 34819 net.cpp:122] Setting up relu2_5
I0522 21:55:25.833467 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.833470 34819 net.cpp:137] Memory required for data: 297272064
I0522 21:55:25.833480 34819 layer_factory.hpp:77] Creating layer res2_5
I0522 21:55:25.833489 34819 net.cpp:84] Creating Layer res2_5
I0522 21:55:25.833493 34819 net.cpp:406] res2_5 <- res2_3_res2_3_0_split_1
I0522 21:55:25.833498 34819 net.cpp:406] res2_5 <- conv2_5
I0522 21:55:25.833504 34819 net.cpp:380] res2_5 -> res2_5
I0522 21:55:25.833530 34819 net.cpp:122] Setting up res2_5
I0522 21:55:25.833539 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.833542 34819 net.cpp:137] Memory required for data: 305529600
I0522 21:55:25.833545 34819 layer_factory.hpp:77] Creating layer res2_5_res2_5_0_split
I0522 21:55:25.833551 34819 net.cpp:84] Creating Layer res2_5_res2_5_0_split
I0522 21:55:25.833555 34819 net.cpp:406] res2_5_res2_5_0_split <- res2_5
I0522 21:55:25.833561 34819 net.cpp:380] res2_5_res2_5_0_split -> res2_5_res2_5_0_split_0
I0522 21:55:25.833567 34819 net.cpp:380] res2_5_res2_5_0_split -> res2_5_res2_5_0_split_1
I0522 21:55:25.833601 34819 net.cpp:122] Setting up res2_5_res2_5_0_split
I0522 21:55:25.833609 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.833614 34819 net.cpp:129] Top shape: 64 48 28 24 (2064384)
I0522 21:55:25.833632 34819 net.cpp:137] Memory required for data: 322044672
I0522 21:55:25.833637 34819 layer_factory.hpp:77] Creating layer res2_5_reduce
I0522 21:55:25.833649 34819 net.cpp:84] Creating Layer res2_5_reduce
I0522 21:55:25.833655 34819 net.cpp:406] res2_5_reduce <- res2_5_res2_5_0_split_0
I0522 21:55:25.833662 34819 net.cpp:380] res2_5_reduce -> res2_5_reduce
I0522 21:55:25.834933 34819 net.cpp:122] Setting up res2_5_reduce
I0522 21:55:25.834951 34819 net.cpp:129] Top shape: 64 72 28 24 (3096576)
I0522 21:55:25.834956 34819 net.cpp:137] Memory required for data: 334430976
I0522 21:55:25.834964 34819 layer_factory.hpp:77] Creating layer pool2
I0522 21:55:25.834973 34819 net.cpp:84] Creating Layer pool2
I0522 21:55:25.834978 34819 net.cpp:406] pool2 <- res2_5_reduce
I0522 21:55:25.834985 34819 net.cpp:380] pool2 -> pool2
I0522 21:55:25.835029 34819 net.cpp:122] Setting up pool2
I0522 21:55:25.835047 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.835052 34819 net.cpp:137] Memory required for data: 337527552
I0522 21:55:25.835055 34819 layer_factory.hpp:77] Creating layer conv3_1
I0522 21:55:25.835067 34819 net.cpp:84] Creating Layer conv3_1
I0522 21:55:25.835072 34819 net.cpp:406] conv3_1 <- res2_5_res2_5_0_split_1
I0522 21:55:25.835079 34819 net.cpp:380] conv3_1 -> conv3_1
I0522 21:55:25.836851 34819 net.cpp:122] Setting up conv3_1
I0522 21:55:25.836870 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.836875 34819 net.cpp:137] Memory required for data: 340624128
I0522 21:55:25.836884 34819 layer_factory.hpp:77] Creating layer relu3_1
I0522 21:55:25.836892 34819 net.cpp:84] Creating Layer relu3_1
I0522 21:55:25.836899 34819 net.cpp:406] relu3_1 <- conv3_1
I0522 21:55:25.836906 34819 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0522 21:55:25.837018 34819 net.cpp:122] Setting up relu3_1
I0522 21:55:25.837026 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.837030 34819 net.cpp:137] Memory required for data: 343720704
I0522 21:55:25.837038 34819 layer_factory.hpp:77] Creating layer res2_5_p
I0522 21:55:25.837045 34819 net.cpp:84] Creating Layer res2_5_p
I0522 21:55:25.837049 34819 net.cpp:406] res2_5_p <- pool2
I0522 21:55:25.837054 34819 net.cpp:406] res2_5_p <- conv3_1
I0522 21:55:25.837060 34819 net.cpp:380] res2_5_p -> res2_5_p
I0522 21:55:25.837087 34819 net.cpp:122] Setting up res2_5_p
I0522 21:55:25.837095 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.837100 34819 net.cpp:137] Memory required for data: 346817280
I0522 21:55:25.837103 34819 layer_factory.hpp:77] Creating layer res2_5_p_res2_5_p_0_split
I0522 21:55:25.837110 34819 net.cpp:84] Creating Layer res2_5_p_res2_5_p_0_split
I0522 21:55:25.837115 34819 net.cpp:406] res2_5_p_res2_5_p_0_split <- res2_5_p
I0522 21:55:25.837121 34819 net.cpp:380] res2_5_p_res2_5_p_0_split -> res2_5_p_res2_5_p_0_split_0
I0522 21:55:25.837127 34819 net.cpp:380] res2_5_p_res2_5_p_0_split -> res2_5_p_res2_5_p_0_split_1
I0522 21:55:25.837162 34819 net.cpp:122] Setting up res2_5_p_res2_5_p_0_split
I0522 21:55:25.837169 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.837174 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.837178 34819 net.cpp:137] Memory required for data: 353010432
I0522 21:55:25.837182 34819 layer_factory.hpp:77] Creating layer conv3_3
I0522 21:55:25.837193 34819 net.cpp:84] Creating Layer conv3_3
I0522 21:55:25.837198 34819 net.cpp:406] conv3_3 <- res2_5_p_res2_5_p_0_split_0
I0522 21:55:25.837205 34819 net.cpp:380] conv3_3 -> conv3_3
I0522 21:55:25.839511 34819 net.cpp:122] Setting up conv3_3
I0522 21:55:25.839530 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.839536 34819 net.cpp:137] Memory required for data: 356107008
I0522 21:55:25.839545 34819 layer_factory.hpp:77] Creating layer relu3_3
I0522 21:55:25.839555 34819 net.cpp:84] Creating Layer relu3_3
I0522 21:55:25.839560 34819 net.cpp:406] relu3_3 <- conv3_3
I0522 21:55:25.839567 34819 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0522 21:55:25.839689 34819 net.cpp:122] Setting up relu3_3
I0522 21:55:25.839711 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.839717 34819 net.cpp:137] Memory required for data: 359203584
I0522 21:55:25.839723 34819 layer_factory.hpp:77] Creating layer res3_3
I0522 21:55:25.839731 34819 net.cpp:84] Creating Layer res3_3
I0522 21:55:25.839736 34819 net.cpp:406] res3_3 <- res2_5_p_res2_5_p_0_split_1
I0522 21:55:25.839741 34819 net.cpp:406] res3_3 <- conv3_3
I0522 21:55:25.839747 34819 net.cpp:380] res3_3 -> res3_3
I0522 21:55:25.839779 34819 net.cpp:122] Setting up res3_3
I0522 21:55:25.839788 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.839792 34819 net.cpp:137] Memory required for data: 362300160
I0522 21:55:25.839797 34819 layer_factory.hpp:77] Creating layer res3_3_res3_3_0_split
I0522 21:55:25.839805 34819 net.cpp:84] Creating Layer res3_3_res3_3_0_split
I0522 21:55:25.839812 34819 net.cpp:406] res3_3_res3_3_0_split <- res3_3
I0522 21:55:25.839818 34819 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_0
I0522 21:55:25.839824 34819 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_1
I0522 21:55:25.839861 34819 net.cpp:122] Setting up res3_3_res3_3_0_split
I0522 21:55:25.839869 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.839874 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.839877 34819 net.cpp:137] Memory required for data: 368493312
I0522 21:55:25.839881 34819 layer_factory.hpp:77] Creating layer conv3_5
I0522 21:55:25.839893 34819 net.cpp:84] Creating Layer conv3_5
I0522 21:55:25.839900 34819 net.cpp:406] conv3_5 <- res3_3_res3_3_0_split_0
I0522 21:55:25.839907 34819 net.cpp:380] conv3_5 -> conv3_5
I0522 21:55:25.842224 34819 net.cpp:122] Setting up conv3_5
I0522 21:55:25.842242 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.842247 34819 net.cpp:137] Memory required for data: 371589888
I0522 21:55:25.842257 34819 layer_factory.hpp:77] Creating layer relu3_5
I0522 21:55:25.842267 34819 net.cpp:84] Creating Layer relu3_5
I0522 21:55:25.842272 34819 net.cpp:406] relu3_5 <- conv3_5
I0522 21:55:25.842280 34819 net.cpp:367] relu3_5 -> conv3_5 (in-place)
I0522 21:55:25.842404 34819 net.cpp:122] Setting up relu3_5
I0522 21:55:25.842414 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.842418 34819 net.cpp:137] Memory required for data: 374686464
I0522 21:55:25.842424 34819 layer_factory.hpp:77] Creating layer res3_5
I0522 21:55:25.842432 34819 net.cpp:84] Creating Layer res3_5
I0522 21:55:25.842440 34819 net.cpp:406] res3_5 <- res3_3_res3_3_0_split_1
I0522 21:55:25.842447 34819 net.cpp:406] res3_5 <- conv3_5
I0522 21:55:25.842453 34819 net.cpp:380] res3_5 -> res3_5
I0522 21:55:25.842479 34819 net.cpp:122] Setting up res3_5
I0522 21:55:25.842489 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.842491 34819 net.cpp:137] Memory required for data: 377783040
I0522 21:55:25.842495 34819 layer_factory.hpp:77] Creating layer res3_5_res3_5_0_split
I0522 21:55:25.842502 34819 net.cpp:84] Creating Layer res3_5_res3_5_0_split
I0522 21:55:25.842506 34819 net.cpp:406] res3_5_res3_5_0_split <- res3_5
I0522 21:55:25.842512 34819 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_0
I0522 21:55:25.842519 34819 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_1
I0522 21:55:25.842556 34819 net.cpp:122] Setting up res3_5_res3_5_0_split
I0522 21:55:25.842563 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.842568 34819 net.cpp:129] Top shape: 64 72 14 12 (774144)
I0522 21:55:25.842572 34819 net.cpp:137] Memory required for data: 383976192
I0522 21:55:25.842576 34819 layer_factory.hpp:77] Creating layer res3_5_reduce
I0522 21:55:25.842588 34819 net.cpp:84] Creating Layer res3_5_reduce
I0522 21:55:25.842592 34819 net.cpp:406] res3_5_reduce <- res3_5_res3_5_0_split_0
I0522 21:55:25.842599 34819 net.cpp:380] res3_5_reduce -> res3_5_reduce
I0522 21:55:25.844048 34819 net.cpp:122] Setting up res3_5_reduce
I0522 21:55:25.844079 34819 net.cpp:129] Top shape: 64 144 14 12 (1548288)
I0522 21:55:25.844096 34819 net.cpp:137] Memory required for data: 390169344
I0522 21:55:25.844106 34819 layer_factory.hpp:77] Creating layer pool3
I0522 21:55:25.844116 34819 net.cpp:84] Creating Layer pool3
I0522 21:55:25.844121 34819 net.cpp:406] pool3 <- res3_5_reduce
I0522 21:55:25.844128 34819 net.cpp:380] pool3 -> pool3
I0522 21:55:25.844177 34819 net.cpp:122] Setting up pool3
I0522 21:55:25.844187 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.844190 34819 net.cpp:137] Memory required for data: 391717632
I0522 21:55:25.844194 34819 layer_factory.hpp:77] Creating layer conv4_1
I0522 21:55:25.844208 34819 net.cpp:84] Creating Layer conv4_1
I0522 21:55:25.844213 34819 net.cpp:406] conv4_1 <- res3_5_res3_5_0_split_1
I0522 21:55:25.844220 34819 net.cpp:380] conv4_1 -> conv4_1
I0522 21:55:25.847626 34819 net.cpp:122] Setting up conv4_1
I0522 21:55:25.847657 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.847662 34819 net.cpp:137] Memory required for data: 393265920
I0522 21:55:25.847671 34819 layer_factory.hpp:77] Creating layer relu4_1
I0522 21:55:25.847681 34819 net.cpp:84] Creating Layer relu4_1
I0522 21:55:25.847685 34819 net.cpp:406] relu4_1 <- conv4_1
I0522 21:55:25.847692 34819 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0522 21:55:25.847820 34819 net.cpp:122] Setting up relu4_1
I0522 21:55:25.847831 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.847834 34819 net.cpp:137] Memory required for data: 394814208
I0522 21:55:25.847847 34819 layer_factory.hpp:77] Creating layer res3_5_p
I0522 21:55:25.847856 34819 net.cpp:84] Creating Layer res3_5_p
I0522 21:55:25.847860 34819 net.cpp:406] res3_5_p <- pool3
I0522 21:55:25.847865 34819 net.cpp:406] res3_5_p <- conv4_1
I0522 21:55:25.847872 34819 net.cpp:380] res3_5_p -> res3_5_p
I0522 21:55:25.847901 34819 net.cpp:122] Setting up res3_5_p
I0522 21:55:25.847909 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.847913 34819 net.cpp:137] Memory required for data: 396362496
I0522 21:55:25.847918 34819 layer_factory.hpp:77] Creating layer res3_5_p_res3_5_p_0_split
I0522 21:55:25.847924 34819 net.cpp:84] Creating Layer res3_5_p_res3_5_p_0_split
I0522 21:55:25.847929 34819 net.cpp:406] res3_5_p_res3_5_p_0_split <- res3_5_p
I0522 21:55:25.847935 34819 net.cpp:380] res3_5_p_res3_5_p_0_split -> res3_5_p_res3_5_p_0_split_0
I0522 21:55:25.847942 34819 net.cpp:380] res3_5_p_res3_5_p_0_split -> res3_5_p_res3_5_p_0_split_1
I0522 21:55:25.847980 34819 net.cpp:122] Setting up res3_5_p_res3_5_p_0_split
I0522 21:55:25.847988 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.847993 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.847996 34819 net.cpp:137] Memory required for data: 399459072
I0522 21:55:25.848000 34819 layer_factory.hpp:77] Creating layer conv4_3
I0522 21:55:25.848011 34819 net.cpp:84] Creating Layer conv4_3
I0522 21:55:25.848017 34819 net.cpp:406] conv4_3 <- res3_5_p_res3_5_p_0_split_0
I0522 21:55:25.848026 34819 net.cpp:380] conv4_3 -> conv4_3
I0522 21:55:25.852720 34819 net.cpp:122] Setting up conv4_3
I0522 21:55:25.852751 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.852759 34819 net.cpp:137] Memory required for data: 401007360
I0522 21:55:25.852769 34819 layer_factory.hpp:77] Creating layer relu4_3
I0522 21:55:25.852783 34819 net.cpp:84] Creating Layer relu4_3
I0522 21:55:25.852788 34819 net.cpp:406] relu4_3 <- conv4_3
I0522 21:55:25.852808 34819 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0522 21:55:25.852955 34819 net.cpp:122] Setting up relu4_3
I0522 21:55:25.852965 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.852969 34819 net.cpp:137] Memory required for data: 402555648
I0522 21:55:25.852977 34819 layer_factory.hpp:77] Creating layer res4_3
I0522 21:55:25.852985 34819 net.cpp:84] Creating Layer res4_3
I0522 21:55:25.852993 34819 net.cpp:406] res4_3 <- res3_5_p_res3_5_p_0_split_1
I0522 21:55:25.852998 34819 net.cpp:406] res4_3 <- conv4_3
I0522 21:55:25.853004 34819 net.cpp:380] res4_3 -> res4_3
I0522 21:55:25.853036 34819 net.cpp:122] Setting up res4_3
I0522 21:55:25.853057 34819 net.cpp:129] Top shape: 64 144 7 6 (387072)
I0522 21:55:25.853062 34819 net.cpp:137] Memory required for data: 404103936
I0522 21:55:25.853066 34819 layer_factory.hpp:77] Creating layer fc5
I0522 21:55:25.853077 34819 net.cpp:84] Creating Layer fc5
I0522 21:55:25.853083 34819 net.cpp:406] fc5 <- res4_3
I0522 21:55:25.853091 34819 net.cpp:380] fc5 -> fc5
I0522 21:55:25.870092 34819 net.cpp:122] Setting up fc5
I0522 21:55:25.870134 34819 net.cpp:129] Top shape: 64 256 (16384)
I0522 21:55:25.870143 34819 net.cpp:137] Memory required for data: 404169472
I0522 21:55:25.870152 34819 layer_factory.hpp:77] Creating layer fc5_bn
I0522 21:55:25.870193 34819 net.cpp:84] Creating Layer fc5_bn
I0522 21:55:25.870206 34819 net.cpp:406] fc5_bn <- fc5
I0522 21:55:25.870214 34819 net.cpp:367] fc5_bn -> fc5 (in-place)
I0522 21:55:25.870543 34819 net.cpp:122] Setting up fc5_bn
I0522 21:55:25.870556 34819 net.cpp:129] Top shape: 64 256 (16384)
I0522 21:55:25.870560 34819 net.cpp:137] Memory required for data: 404235008
I0522 21:55:25.870584 34819 layer_factory.hpp:77] Creating layer norm1
I0522 21:55:25.870597 34819 net.cpp:84] Creating Layer norm1
I0522 21:55:25.870602 34819 net.cpp:406] norm1 <- fc5
I0522 21:55:25.870609 34819 net.cpp:380] norm1 -> norm1
I0522 21:55:25.870692 34819 net.cpp:122] Setting up norm1
I0522 21:55:25.870707 34819 net.cpp:129] Top shape: 64 256 1 1 (16384)
I0522 21:55:25.870712 34819 net.cpp:137] Memory required for data: 404300544
I0522 21:55:25.870717 34819 layer_factory.hpp:77] Creating layer fc-6_l2
I0522 21:55:25.870728 34819 net.cpp:84] Creating Layer fc-6_l2
I0522 21:55:25.870735 34819 net.cpp:406] fc-6_l2 <- norm1
I0522 21:55:25.870743 34819 net.cpp:380] fc-6_l2 -> fc-6_l2
I0522 21:55:26.012423 34819 net.cpp:122] Setting up fc-6_l2
I0522 21:55:26.012482 34819 net.cpp:129] Top shape: 64 54547 (3491008)
I0522 21:55:26.012487 34819 net.cpp:137] Memory required for data: 418264576
I0522 21:55:26.012497 34819 layer_factory.hpp:77] Creating layer fc-6_margin
I0522 21:55:26.012543 34819 net.cpp:84] Creating Layer fc-6_margin
I0522 21:55:26.012550 34819 net.cpp:406] fc-6_margin <- fc-6_l2
I0522 21:55:26.012557 34819 net.cpp:406] fc-6_margin <- label_data_1_split_0
I0522 21:55:26.012580 34819 net.cpp:380] fc-6_margin -> fc-6_margin
I0522 21:55:26.012624 34819 net.cpp:122] Setting up fc-6_margin
I0522 21:55:26.012634 34819 net.cpp:129] Top shape: 64 54547 (3491008)
I0522 21:55:26.012636 34819 net.cpp:137] Memory required for data: 432228608
I0522 21:55:26.012640 34819 layer_factory.hpp:77] Creating layer fc-6_margin_scale
I0522 21:55:26.012650 34819 net.cpp:84] Creating Layer fc-6_margin_scale
I0522 21:55:26.012655 34819 net.cpp:406] fc-6_margin_scale <- fc-6_margin
I0522 21:55:26.012661 34819 net.cpp:380] fc-6_margin_scale -> fc-6_margin_scale
I0522 21:55:26.012832 34819 net.cpp:122] Setting up fc-6_margin_scale
I0522 21:55:26.012841 34819 net.cpp:129] Top shape: 64 54547 (3491008)
I0522 21:55:26.012845 34819 net.cpp:137] Memory required for data: 446192640
I0522 21:55:26.012850 34819 layer_factory.hpp:77] Creating layer softmax_loss
I0522 21:55:26.012857 34819 net.cpp:84] Creating Layer softmax_loss
I0522 21:55:26.012861 34819 net.cpp:406] softmax_loss <- fc-6_margin_scale
I0522 21:55:26.012866 34819 net.cpp:406] softmax_loss <- label_data_1_split_1
I0522 21:55:26.012873 34819 net.cpp:380] softmax_loss -> softmax_loss
I0522 21:55:26.012883 34819 layer_factory.hpp:77] Creating layer softmax_loss
I0522 21:55:26.027292 34819 net.cpp:122] Setting up softmax_loss
I0522 21:55:26.027340 34819 net.cpp:129] Top shape: (1)
I0522 21:55:26.027345 34819 net.cpp:132]     with loss weight 1
I0522 21:55:26.027369 34819 net.cpp:137] Memory required for data: 446192644
I0522 21:55:26.027375 34819 net.cpp:198] softmax_loss needs backward computation.
I0522 21:55:26.027400 34819 net.cpp:198] fc-6_margin_scale needs backward computation.
I0522 21:55:26.027403 34819 net.cpp:198] fc-6_margin needs backward computation.
I0522 21:55:26.027411 34819 net.cpp:198] fc-6_l2 needs backward computation.
I0522 21:55:26.027436 34819 net.cpp:198] norm1 needs backward computation.
I0522 21:55:26.027441 34819 net.cpp:198] fc5_bn needs backward computation.
I0522 21:55:26.027446 34819 net.cpp:198] fc5 needs backward computation.
I0522 21:55:26.027451 34819 net.cpp:198] res4_3 needs backward computation.
I0522 21:55:26.027456 34819 net.cpp:198] relu4_3 needs backward computation.
I0522 21:55:26.027459 34819 net.cpp:198] conv4_3 needs backward computation.
I0522 21:55:26.027467 34819 net.cpp:198] res3_5_p_res3_5_p_0_split needs backward computation.
I0522 21:55:26.027470 34819 net.cpp:198] res3_5_p needs backward computation.
I0522 21:55:26.027477 34819 net.cpp:198] relu4_1 needs backward computation.
I0522 21:55:26.027482 34819 net.cpp:198] conv4_1 needs backward computation.
I0522 21:55:26.027487 34819 net.cpp:198] pool3 needs backward computation.
I0522 21:55:26.027490 34819 net.cpp:198] res3_5_reduce needs backward computation.
I0522 21:55:26.027494 34819 net.cpp:198] res3_5_res3_5_0_split needs backward computation.
I0522 21:55:26.027498 34819 net.cpp:198] res3_5 needs backward computation.
I0522 21:55:26.027503 34819 net.cpp:198] relu3_5 needs backward computation.
I0522 21:55:26.027506 34819 net.cpp:198] conv3_5 needs backward computation.
I0522 21:55:26.027509 34819 net.cpp:198] res3_3_res3_3_0_split needs backward computation.
I0522 21:55:26.027513 34819 net.cpp:198] res3_3 needs backward computation.
I0522 21:55:26.027518 34819 net.cpp:198] relu3_3 needs backward computation.
I0522 21:55:26.027521 34819 net.cpp:198] conv3_3 needs backward computation.
I0522 21:55:26.027526 34819 net.cpp:198] res2_5_p_res2_5_p_0_split needs backward computation.
I0522 21:55:26.027530 34819 net.cpp:198] res2_5_p needs backward computation.
I0522 21:55:26.027534 34819 net.cpp:198] relu3_1 needs backward computation.
I0522 21:55:26.027539 34819 net.cpp:198] conv3_1 needs backward computation.
I0522 21:55:26.027542 34819 net.cpp:198] pool2 needs backward computation.
I0522 21:55:26.027547 34819 net.cpp:198] res2_5_reduce needs backward computation.
I0522 21:55:26.027551 34819 net.cpp:198] res2_5_res2_5_0_split needs backward computation.
I0522 21:55:26.027555 34819 net.cpp:198] res2_5 needs backward computation.
I0522 21:55:26.027560 34819 net.cpp:198] relu2_5 needs backward computation.
I0522 21:55:26.027565 34819 net.cpp:198] conv2_5 needs backward computation.
I0522 21:55:26.027568 34819 net.cpp:198] res2_3_res2_3_0_split needs backward computation.
I0522 21:55:26.027572 34819 net.cpp:198] res2_3 needs backward computation.
I0522 21:55:26.027576 34819 net.cpp:198] relu2_3 needs backward computation.
I0522 21:55:26.027580 34819 net.cpp:198] conv2_3 needs backward computation.
I0522 21:55:26.027585 34819 net.cpp:198] res1_3_p_res1_3_p_0_split needs backward computation.
I0522 21:55:26.027588 34819 net.cpp:198] res1_3_p needs backward computation.
I0522 21:55:26.027592 34819 net.cpp:198] relu2_1 needs backward computation.
I0522 21:55:26.027595 34819 net.cpp:198] conv2_1 needs backward computation.
I0522 21:55:26.027601 34819 net.cpp:198] pool1 needs backward computation.
I0522 21:55:26.027604 34819 net.cpp:198] res1_3_reduce needs backward computation.
I0522 21:55:26.027608 34819 net.cpp:198] res1_3_res1_3_0_split needs backward computation.
I0522 21:55:26.027612 34819 net.cpp:198] res1_3 needs backward computation.
I0522 21:55:26.027617 34819 net.cpp:198] relu1_3 needs backward computation.
I0522 21:55:26.027621 34819 net.cpp:198] conv1_3 needs backward computation.
I0522 21:55:26.027624 34819 net.cpp:198] conv1_1_relu1_1_0_split needs backward computation.
I0522 21:55:26.027628 34819 net.cpp:198] relu1_1 needs backward computation.
I0522 21:55:26.027632 34819 net.cpp:198] conv1_1 needs backward computation.
I0522 21:55:26.027637 34819 net.cpp:200] label_data_1_split does not need backward computation.
I0522 21:55:26.027642 34819 net.cpp:200] data does not need backward computation.
I0522 21:55:26.027644 34819 net.cpp:242] This network produces output softmax_loss
I0522 21:55:26.027691 34819 net.cpp:255] Network initialization done.
I0522 21:55:26.027890 34819 solver.cpp:57] Solver scaffolding done.
I0522 21:55:26.029440 34819 caffe.cpp:239] Starting Optimization
I0522 21:55:34.355713 34819 solver.cpp:293] Solving 2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_train
I0522 21:55:34.355759 34819 solver.cpp:294] Learning Rate Policy: multistep
I0522 21:55:34.601639 34819 solver.cpp:239] Iteration 0 (0 iter/s, 0.237603s/10 iters), loss = 12.7218
I0522 21:55:34.601691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.7218 (* 1 = 12.7218 loss)
I0522 21:55:34.601706 34819 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I0522 21:55:35.234050 34819 solver.cpp:239] Iteration 10 (15.8149 iter/s, 0.632317s/10 iters), loss = 12.5432
I0522 21:55:35.234100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.5432 (* 1 = 12.5432 loss)
I0522 21:55:35.259011 34819 sgd_solver.cpp:112] Iteration 10, lr = 0.01
I0522 21:55:35.834416 34819 solver.cpp:239] Iteration 20 (16.6591 iter/s, 0.600271s/10 iters), loss = 12.6607
I0522 21:55:35.834463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.6607 (* 1 = 12.6607 loss)
I0522 21:55:35.860592 34819 sgd_solver.cpp:112] Iteration 20, lr = 0.01
I0522 21:55:36.460455 34819 solver.cpp:239] Iteration 30 (15.976 iter/s, 0.625941s/10 iters), loss = 12.2455
I0522 21:55:36.460515 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.2455 (* 1 = 12.2455 loss)
I0522 21:55:36.486075 34819 sgd_solver.cpp:112] Iteration 30, lr = 0.01
I0522 21:55:37.072679 34819 solver.cpp:239] Iteration 40 (16.3369 iter/s, 0.612112s/10 iters), loss = 12.5125
I0522 21:55:37.072738 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.5125 (* 1 = 12.5125 loss)
I0522 21:55:37.100375 34819 sgd_solver.cpp:112] Iteration 40, lr = 0.01
I0522 21:55:37.681727 34819 solver.cpp:239] Iteration 50 (16.422 iter/s, 0.60894s/10 iters), loss = 12.343
I0522 21:55:37.681782 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.343 (* 1 = 12.343 loss)
I0522 21:55:37.707690 34819 sgd_solver.cpp:112] Iteration 50, lr = 0.01
I0522 21:55:38.495959 34819 solver.cpp:239] Iteration 60 (12.2834 iter/s, 0.81411s/10 iters), loss = 12.8288
I0522 21:55:38.496012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.8288 (* 1 = 12.8288 loss)
I0522 21:55:38.576320 34819 sgd_solver.cpp:112] Iteration 60, lr = 0.01
I0522 21:55:39.996423 34819 solver.cpp:239] Iteration 70 (6.6652 iter/s, 1.50033s/10 iters), loss = 12.5854
I0522 21:55:39.996464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.5854 (* 1 = 12.5854 loss)
I0522 21:55:40.042462 34819 sgd_solver.cpp:112] Iteration 70, lr = 0.01
I0522 21:55:41.359156 34819 solver.cpp:239] Iteration 80 (7.33892 iter/s, 1.3626s/10 iters), loss = 12.1834
I0522 21:55:41.359230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.1834 (* 1 = 12.1834 loss)
I0522 21:55:41.403693 34819 sgd_solver.cpp:112] Iteration 80, lr = 0.01
I0522 21:55:42.771037 34819 solver.cpp:239] Iteration 90 (7.08353 iter/s, 1.41173s/10 iters), loss = 12.1544
I0522 21:55:42.771136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.1544 (* 1 = 12.1544 loss)
I0522 21:55:42.915081 34819 sgd_solver.cpp:112] Iteration 90, lr = 0.01
I0522 21:55:44.680444 34819 solver.cpp:239] Iteration 100 (5.23771 iter/s, 1.90923s/10 iters), loss = 12.4582
I0522 21:55:44.680498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.4582 (* 1 = 12.4582 loss)
I0522 21:55:44.736038 34819 sgd_solver.cpp:112] Iteration 100, lr = 0.01
I0522 21:55:46.100353 34819 solver.cpp:239] Iteration 110 (7.0433 iter/s, 1.41979s/10 iters), loss = 12.1441
I0522 21:55:46.100399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.1441 (* 1 = 12.1441 loss)
I0522 21:55:46.155773 34819 sgd_solver.cpp:112] Iteration 110, lr = 0.01
I0522 21:55:47.822523 34819 solver.cpp:239] Iteration 120 (5.80711 iter/s, 1.72203s/10 iters), loss = 12.1773
I0522 21:55:47.822573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.1773 (* 1 = 12.1773 loss)
I0522 21:55:47.872424 34819 sgd_solver.cpp:112] Iteration 120, lr = 0.01
I0522 21:55:49.202409 34819 solver.cpp:239] Iteration 130 (7.24776 iter/s, 1.37974s/10 iters), loss = 11.8063
I0522 21:55:49.202471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.8063 (* 1 = 11.8063 loss)
I0522 21:55:49.223419 34819 sgd_solver.cpp:112] Iteration 130, lr = 0.01
I0522 21:55:50.696902 34819 solver.cpp:239] Iteration 140 (6.6918 iter/s, 1.49437s/10 iters), loss = 12.1909
I0522 21:55:50.696946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.1909 (* 1 = 12.1909 loss)
I0522 21:55:50.733978 34819 sgd_solver.cpp:112] Iteration 140, lr = 0.01
I0522 21:55:52.209645 34819 solver.cpp:239] Iteration 150 (6.61101 iter/s, 1.51263s/10 iters), loss = 11.978
I0522 21:55:52.209688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.978 (* 1 = 11.978 loss)
I0522 21:55:52.341379 34819 sgd_solver.cpp:112] Iteration 150, lr = 0.01
I0522 21:55:53.806004 34819 solver.cpp:239] Iteration 160 (6.26483 iter/s, 1.59621s/10 iters), loss = 11.9376
I0522 21:55:53.806380 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.9376 (* 1 = 11.9376 loss)
I0522 21:55:53.853720 34819 sgd_solver.cpp:112] Iteration 160, lr = 0.01
I0522 21:55:55.235877 34819 solver.cpp:239] Iteration 170 (6.99683 iter/s, 1.42922s/10 iters), loss = 11.5426
I0522 21:55:55.235934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.5426 (* 1 = 11.5426 loss)
I0522 21:55:55.285023 34819 sgd_solver.cpp:112] Iteration 170, lr = 0.01
I0522 21:55:56.663092 34819 solver.cpp:239] Iteration 180 (7.00735 iter/s, 1.42707s/10 iters), loss = 11.9104
I0522 21:55:56.663134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.9104 (* 1 = 11.9104 loss)
I0522 21:55:56.716627 34819 sgd_solver.cpp:112] Iteration 180, lr = 0.01
I0522 21:55:58.027247 34819 solver.cpp:239] Iteration 190 (7.33112 iter/s, 1.36405s/10 iters), loss = 12.2106
I0522 21:55:58.027294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.2106 (* 1 = 12.2106 loss)
I0522 21:55:58.070497 34819 sgd_solver.cpp:112] Iteration 190, lr = 0.01
I0522 21:55:59.393162 34819 solver.cpp:239] Iteration 200 (7.32173 iter/s, 1.3658s/10 iters), loss = 11.9728
I0522 21:55:59.393216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.9728 (* 1 = 11.9728 loss)
I0522 21:55:59.441495 34819 sgd_solver.cpp:112] Iteration 200, lr = 0.01
I0522 21:56:01.103473 34819 solver.cpp:239] Iteration 210 (5.84733 iter/s, 1.71018s/10 iters), loss = 11.8248
I0522 21:56:01.103528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.8248 (* 1 = 11.8248 loss)
I0522 21:56:01.152535 34819 sgd_solver.cpp:112] Iteration 210, lr = 0.01
I0522 21:56:02.694257 34819 solver.cpp:239] Iteration 220 (6.28672 iter/s, 1.59065s/10 iters), loss = 11.4185
I0522 21:56:02.694324 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.4185 (* 1 = 11.4185 loss)
I0522 21:56:02.745532 34819 sgd_solver.cpp:112] Iteration 220, lr = 0.01
I0522 21:56:04.176039 34819 solver.cpp:239] Iteration 230 (6.74915 iter/s, 1.48167s/10 iters), loss = 11.8212
I0522 21:56:04.176100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.8212 (* 1 = 11.8212 loss)
I0522 21:56:04.226586 34819 sgd_solver.cpp:112] Iteration 230, lr = 0.01
I0522 21:56:05.395769 34819 solver.cpp:239] Iteration 240 (8.19932 iter/s, 1.21961s/10 iters), loss = 11.9604
I0522 21:56:05.395814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.9604 (* 1 = 11.9604 loss)
I0522 21:56:05.448711 34819 sgd_solver.cpp:112] Iteration 240, lr = 0.01
I0522 21:56:07.039140 34819 solver.cpp:239] Iteration 250 (6.0855 iter/s, 1.64325s/10 iters), loss = 11.6915
I0522 21:56:07.039186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6915 (* 1 = 11.6915 loss)
I0522 21:56:07.091011 34819 sgd_solver.cpp:112] Iteration 250, lr = 0.01
I0522 21:56:08.768739 34819 solver.cpp:239] Iteration 260 (5.78212 iter/s, 1.72947s/10 iters), loss = 12.0003
I0522 21:56:08.768800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 12.0003 (* 1 = 12.0003 loss)
I0522 21:56:08.820677 34819 sgd_solver.cpp:112] Iteration 260, lr = 0.01
I0522 21:56:10.089895 34819 solver.cpp:239] Iteration 270 (7.56982 iter/s, 1.32103s/10 iters), loss = 11.6241
I0522 21:56:10.089933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6241 (* 1 = 11.6241 loss)
I0522 21:56:10.135526 34819 sgd_solver.cpp:112] Iteration 270, lr = 0.01
I0522 21:56:11.708957 34819 solver.cpp:239] Iteration 280 (6.17684 iter/s, 1.61895s/10 iters), loss = 11.5723
I0522 21:56:11.709002 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.5723 (* 1 = 11.5723 loss)
I0522 21:56:11.764067 34819 sgd_solver.cpp:112] Iteration 280, lr = 0.01
I0522 21:56:13.082607 34819 solver.cpp:239] Iteration 290 (7.28045 iter/s, 1.37354s/10 iters), loss = 11.9928
I0522 21:56:13.082666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.9928 (* 1 = 11.9928 loss)
I0522 21:56:13.133980 34819 sgd_solver.cpp:112] Iteration 290, lr = 0.01
I0522 21:56:14.523906 34819 solver.cpp:239] Iteration 300 (6.93878 iter/s, 1.44118s/10 iters), loss = 11.2591
I0522 21:56:14.523998 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.2591 (* 1 = 11.2591 loss)
I0522 21:56:14.609856 34819 sgd_solver.cpp:112] Iteration 300, lr = 0.01
I0522 21:56:18.055490 34819 solver.cpp:239] Iteration 310 (2.83177 iter/s, 3.53136s/10 iters), loss = 11.6521
I0522 21:56:18.055533 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6521 (* 1 = 11.6521 loss)
I0522 21:56:18.122710 34819 sgd_solver.cpp:112] Iteration 310, lr = 0.01
I0522 21:56:22.403364 34819 solver.cpp:239] Iteration 320 (2.3001 iter/s, 4.34764s/10 iters), loss = 11.843
I0522 21:56:22.403419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.843 (* 1 = 11.843 loss)
I0522 21:56:22.975898 34819 sgd_solver.cpp:112] Iteration 320, lr = 0.01
I0522 21:56:27.059818 34819 solver.cpp:239] Iteration 330 (2.14767 iter/s, 4.65621s/10 iters), loss = 11.3749
I0522 21:56:27.060119 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.3749 (* 1 = 11.3749 loss)
I0522 21:56:27.863778 34819 sgd_solver.cpp:112] Iteration 330, lr = 0.01
I0522 21:56:32.039795 34819 solver.cpp:239] Iteration 340 (2.00953 iter/s, 4.9763s/10 iters), loss = 11.654
I0522 21:56:32.039860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.654 (* 1 = 11.654 loss)
I0522 21:56:32.108711 34819 sgd_solver.cpp:112] Iteration 340, lr = 0.01
I0522 21:56:36.269470 34819 solver.cpp:239] Iteration 350 (2.36439 iter/s, 4.22942s/10 iters), loss = 11.6561
I0522 21:56:36.269553 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6561 (* 1 = 11.6561 loss)
I0522 21:56:36.999256 34819 sgd_solver.cpp:112] Iteration 350, lr = 0.01
I0522 21:56:40.354343 34819 solver.cpp:239] Iteration 360 (2.44822 iter/s, 4.0846s/10 iters), loss = 11.6153
I0522 21:56:40.354410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6153 (* 1 = 11.6153 loss)
I0522 21:56:40.432991 34819 sgd_solver.cpp:112] Iteration 360, lr = 0.01
I0522 21:56:45.423519 34819 solver.cpp:239] Iteration 370 (1.97281 iter/s, 5.06891s/10 iters), loss = 11.7754
I0522 21:56:45.423573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.7754 (* 1 = 11.7754 loss)
I0522 21:56:45.490010 34819 sgd_solver.cpp:112] Iteration 370, lr = 0.01
I0522 21:56:50.998613 34819 solver.cpp:239] Iteration 380 (1.79378 iter/s, 5.57482s/10 iters), loss = 11.2439
I0522 21:56:50.998672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.2439 (* 1 = 11.2439 loss)
I0522 21:56:51.742110 34819 sgd_solver.cpp:112] Iteration 380, lr = 0.01
I0522 21:56:56.845532 34819 solver.cpp:239] Iteration 390 (1.71039 iter/s, 5.84661s/10 iters), loss = 11.6897
I0522 21:56:56.845597 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6897 (* 1 = 11.6897 loss)
I0522 21:56:57.529417 34819 sgd_solver.cpp:112] Iteration 390, lr = 0.01
I0522 21:57:03.186177 34819 solver.cpp:239] Iteration 400 (1.5772 iter/s, 6.34034s/10 iters), loss = 11.6933
I0522 21:57:03.186223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6933 (* 1 = 11.6933 loss)
I0522 21:57:03.245746 34819 sgd_solver.cpp:112] Iteration 400, lr = 0.01
I0522 21:57:05.618240 34819 solver.cpp:239] Iteration 410 (4.112 iter/s, 2.43191s/10 iters), loss = 10.8607
I0522 21:57:05.618310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8607 (* 1 = 10.8607 loss)
I0522 21:57:05.680871 34819 sgd_solver.cpp:112] Iteration 410, lr = 0.01
I0522 21:57:11.376351 34819 solver.cpp:239] Iteration 420 (1.73677 iter/s, 5.75782s/10 iters), loss = 11.5151
I0522 21:57:11.376390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.5151 (* 1 = 11.5151 loss)
I0522 21:57:11.441741 34819 sgd_solver.cpp:112] Iteration 420, lr = 0.01
I0522 21:57:15.231240 34819 solver.cpp:239] Iteration 430 (2.59424 iter/s, 3.85469s/10 iters), loss = 11.5188
I0522 21:57:15.231281 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.5188 (* 1 = 11.5188 loss)
I0522 21:57:15.291635 34819 sgd_solver.cpp:112] Iteration 430, lr = 0.01
I0522 21:57:19.493191 34819 solver.cpp:239] Iteration 440 (2.34648 iter/s, 4.2617s/10 iters), loss = 11.1119
I0522 21:57:19.493242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.1119 (* 1 = 11.1119 loss)
I0522 21:57:20.161981 34819 sgd_solver.cpp:112] Iteration 440, lr = 0.01
I0522 21:57:24.220202 34819 solver.cpp:239] Iteration 450 (2.11561 iter/s, 4.72677s/10 iters), loss = 11.7705
I0522 21:57:24.220247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.7705 (* 1 = 11.7705 loss)
I0522 21:57:24.283524 34819 sgd_solver.cpp:112] Iteration 450, lr = 0.01
I0522 21:57:29.332716 34819 solver.cpp:239] Iteration 460 (1.95608 iter/s, 5.11226s/10 iters), loss = 11.4902
I0522 21:57:29.333035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.4902 (* 1 = 11.4902 loss)
I0522 21:57:30.176470 34819 sgd_solver.cpp:112] Iteration 460, lr = 0.01
I0522 21:57:36.600721 34819 solver.cpp:239] Iteration 470 (1.376 iter/s, 7.26747s/10 iters), loss = 11.4716
I0522 21:57:36.600760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.4716 (* 1 = 11.4716 loss)
I0522 21:57:37.374863 34819 sgd_solver.cpp:112] Iteration 470, lr = 0.01
I0522 21:57:43.158707 34819 solver.cpp:239] Iteration 480 (1.52494 iter/s, 6.55766s/10 iters), loss = 11.6269
I0522 21:57:43.158764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6269 (* 1 = 11.6269 loss)
I0522 21:57:43.230679 34819 sgd_solver.cpp:112] Iteration 480, lr = 0.01
I0522 21:57:48.028139 34819 solver.cpp:239] Iteration 490 (2.05374 iter/s, 4.86918s/10 iters), loss = 10.7161
I0522 21:57:48.028194 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7161 (* 1 = 10.7161 loss)
I0522 21:57:48.840062 34819 sgd_solver.cpp:112] Iteration 490, lr = 0.01
I0522 21:57:54.726446 34819 solver.cpp:239] Iteration 500 (1.49299 iter/s, 6.69797s/10 iters), loss = 11.2503
I0522 21:57:54.726486 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.2503 (* 1 = 11.2503 loss)
I0522 21:57:55.431620 34819 sgd_solver.cpp:112] Iteration 500, lr = 0.01
I0522 21:58:00.674147 34819 solver.cpp:239] Iteration 510 (1.6814 iter/s, 5.94742s/10 iters), loss = 11.6977
I0522 21:58:00.674355 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.6977 (* 1 = 11.6977 loss)
I0522 21:58:01.543025 34819 sgd_solver.cpp:112] Iteration 510, lr = 0.01
I0522 21:58:05.849792 34819 solver.cpp:239] Iteration 520 (1.93227 iter/s, 5.17525s/10 iters), loss = 11.133
I0522 21:58:05.849850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.133 (* 1 = 11.133 loss)
I0522 21:58:05.910094 34819 sgd_solver.cpp:112] Iteration 520, lr = 0.01
I0522 21:58:08.835924 34819 solver.cpp:239] Iteration 530 (3.34901 iter/s, 2.98595s/10 iters), loss = 11.7193
I0522 21:58:08.835983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.7193 (* 1 = 11.7193 loss)
I0522 21:58:08.902026 34819 sgd_solver.cpp:112] Iteration 530, lr = 0.01
I0522 21:58:11.944705 34819 solver.cpp:239] Iteration 540 (3.21689 iter/s, 3.10859s/10 iters), loss = 11.586
I0522 21:58:11.944753 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.586 (* 1 = 11.586 loss)
I0522 21:58:12.014183 34819 sgd_solver.cpp:112] Iteration 540, lr = 0.01
I0522 21:58:17.631983 34819 solver.cpp:239] Iteration 550 (1.7584 iter/s, 5.687s/10 iters), loss = 11.2373
I0522 21:58:17.632035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.2373 (* 1 = 11.2373 loss)
I0522 21:58:17.701041 34819 sgd_solver.cpp:112] Iteration 550, lr = 0.01
I0522 21:58:21.665554 34819 solver.cpp:239] Iteration 560 (2.47933 iter/s, 4.03335s/10 iters), loss = 11.1571
I0522 21:58:21.665611 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.1571 (* 1 = 11.1571 loss)
I0522 21:58:21.741843 34819 sgd_solver.cpp:112] Iteration 560, lr = 0.01
I0522 21:58:26.667557 34819 solver.cpp:239] Iteration 570 (1.9993 iter/s, 5.00175s/10 iters), loss = 11.1674
I0522 21:58:26.667595 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.1674 (* 1 = 11.1674 loss)
I0522 21:58:26.743008 34819 sgd_solver.cpp:112] Iteration 570, lr = 0.01
I0522 21:58:31.470219 34819 solver.cpp:239] Iteration 580 (2.08228 iter/s, 4.80242s/10 iters), loss = 10.9293
I0522 21:58:31.470432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9293 (* 1 = 10.9293 loss)
I0522 21:58:31.533378 34819 sgd_solver.cpp:112] Iteration 580, lr = 0.01
I0522 21:58:35.459586 34819 solver.cpp:239] Iteration 590 (2.5069 iter/s, 3.98898s/10 iters), loss = 11.076
I0522 21:58:35.459635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.076 (* 1 = 11.076 loss)
I0522 21:58:35.519721 34819 sgd_solver.cpp:112] Iteration 590, lr = 0.01
I0522 21:58:41.350862 34819 solver.cpp:239] Iteration 600 (1.69751 iter/s, 5.89099s/10 iters), loss = 11.0052
I0522 21:58:41.350908 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.0052 (* 1 = 11.0052 loss)
I0522 21:58:42.109961 34819 sgd_solver.cpp:112] Iteration 600, lr = 0.01
I0522 21:58:44.875669 34819 solver.cpp:239] Iteration 610 (2.83719 iter/s, 3.52462s/10 iters), loss = 11.0519
I0522 21:58:44.875710 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.0519 (* 1 = 11.0519 loss)
I0522 21:58:44.940393 34819 sgd_solver.cpp:112] Iteration 610, lr = 0.01
I0522 21:58:49.607398 34819 solver.cpp:239] Iteration 620 (2.1135 iter/s, 4.73149s/10 iters), loss = 11.3011
I0522 21:58:49.607439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.3011 (* 1 = 11.3011 loss)
I0522 21:58:49.680150 34819 sgd_solver.cpp:112] Iteration 620, lr = 0.01
I0522 21:58:52.989964 34819 solver.cpp:239] Iteration 630 (2.9565 iter/s, 3.38238s/10 iters), loss = 11.4081
I0522 21:58:52.990015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.4081 (* 1 = 11.4081 loss)
I0522 21:58:53.051820 34819 sgd_solver.cpp:112] Iteration 630, lr = 0.01
I0522 21:58:58.076650 34819 solver.cpp:239] Iteration 640 (1.96601 iter/s, 5.08643s/10 iters), loss = 11.0732
I0522 21:58:58.076695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.0732 (* 1 = 11.0732 loss)
I0522 21:58:58.148836 34819 sgd_solver.cpp:112] Iteration 640, lr = 0.01
I0522 21:59:03.105563 34819 solver.cpp:239] Iteration 650 (1.9886 iter/s, 5.02867s/10 iters), loss = 11.1275
I0522 21:59:03.105707 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.1275 (* 1 = 11.1275 loss)
I0522 21:59:03.842895 34819 sgd_solver.cpp:112] Iteration 650, lr = 0.01
I0522 21:59:10.581145 34819 solver.cpp:239] Iteration 660 (1.33777 iter/s, 7.47514s/10 iters), loss = 10.9433
I0522 21:59:10.581187 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9433 (* 1 = 10.9433 loss)
I0522 21:59:10.640497 34819 sgd_solver.cpp:112] Iteration 660, lr = 0.01
I0522 21:59:16.016510 34819 solver.cpp:239] Iteration 670 (1.8399 iter/s, 5.43508s/10 iters), loss = 10.867
I0522 21:59:16.016574 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.867 (* 1 = 10.867 loss)
I0522 21:59:16.880745 34819 sgd_solver.cpp:112] Iteration 670, lr = 0.01
I0522 21:59:21.726810 34819 solver.cpp:239] Iteration 680 (1.75131 iter/s, 5.71001s/10 iters), loss = 10.8843
I0522 21:59:21.726850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8843 (* 1 = 10.8843 loss)
I0522 21:59:22.549965 34819 sgd_solver.cpp:112] Iteration 680, lr = 0.01
I0522 21:59:27.497078 34819 solver.cpp:239] Iteration 690 (1.73311 iter/s, 5.76999s/10 iters), loss = 10.6956
I0522 21:59:27.497123 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6956 (* 1 = 10.6956 loss)
I0522 21:59:28.306984 34819 sgd_solver.cpp:112] Iteration 690, lr = 0.01
I0522 21:59:34.788661 34819 solver.cpp:239] Iteration 700 (1.37151 iter/s, 7.29125s/10 iters), loss = 10.8977
I0522 21:59:34.788913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8977 (* 1 = 10.8977 loss)
I0522 21:59:34.861960 34819 sgd_solver.cpp:112] Iteration 700, lr = 0.01
I0522 21:59:38.883942 34819 solver.cpp:239] Iteration 710 (2.44207 iter/s, 4.09488s/10 iters), loss = 11.041
I0522 21:59:38.883985 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.041 (* 1 = 11.041 loss)
I0522 21:59:38.956246 34819 sgd_solver.cpp:112] Iteration 710, lr = 0.01
I0522 21:59:43.087532 34819 solver.cpp:239] Iteration 720 (2.37904 iter/s, 4.20337s/10 iters), loss = 10.8676
I0522 21:59:43.087579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8676 (* 1 = 10.8676 loss)
I0522 21:59:43.834547 34819 sgd_solver.cpp:112] Iteration 720, lr = 0.01
I0522 21:59:49.288205 34819 solver.cpp:239] Iteration 730 (1.6128 iter/s, 6.20038s/10 iters), loss = 11.2002
I0522 21:59:49.288249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.2002 (* 1 = 11.2002 loss)
I0522 21:59:49.361400 34819 sgd_solver.cpp:112] Iteration 730, lr = 0.01
I0522 21:59:53.616420 34819 solver.cpp:239] Iteration 740 (2.31054 iter/s, 4.32799s/10 iters), loss = 11.021
I0522 21:59:53.616473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.021 (* 1 = 11.021 loss)
I0522 21:59:54.266718 34819 sgd_solver.cpp:112] Iteration 740, lr = 0.01
I0522 21:59:59.142906 34819 solver.cpp:239] Iteration 750 (1.80956 iter/s, 5.52621s/10 iters), loss = 10.8368
I0522 21:59:59.142964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8368 (* 1 = 10.8368 loss)
I0522 21:59:59.207336 34819 sgd_solver.cpp:112] Iteration 750, lr = 0.01
I0522 22:00:05.341850 34819 solver.cpp:239] Iteration 760 (1.61326 iter/s, 6.19864s/10 iters), loss = 10.9523
I0522 22:00:05.342026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9523 (* 1 = 10.9523 loss)
I0522 22:00:05.400072 34819 sgd_solver.cpp:112] Iteration 760, lr = 0.01
I0522 22:00:09.982146 34819 solver.cpp:239] Iteration 770 (2.1552 iter/s, 4.63994s/10 iters), loss = 10.9543
I0522 22:00:09.982195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9543 (* 1 = 10.9543 loss)
I0522 22:00:10.842242 34819 sgd_solver.cpp:112] Iteration 770, lr = 0.01
I0522 22:00:15.789938 34819 solver.cpp:239] Iteration 780 (1.72191 iter/s, 5.80751s/10 iters), loss = 10.6761
I0522 22:00:15.789996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6761 (* 1 = 10.6761 loss)
I0522 22:00:15.863626 34819 sgd_solver.cpp:112] Iteration 780, lr = 0.01
I0522 22:00:19.193635 34819 solver.cpp:239] Iteration 790 (2.93816 iter/s, 3.40349s/10 iters), loss = 11.0684
I0522 22:00:19.193691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.0684 (* 1 = 11.0684 loss)
I0522 22:00:20.005658 34819 sgd_solver.cpp:112] Iteration 790, lr = 0.01
I0522 22:00:24.939715 34819 solver.cpp:239] Iteration 800 (1.7404 iter/s, 5.7458s/10 iters), loss = 11.2591
I0522 22:00:24.939770 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.2591 (* 1 = 11.2591 loss)
I0522 22:00:25.740399 34819 sgd_solver.cpp:112] Iteration 800, lr = 0.01
I0522 22:00:28.987633 34819 solver.cpp:239] Iteration 810 (2.47054 iter/s, 4.04771s/10 iters), loss = 10.6309
I0522 22:00:28.987673 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6309 (* 1 = 10.6309 loss)
I0522 22:00:29.836207 34819 sgd_solver.cpp:112] Iteration 810, lr = 0.01
I0522 22:00:35.396327 34819 solver.cpp:239] Iteration 820 (1.56045 iter/s, 6.40839s/10 iters), loss = 10.7489
I0522 22:00:35.396514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7489 (* 1 = 10.7489 loss)
I0522 22:00:36.199113 34819 sgd_solver.cpp:112] Iteration 820, lr = 0.01
I0522 22:00:39.575662 34819 solver.cpp:239] Iteration 830 (2.39293 iter/s, 4.17898s/10 iters), loss = 10.8819
I0522 22:00:39.575717 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8819 (* 1 = 10.8819 loss)
I0522 22:00:39.655481 34819 sgd_solver.cpp:112] Iteration 830, lr = 0.01
I0522 22:00:44.872783 34819 solver.cpp:239] Iteration 840 (1.88792 iter/s, 5.29684s/10 iters), loss = 10.6353
I0522 22:00:44.872828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6353 (* 1 = 10.6353 loss)
I0522 22:00:44.932445 34819 sgd_solver.cpp:112] Iteration 840, lr = 0.01
I0522 22:00:50.232547 34819 solver.cpp:239] Iteration 850 (1.86585 iter/s, 5.3595s/10 iters), loss = 10.3841
I0522 22:00:50.232586 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3841 (* 1 = 10.3841 loss)
I0522 22:00:50.316184 34819 sgd_solver.cpp:112] Iteration 850, lr = 0.01
I0522 22:00:55.101857 34819 solver.cpp:239] Iteration 860 (2.05378 iter/s, 4.86907s/10 iters), loss = 10.7025
I0522 22:00:55.101905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7025 (* 1 = 10.7025 loss)
I0522 22:00:55.611659 34819 sgd_solver.cpp:112] Iteration 860, lr = 0.01
I0522 22:00:58.884390 34819 solver.cpp:239] Iteration 870 (2.64387 iter/s, 3.78233s/10 iters), loss = 10.8279
I0522 22:00:58.884436 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8279 (* 1 = 10.8279 loss)
I0522 22:00:58.942137 34819 sgd_solver.cpp:112] Iteration 870, lr = 0.01
I0522 22:01:03.628963 34819 solver.cpp:239] Iteration 880 (2.10778 iter/s, 4.74434s/10 iters), loss = 10.9647
I0522 22:01:03.629004 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9647 (* 1 = 10.9647 loss)
I0522 22:01:04.517248 34819 sgd_solver.cpp:112] Iteration 880, lr = 0.01
I0522 22:01:08.500267 34819 solver.cpp:239] Iteration 890 (2.05294 iter/s, 4.87106s/10 iters), loss = 11.0213
I0522 22:01:08.500468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.0213 (* 1 = 11.0213 loss)
I0522 22:01:09.181260 34819 sgd_solver.cpp:112] Iteration 890, lr = 0.01
I0522 22:01:14.013854 34819 solver.cpp:239] Iteration 900 (1.81383 iter/s, 5.51319s/10 iters), loss = 10.9467
I0522 22:01:14.013900 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9467 (* 1 = 10.9467 loss)
I0522 22:01:14.072350 34819 sgd_solver.cpp:112] Iteration 900, lr = 0.01
I0522 22:01:18.664260 34819 solver.cpp:239] Iteration 910 (2.15046 iter/s, 4.65017s/10 iters), loss = 10.8533
I0522 22:01:18.664314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8533 (* 1 = 10.8533 loss)
I0522 22:01:18.732825 34819 sgd_solver.cpp:112] Iteration 910, lr = 0.01
I0522 22:01:24.390367 34819 solver.cpp:239] Iteration 920 (1.74648 iter/s, 5.72582s/10 iters), loss = 10.6703
I0522 22:01:24.390419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6703 (* 1 = 10.6703 loss)
I0522 22:01:24.465468 34819 sgd_solver.cpp:112] Iteration 920, lr = 0.01
I0522 22:01:28.787475 34819 solver.cpp:239] Iteration 930 (2.27434 iter/s, 4.39687s/10 iters), loss = 10.8434
I0522 22:01:28.787523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8434 (* 1 = 10.8434 loss)
I0522 22:01:29.517513 34819 sgd_solver.cpp:112] Iteration 930, lr = 0.01
I0522 22:01:33.579391 34819 solver.cpp:239] Iteration 940 (2.08695 iter/s, 4.79167s/10 iters), loss = 10.7863
I0522 22:01:33.579434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7863 (* 1 = 10.7863 loss)
I0522 22:01:33.656935 34819 sgd_solver.cpp:112] Iteration 940, lr = 0.01
I0522 22:01:38.392107 34819 solver.cpp:239] Iteration 950 (2.07793 iter/s, 4.81248s/10 iters), loss = 10.9047
I0522 22:01:38.392151 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9047 (* 1 = 10.9047 loss)
I0522 22:01:39.239924 34819 sgd_solver.cpp:112] Iteration 950, lr = 0.01
I0522 22:01:44.832429 34819 solver.cpp:239] Iteration 960 (1.55279 iter/s, 6.44002s/10 iters), loss = 11.1256
I0522 22:01:44.832485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.1256 (* 1 = 11.1256 loss)
I0522 22:01:44.901513 34819 sgd_solver.cpp:112] Iteration 960, lr = 0.01
I0522 22:01:49.023543 34819 solver.cpp:239] Iteration 970 (2.38613 iter/s, 4.19089s/10 iters), loss = 10.939
I0522 22:01:49.023581 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.939 (* 1 = 10.939 loss)
I0522 22:01:49.085093 34819 sgd_solver.cpp:112] Iteration 970, lr = 0.01
I0522 22:01:54.001196 34819 solver.cpp:239] Iteration 980 (2.00908 iter/s, 4.97741s/10 iters), loss = 10.5214
I0522 22:01:54.001251 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5214 (* 1 = 10.5214 loss)
I0522 22:01:54.070806 34819 sgd_solver.cpp:112] Iteration 980, lr = 0.01
I0522 22:01:58.512049 34819 solver.cpp:239] Iteration 990 (2.21699 iter/s, 4.51061s/10 iters), loss = 10.7632
I0522 22:01:58.512094 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7632 (* 1 = 10.7632 loss)
I0522 22:01:59.306180 34819 sgd_solver.cpp:112] Iteration 990, lr = 0.01
I0522 22:02:02.788723 34819 solver.cpp:239] Iteration 1000 (2.33839 iter/s, 4.27645s/10 iters), loss = 10.873
I0522 22:02:02.788779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.873 (* 1 = 10.873 loss)
I0522 22:02:03.604032 34819 sgd_solver.cpp:112] Iteration 1000, lr = 0.01
I0522 22:02:08.284937 34819 solver.cpp:239] Iteration 1010 (1.81952 iter/s, 5.49594s/10 iters), loss = 10.8684
I0522 22:02:08.284981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8684 (* 1 = 10.8684 loss)
I0522 22:02:09.138836 34819 sgd_solver.cpp:112] Iteration 1010, lr = 0.01
I0522 22:02:12.882220 34819 solver.cpp:239] Iteration 1020 (2.17531 iter/s, 4.59704s/10 iters), loss = 10.7313
I0522 22:02:12.882395 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7313 (* 1 = 10.7313 loss)
I0522 22:02:13.605058 34819 sgd_solver.cpp:112] Iteration 1020, lr = 0.01
I0522 22:02:17.818060 34819 solver.cpp:239] Iteration 1030 (2.02615 iter/s, 4.93547s/10 iters), loss = 10.6089
I0522 22:02:17.818101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6089 (* 1 = 10.6089 loss)
I0522 22:02:17.879547 34819 sgd_solver.cpp:112] Iteration 1030, lr = 0.01
I0522 22:02:21.431593 34819 solver.cpp:239] Iteration 1040 (2.76753 iter/s, 3.61333s/10 iters), loss = 10.8614
I0522 22:02:21.431660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8614 (* 1 = 10.8614 loss)
I0522 22:02:22.306298 34819 sgd_solver.cpp:112] Iteration 1040, lr = 0.01
I0522 22:02:27.492403 34819 solver.cpp:239] Iteration 1050 (1.65003 iter/s, 6.0605s/10 iters), loss = 10.5738
I0522 22:02:27.492457 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5738 (* 1 = 10.5738 loss)
I0522 22:02:27.558157 34819 sgd_solver.cpp:112] Iteration 1050, lr = 0.01
I0522 22:02:30.896895 34819 solver.cpp:239] Iteration 1060 (2.93746 iter/s, 3.4043s/10 iters), loss = 10.3359
I0522 22:02:30.896946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3359 (* 1 = 10.3359 loss)
I0522 22:02:31.097345 34819 sgd_solver.cpp:112] Iteration 1060, lr = 0.01
I0522 22:02:36.035303 34819 solver.cpp:239] Iteration 1070 (1.94623 iter/s, 5.13814s/10 iters), loss = 10.489
I0522 22:02:36.035357 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.489 (* 1 = 10.489 loss)
I0522 22:02:36.095306 34819 sgd_solver.cpp:112] Iteration 1070, lr = 0.01
I0522 22:02:39.501893 34819 solver.cpp:239] Iteration 1080 (2.88484 iter/s, 3.46639s/10 iters), loss = 10.4133
I0522 22:02:39.501951 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4133 (* 1 = 10.4133 loss)
I0522 22:02:40.311748 34819 sgd_solver.cpp:112] Iteration 1080, lr = 0.01
I0522 22:02:45.250733 34819 solver.cpp:239] Iteration 1090 (1.73957 iter/s, 5.74855s/10 iters), loss = 10.6413
I0522 22:02:45.251425 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6413 (* 1 = 10.6413 loss)
I0522 22:02:45.333751 34819 sgd_solver.cpp:112] Iteration 1090, lr = 0.01
I0522 22:02:50.808531 34819 solver.cpp:239] Iteration 1100 (1.79957 iter/s, 5.5569s/10 iters), loss = 10.8362
I0522 22:02:50.808588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.8362 (* 1 = 10.8362 loss)
I0522 22:02:50.867807 34819 sgd_solver.cpp:112] Iteration 1100, lr = 0.01
I0522 22:02:55.023424 34819 solver.cpp:239] Iteration 1110 (2.37267 iter/s, 4.21466s/10 iters), loss = 11.2697
I0522 22:02:55.023469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.2697 (* 1 = 11.2697 loss)
I0522 22:02:55.079907 34819 sgd_solver.cpp:112] Iteration 1110, lr = 0.01
I0522 22:02:59.232672 34819 solver.cpp:239] Iteration 1120 (2.37584 iter/s, 4.20903s/10 iters), loss = 10.2953
I0522 22:02:59.232719 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2953 (* 1 = 10.2953 loss)
I0522 22:02:59.999994 34819 sgd_solver.cpp:112] Iteration 1120, lr = 0.01
I0522 22:03:04.872607 34819 solver.cpp:239] Iteration 1130 (1.77316 iter/s, 5.63965s/10 iters), loss = 10.5726
I0522 22:03:04.872665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5726 (* 1 = 10.5726 loss)
I0522 22:03:04.959784 34819 sgd_solver.cpp:112] Iteration 1130, lr = 0.01
I0522 22:03:08.695266 34819 solver.cpp:239] Iteration 1140 (2.61613 iter/s, 3.82244s/10 iters), loss = 10.2506
I0522 22:03:08.695317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2506 (* 1 = 10.2506 loss)
I0522 22:03:08.768299 34819 sgd_solver.cpp:112] Iteration 1140, lr = 0.01
I0522 22:03:13.584985 34819 solver.cpp:239] Iteration 1150 (2.04521 iter/s, 4.88947s/10 iters), loss = 11.0044
I0522 22:03:13.585027 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.0044 (* 1 = 11.0044 loss)
I0522 22:03:14.431756 34819 sgd_solver.cpp:112] Iteration 1150, lr = 0.01
I0522 22:03:19.231688 34819 solver.cpp:239] Iteration 1160 (1.77103 iter/s, 5.64644s/10 iters), loss = 9.99567
I0522 22:03:19.232543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.99567 (* 1 = 9.99567 loss)
I0522 22:03:19.298074 34819 sgd_solver.cpp:112] Iteration 1160, lr = 0.01
I0522 22:03:24.297792 34819 solver.cpp:239] Iteration 1170 (1.97505 iter/s, 5.06317s/10 iters), loss = 10.4633
I0522 22:03:24.297837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4633 (* 1 = 10.4633 loss)
I0522 22:03:24.363097 34819 sgd_solver.cpp:112] Iteration 1170, lr = 0.01
I0522 22:03:29.897267 34819 solver.cpp:239] Iteration 1180 (1.78737 iter/s, 5.59482s/10 iters), loss = 10.3702
I0522 22:03:29.897308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3702 (* 1 = 10.3702 loss)
I0522 22:03:29.965684 34819 sgd_solver.cpp:112] Iteration 1180, lr = 0.01
I0522 22:03:35.607226 34819 solver.cpp:239] Iteration 1190 (1.75141 iter/s, 5.70968s/10 iters), loss = 10.6615
I0522 22:03:35.607271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6615 (* 1 = 10.6615 loss)
I0522 22:03:35.680711 34819 sgd_solver.cpp:112] Iteration 1190, lr = 0.01
I0522 22:03:41.851804 34819 solver.cpp:239] Iteration 1200 (1.60147 iter/s, 6.24427s/10 iters), loss = 10.9912
I0522 22:03:41.851853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.9912 (* 1 = 10.9912 loss)
I0522 22:03:41.913056 34819 sgd_solver.cpp:112] Iteration 1200, lr = 0.01
I0522 22:03:46.423533 34819 solver.cpp:239] Iteration 1210 (2.18747 iter/s, 4.5715s/10 iters), loss = 10.3675
I0522 22:03:46.423578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3675 (* 1 = 10.3675 loss)
I0522 22:03:46.484050 34819 sgd_solver.cpp:112] Iteration 1210, lr = 0.01
I0522 22:03:50.299659 34819 solver.cpp:239] Iteration 1220 (2.58003 iter/s, 3.87592s/10 iters), loss = 10.6363
I0522 22:03:50.299885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6363 (* 1 = 10.6363 loss)
I0522 22:03:50.363077 34819 sgd_solver.cpp:112] Iteration 1220, lr = 0.01
I0522 22:03:53.695979 34819 solver.cpp:239] Iteration 1230 (2.94466 iter/s, 3.39597s/10 iters), loss = 10.5804
I0522 22:03:53.696023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5804 (* 1 = 10.5804 loss)
I0522 22:03:53.766800 34819 sgd_solver.cpp:112] Iteration 1230, lr = 0.01
I0522 22:03:59.297116 34819 solver.cpp:239] Iteration 1240 (1.78544 iter/s, 5.60087s/10 iters), loss = 10.742
I0522 22:03:59.297171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.742 (* 1 = 10.742 loss)
I0522 22:03:59.532212 34819 sgd_solver.cpp:112] Iteration 1240, lr = 0.01
I0522 22:04:04.216612 34819 solver.cpp:239] Iteration 1250 (2.03283 iter/s, 4.91924s/10 iters), loss = 10.3055
I0522 22:04:04.216666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3055 (* 1 = 10.3055 loss)
I0522 22:04:05.019980 34819 sgd_solver.cpp:112] Iteration 1250, lr = 0.01
I0522 22:04:09.722000 34819 solver.cpp:239] Iteration 1260 (1.8165 iter/s, 5.5051s/10 iters), loss = 10.886
I0522 22:04:09.722080 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.886 (* 1 = 10.886 loss)
I0522 22:04:09.785428 34819 sgd_solver.cpp:112] Iteration 1260, lr = 0.01
I0522 22:04:14.733557 34819 solver.cpp:239] Iteration 1270 (1.9955 iter/s, 5.01128s/10 iters), loss = 10.6104
I0522 22:04:14.733608 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6104 (* 1 = 10.6104 loss)
I0522 22:04:14.802410 34819 sgd_solver.cpp:112] Iteration 1270, lr = 0.01
I0522 22:04:20.178458 34819 solver.cpp:239] Iteration 1280 (1.83667 iter/s, 5.44463s/10 iters), loss = 9.98616
I0522 22:04:20.178504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.98616 (* 1 = 9.98616 loss)
I0522 22:04:20.950400 34819 sgd_solver.cpp:112] Iteration 1280, lr = 0.01
I0522 22:04:26.611603 34819 solver.cpp:239] Iteration 1290 (1.55453 iter/s, 6.43281s/10 iters), loss = 10.6179
I0522 22:04:26.611701 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6179 (* 1 = 10.6179 loss)
I0522 22:04:27.458753 34819 sgd_solver.cpp:112] Iteration 1290, lr = 0.01
I0522 22:04:31.674274 34819 solver.cpp:239] Iteration 1300 (1.97536 iter/s, 5.06237s/10 iters), loss = 10.4857
I0522 22:04:31.674319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4857 (* 1 = 10.4857 loss)
I0522 22:04:31.745283 34819 sgd_solver.cpp:112] Iteration 1300, lr = 0.01
I0522 22:04:36.657879 34819 solver.cpp:239] Iteration 1310 (2.00668 iter/s, 4.98336s/10 iters), loss = 10.287
I0522 22:04:36.657920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.287 (* 1 = 10.287 loss)
I0522 22:04:37.487046 34819 sgd_solver.cpp:112] Iteration 1310, lr = 0.01
I0522 22:04:42.159811 34819 solver.cpp:239] Iteration 1320 (1.81763 iter/s, 5.50166s/10 iters), loss = 10.3202
I0522 22:04:42.159857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3202 (* 1 = 10.3202 loss)
I0522 22:04:42.229341 34819 sgd_solver.cpp:112] Iteration 1320, lr = 0.01
I0522 22:04:48.593504 34819 solver.cpp:239] Iteration 1330 (1.55439 iter/s, 6.43338s/10 iters), loss = 10.7637
I0522 22:04:48.593551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7637 (* 1 = 10.7637 loss)
I0522 22:04:48.670460 34819 sgd_solver.cpp:112] Iteration 1330, lr = 0.01
I0522 22:04:52.403157 34819 solver.cpp:239] Iteration 1340 (2.62505 iter/s, 3.80945s/10 iters), loss = 10.3234
I0522 22:04:52.403283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3234 (* 1 = 10.3234 loss)
I0522 22:04:52.473337 34819 sgd_solver.cpp:112] Iteration 1340, lr = 0.01
I0522 22:04:56.966123 34819 solver.cpp:239] Iteration 1350 (2.19171 iter/s, 4.56264s/10 iters), loss = 10.2762
I0522 22:04:56.966168 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2762 (* 1 = 10.2762 loss)
I0522 22:04:57.028126 34819 sgd_solver.cpp:112] Iteration 1350, lr = 0.01
I0522 22:05:02.438463 34819 solver.cpp:239] Iteration 1360 (1.82746 iter/s, 5.47207s/10 iters), loss = 9.84572
I0522 22:05:02.438505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84572 (* 1 = 9.84572 loss)
I0522 22:05:03.268492 34819 sgd_solver.cpp:112] Iteration 1360, lr = 0.01
I0522 22:05:07.188661 34819 solver.cpp:239] Iteration 1370 (2.10528 iter/s, 4.74996s/10 iters), loss = 10.3447
I0522 22:05:07.188710 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3447 (* 1 = 10.3447 loss)
I0522 22:05:07.261400 34819 sgd_solver.cpp:112] Iteration 1370, lr = 0.01
I0522 22:05:11.116578 34819 solver.cpp:239] Iteration 1380 (2.54602 iter/s, 3.92771s/10 iters), loss = 10.6436
I0522 22:05:11.116621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6436 (* 1 = 10.6436 loss)
I0522 22:05:11.196996 34819 sgd_solver.cpp:112] Iteration 1380, lr = 0.01
I0522 22:05:15.840102 34819 solver.cpp:239] Iteration 1390 (2.11717 iter/s, 4.72329s/10 iters), loss = 10.2303
I0522 22:05:15.840148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2303 (* 1 = 10.2303 loss)
I0522 22:05:15.902771 34819 sgd_solver.cpp:112] Iteration 1390, lr = 0.01
I0522 22:05:23.021646 34819 solver.cpp:239] Iteration 1400 (1.39252 iter/s, 7.1812s/10 iters), loss = 10.5117
I0522 22:05:23.021917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5117 (* 1 = 10.5117 loss)
I0522 22:05:23.090001 34819 sgd_solver.cpp:112] Iteration 1400, lr = 0.01
I0522 22:05:28.125936 34819 solver.cpp:239] Iteration 1410 (1.95931 iter/s, 5.10383s/10 iters), loss = 10.4011
I0522 22:05:28.125990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4011 (* 1 = 10.4011 loss)
I0522 22:05:28.982311 34819 sgd_solver.cpp:112] Iteration 1410, lr = 0.01
I0522 22:05:33.254844 34819 solver.cpp:239] Iteration 1420 (1.94983 iter/s, 5.12864s/10 iters), loss = 10.2969
I0522 22:05:33.254891 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2969 (* 1 = 10.2969 loss)
I0522 22:05:33.325122 34819 sgd_solver.cpp:112] Iteration 1420, lr = 0.01
I0522 22:05:36.865942 34819 solver.cpp:239] Iteration 1430 (2.76942 iter/s, 3.61087s/10 iters), loss = 10.2446
I0522 22:05:36.866008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2446 (* 1 = 10.2446 loss)
I0522 22:05:37.725232 34819 sgd_solver.cpp:112] Iteration 1430, lr = 0.01
I0522 22:05:41.870962 34819 solver.cpp:239] Iteration 1440 (1.9981 iter/s, 5.00475s/10 iters), loss = 10.5391
I0522 22:05:41.871011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5391 (* 1 = 10.5391 loss)
I0522 22:05:42.707916 34819 sgd_solver.cpp:112] Iteration 1440, lr = 0.01
I0522 22:05:45.754833 34819 solver.cpp:239] Iteration 1450 (2.57489 iter/s, 3.88366s/10 iters), loss = 11.08
I0522 22:05:45.754889 34819 solver.cpp:258]     Train net output #0: softmax_loss = 11.08 (* 1 = 11.08 loss)
I0522 22:05:45.828963 34819 sgd_solver.cpp:112] Iteration 1450, lr = 0.01
I0522 22:05:49.161497 34819 solver.cpp:239] Iteration 1460 (2.93559 iter/s, 3.40647s/10 iters), loss = 10.1284
I0522 22:05:49.161540 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1284 (* 1 = 10.1284 loss)
I0522 22:05:49.227180 34819 sgd_solver.cpp:112] Iteration 1460, lr = 0.01
I0522 22:05:53.329486 34819 solver.cpp:239] Iteration 1470 (2.39936 iter/s, 4.16777s/10 iters), loss = 10.3141
I0522 22:05:53.329690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3141 (* 1 = 10.3141 loss)
I0522 22:05:54.131250 34819 sgd_solver.cpp:112] Iteration 1470, lr = 0.01
I0522 22:05:57.540361 34819 solver.cpp:239] Iteration 1480 (2.375 iter/s, 4.21052s/10 iters), loss = 10.1065
I0522 22:05:57.540423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1065 (* 1 = 10.1065 loss)
I0522 22:05:58.186329 34819 sgd_solver.cpp:112] Iteration 1480, lr = 0.01
I0522 22:06:01.571734 34819 solver.cpp:239] Iteration 1490 (2.48069 iter/s, 4.03113s/10 iters), loss = 10.4959
I0522 22:06:01.571801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4959 (* 1 = 10.4959 loss)
I0522 22:06:01.648939 34819 sgd_solver.cpp:112] Iteration 1490, lr = 0.01
I0522 22:06:06.727861 34819 solver.cpp:239] Iteration 1500 (1.93954 iter/s, 5.15585s/10 iters), loss = 10.1038
I0522 22:06:06.727913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1038 (* 1 = 10.1038 loss)
I0522 22:06:07.580101 34819 sgd_solver.cpp:112] Iteration 1500, lr = 0.01
I0522 22:06:11.689146 34819 solver.cpp:239] Iteration 1510 (2.01571 iter/s, 4.96103s/10 iters), loss = 10.7373
I0522 22:06:11.689198 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.7373 (* 1 = 10.7373 loss)
I0522 22:06:11.759431 34819 sgd_solver.cpp:112] Iteration 1510, lr = 0.01
I0522 22:06:15.717823 34819 solver.cpp:239] Iteration 1520 (2.48234 iter/s, 4.02846s/10 iters), loss = 10.1977
I0522 22:06:15.717880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1977 (* 1 = 10.1977 loss)
I0522 22:06:15.793622 34819 sgd_solver.cpp:112] Iteration 1520, lr = 0.01
I0522 22:06:20.623939 34819 solver.cpp:239] Iteration 1530 (2.03838 iter/s, 4.90586s/10 iters), loss = 10.5656
I0522 22:06:20.624003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5656 (* 1 = 10.5656 loss)
I0522 22:06:20.691740 34819 sgd_solver.cpp:112] Iteration 1530, lr = 0.01
I0522 22:06:26.369730 34819 solver.cpp:239] Iteration 1540 (1.74049 iter/s, 5.7455s/10 iters), loss = 10.4961
I0522 22:06:26.369904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4961 (* 1 = 10.4961 loss)
I0522 22:06:27.077508 34819 sgd_solver.cpp:112] Iteration 1540, lr = 0.01
I0522 22:06:30.466790 34819 solver.cpp:239] Iteration 1550 (2.44098 iter/s, 4.09671s/10 iters), loss = 10.0726
I0522 22:06:30.466852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0726 (* 1 = 10.0726 loss)
I0522 22:06:30.544577 34819 sgd_solver.cpp:112] Iteration 1550, lr = 0.01
I0522 22:06:34.587251 34819 solver.cpp:239] Iteration 1560 (2.42704 iter/s, 4.12024s/10 iters), loss = 10.3954
I0522 22:06:34.587301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3954 (* 1 = 10.3954 loss)
I0522 22:06:34.645624 34819 sgd_solver.cpp:112] Iteration 1560, lr = 0.01
I0522 22:06:39.174000 34819 solver.cpp:239] Iteration 1570 (2.18031 iter/s, 4.58651s/10 iters), loss = 10.4523
I0522 22:06:39.174059 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4523 (* 1 = 10.4523 loss)
I0522 22:06:39.263401 34819 sgd_solver.cpp:112] Iteration 1570, lr = 0.01
I0522 22:06:44.137135 34819 solver.cpp:239] Iteration 1580 (2.01497 iter/s, 4.96286s/10 iters), loss = 9.96742
I0522 22:06:44.137184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.96742 (* 1 = 9.96742 loss)
I0522 22:06:44.668270 34819 sgd_solver.cpp:112] Iteration 1580, lr = 0.01
I0522 22:06:47.706684 34819 solver.cpp:239] Iteration 1590 (2.80165 iter/s, 3.56932s/10 iters), loss = 10.5671
I0522 22:06:47.706756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5671 (* 1 = 10.5671 loss)
I0522 22:06:47.780902 34819 sgd_solver.cpp:112] Iteration 1590, lr = 0.01
I0522 22:06:51.013442 34819 solver.cpp:239] Iteration 1600 (3.0243 iter/s, 3.30655s/10 iters), loss = 10.6171
I0522 22:06:51.013491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6171 (* 1 = 10.6171 loss)
I0522 22:06:51.076139 34819 sgd_solver.cpp:112] Iteration 1600, lr = 0.01
I0522 22:06:54.680286 34819 solver.cpp:239] Iteration 1610 (2.72729 iter/s, 3.66664s/10 iters), loss = 10.2269
I0522 22:06:54.680335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2269 (* 1 = 10.2269 loss)
I0522 22:06:55.454926 34819 sgd_solver.cpp:112] Iteration 1610, lr = 0.01
I0522 22:06:57.984504 34819 solver.cpp:239] Iteration 1620 (3.02661 iter/s, 3.30403s/10 iters), loss = 10.1303
I0522 22:06:57.984666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1303 (* 1 = 10.1303 loss)
I0522 22:06:58.047982 34819 sgd_solver.cpp:112] Iteration 1620, lr = 0.01
I0522 22:07:04.336097 34819 solver.cpp:239] Iteration 1630 (1.57451 iter/s, 6.35117s/10 iters), loss = 10.2456
I0522 22:07:04.336158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2456 (* 1 = 10.2456 loss)
I0522 22:07:04.405905 34819 sgd_solver.cpp:112] Iteration 1630, lr = 0.01
I0522 22:07:11.836814 34819 solver.cpp:239] Iteration 1640 (1.33327 iter/s, 7.50036s/10 iters), loss = 9.90248
I0522 22:07:11.836858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.90248 (* 1 = 9.90248 loss)
I0522 22:07:11.908843 34819 sgd_solver.cpp:112] Iteration 1640, lr = 0.01
I0522 22:07:15.224005 34819 solver.cpp:239] Iteration 1650 (2.95246 iter/s, 3.38701s/10 iters), loss = 10.1213
I0522 22:07:15.224046 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1213 (* 1 = 10.1213 loss)
I0522 22:07:16.100433 34819 sgd_solver.cpp:112] Iteration 1650, lr = 0.01
I0522 22:07:23.241016 34819 solver.cpp:239] Iteration 1660 (1.2474 iter/s, 8.01665s/10 iters), loss = 10.2649
I0522 22:07:23.241070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2649 (* 1 = 10.2649 loss)
I0522 22:07:23.933708 34819 sgd_solver.cpp:112] Iteration 1660, lr = 0.01
I0522 22:07:28.852383 34819 solver.cpp:239] Iteration 1670 (1.78219 iter/s, 5.61108s/10 iters), loss = 10.2743
I0522 22:07:28.852583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2743 (* 1 = 10.2743 loss)
I0522 22:07:29.403373 34819 sgd_solver.cpp:112] Iteration 1670, lr = 0.01
I0522 22:07:34.529368 34819 solver.cpp:239] Iteration 1680 (1.76163 iter/s, 5.67656s/10 iters), loss = 10.2271
I0522 22:07:34.529418 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2271 (* 1 = 10.2271 loss)
I0522 22:07:35.310891 34819 sgd_solver.cpp:112] Iteration 1680, lr = 0.01
I0522 22:07:39.459642 34819 solver.cpp:239] Iteration 1690 (2.02839 iter/s, 4.93002s/10 iters), loss = 10.4922
I0522 22:07:39.459694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4922 (* 1 = 10.4922 loss)
I0522 22:07:39.530678 34819 sgd_solver.cpp:112] Iteration 1690, lr = 0.01
I0522 22:07:43.991300 34819 solver.cpp:239] Iteration 1700 (2.20681 iter/s, 4.53142s/10 iters), loss = 10.2318
I0522 22:07:43.991343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2318 (* 1 = 10.2318 loss)
I0522 22:07:44.062469 34819 sgd_solver.cpp:112] Iteration 1700, lr = 0.01
I0522 22:07:49.929860 34819 solver.cpp:239] Iteration 1710 (1.68399 iter/s, 5.93827s/10 iters), loss = 10.3748
I0522 22:07:49.929906 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3748 (* 1 = 10.3748 loss)
I0522 22:07:50.742210 34819 sgd_solver.cpp:112] Iteration 1710, lr = 0.01
I0522 22:07:54.819862 34819 solver.cpp:239] Iteration 1720 (2.04509 iter/s, 4.88975s/10 iters), loss = 10.3845
I0522 22:07:54.819907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3845 (* 1 = 10.3845 loss)
I0522 22:07:54.891131 34819 sgd_solver.cpp:112] Iteration 1720, lr = 0.01
I0522 22:07:58.303095 34819 solver.cpp:239] Iteration 1730 (2.87106 iter/s, 3.48304s/10 iters), loss = 10.1309
I0522 22:07:58.303140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1309 (* 1 = 10.1309 loss)
I0522 22:07:58.363030 34819 sgd_solver.cpp:112] Iteration 1730, lr = 0.01
I0522 22:08:03.913761 34819 solver.cpp:239] Iteration 1740 (1.78241 iter/s, 5.61039s/10 iters), loss = 10.1544
I0522 22:08:03.913967 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1544 (* 1 = 10.1544 loss)
I0522 22:08:04.697122 34819 sgd_solver.cpp:112] Iteration 1740, lr = 0.01
I0522 22:08:09.659135 34819 solver.cpp:239] Iteration 1750 (1.74066 iter/s, 5.74496s/10 iters), loss = 10.1082
I0522 22:08:09.659183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1082 (* 1 = 10.1082 loss)
I0522 22:08:10.483781 34819 sgd_solver.cpp:112] Iteration 1750, lr = 0.01
I0522 22:08:16.957255 34819 solver.cpp:239] Iteration 1760 (1.37028 iter/s, 7.29778s/10 iters), loss = 10.1994
I0522 22:08:16.957299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1994 (* 1 = 10.1994 loss)
I0522 22:08:17.816203 34819 sgd_solver.cpp:112] Iteration 1760, lr = 0.01
I0522 22:08:23.475582 34819 solver.cpp:239] Iteration 1770 (1.53421 iter/s, 6.51802s/10 iters), loss = 10.5278
I0522 22:08:23.475630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5278 (* 1 = 10.5278 loss)
I0522 22:08:23.530256 34819 sgd_solver.cpp:112] Iteration 1770, lr = 0.01
I0522 22:08:27.655884 34819 solver.cpp:239] Iteration 1780 (2.3923 iter/s, 4.18008s/10 iters), loss = 10.4736
I0522 22:08:27.655936 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4736 (* 1 = 10.4736 loss)
I0522 22:08:27.768323 34819 sgd_solver.cpp:112] Iteration 1780, lr = 0.01
I0522 22:08:33.893831 34819 solver.cpp:239] Iteration 1790 (1.60317 iter/s, 6.23762s/10 iters), loss = 10.2175
I0522 22:08:33.893919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2175 (* 1 = 10.2175 loss)
I0522 22:08:34.676980 34819 sgd_solver.cpp:112] Iteration 1790, lr = 0.01
I0522 22:08:40.743021 34819 solver.cpp:239] Iteration 1800 (1.4601 iter/s, 6.84882s/10 iters), loss = 10.0651
I0522 22:08:40.743083 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0651 (* 1 = 10.0651 loss)
I0522 22:08:41.583376 34819 sgd_solver.cpp:112] Iteration 1800, lr = 0.01
I0522 22:08:46.307991 34819 solver.cpp:239] Iteration 1810 (1.79705 iter/s, 5.56468s/10 iters), loss = 10.2427
I0522 22:08:46.308046 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2427 (* 1 = 10.2427 loss)
I0522 22:08:46.376957 34819 sgd_solver.cpp:112] Iteration 1810, lr = 0.01
I0522 22:08:49.585227 34819 solver.cpp:239] Iteration 1820 (3.05153 iter/s, 3.27704s/10 iters), loss = 10.2652
I0522 22:08:49.585278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2652 (* 1 = 10.2652 loss)
I0522 22:08:49.642609 34819 sgd_solver.cpp:112] Iteration 1820, lr = 0.01
I0522 22:08:53.769634 34819 solver.cpp:239] Iteration 1830 (2.38996 iter/s, 4.18417s/10 iters), loss = 10.1615
I0522 22:08:53.769685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1615 (* 1 = 10.1615 loss)
I0522 22:08:54.528290 34819 sgd_solver.cpp:112] Iteration 1830, lr = 0.01
I0522 22:08:59.967391 34819 solver.cpp:239] Iteration 1840 (1.61357 iter/s, 6.19743s/10 iters), loss = 10.1829
I0522 22:08:59.967427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1829 (* 1 = 10.1829 loss)
I0522 22:09:00.037326 34819 sgd_solver.cpp:112] Iteration 1840, lr = 0.01
I0522 22:09:04.244771 34819 solver.cpp:239] Iteration 1850 (2.338 iter/s, 4.27716s/10 iters), loss = 10.1771
I0522 22:09:04.244817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1771 (* 1 = 10.1771 loss)
I0522 22:09:04.313261 34819 sgd_solver.cpp:112] Iteration 1850, lr = 0.01
I0522 22:09:09.075227 34819 solver.cpp:239] Iteration 1860 (2.0703 iter/s, 4.83021s/10 iters), loss = 10.0295
I0522 22:09:09.075448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0295 (* 1 = 10.0295 loss)
I0522 22:09:09.937206 34819 sgd_solver.cpp:112] Iteration 1860, lr = 0.01
I0522 22:09:15.477790 34819 solver.cpp:239] Iteration 1870 (1.56198 iter/s, 6.40211s/10 iters), loss = 9.79399
I0522 22:09:15.477828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.79399 (* 1 = 9.79399 loss)
I0522 22:09:16.098867 34819 sgd_solver.cpp:112] Iteration 1870, lr = 0.01
I0522 22:09:20.958608 34819 solver.cpp:239] Iteration 1880 (1.82463 iter/s, 5.48055s/10 iters), loss = 10.1364
I0522 22:09:20.958668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1364 (* 1 = 10.1364 loss)
I0522 22:09:21.742329 34819 sgd_solver.cpp:112] Iteration 1880, lr = 0.01
I0522 22:09:27.868664 34819 solver.cpp:239] Iteration 1890 (1.44724 iter/s, 6.90972s/10 iters), loss = 10.3908
I0522 22:09:27.868723 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3908 (* 1 = 10.3908 loss)
I0522 22:09:27.937304 34819 sgd_solver.cpp:112] Iteration 1890, lr = 0.01
I0522 22:09:32.880185 34819 solver.cpp:239] Iteration 1900 (1.99551 iter/s, 5.01125s/10 iters), loss = 10.0144
I0522 22:09:32.880237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0144 (* 1 = 10.0144 loss)
I0522 22:09:32.937099 34819 sgd_solver.cpp:112] Iteration 1900, lr = 0.01
I0522 22:09:37.819634 34819 solver.cpp:239] Iteration 1910 (2.02462 iter/s, 4.9392s/10 iters), loss = 10.1425
I0522 22:09:37.819675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1425 (* 1 = 10.1425 loss)
I0522 22:09:38.302824 34819 sgd_solver.cpp:112] Iteration 1910, lr = 0.01
I0522 22:09:43.354941 34819 solver.cpp:239] Iteration 1920 (1.80667 iter/s, 5.53505s/10 iters), loss = 10.1512
I0522 22:09:43.355245 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1512 (* 1 = 10.1512 loss)
I0522 22:09:44.031214 34819 sgd_solver.cpp:112] Iteration 1920, lr = 0.01
I0522 22:09:48.809264 34819 solver.cpp:239] Iteration 1930 (1.83358 iter/s, 5.45382s/10 iters), loss = 9.93235
I0522 22:09:48.809319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93235 (* 1 = 9.93235 loss)
I0522 22:09:48.869562 34819 sgd_solver.cpp:112] Iteration 1930, lr = 0.01
I0522 22:09:52.264850 34819 solver.cpp:239] Iteration 1940 (2.89403 iter/s, 3.45539s/10 iters), loss = 9.93844
I0522 22:09:52.264895 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93844 (* 1 = 9.93844 loss)
I0522 22:09:52.316687 34819 sgd_solver.cpp:112] Iteration 1940, lr = 0.01
I0522 22:09:55.675598 34819 solver.cpp:239] Iteration 1950 (2.93207 iter/s, 3.41056s/10 iters), loss = 10.1791
I0522 22:09:55.675649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1791 (* 1 = 10.1791 loss)
I0522 22:09:56.503589 34819 sgd_solver.cpp:112] Iteration 1950, lr = 0.01
I0522 22:10:02.629262 34819 solver.cpp:239] Iteration 1960 (1.43816 iter/s, 6.95333s/10 iters), loss = 10.0454
I0522 22:10:02.629317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0454 (* 1 = 10.0454 loss)
I0522 22:10:02.691715 34819 sgd_solver.cpp:112] Iteration 1960, lr = 0.01
I0522 22:10:06.865723 34819 solver.cpp:239] Iteration 1970 (2.36059 iter/s, 4.23623s/10 iters), loss = 10.2991
I0522 22:10:06.865769 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2991 (* 1 = 10.2991 loss)
I0522 22:10:06.928421 34819 sgd_solver.cpp:112] Iteration 1970, lr = 0.01
I0522 22:10:11.181628 34819 solver.cpp:239] Iteration 1980 (2.31713 iter/s, 4.31569s/10 iters), loss = 10.0863
I0522 22:10:11.181679 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0863 (* 1 = 10.0863 loss)
I0522 22:10:11.253583 34819 sgd_solver.cpp:112] Iteration 1980, lr = 0.01
I0522 22:10:16.203999 34819 solver.cpp:239] Iteration 1990 (1.99119 iter/s, 5.02211s/10 iters), loss = 10.6048
I0522 22:10:16.204257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.6048 (* 1 = 10.6048 loss)
I0522 22:10:17.057904 34819 sgd_solver.cpp:112] Iteration 1990, lr = 0.01
I0522 22:10:22.141407 34819 solver.cpp:239] Iteration 2000 (1.68437 iter/s, 5.93693s/10 iters), loss = 9.97246
I0522 22:10:22.141456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.97246 (* 1 = 9.97246 loss)
I0522 22:10:22.217648 34819 sgd_solver.cpp:112] Iteration 2000, lr = 0.01
I0522 22:10:27.980926 34819 solver.cpp:239] Iteration 2010 (1.71256 iter/s, 5.83922s/10 iters), loss = 9.93047
I0522 22:10:27.980975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93047 (* 1 = 9.93047 loss)
I0522 22:10:28.759670 34819 sgd_solver.cpp:112] Iteration 2010, lr = 0.01
I0522 22:10:32.724325 34819 solver.cpp:239] Iteration 2020 (2.1083 iter/s, 4.74315s/10 iters), loss = 9.97523
I0522 22:10:32.724380 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.97523 (* 1 = 9.97523 loss)
I0522 22:10:33.520300 34819 sgd_solver.cpp:112] Iteration 2020, lr = 0.01
I0522 22:10:39.114212 34819 solver.cpp:239] Iteration 2030 (1.56505 iter/s, 6.38958s/10 iters), loss = 9.80524
I0522 22:10:39.114257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.80524 (* 1 = 9.80524 loss)
I0522 22:10:39.939574 34819 sgd_solver.cpp:112] Iteration 2030, lr = 0.01
I0522 22:10:45.005764 34819 solver.cpp:239] Iteration 2040 (1.69743 iter/s, 5.89127s/10 iters), loss = 10.3885
I0522 22:10:45.005806 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3885 (* 1 = 10.3885 loss)
I0522 22:10:45.807808 34819 sgd_solver.cpp:112] Iteration 2040, lr = 0.01
I0522 22:10:50.578894 34819 solver.cpp:239] Iteration 2050 (1.79441 iter/s, 5.57287s/10 iters), loss = 10.0246
I0522 22:10:50.579176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0246 (* 1 = 10.0246 loss)
I0522 22:10:51.333705 34819 sgd_solver.cpp:112] Iteration 2050, lr = 0.01
I0522 22:10:56.176874 34819 solver.cpp:239] Iteration 2060 (1.78651 iter/s, 5.5975s/10 iters), loss = 10.2619
I0522 22:10:56.176920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2619 (* 1 = 10.2619 loss)
I0522 22:10:56.260162 34819 sgd_solver.cpp:112] Iteration 2060, lr = 0.01
I0522 22:11:00.237650 34819 solver.cpp:239] Iteration 2070 (2.46272 iter/s, 4.06056s/10 iters), loss = 9.90296
I0522 22:11:00.237705 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.90296 (* 1 = 9.90296 loss)
I0522 22:11:00.301723 34819 sgd_solver.cpp:112] Iteration 2070, lr = 0.01
I0522 22:11:04.305723 34819 solver.cpp:239] Iteration 2080 (2.4583 iter/s, 4.06785s/10 iters), loss = 10.0764
I0522 22:11:04.305775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0764 (* 1 = 10.0764 loss)
I0522 22:11:04.363948 34819 sgd_solver.cpp:112] Iteration 2080, lr = 0.01
I0522 22:11:08.567662 34819 solver.cpp:239] Iteration 2090 (2.34648 iter/s, 4.26171s/10 iters), loss = 10.08
I0522 22:11:08.567713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.08 (* 1 = 10.08 loss)
I0522 22:11:08.631965 34819 sgd_solver.cpp:112] Iteration 2090, lr = 0.01
I0522 22:11:13.914430 34819 solver.cpp:239] Iteration 2100 (1.87039 iter/s, 5.34649s/10 iters), loss = 10.059
I0522 22:11:13.914486 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.059 (* 1 = 10.059 loss)
I0522 22:11:14.451045 34819 sgd_solver.cpp:112] Iteration 2100, lr = 0.01
I0522 22:11:17.686379 34819 solver.cpp:239] Iteration 2110 (2.65131 iter/s, 3.77172s/10 iters), loss = 9.93832
I0522 22:11:17.686431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93832 (* 1 = 9.93832 loss)
I0522 22:11:18.392570 34819 sgd_solver.cpp:112] Iteration 2110, lr = 0.01
I0522 22:11:22.879254 34819 solver.cpp:239] Iteration 2120 (1.92581 iter/s, 5.19262s/10 iters), loss = 9.88844
I0522 22:11:22.879374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.88844 (* 1 = 9.88844 loss)
I0522 22:11:22.949657 34819 sgd_solver.cpp:112] Iteration 2120, lr = 0.01
I0522 22:11:26.276608 34819 solver.cpp:239] Iteration 2130 (2.94369 iter/s, 3.3971s/10 iters), loss = 10.439
I0522 22:11:26.276654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.439 (* 1 = 10.439 loss)
I0522 22:11:27.067989 34819 sgd_solver.cpp:112] Iteration 2130, lr = 0.01
I0522 22:11:32.470016 34819 solver.cpp:239] Iteration 2140 (1.6147 iter/s, 6.19311s/10 iters), loss = 10.0962
I0522 22:11:32.470062 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0962 (* 1 = 10.0962 loss)
I0522 22:11:33.288117 34819 sgd_solver.cpp:112] Iteration 2140, lr = 0.01
I0522 22:11:36.934443 34819 solver.cpp:239] Iteration 2150 (2.24005 iter/s, 4.46419s/10 iters), loss = 9.97539
I0522 22:11:36.934497 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.97539 (* 1 = 9.97539 loss)
I0522 22:11:37.777730 34819 sgd_solver.cpp:112] Iteration 2150, lr = 0.01
I0522 22:11:43.740593 34819 solver.cpp:239] Iteration 2160 (1.46933 iter/s, 6.80581s/10 iters), loss = 10.1358
I0522 22:11:43.740658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1358 (* 1 = 10.1358 loss)
I0522 22:11:44.581760 34819 sgd_solver.cpp:112] Iteration 2160, lr = 0.01
I0522 22:11:47.428376 34819 solver.cpp:239] Iteration 2170 (2.71181 iter/s, 3.68757s/10 iters), loss = 9.69635
I0522 22:11:47.428419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.69635 (* 1 = 9.69635 loss)
I0522 22:11:47.505460 34819 sgd_solver.cpp:112] Iteration 2170, lr = 0.01
I0522 22:11:52.938009 34819 solver.cpp:239] Iteration 2180 (1.81509 iter/s, 5.50936s/10 iters), loss = 10.0809
I0522 22:11:52.938192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0809 (* 1 = 10.0809 loss)
I0522 22:11:53.009583 34819 sgd_solver.cpp:112] Iteration 2180, lr = 0.01
I0522 22:11:58.283793 34819 solver.cpp:239] Iteration 2190 (1.87077 iter/s, 5.34539s/10 iters), loss = 9.93767
I0522 22:11:58.283860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93767 (* 1 = 9.93767 loss)
I0522 22:11:58.356122 34819 sgd_solver.cpp:112] Iteration 2190, lr = 0.01
I0522 22:12:02.954740 34819 solver.cpp:239] Iteration 2200 (2.14101 iter/s, 4.67069s/10 iters), loss = 9.91597
I0522 22:12:02.954792 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.91597 (* 1 = 9.91597 loss)
I0522 22:12:03.017781 34819 sgd_solver.cpp:112] Iteration 2200, lr = 0.01
I0522 22:12:06.812953 34819 solver.cpp:239] Iteration 2210 (2.59202 iter/s, 3.858s/10 iters), loss = 10.2195
I0522 22:12:06.813005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2195 (* 1 = 10.2195 loss)
I0522 22:12:06.868610 34819 sgd_solver.cpp:112] Iteration 2210, lr = 0.01
I0522 22:12:11.864327 34819 solver.cpp:239] Iteration 2220 (1.97976 iter/s, 5.05111s/10 iters), loss = 10.2971
I0522 22:12:11.864388 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2971 (* 1 = 10.2971 loss)
I0522 22:12:12.750607 34819 sgd_solver.cpp:112] Iteration 2220, lr = 0.01
I0522 22:12:19.805959 34819 solver.cpp:239] Iteration 2230 (1.25925 iter/s, 7.94124s/10 iters), loss = 9.65972
I0522 22:12:19.806013 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65972 (* 1 = 9.65972 loss)
I0522 22:12:20.630980 34819 sgd_solver.cpp:112] Iteration 2230, lr = 0.01
I0522 22:12:27.919360 34819 solver.cpp:239] Iteration 2240 (1.23259 iter/s, 8.11302s/10 iters), loss = 9.84949
I0522 22:12:27.919692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84949 (* 1 = 9.84949 loss)
I0522 22:12:28.740286 34819 sgd_solver.cpp:112] Iteration 2240, lr = 0.01
I0522 22:12:32.670920 34819 solver.cpp:239] Iteration 2250 (2.10479 iter/s, 4.75106s/10 iters), loss = 10.2815
I0522 22:12:32.670976 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2815 (* 1 = 10.2815 loss)
I0522 22:12:32.739929 34819 sgd_solver.cpp:112] Iteration 2250, lr = 0.01
I0522 22:12:35.958055 34819 solver.cpp:239] Iteration 2260 (3.04234 iter/s, 3.28695s/10 iters), loss = 10.1397
I0522 22:12:35.958101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1397 (* 1 = 10.1397 loss)
I0522 22:12:36.801084 34819 sgd_solver.cpp:112] Iteration 2260, lr = 0.01
I0522 22:12:40.827513 34819 solver.cpp:239] Iteration 2270 (2.05372 iter/s, 4.86921s/10 iters), loss = 9.90529
I0522 22:12:40.827569 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.90529 (* 1 = 9.90529 loss)
I0522 22:12:41.622864 34819 sgd_solver.cpp:112] Iteration 2270, lr = 0.01
I0522 22:12:47.911444 34819 solver.cpp:239] Iteration 2280 (1.41171 iter/s, 7.08359s/10 iters), loss = 9.80695
I0522 22:12:47.911504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.80695 (* 1 = 9.80695 loss)
I0522 22:12:48.654985 34819 sgd_solver.cpp:112] Iteration 2280, lr = 0.01
I0522 22:12:53.182446 34819 solver.cpp:239] Iteration 2290 (1.89727 iter/s, 5.27073s/10 iters), loss = 10.2393
I0522 22:12:53.182485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2393 (* 1 = 10.2393 loss)
I0522 22:12:53.244359 34819 sgd_solver.cpp:112] Iteration 2290, lr = 0.01
I0522 22:12:57.401218 34819 solver.cpp:239] Iteration 2300 (2.37048 iter/s, 4.21855s/10 iters), loss = 10.0776
I0522 22:12:57.401271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0776 (* 1 = 10.0776 loss)
I0522 22:12:57.472546 34819 sgd_solver.cpp:112] Iteration 2300, lr = 0.01
I0522 22:13:02.423260 34819 solver.cpp:239] Iteration 2310 (1.99132 iter/s, 5.02178s/10 iters), loss = 9.8893
I0522 22:13:02.423504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.8893 (* 1 = 9.8893 loss)
I0522 22:13:03.094424 34819 sgd_solver.cpp:112] Iteration 2310, lr = 0.01
I0522 22:13:07.200403 34819 solver.cpp:239] Iteration 2320 (2.09348 iter/s, 4.77673s/10 iters), loss = 10.1219
I0522 22:13:07.200450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1219 (* 1 = 10.1219 loss)
I0522 22:13:08.033058 34819 sgd_solver.cpp:112] Iteration 2320, lr = 0.01
I0522 22:13:13.039335 34819 solver.cpp:239] Iteration 2330 (1.71273 iter/s, 5.83865s/10 iters), loss = 9.71115
I0522 22:13:13.039389 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71115 (* 1 = 9.71115 loss)
I0522 22:13:13.112203 34819 sgd_solver.cpp:112] Iteration 2330, lr = 0.01
I0522 22:13:17.890149 34819 solver.cpp:239] Iteration 2340 (2.06162 iter/s, 4.85056s/10 iters), loss = 9.99403
I0522 22:13:17.890192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.99403 (* 1 = 9.99403 loss)
I0522 22:13:17.960144 34819 sgd_solver.cpp:112] Iteration 2340, lr = 0.01
I0522 22:13:23.634192 34819 solver.cpp:239] Iteration 2350 (1.74102 iter/s, 5.74376s/10 iters), loss = 10.0383
I0522 22:13:23.634249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0383 (* 1 = 10.0383 loss)
I0522 22:13:24.452172 34819 sgd_solver.cpp:112] Iteration 2350, lr = 0.01
I0522 22:13:30.382357 34819 solver.cpp:239] Iteration 2360 (1.48196 iter/s, 6.74784s/10 iters), loss = 9.83521
I0522 22:13:30.382405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.83521 (* 1 = 9.83521 loss)
I0522 22:13:31.134511 34819 sgd_solver.cpp:112] Iteration 2360, lr = 0.01
I0522 22:13:35.928081 34819 solver.cpp:239] Iteration 2370 (1.80328 iter/s, 5.54545s/10 iters), loss = 10.4019
I0522 22:13:35.928308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4019 (* 1 = 10.4019 loss)
I0522 22:13:35.987802 34819 sgd_solver.cpp:112] Iteration 2370, lr = 0.01
I0522 22:13:40.144512 34819 solver.cpp:239] Iteration 2380 (2.37189 iter/s, 4.21605s/10 iters), loss = 9.92072
I0522 22:13:40.144565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.92072 (* 1 = 9.92072 loss)
I0522 22:13:40.786794 34819 sgd_solver.cpp:112] Iteration 2380, lr = 0.01
I0522 22:13:44.965358 34819 solver.cpp:239] Iteration 2390 (2.07443 iter/s, 4.8206s/10 iters), loss = 9.94682
I0522 22:13:44.965400 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.94682 (* 1 = 9.94682 loss)
I0522 22:13:45.226752 34819 sgd_solver.cpp:112] Iteration 2390, lr = 0.01
I0522 22:13:50.123049 34819 solver.cpp:239] Iteration 2400 (1.93896 iter/s, 5.15741s/10 iters), loss = 10.0475
I0522 22:13:50.123105 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0475 (* 1 = 10.0475 loss)
I0522 22:13:50.195453 34819 sgd_solver.cpp:112] Iteration 2400, lr = 0.01
I0522 22:13:55.041311 34819 solver.cpp:239] Iteration 2410 (2.03334 iter/s, 4.91801s/10 iters), loss = 10.2914
I0522 22:13:55.041359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2914 (* 1 = 10.2914 loss)
I0522 22:13:55.841114 34819 sgd_solver.cpp:112] Iteration 2410, lr = 0.01
I0522 22:14:00.091768 34819 solver.cpp:239] Iteration 2420 (1.98012 iter/s, 5.0502s/10 iters), loss = 9.72482
I0522 22:14:00.091812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72482 (* 1 = 9.72482 loss)
I0522 22:14:00.153012 34819 sgd_solver.cpp:112] Iteration 2420, lr = 0.01
I0522 22:14:03.974056 34819 solver.cpp:239] Iteration 2430 (2.57593 iter/s, 3.88209s/10 iters), loss = 10.0683
I0522 22:14:03.974098 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0683 (* 1 = 10.0683 loss)
I0522 22:14:04.032624 34819 sgd_solver.cpp:112] Iteration 2430, lr = 0.01
I0522 22:14:07.350813 34819 solver.cpp:239] Iteration 2440 (2.96159 iter/s, 3.37657s/10 iters), loss = 10.0122
I0522 22:14:07.351044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0122 (* 1 = 10.0122 loss)
I0522 22:14:08.106250 34819 sgd_solver.cpp:112] Iteration 2440, lr = 0.01
I0522 22:14:13.550194 34819 solver.cpp:239] Iteration 2450 (1.61319 iter/s, 6.1989s/10 iters), loss = 10.344
I0522 22:14:13.550256 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.344 (* 1 = 10.344 loss)
I0522 22:14:14.329478 34819 sgd_solver.cpp:112] Iteration 2450, lr = 0.01
I0522 22:14:19.256927 34819 solver.cpp:239] Iteration 2460 (1.75241 iter/s, 5.70643s/10 iters), loss = 9.45885
I0522 22:14:19.256968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45885 (* 1 = 9.45885 loss)
I0522 22:14:20.086782 34819 sgd_solver.cpp:112] Iteration 2460, lr = 0.01
I0522 22:14:25.466006 34819 solver.cpp:239] Iteration 2470 (1.61062 iter/s, 6.20879s/10 iters), loss = 10.1811
I0522 22:14:25.466049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1811 (* 1 = 10.1811 loss)
I0522 22:14:26.131860 34819 sgd_solver.cpp:112] Iteration 2470, lr = 0.01
I0522 22:14:30.520130 34819 solver.cpp:239] Iteration 2480 (1.97868 iter/s, 5.05387s/10 iters), loss = 9.67871
I0522 22:14:30.520179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67871 (* 1 = 9.67871 loss)
I0522 22:14:30.588418 34819 sgd_solver.cpp:112] Iteration 2480, lr = 0.01
I0522 22:14:35.272270 34819 solver.cpp:239] Iteration 2490 (2.10442 iter/s, 4.7519s/10 iters), loss = 9.99701
I0522 22:14:35.272312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.99701 (* 1 = 9.99701 loss)
I0522 22:14:36.076867 34819 sgd_solver.cpp:112] Iteration 2490, lr = 0.01
I0522 22:14:40.807162 34819 solver.cpp:239] Iteration 2500 (1.80681 iter/s, 5.53462s/10 iters), loss = 9.76122
I0522 22:14:40.807428 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.76122 (* 1 = 9.76122 loss)
I0522 22:14:40.886219 34819 sgd_solver.cpp:112] Iteration 2500, lr = 0.01
I0522 22:14:46.822376 34819 solver.cpp:239] Iteration 2510 (1.66258 iter/s, 6.01473s/10 iters), loss = 9.73829
I0522 22:14:46.822430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.73829 (* 1 = 9.73829 loss)
I0522 22:14:46.892165 34819 sgd_solver.cpp:112] Iteration 2510, lr = 0.01
I0522 22:14:49.998014 34819 solver.cpp:239] Iteration 2520 (3.14919 iter/s, 3.17542s/10 iters), loss = 10.28
I0522 22:14:49.998090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.28 (* 1 = 10.28 loss)
I0522 22:14:50.574465 34819 sgd_solver.cpp:112] Iteration 2520, lr = 0.01
I0522 22:14:55.410017 34819 solver.cpp:239] Iteration 2530 (1.84784 iter/s, 5.41171s/10 iters), loss = 9.98317
I0522 22:14:55.410060 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.98317 (* 1 = 9.98317 loss)
I0522 22:14:56.237699 34819 sgd_solver.cpp:112] Iteration 2530, lr = 0.01
I0522 22:15:00.412398 34819 solver.cpp:239] Iteration 2540 (1.99915 iter/s, 5.00213s/10 iters), loss = 9.88274
I0522 22:15:00.412443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.88274 (* 1 = 9.88274 loss)
I0522 22:15:01.154749 34819 sgd_solver.cpp:112] Iteration 2540, lr = 0.01
I0522 22:15:06.908133 34819 solver.cpp:239] Iteration 2550 (1.53954 iter/s, 6.49543s/10 iters), loss = 10.1667
I0522 22:15:06.908176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1667 (* 1 = 10.1667 loss)
I0522 22:15:07.609516 34819 sgd_solver.cpp:112] Iteration 2550, lr = 0.01
I0522 22:15:12.514498 34819 solver.cpp:239] Iteration 2560 (1.78378 iter/s, 5.60609s/10 iters), loss = 10.1886
I0522 22:15:12.514757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1886 (* 1 = 10.1886 loss)
I0522 22:15:13.353705 34819 sgd_solver.cpp:112] Iteration 2560, lr = 0.01
I0522 22:15:18.582237 34819 solver.cpp:239] Iteration 2570 (1.64819 iter/s, 6.06725s/10 iters), loss = 9.59267
I0522 22:15:18.582280 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.59267 (* 1 = 9.59267 loss)
I0522 22:15:18.654103 34819 sgd_solver.cpp:112] Iteration 2570, lr = 0.01
I0522 22:15:23.285984 34819 solver.cpp:239] Iteration 2580 (2.12607 iter/s, 4.70351s/10 iters), loss = 9.86582
I0522 22:15:23.286023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.86582 (* 1 = 9.86582 loss)
I0522 22:15:23.894222 34819 sgd_solver.cpp:112] Iteration 2580, lr = 0.01
I0522 22:15:28.783280 34819 solver.cpp:239] Iteration 2590 (1.81916 iter/s, 5.49703s/10 iters), loss = 9.64398
I0522 22:15:28.783323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64398 (* 1 = 9.64398 loss)
I0522 22:15:29.599989 34819 sgd_solver.cpp:112] Iteration 2590, lr = 0.01
I0522 22:15:33.884901 34819 solver.cpp:239] Iteration 2600 (1.96026 iter/s, 5.10136s/10 iters), loss = 9.6437
I0522 22:15:33.884954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6437 (* 1 = 9.6437 loss)
I0522 22:15:33.957110 34819 sgd_solver.cpp:112] Iteration 2600, lr = 0.01
I0522 22:15:38.258338 34819 solver.cpp:239] Iteration 2610 (2.28665 iter/s, 4.3732s/10 iters), loss = 9.0306
I0522 22:15:38.258381 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0306 (* 1 = 9.0306 loss)
I0522 22:15:38.885048 34819 sgd_solver.cpp:112] Iteration 2610, lr = 0.01
I0522 22:15:41.492491 34819 solver.cpp:239] Iteration 2620 (3.09217 iter/s, 3.23397s/10 iters), loss = 9.97493
I0522 22:15:41.492534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.97493 (* 1 = 9.97493 loss)
I0522 22:15:41.560992 34819 sgd_solver.cpp:112] Iteration 2620, lr = 0.01
I0522 22:15:45.963840 34819 solver.cpp:239] Iteration 2630 (2.23658 iter/s, 4.47112s/10 iters), loss = 9.66184
I0522 22:15:45.964116 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.66184 (* 1 = 9.66184 loss)
I0522 22:15:46.037016 34819 sgd_solver.cpp:112] Iteration 2630, lr = 0.01
I0522 22:15:50.060457 34819 solver.cpp:239] Iteration 2640 (2.44128 iter/s, 4.0962s/10 iters), loss = 9.44505
I0522 22:15:50.060511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44505 (* 1 = 9.44505 loss)
I0522 22:15:50.821532 34819 sgd_solver.cpp:112] Iteration 2640, lr = 0.01
I0522 22:15:54.465826 34819 solver.cpp:239] Iteration 2650 (2.27008 iter/s, 4.40513s/10 iters), loss = 9.72696
I0522 22:15:54.465879 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72696 (* 1 = 9.72696 loss)
I0522 22:15:54.532609 34819 sgd_solver.cpp:112] Iteration 2650, lr = 0.01
I0522 22:15:57.898452 34819 solver.cpp:239] Iteration 2660 (2.9134 iter/s, 3.43242s/10 iters), loss = 9.878
I0522 22:15:57.898516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.878 (* 1 = 9.878 loss)
I0522 22:15:58.271301 34819 sgd_solver.cpp:112] Iteration 2660, lr = 0.01
I0522 22:16:03.884213 34819 solver.cpp:239] Iteration 2670 (1.67072 iter/s, 5.98545s/10 iters), loss = 9.97554
I0522 22:16:03.884271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.97554 (* 1 = 9.97554 loss)
I0522 22:16:04.680127 34819 sgd_solver.cpp:112] Iteration 2670, lr = 0.01
I0522 22:16:09.412832 34819 solver.cpp:239] Iteration 2680 (1.80886 iter/s, 5.52834s/10 iters), loss = 9.72284
I0522 22:16:09.412874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72284 (* 1 = 9.72284 loss)
I0522 22:16:10.224025 34819 sgd_solver.cpp:112] Iteration 2680, lr = 0.01
I0522 22:16:13.939680 34819 solver.cpp:239] Iteration 2690 (2.20915 iter/s, 4.52662s/10 iters), loss = 9.7119
I0522 22:16:13.939725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.7119 (* 1 = 9.7119 loss)
I0522 22:16:13.998677 34819 sgd_solver.cpp:112] Iteration 2690, lr = 0.01
I0522 22:16:17.712131 34819 solver.cpp:239] Iteration 2700 (2.65095 iter/s, 3.77224s/10 iters), loss = 9.50023
I0522 22:16:17.712293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50023 (* 1 = 9.50023 loss)
I0522 22:16:17.776502 34819 sgd_solver.cpp:112] Iteration 2700, lr = 0.01
I0522 22:16:21.995353 34819 solver.cpp:239] Iteration 2710 (2.33487 iter/s, 4.28289s/10 iters), loss = 9.57012
I0522 22:16:21.995406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57012 (* 1 = 9.57012 loss)
I0522 22:16:22.055279 34819 sgd_solver.cpp:112] Iteration 2710, lr = 0.01
I0522 22:16:27.004195 34819 solver.cpp:239] Iteration 2720 (1.99657 iter/s, 5.00859s/10 iters), loss = 9.46074
I0522 22:16:27.004240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46074 (* 1 = 9.46074 loss)
I0522 22:16:27.065527 34819 sgd_solver.cpp:112] Iteration 2720, lr = 0.01
I0522 22:16:31.190798 34819 solver.cpp:239] Iteration 2730 (2.3887 iter/s, 4.18638s/10 iters), loss = 9.34154
I0522 22:16:31.190843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34154 (* 1 = 9.34154 loss)
I0522 22:16:31.269851 34819 sgd_solver.cpp:112] Iteration 2730, lr = 0.01
I0522 22:16:35.269448 34819 solver.cpp:239] Iteration 2740 (2.45192 iter/s, 4.07844s/10 iters), loss = 9.67731
I0522 22:16:35.269490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67731 (* 1 = 9.67731 loss)
I0522 22:16:35.344655 34819 sgd_solver.cpp:112] Iteration 2740, lr = 0.01
I0522 22:16:38.909616 34819 solver.cpp:239] Iteration 2750 (2.74728 iter/s, 3.63997s/10 iters), loss = 9.92521
I0522 22:16:38.909660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.92521 (* 1 = 9.92521 loss)
I0522 22:16:38.983988 34819 sgd_solver.cpp:112] Iteration 2750, lr = 0.01
I0522 22:16:44.311084 34819 solver.cpp:239] Iteration 2760 (1.85144 iter/s, 5.4012s/10 iters), loss = 10.3078
I0522 22:16:44.311132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3078 (* 1 = 10.3078 loss)
I0522 22:16:44.372404 34819 sgd_solver.cpp:112] Iteration 2760, lr = 0.01
I0522 22:16:47.527174 34819 solver.cpp:239] Iteration 2770 (3.10955 iter/s, 3.2159s/10 iters), loss = 9.89864
I0522 22:16:47.527230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.89864 (* 1 = 9.89864 loss)
I0522 22:16:48.386436 34819 sgd_solver.cpp:112] Iteration 2770, lr = 0.01
I0522 22:16:53.980023 34819 solver.cpp:239] Iteration 2780 (1.54978 iter/s, 6.45253s/10 iters), loss = 9.9005
I0522 22:16:53.980067 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.9005 (* 1 = 9.9005 loss)
I0522 22:16:54.054217 34819 sgd_solver.cpp:112] Iteration 2780, lr = 0.01
I0522 22:17:00.355532 34819 solver.cpp:239] Iteration 2790 (1.56858 iter/s, 6.37521s/10 iters), loss = 9.99992
I0522 22:17:00.355581 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.99992 (* 1 = 9.99992 loss)
I0522 22:17:01.108186 34819 sgd_solver.cpp:112] Iteration 2790, lr = 0.01
I0522 22:17:05.350594 34819 solver.cpp:239] Iteration 2800 (2.00208 iter/s, 4.9948s/10 iters), loss = 9.60215
I0522 22:17:05.350661 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60215 (* 1 = 9.60215 loss)
I0522 22:17:05.402537 34819 sgd_solver.cpp:112] Iteration 2800, lr = 0.01
I0522 22:17:08.769248 34819 solver.cpp:239] Iteration 2810 (2.9253 iter/s, 3.41845s/10 iters), loss = 9.94278
I0522 22:17:08.769294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.94278 (* 1 = 9.94278 loss)
I0522 22:17:09.395159 34819 sgd_solver.cpp:112] Iteration 2810, lr = 0.01
I0522 22:17:13.350764 34819 solver.cpp:239] Iteration 2820 (2.1828 iter/s, 4.58128s/10 iters), loss = 9.04512
I0522 22:17:13.350811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04512 (* 1 = 9.04512 loss)
I0522 22:17:13.407163 34819 sgd_solver.cpp:112] Iteration 2820, lr = 0.01
I0522 22:17:18.035639 34819 solver.cpp:239] Iteration 2830 (2.13464 iter/s, 4.68463s/10 iters), loss = 9.3138
I0522 22:17:18.035706 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3138 (* 1 = 9.3138 loss)
I0522 22:17:18.243734 34819 sgd_solver.cpp:112] Iteration 2830, lr = 0.01
I0522 22:17:23.075686 34819 solver.cpp:239] Iteration 2840 (1.98422 iter/s, 5.03977s/10 iters), loss = 9.51855
I0522 22:17:23.075857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51855 (* 1 = 9.51855 loss)
I0522 22:17:23.138613 34819 sgd_solver.cpp:112] Iteration 2840, lr = 0.01
I0522 22:17:27.375713 34819 solver.cpp:239] Iteration 2850 (2.32575 iter/s, 4.29968s/10 iters), loss = 10.0247
I0522 22:17:27.375762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0247 (* 1 = 10.0247 loss)
I0522 22:17:28.152889 34819 sgd_solver.cpp:112] Iteration 2850, lr = 0.01
I0522 22:17:34.154515 34819 solver.cpp:239] Iteration 2860 (1.47526 iter/s, 6.77848s/10 iters), loss = 9.8809
I0522 22:17:34.154556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.8809 (* 1 = 9.8809 loss)
I0522 22:17:34.217645 34819 sgd_solver.cpp:112] Iteration 2860, lr = 0.01
I0522 22:17:39.470382 34819 solver.cpp:239] Iteration 2870 (1.88125 iter/s, 5.31561s/10 iters), loss = 9.89082
I0522 22:17:39.470443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.89082 (* 1 = 9.89082 loss)
I0522 22:17:39.535477 34819 sgd_solver.cpp:112] Iteration 2870, lr = 0.01
I0522 22:17:45.415316 34819 solver.cpp:239] Iteration 2880 (1.68219 iter/s, 5.94462s/10 iters), loss = 9.17776
I0522 22:17:45.415364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17776 (* 1 = 9.17776 loss)
I0522 22:17:46.313819 34819 sgd_solver.cpp:112] Iteration 2880, lr = 0.01
I0522 22:17:48.957342 34819 solver.cpp:239] Iteration 2890 (2.82341 iter/s, 3.54182s/10 iters), loss = 9.74376
I0522 22:17:48.957404 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74376 (* 1 = 9.74376 loss)
I0522 22:17:49.767737 34819 sgd_solver.cpp:112] Iteration 2890, lr = 0.01
I0522 22:17:53.802027 34819 solver.cpp:239] Iteration 2900 (2.06423 iter/s, 4.84443s/10 iters), loss = 9.99004
I0522 22:17:53.802165 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.99004 (* 1 = 9.99004 loss)
I0522 22:17:53.862987 34819 sgd_solver.cpp:112] Iteration 2900, lr = 0.01
I0522 22:17:58.019394 34819 solver.cpp:239] Iteration 2910 (2.37132 iter/s, 4.21706s/10 iters), loss = 9.71321
I0522 22:17:58.019450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71321 (* 1 = 9.71321 loss)
I0522 22:17:58.332160 34819 sgd_solver.cpp:112] Iteration 2910, lr = 0.01
I0522 22:18:03.350980 34819 solver.cpp:239] Iteration 2920 (1.87571 iter/s, 5.33131s/10 iters), loss = 10.0448
I0522 22:18:03.351034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0448 (* 1 = 10.0448 loss)
I0522 22:18:03.429615 34819 sgd_solver.cpp:112] Iteration 2920, lr = 0.01
I0522 22:18:05.934578 34819 solver.cpp:239] Iteration 2930 (3.87081 iter/s, 2.58344s/10 iters), loss = 9.60983
I0522 22:18:05.934629 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60983 (* 1 = 9.60983 loss)
I0522 22:18:06.004310 34819 sgd_solver.cpp:112] Iteration 2930, lr = 0.01
I0522 22:18:11.413455 34819 solver.cpp:239] Iteration 2940 (1.82528 iter/s, 5.4786s/10 iters), loss = 9.34932
I0522 22:18:11.413513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34932 (* 1 = 9.34932 loss)
I0522 22:18:12.252651 34819 sgd_solver.cpp:112] Iteration 2940, lr = 0.01
I0522 22:18:17.842159 34819 solver.cpp:239] Iteration 2950 (1.5556 iter/s, 6.42839s/10 iters), loss = 9.30258
I0522 22:18:17.842202 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30258 (* 1 = 9.30258 loss)
I0522 22:18:18.655182 34819 sgd_solver.cpp:112] Iteration 2950, lr = 0.01
I0522 22:18:23.092586 34819 solver.cpp:239] Iteration 2960 (1.9047 iter/s, 5.25017s/10 iters), loss = 8.9931
I0522 22:18:23.092631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9931 (* 1 = 8.9931 loss)
I0522 22:18:23.165410 34819 sgd_solver.cpp:112] Iteration 2960, lr = 0.01
I0522 22:18:27.347398 34819 solver.cpp:239] Iteration 2970 (2.3504 iter/s, 4.25459s/10 iters), loss = 9.4504
I0522 22:18:27.347501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4504 (* 1 = 9.4504 loss)
I0522 22:18:27.423418 34819 sgd_solver.cpp:112] Iteration 2970, lr = 0.01
I0522 22:18:31.622135 34819 solver.cpp:239] Iteration 2980 (2.33948 iter/s, 4.27446s/10 iters), loss = 9.23099
I0522 22:18:31.622180 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23099 (* 1 = 9.23099 loss)
I0522 22:18:32.431977 34819 sgd_solver.cpp:112] Iteration 2980, lr = 0.01
I0522 22:18:38.412243 34819 solver.cpp:239] Iteration 2990 (1.4728 iter/s, 6.78979s/10 iters), loss = 9.37595
I0522 22:18:38.412291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37595 (* 1 = 9.37595 loss)
I0522 22:18:38.484694 34819 sgd_solver.cpp:112] Iteration 2990, lr = 0.01
I0522 22:18:44.363739 34819 solver.cpp:239] Iteration 3000 (1.68033 iter/s, 5.95121s/10 iters), loss = 9.35815
I0522 22:18:44.363788 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35815 (* 1 = 9.35815 loss)
I0522 22:18:44.422077 34819 sgd_solver.cpp:112] Iteration 3000, lr = 0.01
I0522 22:18:48.415781 34819 solver.cpp:239] Iteration 3010 (2.46803 iter/s, 4.05182s/10 iters), loss = 9.70583
I0522 22:18:48.415820 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70583 (* 1 = 9.70583 loss)
I0522 22:18:48.477879 34819 sgd_solver.cpp:112] Iteration 3010, lr = 0.01
I0522 22:18:51.875977 34819 solver.cpp:239] Iteration 3020 (2.89016 iter/s, 3.46001s/10 iters), loss = 9.1736
I0522 22:18:51.876019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1736 (* 1 = 9.1736 loss)
I0522 22:18:51.938513 34819 sgd_solver.cpp:112] Iteration 3020, lr = 0.01
I0522 22:18:54.467249 34819 solver.cpp:239] Iteration 3030 (3.85936 iter/s, 2.59111s/10 iters), loss = 9.6213
I0522 22:18:54.467304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6213 (* 1 = 9.6213 loss)
I0522 22:18:55.322800 34819 sgd_solver.cpp:112] Iteration 3030, lr = 0.01
I0522 22:19:00.655267 34819 solver.cpp:239] Iteration 3040 (1.61611 iter/s, 6.18769s/10 iters), loss = 9.71315
I0522 22:19:00.655463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71315 (* 1 = 9.71315 loss)
I0522 22:19:00.726698 34819 sgd_solver.cpp:112] Iteration 3040, lr = 0.01
I0522 22:19:06.702163 34819 solver.cpp:239] Iteration 3050 (1.65455 iter/s, 6.04393s/10 iters), loss = 10.2228
I0522 22:19:06.702206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2228 (* 1 = 10.2228 loss)
I0522 22:19:06.758605 34819 sgd_solver.cpp:112] Iteration 3050, lr = 0.01
I0522 22:19:11.653720 34819 solver.cpp:239] Iteration 3060 (2.01967 iter/s, 4.95131s/10 iters), loss = 9.32603
I0522 22:19:11.653764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32603 (* 1 = 9.32603 loss)
I0522 22:19:11.725812 34819 sgd_solver.cpp:112] Iteration 3060, lr = 0.01
I0522 22:19:15.869915 34819 solver.cpp:239] Iteration 3070 (2.37193 iter/s, 4.21597s/10 iters), loss = 9.82604
I0522 22:19:15.869962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.82604 (* 1 = 9.82604 loss)
I0522 22:19:16.604805 34819 sgd_solver.cpp:112] Iteration 3070, lr = 0.01
I0522 22:19:21.247813 34819 solver.cpp:239] Iteration 3080 (1.85955 iter/s, 5.37763s/10 iters), loss = 9.64672
I0522 22:19:21.247855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64672 (* 1 = 9.64672 loss)
I0522 22:19:22.026887 34819 sgd_solver.cpp:112] Iteration 3080, lr = 0.01
I0522 22:19:26.768260 34819 solver.cpp:239] Iteration 3090 (1.81154 iter/s, 5.52018s/10 iters), loss = 9.23242
I0522 22:19:26.768304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23242 (* 1 = 9.23242 loss)
I0522 22:19:27.608140 34819 sgd_solver.cpp:112] Iteration 3090, lr = 0.01
I0522 22:19:32.495527 34819 solver.cpp:239] Iteration 3100 (1.74612 iter/s, 5.72699s/10 iters), loss = 10.0119
I0522 22:19:32.495667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0119 (* 1 = 10.0119 loss)
I0522 22:19:33.116578 34819 sgd_solver.cpp:112] Iteration 3100, lr = 0.01
I0522 22:19:37.207346 34819 solver.cpp:239] Iteration 3110 (2.12247 iter/s, 4.71148s/10 iters), loss = 9.71217
I0522 22:19:37.207396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71217 (* 1 = 9.71217 loss)
I0522 22:19:37.263034 34819 sgd_solver.cpp:112] Iteration 3110, lr = 0.01
I0522 22:19:40.600366 34819 solver.cpp:239] Iteration 3120 (2.94741 iter/s, 3.39281s/10 iters), loss = 9.46984
I0522 22:19:40.600432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46984 (* 1 = 9.46984 loss)
I0522 22:19:40.674955 34819 sgd_solver.cpp:112] Iteration 3120, lr = 0.01
I0522 22:19:46.595829 34819 solver.cpp:239] Iteration 3130 (1.66801 iter/s, 5.99516s/10 iters), loss = 9.94417
I0522 22:19:46.595878 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.94417 (* 1 = 9.94417 loss)
I0522 22:19:47.475584 34819 sgd_solver.cpp:112] Iteration 3130, lr = 0.01
I0522 22:19:50.078275 34819 solver.cpp:239] Iteration 3140 (2.8717 iter/s, 3.48225s/10 iters), loss = 9.54801
I0522 22:19:50.078320 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54801 (* 1 = 9.54801 loss)
I0522 22:19:50.789973 34819 sgd_solver.cpp:112] Iteration 3140, lr = 0.01
I0522 22:19:55.994822 34819 solver.cpp:239] Iteration 3150 (1.69026 iter/s, 5.91625s/10 iters), loss = 9.72227
I0522 22:19:55.994884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72227 (* 1 = 9.72227 loss)
I0522 22:19:56.755123 34819 sgd_solver.cpp:112] Iteration 3150, lr = 0.01
I0522 22:20:00.292045 34819 solver.cpp:239] Iteration 3160 (2.32721 iter/s, 4.29699s/10 iters), loss = 10.4234
I0522 22:20:00.292115 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4234 (* 1 = 10.4234 loss)
I0522 22:20:01.134568 34819 sgd_solver.cpp:112] Iteration 3160, lr = 0.01
I0522 22:20:07.308225 34819 solver.cpp:239] Iteration 3170 (1.42535 iter/s, 7.0158s/10 iters), loss = 9.79592
I0522 22:20:07.308367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.79592 (* 1 = 9.79592 loss)
I0522 22:20:08.171097 34819 sgd_solver.cpp:112] Iteration 3170, lr = 0.01
I0522 22:20:13.796319 34819 solver.cpp:239] Iteration 3180 (1.54138 iter/s, 6.48769s/10 iters), loss = 9.24015
I0522 22:20:13.796363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24015 (* 1 = 9.24015 loss)
I0522 22:20:13.854801 34819 sgd_solver.cpp:112] Iteration 3180, lr = 0.01
I0522 22:20:17.332902 34819 solver.cpp:239] Iteration 3190 (2.82775 iter/s, 3.53638s/10 iters), loss = 9.68167
I0522 22:20:17.332950 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68167 (* 1 = 9.68167 loss)
I0522 22:20:17.391427 34819 sgd_solver.cpp:112] Iteration 3190, lr = 0.01
I0522 22:20:25.628408 34819 solver.cpp:239] Iteration 3200 (1.20553 iter/s, 8.29513s/10 iters), loss = 9.27074
I0522 22:20:25.628450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27074 (* 1 = 9.27074 loss)
I0522 22:20:26.335669 34819 sgd_solver.cpp:112] Iteration 3200, lr = 0.01
I0522 22:20:31.982581 34819 solver.cpp:239] Iteration 3210 (1.57384 iter/s, 6.35387s/10 iters), loss = 9.50826
I0522 22:20:31.982641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50826 (* 1 = 9.50826 loss)
I0522 22:20:32.119999 34819 sgd_solver.cpp:112] Iteration 3210, lr = 0.01
I0522 22:20:35.730454 34819 solver.cpp:239] Iteration 3220 (2.66833 iter/s, 3.74766s/10 iters), loss = 9.81492
I0522 22:20:35.730499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.81492 (* 1 = 9.81492 loss)
I0522 22:20:35.792280 34819 sgd_solver.cpp:112] Iteration 3220, lr = 0.01
I0522 22:20:39.768669 34819 solver.cpp:239] Iteration 3230 (2.47648 iter/s, 4.038s/10 iters), loss = 9.37033
I0522 22:20:39.768880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37033 (* 1 = 9.37033 loss)
I0522 22:20:39.842872 34819 sgd_solver.cpp:112] Iteration 3230, lr = 0.01
I0522 22:20:44.598724 34819 solver.cpp:239] Iteration 3240 (2.07055 iter/s, 4.82965s/10 iters), loss = 8.74004
I0522 22:20:44.598767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74004 (* 1 = 8.74004 loss)
I0522 22:20:44.672932 34819 sgd_solver.cpp:112] Iteration 3240, lr = 0.01
I0522 22:20:49.764250 34819 solver.cpp:239] Iteration 3250 (1.93601 iter/s, 5.16527s/10 iters), loss = 9.62726
I0522 22:20:49.764304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.62726 (* 1 = 9.62726 loss)
I0522 22:20:49.837303 34819 sgd_solver.cpp:112] Iteration 3250, lr = 0.01
I0522 22:20:53.982647 34819 solver.cpp:239] Iteration 3260 (2.37071 iter/s, 4.21815s/10 iters), loss = 9.43015
I0522 22:20:53.982736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43015 (* 1 = 9.43015 loss)
I0522 22:20:54.038668 34819 sgd_solver.cpp:112] Iteration 3260, lr = 0.01
I0522 22:20:57.757220 34819 solver.cpp:239] Iteration 3270 (2.64948 iter/s, 3.77433s/10 iters), loss = 9.53357
I0522 22:20:57.757261 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.53357 (* 1 = 9.53357 loss)
I0522 22:20:58.620378 34819 sgd_solver.cpp:112] Iteration 3270, lr = 0.01
I0522 22:21:03.860221 34819 solver.cpp:239] Iteration 3280 (1.63862 iter/s, 6.10271s/10 iters), loss = 9.49851
I0522 22:21:03.860276 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49851 (* 1 = 9.49851 loss)
I0522 22:21:03.941196 34819 sgd_solver.cpp:112] Iteration 3280, lr = 0.01
I0522 22:21:07.723999 34819 solver.cpp:239] Iteration 3290 (2.58829 iter/s, 3.86356s/10 iters), loss = 9.41648
I0522 22:21:07.724050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41648 (* 1 = 9.41648 loss)
I0522 22:21:08.465653 34819 sgd_solver.cpp:112] Iteration 3290, lr = 0.01
I0522 22:21:12.720371 34819 solver.cpp:239] Iteration 3300 (2.00156 iter/s, 4.99611s/10 iters), loss = 9.63069
I0522 22:21:12.720578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63069 (* 1 = 9.63069 loss)
I0522 22:21:12.776625 34819 sgd_solver.cpp:112] Iteration 3300, lr = 0.01
I0522 22:21:18.486862 34819 solver.cpp:239] Iteration 3310 (1.73429 iter/s, 5.76605s/10 iters), loss = 9.75743
I0522 22:21:18.486918 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75743 (* 1 = 9.75743 loss)
I0522 22:21:18.556668 34819 sgd_solver.cpp:112] Iteration 3310, lr = 0.01
I0522 22:21:21.982975 34819 solver.cpp:239] Iteration 3320 (2.86049 iter/s, 3.49591s/10 iters), loss = 9.63395
I0522 22:21:21.983028 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63395 (* 1 = 9.63395 loss)
I0522 22:21:22.062937 34819 sgd_solver.cpp:112] Iteration 3320, lr = 0.01
I0522 22:21:24.594938 34819 solver.cpp:239] Iteration 3330 (3.82878 iter/s, 2.6118s/10 iters), loss = 9.16003
I0522 22:21:24.594979 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16003 (* 1 = 9.16003 loss)
I0522 22:21:24.657606 34819 sgd_solver.cpp:112] Iteration 3330, lr = 0.01
I0522 22:21:29.635655 34819 solver.cpp:239] Iteration 3340 (1.98395 iter/s, 5.04046s/10 iters), loss = 8.99194
I0522 22:21:29.635713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99194 (* 1 = 8.99194 loss)
I0522 22:21:29.820066 34819 sgd_solver.cpp:112] Iteration 3340, lr = 0.01
I0522 22:21:32.418452 34819 solver.cpp:239] Iteration 3350 (3.59373 iter/s, 2.78262s/10 iters), loss = 9.65249
I0522 22:21:32.418498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65249 (* 1 = 9.65249 loss)
I0522 22:21:33.233129 34819 sgd_solver.cpp:112] Iteration 3350, lr = 0.01
I0522 22:21:39.281821 34819 solver.cpp:239] Iteration 3360 (1.45708 iter/s, 6.86305s/10 iters), loss = 9.57016
I0522 22:21:39.281875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57016 (* 1 = 9.57016 loss)
I0522 22:21:39.348942 34819 sgd_solver.cpp:112] Iteration 3360, lr = 0.01
I0522 22:21:47.109138 34819 solver.cpp:239] Iteration 3370 (1.27764 iter/s, 7.82695s/10 iters), loss = 9.58284
I0522 22:21:47.109391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58284 (* 1 = 9.58284 loss)
I0522 22:21:47.184001 34819 sgd_solver.cpp:112] Iteration 3370, lr = 0.01
I0522 22:21:52.264672 34819 solver.cpp:239] Iteration 3380 (1.93983 iter/s, 5.1551s/10 iters), loss = 8.95147
I0522 22:21:52.264725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95147 (* 1 = 8.95147 loss)
I0522 22:21:53.083822 34819 sgd_solver.cpp:112] Iteration 3380, lr = 0.01
I0522 22:21:57.475570 34819 solver.cpp:239] Iteration 3390 (1.91916 iter/s, 5.2106s/10 iters), loss = 8.93115
I0522 22:21:57.475633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93115 (* 1 = 8.93115 loss)
I0522 22:21:58.236431 34819 sgd_solver.cpp:112] Iteration 3390, lr = 0.01
I0522 22:22:03.060261 34819 solver.cpp:239] Iteration 3400 (1.79071 iter/s, 5.58437s/10 iters), loss = 9.063
I0522 22:22:03.060318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.063 (* 1 = 9.063 loss)
I0522 22:22:03.853121 34819 sgd_solver.cpp:112] Iteration 3400, lr = 0.01
I0522 22:22:08.645665 34819 solver.cpp:239] Iteration 3410 (1.79047 iter/s, 5.58512s/10 iters), loss = 9.36557
I0522 22:22:08.645709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36557 (* 1 = 9.36557 loss)
I0522 22:22:09.515661 34819 sgd_solver.cpp:112] Iteration 3410, lr = 0.01
I0522 22:22:13.544507 34819 solver.cpp:239] Iteration 3420 (2.0414 iter/s, 4.8986s/10 iters), loss = 9.337
I0522 22:22:13.544567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.337 (* 1 = 9.337 loss)
I0522 22:22:13.607836 34819 sgd_solver.cpp:112] Iteration 3420, lr = 0.01
I0522 22:22:17.897763 34819 solver.cpp:239] Iteration 3430 (2.29726 iter/s, 4.35302s/10 iters), loss = 9.75022
I0522 22:22:17.897992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75022 (* 1 = 9.75022 loss)
I0522 22:22:17.958148 34819 sgd_solver.cpp:112] Iteration 3430, lr = 0.01
I0522 22:22:23.304450 34819 solver.cpp:239] Iteration 3440 (1.84971 iter/s, 5.40624s/10 iters), loss = 9.09967
I0522 22:22:23.304505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09967 (* 1 = 9.09967 loss)
I0522 22:22:23.369549 34819 sgd_solver.cpp:112] Iteration 3440, lr = 0.01
I0522 22:22:27.581185 34819 solver.cpp:239] Iteration 3450 (2.33836 iter/s, 4.2765s/10 iters), loss = 8.48855
I0522 22:22:27.581239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48855 (* 1 = 8.48855 loss)
I0522 22:22:28.027408 34819 sgd_solver.cpp:112] Iteration 3450, lr = 0.01
I0522 22:22:33.947424 34819 solver.cpp:239] Iteration 3460 (1.57086 iter/s, 6.36593s/10 iters), loss = 8.86671
I0522 22:22:33.947468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86671 (* 1 = 8.86671 loss)
I0522 22:22:34.021931 34819 sgd_solver.cpp:112] Iteration 3460, lr = 0.01
I0522 22:22:39.573863 34819 solver.cpp:239] Iteration 3470 (1.77741 iter/s, 5.62616s/10 iters), loss = 9.16212
I0522 22:22:39.573906 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16212 (* 1 = 9.16212 loss)
I0522 22:22:39.637962 34819 sgd_solver.cpp:112] Iteration 3470, lr = 0.01
I0522 22:22:44.610975 34819 solver.cpp:239] Iteration 3480 (1.98536 iter/s, 5.03686s/10 iters), loss = 9.49539
I0522 22:22:44.611026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49539 (* 1 = 9.49539 loss)
I0522 22:22:44.991092 34819 sgd_solver.cpp:112] Iteration 3480, lr = 0.01
I0522 22:22:48.356922 34819 solver.cpp:239] Iteration 3490 (2.6697 iter/s, 3.74574s/10 iters), loss = 8.95919
I0522 22:22:48.357156 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95919 (* 1 = 8.95919 loss)
I0522 22:22:49.152467 34819 sgd_solver.cpp:112] Iteration 3490, lr = 0.01
I0522 22:22:53.393549 34819 solver.cpp:239] Iteration 3500 (1.98562 iter/s, 5.03621s/10 iters), loss = 8.92988
I0522 22:22:53.393604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92988 (* 1 = 8.92988 loss)
I0522 22:22:54.256801 34819 sgd_solver.cpp:112] Iteration 3500, lr = 0.01
I0522 22:22:59.813917 34819 solver.cpp:239] Iteration 3510 (1.55762 iter/s, 6.42006s/10 iters), loss = 9.57024
I0522 22:22:59.813961 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57024 (* 1 = 9.57024 loss)
I0522 22:23:00.625174 34819 sgd_solver.cpp:112] Iteration 3510, lr = 0.01
I0522 22:23:06.222640 34819 solver.cpp:239] Iteration 3520 (1.56045 iter/s, 6.40842s/10 iters), loss = 9.63578
I0522 22:23:06.222685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63578 (* 1 = 9.63578 loss)
I0522 22:23:06.488648 34819 sgd_solver.cpp:112] Iteration 3520, lr = 0.01
I0522 22:23:08.841343 34819 solver.cpp:239] Iteration 3530 (3.81892 iter/s, 2.61854s/10 iters), loss = 9.57519
I0522 22:23:08.841383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57519 (* 1 = 9.57519 loss)
I0522 22:23:08.898650 34819 sgd_solver.cpp:112] Iteration 3530, lr = 0.01
I0522 22:23:12.932380 34819 solver.cpp:239] Iteration 3540 (2.44449 iter/s, 4.09083s/10 iters), loss = 9.26718
I0522 22:23:12.932423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26718 (* 1 = 9.26718 loss)
I0522 22:23:13.533205 34819 sgd_solver.cpp:112] Iteration 3540, lr = 0.01
I0522 22:23:18.992519 34819 solver.cpp:239] Iteration 3550 (1.65021 iter/s, 6.05985s/10 iters), loss = 9.72202
I0522 22:23:18.992653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72202 (* 1 = 9.72202 loss)
I0522 22:23:19.045305 34819 sgd_solver.cpp:112] Iteration 3550, lr = 0.01
I0522 22:23:22.463120 34819 solver.cpp:239] Iteration 3560 (2.88158 iter/s, 3.47032s/10 iters), loss = 8.45166
I0522 22:23:22.463171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45166 (* 1 = 8.45166 loss)
I0522 22:23:22.525804 34819 sgd_solver.cpp:112] Iteration 3560, lr = 0.01
I0522 22:23:26.038486 34819 solver.cpp:239] Iteration 3570 (2.79708 iter/s, 3.57516s/10 iters), loss = 9.19246
I0522 22:23:26.038527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19246 (* 1 = 9.19246 loss)
I0522 22:23:26.101130 34819 sgd_solver.cpp:112] Iteration 3570, lr = 0.01
I0522 22:23:29.386957 34819 solver.cpp:239] Iteration 3580 (2.9866 iter/s, 3.34829s/10 iters), loss = 8.73826
I0522 22:23:29.386999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73826 (* 1 = 8.73826 loss)
I0522 22:23:29.448345 34819 sgd_solver.cpp:112] Iteration 3580, lr = 0.01
I0522 22:23:34.728066 34819 solver.cpp:239] Iteration 3590 (1.87236 iter/s, 5.34085s/10 iters), loss = 9.64382
I0522 22:23:34.728109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64382 (* 1 = 9.64382 loss)
I0522 22:23:34.790742 34819 sgd_solver.cpp:112] Iteration 3590, lr = 0.01
I0522 22:23:41.138631 34819 solver.cpp:239] Iteration 3600 (1.56 iter/s, 6.41027s/10 iters), loss = 9.38538
I0522 22:23:41.138677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38538 (* 1 = 9.38538 loss)
I0522 22:23:41.211473 34819 sgd_solver.cpp:112] Iteration 3600, lr = 0.01
I0522 22:23:46.541492 34819 solver.cpp:239] Iteration 3610 (1.85096 iter/s, 5.40259s/10 iters), loss = 8.99959
I0522 22:23:46.541539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99959 (* 1 = 8.99959 loss)
I0522 22:23:46.614378 34819 sgd_solver.cpp:112] Iteration 3610, lr = 0.01
I0522 22:23:50.979005 34819 solver.cpp:239] Iteration 3620 (2.25364 iter/s, 4.43727s/10 iters), loss = 9.46181
I0522 22:23:50.979234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46181 (* 1 = 9.46181 loss)
I0522 22:23:51.745129 34819 sgd_solver.cpp:112] Iteration 3620, lr = 0.01
I0522 22:23:55.834776 34819 solver.cpp:239] Iteration 3630 (2.05959 iter/s, 4.85534s/10 iters), loss = 9.91393
I0522 22:23:55.834836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.91393 (* 1 = 9.91393 loss)
I0522 22:23:56.227943 34819 sgd_solver.cpp:112] Iteration 3630, lr = 0.01
I0522 22:23:59.460117 34819 solver.cpp:239] Iteration 3640 (2.75852 iter/s, 3.62513s/10 iters), loss = 8.78782
I0522 22:23:59.460171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78782 (* 1 = 8.78782 loss)
I0522 22:23:59.529456 34819 sgd_solver.cpp:112] Iteration 3640, lr = 0.01
I0522 22:24:03.533026 34819 solver.cpp:239] Iteration 3650 (2.45538 iter/s, 4.07269s/10 iters), loss = 9.56595
I0522 22:24:03.533071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56595 (* 1 = 9.56595 loss)
I0522 22:24:04.385484 34819 sgd_solver.cpp:112] Iteration 3650, lr = 0.01
I0522 22:24:11.222159 34819 solver.cpp:239] Iteration 3660 (1.3006 iter/s, 7.68878s/10 iters), loss = 8.94025
I0522 22:24:11.222203 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94025 (* 1 = 8.94025 loss)
I0522 22:24:11.285526 34819 sgd_solver.cpp:112] Iteration 3660, lr = 0.01
I0522 22:24:16.952231 34819 solver.cpp:239] Iteration 3670 (1.74526 iter/s, 5.72979s/10 iters), loss = 9.38942
I0522 22:24:16.952288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38942 (* 1 = 9.38942 loss)
I0522 22:24:17.020027 34819 sgd_solver.cpp:112] Iteration 3670, lr = 0.01
I0522 22:24:21.748970 34819 solver.cpp:239] Iteration 3680 (2.08486 iter/s, 4.79649s/10 iters), loss = 9.57226
I0522 22:24:21.749117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57226 (* 1 = 9.57226 loss)
I0522 22:24:21.808706 34819 sgd_solver.cpp:112] Iteration 3680, lr = 0.01
I0522 22:24:25.823107 34819 solver.cpp:239] Iteration 3690 (2.4547 iter/s, 4.07383s/10 iters), loss = 8.40317
I0522 22:24:25.823153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40317 (* 1 = 8.40317 loss)
I0522 22:24:25.873239 34819 sgd_solver.cpp:112] Iteration 3690, lr = 0.01
I0522 22:24:31.045292 34819 solver.cpp:239] Iteration 3700 (1.91501 iter/s, 5.22191s/10 iters), loss = 9.26534
I0522 22:24:31.045357 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26534 (* 1 = 9.26534 loss)
I0522 22:24:31.881945 34819 sgd_solver.cpp:112] Iteration 3700, lr = 0.01
I0522 22:24:36.002180 34819 solver.cpp:239] Iteration 3710 (2.0175 iter/s, 4.95662s/10 iters), loss = 8.67794
I0522 22:24:36.002238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67794 (* 1 = 8.67794 loss)
I0522 22:24:36.078644 34819 sgd_solver.cpp:112] Iteration 3710, lr = 0.01
I0522 22:24:41.725049 34819 solver.cpp:239] Iteration 3720 (1.74746 iter/s, 5.72258s/10 iters), loss = 9.22414
I0522 22:24:41.725091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22414 (* 1 = 9.22414 loss)
I0522 22:24:41.782757 34819 sgd_solver.cpp:112] Iteration 3720, lr = 0.01
I0522 22:24:45.971318 34819 solver.cpp:239] Iteration 3730 (2.35514 iter/s, 4.24604s/10 iters), loss = 9.64831
I0522 22:24:45.971384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64831 (* 1 = 9.64831 loss)
I0522 22:24:46.802940 34819 sgd_solver.cpp:112] Iteration 3730, lr = 0.01
I0522 22:24:49.483530 34819 solver.cpp:239] Iteration 3740 (2.84739 iter/s, 3.51199s/10 iters), loss = 9.30605
I0522 22:24:49.483583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30605 (* 1 = 9.30605 loss)
I0522 22:24:49.591435 34819 sgd_solver.cpp:112] Iteration 3740, lr = 0.01
I0522 22:24:54.046001 34819 solver.cpp:239] Iteration 3750 (2.19191 iter/s, 4.56223s/10 iters), loss = 9.56368
I0522 22:24:54.046209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56368 (* 1 = 9.56368 loss)
I0522 22:24:54.839212 34819 sgd_solver.cpp:112] Iteration 3750, lr = 0.01
I0522 22:24:58.997563 34819 solver.cpp:239] Iteration 3760 (2.01973 iter/s, 4.95117s/10 iters), loss = 9.32059
I0522 22:24:58.997622 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32059 (* 1 = 9.32059 loss)
I0522 22:24:59.875965 34819 sgd_solver.cpp:112] Iteration 3760, lr = 0.01
I0522 22:25:05.618760 34819 solver.cpp:239] Iteration 3770 (1.51039 iter/s, 6.62082s/10 iters), loss = 9.03252
I0522 22:25:05.618824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03252 (* 1 = 9.03252 loss)
I0522 22:25:06.508215 34819 sgd_solver.cpp:112] Iteration 3770, lr = 0.01
I0522 22:25:11.507372 34819 solver.cpp:239] Iteration 3780 (1.69828 iter/s, 5.88831s/10 iters), loss = 8.89169
I0522 22:25:11.507426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89169 (* 1 = 8.89169 loss)
I0522 22:25:11.580716 34819 sgd_solver.cpp:112] Iteration 3780, lr = 0.01
I0522 22:25:15.229486 34819 solver.cpp:239] Iteration 3790 (2.6868 iter/s, 3.7219s/10 iters), loss = 8.73714
I0522 22:25:15.229542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73714 (* 1 = 8.73714 loss)
I0522 22:25:15.973120 34819 sgd_solver.cpp:112] Iteration 3790, lr = 0.01
I0522 22:25:20.216434 34819 solver.cpp:239] Iteration 3800 (2.00534 iter/s, 4.98669s/10 iters), loss = 8.92969
I0522 22:25:20.216480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92969 (* 1 = 8.92969 loss)
I0522 22:25:20.845288 34819 sgd_solver.cpp:112] Iteration 3800, lr = 0.01
I0522 22:25:24.506111 34819 solver.cpp:239] Iteration 3810 (2.3313 iter/s, 4.28945s/10 iters), loss = 8.70774
I0522 22:25:24.506229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70774 (* 1 = 8.70774 loss)
I0522 22:25:25.235399 34819 sgd_solver.cpp:112] Iteration 3810, lr = 0.01
I0522 22:25:28.939354 34819 solver.cpp:239] Iteration 3820 (2.25584 iter/s, 4.43294s/10 iters), loss = 8.9322
I0522 22:25:28.939393 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9322 (* 1 = 8.9322 loss)
I0522 22:25:29.010603 34819 sgd_solver.cpp:112] Iteration 3820, lr = 0.01
I0522 22:25:34.196220 34819 solver.cpp:239] Iteration 3830 (1.90237 iter/s, 5.25659s/10 iters), loss = 9.63607
I0522 22:25:34.196274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63607 (* 1 = 9.63607 loss)
I0522 22:25:35.014870 34819 sgd_solver.cpp:112] Iteration 3830, lr = 0.01
I0522 22:25:39.094811 34819 solver.cpp:239] Iteration 3840 (2.04151 iter/s, 4.89834s/10 iters), loss = 8.79333
I0522 22:25:39.094854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79333 (* 1 = 8.79333 loss)
I0522 22:25:39.882375 34819 sgd_solver.cpp:112] Iteration 3840, lr = 0.01
I0522 22:25:44.644706 34819 solver.cpp:239] Iteration 3850 (1.80193 iter/s, 5.54962s/10 iters), loss = 9.24502
I0522 22:25:44.644760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24502 (* 1 = 9.24502 loss)
I0522 22:25:45.442239 34819 sgd_solver.cpp:112] Iteration 3850, lr = 0.01
I0522 22:25:49.532094 34819 solver.cpp:239] Iteration 3860 (2.04619 iter/s, 4.88713s/10 iters), loss = 9.47762
I0522 22:25:49.532150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47762 (* 1 = 9.47762 loss)
I0522 22:25:50.369206 34819 sgd_solver.cpp:112] Iteration 3860, lr = 0.01
I0522 22:25:54.915292 34819 solver.cpp:239] Iteration 3870 (1.85773 iter/s, 5.38292s/10 iters), loss = 9.16166
I0522 22:25:54.915534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16166 (* 1 = 9.16166 loss)
I0522 22:25:55.651984 34819 sgd_solver.cpp:112] Iteration 3870, lr = 0.01
I0522 22:25:59.414733 34819 solver.cpp:239] Iteration 3880 (2.22271 iter/s, 4.49902s/10 iters), loss = 9.01542
I0522 22:25:59.414804 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01542 (* 1 = 9.01542 loss)
I0522 22:25:59.493551 34819 sgd_solver.cpp:112] Iteration 3880, lr = 0.01
I0522 22:26:04.824337 34819 solver.cpp:239] Iteration 3890 (1.84866 iter/s, 5.40932s/10 iters), loss = 8.83497
I0522 22:26:04.824399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83497 (* 1 = 8.83497 loss)
I0522 22:26:04.881166 34819 sgd_solver.cpp:112] Iteration 3890, lr = 0.01
I0522 22:26:10.513859 34819 solver.cpp:239] Iteration 3900 (1.75771 iter/s, 5.68923s/10 iters), loss = 9.4225
I0522 22:26:10.513921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4225 (* 1 = 9.4225 loss)
I0522 22:26:11.348772 34819 sgd_solver.cpp:112] Iteration 3900, lr = 0.01
I0522 22:26:15.375840 34819 solver.cpp:239] Iteration 3910 (2.05688 iter/s, 4.86172s/10 iters), loss = 8.79045
I0522 22:26:15.375886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79045 (* 1 = 8.79045 loss)
I0522 22:26:15.763514 34819 sgd_solver.cpp:112] Iteration 3910, lr = 0.01
I0522 22:26:20.526764 34819 solver.cpp:239] Iteration 3920 (1.9415 iter/s, 5.15066s/10 iters), loss = 9.49248
I0522 22:26:20.526821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49248 (* 1 = 9.49248 loss)
I0522 22:26:21.402194 34819 sgd_solver.cpp:112] Iteration 3920, lr = 0.01
I0522 22:26:25.618440 34819 solver.cpp:239] Iteration 3930 (1.96409 iter/s, 5.09141s/10 iters), loss = 9.38393
I0522 22:26:25.618597 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38393 (* 1 = 9.38393 loss)
I0522 22:26:25.683456 34819 sgd_solver.cpp:112] Iteration 3930, lr = 0.01
I0522 22:26:29.303685 34819 solver.cpp:239] Iteration 3940 (2.71376 iter/s, 3.68493s/10 iters), loss = 9.52822
I0522 22:26:29.303742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52822 (* 1 = 9.52822 loss)
I0522 22:26:30.140692 34819 sgd_solver.cpp:112] Iteration 3940, lr = 0.01
I0522 22:26:34.967186 34819 solver.cpp:239] Iteration 3950 (1.76578 iter/s, 5.66321s/10 iters), loss = 9.68696
I0522 22:26:34.967241 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68696 (* 1 = 9.68696 loss)
I0522 22:26:35.041667 34819 sgd_solver.cpp:112] Iteration 3950, lr = 0.01
I0522 22:26:39.893056 34819 solver.cpp:239] Iteration 3960 (2.0302 iter/s, 4.92562s/10 iters), loss = 8.84905
I0522 22:26:39.893100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84905 (* 1 = 8.84905 loss)
I0522 22:26:39.960412 34819 sgd_solver.cpp:112] Iteration 3960, lr = 0.01
I0522 22:26:43.250216 34819 solver.cpp:239] Iteration 3970 (2.97888 iter/s, 3.35697s/10 iters), loss = 9.0049
I0522 22:26:43.250258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0049 (* 1 = 9.0049 loss)
I0522 22:26:43.323902 34819 sgd_solver.cpp:112] Iteration 3970, lr = 0.01
I0522 22:26:47.397580 34819 solver.cpp:239] Iteration 3980 (2.4113 iter/s, 4.14715s/10 iters), loss = 8.84237
I0522 22:26:47.397635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84237 (* 1 = 8.84237 loss)
I0522 22:26:47.463553 34819 sgd_solver.cpp:112] Iteration 3980, lr = 0.01
I0522 22:26:53.049530 34819 solver.cpp:239] Iteration 3990 (1.76939 iter/s, 5.65167s/10 iters), loss = 8.99048
I0522 22:26:53.049573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99048 (* 1 = 8.99048 loss)
I0522 22:26:53.884064 34819 sgd_solver.cpp:112] Iteration 3990, lr = 0.01
I0522 22:26:56.396857 34819 solver.cpp:239] Iteration 4000 (2.98762 iter/s, 3.34714s/10 iters), loss = 9.04997
I0522 22:26:56.397032 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04997 (* 1 = 9.04997 loss)
I0522 22:26:56.556629 34819 sgd_solver.cpp:112] Iteration 4000, lr = 0.01
I0522 22:26:58.740957 34819 solver.cpp:239] Iteration 4010 (4.26654 iter/s, 2.34382s/10 iters), loss = 9.90125
I0522 22:26:58.741014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.90125 (* 1 = 9.90125 loss)
I0522 22:26:58.829882 34819 sgd_solver.cpp:112] Iteration 4010, lr = 0.01
I0522 22:27:02.823364 34819 solver.cpp:239] Iteration 4020 (2.44967 iter/s, 4.08218s/10 iters), loss = 9.70074
I0522 22:27:02.823410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70074 (* 1 = 9.70074 loss)
I0522 22:27:02.905902 34819 sgd_solver.cpp:112] Iteration 4020, lr = 0.01
I0522 22:27:08.953279 34819 solver.cpp:239] Iteration 4030 (1.63142 iter/s, 6.12962s/10 iters), loss = 9.1901
I0522 22:27:08.953339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1901 (* 1 = 9.1901 loss)
I0522 22:27:09.022455 34819 sgd_solver.cpp:112] Iteration 4030, lr = 0.01
I0522 22:27:13.957114 34819 solver.cpp:239] Iteration 4040 (1.99986 iter/s, 5.00035s/10 iters), loss = 8.91128
I0522 22:27:13.957170 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91128 (* 1 = 8.91128 loss)
I0522 22:27:14.723804 34819 sgd_solver.cpp:112] Iteration 4040, lr = 0.01
I0522 22:27:17.792634 34819 solver.cpp:239] Iteration 4050 (2.60736 iter/s, 3.8353s/10 iters), loss = 9.14842
I0522 22:27:17.792686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14842 (* 1 = 9.14842 loss)
I0522 22:27:17.877460 34819 sgd_solver.cpp:112] Iteration 4050, lr = 0.01
I0522 22:27:20.946151 34819 solver.cpp:239] Iteration 4060 (3.17126 iter/s, 3.15332s/10 iters), loss = 8.66339
I0522 22:27:20.946198 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66339 (* 1 = 8.66339 loss)
I0522 22:27:21.686077 34819 sgd_solver.cpp:112] Iteration 4060, lr = 0.01
I0522 22:27:28.419598 34819 solver.cpp:239] Iteration 4070 (1.33814 iter/s, 7.47308s/10 iters), loss = 8.8472
I0522 22:27:28.419746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8472 (* 1 = 8.8472 loss)
I0522 22:27:29.024155 34819 sgd_solver.cpp:112] Iteration 4070, lr = 0.01
I0522 22:27:33.037642 34819 solver.cpp:239] Iteration 4080 (2.16558 iter/s, 4.6177s/10 iters), loss = 9.02489
I0522 22:27:33.037701 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02489 (* 1 = 9.02489 loss)
I0522 22:27:33.855489 34819 sgd_solver.cpp:112] Iteration 4080, lr = 0.01
I0522 22:27:38.964171 34819 solver.cpp:239] Iteration 4090 (1.68741 iter/s, 5.92623s/10 iters), loss = 9.08504
I0522 22:27:38.964224 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08504 (* 1 = 9.08504 loss)
I0522 22:27:39.783715 34819 sgd_solver.cpp:112] Iteration 4090, lr = 0.01
I0522 22:27:43.876804 34819 solver.cpp:239] Iteration 4100 (2.03568 iter/s, 4.91236s/10 iters), loss = 9.11923
I0522 22:27:43.876860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11923 (* 1 = 9.11923 loss)
I0522 22:27:44.623880 34819 sgd_solver.cpp:112] Iteration 4100, lr = 0.01
I0522 22:27:49.812125 34819 solver.cpp:239] Iteration 4110 (1.68491 iter/s, 5.93503s/10 iters), loss = 8.86858
I0522 22:27:49.812168 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86858 (* 1 = 8.86858 loss)
I0522 22:27:50.321607 34819 sgd_solver.cpp:112] Iteration 4110, lr = 0.01
I0522 22:27:56.046166 34819 solver.cpp:239] Iteration 4120 (1.60417 iter/s, 6.23375s/10 iters), loss = 9.07531
I0522 22:27:56.046208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07531 (* 1 = 9.07531 loss)
I0522 22:27:56.794701 34819 sgd_solver.cpp:112] Iteration 4120, lr = 0.01
I0522 22:28:01.732563 34819 solver.cpp:239] Iteration 4130 (1.75867 iter/s, 5.68612s/10 iters), loss = 8.3096
I0522 22:28:01.732749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3096 (* 1 = 8.3096 loss)
I0522 22:28:01.788197 34819 sgd_solver.cpp:112] Iteration 4130, lr = 0.01
I0522 22:28:07.331923 34819 solver.cpp:239] Iteration 4140 (1.78605 iter/s, 5.59895s/10 iters), loss = 8.57428
I0522 22:28:07.331969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57428 (* 1 = 8.57428 loss)
I0522 22:28:08.155755 34819 sgd_solver.cpp:112] Iteration 4140, lr = 0.01
I0522 22:28:14.006947 34819 solver.cpp:239] Iteration 4150 (1.49819 iter/s, 6.67471s/10 iters), loss = 8.99452
I0522 22:28:14.006994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99452 (* 1 = 8.99452 loss)
I0522 22:28:14.828450 34819 sgd_solver.cpp:112] Iteration 4150, lr = 0.01
I0522 22:28:17.957954 34819 solver.cpp:239] Iteration 4160 (2.53114 iter/s, 3.95079s/10 iters), loss = 8.24148
I0522 22:28:17.957998 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24148 (* 1 = 8.24148 loss)
I0522 22:28:18.602818 34819 sgd_solver.cpp:112] Iteration 4160, lr = 0.01
I0522 22:28:23.344487 34819 solver.cpp:239] Iteration 4170 (1.85658 iter/s, 5.38625s/10 iters), loss = 10.0297
I0522 22:28:23.344552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0297 (* 1 = 10.0297 loss)
I0522 22:28:24.152359 34819 sgd_solver.cpp:112] Iteration 4170, lr = 0.01
I0522 22:28:28.867327 34819 solver.cpp:239] Iteration 4180 (1.81076 iter/s, 5.52255s/10 iters), loss = 9.64026
I0522 22:28:28.867370 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64026 (* 1 = 9.64026 loss)
I0522 22:28:28.954669 34819 sgd_solver.cpp:112] Iteration 4180, lr = 0.01
I0522 22:28:35.337559 34819 solver.cpp:239] Iteration 4190 (1.54562 iter/s, 6.4699s/10 iters), loss = 9.37471
I0522 22:28:35.337712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37471 (* 1 = 9.37471 loss)
I0522 22:28:35.405076 34819 sgd_solver.cpp:112] Iteration 4190, lr = 0.01
I0522 22:28:39.140588 34819 solver.cpp:239] Iteration 4200 (2.62972 iter/s, 3.80268s/10 iters), loss = 9.13265
I0522 22:28:39.140664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13265 (* 1 = 9.13265 loss)
I0522 22:28:39.211482 34819 sgd_solver.cpp:112] Iteration 4200, lr = 0.01
I0522 22:28:42.665690 34819 solver.cpp:239] Iteration 4210 (2.83698 iter/s, 3.52488s/10 iters), loss = 9.3373
I0522 22:28:42.665742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3373 (* 1 = 9.3373 loss)
I0522 22:28:42.726284 34819 sgd_solver.cpp:112] Iteration 4210, lr = 0.01
I0522 22:28:47.668037 34819 solver.cpp:239] Iteration 4220 (1.99917 iter/s, 5.00208s/10 iters), loss = 7.99528
I0522 22:28:47.668094 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99528 (* 1 = 7.99528 loss)
I0522 22:28:47.872493 34819 sgd_solver.cpp:112] Iteration 4220, lr = 0.01
I0522 22:28:50.971864 34819 solver.cpp:239] Iteration 4230 (3.02698 iter/s, 3.30363s/10 iters), loss = 8.31611
I0522 22:28:50.971917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31611 (* 1 = 8.31611 loss)
I0522 22:28:51.054059 34819 sgd_solver.cpp:112] Iteration 4230, lr = 0.01
I0522 22:28:57.588284 34819 solver.cpp:239] Iteration 4240 (1.51147 iter/s, 6.61609s/10 iters), loss = 8.57801
I0522 22:28:57.588346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57801 (* 1 = 8.57801 loss)
I0522 22:28:58.116945 34819 sgd_solver.cpp:112] Iteration 4240, lr = 0.01
I0522 22:29:02.844833 34819 solver.cpp:239] Iteration 4250 (1.90249 iter/s, 5.25628s/10 iters), loss = 9.03629
I0522 22:29:02.844882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03629 (* 1 = 9.03629 loss)
I0522 22:29:03.666687 34819 sgd_solver.cpp:112] Iteration 4250, lr = 0.01
I0522 22:29:09.353895 34819 solver.cpp:239] Iteration 4260 (1.53639 iter/s, 6.50875s/10 iters), loss = 8.83546
I0522 22:29:09.354086 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83546 (* 1 = 8.83546 loss)
I0522 22:29:10.180944 34819 sgd_solver.cpp:112] Iteration 4260, lr = 0.01
I0522 22:29:15.611706 34819 solver.cpp:239] Iteration 4270 (1.59812 iter/s, 6.25737s/10 iters), loss = 9.54619
I0522 22:29:15.611763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54619 (* 1 = 9.54619 loss)
I0522 22:29:15.680368 34819 sgd_solver.cpp:112] Iteration 4270, lr = 0.01
I0522 22:29:19.792971 34819 solver.cpp:239] Iteration 4280 (2.39175 iter/s, 4.18103s/10 iters), loss = 9.36663
I0522 22:29:19.793021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36663 (* 1 = 9.36663 loss)
I0522 22:29:19.890800 34819 sgd_solver.cpp:112] Iteration 4280, lr = 0.01
I0522 22:29:23.240195 34819 solver.cpp:239] Iteration 4290 (2.90105 iter/s, 3.44703s/10 iters), loss = 9.19737
I0522 22:29:23.240242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19737 (* 1 = 9.19737 loss)
I0522 22:29:24.082399 34819 sgd_solver.cpp:112] Iteration 4290, lr = 0.01
I0522 22:29:30.239648 34819 solver.cpp:239] Iteration 4300 (1.42875 iter/s, 6.99912s/10 iters), loss = 8.88923
I0522 22:29:30.239704 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88923 (* 1 = 8.88923 loss)
I0522 22:29:31.072125 34819 sgd_solver.cpp:112] Iteration 4300, lr = 0.01
I0522 22:29:35.111968 34819 solver.cpp:239] Iteration 4310 (2.05252 iter/s, 4.87206s/10 iters), loss = 8.92875
I0522 22:29:35.112023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92875 (* 1 = 8.92875 loss)
I0522 22:29:35.184898 34819 sgd_solver.cpp:112] Iteration 4310, lr = 0.01
I0522 22:29:40.174356 34819 solver.cpp:239] Iteration 4320 (1.97546 iter/s, 5.06212s/10 iters), loss = 8.76293
I0522 22:29:40.174516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76293 (* 1 = 8.76293 loss)
I0522 22:29:40.257423 34819 sgd_solver.cpp:112] Iteration 4320, lr = 0.01
I0522 22:29:44.982841 34819 solver.cpp:239] Iteration 4330 (2.07981 iter/s, 4.80813s/10 iters), loss = 9.05048
I0522 22:29:44.982897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05048 (* 1 = 9.05048 loss)
I0522 22:29:45.804822 34819 sgd_solver.cpp:112] Iteration 4330, lr = 0.01
I0522 22:29:49.658836 34819 solver.cpp:239] Iteration 4340 (2.1387 iter/s, 4.67574s/10 iters), loss = 8.86982
I0522 22:29:49.658903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86982 (* 1 = 8.86982 loss)
I0522 22:29:49.731745 34819 sgd_solver.cpp:112] Iteration 4340, lr = 0.01
I0522 22:29:52.298264 34819 solver.cpp:239] Iteration 4350 (3.78896 iter/s, 2.63925s/10 iters), loss = 8.96076
I0522 22:29:52.298317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96076 (* 1 = 8.96076 loss)
I0522 22:29:52.371729 34819 sgd_solver.cpp:112] Iteration 4350, lr = 0.01
I0522 22:29:57.648911 34819 solver.cpp:239] Iteration 4360 (1.86903 iter/s, 5.35038s/10 iters), loss = 9.69829
I0522 22:29:57.648977 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.69829 (* 1 = 9.69829 loss)
I0522 22:29:58.332602 34819 sgd_solver.cpp:112] Iteration 4360, lr = 0.01
I0522 22:30:01.886804 34819 solver.cpp:239] Iteration 4370 (2.3598 iter/s, 4.23765s/10 iters), loss = 9.71841
I0522 22:30:01.886855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71841 (* 1 = 9.71841 loss)
I0522 22:30:01.943312 34819 sgd_solver.cpp:112] Iteration 4370, lr = 0.01
I0522 22:30:05.458452 34819 solver.cpp:239] Iteration 4380 (2.79999 iter/s, 3.57145s/10 iters), loss = 9.361
I0522 22:30:05.458508 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.361 (* 1 = 9.361 loss)
I0522 22:30:05.531036 34819 sgd_solver.cpp:112] Iteration 4380, lr = 0.01
I0522 22:30:10.307423 34819 solver.cpp:239] Iteration 4390 (2.0624 iter/s, 4.84871s/10 iters), loss = 8.3328
I0522 22:30:10.307612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3328 (* 1 = 8.3328 loss)
I0522 22:30:10.384696 34819 sgd_solver.cpp:112] Iteration 4390, lr = 0.01
I0522 22:30:14.597704 34819 solver.cpp:239] Iteration 4400 (2.33105 iter/s, 4.28991s/10 iters), loss = 8.83158
I0522 22:30:14.597760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83158 (* 1 = 8.83158 loss)
I0522 22:30:14.662869 34819 sgd_solver.cpp:112] Iteration 4400, lr = 0.01
I0522 22:30:19.768973 34819 solver.cpp:239] Iteration 4410 (1.93386 iter/s, 5.171s/10 iters), loss = 9.34947
I0522 22:30:19.769017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34947 (* 1 = 9.34947 loss)
I0522 22:30:20.473587 34819 sgd_solver.cpp:112] Iteration 4410, lr = 0.01
I0522 22:30:24.277432 34819 solver.cpp:239] Iteration 4420 (2.21817 iter/s, 4.50823s/10 iters), loss = 8.71196
I0522 22:30:24.277484 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71196 (* 1 = 8.71196 loss)
I0522 22:30:24.352663 34819 sgd_solver.cpp:112] Iteration 4420, lr = 0.01
I0522 22:30:30.026635 34819 solver.cpp:239] Iteration 4430 (1.73946 iter/s, 5.74892s/10 iters), loss = 8.56003
I0522 22:30:30.026679 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56003 (* 1 = 8.56003 loss)
I0522 22:30:30.087867 34819 sgd_solver.cpp:112] Iteration 4430, lr = 0.01
I0522 22:30:35.115177 34819 solver.cpp:239] Iteration 4440 (1.96655 iter/s, 5.08505s/10 iters), loss = 8.88728
I0522 22:30:35.115222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88728 (* 1 = 8.88728 loss)
I0522 22:30:35.904690 34819 sgd_solver.cpp:112] Iteration 4440, lr = 0.01
I0522 22:30:40.109871 34819 solver.cpp:239] Iteration 4450 (2.00223 iter/s, 4.99444s/10 iters), loss = 8.83425
I0522 22:30:40.109916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83425 (* 1 = 8.83425 loss)
I0522 22:30:40.174412 34819 sgd_solver.cpp:112] Iteration 4450, lr = 0.01
I0522 22:30:44.099655 34819 solver.cpp:239] Iteration 4460 (2.50653 iter/s, 3.98957s/10 iters), loss = 9.02826
I0522 22:30:44.099797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02826 (* 1 = 9.02826 loss)
I0522 22:30:44.926585 34819 sgd_solver.cpp:112] Iteration 4460, lr = 0.01
I0522 22:30:49.697669 34819 solver.cpp:239] Iteration 4470 (1.78646 iter/s, 5.59765s/10 iters), loss = 8.89851
I0522 22:30:49.697715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89851 (* 1 = 8.89851 loss)
I0522 22:30:49.788025 34819 sgd_solver.cpp:112] Iteration 4470, lr = 0.01
I0522 22:30:51.705327 34819 solver.cpp:239] Iteration 4480 (4.98126 iter/s, 2.00752s/10 iters), loss = 8.78133
I0522 22:30:51.705374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78133 (* 1 = 8.78133 loss)
I0522 22:30:52.256873 34819 sgd_solver.cpp:112] Iteration 4480, lr = 0.01
I0522 22:30:55.531949 34819 solver.cpp:239] Iteration 4490 (2.61342 iter/s, 3.82641s/10 iters), loss = 8.69813
I0522 22:30:55.532016 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69813 (* 1 = 8.69813 loss)
I0522 22:30:55.591087 34819 sgd_solver.cpp:112] Iteration 4490, lr = 0.01
I0522 22:31:00.867133 34819 solver.cpp:239] Iteration 4500 (1.87445 iter/s, 5.33489s/10 iters), loss = 8.44992
I0522 22:31:00.867192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44992 (* 1 = 8.44992 loss)
I0522 22:31:00.939033 34819 sgd_solver.cpp:112] Iteration 4500, lr = 0.01
I0522 22:31:05.970409 34819 solver.cpp:239] Iteration 4510 (1.95963 iter/s, 5.10301s/10 iters), loss = 9.15365
I0522 22:31:05.970463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15365 (* 1 = 9.15365 loss)
I0522 22:31:06.034507 34819 sgd_solver.cpp:112] Iteration 4510, lr = 0.01
I0522 22:31:11.187387 34819 solver.cpp:239] Iteration 4520 (1.91692 iter/s, 5.2167s/10 iters), loss = 8.69999
I0522 22:31:11.187433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69999 (* 1 = 8.69999 loss)
I0522 22:31:11.253123 34819 sgd_solver.cpp:112] Iteration 4520, lr = 0.01
I0522 22:31:15.147610 34819 solver.cpp:239] Iteration 4530 (2.52524 iter/s, 3.96001s/10 iters), loss = 9.08616
I0522 22:31:15.147776 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08616 (* 1 = 9.08616 loss)
I0522 22:31:15.956121 34819 sgd_solver.cpp:112] Iteration 4530, lr = 0.01
I0522 22:31:20.836365 34819 solver.cpp:239] Iteration 4540 (1.75798 iter/s, 5.68834s/10 iters), loss = 9.06032
I0522 22:31:20.836419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06032 (* 1 = 9.06032 loss)
I0522 22:31:20.892490 34819 sgd_solver.cpp:112] Iteration 4540, lr = 0.01
I0522 22:31:24.987206 34819 solver.cpp:239] Iteration 4550 (2.40928 iter/s, 4.15061s/10 iters), loss = 8.95719
I0522 22:31:24.987258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95719 (* 1 = 8.95719 loss)
I0522 22:31:25.059279 34819 sgd_solver.cpp:112] Iteration 4550, lr = 0.01
I0522 22:31:30.931483 34819 solver.cpp:239] Iteration 4560 (1.68363 iter/s, 5.93955s/10 iters), loss = 8.67817
I0522 22:31:30.931535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67817 (* 1 = 8.67817 loss)
I0522 22:31:30.993665 34819 sgd_solver.cpp:112] Iteration 4560, lr = 0.01
I0522 22:31:34.583786 34819 solver.cpp:239] Iteration 4570 (2.73815 iter/s, 3.6521s/10 iters), loss = 8.64475
I0522 22:31:34.583834 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64475 (* 1 = 8.64475 loss)
I0522 22:31:34.652046 34819 sgd_solver.cpp:112] Iteration 4570, lr = 0.01
I0522 22:31:37.444138 34819 solver.cpp:239] Iteration 4580 (3.49629 iter/s, 2.86018s/10 iters), loss = 8.75817
I0522 22:31:37.444191 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75817 (* 1 = 8.75817 loss)
I0522 22:31:38.240360 34819 sgd_solver.cpp:112] Iteration 4580, lr = 0.01
I0522 22:31:42.937764 34819 solver.cpp:239] Iteration 4590 (1.82038 iter/s, 5.49335s/10 iters), loss = 9.11676
I0522 22:31:42.937808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11676 (* 1 = 9.11676 loss)
I0522 22:31:42.999701 34819 sgd_solver.cpp:112] Iteration 4590, lr = 0.01
I0522 22:31:46.966786 34819 solver.cpp:239] Iteration 4600 (2.48212 iter/s, 4.02881s/10 iters), loss = 8.85833
I0522 22:31:46.966961 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85833 (* 1 = 8.85833 loss)
I0522 22:31:47.810628 34819 sgd_solver.cpp:112] Iteration 4600, lr = 0.01
I0522 22:31:52.530447 34819 solver.cpp:239] Iteration 4610 (1.79751 iter/s, 5.56326s/10 iters), loss = 8.76922
I0522 22:31:52.530490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76922 (* 1 = 8.76922 loss)
I0522 22:31:52.594771 34819 sgd_solver.cpp:112] Iteration 4610, lr = 0.01
I0522 22:31:58.331737 34819 solver.cpp:239] Iteration 4620 (1.72384 iter/s, 5.801s/10 iters), loss = 8.8402
I0522 22:31:58.331801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8402 (* 1 = 8.8402 loss)
I0522 22:31:58.400519 34819 sgd_solver.cpp:112] Iteration 4620, lr = 0.01
I0522 22:32:03.993885 34819 solver.cpp:239] Iteration 4630 (1.76621 iter/s, 5.66185s/10 iters), loss = 8.82269
I0522 22:32:03.993963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82269 (* 1 = 8.82269 loss)
I0522 22:32:04.885802 34819 sgd_solver.cpp:112] Iteration 4630, lr = 0.01
I0522 22:32:10.661516 34819 solver.cpp:239] Iteration 4640 (1.49986 iter/s, 6.66729s/10 iters), loss = 8.35915
I0522 22:32:10.661578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35915 (* 1 = 8.35915 loss)
I0522 22:32:10.720948 34819 sgd_solver.cpp:112] Iteration 4640, lr = 0.01
I0522 22:32:14.786552 34819 solver.cpp:239] Iteration 4650 (2.42631 iter/s, 4.12148s/10 iters), loss = 8.09755
I0522 22:32:14.786607 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09755 (* 1 = 8.09755 loss)
I0522 22:32:14.841136 34819 sgd_solver.cpp:112] Iteration 4650, lr = 0.01
I0522 22:32:19.093878 34819 solver.cpp:239] Iteration 4660 (2.32175 iter/s, 4.30709s/10 iters), loss = 8.55174
I0522 22:32:19.094101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55174 (* 1 = 8.55174 loss)
I0522 22:32:19.966159 34819 sgd_solver.cpp:112] Iteration 4660, lr = 0.01
I0522 22:32:25.298099 34819 solver.cpp:239] Iteration 4670 (1.61192 iter/s, 6.20378s/10 iters), loss = 8.30457
I0522 22:32:25.298144 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30457 (* 1 = 8.30457 loss)
I0522 22:32:25.361544 34819 sgd_solver.cpp:112] Iteration 4670, lr = 0.01
I0522 22:32:29.081262 34819 solver.cpp:239] Iteration 4680 (2.64343 iter/s, 3.78296s/10 iters), loss = 8.32146
I0522 22:32:29.081310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32146 (* 1 = 8.32146 loss)
I0522 22:32:29.147644 34819 sgd_solver.cpp:112] Iteration 4680, lr = 0.01
I0522 22:32:34.021186 34819 solver.cpp:239] Iteration 4690 (2.02443 iter/s, 4.93967s/10 iters), loss = 8.78408
I0522 22:32:34.021232 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78408 (* 1 = 8.78408 loss)
I0522 22:32:34.078272 34819 sgd_solver.cpp:112] Iteration 4690, lr = 0.01
I0522 22:32:37.600883 34819 solver.cpp:239] Iteration 4700 (2.79369 iter/s, 3.5795s/10 iters), loss = 8.63643
I0522 22:32:37.600927 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63643 (* 1 = 8.63643 loss)
I0522 22:32:37.659867 34819 sgd_solver.cpp:112] Iteration 4700, lr = 0.01
I0522 22:32:41.409401 34819 solver.cpp:239] Iteration 4710 (2.62585 iter/s, 3.80829s/10 iters), loss = 8.76967
I0522 22:32:41.409476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76967 (* 1 = 8.76967 loss)
I0522 22:32:42.218957 34819 sgd_solver.cpp:112] Iteration 4710, lr = 0.01
I0522 22:32:46.917924 34819 solver.cpp:239] Iteration 4720 (1.81547 iter/s, 5.50823s/10 iters), loss = 8.62041
I0522 22:32:46.917968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62041 (* 1 = 8.62041 loss)
I0522 22:32:47.775888 34819 sgd_solver.cpp:112] Iteration 4720, lr = 0.01
I0522 22:32:50.358671 34819 solver.cpp:239] Iteration 4730 (2.90651 iter/s, 3.44055s/10 iters), loss = 8.6765
I0522 22:32:50.358860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6765 (* 1 = 8.6765 loss)
I0522 22:32:50.426591 34819 sgd_solver.cpp:112] Iteration 4730, lr = 0.01
I0522 22:32:54.566496 34819 solver.cpp:239] Iteration 4740 (2.37673 iter/s, 4.20746s/10 iters), loss = 9.17746
I0522 22:32:54.566565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17746 (* 1 = 9.17746 loss)
I0522 22:32:54.626896 34819 sgd_solver.cpp:112] Iteration 4740, lr = 0.01
I0522 22:32:59.278282 34819 solver.cpp:239] Iteration 4750 (2.12245 iter/s, 4.71153s/10 iters), loss = 8.44974
I0522 22:32:59.278326 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44974 (* 1 = 8.44974 loss)
I0522 22:32:59.336217 34819 sgd_solver.cpp:112] Iteration 4750, lr = 0.01
I0522 22:33:04.280694 34819 solver.cpp:239] Iteration 4760 (1.99914 iter/s, 5.00216s/10 iters), loss = 8.25569
I0522 22:33:04.280752 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25569 (* 1 = 8.25569 loss)
I0522 22:33:04.349361 34819 sgd_solver.cpp:112] Iteration 4760, lr = 0.01
I0522 22:33:08.287519 34819 solver.cpp:239] Iteration 4770 (2.49588 iter/s, 4.0066s/10 iters), loss = 8.70093
I0522 22:33:08.287569 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70093 (* 1 = 8.70093 loss)
I0522 22:33:09.155575 34819 sgd_solver.cpp:112] Iteration 4770, lr = 0.01
I0522 22:33:15.548225 34819 solver.cpp:239] Iteration 4780 (1.37734 iter/s, 7.26036s/10 iters), loss = 8.3782
I0522 22:33:15.548283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3782 (* 1 = 8.3782 loss)
I0522 22:33:15.607241 34819 sgd_solver.cpp:112] Iteration 4780, lr = 0.01
I0522 22:33:20.262881 34819 solver.cpp:239] Iteration 4790 (2.12116 iter/s, 4.71441s/10 iters), loss = 9.0856
I0522 22:33:20.262928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0856 (* 1 = 9.0856 loss)
I0522 22:33:20.330189 34819 sgd_solver.cpp:112] Iteration 4790, lr = 0.01
I0522 22:33:24.439402 34819 solver.cpp:239] Iteration 4800 (2.39447 iter/s, 4.17629s/10 iters), loss = 9.31067
I0522 22:33:24.439584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31067 (* 1 = 9.31067 loss)
I0522 22:33:25.117004 34819 sgd_solver.cpp:112] Iteration 4800, lr = 0.01
I0522 22:33:30.081168 34819 solver.cpp:239] Iteration 4810 (1.77262 iter/s, 5.64136s/10 iters), loss = 8.40146
I0522 22:33:30.081213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40146 (* 1 = 8.40146 loss)
I0522 22:33:30.143831 34819 sgd_solver.cpp:112] Iteration 4810, lr = 0.01
I0522 22:33:34.885977 34819 solver.cpp:239] Iteration 4820 (2.08135 iter/s, 4.80457s/10 iters), loss = 8.66472
I0522 22:33:34.886023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66472 (* 1 = 8.66472 loss)
I0522 22:33:35.282171 34819 sgd_solver.cpp:112] Iteration 4820, lr = 0.01
I0522 22:33:40.207695 34819 solver.cpp:239] Iteration 4830 (1.87918 iter/s, 5.32146s/10 iters), loss = 8.74507
I0522 22:33:40.207737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74507 (* 1 = 8.74507 loss)
I0522 22:33:40.272594 34819 sgd_solver.cpp:112] Iteration 4830, lr = 0.01
I0522 22:33:45.352771 34819 solver.cpp:239] Iteration 4840 (1.94371 iter/s, 5.1448s/10 iters), loss = 9.02328
I0522 22:33:45.352833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02328 (* 1 = 9.02328 loss)
I0522 22:33:46.164973 34819 sgd_solver.cpp:112] Iteration 4840, lr = 0.01
I0522 22:33:50.888329 34819 solver.cpp:239] Iteration 4850 (1.8066 iter/s, 5.53527s/10 iters), loss = 8.97599
I0522 22:33:50.888376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97599 (* 1 = 8.97599 loss)
I0522 22:33:50.974654 34819 sgd_solver.cpp:112] Iteration 4850, lr = 0.01
I0522 22:33:55.211971 34819 solver.cpp:239] Iteration 4860 (2.31299 iter/s, 4.32341s/10 iters), loss = 8.46227
I0522 22:33:55.212108 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46227 (* 1 = 8.46227 loss)
I0522 22:33:55.276150 34819 sgd_solver.cpp:112] Iteration 4860, lr = 0.01
I0522 22:34:00.277163 34819 solver.cpp:239] Iteration 4870 (1.97439 iter/s, 5.06485s/10 iters), loss = 8.98298
I0522 22:34:00.277212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98298 (* 1 = 8.98298 loss)
I0522 22:34:00.986594 34819 sgd_solver.cpp:112] Iteration 4870, lr = 0.01
I0522 22:34:03.565086 34819 solver.cpp:239] Iteration 4880 (3.04161 iter/s, 3.28773s/10 iters), loss = 8.24241
I0522 22:34:03.565132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24241 (* 1 = 8.24241 loss)
I0522 22:34:03.617491 34819 sgd_solver.cpp:112] Iteration 4880, lr = 0.01
I0522 22:34:08.710202 34819 solver.cpp:239] Iteration 4890 (1.94369 iter/s, 5.14486s/10 iters), loss = 8.18818
I0522 22:34:08.710255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18818 (* 1 = 8.18818 loss)
I0522 22:34:08.777776 34819 sgd_solver.cpp:112] Iteration 4890, lr = 0.01
I0522 22:34:14.335584 34819 solver.cpp:239] Iteration 4900 (1.77775 iter/s, 5.6251s/10 iters), loss = 8.69359
I0522 22:34:14.335636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69359 (* 1 = 8.69359 loss)
I0522 22:34:14.416937 34819 sgd_solver.cpp:112] Iteration 4900, lr = 0.01
I0522 22:34:17.839802 34819 solver.cpp:239] Iteration 4910 (2.85387 iter/s, 3.50402s/10 iters), loss = 8.9049
I0522 22:34:17.839856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9049 (* 1 = 8.9049 loss)
I0522 22:34:18.700189 34819 sgd_solver.cpp:112] Iteration 4910, lr = 0.01
I0522 22:34:25.549238 34819 solver.cpp:239] Iteration 4920 (1.29717 iter/s, 7.70907s/10 iters), loss = 8.42962
I0522 22:34:25.549383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42962 (* 1 = 8.42962 loss)
I0522 22:34:25.606633 34819 sgd_solver.cpp:112] Iteration 4920, lr = 0.01
I0522 22:34:30.641945 34819 solver.cpp:239] Iteration 4930 (1.96374 iter/s, 5.09234s/10 iters), loss = 8.61499
I0522 22:34:30.642009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61499 (* 1 = 8.61499 loss)
I0522 22:34:31.449371 34819 sgd_solver.cpp:112] Iteration 4930, lr = 0.01
I0522 22:34:34.706064 34819 solver.cpp:239] Iteration 4940 (2.4607 iter/s, 4.06389s/10 iters), loss = 9.09254
I0522 22:34:34.706118 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09254 (* 1 = 9.09254 loss)
I0522 22:34:34.778692 34819 sgd_solver.cpp:112] Iteration 4940, lr = 0.01
I0522 22:34:38.077203 34819 solver.cpp:239] Iteration 4950 (2.96654 iter/s, 3.37093s/10 iters), loss = 8.67668
I0522 22:34:38.077260 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67668 (* 1 = 8.67668 loss)
I0522 22:34:38.806836 34819 sgd_solver.cpp:112] Iteration 4950, lr = 0.01
I0522 22:34:43.505952 34819 solver.cpp:239] Iteration 4960 (1.84214 iter/s, 5.42847s/10 iters), loss = 8.74391
I0522 22:34:43.506006 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74391 (* 1 = 8.74391 loss)
I0522 22:34:43.586356 34819 sgd_solver.cpp:112] Iteration 4960, lr = 0.01
I0522 22:34:47.700361 34819 solver.cpp:239] Iteration 4970 (2.38426 iter/s, 4.19418s/10 iters), loss = 8.84718
I0522 22:34:47.700413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84718 (* 1 = 8.84718 loss)
I0522 22:34:47.767201 34819 sgd_solver.cpp:112] Iteration 4970, lr = 0.01
I0522 22:34:53.768318 34819 solver.cpp:239] Iteration 4980 (1.64808 iter/s, 6.06766s/10 iters), loss = 8.4485
I0522 22:34:53.768360 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4485 (* 1 = 8.4485 loss)
I0522 22:34:54.331061 34819 sgd_solver.cpp:112] Iteration 4980, lr = 0.01
I0522 22:34:59.311255 34819 solver.cpp:239] Iteration 4990 (1.80419 iter/s, 5.54266s/10 iters), loss = 9.23261
I0522 22:34:59.311465 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23261 (* 1 = 9.23261 loss)
I0522 22:35:00.005409 34819 sgd_solver.cpp:112] Iteration 4990, lr = 0.01
I0522 22:35:04.537384 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_5000.caffemodel
I0522 22:35:07.057422 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_5000.solverstate
I0522 22:35:07.273856 34819 solver.cpp:239] Iteration 5000 (1.25596 iter/s, 7.96206s/10 iters), loss = 8.90094
I0522 22:35:07.273922 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90094 (* 1 = 8.90094 loss)
I0522 22:35:07.341977 34819 sgd_solver.cpp:112] Iteration 5000, lr = 0.01
I0522 22:35:11.397397 34819 solver.cpp:239] Iteration 5010 (2.42524 iter/s, 4.1233s/10 iters), loss = 8.66708
I0522 22:35:11.397444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66708 (* 1 = 8.66708 loss)
I0522 22:35:11.456615 34819 sgd_solver.cpp:112] Iteration 5010, lr = 0.01
I0522 22:35:15.484105 34819 solver.cpp:239] Iteration 5020 (2.44709 iter/s, 4.08648s/10 iters), loss = 8.66912
I0522 22:35:15.484153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66912 (* 1 = 8.66912 loss)
I0522 22:35:15.544250 34819 sgd_solver.cpp:112] Iteration 5020, lr = 0.01
I0522 22:35:20.382395 34819 solver.cpp:239] Iteration 5030 (2.04163 iter/s, 4.89804s/10 iters), loss = 8.50932
I0522 22:35:20.382444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50932 (* 1 = 8.50932 loss)
I0522 22:35:21.238792 34819 sgd_solver.cpp:112] Iteration 5030, lr = 0.01
I0522 22:35:25.920907 34819 solver.cpp:239] Iteration 5040 (1.80564 iter/s, 5.5382s/10 iters), loss = 9.22241
I0522 22:35:25.920972 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22241 (* 1 = 9.22241 loss)
I0522 22:35:26.586508 34819 sgd_solver.cpp:112] Iteration 5040, lr = 0.01
I0522 22:35:32.990643 34819 solver.cpp:239] Iteration 5050 (1.41455 iter/s, 7.06938s/10 iters), loss = 9.39143
I0522 22:35:32.990805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39143 (* 1 = 9.39143 loss)
I0522 22:35:33.055474 34819 sgd_solver.cpp:112] Iteration 5050, lr = 0.01
I0522 22:35:38.043018 34819 solver.cpp:239] Iteration 5060 (1.97941 iter/s, 5.05201s/10 iters), loss = 9.17861
I0522 22:35:38.043062 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17861 (* 1 = 9.17861 loss)
I0522 22:35:38.916074 34819 sgd_solver.cpp:112] Iteration 5060, lr = 0.01
I0522 22:35:43.367872 34819 solver.cpp:239] Iteration 5070 (1.87808 iter/s, 5.32459s/10 iters), loss = 8.58971
I0522 22:35:43.367923 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58971 (* 1 = 8.58971 loss)
I0522 22:35:43.426954 34819 sgd_solver.cpp:112] Iteration 5070, lr = 0.01
I0522 22:35:48.364154 34819 solver.cpp:239] Iteration 5080 (2.00159 iter/s, 4.99602s/10 iters), loss = 8.32762
I0522 22:35:48.364207 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32762 (* 1 = 8.32762 loss)
I0522 22:35:48.444169 34819 sgd_solver.cpp:112] Iteration 5080, lr = 0.01
I0522 22:35:54.568877 34819 solver.cpp:239] Iteration 5090 (1.61176 iter/s, 6.20439s/10 iters), loss = 8.38223
I0522 22:35:54.568941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38223 (* 1 = 8.38223 loss)
I0522 22:35:54.634434 34819 sgd_solver.cpp:112] Iteration 5090, lr = 0.01
I0522 22:35:59.037616 34819 solver.cpp:239] Iteration 5100 (2.23789 iter/s, 4.46849s/10 iters), loss = 8.90105
I0522 22:35:59.037662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90105 (* 1 = 8.90105 loss)
I0522 22:35:59.110378 34819 sgd_solver.cpp:112] Iteration 5100, lr = 0.01
I0522 22:36:02.817816 34819 solver.cpp:239] Iteration 5110 (2.64552 iter/s, 3.77998s/10 iters), loss = 9.09563
I0522 22:36:02.817884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09563 (* 1 = 9.09563 loss)
I0522 22:36:03.655423 34819 sgd_solver.cpp:112] Iteration 5110, lr = 0.01
I0522 22:36:09.189260 34819 solver.cpp:239] Iteration 5120 (1.56958 iter/s, 6.37112s/10 iters), loss = 8.59583
I0522 22:36:09.189301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59583 (* 1 = 8.59583 loss)
I0522 22:36:09.252835 34819 sgd_solver.cpp:112] Iteration 5120, lr = 0.01
I0522 22:36:11.971370 34819 solver.cpp:239] Iteration 5130 (3.59463 iter/s, 2.78193s/10 iters), loss = 8.6615
I0522 22:36:11.971436 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6615 (* 1 = 8.6615 loss)
I0522 22:36:12.250447 34819 sgd_solver.cpp:112] Iteration 5130, lr = 0.01
I0522 22:36:16.796083 34819 solver.cpp:239] Iteration 5140 (2.07278 iter/s, 4.82445s/10 iters), loss = 9.40751
I0522 22:36:16.796138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40751 (* 1 = 9.40751 loss)
I0522 22:36:16.865113 34819 sgd_solver.cpp:112] Iteration 5140, lr = 0.01
I0522 22:36:21.007831 34819 solver.cpp:239] Iteration 5150 (2.37444 iter/s, 4.21152s/10 iters), loss = 8.76367
I0522 22:36:21.007884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76367 (* 1 = 8.76367 loss)
I0522 22:36:21.894934 34819 sgd_solver.cpp:112] Iteration 5150, lr = 0.01
I0522 22:36:25.867820 34819 solver.cpp:239] Iteration 5160 (2.05773 iter/s, 4.85972s/10 iters), loss = 8.73089
I0522 22:36:25.867875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73089 (* 1 = 8.73089 loss)
I0522 22:36:25.941257 34819 sgd_solver.cpp:112] Iteration 5160, lr = 0.01
I0522 22:36:30.633847 34819 solver.cpp:239] Iteration 5170 (2.0983 iter/s, 4.76577s/10 iters), loss = 8.64577
I0522 22:36:30.633903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64577 (* 1 = 8.64577 loss)
I0522 22:36:30.692889 34819 sgd_solver.cpp:112] Iteration 5170, lr = 0.01
I0522 22:36:36.155014 34819 solver.cpp:239] Iteration 5180 (1.8113 iter/s, 5.52088s/10 iters), loss = 9.02744
I0522 22:36:36.155238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02744 (* 1 = 9.02744 loss)
I0522 22:36:36.219048 34819 sgd_solver.cpp:112] Iteration 5180, lr = 0.01
I0522 22:36:40.887392 34819 solver.cpp:239] Iteration 5190 (2.11328 iter/s, 4.73198s/10 iters), loss = 8.92016
I0522 22:36:40.887444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92016 (* 1 = 8.92016 loss)
I0522 22:36:41.771541 34819 sgd_solver.cpp:112] Iteration 5190, lr = 0.01
I0522 22:36:46.998778 34819 solver.cpp:239] Iteration 5200 (1.63638 iter/s, 6.11107s/10 iters), loss = 8.70881
I0522 22:36:46.998837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70881 (* 1 = 8.70881 loss)
I0522 22:36:47.063197 34819 sgd_solver.cpp:112] Iteration 5200, lr = 0.01
I0522 22:36:52.934943 34819 solver.cpp:239] Iteration 5210 (1.68468 iter/s, 5.93586s/10 iters), loss = 8.09781
I0522 22:36:52.934996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09781 (* 1 = 8.09781 loss)
I0522 22:36:52.990252 34819 sgd_solver.cpp:112] Iteration 5210, lr = 0.01
I0522 22:36:59.540400 34819 solver.cpp:239] Iteration 5220 (1.51397 iter/s, 6.60513s/10 iters), loss = 8.54882
I0522 22:36:59.540443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54882 (* 1 = 8.54882 loss)
I0522 22:37:00.375447 34819 sgd_solver.cpp:112] Iteration 5220, lr = 0.01
I0522 22:37:04.338238 34819 solver.cpp:239] Iteration 5230 (2.08438 iter/s, 4.79759s/10 iters), loss = 8.57062
I0522 22:37:04.338297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57062 (* 1 = 8.57062 loss)
I0522 22:37:05.172490 34819 sgd_solver.cpp:112] Iteration 5230, lr = 0.01
I0522 22:37:09.306993 34819 solver.cpp:239] Iteration 5240 (2.01269 iter/s, 4.96849s/10 iters), loss = 8.90656
I0522 22:37:09.307179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90656 (* 1 = 8.90656 loss)
I0522 22:37:10.145292 34819 sgd_solver.cpp:112] Iteration 5240, lr = 0.01
I0522 22:37:16.475767 34819 solver.cpp:239] Iteration 5250 (1.39503 iter/s, 7.16829s/10 iters), loss = 9.23626
I0522 22:37:16.475822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23626 (* 1 = 9.23626 loss)
I0522 22:37:16.725072 34819 sgd_solver.cpp:112] Iteration 5250, lr = 0.01
I0522 22:37:21.076941 34819 solver.cpp:239] Iteration 5260 (2.17347 iter/s, 4.60093s/10 iters), loss = 8.50126
I0522 22:37:21.076987 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50126 (* 1 = 8.50126 loss)
I0522 22:37:21.333447 34819 sgd_solver.cpp:112] Iteration 5260, lr = 0.01
I0522 22:37:26.199610 34819 solver.cpp:239] Iteration 5270 (1.95221 iter/s, 5.12241s/10 iters), loss = 8.06675
I0522 22:37:26.199668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06675 (* 1 = 8.06675 loss)
I0522 22:37:27.081413 34819 sgd_solver.cpp:112] Iteration 5270, lr = 0.01
I0522 22:37:33.803225 34819 solver.cpp:239] Iteration 5280 (1.31523 iter/s, 7.60325s/10 iters), loss = 9.4126
I0522 22:37:33.803282 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4126 (* 1 = 9.4126 loss)
I0522 22:37:34.575865 34819 sgd_solver.cpp:112] Iteration 5280, lr = 0.01
I0522 22:37:38.982225 34819 solver.cpp:239] Iteration 5290 (1.93099 iter/s, 5.17868s/10 iters), loss = 8.35465
I0522 22:37:38.982285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35465 (* 1 = 8.35465 loss)
I0522 22:37:39.781008 34819 sgd_solver.cpp:112] Iteration 5290, lr = 0.01
I0522 22:37:44.490428 34819 solver.cpp:239] Iteration 5300 (1.81557 iter/s, 5.50792s/10 iters), loss = 8.92055
I0522 22:37:44.490473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92055 (* 1 = 8.92055 loss)
I0522 22:37:44.551472 34819 sgd_solver.cpp:112] Iteration 5300, lr = 0.01
I0522 22:37:49.440520 34819 solver.cpp:239] Iteration 5310 (2.02027 iter/s, 4.94984s/10 iters), loss = 9.15594
I0522 22:37:49.440575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15594 (* 1 = 9.15594 loss)
I0522 22:37:49.902110 34819 sgd_solver.cpp:112] Iteration 5310, lr = 0.01
I0522 22:37:54.251256 34819 solver.cpp:239] Iteration 5320 (2.0788 iter/s, 4.81047s/10 iters), loss = 8.69829
I0522 22:37:54.251323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69829 (* 1 = 8.69829 loss)
I0522 22:37:55.052430 34819 sgd_solver.cpp:112] Iteration 5320, lr = 0.01
I0522 22:37:59.155160 34819 solver.cpp:239] Iteration 5330 (2.03931 iter/s, 4.90363s/10 iters), loss = 8.92825
I0522 22:37:59.155215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92825 (* 1 = 8.92825 loss)
I0522 22:37:59.950764 34819 sgd_solver.cpp:112] Iteration 5330, lr = 0.01
I0522 22:38:04.306888 34819 solver.cpp:239] Iteration 5340 (1.9412 iter/s, 5.15146s/10 iters), loss = 8.83427
I0522 22:38:04.306943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83427 (* 1 = 8.83427 loss)
I0522 22:38:04.370340 34819 sgd_solver.cpp:112] Iteration 5340, lr = 0.01
I0522 22:38:09.648699 34819 solver.cpp:239] Iteration 5350 (1.87212 iter/s, 5.34153s/10 iters), loss = 8.91438
I0522 22:38:09.648762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91438 (* 1 = 8.91438 loss)
I0522 22:38:09.705880 34819 sgd_solver.cpp:112] Iteration 5350, lr = 0.01
I0522 22:38:12.842398 34819 solver.cpp:239] Iteration 5360 (3.13136 iter/s, 3.1935s/10 iters), loss = 8.29259
I0522 22:38:12.842584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29259 (* 1 = 8.29259 loss)
I0522 22:38:13.697914 34819 sgd_solver.cpp:112] Iteration 5360, lr = 0.01
I0522 22:38:17.298732 34819 solver.cpp:239] Iteration 5370 (2.2442 iter/s, 4.45593s/10 iters), loss = 8.98091
I0522 22:38:17.298787 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98091 (* 1 = 8.98091 loss)
I0522 22:38:18.130812 34819 sgd_solver.cpp:112] Iteration 5370, lr = 0.01
I0522 22:38:22.068665 34819 solver.cpp:239] Iteration 5380 (2.09658 iter/s, 4.76968s/10 iters), loss = 8.52749
I0522 22:38:22.068720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52749 (* 1 = 8.52749 loss)
I0522 22:38:22.141147 34819 sgd_solver.cpp:112] Iteration 5380, lr = 0.01
I0522 22:38:25.603747 34819 solver.cpp:239] Iteration 5390 (2.82895 iter/s, 3.53488s/10 iters), loss = 8.91468
I0522 22:38:25.603790 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91468 (* 1 = 8.91468 loss)
I0522 22:38:26.442029 34819 sgd_solver.cpp:112] Iteration 5390, lr = 0.01
I0522 22:38:32.215106 34819 solver.cpp:239] Iteration 5400 (1.51262 iter/s, 6.61104s/10 iters), loss = 9.0184
I0522 22:38:32.215163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0184 (* 1 = 9.0184 loss)
I0522 22:38:32.273036 34819 sgd_solver.cpp:112] Iteration 5400, lr = 0.01
I0522 22:38:35.743670 34819 solver.cpp:239] Iteration 5410 (2.83419 iter/s, 3.52835s/10 iters), loss = 8.23224
I0522 22:38:35.743723 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23224 (* 1 = 8.23224 loss)
I0522 22:38:36.612165 34819 sgd_solver.cpp:112] Iteration 5410, lr = 0.01
I0522 22:38:42.572769 34819 solver.cpp:239] Iteration 5420 (1.4644 iter/s, 6.82876s/10 iters), loss = 8.69867
I0522 22:38:42.572823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69867 (* 1 = 8.69867 loss)
I0522 22:38:42.636991 34819 sgd_solver.cpp:112] Iteration 5420, lr = 0.01
I0522 22:38:48.638617 34819 solver.cpp:239] Iteration 5430 (1.64866 iter/s, 6.06554s/10 iters), loss = 8.28272
I0522 22:38:48.638866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28272 (* 1 = 8.28272 loss)
I0522 22:38:49.441365 34819 sgd_solver.cpp:112] Iteration 5430, lr = 0.01
I0522 22:38:54.279839 34819 solver.cpp:239] Iteration 5440 (1.77281 iter/s, 5.64076s/10 iters), loss = 7.63378
I0522 22:38:54.279898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63378 (* 1 = 7.63378 loss)
I0522 22:38:54.343374 34819 sgd_solver.cpp:112] Iteration 5440, lr = 0.01
I0522 22:38:57.678985 34819 solver.cpp:239] Iteration 5450 (2.94493 iter/s, 3.39566s/10 iters), loss = 9.23635
I0522 22:38:57.679039 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23635 (* 1 = 9.23635 loss)
I0522 22:38:57.736676 34819 sgd_solver.cpp:112] Iteration 5450, lr = 0.01
I0522 22:39:01.867128 34819 solver.cpp:239] Iteration 5460 (2.38783 iter/s, 4.1879s/10 iters), loss = 8.67037
I0522 22:39:01.867202 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67037 (* 1 = 8.67037 loss)
I0522 22:39:02.683017 34819 sgd_solver.cpp:112] Iteration 5460, lr = 0.01
I0522 22:39:06.104475 34819 solver.cpp:239] Iteration 5470 (2.36012 iter/s, 4.23708s/10 iters), loss = 8.78376
I0522 22:39:06.104538 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78376 (* 1 = 8.78376 loss)
I0522 22:39:06.879951 34819 sgd_solver.cpp:112] Iteration 5470, lr = 0.01
I0522 22:39:10.537082 34819 solver.cpp:239] Iteration 5480 (2.25613 iter/s, 4.43237s/10 iters), loss = 9.48145
I0522 22:39:10.537128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48145 (* 1 = 9.48145 loss)
I0522 22:39:11.336807 34819 sgd_solver.cpp:112] Iteration 5480, lr = 0.01
I0522 22:39:15.514510 34819 solver.cpp:239] Iteration 5490 (2.00917 iter/s, 4.97717s/10 iters), loss = 8.22145
I0522 22:39:15.514560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22145 (* 1 = 8.22145 loss)
I0522 22:39:15.586693 34819 sgd_solver.cpp:112] Iteration 5490, lr = 0.01
I0522 22:39:20.691247 34819 solver.cpp:239] Iteration 5500 (1.93182 iter/s, 5.17646s/10 iters), loss = 8.3839
I0522 22:39:20.691500 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3839 (* 1 = 8.3839 loss)
I0522 22:39:21.480828 34819 sgd_solver.cpp:112] Iteration 5500, lr = 0.01
I0522 22:39:25.610193 34819 solver.cpp:239] Iteration 5510 (2.03314 iter/s, 4.9185s/10 iters), loss = 9.06253
I0522 22:39:25.610257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06253 (* 1 = 9.06253 loss)
I0522 22:39:26.474814 34819 sgd_solver.cpp:112] Iteration 5510, lr = 0.01
I0522 22:39:31.131752 34819 solver.cpp:239] Iteration 5520 (1.81118 iter/s, 5.52125s/10 iters), loss = 8.05306
I0522 22:39:31.131824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05306 (* 1 = 8.05306 loss)
I0522 22:39:31.990345 34819 sgd_solver.cpp:112] Iteration 5520, lr = 0.01
I0522 22:39:35.889405 34819 solver.cpp:239] Iteration 5530 (2.102 iter/s, 4.75738s/10 iters), loss = 8.75826
I0522 22:39:35.889467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75826 (* 1 = 8.75826 loss)
I0522 22:39:35.955754 34819 sgd_solver.cpp:112] Iteration 5530, lr = 0.01
I0522 22:39:39.923907 34819 solver.cpp:239] Iteration 5540 (2.47877 iter/s, 4.03426s/10 iters), loss = 8.53503
I0522 22:39:39.923961 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53503 (* 1 = 8.53503 loss)
I0522 22:39:39.986024 34819 sgd_solver.cpp:112] Iteration 5540, lr = 0.01
I0522 22:39:44.576017 34819 solver.cpp:239] Iteration 5550 (2.14968 iter/s, 4.65186s/10 iters), loss = 8.68635
I0522 22:39:44.576061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68635 (* 1 = 8.68635 loss)
I0522 22:39:45.400305 34819 sgd_solver.cpp:112] Iteration 5550, lr = 0.01
I0522 22:39:49.929078 34819 solver.cpp:239] Iteration 5560 (1.86818 iter/s, 5.35279s/10 iters), loss = 8.79852
I0522 22:39:49.929133 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79852 (* 1 = 8.79852 loss)
I0522 22:39:50.005353 34819 sgd_solver.cpp:112] Iteration 5560, lr = 0.01
I0522 22:39:55.866462 34819 solver.cpp:239] Iteration 5570 (1.68433 iter/s, 5.93709s/10 iters), loss = 8.57185
I0522 22:39:55.866629 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57185 (* 1 = 8.57185 loss)
I0522 22:39:55.938616 34819 sgd_solver.cpp:112] Iteration 5570, lr = 0.01
I0522 22:40:01.381883 34819 solver.cpp:239] Iteration 5580 (1.81323 iter/s, 5.51502s/10 iters), loss = 8.85853
I0522 22:40:01.381937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85853 (* 1 = 8.85853 loss)
I0522 22:40:01.442754 34819 sgd_solver.cpp:112] Iteration 5580, lr = 0.01
I0522 22:40:05.513737 34819 solver.cpp:239] Iteration 5590 (2.42035 iter/s, 4.13163s/10 iters), loss = 8.96499
I0522 22:40:05.513782 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96499 (* 1 = 8.96499 loss)
I0522 22:40:05.762426 34819 sgd_solver.cpp:112] Iteration 5590, lr = 0.01
I0522 22:40:11.296572 34819 solver.cpp:239] Iteration 5600 (1.72934 iter/s, 5.78255s/10 iters), loss = 8.62648
I0522 22:40:11.296617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62648 (* 1 = 8.62648 loss)
I0522 22:40:11.372337 34819 sgd_solver.cpp:112] Iteration 5600, lr = 0.01
I0522 22:40:16.061278 34819 solver.cpp:239] Iteration 5610 (2.09888 iter/s, 4.76445s/10 iters), loss = 9.40051
I0522 22:40:16.061321 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40051 (* 1 = 9.40051 loss)
I0522 22:40:16.129859 34819 sgd_solver.cpp:112] Iteration 5610, lr = 0.01
I0522 22:40:20.979516 34819 solver.cpp:239] Iteration 5620 (2.03335 iter/s, 4.91798s/10 iters), loss = 8.35141
I0522 22:40:20.979564 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35141 (* 1 = 8.35141 loss)
I0522 22:40:21.047955 34819 sgd_solver.cpp:112] Iteration 5620, lr = 0.01
I0522 22:40:25.931952 34819 solver.cpp:239] Iteration 5630 (2.01932 iter/s, 4.95217s/10 iters), loss = 9.06231
I0522 22:40:25.932135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06231 (* 1 = 9.06231 loss)
I0522 22:40:26.779587 34819 sgd_solver.cpp:112] Iteration 5630, lr = 0.01
I0522 22:40:29.221457 34819 solver.cpp:239] Iteration 5640 (3.04028 iter/s, 3.28918s/10 iters), loss = 9.05704
I0522 22:40:29.221546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05704 (* 1 = 9.05704 loss)
I0522 22:40:29.293509 34819 sgd_solver.cpp:112] Iteration 5640, lr = 0.01
I0522 22:40:35.124620 34819 solver.cpp:239] Iteration 5650 (1.6941 iter/s, 5.90283s/10 iters), loss = 8.81117
I0522 22:40:35.124689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81117 (* 1 = 8.81117 loss)
I0522 22:40:35.198424 34819 sgd_solver.cpp:112] Iteration 5650, lr = 0.01
I0522 22:40:40.345635 34819 solver.cpp:239] Iteration 5660 (1.91545 iter/s, 5.22072s/10 iters), loss = 8.78606
I0522 22:40:40.345700 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78606 (* 1 = 8.78606 loss)
I0522 22:40:40.407413 34819 sgd_solver.cpp:112] Iteration 5660, lr = 0.01
I0522 22:40:43.324393 34819 solver.cpp:239] Iteration 5670 (3.35734 iter/s, 2.97855s/10 iters), loss = 8.46392
I0522 22:40:43.324450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46392 (* 1 = 8.46392 loss)
I0522 22:40:43.381682 34819 sgd_solver.cpp:112] Iteration 5670, lr = 0.01
I0522 22:40:48.791102 34819 solver.cpp:239] Iteration 5680 (1.82935 iter/s, 5.46642s/10 iters), loss = 8.59394
I0522 22:40:48.791163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59394 (* 1 = 8.59394 loss)
I0522 22:40:48.867476 34819 sgd_solver.cpp:112] Iteration 5680, lr = 0.01
I0522 22:40:53.057601 34819 solver.cpp:239] Iteration 5690 (2.34398 iter/s, 4.26624s/10 iters), loss = 8.80805
I0522 22:40:53.057657 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80805 (* 1 = 8.80805 loss)
I0522 22:40:53.929936 34819 sgd_solver.cpp:112] Iteration 5690, lr = 0.01
I0522 22:40:58.820713 34819 solver.cpp:239] Iteration 5700 (1.73526 iter/s, 5.76282s/10 iters), loss = 8.76212
I0522 22:40:58.820861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76212 (* 1 = 8.76212 loss)
I0522 22:40:59.671138 34819 sgd_solver.cpp:112] Iteration 5700, lr = 0.01
I0522 22:41:04.771225 34819 solver.cpp:239] Iteration 5710 (1.68064 iter/s, 5.95012s/10 iters), loss = 8.67399
I0522 22:41:04.771270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67399 (* 1 = 8.67399 loss)
I0522 22:41:04.829744 34819 sgd_solver.cpp:112] Iteration 5710, lr = 0.01
I0522 22:41:09.522562 34819 solver.cpp:239] Iteration 5720 (2.10478 iter/s, 4.75109s/10 iters), loss = 8.54027
I0522 22:41:09.522616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54027 (* 1 = 8.54027 loss)
I0522 22:41:09.590742 34819 sgd_solver.cpp:112] Iteration 5720, lr = 0.01
I0522 22:41:15.222519 34819 solver.cpp:239] Iteration 5730 (1.75449 iter/s, 5.69967s/10 iters), loss = 8.60642
I0522 22:41:15.222576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60642 (* 1 = 8.60642 loss)
I0522 22:41:15.276584 34819 sgd_solver.cpp:112] Iteration 5730, lr = 0.01
I0522 22:41:20.853335 34819 solver.cpp:239] Iteration 5740 (1.77603 iter/s, 5.63052s/10 iters), loss = 8.32123
I0522 22:41:20.853386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32123 (* 1 = 8.32123 loss)
I0522 22:41:21.521502 34819 sgd_solver.cpp:112] Iteration 5740, lr = 0.01
I0522 22:41:26.168228 34819 solver.cpp:239] Iteration 5750 (1.88161 iter/s, 5.31459s/10 iters), loss = 8.77686
I0522 22:41:26.168285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77686 (* 1 = 8.77686 loss)
I0522 22:41:26.233726 34819 sgd_solver.cpp:112] Iteration 5750, lr = 0.01
I0522 22:41:31.426939 34819 solver.cpp:239] Iteration 5760 (1.90171 iter/s, 5.25843s/10 iters), loss = 8.8516
I0522 22:41:31.427157 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8516 (* 1 = 8.8516 loss)
I0522 22:41:31.503695 34819 sgd_solver.cpp:112] Iteration 5760, lr = 0.01
I0522 22:41:35.635231 34819 solver.cpp:239] Iteration 5770 (2.37648 iter/s, 4.2079s/10 iters), loss = 8.72778
I0522 22:41:35.635285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72778 (* 1 = 8.72778 loss)
I0522 22:41:35.708587 34819 sgd_solver.cpp:112] Iteration 5770, lr = 0.01
I0522 22:41:39.058735 34819 solver.cpp:239] Iteration 5780 (2.92115 iter/s, 3.4233s/10 iters), loss = 8.62664
I0522 22:41:39.058780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62664 (* 1 = 8.62664 loss)
I0522 22:41:39.118993 34819 sgd_solver.cpp:112] Iteration 5780, lr = 0.01
I0522 22:41:44.183485 34819 solver.cpp:239] Iteration 5790 (1.95142 iter/s, 5.12449s/10 iters), loss = 9.01991
I0522 22:41:44.183528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01991 (* 1 = 9.01991 loss)
I0522 22:41:44.243101 34819 sgd_solver.cpp:112] Iteration 5790, lr = 0.01
I0522 22:41:48.322878 34819 solver.cpp:239] Iteration 5800 (2.41595 iter/s, 4.13915s/10 iters), loss = 8.96606
I0522 22:41:48.322935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96606 (* 1 = 8.96606 loss)
I0522 22:41:48.387322 34819 sgd_solver.cpp:112] Iteration 5800, lr = 0.01
I0522 22:41:53.973330 34819 solver.cpp:239] Iteration 5810 (1.76986 iter/s, 5.65016s/10 iters), loss = 8.8765
I0522 22:41:53.973386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8765 (* 1 = 8.8765 loss)
I0522 22:41:54.820060 34819 sgd_solver.cpp:112] Iteration 5810, lr = 0.01
I0522 22:42:00.036851 34819 solver.cpp:239] Iteration 5820 (1.64929 iter/s, 6.06322s/10 iters), loss = 9.02944
I0522 22:42:00.036907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02944 (* 1 = 9.02944 loss)
I0522 22:42:00.707345 34819 sgd_solver.cpp:112] Iteration 5820, lr = 0.01
I0522 22:42:06.132860 34819 solver.cpp:239] Iteration 5830 (1.6405 iter/s, 6.09571s/10 iters), loss = 8.5858
I0522 22:42:06.133026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5858 (* 1 = 8.5858 loss)
I0522 22:42:06.191529 34819 sgd_solver.cpp:112] Iteration 5830, lr = 0.01
I0522 22:42:11.980623 34819 solver.cpp:239] Iteration 5840 (1.71017 iter/s, 5.84736s/10 iters), loss = 8.68832
I0522 22:42:11.980710 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68832 (* 1 = 8.68832 loss)
I0522 22:42:12.821735 34819 sgd_solver.cpp:112] Iteration 5840, lr = 0.01
I0522 22:42:18.968739 34819 solver.cpp:239] Iteration 5850 (1.43108 iter/s, 6.98774s/10 iters), loss = 8.75673
I0522 22:42:18.968801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75673 (* 1 = 8.75673 loss)
I0522 22:42:19.041292 34819 sgd_solver.cpp:112] Iteration 5850, lr = 0.01
I0522 22:42:22.056071 34819 solver.cpp:239] Iteration 5860 (3.23925 iter/s, 3.08713s/10 iters), loss = 8.48197
I0522 22:42:22.056129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48197 (* 1 = 8.48197 loss)
I0522 22:42:22.614856 34819 sgd_solver.cpp:112] Iteration 5860, lr = 0.01
I0522 22:42:26.693017 34819 solver.cpp:239] Iteration 5870 (2.15671 iter/s, 4.63669s/10 iters), loss = 8.48098
I0522 22:42:26.693079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48098 (* 1 = 8.48098 loss)
I0522 22:42:26.765061 34819 sgd_solver.cpp:112] Iteration 5870, lr = 0.01
I0522 22:42:32.317173 34819 solver.cpp:239] Iteration 5880 (1.77814 iter/s, 5.62385s/10 iters), loss = 8.89785
I0522 22:42:32.317230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89785 (* 1 = 8.89785 loss)
I0522 22:42:32.384320 34819 sgd_solver.cpp:112] Iteration 5880, lr = 0.01
I0522 22:42:39.748119 34819 solver.cpp:239] Iteration 5890 (1.34579 iter/s, 7.43058s/10 iters), loss = 8.78192
I0522 22:42:39.748298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78192 (* 1 = 8.78192 loss)
I0522 22:42:40.452152 34819 sgd_solver.cpp:112] Iteration 5890, lr = 0.01
I0522 22:42:45.552323 34819 solver.cpp:239] Iteration 5900 (1.72302 iter/s, 5.80377s/10 iters), loss = 8.27533
I0522 22:42:45.552390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27533 (* 1 = 8.27533 loss)
I0522 22:42:46.251261 34819 sgd_solver.cpp:112] Iteration 5900, lr = 0.01
I0522 22:42:50.795449 34819 solver.cpp:239] Iteration 5910 (1.90736 iter/s, 5.24284s/10 iters), loss = 8.07726
I0522 22:42:50.795505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07726 (* 1 = 8.07726 loss)
I0522 22:42:50.878399 34819 sgd_solver.cpp:112] Iteration 5910, lr = 0.01
I0522 22:42:53.518347 34819 solver.cpp:239] Iteration 5920 (3.67279 iter/s, 2.72272s/10 iters), loss = 8.69894
I0522 22:42:53.518401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69894 (* 1 = 8.69894 loss)
I0522 22:42:53.573384 34819 sgd_solver.cpp:112] Iteration 5920, lr = 0.01
I0522 22:42:59.159778 34819 solver.cpp:239] Iteration 5930 (1.7727 iter/s, 5.64112s/10 iters), loss = 8.31946
I0522 22:42:59.159854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31946 (* 1 = 8.31946 loss)
I0522 22:42:59.214576 34819 sgd_solver.cpp:112] Iteration 5930, lr = 0.01
I0522 22:43:04.349725 34819 solver.cpp:239] Iteration 5940 (1.92691 iter/s, 5.18966s/10 iters), loss = 8.63741
I0522 22:43:04.349782 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63741 (* 1 = 8.63741 loss)
I0522 22:43:04.424170 34819 sgd_solver.cpp:112] Iteration 5940, lr = 0.01
I0522 22:43:09.245148 34819 solver.cpp:239] Iteration 5950 (2.04283 iter/s, 4.89516s/10 iters), loss = 8.45067
I0522 22:43:09.245206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45067 (* 1 = 8.45067 loss)
I0522 22:43:09.849203 34819 sgd_solver.cpp:112] Iteration 5950, lr = 0.01
I0522 22:43:13.983474 34819 solver.cpp:239] Iteration 5960 (2.11057 iter/s, 4.73806s/10 iters), loss = 8.5638
I0522 22:43:13.983532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5638 (* 1 = 8.5638 loss)
I0522 22:43:14.764984 34819 sgd_solver.cpp:112] Iteration 5960, lr = 0.01
I0522 22:43:20.136236 34819 solver.cpp:239] Iteration 5970 (1.62538 iter/s, 6.15242s/10 iters), loss = 9.09676
I0522 22:43:20.136297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09676 (* 1 = 9.09676 loss)
I0522 22:43:20.997691 34819 sgd_solver.cpp:112] Iteration 5970, lr = 0.01
I0522 22:43:26.547972 34819 solver.cpp:239] Iteration 5980 (1.55972 iter/s, 6.41141s/10 iters), loss = 8.9694
I0522 22:43:26.548032 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9694 (* 1 = 8.9694 loss)
I0522 22:43:27.370656 34819 sgd_solver.cpp:112] Iteration 5980, lr = 0.01
I0522 22:43:31.607841 34819 solver.cpp:239] Iteration 5990 (1.97644 iter/s, 5.05959s/10 iters), loss = 8.85515
I0522 22:43:31.607905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85515 (* 1 = 8.85515 loss)
I0522 22:43:32.372184 34819 sgd_solver.cpp:112] Iteration 5990, lr = 0.01
I0522 22:43:38.045778 34819 solver.cpp:239] Iteration 6000 (1.55337 iter/s, 6.4376s/10 iters), loss = 7.83624
I0522 22:43:38.045836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83624 (* 1 = 7.83624 loss)
I0522 22:43:38.106268 34819 sgd_solver.cpp:112] Iteration 6000, lr = 0.01
I0522 22:43:43.002370 34819 solver.cpp:239] Iteration 6010 (2.01762 iter/s, 4.95632s/10 iters), loss = 8.37162
I0522 22:43:43.002521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37162 (* 1 = 8.37162 loss)
I0522 22:43:43.058495 34819 sgd_solver.cpp:112] Iteration 6010, lr = 0.01
I0522 22:43:48.121510 34819 solver.cpp:239] Iteration 6020 (1.9536 iter/s, 5.11876s/10 iters), loss = 8.83918
I0522 22:43:48.121572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83918 (* 1 = 8.83918 loss)
I0522 22:43:48.183001 34819 sgd_solver.cpp:112] Iteration 6020, lr = 0.01
I0522 22:43:51.629281 34819 solver.cpp:239] Iteration 6030 (2.85099 iter/s, 3.50756s/10 iters), loss = 8.68282
I0522 22:43:51.629338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68282 (* 1 = 8.68282 loss)
I0522 22:43:52.262962 34819 sgd_solver.cpp:112] Iteration 6030, lr = 0.01
I0522 22:43:57.413672 34819 solver.cpp:239] Iteration 6040 (1.72888 iter/s, 5.7841s/10 iters), loss = 8.92135
I0522 22:43:57.413720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92135 (* 1 = 8.92135 loss)
I0522 22:43:58.241422 34819 sgd_solver.cpp:112] Iteration 6040, lr = 0.01
I0522 22:44:02.534591 34819 solver.cpp:239] Iteration 6050 (1.95288 iter/s, 5.12064s/10 iters), loss = 8.84404
I0522 22:44:02.534647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84404 (* 1 = 8.84404 loss)
I0522 22:44:02.604667 34819 sgd_solver.cpp:112] Iteration 6050, lr = 0.01
I0522 22:44:06.529435 34819 solver.cpp:239] Iteration 6060 (2.50337 iter/s, 3.99462s/10 iters), loss = 8.62847
I0522 22:44:06.529486 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62847 (* 1 = 8.62847 loss)
I0522 22:44:06.591037 34819 sgd_solver.cpp:112] Iteration 6060, lr = 0.01
I0522 22:44:10.675415 34819 solver.cpp:239] Iteration 6070 (2.41211 iter/s, 4.14575s/10 iters), loss = 8.84987
I0522 22:44:10.675458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84987 (* 1 = 8.84987 loss)
I0522 22:44:10.733399 34819 sgd_solver.cpp:112] Iteration 6070, lr = 0.01
I0522 22:44:15.539280 34819 solver.cpp:239] Iteration 6080 (2.05609 iter/s, 4.86361s/10 iters), loss = 8.45775
I0522 22:44:15.539458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45775 (* 1 = 8.45775 loss)
I0522 22:44:15.618463 34819 sgd_solver.cpp:112] Iteration 6080, lr = 0.01
I0522 22:44:20.033084 34819 solver.cpp:239] Iteration 6090 (2.22547 iter/s, 4.49344s/10 iters), loss = 8.95748
I0522 22:44:20.033156 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95748 (* 1 = 8.95748 loss)
I0522 22:44:20.104063 34819 sgd_solver.cpp:112] Iteration 6090, lr = 0.01
I0522 22:44:24.619231 34819 solver.cpp:239] Iteration 6100 (2.18061 iter/s, 4.58588s/10 iters), loss = 9.36035
I0522 22:44:24.619302 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36035 (* 1 = 9.36035 loss)
I0522 22:44:24.675431 34819 sgd_solver.cpp:112] Iteration 6100, lr = 0.01
I0522 22:44:29.710785 34819 solver.cpp:239] Iteration 6110 (1.96415 iter/s, 5.09127s/10 iters), loss = 8.17609
I0522 22:44:29.710846 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17609 (* 1 = 8.17609 loss)
I0522 22:44:30.552829 34819 sgd_solver.cpp:112] Iteration 6110, lr = 0.01
I0522 22:44:34.206672 34819 solver.cpp:239] Iteration 6120 (2.22439 iter/s, 4.49562s/10 iters), loss = 9.18243
I0522 22:44:34.206768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18243 (* 1 = 9.18243 loss)
I0522 22:44:34.911978 34819 sgd_solver.cpp:112] Iteration 6120, lr = 0.01
I0522 22:44:37.447700 34819 solver.cpp:239] Iteration 6130 (3.08571 iter/s, 3.24074s/10 iters), loss = 8.17669
I0522 22:44:37.447751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17669 (* 1 = 8.17669 loss)
I0522 22:44:37.839465 34819 sgd_solver.cpp:112] Iteration 6130, lr = 0.01
I0522 22:44:44.068210 34819 solver.cpp:239] Iteration 6140 (1.51053 iter/s, 6.62019s/10 iters), loss = 8.48298
I0522 22:44:44.068258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48298 (* 1 = 8.48298 loss)
I0522 22:44:44.903118 34819 sgd_solver.cpp:112] Iteration 6140, lr = 0.01
I0522 22:44:48.993018 34819 solver.cpp:239] Iteration 6150 (2.03064 iter/s, 4.92455s/10 iters), loss = 8.42997
I0522 22:44:48.993158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42997 (* 1 = 8.42997 loss)
I0522 22:44:49.788245 34819 sgd_solver.cpp:112] Iteration 6150, lr = 0.01
I0522 22:44:51.983057 34819 solver.cpp:239] Iteration 6160 (3.34474 iter/s, 2.98977s/10 iters), loss = 8.99128
I0522 22:44:51.983100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99128 (* 1 = 8.99128 loss)
I0522 22:44:52.040437 34819 sgd_solver.cpp:112] Iteration 6160, lr = 0.01
I0522 22:44:56.048357 34819 solver.cpp:239] Iteration 6170 (2.45997 iter/s, 4.06509s/10 iters), loss = 8.78218
I0522 22:44:56.048414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78218 (* 1 = 8.78218 loss)
I0522 22:44:56.340261 34819 sgd_solver.cpp:112] Iteration 6170, lr = 0.01
I0522 22:44:59.663586 34819 solver.cpp:239] Iteration 6180 (2.76624 iter/s, 3.61501s/10 iters), loss = 9.36307
I0522 22:44:59.663635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36307 (* 1 = 9.36307 loss)
I0522 22:44:59.739974 34819 sgd_solver.cpp:112] Iteration 6180, lr = 0.01
I0522 22:45:04.034454 34819 solver.cpp:239] Iteration 6190 (2.288 iter/s, 4.37063s/10 iters), loss = 8.47366
I0522 22:45:04.034512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47366 (* 1 = 8.47366 loss)
I0522 22:45:04.772161 34819 sgd_solver.cpp:112] Iteration 6190, lr = 0.01
I0522 22:45:08.902143 34819 solver.cpp:239] Iteration 6200 (2.05448 iter/s, 4.86742s/10 iters), loss = 8.98208
I0522 22:45:08.902210 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98208 (* 1 = 8.98208 loss)
I0522 22:45:09.613509 34819 sgd_solver.cpp:112] Iteration 6200, lr = 0.01
I0522 22:45:12.130853 34819 solver.cpp:239] Iteration 6210 (3.09741 iter/s, 3.22851s/10 iters), loss = 8.39361
I0522 22:45:12.130897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39361 (* 1 = 8.39361 loss)
I0522 22:45:12.932737 34819 sgd_solver.cpp:112] Iteration 6210, lr = 0.01
I0522 22:45:16.925966 34819 solver.cpp:239] Iteration 6220 (2.08557 iter/s, 4.79486s/10 iters), loss = 8.61913
I0522 22:45:16.926040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61913 (* 1 = 8.61913 loss)
I0522 22:45:17.743728 34819 sgd_solver.cpp:112] Iteration 6220, lr = 0.01
I0522 22:45:22.353415 34819 solver.cpp:239] Iteration 6230 (1.8426 iter/s, 5.42711s/10 iters), loss = 8.41872
I0522 22:45:22.353638 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41872 (* 1 = 8.41872 loss)
I0522 22:45:23.223245 34819 sgd_solver.cpp:112] Iteration 6230, lr = 0.01
I0522 22:45:26.920379 34819 solver.cpp:239] Iteration 6240 (2.18984 iter/s, 4.56655s/10 iters), loss = 8.44396
I0522 22:45:26.920420 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44396 (* 1 = 8.44396 loss)
I0522 22:45:27.732882 34819 sgd_solver.cpp:112] Iteration 6240, lr = 0.01
I0522 22:45:31.503576 34819 solver.cpp:239] Iteration 6250 (2.182 iter/s, 4.58295s/10 iters), loss = 8.93308
I0522 22:45:31.503633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93308 (* 1 = 8.93308 loss)
I0522 22:45:32.327977 34819 sgd_solver.cpp:112] Iteration 6250, lr = 0.01
I0522 22:45:36.276563 34819 solver.cpp:239] Iteration 6260 (2.09524 iter/s, 4.77272s/10 iters), loss = 8.52483
I0522 22:45:36.276616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52483 (* 1 = 8.52483 loss)
I0522 22:45:37.066609 34819 sgd_solver.cpp:112] Iteration 6260, lr = 0.01
I0522 22:45:41.050570 34819 solver.cpp:239] Iteration 6270 (2.09479 iter/s, 4.77375s/10 iters), loss = 8.70093
I0522 22:45:41.050631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70093 (* 1 = 8.70093 loss)
I0522 22:45:41.113833 34819 sgd_solver.cpp:112] Iteration 6270, lr = 0.01
I0522 22:45:45.300567 34819 solver.cpp:239] Iteration 6280 (2.35308 iter/s, 4.24975s/10 iters), loss = 8.09368
I0522 22:45:45.300611 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09368 (* 1 = 8.09368 loss)
I0522 22:45:46.102222 34819 sgd_solver.cpp:112] Iteration 6280, lr = 0.01
I0522 22:45:48.675832 34819 solver.cpp:239] Iteration 6290 (2.96291 iter/s, 3.37507s/10 iters), loss = 8.41924
I0522 22:45:48.675920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41924 (* 1 = 8.41924 loss)
I0522 22:45:49.512190 34819 sgd_solver.cpp:112] Iteration 6290, lr = 0.01
I0522 22:45:53.301576 34819 solver.cpp:239] Iteration 6300 (2.16194 iter/s, 4.62547s/10 iters), loss = 8.71958
I0522 22:45:53.301831 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71958 (* 1 = 8.71958 loss)
I0522 22:45:53.361570 34819 sgd_solver.cpp:112] Iteration 6300, lr = 0.01
I0522 22:45:57.598961 34819 solver.cpp:239] Iteration 6310 (2.32724 iter/s, 4.29694s/10 iters), loss = 8.03546
I0522 22:45:57.599037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03546 (* 1 = 8.03546 loss)
I0522 22:45:57.672919 34819 sgd_solver.cpp:112] Iteration 6310, lr = 0.01
I0522 22:46:03.131732 34819 solver.cpp:239] Iteration 6320 (1.80751 iter/s, 5.53247s/10 iters), loss = 8.78762
I0522 22:46:03.131783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78762 (* 1 = 8.78762 loss)
I0522 22:46:03.194484 34819 sgd_solver.cpp:112] Iteration 6320, lr = 0.01
I0522 22:46:06.548293 34819 solver.cpp:239] Iteration 6330 (2.92709 iter/s, 3.41636s/10 iters), loss = 8.46342
I0522 22:46:06.548347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46342 (* 1 = 8.46342 loss)
I0522 22:46:06.632897 34819 sgd_solver.cpp:112] Iteration 6330, lr = 0.01
I0522 22:46:12.031648 34819 solver.cpp:239] Iteration 6340 (1.8238 iter/s, 5.48305s/10 iters), loss = 8.6455
I0522 22:46:12.031716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6455 (* 1 = 8.6455 loss)
I0522 22:46:12.704381 34819 sgd_solver.cpp:112] Iteration 6340, lr = 0.01
I0522 22:46:16.044857 34819 solver.cpp:239] Iteration 6350 (2.49192 iter/s, 4.01297s/10 iters), loss = 8.2854
I0522 22:46:16.044908 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2854 (* 1 = 8.2854 loss)
I0522 22:46:16.118238 34819 sgd_solver.cpp:112] Iteration 6350, lr = 0.01
I0522 22:46:21.121628 34819 solver.cpp:239] Iteration 6360 (1.96986 iter/s, 5.07651s/10 iters), loss = 9.33153
I0522 22:46:21.121685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33153 (* 1 = 9.33153 loss)
I0522 22:46:21.183595 34819 sgd_solver.cpp:112] Iteration 6360, lr = 0.01
I0522 22:46:25.992691 34819 solver.cpp:239] Iteration 6370 (2.05306 iter/s, 4.87079s/10 iters), loss = 9.07395
I0522 22:46:25.992861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07395 (* 1 = 9.07395 loss)
I0522 22:46:26.641858 34819 sgd_solver.cpp:112] Iteration 6370, lr = 0.01
I0522 22:46:31.605384 34819 solver.cpp:239] Iteration 6380 (1.7818 iter/s, 5.61229s/10 iters), loss = 8.3058
I0522 22:46:31.605448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3058 (* 1 = 8.3058 loss)
I0522 22:46:31.664525 34819 sgd_solver.cpp:112] Iteration 6380, lr = 0.01
I0522 22:46:35.409703 34819 solver.cpp:239] Iteration 6390 (2.62875 iter/s, 3.80408s/10 iters), loss = 8.47128
I0522 22:46:35.409755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47128 (* 1 = 8.47128 loss)
I0522 22:46:35.489600 34819 sgd_solver.cpp:112] Iteration 6390, lr = 0.01
I0522 22:46:38.975172 34819 solver.cpp:239] Iteration 6400 (2.80485 iter/s, 3.56525s/10 iters), loss = 8.53795
I0522 22:46:38.975244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53795 (* 1 = 8.53795 loss)
I0522 22:46:39.743057 34819 sgd_solver.cpp:112] Iteration 6400, lr = 0.01
I0522 22:46:43.555995 34819 solver.cpp:239] Iteration 6410 (2.18314 iter/s, 4.58055s/10 iters), loss = 8.60939
I0522 22:46:43.556053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60939 (* 1 = 8.60939 loss)
I0522 22:46:43.628958 34819 sgd_solver.cpp:112] Iteration 6410, lr = 0.01
I0522 22:46:48.716656 34819 solver.cpp:239] Iteration 6420 (1.93784 iter/s, 5.16038s/10 iters), loss = 9.01949
I0522 22:46:48.716709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01949 (* 1 = 9.01949 loss)
I0522 22:46:48.784582 34819 sgd_solver.cpp:112] Iteration 6420, lr = 0.01
I0522 22:46:53.588692 34819 solver.cpp:239] Iteration 6430 (2.05264 iter/s, 4.87178s/10 iters), loss = 8.45014
I0522 22:46:53.588747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45014 (* 1 = 8.45014 loss)
I0522 22:46:54.378366 34819 sgd_solver.cpp:112] Iteration 6430, lr = 0.01
I0522 22:46:56.952105 34819 solver.cpp:239] Iteration 6440 (2.97335 iter/s, 3.36321s/10 iters), loss = 8.8174
I0522 22:46:56.952286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8174 (* 1 = 8.8174 loss)
I0522 22:46:57.016856 34819 sgd_solver.cpp:112] Iteration 6440, lr = 0.01
I0522 22:47:01.956847 34819 solver.cpp:239] Iteration 6450 (1.99827 iter/s, 5.00433s/10 iters), loss = 8.29416
I0522 22:47:01.956918 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29416 (* 1 = 8.29416 loss)
I0522 22:47:02.802768 34819 sgd_solver.cpp:112] Iteration 6450, lr = 0.01
I0522 22:47:09.344363 34819 solver.cpp:239] Iteration 6460 (1.3537 iter/s, 7.38714s/10 iters), loss = 8.43771
I0522 22:47:09.344414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43771 (* 1 = 8.43771 loss)
I0522 22:47:09.418262 34819 sgd_solver.cpp:112] Iteration 6460, lr = 0.01
I0522 22:47:14.343817 34819 solver.cpp:239] Iteration 6470 (2.00033 iter/s, 4.99918s/10 iters), loss = 8.34677
I0522 22:47:14.343888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34677 (* 1 = 8.34677 loss)
I0522 22:47:15.139106 34819 sgd_solver.cpp:112] Iteration 6470, lr = 0.01
I0522 22:47:20.064831 34819 solver.cpp:239] Iteration 6480 (1.74804 iter/s, 5.7207s/10 iters), loss = 8.72326
I0522 22:47:20.064903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72326 (* 1 = 8.72326 loss)
I0522 22:47:20.133499 34819 sgd_solver.cpp:112] Iteration 6480, lr = 0.01
I0522 22:47:24.986444 34819 solver.cpp:239] Iteration 6490 (2.03197 iter/s, 4.92133s/10 iters), loss = 8.3083
I0522 22:47:24.986495 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3083 (* 1 = 8.3083 loss)
I0522 22:47:25.049955 34819 sgd_solver.cpp:112] Iteration 6490, lr = 0.01
I0522 22:47:29.135495 34819 solver.cpp:239] Iteration 6500 (2.41032 iter/s, 4.14882s/10 iters), loss = 8.75751
I0522 22:47:29.135617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75751 (* 1 = 8.75751 loss)
I0522 22:47:29.194941 34819 sgd_solver.cpp:112] Iteration 6500, lr = 0.01
I0522 22:47:33.147172 34819 solver.cpp:239] Iteration 6510 (2.4929 iter/s, 4.01139s/10 iters), loss = 8.8902
I0522 22:47:33.147228 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8902 (* 1 = 8.8902 loss)
I0522 22:47:33.205605 34819 sgd_solver.cpp:112] Iteration 6510, lr = 0.01
I0522 22:47:38.112031 34819 solver.cpp:239] Iteration 6520 (2.01427 iter/s, 4.96458s/10 iters), loss = 8.1693
I0522 22:47:38.112109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1693 (* 1 = 8.1693 loss)
I0522 22:47:38.158241 34819 sgd_solver.cpp:112] Iteration 6520, lr = 0.01
I0522 22:47:43.645354 34819 solver.cpp:239] Iteration 6530 (1.80734 iter/s, 5.533s/10 iters), loss = 8.42402
I0522 22:47:43.645422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42402 (* 1 = 8.42402 loss)
I0522 22:47:44.484284 34819 sgd_solver.cpp:112] Iteration 6530, lr = 0.01
I0522 22:47:47.683115 34819 solver.cpp:239] Iteration 6540 (2.47677 iter/s, 4.03752s/10 iters), loss = 8.72906
I0522 22:47:47.683158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72906 (* 1 = 8.72906 loss)
I0522 22:47:47.743181 34819 sgd_solver.cpp:112] Iteration 6540, lr = 0.01
I0522 22:47:54.233276 34819 solver.cpp:239] Iteration 6550 (1.52675 iter/s, 6.54985s/10 iters), loss = 8.90518
I0522 22:47:54.233330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90518 (* 1 = 8.90518 loss)
I0522 22:47:55.053581 34819 sgd_solver.cpp:112] Iteration 6550, lr = 0.01
I0522 22:48:00.671393 34819 solver.cpp:239] Iteration 6560 (1.55333 iter/s, 6.4378s/10 iters), loss = 9.8154
I0522 22:48:00.671517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.8154 (* 1 = 9.8154 loss)
I0522 22:48:01.514169 34819 sgd_solver.cpp:112] Iteration 6560, lr = 0.01
I0522 22:48:07.246515 34819 solver.cpp:239] Iteration 6570 (1.52097 iter/s, 6.57473s/10 iters), loss = 8.16974
I0522 22:48:07.246567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16974 (* 1 = 8.16974 loss)
I0522 22:48:07.701146 34819 sgd_solver.cpp:112] Iteration 6570, lr = 0.01
I0522 22:48:11.933506 34819 solver.cpp:239] Iteration 6580 (2.13368 iter/s, 4.68674s/10 iters), loss = 8.757
I0522 22:48:11.933550 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.757 (* 1 = 8.757 loss)
I0522 22:48:11.991524 34819 sgd_solver.cpp:112] Iteration 6580, lr = 0.01
I0522 22:48:15.271080 34819 solver.cpp:239] Iteration 6590 (2.99637 iter/s, 3.33738s/10 iters), loss = 8.18126
I0522 22:48:15.271150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18126 (* 1 = 8.18126 loss)
I0522 22:48:15.322710 34819 sgd_solver.cpp:112] Iteration 6590, lr = 0.01
I0522 22:48:22.756079 34819 solver.cpp:239] Iteration 6600 (1.33607 iter/s, 7.48462s/10 iters), loss = 8.30284
I0522 22:48:22.756145 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30284 (* 1 = 8.30284 loss)
I0522 22:48:22.837919 34819 sgd_solver.cpp:112] Iteration 6600, lr = 0.01
I0522 22:48:26.356003 34819 solver.cpp:239] Iteration 6610 (2.77801 iter/s, 3.59969s/10 iters), loss = 7.98507
I0522 22:48:26.356055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98507 (* 1 = 7.98507 loss)
I0522 22:48:26.425006 34819 sgd_solver.cpp:112] Iteration 6610, lr = 0.01
I0522 22:48:31.402427 34819 solver.cpp:239] Iteration 6620 (1.98172 iter/s, 5.04613s/10 iters), loss = 8.28327
I0522 22:48:31.402657 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28327 (* 1 = 8.28327 loss)
I0522 22:48:32.232991 34819 sgd_solver.cpp:112] Iteration 6620, lr = 0.01
I0522 22:48:36.453274 34819 solver.cpp:239] Iteration 6630 (1.98004 iter/s, 5.05041s/10 iters), loss = 8.9465
I0522 22:48:36.453342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9465 (* 1 = 8.9465 loss)
I0522 22:48:37.290012 34819 sgd_solver.cpp:112] Iteration 6630, lr = 0.01
I0522 22:48:43.056937 34819 solver.cpp:239] Iteration 6640 (1.51439 iter/s, 6.60333s/10 iters), loss = 8.7605
I0522 22:48:43.056993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7605 (* 1 = 8.7605 loss)
I0522 22:48:43.134932 34819 sgd_solver.cpp:112] Iteration 6640, lr = 0.01
I0522 22:48:47.247931 34819 solver.cpp:239] Iteration 6650 (2.38622 iter/s, 4.19073s/10 iters), loss = 9.29766
I0522 22:48:47.248004 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29766 (* 1 = 9.29766 loss)
I0522 22:48:47.887547 34819 sgd_solver.cpp:112] Iteration 6650, lr = 0.01
I0522 22:48:53.586515 34819 solver.cpp:239] Iteration 6660 (1.57772 iter/s, 6.33824s/10 iters), loss = 8.32089
I0522 22:48:53.586580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32089 (* 1 = 8.32089 loss)
I0522 22:48:53.658430 34819 sgd_solver.cpp:112] Iteration 6660, lr = 0.01
I0522 22:48:59.839787 34819 solver.cpp:239] Iteration 6670 (1.59925 iter/s, 6.25294s/10 iters), loss = 9.12935
I0522 22:48:59.839843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12935 (* 1 = 9.12935 loss)
I0522 22:49:00.551381 34819 sgd_solver.cpp:112] Iteration 6670, lr = 0.01
I0522 22:49:03.734803 34819 solver.cpp:239] Iteration 6680 (2.56753 iter/s, 3.8948s/10 iters), loss = 8.70559
I0522 22:49:03.734946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70559 (* 1 = 8.70559 loss)
I0522 22:49:04.564679 34819 sgd_solver.cpp:112] Iteration 6680, lr = 0.01
I0522 22:49:08.754446 34819 solver.cpp:239] Iteration 6690 (1.99231 iter/s, 5.01929s/10 iters), loss = 8.69852
I0522 22:49:08.754503 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69852 (* 1 = 8.69852 loss)
I0522 22:49:08.822198 34819 sgd_solver.cpp:112] Iteration 6690, lr = 0.01
I0522 22:49:14.272886 34819 solver.cpp:239] Iteration 6700 (1.8122 iter/s, 5.51814s/10 iters), loss = 8.71128
I0522 22:49:14.272941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71128 (* 1 = 8.71128 loss)
I0522 22:49:14.342126 34819 sgd_solver.cpp:112] Iteration 6700, lr = 0.01
I0522 22:49:18.497509 34819 solver.cpp:239] Iteration 6710 (2.36721 iter/s, 4.22438s/10 iters), loss = 8.94043
I0522 22:49:18.497566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94043 (* 1 = 8.94043 loss)
I0522 22:49:18.564755 34819 sgd_solver.cpp:112] Iteration 6710, lr = 0.01
I0522 22:49:22.300977 34819 solver.cpp:239] Iteration 6720 (2.62934 iter/s, 3.80323s/10 iters), loss = 9.16459
I0522 22:49:22.301033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16459 (* 1 = 9.16459 loss)
I0522 22:49:22.359297 34819 sgd_solver.cpp:112] Iteration 6720, lr = 0.01
I0522 22:49:28.373687 34819 solver.cpp:239] Iteration 6730 (1.6468 iter/s, 6.07239s/10 iters), loss = 8.67744
I0522 22:49:28.373744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67744 (* 1 = 8.67744 loss)
I0522 22:49:28.446333 34819 sgd_solver.cpp:112] Iteration 6730, lr = 0.01
I0522 22:49:33.469943 34819 solver.cpp:239] Iteration 6740 (1.96233 iter/s, 5.09599s/10 iters), loss = 8.98206
I0522 22:49:33.470002 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98206 (* 1 = 8.98206 loss)
I0522 22:49:33.535908 34819 sgd_solver.cpp:112] Iteration 6740, lr = 0.01
I0522 22:49:38.410368 34819 solver.cpp:239] Iteration 6750 (2.02423 iter/s, 4.94016s/10 iters), loss = 8.21517
I0522 22:49:38.410562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21517 (* 1 = 8.21517 loss)
I0522 22:49:38.487018 34819 sgd_solver.cpp:112] Iteration 6750, lr = 0.01
I0522 22:49:42.079252 34819 solver.cpp:239] Iteration 6760 (2.72588 iter/s, 3.66854s/10 iters), loss = 9.03659
I0522 22:49:42.079301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03659 (* 1 = 9.03659 loss)
I0522 22:49:42.144074 34819 sgd_solver.cpp:112] Iteration 6760, lr = 0.01
I0522 22:49:46.422065 34819 solver.cpp:239] Iteration 6770 (2.30278 iter/s, 4.34258s/10 iters), loss = 8.10297
I0522 22:49:46.422107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10297 (* 1 = 8.10297 loss)
I0522 22:49:46.484302 34819 sgd_solver.cpp:112] Iteration 6770, lr = 0.01
I0522 22:49:51.876368 34819 solver.cpp:239] Iteration 6780 (1.8335 iter/s, 5.45404s/10 iters), loss = 8.89359
I0522 22:49:51.876411 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89359 (* 1 = 8.89359 loss)
I0522 22:49:52.546012 34819 sgd_solver.cpp:112] Iteration 6780, lr = 0.01
I0522 22:49:57.159287 34819 solver.cpp:239] Iteration 6790 (1.89299 iter/s, 5.28265s/10 iters), loss = 8.517
I0522 22:49:57.159330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.517 (* 1 = 8.517 loss)
I0522 22:49:57.227372 34819 sgd_solver.cpp:112] Iteration 6790, lr = 0.01
I0522 22:50:01.336146 34819 solver.cpp:239] Iteration 6800 (2.39427 iter/s, 4.17664s/10 iters), loss = 8.26225
I0522 22:50:01.336203 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26225 (* 1 = 8.26225 loss)
I0522 22:50:02.168920 34819 sgd_solver.cpp:112] Iteration 6800, lr = 0.01
I0522 22:50:07.141739 34819 solver.cpp:239] Iteration 6810 (1.72257 iter/s, 5.8053s/10 iters), loss = 8.64665
I0522 22:50:07.141796 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64665 (* 1 = 8.64665 loss)
I0522 22:50:08.011855 34819 sgd_solver.cpp:112] Iteration 6810, lr = 0.01
I0522 22:50:11.390679 34819 solver.cpp:239] Iteration 6820 (2.35366 iter/s, 4.2487s/10 iters), loss = 8.9163
I0522 22:50:11.390838 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9163 (* 1 = 8.9163 loss)
I0522 22:50:12.254323 34819 sgd_solver.cpp:112] Iteration 6820, lr = 0.01
I0522 22:50:17.878366 34819 solver.cpp:239] Iteration 6830 (1.54148 iter/s, 6.48726s/10 iters), loss = 8.00008
I0522 22:50:17.878430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00008 (* 1 = 8.00008 loss)
I0522 22:50:17.952021 34819 sgd_solver.cpp:112] Iteration 6830, lr = 0.01
I0522 22:50:23.499828 34819 solver.cpp:239] Iteration 6840 (1.77899 iter/s, 5.62116s/10 iters), loss = 8.42009
I0522 22:50:23.499884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42009 (* 1 = 8.42009 loss)
I0522 22:50:23.581411 34819 sgd_solver.cpp:112] Iteration 6840, lr = 0.01
I0522 22:50:28.559754 34819 solver.cpp:239] Iteration 6850 (1.97642 iter/s, 5.05965s/10 iters), loss = 8.87317
I0522 22:50:28.559797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87317 (* 1 = 8.87317 loss)
I0522 22:50:28.620137 34819 sgd_solver.cpp:112] Iteration 6850, lr = 0.01
I0522 22:50:34.762552 34819 solver.cpp:239] Iteration 6860 (1.61226 iter/s, 6.20249s/10 iters), loss = 9.38232
I0522 22:50:34.762619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38232 (* 1 = 9.38232 loss)
I0522 22:50:34.843441 34819 sgd_solver.cpp:112] Iteration 6860, lr = 0.01
I0522 22:50:38.266790 34819 solver.cpp:239] Iteration 6870 (2.85386 iter/s, 3.50402s/10 iters), loss = 8.44758
I0522 22:50:38.266847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44758 (* 1 = 8.44758 loss)
I0522 22:50:38.328981 34819 sgd_solver.cpp:112] Iteration 6870, lr = 0.01
I0522 22:50:43.758790 34819 solver.cpp:239] Iteration 6880 (1.82092 iter/s, 5.49171s/10 iters), loss = 8.93613
I0522 22:50:43.758973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93613 (* 1 = 8.93613 loss)
I0522 22:50:44.583613 34819 sgd_solver.cpp:112] Iteration 6880, lr = 0.01
I0522 22:50:50.262221 34819 solver.cpp:239] Iteration 6890 (1.53776 iter/s, 6.50298s/10 iters), loss = 8.86681
I0522 22:50:50.262272 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86681 (* 1 = 8.86681 loss)
I0522 22:50:50.895678 34819 sgd_solver.cpp:112] Iteration 6890, lr = 0.01
I0522 22:50:55.029611 34819 solver.cpp:239] Iteration 6900 (2.0977 iter/s, 4.76713s/10 iters), loss = 9.06461
I0522 22:50:55.029690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06461 (* 1 = 9.06461 loss)
I0522 22:50:55.110447 34819 sgd_solver.cpp:112] Iteration 6900, lr = 0.01
I0522 22:50:58.446059 34819 solver.cpp:239] Iteration 6910 (2.92721 iter/s, 3.41622s/10 iters), loss = 8.26278
I0522 22:50:58.446111 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26278 (* 1 = 8.26278 loss)
I0522 22:50:58.503886 34819 sgd_solver.cpp:112] Iteration 6910, lr = 0.01
I0522 22:51:03.021211 34819 solver.cpp:239] Iteration 6920 (2.18584 iter/s, 4.5749s/10 iters), loss = 8.20718
I0522 22:51:03.021265 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20718 (* 1 = 8.20718 loss)
I0522 22:51:03.090960 34819 sgd_solver.cpp:112] Iteration 6920, lr = 0.01
I0522 22:51:09.641758 34819 solver.cpp:239] Iteration 6930 (1.51052 iter/s, 6.62022s/10 iters), loss = 8.6464
I0522 22:51:09.641825 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6464 (* 1 = 8.6464 loss)
I0522 22:51:09.712427 34819 sgd_solver.cpp:112] Iteration 6930, lr = 0.01
I0522 22:51:15.108780 34819 solver.cpp:239] Iteration 6940 (1.82925 iter/s, 5.46672s/10 iters), loss = 8.73483
I0522 22:51:15.108937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73483 (* 1 = 8.73483 loss)
I0522 22:51:15.178421 34819 sgd_solver.cpp:112] Iteration 6940, lr = 0.01
I0522 22:51:19.127563 34819 solver.cpp:239] Iteration 6950 (2.48853 iter/s, 4.01844s/10 iters), loss = 8.40675
I0522 22:51:19.127634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40675 (* 1 = 8.40675 loss)
I0522 22:51:20.006850 34819 sgd_solver.cpp:112] Iteration 6950, lr = 0.01
I0522 22:51:24.797406 34819 solver.cpp:239] Iteration 6960 (1.76381 iter/s, 5.66955s/10 iters), loss = 8.75786
I0522 22:51:24.797448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75786 (* 1 = 8.75786 loss)
I0522 22:51:24.852843 34819 sgd_solver.cpp:112] Iteration 6960, lr = 0.01
I0522 22:51:32.154088 34819 solver.cpp:239] Iteration 6970 (1.35937 iter/s, 7.35634s/10 iters), loss = 9.12439
I0522 22:51:32.154131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12439 (* 1 = 9.12439 loss)
I0522 22:51:32.226444 34819 sgd_solver.cpp:112] Iteration 6970, lr = 0.01
I0522 22:51:39.023788 34819 solver.cpp:239] Iteration 6980 (1.45574 iter/s, 6.86937s/10 iters), loss = 8.84713
I0522 22:51:39.023846 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84713 (* 1 = 8.84713 loss)
I0522 22:51:39.095147 34819 sgd_solver.cpp:112] Iteration 6980, lr = 0.01
I0522 22:51:43.839165 34819 solver.cpp:239] Iteration 6990 (2.0768 iter/s, 4.8151s/10 iters), loss = 8.85018
I0522 22:51:43.839231 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85018 (* 1 = 8.85018 loss)
I0522 22:51:43.918434 34819 sgd_solver.cpp:112] Iteration 6990, lr = 0.01
I0522 22:51:49.258131 34819 solver.cpp:239] Iteration 7000 (1.84547 iter/s, 5.41867s/10 iters), loss = 7.18222
I0522 22:51:49.258309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.18222 (* 1 = 7.18222 loss)
I0522 22:51:49.321859 34819 sgd_solver.cpp:112] Iteration 7000, lr = 0.01
I0522 22:51:54.194226 34819 solver.cpp:239] Iteration 7010 (2.02605 iter/s, 4.93572s/10 iters), loss = 9.26848
I0522 22:51:54.194283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26848 (* 1 = 9.26848 loss)
I0522 22:51:55.031324 34819 sgd_solver.cpp:112] Iteration 7010, lr = 0.01
I0522 22:51:59.847370 34819 solver.cpp:239] Iteration 7020 (1.76902 iter/s, 5.65285s/10 iters), loss = 8.85506
I0522 22:51:59.847421 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85506 (* 1 = 8.85506 loss)
I0522 22:51:59.908843 34819 sgd_solver.cpp:112] Iteration 7020, lr = 0.01
I0522 22:52:04.309707 34819 solver.cpp:239] Iteration 7030 (2.2411 iter/s, 4.46209s/10 iters), loss = 9.00181
I0522 22:52:04.309764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00181 (* 1 = 9.00181 loss)
I0522 22:52:04.367178 34819 sgd_solver.cpp:112] Iteration 7030, lr = 0.01
I0522 22:52:08.175436 34819 solver.cpp:239] Iteration 7040 (2.58699 iter/s, 3.8655s/10 iters), loss = 8.74184
I0522 22:52:08.175477 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74184 (* 1 = 8.74184 loss)
I0522 22:52:08.229779 34819 sgd_solver.cpp:112] Iteration 7040, lr = 0.01
I0522 22:52:13.519085 34819 solver.cpp:239] Iteration 7050 (1.87147 iter/s, 5.34339s/10 iters), loss = 8.32779
I0522 22:52:13.519129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32779 (* 1 = 8.32779 loss)
I0522 22:52:13.577513 34819 sgd_solver.cpp:112] Iteration 7050, lr = 0.01
I0522 22:52:17.877823 34819 solver.cpp:239] Iteration 7060 (2.29437 iter/s, 4.3585s/10 iters), loss = 8.76262
I0522 22:52:17.877874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76262 (* 1 = 8.76262 loss)
I0522 22:52:18.666396 34819 sgd_solver.cpp:112] Iteration 7060, lr = 0.01
I0522 22:52:23.354573 34819 solver.cpp:239] Iteration 7070 (1.826 iter/s, 5.47645s/10 iters), loss = 8.66892
I0522 22:52:23.354784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66892 (* 1 = 8.66892 loss)
I0522 22:52:23.411789 34819 sgd_solver.cpp:112] Iteration 7070, lr = 0.01
I0522 22:52:28.940495 34819 solver.cpp:239] Iteration 7080 (1.79036 iter/s, 5.58547s/10 iters), loss = 8.5291
I0522 22:52:28.940551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5291 (* 1 = 8.5291 loss)
I0522 22:52:29.778040 34819 sgd_solver.cpp:112] Iteration 7080, lr = 0.01
I0522 22:52:33.458073 34819 solver.cpp:239] Iteration 7090 (2.2137 iter/s, 4.51733s/10 iters), loss = 9.1971
I0522 22:52:33.458139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1971 (* 1 = 9.1971 loss)
I0522 22:52:33.518177 34819 sgd_solver.cpp:112] Iteration 7090, lr = 0.01
I0522 22:52:38.392232 34819 solver.cpp:239] Iteration 7100 (2.0268 iter/s, 4.93388s/10 iters), loss = 8.84449
I0522 22:52:38.392280 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84449 (* 1 = 8.84449 loss)
I0522 22:52:39.189635 34819 sgd_solver.cpp:112] Iteration 7100, lr = 0.01
I0522 22:52:42.590135 34819 solver.cpp:239] Iteration 7110 (2.38227 iter/s, 4.19768s/10 iters), loss = 8.70219
I0522 22:52:42.590194 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70219 (* 1 = 8.70219 loss)
I0522 22:52:43.420719 34819 sgd_solver.cpp:112] Iteration 7110, lr = 0.01
I0522 22:52:48.841706 34819 solver.cpp:239] Iteration 7120 (1.60028 iter/s, 6.24892s/10 iters), loss = 8.71265
I0522 22:52:48.841751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71265 (* 1 = 8.71265 loss)
I0522 22:52:49.712090 34819 sgd_solver.cpp:112] Iteration 7120, lr = 0.01
I0522 22:52:53.928544 34819 solver.cpp:239] Iteration 7130 (1.96596 iter/s, 5.08658s/10 iters), loss = 9.25926
I0522 22:52:53.928735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25926 (* 1 = 9.25926 loss)
I0522 22:52:54.669000 34819 sgd_solver.cpp:112] Iteration 7130, lr = 0.01
I0522 22:53:00.320614 34819 solver.cpp:239] Iteration 7140 (1.56455 iter/s, 6.39161s/10 iters), loss = 8.47194
I0522 22:53:00.320658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47194 (* 1 = 8.47194 loss)
I0522 22:53:01.113118 34819 sgd_solver.cpp:112] Iteration 7140, lr = 0.01
I0522 22:53:05.373066 34819 solver.cpp:239] Iteration 7150 (1.97934 iter/s, 5.05219s/10 iters), loss = 9.04486
I0522 22:53:05.373112 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04486 (* 1 = 9.04486 loss)
I0522 22:53:05.445024 34819 sgd_solver.cpp:112] Iteration 7150, lr = 0.01
I0522 22:53:10.463680 34819 solver.cpp:239] Iteration 7160 (1.9645 iter/s, 5.09036s/10 iters), loss = 8.78489
I0522 22:53:10.463722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78489 (* 1 = 8.78489 loss)
I0522 22:53:11.305444 34819 sgd_solver.cpp:112] Iteration 7160, lr = 0.01
I0522 22:53:15.534287 34819 solver.cpp:239] Iteration 7170 (1.97225 iter/s, 5.07035s/10 iters), loss = 9.14724
I0522 22:53:15.534330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14724 (* 1 = 9.14724 loss)
I0522 22:53:15.597874 34819 sgd_solver.cpp:112] Iteration 7170, lr = 0.01
I0522 22:53:19.965623 34819 solver.cpp:239] Iteration 7180 (2.25678 iter/s, 4.43109s/10 iters), loss = 8.49712
I0522 22:53:19.965682 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49712 (* 1 = 8.49712 loss)
I0522 22:53:20.813949 34819 sgd_solver.cpp:112] Iteration 7180, lr = 0.01
I0522 22:53:26.360821 34819 solver.cpp:239] Iteration 7190 (1.56375 iter/s, 6.39487s/10 iters), loss = 8.36432
I0522 22:53:26.360949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36432 (* 1 = 8.36432 loss)
I0522 22:53:26.435925 34819 sgd_solver.cpp:112] Iteration 7190, lr = 0.01
I0522 22:53:31.572942 34819 solver.cpp:239] Iteration 7200 (1.91873 iter/s, 5.21178s/10 iters), loss = 8.19855
I0522 22:53:31.572993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19855 (* 1 = 8.19855 loss)
I0522 22:53:31.648931 34819 sgd_solver.cpp:112] Iteration 7200, lr = 0.01
I0522 22:53:38.099660 34819 solver.cpp:239] Iteration 7210 (1.53224 iter/s, 6.52638s/10 iters), loss = 8.62532
I0522 22:53:38.099719 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62532 (* 1 = 8.62532 loss)
I0522 22:53:38.933277 34819 sgd_solver.cpp:112] Iteration 7210, lr = 0.01
I0522 22:53:44.391242 34819 solver.cpp:239] Iteration 7220 (1.5895 iter/s, 6.29127s/10 iters), loss = 8.58932
I0522 22:53:44.391284 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58932 (* 1 = 8.58932 loss)
I0522 22:53:44.455606 34819 sgd_solver.cpp:112] Iteration 7220, lr = 0.01
I0522 22:53:47.657685 34819 solver.cpp:239] Iteration 7230 (3.06161 iter/s, 3.26625s/10 iters), loss = 8.56495
I0522 22:53:47.657734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56495 (* 1 = 8.56495 loss)
I0522 22:53:47.721906 34819 sgd_solver.cpp:112] Iteration 7230, lr = 0.01
I0522 22:53:53.202466 34819 solver.cpp:239] Iteration 7240 (1.80359 iter/s, 5.54449s/10 iters), loss = 8.21608
I0522 22:53:53.202524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21608 (* 1 = 8.21608 loss)
I0522 22:53:53.278355 34819 sgd_solver.cpp:112] Iteration 7240, lr = 0.01
I0522 22:53:58.592262 34819 solver.cpp:239] Iteration 7250 (1.85546 iter/s, 5.38951s/10 iters), loss = 9.30765
I0522 22:53:58.592397 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30765 (* 1 = 9.30765 loss)
I0522 22:53:58.661690 34819 sgd_solver.cpp:112] Iteration 7250, lr = 0.01
I0522 22:54:03.305456 34819 solver.cpp:239] Iteration 7260 (2.12284 iter/s, 4.71067s/10 iters), loss = 8.14454
I0522 22:54:03.305511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14454 (* 1 = 8.14454 loss)
I0522 22:54:03.378540 34819 sgd_solver.cpp:112] Iteration 7260, lr = 0.01
I0522 22:54:07.485632 34819 solver.cpp:239] Iteration 7270 (2.39238 iter/s, 4.17994s/10 iters), loss = 7.99074
I0522 22:54:07.485674 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99074 (* 1 = 7.99074 loss)
I0522 22:54:08.158628 34819 sgd_solver.cpp:112] Iteration 7270, lr = 0.01
I0522 22:54:13.196887 34819 solver.cpp:239] Iteration 7280 (1.75102 iter/s, 5.71097s/10 iters), loss = 8.88791
I0522 22:54:13.196954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88791 (* 1 = 8.88791 loss)
I0522 22:54:13.263908 34819 sgd_solver.cpp:112] Iteration 7280, lr = 0.01
I0522 22:54:16.640816 34819 solver.cpp:239] Iteration 7290 (2.90385 iter/s, 3.4437s/10 iters), loss = 8.77873
I0522 22:54:16.640866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77873 (* 1 = 8.77873 loss)
I0522 22:54:17.525035 34819 sgd_solver.cpp:112] Iteration 7290, lr = 0.01
I0522 22:54:20.060336 34819 solver.cpp:239] Iteration 7300 (2.92457 iter/s, 3.41931s/10 iters), loss = 9.1682
I0522 22:54:20.060386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1682 (* 1 = 9.1682 loss)
I0522 22:54:20.129830 34819 sgd_solver.cpp:112] Iteration 7300, lr = 0.01
I0522 22:54:25.357445 34819 solver.cpp:239] Iteration 7310 (1.88792 iter/s, 5.29684s/10 iters), loss = 7.8234
I0522 22:54:25.357488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8234 (* 1 = 7.8234 loss)
I0522 22:54:25.428369 34819 sgd_solver.cpp:112] Iteration 7310, lr = 0.01
I0522 22:54:29.419446 34819 solver.cpp:239] Iteration 7320 (2.46197 iter/s, 4.06178s/10 iters), loss = 8.67774
I0522 22:54:29.419651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67774 (* 1 = 8.67774 loss)
I0522 22:54:30.165753 34819 sgd_solver.cpp:112] Iteration 7320, lr = 0.01
I0522 22:54:33.883412 34819 solver.cpp:239] Iteration 7330 (2.24036 iter/s, 4.46357s/10 iters), loss = 8.67293
I0522 22:54:33.883471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67293 (* 1 = 8.67293 loss)
I0522 22:54:33.950870 34819 sgd_solver.cpp:112] Iteration 7330, lr = 0.01
I0522 22:54:37.418107 34819 solver.cpp:239] Iteration 7340 (2.82929 iter/s, 3.53446s/10 iters), loss = 8.62861
I0522 22:54:37.418176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62861 (* 1 = 8.62861 loss)
I0522 22:54:38.208288 34819 sgd_solver.cpp:112] Iteration 7340, lr = 0.01
I0522 22:54:44.419283 34819 solver.cpp:239] Iteration 7350 (1.42841 iter/s, 7.00078s/10 iters), loss = 8.83105
I0522 22:54:44.419335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83105 (* 1 = 8.83105 loss)
I0522 22:54:45.178230 34819 sgd_solver.cpp:112] Iteration 7350, lr = 0.01
I0522 22:54:50.529435 34819 solver.cpp:239] Iteration 7360 (1.6367 iter/s, 6.10984s/10 iters), loss = 9.6102
I0522 22:54:50.529477 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6102 (* 1 = 9.6102 loss)
I0522 22:54:51.333070 34819 sgd_solver.cpp:112] Iteration 7360, lr = 0.01
I0522 22:54:53.921733 34819 solver.cpp:239] Iteration 7370 (2.94802 iter/s, 3.3921s/10 iters), loss = 9.94742
I0522 22:54:53.921787 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.94742 (* 1 = 9.94742 loss)
I0522 22:54:53.991804 34819 sgd_solver.cpp:112] Iteration 7370, lr = 0.01
I0522 22:54:59.782261 34819 solver.cpp:239] Iteration 7380 (1.70642 iter/s, 5.86023s/10 iters), loss = 9.01736
I0522 22:54:59.782394 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01736 (* 1 = 9.01736 loss)
I0522 22:54:59.856232 34819 sgd_solver.cpp:112] Iteration 7380, lr = 0.01
I0522 22:55:03.903571 34819 solver.cpp:239] Iteration 7390 (2.4266 iter/s, 4.12099s/10 iters), loss = 9.16239
I0522 22:55:03.903653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16239 (* 1 = 9.16239 loss)
I0522 22:55:03.966215 34819 sgd_solver.cpp:112] Iteration 7390, lr = 0.01
I0522 22:55:06.169248 34819 solver.cpp:239] Iteration 7400 (4.41405 iter/s, 2.26549s/10 iters), loss = 8.22084
I0522 22:55:06.169312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22084 (* 1 = 8.22084 loss)
I0522 22:55:06.228801 34819 sgd_solver.cpp:112] Iteration 7400, lr = 0.01
I0522 22:55:11.185138 34819 solver.cpp:239] Iteration 7410 (1.99378 iter/s, 5.01561s/10 iters), loss = 8.4538
I0522 22:55:11.185217 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4538 (* 1 = 8.4538 loss)
I0522 22:55:11.237217 34819 sgd_solver.cpp:112] Iteration 7410, lr = 0.01
I0522 22:55:15.313087 34819 solver.cpp:239] Iteration 7420 (2.42267 iter/s, 4.12768s/10 iters), loss = 8.90231
I0522 22:55:15.313163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90231 (* 1 = 8.90231 loss)
I0522 22:55:16.161291 34819 sgd_solver.cpp:112] Iteration 7420, lr = 0.01
I0522 22:55:20.991891 34819 solver.cpp:239] Iteration 7430 (1.76103 iter/s, 5.67849s/10 iters), loss = 8.40099
I0522 22:55:20.991951 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40099 (* 1 = 8.40099 loss)
I0522 22:55:21.691560 34819 sgd_solver.cpp:112] Iteration 7430, lr = 0.01
I0522 22:55:25.196205 34819 solver.cpp:239] Iteration 7440 (2.37865 iter/s, 4.20406s/10 iters), loss = 8.12423
I0522 22:55:25.196261 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12423 (* 1 = 8.12423 loss)
I0522 22:55:25.261167 34819 sgd_solver.cpp:112] Iteration 7440, lr = 0.01
I0522 22:55:30.928143 34819 solver.cpp:239] Iteration 7450 (1.7447 iter/s, 5.73163s/10 iters), loss = 8.51104
I0522 22:55:30.928347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51104 (* 1 = 8.51104 loss)
I0522 22:55:30.999438 34819 sgd_solver.cpp:112] Iteration 7450, lr = 0.01
I0522 22:55:35.093749 34819 solver.cpp:239] Iteration 7460 (2.40083 iter/s, 4.16522s/10 iters), loss = 8.57156
I0522 22:55:35.093816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57156 (* 1 = 8.57156 loss)
I0522 22:55:35.148828 34819 sgd_solver.cpp:112] Iteration 7460, lr = 0.01
I0522 22:55:38.907862 34819 solver.cpp:239] Iteration 7470 (2.62199 iter/s, 3.81389s/10 iters), loss = 9.0096
I0522 22:55:38.907907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0096 (* 1 = 9.0096 loss)
I0522 22:55:38.987545 34819 sgd_solver.cpp:112] Iteration 7470, lr = 0.01
I0522 22:55:43.210338 34819 solver.cpp:239] Iteration 7480 (2.32678 iter/s, 4.29778s/10 iters), loss = 8.67876
I0522 22:55:43.210410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67876 (* 1 = 8.67876 loss)
I0522 22:55:43.279364 34819 sgd_solver.cpp:112] Iteration 7480, lr = 0.01
I0522 22:55:48.638298 34819 solver.cpp:239] Iteration 7490 (1.84241 iter/s, 5.42766s/10 iters), loss = 8.65081
I0522 22:55:48.638365 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65081 (* 1 = 8.65081 loss)
I0522 22:55:48.702556 34819 sgd_solver.cpp:112] Iteration 7490, lr = 0.01
I0522 22:55:54.296969 34819 solver.cpp:239] Iteration 7500 (1.76729 iter/s, 5.65837s/10 iters), loss = 8.7798
I0522 22:55:54.297024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7798 (* 1 = 8.7798 loss)
I0522 22:55:55.035202 34819 sgd_solver.cpp:112] Iteration 7500, lr = 0.01
I0522 22:55:59.809319 34819 solver.cpp:239] Iteration 7510 (1.8142 iter/s, 5.51207s/10 iters), loss = 8.59467
I0522 22:55:59.809368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59467 (* 1 = 8.59467 loss)
I0522 22:55:59.884369 34819 sgd_solver.cpp:112] Iteration 7510, lr = 0.01
I0522 22:56:04.035840 34819 solver.cpp:239] Iteration 7520 (2.36615 iter/s, 4.22628s/10 iters), loss = 9.12721
I0522 22:56:04.036041 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12721 (* 1 = 9.12721 loss)
I0522 22:56:04.111156 34819 sgd_solver.cpp:112] Iteration 7520, lr = 0.01
I0522 22:56:07.443431 34819 solver.cpp:239] Iteration 7530 (2.93579 iter/s, 3.40624s/10 iters), loss = 8.68518
I0522 22:56:07.443475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68518 (* 1 = 8.68518 loss)
I0522 22:56:07.499948 34819 sgd_solver.cpp:112] Iteration 7530, lr = 0.01
I0522 22:56:11.495261 34819 solver.cpp:239] Iteration 7540 (2.46816 iter/s, 4.05161s/10 iters), loss = 9.2492
I0522 22:56:11.495328 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2492 (* 1 = 9.2492 loss)
I0522 22:56:12.193282 34819 sgd_solver.cpp:112] Iteration 7540, lr = 0.01
I0522 22:56:16.066200 34819 solver.cpp:239] Iteration 7550 (2.18786 iter/s, 4.57068s/10 iters), loss = 8.97156
I0522 22:56:16.066246 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97156 (* 1 = 8.97156 loss)
I0522 22:56:16.120662 34819 sgd_solver.cpp:112] Iteration 7550, lr = 0.01
I0522 22:56:20.346144 34819 solver.cpp:239] Iteration 7560 (2.3366 iter/s, 4.27972s/10 iters), loss = 8.52009
I0522 22:56:20.346189 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52009 (* 1 = 8.52009 loss)
I0522 22:56:20.415658 34819 sgd_solver.cpp:112] Iteration 7560, lr = 0.01
I0522 22:56:24.560971 34819 solver.cpp:239] Iteration 7570 (2.37271 iter/s, 4.2146s/10 iters), loss = 9.06096
I0522 22:56:24.561034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06096 (* 1 = 9.06096 loss)
I0522 22:56:25.265851 34819 sgd_solver.cpp:112] Iteration 7570, lr = 0.01
I0522 22:56:30.689518 34819 solver.cpp:239] Iteration 7580 (1.63179 iter/s, 6.12824s/10 iters), loss = 9.46038
I0522 22:56:30.689563 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46038 (* 1 = 9.46038 loss)
I0522 22:56:30.747318 34819 sgd_solver.cpp:112] Iteration 7580, lr = 0.01
I0522 22:56:35.604866 34819 solver.cpp:239] Iteration 7590 (2.03455 iter/s, 4.91508s/10 iters), loss = 8.69326
I0522 22:56:35.605065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69326 (* 1 = 8.69326 loss)
I0522 22:56:35.682245 34819 sgd_solver.cpp:112] Iteration 7590, lr = 0.01
I0522 22:56:39.046605 34819 solver.cpp:239] Iteration 7600 (2.90579 iter/s, 3.4414s/10 iters), loss = 8.66076
I0522 22:56:39.046648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66076 (* 1 = 8.66076 loss)
I0522 22:56:39.501327 34819 sgd_solver.cpp:112] Iteration 7600, lr = 0.01
I0522 22:56:44.047582 34819 solver.cpp:239] Iteration 7610 (1.99971 iter/s, 5.00071s/10 iters), loss = 9.60662
I0522 22:56:44.047647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60662 (* 1 = 9.60662 loss)
I0522 22:56:44.352321 34819 sgd_solver.cpp:112] Iteration 7610, lr = 0.01
I0522 22:56:49.798140 34819 solver.cpp:239] Iteration 7620 (1.73906 iter/s, 5.75024s/10 iters), loss = 9.41156
I0522 22:56:49.798204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41156 (* 1 = 9.41156 loss)
I0522 22:56:50.491957 34819 sgd_solver.cpp:112] Iteration 7620, lr = 0.01
I0522 22:56:54.366901 34819 solver.cpp:239] Iteration 7630 (2.1889 iter/s, 4.5685s/10 iters), loss = 8.30178
I0522 22:56:54.366961 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30178 (* 1 = 8.30178 loss)
I0522 22:56:54.500391 34819 sgd_solver.cpp:112] Iteration 7630, lr = 0.01
I0522 22:56:59.471279 34819 solver.cpp:239] Iteration 7640 (1.95921 iter/s, 5.10411s/10 iters), loss = 9.05967
I0522 22:56:59.471328 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05967 (* 1 = 9.05967 loss)
I0522 22:56:59.544749 34819 sgd_solver.cpp:112] Iteration 7640, lr = 0.01
I0522 22:57:05.195781 34819 solver.cpp:239] Iteration 7650 (1.74696 iter/s, 5.72422s/10 iters), loss = 8.97877
I0522 22:57:05.195832 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97877 (* 1 = 8.97877 loss)
I0522 22:57:05.268965 34819 sgd_solver.cpp:112] Iteration 7650, lr = 0.01
I0522 22:57:09.885943 34819 solver.cpp:239] Iteration 7660 (2.13224 iter/s, 4.6899s/10 iters), loss = 9.81098
I0522 22:57:09.886131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.81098 (* 1 = 9.81098 loss)
I0522 22:57:10.737324 34819 sgd_solver.cpp:112] Iteration 7660, lr = 0.01
I0522 22:57:13.219203 34819 solver.cpp:239] Iteration 7670 (3.00038 iter/s, 3.33291s/10 iters), loss = 9.02738
I0522 22:57:13.219266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02738 (* 1 = 9.02738 loss)
I0522 22:57:14.072793 34819 sgd_solver.cpp:112] Iteration 7670, lr = 0.01
I0522 22:57:17.736141 34819 solver.cpp:239] Iteration 7680 (2.21402 iter/s, 4.51667s/10 iters), loss = 8.07673
I0522 22:57:17.736207 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07673 (* 1 = 8.07673 loss)
I0522 22:57:17.793836 34819 sgd_solver.cpp:112] Iteration 7680, lr = 0.01
I0522 22:57:23.607177 34819 solver.cpp:239] Iteration 7690 (1.70337 iter/s, 5.87072s/10 iters), loss = 8.91055
I0522 22:57:23.607235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91055 (* 1 = 8.91055 loss)
I0522 22:57:23.677105 34819 sgd_solver.cpp:112] Iteration 7690, lr = 0.01
I0522 22:57:27.551848 34819 solver.cpp:239] Iteration 7700 (2.53521 iter/s, 3.94445s/10 iters), loss = 8.90511
I0522 22:57:27.551908 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90511 (* 1 = 8.90511 loss)
I0522 22:57:27.630211 34819 sgd_solver.cpp:112] Iteration 7700, lr = 0.01
I0522 22:57:33.241991 34819 solver.cpp:239] Iteration 7710 (1.75752 iter/s, 5.68983s/10 iters), loss = 8.69614
I0522 22:57:33.242050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69614 (* 1 = 8.69614 loss)
I0522 22:57:33.312189 34819 sgd_solver.cpp:112] Iteration 7710, lr = 0.01
I0522 22:57:36.633092 34819 solver.cpp:239] Iteration 7720 (2.94909 iter/s, 3.39088s/10 iters), loss = 8.64626
I0522 22:57:36.633146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64626 (* 1 = 8.64626 loss)
I0522 22:57:36.707681 34819 sgd_solver.cpp:112] Iteration 7720, lr = 0.01
I0522 22:57:40.909785 34819 solver.cpp:239] Iteration 7730 (2.33839 iter/s, 4.27646s/10 iters), loss = 9.13232
I0522 22:57:40.910068 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13232 (* 1 = 9.13232 loss)
I0522 22:57:40.970502 34819 sgd_solver.cpp:112] Iteration 7730, lr = 0.01
I0522 22:57:44.957828 34819 solver.cpp:239] Iteration 7740 (2.47059 iter/s, 4.04762s/10 iters), loss = 8.98257
I0522 22:57:44.957882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98257 (* 1 = 8.98257 loss)
I0522 22:57:45.684998 34819 sgd_solver.cpp:112] Iteration 7740, lr = 0.01
I0522 22:57:48.894680 34819 solver.cpp:239] Iteration 7750 (2.54024 iter/s, 3.93663s/10 iters), loss = 8.93416
I0522 22:57:48.894767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93416 (* 1 = 8.93416 loss)
I0522 22:57:49.730139 34819 sgd_solver.cpp:112] Iteration 7750, lr = 0.01
I0522 22:57:54.267406 34819 solver.cpp:239] Iteration 7760 (1.86136 iter/s, 5.37241s/10 iters), loss = 9.35056
I0522 22:57:54.267464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35056 (* 1 = 9.35056 loss)
I0522 22:57:54.342000 34819 sgd_solver.cpp:112] Iteration 7760, lr = 0.01
I0522 22:57:58.112041 34819 solver.cpp:239] Iteration 7770 (2.60119 iter/s, 3.8444s/10 iters), loss = 8.92879
I0522 22:57:58.112102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92879 (* 1 = 8.92879 loss)
I0522 22:57:58.174901 34819 sgd_solver.cpp:112] Iteration 7770, lr = 0.01
I0522 22:58:01.244861 34819 solver.cpp:239] Iteration 7780 (3.19222 iter/s, 3.13262s/10 iters), loss = 8.92685
I0522 22:58:01.244902 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92685 (* 1 = 8.92685 loss)
I0522 22:58:02.114575 34819 sgd_solver.cpp:112] Iteration 7780, lr = 0.01
I0522 22:58:07.288287 34819 solver.cpp:239] Iteration 7790 (1.65477 iter/s, 6.04314s/10 iters), loss = 8.85529
I0522 22:58:07.288341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85529 (* 1 = 8.85529 loss)
I0522 22:58:07.668401 34819 sgd_solver.cpp:112] Iteration 7790, lr = 0.01
I0522 22:58:11.020644 34819 solver.cpp:239] Iteration 7800 (2.67942 iter/s, 3.73215s/10 iters), loss = 9.22924
I0522 22:58:11.020748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22924 (* 1 = 9.22924 loss)
I0522 22:58:11.078847 34819 sgd_solver.cpp:112] Iteration 7800, lr = 0.01
I0522 22:58:15.837857 34819 solver.cpp:239] Iteration 7810 (2.07602 iter/s, 4.8169s/10 iters), loss = 9.02677
I0522 22:58:15.837900 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02677 (* 1 = 9.02677 loss)
I0522 22:58:15.898957 34819 sgd_solver.cpp:112] Iteration 7810, lr = 0.01
I0522 22:58:19.691481 34819 solver.cpp:239] Iteration 7820 (2.59511 iter/s, 3.8534s/10 iters), loss = 7.77783
I0522 22:58:19.691543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77783 (* 1 = 7.77783 loss)
I0522 22:58:20.099478 34819 sgd_solver.cpp:112] Iteration 7820, lr = 0.01
I0522 22:58:25.846678 34819 solver.cpp:239] Iteration 7830 (1.62473 iter/s, 6.15489s/10 iters), loss = 8.53421
I0522 22:58:25.846751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53421 (* 1 = 8.53421 loss)
I0522 22:58:25.919945 34819 sgd_solver.cpp:112] Iteration 7830, lr = 0.01
I0522 22:58:31.062572 34819 solver.cpp:239] Iteration 7840 (1.91733 iter/s, 5.21559s/10 iters), loss = 8.94779
I0522 22:58:31.062626 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94779 (* 1 = 8.94779 loss)
I0522 22:58:31.126654 34819 sgd_solver.cpp:112] Iteration 7840, lr = 0.01
I0522 22:58:33.959095 34819 solver.cpp:239] Iteration 7850 (3.45264 iter/s, 2.89633s/10 iters), loss = 8.95599
I0522 22:58:33.959156 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95599 (* 1 = 8.95599 loss)
I0522 22:58:34.027566 34819 sgd_solver.cpp:112] Iteration 7850, lr = 0.01
I0522 22:58:39.429486 34819 solver.cpp:239] Iteration 7860 (1.82812 iter/s, 5.4701s/10 iters), loss = 8.90648
I0522 22:58:39.429528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90648 (* 1 = 8.90648 loss)
I0522 22:58:39.496083 34819 sgd_solver.cpp:112] Iteration 7860, lr = 0.01
I0522 22:58:45.644567 34819 solver.cpp:239] Iteration 7870 (1.60907 iter/s, 6.21478s/10 iters), loss = 9.5946
I0522 22:58:45.644803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.5946 (* 1 = 9.5946 loss)
I0522 22:58:46.375545 34819 sgd_solver.cpp:112] Iteration 7870, lr = 0.01
I0522 22:58:50.380666 34819 solver.cpp:239] Iteration 7880 (2.11163 iter/s, 4.73567s/10 iters), loss = 9.67107
I0522 22:58:50.380720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67107 (* 1 = 9.67107 loss)
I0522 22:58:51.080080 34819 sgd_solver.cpp:112] Iteration 7880, lr = 0.01
I0522 22:58:53.701299 34819 solver.cpp:239] Iteration 7890 (3.01167 iter/s, 3.32042s/10 iters), loss = 8.57837
I0522 22:58:53.701371 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57837 (* 1 = 8.57837 loss)
I0522 22:58:53.766252 34819 sgd_solver.cpp:112] Iteration 7890, lr = 0.01
I0522 22:58:56.238093 34819 solver.cpp:239] Iteration 7900 (3.94228 iter/s, 2.53661s/10 iters), loss = 9.36741
I0522 22:58:56.238153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36741 (* 1 = 9.36741 loss)
I0522 22:58:56.869782 34819 sgd_solver.cpp:112] Iteration 7900, lr = 0.01
I0522 22:59:01.811316 34819 solver.cpp:239] Iteration 7910 (1.79439 iter/s, 5.57293s/10 iters), loss = 9.43439
I0522 22:59:01.811362 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43439 (* 1 = 9.43439 loss)
I0522 22:59:02.671375 34819 sgd_solver.cpp:112] Iteration 7910, lr = 0.01
I0522 22:59:08.181242 34819 solver.cpp:239] Iteration 7920 (1.56995 iter/s, 6.36962s/10 iters), loss = 9.3172
I0522 22:59:08.181298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3172 (* 1 = 9.3172 loss)
I0522 22:59:08.240844 34819 sgd_solver.cpp:112] Iteration 7920, lr = 0.01
I0522 22:59:13.898525 34819 solver.cpp:239] Iteration 7930 (1.74917 iter/s, 5.71699s/10 iters), loss = 8.68708
I0522 22:59:13.898587 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68708 (* 1 = 8.68708 loss)
I0522 22:59:13.968423 34819 sgd_solver.cpp:112] Iteration 7930, lr = 0.01
I0522 22:59:18.507361 34819 solver.cpp:239] Iteration 7940 (2.16987 iter/s, 4.60856s/10 iters), loss = 8.9661
I0522 22:59:18.507539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9661 (* 1 = 8.9661 loss)
I0522 22:59:18.575346 34819 sgd_solver.cpp:112] Iteration 7940, lr = 0.01
I0522 22:59:21.870779 34819 solver.cpp:239] Iteration 7950 (2.97346 iter/s, 3.36309s/10 iters), loss = 8.57685
I0522 22:59:21.870852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57685 (* 1 = 8.57685 loss)
I0522 22:59:21.938838 34819 sgd_solver.cpp:112] Iteration 7950, lr = 0.01
I0522 22:59:26.015944 34819 solver.cpp:239] Iteration 7960 (2.41259 iter/s, 4.14492s/10 iters), loss = 9.28827
I0522 22:59:26.016010 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28827 (* 1 = 9.28827 loss)
I0522 22:59:26.585767 34819 sgd_solver.cpp:112] Iteration 7960, lr = 0.01
I0522 22:59:32.231314 34819 solver.cpp:239] Iteration 7970 (1.609 iter/s, 6.21505s/10 iters), loss = 9.33897
I0522 22:59:32.231376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33897 (* 1 = 9.33897 loss)
I0522 22:59:32.298671 34819 sgd_solver.cpp:112] Iteration 7970, lr = 0.01
I0522 22:59:36.154093 34819 solver.cpp:239] Iteration 7980 (2.54936 iter/s, 3.92255s/10 iters), loss = 8.15859
I0522 22:59:36.154152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15859 (* 1 = 8.15859 loss)
I0522 22:59:36.224344 34819 sgd_solver.cpp:112] Iteration 7980, lr = 0.01
I0522 22:59:42.031507 34819 solver.cpp:239] Iteration 7990 (1.70152 iter/s, 5.87711s/10 iters), loss = 8.96366
I0522 22:59:42.031553 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96366 (* 1 = 8.96366 loss)
I0522 22:59:42.859848 34819 sgd_solver.cpp:112] Iteration 7990, lr = 0.01
I0522 22:59:47.983860 34819 solver.cpp:239] Iteration 8000 (1.68009 iter/s, 5.95207s/10 iters), loss = 8.03382
I0522 22:59:47.983916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03382 (* 1 = 8.03382 loss)
I0522 22:59:48.786679 34819 sgd_solver.cpp:112] Iteration 8000, lr = 0.01
I0522 22:59:52.941643 34819 solver.cpp:239] Iteration 8010 (2.01714 iter/s, 4.95751s/10 iters), loss = 8.32855
I0522 22:59:52.941701 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32855 (* 1 = 8.32855 loss)
I0522 22:59:53.011930 34819 sgd_solver.cpp:112] Iteration 8010, lr = 0.01
I0522 22:59:56.063798 34819 solver.cpp:239] Iteration 8020 (3.20312 iter/s, 3.12196s/10 iters), loss = 9.17122
I0522 22:59:56.063853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17122 (* 1 = 9.17122 loss)
I0522 22:59:56.122306 34819 sgd_solver.cpp:112] Iteration 8020, lr = 0.01
I0522 23:00:00.874986 34819 solver.cpp:239] Iteration 8030 (2.0786 iter/s, 4.81093s/10 iters), loss = 8.80039
I0522 23:00:00.875044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80039 (* 1 = 8.80039 loss)
I0522 23:00:00.960815 34819 sgd_solver.cpp:112] Iteration 8030, lr = 0.01
I0522 23:00:04.969772 34819 solver.cpp:239] Iteration 8040 (2.44228 iter/s, 4.09454s/10 iters), loss = 8.52135
I0522 23:00:04.969840 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52135 (* 1 = 8.52135 loss)
I0522 23:00:05.862443 34819 sgd_solver.cpp:112] Iteration 8040, lr = 0.01
I0522 23:00:09.244820 34819 solver.cpp:239] Iteration 8050 (2.3393 iter/s, 4.27479s/10 iters), loss = 8.67822
I0522 23:00:09.244874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67822 (* 1 = 8.67822 loss)
I0522 23:00:09.317260 34819 sgd_solver.cpp:112] Iteration 8050, lr = 0.01
I0522 23:00:15.168033 34819 solver.cpp:239] Iteration 8060 (1.68836 iter/s, 5.9229s/10 iters), loss = 9.19207
I0522 23:00:15.168090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19207 (* 1 = 9.19207 loss)
I0522 23:00:15.278620 34819 sgd_solver.cpp:112] Iteration 8060, lr = 0.01
I0522 23:00:20.462199 34819 solver.cpp:239] Iteration 8070 (1.88898 iter/s, 5.29387s/10 iters), loss = 8.98309
I0522 23:00:20.462424 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98309 (* 1 = 8.98309 loss)
I0522 23:00:21.221737 34819 sgd_solver.cpp:112] Iteration 8070, lr = 0.01
I0522 23:00:28.113425 34819 solver.cpp:239] Iteration 8080 (1.30707 iter/s, 7.65072s/10 iters), loss = 9.14002
I0522 23:00:28.113468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14002 (* 1 = 9.14002 loss)
I0522 23:00:28.951431 34819 sgd_solver.cpp:112] Iteration 8080, lr = 0.01
I0522 23:00:33.488407 34819 solver.cpp:239] Iteration 8090 (1.86057 iter/s, 5.37471s/10 iters), loss = 8.69214
I0522 23:00:33.488451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69214 (* 1 = 8.69214 loss)
I0522 23:00:34.244768 34819 sgd_solver.cpp:112] Iteration 8090, lr = 0.01
I0522 23:00:39.140338 34819 solver.cpp:239] Iteration 8100 (1.7694 iter/s, 5.65164s/10 iters), loss = 8.2768
I0522 23:00:39.140393 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2768 (* 1 = 8.2768 loss)
I0522 23:00:39.202666 34819 sgd_solver.cpp:112] Iteration 8100, lr = 0.01
I0522 23:00:41.431111 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0522 23:00:45.822382 34819 solver.cpp:239] Iteration 8110 (1.49662 iter/s, 6.68172s/10 iters), loss = 8.38211
I0522 23:00:45.822438 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38211 (* 1 = 8.38211 loss)
I0522 23:00:46.686270 34819 sgd_solver.cpp:112] Iteration 8110, lr = 0.01
I0522 23:00:51.900918 34819 solver.cpp:239] Iteration 8120 (1.64522 iter/s, 6.07822s/10 iters), loss = 8.75142
I0522 23:00:51.901101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75142 (* 1 = 8.75142 loss)
I0522 23:00:51.972689 34819 sgd_solver.cpp:112] Iteration 8120, lr = 0.01
I0522 23:00:56.039870 34819 solver.cpp:239] Iteration 8130 (2.41629 iter/s, 4.13858s/10 iters), loss = 8.55676
I0522 23:00:56.039938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55676 (* 1 = 8.55676 loss)
I0522 23:00:56.101388 34819 sgd_solver.cpp:112] Iteration 8130, lr = 0.01
I0522 23:01:00.649420 34819 solver.cpp:239] Iteration 8140 (2.16953 iter/s, 4.60929s/10 iters), loss = 8.69291
I0522 23:01:00.649462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69291 (* 1 = 8.69291 loss)
I0522 23:01:00.868185 34819 sgd_solver.cpp:112] Iteration 8140, lr = 0.01
I0522 23:01:04.582046 34819 solver.cpp:239] Iteration 8150 (2.54296 iter/s, 3.93242s/10 iters), loss = 9.02758
I0522 23:01:04.582093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02758 (* 1 = 9.02758 loss)
I0522 23:01:04.638337 34819 sgd_solver.cpp:112] Iteration 8150, lr = 0.01
I0522 23:01:08.619045 34819 solver.cpp:239] Iteration 8160 (2.47722 iter/s, 4.03678s/10 iters), loss = 9.52271
I0522 23:01:08.619105 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52271 (* 1 = 9.52271 loss)
I0522 23:01:09.466702 34819 sgd_solver.cpp:112] Iteration 8160, lr = 0.01
I0522 23:01:12.838860 34819 solver.cpp:239] Iteration 8170 (2.36991 iter/s, 4.21958s/10 iters), loss = 9.12565
I0522 23:01:12.838913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12565 (* 1 = 9.12565 loss)
I0522 23:01:13.687655 34819 sgd_solver.cpp:112] Iteration 8170, lr = 0.01
I0522 23:01:18.592795 34819 solver.cpp:239] Iteration 8180 (1.73803 iter/s, 5.75363s/10 iters), loss = 8.6792
I0522 23:01:18.592854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6792 (* 1 = 8.6792 loss)
I0522 23:01:18.665014 34819 sgd_solver.cpp:112] Iteration 8180, lr = 0.01
I0522 23:01:25.614964 34819 solver.cpp:239] Iteration 8190 (1.42413 iter/s, 7.02182s/10 iters), loss = 9.21011
I0522 23:01:25.615162 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21011 (* 1 = 9.21011 loss)
I0522 23:01:25.686096 34819 sgd_solver.cpp:112] Iteration 8190, lr = 0.01
I0522 23:01:29.799571 34819 solver.cpp:239] Iteration 8200 (2.38992 iter/s, 4.18423s/10 iters), loss = 8.42049
I0522 23:01:29.799655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42049 (* 1 = 8.42049 loss)
I0522 23:01:30.640509 34819 sgd_solver.cpp:112] Iteration 8200, lr = 0.01
I0522 23:01:34.869544 34819 solver.cpp:239] Iteration 8210 (1.97251 iter/s, 5.06968s/10 iters), loss = 9.32246
I0522 23:01:34.869602 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32246 (* 1 = 9.32246 loss)
I0522 23:01:34.941740 34819 sgd_solver.cpp:112] Iteration 8210, lr = 0.01
I0522 23:01:39.099630 34819 solver.cpp:239] Iteration 8220 (2.36415 iter/s, 4.22985s/10 iters), loss = 9.08705
I0522 23:01:39.099683 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08705 (* 1 = 9.08705 loss)
I0522 23:01:39.165678 34819 sgd_solver.cpp:112] Iteration 8220, lr = 0.01
I0522 23:01:42.565562 34819 solver.cpp:239] Iteration 8230 (2.8854 iter/s, 3.46572s/10 iters), loss = 8.07561
I0522 23:01:42.565611 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07561 (* 1 = 8.07561 loss)
I0522 23:01:43.405373 34819 sgd_solver.cpp:112] Iteration 8230, lr = 0.01
I0522 23:01:48.936708 34819 solver.cpp:239] Iteration 8240 (1.56966 iter/s, 6.37081s/10 iters), loss = 9.18045
I0522 23:01:48.936786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18045 (* 1 = 9.18045 loss)
I0522 23:01:49.759799 34819 sgd_solver.cpp:112] Iteration 8240, lr = 0.01
I0522 23:01:55.398236 34819 solver.cpp:239] Iteration 8250 (1.54771 iter/s, 6.46117s/10 iters), loss = 9.47064
I0522 23:01:55.398301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47064 (* 1 = 9.47064 loss)
I0522 23:01:55.460661 34819 sgd_solver.cpp:112] Iteration 8250, lr = 0.01
I0522 23:01:59.624512 34819 solver.cpp:239] Iteration 8260 (2.36629 iter/s, 4.22602s/10 iters), loss = 8.81675
I0522 23:01:59.624660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81675 (* 1 = 8.81675 loss)
I0522 23:01:59.694988 34819 sgd_solver.cpp:112] Iteration 8260, lr = 0.01
I0522 23:02:02.918165 34819 solver.cpp:239] Iteration 8270 (3.03642 iter/s, 3.29335s/10 iters), loss = 9.07032
I0522 23:02:02.918236 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07032 (* 1 = 9.07032 loss)
I0522 23:02:02.983981 34819 sgd_solver.cpp:112] Iteration 8270, lr = 0.01
I0522 23:02:07.129555 34819 solver.cpp:239] Iteration 8280 (2.37466 iter/s, 4.21113s/10 iters), loss = 8.7357
I0522 23:02:07.129612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7357 (* 1 = 8.7357 loss)
I0522 23:02:07.206046 34819 sgd_solver.cpp:112] Iteration 8280, lr = 0.01
I0522 23:02:10.615802 34819 solver.cpp:239] Iteration 8290 (2.8686 iter/s, 3.48602s/10 iters), loss = 9.74713
I0522 23:02:10.615870 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74713 (* 1 = 9.74713 loss)
I0522 23:02:10.675992 34819 sgd_solver.cpp:112] Iteration 8290, lr = 0.01
I0522 23:02:15.870430 34819 solver.cpp:239] Iteration 8300 (1.90319 iter/s, 5.25434s/10 iters), loss = 8.96505
I0522 23:02:15.870484 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96505 (* 1 = 8.96505 loss)
I0522 23:02:15.944264 34819 sgd_solver.cpp:112] Iteration 8300, lr = 0.01
I0522 23:02:20.195485 34819 solver.cpp:239] Iteration 8310 (2.31224 iter/s, 4.3248s/10 iters), loss = 8.70629
I0522 23:02:20.195542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70629 (* 1 = 8.70629 loss)
I0522 23:02:21.004873 34819 sgd_solver.cpp:112] Iteration 8310, lr = 0.01
I0522 23:02:26.750687 34819 solver.cpp:239] Iteration 8320 (1.52558 iter/s, 6.55487s/10 iters), loss = 8.85295
I0522 23:02:26.750777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85295 (* 1 = 8.85295 loss)
I0522 23:02:27.483789 34819 sgd_solver.cpp:112] Iteration 8320, lr = 0.01
I0522 23:02:31.531188 34819 solver.cpp:239] Iteration 8330 (2.09196 iter/s, 4.78021s/10 iters), loss = 8.73788
I0522 23:02:31.531312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73788 (* 1 = 8.73788 loss)
I0522 23:02:32.111250 34819 sgd_solver.cpp:112] Iteration 8330, lr = 0.01
I0522 23:02:36.377678 34819 solver.cpp:239] Iteration 8340 (2.06349 iter/s, 4.84617s/10 iters), loss = 8.92537
I0522 23:02:36.377722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92537 (* 1 = 8.92537 loss)
I0522 23:02:37.078737 34819 sgd_solver.cpp:112] Iteration 8340, lr = 0.01
I0522 23:02:41.218902 34819 solver.cpp:239] Iteration 8350 (2.0657 iter/s, 4.84098s/10 iters), loss = 8.93059
I0522 23:02:41.218967 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93059 (* 1 = 8.93059 loss)
I0522 23:02:41.280539 34819 sgd_solver.cpp:112] Iteration 8350, lr = 0.01
I0522 23:02:47.104374 34819 solver.cpp:239] Iteration 8360 (1.69919 iter/s, 5.88515s/10 iters), loss = 8.82299
I0522 23:02:47.104426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82299 (* 1 = 8.82299 loss)
I0522 23:02:47.179095 34819 sgd_solver.cpp:112] Iteration 8360, lr = 0.01
I0522 23:02:50.508416 34819 solver.cpp:239] Iteration 8370 (2.93785 iter/s, 3.40385s/10 iters), loss = 9.21142
I0522 23:02:50.508461 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21142 (* 1 = 9.21142 loss)
I0522 23:02:51.085309 34819 sgd_solver.cpp:112] Iteration 8370, lr = 0.01
I0522 23:02:55.005519 34819 solver.cpp:239] Iteration 8380 (2.22377 iter/s, 4.49686s/10 iters), loss = 8.68742
I0522 23:02:55.005584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68742 (* 1 = 8.68742 loss)
I0522 23:02:55.083835 34819 sgd_solver.cpp:112] Iteration 8380, lr = 0.01
I0522 23:02:59.808593 34819 solver.cpp:239] Iteration 8390 (2.08212 iter/s, 4.8028s/10 iters), loss = 8.87826
I0522 23:02:59.808656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87826 (* 1 = 8.87826 loss)
I0522 23:02:59.881371 34819 sgd_solver.cpp:112] Iteration 8390, lr = 0.01
I0522 23:03:04.830479 34819 solver.cpp:239] Iteration 8400 (1.99139 iter/s, 5.02161s/10 iters), loss = 8.51619
I0522 23:03:04.830688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51619 (* 1 = 8.51619 loss)
I0522 23:03:05.682767 34819 sgd_solver.cpp:112] Iteration 8400, lr = 0.01
I0522 23:03:11.262305 34819 solver.cpp:239] Iteration 8410 (1.55489 iter/s, 6.43134s/10 iters), loss = 8.92388
I0522 23:03:11.262382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92388 (* 1 = 8.92388 loss)
I0522 23:03:11.329005 34819 sgd_solver.cpp:112] Iteration 8410, lr = 0.01
I0522 23:03:15.895488 34819 solver.cpp:239] Iteration 8420 (2.15847 iter/s, 4.6329s/10 iters), loss = 8.94077
I0522 23:03:15.895557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94077 (* 1 = 8.94077 loss)
I0522 23:03:16.731079 34819 sgd_solver.cpp:112] Iteration 8420, lr = 0.01
I0522 23:03:21.221145 34819 solver.cpp:239] Iteration 8430 (1.8778 iter/s, 5.32537s/10 iters), loss = 9.10433
I0522 23:03:21.221200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10433 (* 1 = 9.10433 loss)
I0522 23:03:21.307576 34819 sgd_solver.cpp:112] Iteration 8430, lr = 0.01
I0522 23:03:25.204797 34819 solver.cpp:239] Iteration 8440 (2.5132 iter/s, 3.97899s/10 iters), loss = 8.75433
I0522 23:03:25.204861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75433 (* 1 = 8.75433 loss)
I0522 23:03:25.279660 34819 sgd_solver.cpp:112] Iteration 8440, lr = 0.01
I0522 23:03:31.542677 34819 solver.cpp:239] Iteration 8450 (1.5779 iter/s, 6.33754s/10 iters), loss = 8.75158
I0522 23:03:31.542757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75158 (* 1 = 8.75158 loss)
I0522 23:03:31.608218 34819 sgd_solver.cpp:112] Iteration 8450, lr = 0.01
I0522 23:03:34.428833 34819 solver.cpp:239] Iteration 8460 (3.46507 iter/s, 2.88594s/10 iters), loss = 9.30925
I0522 23:03:34.428877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30925 (* 1 = 9.30925 loss)
I0522 23:03:34.499313 34819 sgd_solver.cpp:112] Iteration 8460, lr = 0.01
I0522 23:03:37.762975 34819 solver.cpp:239] Iteration 8470 (2.99946 iter/s, 3.33393s/10 iters), loss = 8.49352
I0522 23:03:37.763216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49352 (* 1 = 8.49352 loss)
I0522 23:03:38.570010 34819 sgd_solver.cpp:112] Iteration 8470, lr = 0.01
I0522 23:03:43.867910 34819 solver.cpp:239] Iteration 8480 (1.63815 iter/s, 6.10446s/10 iters), loss = 9.08012
I0522 23:03:43.867976 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08012 (* 1 = 9.08012 loss)
I0522 23:03:44.702100 34819 sgd_solver.cpp:112] Iteration 8480, lr = 0.01
I0522 23:03:48.685978 34819 solver.cpp:239] Iteration 8490 (2.07564 iter/s, 4.81779s/10 iters), loss = 9.51442
I0522 23:03:48.686048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51442 (* 1 = 9.51442 loss)
I0522 23:03:48.754724 34819 sgd_solver.cpp:112] Iteration 8490, lr = 0.01
I0522 23:03:53.588203 34819 solver.cpp:239] Iteration 8500 (2.04 iter/s, 4.90195s/10 iters), loss = 8.5901
I0522 23:03:53.588258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5901 (* 1 = 8.5901 loss)
I0522 23:03:54.285444 34819 sgd_solver.cpp:112] Iteration 8500, lr = 0.01
I0522 23:03:57.629048 34819 solver.cpp:239] Iteration 8510 (2.47487 iter/s, 4.04062s/10 iters), loss = 9.14228
I0522 23:03:57.629112 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14228 (* 1 = 9.14228 loss)
I0522 23:03:58.287277 34819 sgd_solver.cpp:112] Iteration 8510, lr = 0.01
I0522 23:04:03.833616 34819 solver.cpp:239] Iteration 8520 (1.6118 iter/s, 6.20423s/10 iters), loss = 9.12306
I0522 23:04:03.833685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12306 (* 1 = 9.12306 loss)
I0522 23:04:04.642320 34819 sgd_solver.cpp:112] Iteration 8520, lr = 0.01
I0522 23:04:07.261968 34819 solver.cpp:239] Iteration 8530 (2.91704 iter/s, 3.42814s/10 iters), loss = 9.8036
I0522 23:04:07.262018 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.8036 (* 1 = 9.8036 loss)
I0522 23:04:07.339049 34819 sgd_solver.cpp:112] Iteration 8530, lr = 0.01
I0522 23:04:11.376896 34819 solver.cpp:239] Iteration 8540 (2.43031 iter/s, 4.1147s/10 iters), loss = 9.04069
I0522 23:04:11.377085 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04069 (* 1 = 9.04069 loss)
I0522 23:04:11.454758 34819 sgd_solver.cpp:112] Iteration 8540, lr = 0.01
I0522 23:04:16.259799 34819 solver.cpp:239] Iteration 8550 (2.04813 iter/s, 4.88251s/10 iters), loss = 8.71582
I0522 23:04:16.259866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71582 (* 1 = 8.71582 loss)
I0522 23:04:16.955482 34819 sgd_solver.cpp:112] Iteration 8550, lr = 0.01
I0522 23:04:22.651971 34819 solver.cpp:239] Iteration 8560 (1.5645 iter/s, 6.39184s/10 iters), loss = 9.6404
I0522 23:04:22.652020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6404 (* 1 = 9.6404 loss)
I0522 23:04:22.709430 34819 sgd_solver.cpp:112] Iteration 8560, lr = 0.01
I0522 23:04:25.181376 34819 solver.cpp:239] Iteration 8570 (3.95377 iter/s, 2.52923s/10 iters), loss = 8.6896
I0522 23:04:25.181448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6896 (* 1 = 8.6896 loss)
I0522 23:04:25.985046 34819 sgd_solver.cpp:112] Iteration 8570, lr = 0.01
I0522 23:04:30.032925 34819 solver.cpp:239] Iteration 8580 (2.06132 iter/s, 4.85125s/10 iters), loss = 9.21311
I0522 23:04:30.032994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21311 (* 1 = 9.21311 loss)
I0522 23:04:30.788666 34819 sgd_solver.cpp:112] Iteration 8580, lr = 0.01
I0522 23:04:35.364008 34819 solver.cpp:239] Iteration 8590 (1.87589 iter/s, 5.33079s/10 iters), loss = 9.49684
I0522 23:04:35.364063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49684 (* 1 = 9.49684 loss)
I0522 23:04:36.123051 34819 sgd_solver.cpp:112] Iteration 8590, lr = 0.01
I0522 23:04:40.784852 34819 solver.cpp:239] Iteration 8600 (1.84483 iter/s, 5.42055s/10 iters), loss = 8.66745
I0522 23:04:40.784916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66745 (* 1 = 8.66745 loss)
I0522 23:04:40.848387 34819 sgd_solver.cpp:112] Iteration 8600, lr = 0.01
I0522 23:04:45.764863 34819 solver.cpp:239] Iteration 8610 (2.00814 iter/s, 4.97973s/10 iters), loss = 9.04946
I0522 23:04:45.765028 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04946 (* 1 = 9.04946 loss)
I0522 23:04:45.839691 34819 sgd_solver.cpp:112] Iteration 8610, lr = 0.01
I0522 23:04:50.729791 34819 solver.cpp:239] Iteration 8620 (2.01428 iter/s, 4.96455s/10 iters), loss = 8.80395
I0522 23:04:50.729851 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80395 (* 1 = 8.80395 loss)
I0522 23:04:51.487916 34819 sgd_solver.cpp:112] Iteration 8620, lr = 0.01
I0522 23:04:54.509124 34819 solver.cpp:239] Iteration 8630 (2.64612 iter/s, 3.77912s/10 iters), loss = 9.07251
I0522 23:04:54.509166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07251 (* 1 = 9.07251 loss)
I0522 23:04:54.588853 34819 sgd_solver.cpp:112] Iteration 8630, lr = 0.01
I0522 23:04:58.644191 34819 solver.cpp:239] Iteration 8640 (2.41847 iter/s, 4.13485s/10 iters), loss = 9.55735
I0522 23:04:58.644233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55735 (* 1 = 9.55735 loss)
I0522 23:04:59.452939 34819 sgd_solver.cpp:112] Iteration 8640, lr = 0.01
I0522 23:05:04.168591 34819 solver.cpp:239] Iteration 8650 (1.81024 iter/s, 5.52413s/10 iters), loss = 9.29835
I0522 23:05:04.168635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29835 (* 1 = 9.29835 loss)
I0522 23:05:04.234737 34819 sgd_solver.cpp:112] Iteration 8650, lr = 0.01
I0522 23:05:09.245061 34819 solver.cpp:239] Iteration 8660 (1.96998 iter/s, 5.0762s/10 iters), loss = 8.65736
I0522 23:05:09.245118 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65736 (* 1 = 8.65736 loss)
I0522 23:05:10.066820 34819 sgd_solver.cpp:112] Iteration 8660, lr = 0.01
I0522 23:05:12.455797 34819 solver.cpp:239] Iteration 8670 (3.11474 iter/s, 3.21054s/10 iters), loss = 9.4218
I0522 23:05:12.455850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4218 (* 1 = 9.4218 loss)
I0522 23:05:12.513701 34819 sgd_solver.cpp:112] Iteration 8670, lr = 0.01
I0522 23:05:15.876197 34819 solver.cpp:239] Iteration 8680 (2.9238 iter/s, 3.4202s/10 iters), loss = 9.17347
I0522 23:05:15.876363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17347 (* 1 = 9.17347 loss)
I0522 23:05:15.949605 34819 sgd_solver.cpp:112] Iteration 8680, lr = 0.01
I0522 23:05:21.567819 34819 solver.cpp:239] Iteration 8690 (1.75709 iter/s, 5.69122s/10 iters), loss = 9.06114
I0522 23:05:21.567862 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06114 (* 1 = 9.06114 loss)
I0522 23:05:21.640116 34819 sgd_solver.cpp:112] Iteration 8690, lr = 0.01
I0522 23:05:26.556071 34819 solver.cpp:239] Iteration 8700 (2.00481 iter/s, 4.988s/10 iters), loss = 9.5022
I0522 23:05:26.556113 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.5022 (* 1 = 9.5022 loss)
I0522 23:05:27.397459 34819 sgd_solver.cpp:112] Iteration 8700, lr = 0.01
I0522 23:05:32.830263 34819 solver.cpp:239] Iteration 8710 (1.59391 iter/s, 6.27389s/10 iters), loss = 9.34559
I0522 23:05:32.830322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34559 (* 1 = 9.34559 loss)
I0522 23:05:32.912413 34819 sgd_solver.cpp:112] Iteration 8710, lr = 0.01
I0522 23:05:37.393209 34819 solver.cpp:239] Iteration 8720 (2.19169 iter/s, 4.5627s/10 iters), loss = 8.93131
I0522 23:05:37.393254 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93131 (* 1 = 8.93131 loss)
I0522 23:05:37.463850 34819 sgd_solver.cpp:112] Iteration 8720, lr = 0.01
I0522 23:05:43.228119 34819 solver.cpp:239] Iteration 8730 (1.71391 iter/s, 5.83462s/10 iters), loss = 8.21156
I0522 23:05:43.228163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21156 (* 1 = 8.21156 loss)
I0522 23:05:44.064116 34819 sgd_solver.cpp:112] Iteration 8730, lr = 0.01
I0522 23:05:47.456843 34819 solver.cpp:239] Iteration 8740 (2.3649 iter/s, 4.2285s/10 iters), loss = 8.74496
I0522 23:05:47.456964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74496 (* 1 = 8.74496 loss)
I0522 23:05:48.280546 34819 sgd_solver.cpp:112] Iteration 8740, lr = 0.01
I0522 23:05:52.504642 34819 solver.cpp:239] Iteration 8750 (1.98119 iter/s, 5.04746s/10 iters), loss = 9.89366
I0522 23:05:52.504684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.89366 (* 1 = 9.89366 loss)
I0522 23:05:52.579504 34819 sgd_solver.cpp:112] Iteration 8750, lr = 0.01
I0522 23:05:58.305977 34819 solver.cpp:239] Iteration 8760 (1.72383 iter/s, 5.80103s/10 iters), loss = 8.28475
I0522 23:05:58.306037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28475 (* 1 = 8.28475 loss)
I0522 23:05:58.366220 34819 sgd_solver.cpp:112] Iteration 8760, lr = 0.01
I0522 23:06:02.698770 34819 solver.cpp:239] Iteration 8770 (2.27659 iter/s, 4.39254s/10 iters), loss = 9.34057
I0522 23:06:02.698830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34057 (* 1 = 9.34057 loss)
I0522 23:06:03.514971 34819 sgd_solver.cpp:112] Iteration 8770, lr = 0.01
I0522 23:06:07.614933 34819 solver.cpp:239] Iteration 8780 (2.03422 iter/s, 4.9159s/10 iters), loss = 9.09287
I0522 23:06:07.614979 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09287 (* 1 = 9.09287 loss)
I0522 23:06:07.673880 34819 sgd_solver.cpp:112] Iteration 8780, lr = 0.01
I0522 23:06:11.436386 34819 solver.cpp:239] Iteration 8790 (2.61695 iter/s, 3.82124s/10 iters), loss = 9.16146
I0522 23:06:11.436441 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16146 (* 1 = 9.16146 loss)
I0522 23:06:12.150046 34819 sgd_solver.cpp:112] Iteration 8790, lr = 0.01
I0522 23:06:14.532440 34819 solver.cpp:239] Iteration 8800 (3.23014 iter/s, 3.09584s/10 iters), loss = 8.97366
I0522 23:06:14.532482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97366 (* 1 = 8.97366 loss)
I0522 23:06:15.361119 34819 sgd_solver.cpp:112] Iteration 8800, lr = 0.01
I0522 23:06:19.489243 34819 solver.cpp:239] Iteration 8810 (2.01753 iter/s, 4.95655s/10 iters), loss = 9.0184
I0522 23:06:19.489398 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0184 (* 1 = 9.0184 loss)
I0522 23:06:20.323961 34819 sgd_solver.cpp:112] Iteration 8810, lr = 0.01
I0522 23:06:24.345311 34819 solver.cpp:239] Iteration 8820 (2.05943 iter/s, 4.85572s/10 iters), loss = 9.37116
I0522 23:06:24.345352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37116 (* 1 = 9.37116 loss)
I0522 23:06:25.037811 34819 sgd_solver.cpp:112] Iteration 8820, lr = 0.01
I0522 23:06:29.242900 34819 solver.cpp:239] Iteration 8830 (2.04193 iter/s, 4.89734s/10 iters), loss = 8.84
I0522 23:06:29.242966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84 (* 1 = 8.84 loss)
I0522 23:06:29.302657 34819 sgd_solver.cpp:112] Iteration 8830, lr = 0.01
I0522 23:06:33.336022 34819 solver.cpp:239] Iteration 8840 (2.44326 iter/s, 4.09289s/10 iters), loss = 9.33998
I0522 23:06:33.336063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33998 (* 1 = 9.33998 loss)
I0522 23:06:33.409601 34819 sgd_solver.cpp:112] Iteration 8840, lr = 0.01
I0522 23:06:38.334868 34819 solver.cpp:239] Iteration 8850 (2.00057 iter/s, 4.99859s/10 iters), loss = 8.58536
I0522 23:06:38.334923 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58536 (* 1 = 8.58536 loss)
I0522 23:06:39.117223 34819 sgd_solver.cpp:112] Iteration 8850, lr = 0.01
I0522 23:06:43.389111 34819 solver.cpp:239] Iteration 8860 (1.97864 iter/s, 5.05398s/10 iters), loss = 9.14378
I0522 23:06:43.389154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14378 (* 1 = 9.14378 loss)
I0522 23:06:43.925912 34819 sgd_solver.cpp:112] Iteration 8860, lr = 0.01
I0522 23:06:48.736548 34819 solver.cpp:239] Iteration 8870 (1.87015 iter/s, 5.34717s/10 iters), loss = 9.05562
I0522 23:06:48.736601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05562 (* 1 = 9.05562 loss)
I0522 23:06:49.585961 34819 sgd_solver.cpp:112] Iteration 8870, lr = 0.01
I0522 23:06:55.057682 34819 solver.cpp:239] Iteration 8880 (1.58208 iter/s, 6.32081s/10 iters), loss = 9.76622
I0522 23:06:55.057747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.76622 (* 1 = 9.76622 loss)
I0522 23:06:55.831035 34819 sgd_solver.cpp:112] Iteration 8880, lr = 0.01
I0522 23:07:01.001004 34819 solver.cpp:239] Iteration 8890 (1.68265 iter/s, 5.94301s/10 iters), loss = 9.26323
I0522 23:07:01.001045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26323 (* 1 = 9.26323 loss)
I0522 23:07:01.077611 34819 sgd_solver.cpp:112] Iteration 8890, lr = 0.01
I0522 23:07:04.742291 34819 solver.cpp:239] Iteration 8900 (2.67302 iter/s, 3.74109s/10 iters), loss = 9.19474
I0522 23:07:04.742334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19474 (* 1 = 9.19474 loss)
I0522 23:07:05.395592 34819 sgd_solver.cpp:112] Iteration 8900, lr = 0.01
I0522 23:07:11.246933 34819 solver.cpp:239] Iteration 8910 (1.53744 iter/s, 6.5043s/10 iters), loss = 9.24735
I0522 23:07:11.246984 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24735 (* 1 = 9.24735 loss)
I0522 23:07:11.465422 34819 sgd_solver.cpp:112] Iteration 8910, lr = 0.01
I0522 23:07:16.013670 34819 solver.cpp:239] Iteration 8920 (2.09798 iter/s, 4.76648s/10 iters), loss = 9.85779
I0522 23:07:16.013726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.85779 (* 1 = 9.85779 loss)
I0522 23:07:16.083376 34819 sgd_solver.cpp:112] Iteration 8920, lr = 0.01
I0522 23:07:19.024224 34819 solver.cpp:239] Iteration 8930 (3.32187 iter/s, 3.01035s/10 iters), loss = 9.87048
I0522 23:07:19.024273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.87048 (* 1 = 9.87048 loss)
I0522 23:07:19.094391 34819 sgd_solver.cpp:112] Iteration 8930, lr = 0.01
I0522 23:07:23.702736 34819 solver.cpp:239] Iteration 8940 (2.13754 iter/s, 4.67827s/10 iters), loss = 8.84287
I0522 23:07:23.702885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84287 (* 1 = 8.84287 loss)
I0522 23:07:24.327960 34819 sgd_solver.cpp:112] Iteration 8940, lr = 0.01
I0522 23:07:28.049183 34819 solver.cpp:239] Iteration 8950 (2.3009 iter/s, 4.34612s/10 iters), loss = 9.1508
I0522 23:07:28.049240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1508 (* 1 = 9.1508 loss)
I0522 23:07:28.117638 34819 sgd_solver.cpp:112] Iteration 8950, lr = 0.01
I0522 23:07:32.334080 34819 solver.cpp:239] Iteration 8960 (2.33391 iter/s, 4.28465s/10 iters), loss = 8.91374
I0522 23:07:32.334125 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91374 (* 1 = 8.91374 loss)
I0522 23:07:32.392304 34819 sgd_solver.cpp:112] Iteration 8960, lr = 0.01
I0522 23:07:35.751325 34819 solver.cpp:239] Iteration 8970 (2.9265 iter/s, 3.41705s/10 iters), loss = 9.38378
I0522 23:07:35.751368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38378 (* 1 = 9.38378 loss)
I0522 23:07:35.812559 34819 sgd_solver.cpp:112] Iteration 8970, lr = 0.01
I0522 23:07:41.557590 34819 solver.cpp:239] Iteration 8980 (1.72237 iter/s, 5.80597s/10 iters), loss = 9.20536
I0522 23:07:41.557646 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20536 (* 1 = 9.20536 loss)
I0522 23:07:41.626476 34819 sgd_solver.cpp:112] Iteration 8980, lr = 0.01
I0522 23:07:44.643961 34819 solver.cpp:239] Iteration 8990 (3.24025 iter/s, 3.08619s/10 iters), loss = 9.87502
I0522 23:07:44.644008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.87502 (* 1 = 9.87502 loss)
I0522 23:07:44.685823 34819 sgd_solver.cpp:112] Iteration 8990, lr = 0.01
I0522 23:07:49.951535 34819 solver.cpp:239] Iteration 9000 (1.88419 iter/s, 5.30731s/10 iters), loss = 9.36092
I0522 23:07:49.951588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36092 (* 1 = 9.36092 loss)
I0522 23:07:50.022368 34819 sgd_solver.cpp:112] Iteration 9000, lr = 0.01
I0522 23:07:55.601503 34819 solver.cpp:239] Iteration 9010 (1.77002 iter/s, 5.64967s/10 iters), loss = 9.3455
I0522 23:07:55.601641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3455 (* 1 = 9.3455 loss)
I0522 23:07:55.675067 34819 sgd_solver.cpp:112] Iteration 9010, lr = 0.01
I0522 23:08:00.692034 34819 solver.cpp:239] Iteration 9020 (1.96456 iter/s, 5.09019s/10 iters), loss = 9.31116
I0522 23:08:00.692077 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31116 (* 1 = 9.31116 loss)
I0522 23:08:00.752679 34819 sgd_solver.cpp:112] Iteration 9020, lr = 0.01
I0522 23:08:04.145404 34819 solver.cpp:239] Iteration 9030 (2.89588 iter/s, 3.45318s/10 iters), loss = 9.49864
I0522 23:08:04.145460 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49864 (* 1 = 9.49864 loss)
I0522 23:08:04.222229 34819 sgd_solver.cpp:112] Iteration 9030, lr = 0.01
I0522 23:08:09.290572 34819 solver.cpp:239] Iteration 9040 (1.94368 iter/s, 5.14488s/10 iters), loss = 8.84651
I0522 23:08:09.290624 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84651 (* 1 = 8.84651 loss)
I0522 23:08:09.365350 34819 sgd_solver.cpp:112] Iteration 9040, lr = 0.01
I0522 23:08:15.259773 34819 solver.cpp:239] Iteration 9050 (1.67535 iter/s, 5.9689s/10 iters), loss = 9.2389
I0522 23:08:15.259826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2389 (* 1 = 9.2389 loss)
I0522 23:08:16.089747 34819 sgd_solver.cpp:112] Iteration 9050, lr = 0.01
I0522 23:08:20.823702 34819 solver.cpp:239] Iteration 9060 (1.79738 iter/s, 5.56365s/10 iters), loss = 8.42705
I0522 23:08:20.823755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42705 (* 1 = 8.42705 loss)
I0522 23:08:20.885094 34819 sgd_solver.cpp:112] Iteration 9060, lr = 0.01
I0522 23:08:25.614393 34819 solver.cpp:239] Iteration 9070 (2.08749 iter/s, 4.79043s/10 iters), loss = 9.07862
I0522 23:08:25.614595 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07862 (* 1 = 9.07862 loss)
I0522 23:08:25.690845 34819 sgd_solver.cpp:112] Iteration 9070, lr = 0.01
I0522 23:08:30.168979 34819 solver.cpp:239] Iteration 9080 (2.19578 iter/s, 4.55419s/10 iters), loss = 9.27991
I0522 23:08:30.169031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27991 (* 1 = 9.27991 loss)
I0522 23:08:30.999899 34819 sgd_solver.cpp:112] Iteration 9080, lr = 0.01
I0522 23:08:37.204272 34819 solver.cpp:239] Iteration 9090 (1.42148 iter/s, 7.03491s/10 iters), loss = 8.7751
I0522 23:08:37.204334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7751 (* 1 = 8.7751 loss)
I0522 23:08:38.056111 34819 sgd_solver.cpp:112] Iteration 9090, lr = 0.01
I0522 23:08:41.139116 34819 solver.cpp:239] Iteration 9100 (2.54154 iter/s, 3.93462s/10 iters), loss = 9.04404
I0522 23:08:41.139164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04404 (* 1 = 9.04404 loss)
I0522 23:08:41.191911 34819 sgd_solver.cpp:112] Iteration 9100, lr = 0.01
I0522 23:08:46.757483 34819 solver.cpp:239] Iteration 9110 (1.77998 iter/s, 5.61805s/10 iters), loss = 9.31417
I0522 23:08:46.757540 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31417 (* 1 = 9.31417 loss)
I0522 23:08:47.455543 34819 sgd_solver.cpp:112] Iteration 9110, lr = 0.01
I0522 23:08:52.438304 34819 solver.cpp:239] Iteration 9120 (1.7604 iter/s, 5.68053s/10 iters), loss = 8.77429
I0522 23:08:52.438347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77429 (* 1 = 8.77429 loss)
I0522 23:08:52.498230 34819 sgd_solver.cpp:112] Iteration 9120, lr = 0.01
I0522 23:08:56.001116 34819 solver.cpp:239] Iteration 9130 (2.80694 iter/s, 3.5626s/10 iters), loss = 9.33976
I0522 23:08:56.001233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33976 (* 1 = 9.33976 loss)
I0522 23:08:56.082015 34819 sgd_solver.cpp:112] Iteration 9130, lr = 0.01
I0522 23:09:01.809800 34819 solver.cpp:239] Iteration 9140 (1.72167 iter/s, 5.80832s/10 iters), loss = 8.6339
I0522 23:09:01.809857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6339 (* 1 = 8.6339 loss)
I0522 23:09:02.581542 34819 sgd_solver.cpp:112] Iteration 9140, lr = 0.01
I0522 23:09:07.852829 34819 solver.cpp:239] Iteration 9150 (1.65489 iter/s, 6.04271s/10 iters), loss = 9.32924
I0522 23:09:07.852895 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32924 (* 1 = 9.32924 loss)
I0522 23:09:07.913885 34819 sgd_solver.cpp:112] Iteration 9150, lr = 0.01
I0522 23:09:14.585543 34819 solver.cpp:239] Iteration 9160 (1.48536 iter/s, 6.73238s/10 iters), loss = 9.19082
I0522 23:09:14.585587 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19082 (* 1 = 9.19082 loss)
I0522 23:09:15.383698 34819 sgd_solver.cpp:112] Iteration 9160, lr = 0.01
I0522 23:09:17.837316 34819 solver.cpp:239] Iteration 9170 (3.07542 iter/s, 3.25159s/10 iters), loss = 9.70703
I0522 23:09:17.837363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70703 (* 1 = 9.70703 loss)
I0522 23:09:18.626875 34819 sgd_solver.cpp:112] Iteration 9170, lr = 0.01
I0522 23:09:22.652012 34819 solver.cpp:239] Iteration 9180 (2.07708 iter/s, 4.81445s/10 iters), loss = 9.00068
I0522 23:09:22.652065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00068 (* 1 = 9.00068 loss)
I0522 23:09:22.731645 34819 sgd_solver.cpp:112] Iteration 9180, lr = 0.01
I0522 23:09:26.955379 34819 solver.cpp:239] Iteration 9190 (2.32389 iter/s, 4.30313s/10 iters), loss = 9.02737
I0522 23:09:26.955570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02737 (* 1 = 9.02737 loss)
I0522 23:09:27.019812 34819 sgd_solver.cpp:112] Iteration 9190, lr = 0.01
I0522 23:09:31.024997 34819 solver.cpp:239] Iteration 9200 (2.45745 iter/s, 4.06925s/10 iters), loss = 9.75794
I0522 23:09:31.025054 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75794 (* 1 = 9.75794 loss)
I0522 23:09:31.088104 34819 sgd_solver.cpp:112] Iteration 9200, lr = 0.01
I0522 23:09:36.351502 34819 solver.cpp:239] Iteration 9210 (1.87751 iter/s, 5.32621s/10 iters), loss = 9.28119
I0522 23:09:36.351557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28119 (* 1 = 9.28119 loss)
I0522 23:09:36.406188 34819 sgd_solver.cpp:112] Iteration 9210, lr = 0.01
I0522 23:09:40.562872 34819 solver.cpp:239] Iteration 9220 (2.37467 iter/s, 4.21111s/10 iters), loss = 9.18948
I0522 23:09:40.562940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18948 (* 1 = 9.18948 loss)
I0522 23:09:40.633868 34819 sgd_solver.cpp:112] Iteration 9220, lr = 0.01
I0522 23:09:45.116598 34819 solver.cpp:239] Iteration 9230 (2.19613 iter/s, 4.55347s/10 iters), loss = 9.38828
I0522 23:09:45.116654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38828 (* 1 = 9.38828 loss)
I0522 23:09:45.597170 34819 sgd_solver.cpp:112] Iteration 9230, lr = 0.01
I0522 23:09:52.531710 34819 solver.cpp:239] Iteration 9240 (1.34866 iter/s, 7.41476s/10 iters), loss = 9.08301
I0522 23:09:52.531759 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08301 (* 1 = 9.08301 loss)
I0522 23:09:52.613606 34819 sgd_solver.cpp:112] Iteration 9240, lr = 0.01
I0522 23:09:57.645105 34819 solver.cpp:239] Iteration 9250 (1.95575 iter/s, 5.11313s/10 iters), loss = 8.90258
I0522 23:09:57.645292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90258 (* 1 = 8.90258 loss)
I0522 23:09:57.722446 34819 sgd_solver.cpp:112] Iteration 9250, lr = 0.01
I0522 23:10:01.932647 34819 solver.cpp:239] Iteration 9260 (2.33253 iter/s, 4.28718s/10 iters), loss = 9.79439
I0522 23:10:01.932688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.79439 (* 1 = 9.79439 loss)
I0522 23:10:01.990080 34819 sgd_solver.cpp:112] Iteration 9260, lr = 0.01
I0522 23:10:05.225239 34819 solver.cpp:239] Iteration 9270 (3.0373 iter/s, 3.2924s/10 iters), loss = 9.30036
I0522 23:10:05.225296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30036 (* 1 = 9.30036 loss)
I0522 23:10:06.097353 34819 sgd_solver.cpp:112] Iteration 9270, lr = 0.01
I0522 23:10:10.417244 34819 solver.cpp:239] Iteration 9280 (1.92614 iter/s, 5.19172s/10 iters), loss = 9.42913
I0522 23:10:10.417297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42913 (* 1 = 9.42913 loss)
I0522 23:10:10.485242 34819 sgd_solver.cpp:112] Iteration 9280, lr = 0.01
I0522 23:10:15.252915 34819 solver.cpp:239] Iteration 9290 (2.06807 iter/s, 4.83542s/10 iters), loss = 9.01986
I0522 23:10:15.252964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01986 (* 1 = 9.01986 loss)
I0522 23:10:15.320384 34819 sgd_solver.cpp:112] Iteration 9290, lr = 0.01
I0522 23:10:21.301748 34819 solver.cpp:239] Iteration 9300 (1.6533 iter/s, 6.04852s/10 iters), loss = 9.12967
I0522 23:10:21.301800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12967 (* 1 = 9.12967 loss)
I0522 23:10:21.366845 34819 sgd_solver.cpp:112] Iteration 9300, lr = 0.01
I0522 23:10:27.394312 34819 solver.cpp:239] Iteration 9310 (1.64143 iter/s, 6.09226s/10 iters), loss = 9.18434
I0522 23:10:27.394377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18434 (* 1 = 9.18434 loss)
I0522 23:10:27.463101 34819 sgd_solver.cpp:112] Iteration 9310, lr = 0.01
I0522 23:10:32.379648 34819 solver.cpp:239] Iteration 9320 (2.006 iter/s, 4.98505s/10 iters), loss = 9.41941
I0522 23:10:32.379784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41941 (* 1 = 9.41941 loss)
I0522 23:10:32.454169 34819 sgd_solver.cpp:112] Iteration 9320, lr = 0.01
I0522 23:10:36.640954 34819 solver.cpp:239] Iteration 9330 (2.34689 iter/s, 4.26095s/10 iters), loss = 8.44466
I0522 23:10:36.641005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44466 (* 1 = 8.44466 loss)
I0522 23:10:37.513535 34819 sgd_solver.cpp:112] Iteration 9330, lr = 0.01
I0522 23:10:42.407568 34819 solver.cpp:239] Iteration 9340 (1.73421 iter/s, 5.76631s/10 iters), loss = 9.31568
I0522 23:10:42.407621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31568 (* 1 = 9.31568 loss)
I0522 23:10:42.488214 34819 sgd_solver.cpp:112] Iteration 9340, lr = 0.01
I0522 23:10:45.641582 34819 solver.cpp:239] Iteration 9350 (3.09233 iter/s, 3.23381s/10 iters), loss = 8.78683
I0522 23:10:45.641636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78683 (* 1 = 8.78683 loss)
I0522 23:10:45.721485 34819 sgd_solver.cpp:112] Iteration 9350, lr = 0.01
I0522 23:10:48.865907 34819 solver.cpp:239] Iteration 9360 (3.10161 iter/s, 3.22413s/10 iters), loss = 9.79191
I0522 23:10:48.865958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.79191 (* 1 = 9.79191 loss)
I0522 23:10:48.930558 34819 sgd_solver.cpp:112] Iteration 9360, lr = 0.01
I0522 23:10:53.636560 34819 solver.cpp:239] Iteration 9370 (2.09627 iter/s, 4.77038s/10 iters), loss = 9.55528
I0522 23:10:53.636618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55528 (* 1 = 9.55528 loss)
I0522 23:10:53.707404 34819 sgd_solver.cpp:112] Iteration 9370, lr = 0.01
I0522 23:10:57.085566 34819 solver.cpp:239] Iteration 9380 (2.89956 iter/s, 3.4488s/10 iters), loss = 9.40598
I0522 23:10:57.085621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40598 (* 1 = 9.40598 loss)
I0522 23:10:57.158504 34819 sgd_solver.cpp:112] Iteration 9380, lr = 0.01
I0522 23:11:03.506932 34819 solver.cpp:239] Iteration 9390 (1.55738 iter/s, 6.42104s/10 iters), loss = 8.6349
I0522 23:11:03.507123 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6349 (* 1 = 8.6349 loss)
I0522 23:11:04.235275 34819 sgd_solver.cpp:112] Iteration 9390, lr = 0.01
I0522 23:11:10.442854 34819 solver.cpp:239] Iteration 9400 (1.44187 iter/s, 6.93545s/10 iters), loss = 9.25841
I0522 23:11:10.442909 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25841 (* 1 = 9.25841 loss)
I0522 23:11:10.504045 34819 sgd_solver.cpp:112] Iteration 9400, lr = 0.01
I0522 23:11:17.422453 34819 solver.cpp:239] Iteration 9410 (1.43282 iter/s, 6.97925s/10 iters), loss = 9.34933
I0522 23:11:17.422515 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34933 (* 1 = 9.34933 loss)
I0522 23:11:18.231957 34819 sgd_solver.cpp:112] Iteration 9410, lr = 0.01
I0522 23:11:24.177544 34819 solver.cpp:239] Iteration 9420 (1.48044 iter/s, 6.75474s/10 iters), loss = 9.14876
I0522 23:11:24.177597 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14876 (* 1 = 9.14876 loss)
I0522 23:11:25.022048 34819 sgd_solver.cpp:112] Iteration 9420, lr = 0.01
I0522 23:11:28.461472 34819 solver.cpp:239] Iteration 9430 (2.33443 iter/s, 4.28369s/10 iters), loss = 8.76392
I0522 23:11:28.461529 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76392 (* 1 = 8.76392 loss)
I0522 23:11:28.545476 34819 sgd_solver.cpp:112] Iteration 9430, lr = 0.01
I0522 23:11:32.684449 34819 solver.cpp:239] Iteration 9440 (2.36813 iter/s, 4.22274s/10 iters), loss = 8.93103
I0522 23:11:32.684496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93103 (* 1 = 8.93103 loss)
I0522 23:11:33.512109 34819 sgd_solver.cpp:112] Iteration 9440, lr = 0.01
I0522 23:11:37.231634 34819 solver.cpp:239] Iteration 9450 (2.19928 iter/s, 4.54694s/10 iters), loss = 9.02123
I0522 23:11:37.231688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02123 (* 1 = 9.02123 loss)
I0522 23:11:37.284984 34819 sgd_solver.cpp:112] Iteration 9450, lr = 0.01
I0522 23:11:40.842941 34819 solver.cpp:239] Iteration 9460 (2.76924 iter/s, 3.6111s/10 iters), loss = 9.34861
I0522 23:11:40.842998 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34861 (* 1 = 9.34861 loss)
I0522 23:11:40.912427 34819 sgd_solver.cpp:112] Iteration 9460, lr = 0.01
I0522 23:11:45.800065 34819 solver.cpp:239] Iteration 9470 (2.01741 iter/s, 4.95685s/10 iters), loss = 8.9875
I0522 23:11:45.800122 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9875 (* 1 = 8.9875 loss)
I0522 23:11:45.869980 34819 sgd_solver.cpp:112] Iteration 9470, lr = 0.01
I0522 23:11:49.854955 34819 solver.cpp:239] Iteration 9480 (2.4663 iter/s, 4.05466s/10 iters), loss = 9.29103
I0522 23:11:49.855008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29103 (* 1 = 9.29103 loss)
I0522 23:11:50.696810 34819 sgd_solver.cpp:112] Iteration 9480, lr = 0.01
I0522 23:11:53.629168 34819 solver.cpp:239] Iteration 9490 (2.64971 iter/s, 3.774s/10 iters), loss = 9.13689
I0522 23:11:53.629223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13689 (* 1 = 9.13689 loss)
I0522 23:11:54.446535 34819 sgd_solver.cpp:112] Iteration 9490, lr = 0.01
I0522 23:11:58.790571 34819 solver.cpp:239] Iteration 9500 (1.93756 iter/s, 5.16113s/10 iters), loss = 9.07511
I0522 23:11:58.790614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07511 (* 1 = 9.07511 loss)
I0522 23:11:59.638381 34819 sgd_solver.cpp:112] Iteration 9500, lr = 0.01
I0522 23:12:06.858286 34819 solver.cpp:239] Iteration 9510 (1.23957 iter/s, 8.06734s/10 iters), loss = 9.24353
I0522 23:12:06.858444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24353 (* 1 = 9.24353 loss)
I0522 23:12:06.930250 34819 sgd_solver.cpp:112] Iteration 9510, lr = 0.01
I0522 23:12:10.275797 34819 solver.cpp:239] Iteration 9520 (2.92637 iter/s, 3.4172s/10 iters), loss = 8.50296
I0522 23:12:10.275849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50296 (* 1 = 8.50296 loss)
I0522 23:12:11.146217 34819 sgd_solver.cpp:112] Iteration 9520, lr = 0.01
I0522 23:12:15.621956 34819 solver.cpp:239] Iteration 9530 (1.8706 iter/s, 5.34589s/10 iters), loss = 9.54234
I0522 23:12:15.622014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54234 (* 1 = 9.54234 loss)
I0522 23:12:15.699512 34819 sgd_solver.cpp:112] Iteration 9530, lr = 0.01
I0522 23:12:21.104900 34819 solver.cpp:239] Iteration 9540 (1.82393 iter/s, 5.48265s/10 iters), loss = 9.04633
I0522 23:12:21.104959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04633 (* 1 = 9.04633 loss)
I0522 23:12:21.847935 34819 sgd_solver.cpp:112] Iteration 9540, lr = 0.01
I0522 23:12:26.279891 34819 solver.cpp:239] Iteration 9550 (1.93247 iter/s, 5.17472s/10 iters), loss = 8.92206
I0522 23:12:26.279944 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92206 (* 1 = 8.92206 loss)
I0522 23:12:26.341667 34819 sgd_solver.cpp:112] Iteration 9550, lr = 0.01
I0522 23:12:30.999650 34819 solver.cpp:239] Iteration 9560 (2.11887 iter/s, 4.71949s/10 iters), loss = 9.34467
I0522 23:12:30.999706 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34467 (* 1 = 9.34467 loss)
I0522 23:12:31.631822 34819 sgd_solver.cpp:112] Iteration 9560, lr = 0.01
I0522 23:12:38.133400 34819 solver.cpp:239] Iteration 9570 (1.40186 iter/s, 7.13339s/10 iters), loss = 9.67388
I0522 23:12:38.133543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67388 (* 1 = 9.67388 loss)
I0522 23:12:38.203330 34819 sgd_solver.cpp:112] Iteration 9570, lr = 0.01
I0522 23:12:43.669978 34819 solver.cpp:239] Iteration 9580 (1.80629 iter/s, 5.53621s/10 iters), loss = 9.37774
I0522 23:12:43.670038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37774 (* 1 = 9.37774 loss)
I0522 23:12:44.484262 34819 sgd_solver.cpp:112] Iteration 9580, lr = 0.01
I0522 23:12:49.205035 34819 solver.cpp:239] Iteration 9590 (1.80676 iter/s, 5.53478s/10 iters), loss = 9.4154
I0522 23:12:49.205085 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4154 (* 1 = 9.4154 loss)
I0522 23:12:49.263017 34819 sgd_solver.cpp:112] Iteration 9590, lr = 0.01
I0522 23:12:53.608988 34819 solver.cpp:239] Iteration 9600 (2.27081 iter/s, 4.40372s/10 iters), loss = 9.15157
I0522 23:12:53.609043 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15157 (* 1 = 9.15157 loss)
I0522 23:12:54.308604 34819 sgd_solver.cpp:112] Iteration 9600, lr = 0.01
I0522 23:12:58.008810 34819 solver.cpp:239] Iteration 9610 (2.27295 iter/s, 4.39956s/10 iters), loss = 9.50065
I0522 23:12:58.008882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50065 (* 1 = 9.50065 loss)
I0522 23:12:58.749795 34819 sgd_solver.cpp:112] Iteration 9610, lr = 0.01
I0522 23:13:04.500614 34819 solver.cpp:239] Iteration 9620 (1.54049 iter/s, 6.49145s/10 iters), loss = 8.94251
I0522 23:13:04.500668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94251 (* 1 = 8.94251 loss)
I0522 23:13:04.573807 34819 sgd_solver.cpp:112] Iteration 9620, lr = 0.01
I0522 23:13:09.463160 34819 solver.cpp:239] Iteration 9630 (2.0162 iter/s, 4.95982s/10 iters), loss = 9.58444
I0522 23:13:09.463413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58444 (* 1 = 9.58444 loss)
I0522 23:13:09.534472 34819 sgd_solver.cpp:112] Iteration 9630, lr = 0.01
I0522 23:13:13.439641 34819 solver.cpp:239] Iteration 9640 (2.51504 iter/s, 3.97608s/10 iters), loss = 9.24233
I0522 23:13:13.439694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24233 (* 1 = 9.24233 loss)
I0522 23:13:13.523986 34819 sgd_solver.cpp:112] Iteration 9640, lr = 0.01
I0522 23:13:17.677143 34819 solver.cpp:239] Iteration 9650 (2.36002 iter/s, 4.23726s/10 iters), loss = 9.13159
I0522 23:13:17.677208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13159 (* 1 = 9.13159 loss)
I0522 23:13:18.123008 34819 sgd_solver.cpp:112] Iteration 9650, lr = 0.01
I0522 23:13:24.611459 34819 solver.cpp:239] Iteration 9660 (1.44218 iter/s, 6.93396s/10 iters), loss = 9.4298
I0522 23:13:24.611510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4298 (* 1 = 9.4298 loss)
I0522 23:13:24.673491 34819 sgd_solver.cpp:112] Iteration 9660, lr = 0.01
I0522 23:13:29.513561 34819 solver.cpp:239] Iteration 9670 (2.04005 iter/s, 4.90184s/10 iters), loss = 9.42373
I0522 23:13:29.513613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42373 (* 1 = 9.42373 loss)
I0522 23:13:29.581583 34819 sgd_solver.cpp:112] Iteration 9670, lr = 0.01
I0522 23:13:35.839402 34819 solver.cpp:239] Iteration 9680 (1.5809 iter/s, 6.32553s/10 iters), loss = 9.73114
I0522 23:13:35.839447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.73114 (* 1 = 9.73114 loss)
I0522 23:13:35.904842 34819 sgd_solver.cpp:112] Iteration 9680, lr = 0.01
I0522 23:13:40.765650 34819 solver.cpp:239] Iteration 9690 (2.03005 iter/s, 4.92598s/10 iters), loss = 9.16189
I0522 23:13:40.765895 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16189 (* 1 = 9.16189 loss)
I0522 23:13:41.589818 34819 sgd_solver.cpp:112] Iteration 9690, lr = 0.01
I0522 23:13:45.810768 34819 solver.cpp:239] Iteration 9700 (1.98229 iter/s, 5.04468s/10 iters), loss = 8.3757
I0522 23:13:45.810827 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3757 (* 1 = 8.3757 loss)
I0522 23:13:45.868558 34819 sgd_solver.cpp:112] Iteration 9700, lr = 0.01
I0522 23:13:50.064993 34819 solver.cpp:239] Iteration 9710 (2.35074 iter/s, 4.25399s/10 iters), loss = 9.54682
I0522 23:13:50.065039 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54682 (* 1 = 9.54682 loss)
I0522 23:13:50.119227 34819 sgd_solver.cpp:112] Iteration 9710, lr = 0.01
I0522 23:13:53.533694 34819 solver.cpp:239] Iteration 9720 (2.88309 iter/s, 3.4685s/10 iters), loss = 8.88945
I0522 23:13:53.533746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88945 (* 1 = 8.88945 loss)
I0522 23:13:53.592454 34819 sgd_solver.cpp:112] Iteration 9720, lr = 0.01
I0522 23:13:58.329277 34819 solver.cpp:239] Iteration 9730 (2.08536 iter/s, 4.79533s/10 iters), loss = 9.79886
I0522 23:13:58.329319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.79886 (* 1 = 9.79886 loss)
I0522 23:13:58.386590 34819 sgd_solver.cpp:112] Iteration 9730, lr = 0.01
I0522 23:14:03.899895 34819 solver.cpp:239] Iteration 9740 (1.79522 iter/s, 5.57035s/10 iters), loss = 8.97967
I0522 23:14:03.899940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97967 (* 1 = 8.97967 loss)
I0522 23:14:03.967721 34819 sgd_solver.cpp:112] Iteration 9740, lr = 0.01
I0522 23:14:09.648982 34819 solver.cpp:239] Iteration 9750 (1.73949 iter/s, 5.74881s/10 iters), loss = 9.43379
I0522 23:14:09.649025 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43379 (* 1 = 9.43379 loss)
I0522 23:14:10.218340 34819 sgd_solver.cpp:112] Iteration 9750, lr = 0.01
I0522 23:14:15.702543 34819 solver.cpp:239] Iteration 9760 (1.652 iter/s, 6.05326s/10 iters), loss = 8.93639
I0522 23:14:15.702816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93639 (* 1 = 8.93639 loss)
I0522 23:14:15.771194 34819 sgd_solver.cpp:112] Iteration 9760, lr = 0.01
I0522 23:14:20.714900 34819 solver.cpp:239] Iteration 9770 (1.99526 iter/s, 5.01188s/10 iters), loss = 8.85886
I0522 23:14:20.714951 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85886 (* 1 = 8.85886 loss)
I0522 23:14:21.263187 34819 sgd_solver.cpp:112] Iteration 9770, lr = 0.01
I0522 23:14:24.674448 34819 solver.cpp:239] Iteration 9780 (2.52568 iter/s, 3.95933s/10 iters), loss = 8.9957
I0522 23:14:24.674490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9957 (* 1 = 8.9957 loss)
I0522 23:14:24.728261 34819 sgd_solver.cpp:112] Iteration 9780, lr = 0.01
I0522 23:14:29.592764 34819 solver.cpp:239] Iteration 9790 (2.03333 iter/s, 4.91805s/10 iters), loss = 9.11221
I0522 23:14:29.592833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11221 (* 1 = 9.11221 loss)
I0522 23:14:30.396021 34819 sgd_solver.cpp:112] Iteration 9790, lr = 0.01
I0522 23:14:34.257658 34819 solver.cpp:239] Iteration 9800 (2.14379 iter/s, 4.66464s/10 iters), loss = 9.61954
I0522 23:14:34.257701 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61954 (* 1 = 9.61954 loss)
I0522 23:14:35.078522 34819 sgd_solver.cpp:112] Iteration 9800, lr = 0.01
I0522 23:14:38.454365 34819 solver.cpp:239] Iteration 9810 (2.38295 iter/s, 4.19648s/10 iters), loss = 9.20669
I0522 23:14:38.454423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20669 (* 1 = 9.20669 loss)
I0522 23:14:39.307494 34819 sgd_solver.cpp:112] Iteration 9810, lr = 0.01
I0522 23:14:43.291803 34819 solver.cpp:239] Iteration 9820 (2.06733 iter/s, 4.83717s/10 iters), loss = 8.7451
I0522 23:14:43.291860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7451 (* 1 = 8.7451 loss)
I0522 23:14:43.355549 34819 sgd_solver.cpp:112] Iteration 9820, lr = 0.01
I0522 23:14:47.405676 34819 solver.cpp:239] Iteration 9830 (2.43094 iter/s, 4.11364s/10 iters), loss = 9.32298
I0522 23:14:47.405793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32298 (* 1 = 9.32298 loss)
I0522 23:14:47.462432 34819 sgd_solver.cpp:112] Iteration 9830, lr = 0.01
I0522 23:14:52.342519 34819 solver.cpp:239] Iteration 9840 (2.02572 iter/s, 4.93651s/10 iters), loss = 8.61359
I0522 23:14:52.342566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61359 (* 1 = 8.61359 loss)
I0522 23:14:52.397802 34819 sgd_solver.cpp:112] Iteration 9840, lr = 0.01
I0522 23:14:59.376796 34819 solver.cpp:239] Iteration 9850 (1.42168 iter/s, 7.03393s/10 iters), loss = 10.0692
I0522 23:14:59.376852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0692 (* 1 = 10.0692 loss)
I0522 23:15:00.056056 34819 sgd_solver.cpp:112] Iteration 9850, lr = 0.01
I0522 23:15:03.262483 34819 solver.cpp:239] Iteration 9860 (2.5737 iter/s, 3.88545s/10 iters), loss = 9.30277
I0522 23:15:03.262536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30277 (* 1 = 9.30277 loss)
I0522 23:15:03.334996 34819 sgd_solver.cpp:112] Iteration 9860, lr = 0.01
I0522 23:15:08.765691 34819 solver.cpp:239] Iteration 9870 (1.81721 iter/s, 5.50293s/10 iters), loss = 8.81352
I0522 23:15:08.765745 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81352 (* 1 = 8.81352 loss)
I0522 23:15:08.847693 34819 sgd_solver.cpp:112] Iteration 9870, lr = 0.01
I0522 23:15:13.048995 34819 solver.cpp:239] Iteration 9880 (2.33477 iter/s, 4.28307s/10 iters), loss = 9.24646
I0522 23:15:13.049041 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24646 (* 1 = 9.24646 loss)
I0522 23:15:13.104317 34819 sgd_solver.cpp:112] Iteration 9880, lr = 0.01
I0522 23:15:18.794662 34819 solver.cpp:239] Iteration 9890 (1.74053 iter/s, 5.74538s/10 iters), loss = 9.61068
I0522 23:15:18.794944 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61068 (* 1 = 9.61068 loss)
I0522 23:15:19.321461 34819 sgd_solver.cpp:112] Iteration 9890, lr = 0.01
I0522 23:15:23.313904 34819 solver.cpp:239] Iteration 9900 (2.21298 iter/s, 4.51879s/10 iters), loss = 9.20199
I0522 23:15:23.313957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20199 (* 1 = 9.20199 loss)
I0522 23:15:23.939671 34819 sgd_solver.cpp:112] Iteration 9900, lr = 0.01
I0522 23:15:27.942550 34819 solver.cpp:239] Iteration 9910 (2.16057 iter/s, 4.6284s/10 iters), loss = 9.74165
I0522 23:15:27.942602 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74165 (* 1 = 9.74165 loss)
I0522 23:15:28.839694 34819 sgd_solver.cpp:112] Iteration 9910, lr = 0.01
I0522 23:15:34.286545 34819 solver.cpp:239] Iteration 9920 (1.57637 iter/s, 6.34368s/10 iters), loss = 9.21394
I0522 23:15:34.286598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21394 (* 1 = 9.21394 loss)
I0522 23:15:35.105355 34819 sgd_solver.cpp:112] Iteration 9920, lr = 0.01
I0522 23:15:40.005744 34819 solver.cpp:239] Iteration 9930 (1.74859 iter/s, 5.7189s/10 iters), loss = 9.9221
I0522 23:15:40.005798 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.9221 (* 1 = 9.9221 loss)
I0522 23:15:40.078238 34819 sgd_solver.cpp:112] Iteration 9930, lr = 0.01
I0522 23:15:45.115602 34819 solver.cpp:239] Iteration 9940 (1.95711 iter/s, 5.10959s/10 iters), loss = 9.42597
I0522 23:15:45.115664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42597 (* 1 = 9.42597 loss)
I0522 23:15:45.875341 34819 sgd_solver.cpp:112] Iteration 9940, lr = 0.01
I0522 23:15:51.436619 34819 solver.cpp:239] Iteration 9950 (1.58211 iter/s, 6.32068s/10 iters), loss = 9.52944
I0522 23:15:51.436784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52944 (* 1 = 9.52944 loss)
I0522 23:15:51.511355 34819 sgd_solver.cpp:112] Iteration 9950, lr = 0.01
I0522 23:15:57.107249 34819 solver.cpp:239] Iteration 9960 (1.7636 iter/s, 5.67021s/10 iters), loss = 8.62532
I0522 23:15:57.107316 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62532 (* 1 = 8.62532 loss)
I0522 23:15:57.919286 34819 sgd_solver.cpp:112] Iteration 9960, lr = 0.01
I0522 23:16:02.488592 34819 solver.cpp:239] Iteration 9970 (1.85838 iter/s, 5.38104s/10 iters), loss = 9.05974
I0522 23:16:02.488659 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05974 (* 1 = 9.05974 loss)
I0522 23:16:02.797766 34819 sgd_solver.cpp:112] Iteration 9970, lr = 0.01
I0522 23:16:07.435066 34819 solver.cpp:239] Iteration 9980 (2.02176 iter/s, 4.94619s/10 iters), loss = 9.76601
I0522 23:16:07.435120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.76601 (* 1 = 9.76601 loss)
I0522 23:16:07.506575 34819 sgd_solver.cpp:112] Iteration 9980, lr = 0.01
I0522 23:16:12.384562 34819 solver.cpp:239] Iteration 9990 (2.02051 iter/s, 4.94924s/10 iters), loss = 8.29149
I0522 23:16:12.384606 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29149 (* 1 = 8.29149 loss)
I0522 23:16:12.454991 34819 sgd_solver.cpp:112] Iteration 9990, lr = 0.01
I0522 23:16:16.045044 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_10000.caffemodel
I0522 23:16:17.764683 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_10000.solverstate
I0522 23:16:17.991456 34819 solver.cpp:239] Iteration 10000 (1.7836 iter/s, 5.60663s/10 iters), loss = 8.71673
I0522 23:16:17.991494 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71673 (* 1 = 8.71673 loss)
I0522 23:16:18.064863 34819 sgd_solver.cpp:112] Iteration 10000, lr = 0.01
I0522 23:16:21.374397 34819 solver.cpp:239] Iteration 10010 (2.95619 iter/s, 3.38273s/10 iters), loss = 9.25604
I0522 23:16:21.374456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25604 (* 1 = 9.25604 loss)
I0522 23:16:22.233950 34819 sgd_solver.cpp:112] Iteration 10010, lr = 0.01
I0522 23:16:26.335935 34819 solver.cpp:239] Iteration 10020 (2.01562 iter/s, 4.96125s/10 iters), loss = 9.51683
I0522 23:16:26.335997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51683 (* 1 = 9.51683 loss)
I0522 23:16:27.099501 34819 sgd_solver.cpp:112] Iteration 10020, lr = 0.01
I0522 23:16:32.868372 34819 solver.cpp:239] Iteration 10030 (1.5309 iter/s, 6.5321s/10 iters), loss = 8.72655
I0522 23:16:32.868424 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72655 (* 1 = 8.72655 loss)
I0522 23:16:32.945475 34819 sgd_solver.cpp:112] Iteration 10030, lr = 0.01
I0522 23:16:37.512552 34819 solver.cpp:239] Iteration 10040 (2.15334 iter/s, 4.64394s/10 iters), loss = 9.49354
I0522 23:16:37.512598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49354 (* 1 = 9.49354 loss)
I0522 23:16:37.568408 34819 sgd_solver.cpp:112] Iteration 10040, lr = 0.01
I0522 23:16:42.427930 34819 solver.cpp:239] Iteration 10050 (2.03454 iter/s, 4.91512s/10 iters), loss = 8.82504
I0522 23:16:42.427974 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82504 (* 1 = 8.82504 loss)
I0522 23:16:43.196949 34819 sgd_solver.cpp:112] Iteration 10050, lr = 0.01
I0522 23:16:47.498805 34819 solver.cpp:239] Iteration 10060 (1.97215 iter/s, 5.0706s/10 iters), loss = 9.39207
I0522 23:16:47.498849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39207 (* 1 = 9.39207 loss)
I0522 23:16:47.558197 34819 sgd_solver.cpp:112] Iteration 10060, lr = 0.01
I0522 23:16:52.633417 34819 solver.cpp:239] Iteration 10070 (1.94767 iter/s, 5.13435s/10 iters), loss = 8.62283
I0522 23:16:52.633641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62283 (* 1 = 8.62283 loss)
I0522 23:16:52.695775 34819 sgd_solver.cpp:112] Iteration 10070, lr = 0.01
I0522 23:16:58.348858 34819 solver.cpp:239] Iteration 10080 (1.74978 iter/s, 5.71501s/10 iters), loss = 9.36104
I0522 23:16:58.348912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36104 (* 1 = 9.36104 loss)
I0522 23:16:58.416927 34819 sgd_solver.cpp:112] Iteration 10080, lr = 0.01
I0522 23:17:01.652786 34819 solver.cpp:239] Iteration 10090 (3.0269 iter/s, 3.30371s/10 iters), loss = 9.34838
I0522 23:17:01.652840 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34838 (* 1 = 9.34838 loss)
I0522 23:17:02.382788 34819 sgd_solver.cpp:112] Iteration 10090, lr = 0.01
I0522 23:17:07.380257 34819 solver.cpp:239] Iteration 10100 (1.74606 iter/s, 5.72717s/10 iters), loss = 9.32339
I0522 23:17:07.380317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32339 (* 1 = 9.32339 loss)
I0522 23:17:07.444535 34819 sgd_solver.cpp:112] Iteration 10100, lr = 0.01
I0522 23:17:13.210570 34819 solver.cpp:239] Iteration 10110 (1.71526 iter/s, 5.83002s/10 iters), loss = 9.16338
I0522 23:17:13.210615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16338 (* 1 = 9.16338 loss)
I0522 23:17:13.930733 34819 sgd_solver.cpp:112] Iteration 10110, lr = 0.01
I0522 23:17:18.647009 34819 solver.cpp:239] Iteration 10120 (1.83953 iter/s, 5.43617s/10 iters), loss = 9.21595
I0522 23:17:18.647055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21595 (* 1 = 9.21595 loss)
I0522 23:17:18.702668 34819 sgd_solver.cpp:112] Iteration 10120, lr = 0.01
I0522 23:17:23.818382 34819 solver.cpp:239] Iteration 10130 (1.93382 iter/s, 5.17111s/10 iters), loss = 9.02318
I0522 23:17:23.818533 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02318 (* 1 = 9.02318 loss)
I0522 23:17:23.885222 34819 sgd_solver.cpp:112] Iteration 10130, lr = 0.01
I0522 23:17:28.505488 34819 solver.cpp:239] Iteration 10140 (2.13367 iter/s, 4.68676s/10 iters), loss = 8.62778
I0522 23:17:28.505532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62778 (* 1 = 8.62778 loss)
I0522 23:17:28.562201 34819 sgd_solver.cpp:112] Iteration 10140, lr = 0.01
I0522 23:17:32.655728 34819 solver.cpp:239] Iteration 10150 (2.40963 iter/s, 4.15002s/10 iters), loss = 8.50645
I0522 23:17:32.655786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50645 (* 1 = 8.50645 loss)
I0522 23:17:32.717706 34819 sgd_solver.cpp:112] Iteration 10150, lr = 0.01
I0522 23:17:36.692836 34819 solver.cpp:239] Iteration 10160 (2.47716 iter/s, 4.03687s/10 iters), loss = 9.32757
I0522 23:17:36.692879 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32757 (* 1 = 9.32757 loss)
I0522 23:17:36.770869 34819 sgd_solver.cpp:112] Iteration 10160, lr = 0.01
I0522 23:17:41.616075 34819 solver.cpp:239] Iteration 10170 (2.03129 iter/s, 4.92298s/10 iters), loss = 8.63841
I0522 23:17:41.616130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63841 (* 1 = 8.63841 loss)
I0522 23:17:42.451174 34819 sgd_solver.cpp:112] Iteration 10170, lr = 0.01
I0522 23:17:46.102814 34819 solver.cpp:239] Iteration 10180 (2.22891 iter/s, 4.48649s/10 iters), loss = 9.57942
I0522 23:17:46.102856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57942 (* 1 = 9.57942 loss)
I0522 23:17:46.168822 34819 sgd_solver.cpp:112] Iteration 10180, lr = 0.01
I0522 23:17:49.777022 34819 solver.cpp:239] Iteration 10190 (2.72183 iter/s, 3.674s/10 iters), loss = 9.23403
I0522 23:17:49.777076 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23403 (* 1 = 9.23403 loss)
I0522 23:17:49.837658 34819 sgd_solver.cpp:112] Iteration 10190, lr = 0.01
I0522 23:17:53.174846 34819 solver.cpp:239] Iteration 10200 (2.94324 iter/s, 3.39762s/10 iters), loss = 8.9311
I0522 23:17:53.174888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9311 (* 1 = 8.9311 loss)
I0522 23:17:53.248210 34819 sgd_solver.cpp:112] Iteration 10200, lr = 0.01
I0522 23:17:56.739897 34819 solver.cpp:239] Iteration 10210 (2.80516 iter/s, 3.56485s/10 iters), loss = 8.97483
I0522 23:17:56.740020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97483 (* 1 = 8.97483 loss)
I0522 23:17:57.569424 34819 sgd_solver.cpp:112] Iteration 10210, lr = 0.01
I0522 23:18:03.777369 34819 solver.cpp:239] Iteration 10220 (1.42105 iter/s, 7.03705s/10 iters), loss = 9.22197
I0522 23:18:03.777421 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22197 (* 1 = 9.22197 loss)
I0522 23:18:03.850904 34819 sgd_solver.cpp:112] Iteration 10220, lr = 0.01
I0522 23:18:07.866972 34819 solver.cpp:239] Iteration 10230 (2.44537 iter/s, 4.08937s/10 iters), loss = 8.32936
I0522 23:18:07.867033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32936 (* 1 = 8.32936 loss)
I0522 23:18:08.709213 34819 sgd_solver.cpp:112] Iteration 10230, lr = 0.01
I0522 23:18:14.142196 34819 solver.cpp:239] Iteration 10240 (1.59365 iter/s, 6.2749s/10 iters), loss = 9.14359
I0522 23:18:14.142238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14359 (* 1 = 9.14359 loss)
I0522 23:18:14.955049 34819 sgd_solver.cpp:112] Iteration 10240, lr = 0.01
I0522 23:18:20.543092 34819 solver.cpp:239] Iteration 10250 (1.56236 iter/s, 6.40058s/10 iters), loss = 8.59279
I0522 23:18:20.543143 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59279 (* 1 = 8.59279 loss)
I0522 23:18:20.601534 34819 sgd_solver.cpp:112] Iteration 10250, lr = 0.01
I0522 23:18:23.758091 34819 solver.cpp:239] Iteration 10260 (3.11061 iter/s, 3.21481s/10 iters), loss = 8.94296
I0522 23:18:23.758146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94296 (* 1 = 8.94296 loss)
I0522 23:18:24.625876 34819 sgd_solver.cpp:112] Iteration 10260, lr = 0.01
I0522 23:18:28.901945 34819 solver.cpp:239] Iteration 10270 (1.94417 iter/s, 5.14358s/10 iters), loss = 8.88417
I0522 23:18:28.902137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88417 (* 1 = 8.88417 loss)
I0522 23:18:29.617044 34819 sgd_solver.cpp:112] Iteration 10270, lr = 0.01
I0522 23:18:34.319705 34819 solver.cpp:239] Iteration 10280 (1.84592 iter/s, 5.41735s/10 iters), loss = 9.90312
I0522 23:18:34.319756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.90312 (* 1 = 9.90312 loss)
I0522 23:18:34.891455 34819 sgd_solver.cpp:112] Iteration 10280, lr = 0.01
I0522 23:18:38.923300 34819 solver.cpp:239] Iteration 10290 (2.17233 iter/s, 4.60335s/10 iters), loss = 8.97087
I0522 23:18:38.923353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97087 (* 1 = 8.97087 loss)
I0522 23:18:38.999184 34819 sgd_solver.cpp:112] Iteration 10290, lr = 0.01
I0522 23:18:42.643235 34819 solver.cpp:239] Iteration 10300 (2.68838 iter/s, 3.71971s/10 iters), loss = 9.50649
I0522 23:18:42.643288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50649 (* 1 = 9.50649 loss)
I0522 23:18:42.728399 34819 sgd_solver.cpp:112] Iteration 10300, lr = 0.01
I0522 23:18:46.920635 34819 solver.cpp:239] Iteration 10310 (2.33799 iter/s, 4.27717s/10 iters), loss = 9.2583
I0522 23:18:46.920682 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2583 (* 1 = 9.2583 loss)
I0522 23:18:46.978303 34819 sgd_solver.cpp:112] Iteration 10310, lr = 0.01
I0522 23:18:51.595193 34819 solver.cpp:239] Iteration 10320 (2.13935 iter/s, 4.67431s/10 iters), loss = 9.26298
I0522 23:18:51.595237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26298 (* 1 = 9.26298 loss)
I0522 23:18:51.648380 34819 sgd_solver.cpp:112] Iteration 10320, lr = 0.01
I0522 23:18:54.944247 34819 solver.cpp:239] Iteration 10330 (2.9861 iter/s, 3.34885s/10 iters), loss = 9.34543
I0522 23:18:54.944293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34543 (* 1 = 9.34543 loss)
I0522 23:18:55.775624 34819 sgd_solver.cpp:112] Iteration 10330, lr = 0.01
I0522 23:19:01.012362 34819 solver.cpp:239] Iteration 10340 (1.64804 iter/s, 6.06782s/10 iters), loss = 8.88142
I0522 23:19:01.013763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88142 (* 1 = 8.88142 loss)
I0522 23:19:01.075469 34819 sgd_solver.cpp:112] Iteration 10340, lr = 0.01
I0522 23:19:05.638384 34819 solver.cpp:239] Iteration 10350 (2.16311 iter/s, 4.62298s/10 iters), loss = 8.54706
I0522 23:19:05.638434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54706 (* 1 = 8.54706 loss)
I0522 23:19:06.328308 34819 sgd_solver.cpp:112] Iteration 10350, lr = 0.01
I0522 23:19:10.348188 34819 solver.cpp:239] Iteration 10360 (2.12337 iter/s, 4.70949s/10 iters), loss = 9.45285
I0522 23:19:10.348239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45285 (* 1 = 9.45285 loss)
I0522 23:19:10.920256 34819 sgd_solver.cpp:112] Iteration 10360, lr = 0.01
I0522 23:19:13.258834 34819 solver.cpp:239] Iteration 10370 (3.43588 iter/s, 2.91046s/10 iters), loss = 9.03054
I0522 23:19:13.258885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03054 (* 1 = 9.03054 loss)
I0522 23:19:13.335913 34819 sgd_solver.cpp:112] Iteration 10370, lr = 0.01
I0522 23:19:17.158205 34819 solver.cpp:239] Iteration 10380 (2.56467 iter/s, 3.89914s/10 iters), loss = 8.76784
I0522 23:19:17.158264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76784 (* 1 = 8.76784 loss)
I0522 23:19:17.225546 34819 sgd_solver.cpp:112] Iteration 10380, lr = 0.01
I0522 23:19:21.355453 34819 solver.cpp:239] Iteration 10390 (2.38265 iter/s, 4.19701s/10 iters), loss = 9.13683
I0522 23:19:21.355502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13683 (* 1 = 9.13683 loss)
I0522 23:19:21.416225 34819 sgd_solver.cpp:112] Iteration 10390, lr = 0.01
I0522 23:19:24.842397 34819 solver.cpp:239] Iteration 10400 (2.86802 iter/s, 3.48673s/10 iters), loss = 9.05898
I0522 23:19:24.842458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05898 (* 1 = 9.05898 loss)
I0522 23:19:24.907846 34819 sgd_solver.cpp:112] Iteration 10400, lr = 0.01
I0522 23:19:29.218984 34819 solver.cpp:239] Iteration 10410 (2.28502 iter/s, 4.37632s/10 iters), loss = 9.12223
I0522 23:19:29.219044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12223 (* 1 = 9.12223 loss)
I0522 23:19:30.047737 34819 sgd_solver.cpp:112] Iteration 10410, lr = 0.01
I0522 23:19:35.302232 34819 solver.cpp:239] Iteration 10420 (1.64395 iter/s, 6.08292s/10 iters), loss = 9.87575
I0522 23:19:35.302428 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.87575 (* 1 = 9.87575 loss)
I0522 23:19:35.966924 34819 sgd_solver.cpp:112] Iteration 10420, lr = 0.01
I0522 23:19:41.012500 34819 solver.cpp:239] Iteration 10430 (1.75136 iter/s, 5.70984s/10 iters), loss = 9.65064
I0522 23:19:41.012549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65064 (* 1 = 9.65064 loss)
I0522 23:19:41.084163 34819 sgd_solver.cpp:112] Iteration 10430, lr = 0.01
I0522 23:19:47.006331 34819 solver.cpp:239] Iteration 10440 (1.66847 iter/s, 5.99353s/10 iters), loss = 8.95707
I0522 23:19:47.006376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95707 (* 1 = 8.95707 loss)
I0522 23:19:47.064426 34819 sgd_solver.cpp:112] Iteration 10440, lr = 0.01
I0522 23:19:53.302966 34819 solver.cpp:239] Iteration 10450 (1.58823 iter/s, 6.29633s/10 iters), loss = 9.17099
I0522 23:19:53.303009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17099 (* 1 = 9.17099 loss)
I0522 23:19:54.166787 34819 sgd_solver.cpp:112] Iteration 10450, lr = 0.01
I0522 23:20:00.771188 34819 solver.cpp:239] Iteration 10460 (1.33907 iter/s, 7.46786s/10 iters), loss = 9.30146
I0522 23:20:00.771250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30146 (* 1 = 9.30146 loss)
I0522 23:20:01.618571 34819 sgd_solver.cpp:112] Iteration 10460, lr = 0.01
I0522 23:20:08.016048 34819 solver.cpp:239] Iteration 10470 (1.38036 iter/s, 7.2445s/10 iters), loss = 9.44115
I0522 23:20:08.016230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44115 (* 1 = 9.44115 loss)
I0522 23:20:08.074883 34819 sgd_solver.cpp:112] Iteration 10470, lr = 0.01
I0522 23:20:12.663081 34819 solver.cpp:239] Iteration 10480 (2.15207 iter/s, 4.64668s/10 iters), loss = 9.13137
I0522 23:20:12.663131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13137 (* 1 = 9.13137 loss)
I0522 23:20:13.357061 34819 sgd_solver.cpp:112] Iteration 10480, lr = 0.01
I0522 23:20:16.648823 34819 solver.cpp:239] Iteration 10490 (2.50908 iter/s, 3.98552s/10 iters), loss = 8.36675
I0522 23:20:16.648875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36675 (* 1 = 8.36675 loss)
I0522 23:20:16.728090 34819 sgd_solver.cpp:112] Iteration 10490, lr = 0.01
I0522 23:20:22.843039 34819 solver.cpp:239] Iteration 10500 (1.61449 iter/s, 6.19389s/10 iters), loss = 9.33858
I0522 23:20:22.843107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33858 (* 1 = 9.33858 loss)
I0522 23:20:23.659783 34819 sgd_solver.cpp:112] Iteration 10500, lr = 0.01
I0522 23:20:26.789675 34819 solver.cpp:239] Iteration 10510 (2.53396 iter/s, 3.94639s/10 iters), loss = 8.65971
I0522 23:20:26.789736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65971 (* 1 = 8.65971 loss)
I0522 23:20:27.481894 34819 sgd_solver.cpp:112] Iteration 10510, lr = 0.01
I0522 23:20:29.791254 34819 solver.cpp:239] Iteration 10520 (3.33179 iter/s, 3.00139s/10 iters), loss = 9.18512
I0522 23:20:29.791299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18512 (* 1 = 9.18512 loss)
I0522 23:20:30.485056 34819 sgd_solver.cpp:112] Iteration 10520, lr = 0.01
I0522 23:20:34.332636 34819 solver.cpp:239] Iteration 10530 (2.20209 iter/s, 4.54113s/10 iters), loss = 8.94498
I0522 23:20:34.332690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94498 (* 1 = 8.94498 loss)
I0522 23:20:34.414475 34819 sgd_solver.cpp:112] Iteration 10530, lr = 0.01
I0522 23:20:40.086529 34819 solver.cpp:239] Iteration 10540 (1.73805 iter/s, 5.75359s/10 iters), loss = 9.42489
I0522 23:20:40.086876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42489 (* 1 = 9.42489 loss)
I0522 23:20:40.284438 34819 sgd_solver.cpp:112] Iteration 10540, lr = 0.01
I0522 23:20:43.823797 34819 solver.cpp:239] Iteration 10550 (2.67605 iter/s, 3.73685s/10 iters), loss = 9.05951
I0522 23:20:43.823849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05951 (* 1 = 9.05951 loss)
I0522 23:20:44.194253 34819 sgd_solver.cpp:112] Iteration 10550, lr = 0.01
I0522 23:20:47.512342 34819 solver.cpp:239] Iteration 10560 (2.71125 iter/s, 3.68833s/10 iters), loss = 9.43918
I0522 23:20:47.512401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43918 (* 1 = 9.43918 loss)
I0522 23:20:48.260854 34819 sgd_solver.cpp:112] Iteration 10560, lr = 0.01
I0522 23:20:53.208387 34819 solver.cpp:239] Iteration 10570 (1.7557 iter/s, 5.69575s/10 iters), loss = 8.93373
I0522 23:20:53.208446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93373 (* 1 = 8.93373 loss)
I0522 23:20:54.069198 34819 sgd_solver.cpp:112] Iteration 10570, lr = 0.01
I0522 23:20:59.492238 34819 solver.cpp:239] Iteration 10580 (1.59146 iter/s, 6.28352s/10 iters), loss = 10.0084
I0522 23:20:59.492293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0084 (* 1 = 10.0084 loss)
I0522 23:20:59.580142 34819 sgd_solver.cpp:112] Iteration 10580, lr = 0.01
I0522 23:21:05.799372 34819 solver.cpp:239] Iteration 10590 (1.58558 iter/s, 6.30682s/10 iters), loss = 9.0181
I0522 23:21:05.799427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0181 (* 1 = 9.0181 loss)
I0522 23:21:05.867290 34819 sgd_solver.cpp:112] Iteration 10590, lr = 0.01
I0522 23:21:10.092532 34819 solver.cpp:239] Iteration 10600 (2.32942 iter/s, 4.29291s/10 iters), loss = 9.62801
I0522 23:21:10.092682 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.62801 (* 1 = 9.62801 loss)
I0522 23:21:10.355238 34819 sgd_solver.cpp:112] Iteration 10600, lr = 0.01
I0522 23:21:13.487045 34819 solver.cpp:239] Iteration 10610 (2.94619 iter/s, 3.39422s/10 iters), loss = 8.39697
I0522 23:21:13.487097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39697 (* 1 = 8.39697 loss)
I0522 23:21:13.548375 34819 sgd_solver.cpp:112] Iteration 10610, lr = 0.01
I0522 23:21:18.359954 34819 solver.cpp:239] Iteration 10620 (2.05227 iter/s, 4.87266s/10 iters), loss = 9.64139
I0522 23:21:18.359999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64139 (* 1 = 9.64139 loss)
I0522 23:21:19.061276 34819 sgd_solver.cpp:112] Iteration 10620, lr = 0.01
I0522 23:21:24.287871 34819 solver.cpp:239] Iteration 10630 (1.68702 iter/s, 5.92762s/10 iters), loss = 8.64222
I0522 23:21:24.287919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64222 (* 1 = 8.64222 loss)
I0522 23:21:24.359583 34819 sgd_solver.cpp:112] Iteration 10630, lr = 0.01
I0522 23:21:28.467059 34819 solver.cpp:239] Iteration 10640 (2.39294 iter/s, 4.17896s/10 iters), loss = 9.28039
I0522 23:21:28.467115 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28039 (* 1 = 9.28039 loss)
I0522 23:21:28.538419 34819 sgd_solver.cpp:112] Iteration 10640, lr = 0.01
I0522 23:21:34.229841 34819 solver.cpp:239] Iteration 10650 (1.73537 iter/s, 5.76248s/10 iters), loss = 9.25041
I0522 23:21:34.229887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25041 (* 1 = 9.25041 loss)
I0522 23:21:34.302904 34819 sgd_solver.cpp:112] Iteration 10650, lr = 0.01
I0522 23:21:37.812398 34819 solver.cpp:239] Iteration 10660 (2.79146 iter/s, 3.58236s/10 iters), loss = 9.13222
I0522 23:21:37.812451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13222 (* 1 = 9.13222 loss)
I0522 23:21:37.883097 34819 sgd_solver.cpp:112] Iteration 10660, lr = 0.01
I0522 23:21:42.411729 34819 solver.cpp:239] Iteration 10670 (2.17435 iter/s, 4.59907s/10 iters), loss = 9.31142
I0522 23:21:42.411844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31142 (* 1 = 9.31142 loss)
I0522 23:21:42.490509 34819 sgd_solver.cpp:112] Iteration 10670, lr = 0.01
I0522 23:21:45.688292 34819 solver.cpp:239] Iteration 10680 (3.05222 iter/s, 3.27631s/10 iters), loss = 8.93241
I0522 23:21:45.688357 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93241 (* 1 = 8.93241 loss)
I0522 23:21:46.461061 34819 sgd_solver.cpp:112] Iteration 10680, lr = 0.01
I0522 23:21:51.334750 34819 solver.cpp:239] Iteration 10690 (1.77111 iter/s, 5.64617s/10 iters), loss = 9.4831
I0522 23:21:51.334794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4831 (* 1 = 9.4831 loss)
I0522 23:21:52.106755 34819 sgd_solver.cpp:112] Iteration 10690, lr = 0.01
I0522 23:21:54.609448 34819 solver.cpp:239] Iteration 10700 (3.05389 iter/s, 3.27451s/10 iters), loss = 9.7968
I0522 23:21:54.609513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.7968 (* 1 = 9.7968 loss)
I0522 23:21:54.839982 34819 sgd_solver.cpp:112] Iteration 10700, lr = 0.01
I0522 23:21:59.083287 34819 solver.cpp:239] Iteration 10710 (2.23535 iter/s, 4.47357s/10 iters), loss = 8.7522
I0522 23:21:59.083339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7522 (* 1 = 8.7522 loss)
I0522 23:21:59.153980 34819 sgd_solver.cpp:112] Iteration 10710, lr = 0.01
I0522 23:22:03.308698 34819 solver.cpp:239] Iteration 10720 (2.36678 iter/s, 4.22516s/10 iters), loss = 8.93084
I0522 23:22:03.308758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93084 (* 1 = 8.93084 loss)
I0522 23:22:04.116884 34819 sgd_solver.cpp:112] Iteration 10720, lr = 0.01
I0522 23:22:09.488163 34819 solver.cpp:239] Iteration 10730 (1.61835 iter/s, 6.17914s/10 iters), loss = 9.14444
I0522 23:22:09.488219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14444 (* 1 = 9.14444 loss)
I0522 23:22:10.366858 34819 sgd_solver.cpp:112] Iteration 10730, lr = 0.01
I0522 23:22:13.644524 34819 solver.cpp:239] Iteration 10740 (2.40608 iter/s, 4.15613s/10 iters), loss = 9.37071
I0522 23:22:13.644773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37071 (* 1 = 9.37071 loss)
I0522 23:22:13.704666 34819 sgd_solver.cpp:112] Iteration 10740, lr = 0.01
I0522 23:22:16.822223 34819 solver.cpp:239] Iteration 10750 (3.14729 iter/s, 3.17734s/10 iters), loss = 9.44406
I0522 23:22:16.822269 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44406 (* 1 = 9.44406 loss)
I0522 23:22:17.673534 34819 sgd_solver.cpp:112] Iteration 10750, lr = 0.01
I0522 23:22:22.597635 34819 solver.cpp:239] Iteration 10760 (1.73156 iter/s, 5.77512s/10 iters), loss = 8.80437
I0522 23:22:22.597687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80437 (* 1 = 8.80437 loss)
I0522 23:22:22.851212 34819 sgd_solver.cpp:112] Iteration 10760, lr = 0.01
I0522 23:22:29.363854 34819 solver.cpp:239] Iteration 10770 (1.478 iter/s, 6.76589s/10 iters), loss = 8.97101
I0522 23:22:29.363898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97101 (* 1 = 8.97101 loss)
I0522 23:22:30.202934 34819 sgd_solver.cpp:112] Iteration 10770, lr = 0.01
I0522 23:22:34.340620 34819 solver.cpp:239] Iteration 10780 (2.00944 iter/s, 4.97652s/10 iters), loss = 8.67014
I0522 23:22:34.340664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67014 (* 1 = 8.67014 loss)
I0522 23:22:35.101558 34819 sgd_solver.cpp:112] Iteration 10780, lr = 0.01
I0522 23:22:39.701159 34819 solver.cpp:239] Iteration 10790 (1.86558 iter/s, 5.36027s/10 iters), loss = 8.67304
I0522 23:22:39.701228 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67304 (* 1 = 8.67304 loss)
I0522 23:22:39.760004 34819 sgd_solver.cpp:112] Iteration 10790, lr = 0.01
I0522 23:22:46.368919 34819 solver.cpp:239] Iteration 10800 (1.49983 iter/s, 6.66741s/10 iters), loss = 8.93468
I0522 23:22:46.369135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93468 (* 1 = 8.93468 loss)
I0522 23:22:47.212155 34819 sgd_solver.cpp:112] Iteration 10800, lr = 0.01
I0522 23:22:50.775156 34819 solver.cpp:239] Iteration 10810 (2.26971 iter/s, 4.40586s/10 iters), loss = 8.77929
I0522 23:22:50.775202 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77929 (* 1 = 8.77929 loss)
I0522 23:22:50.847801 34819 sgd_solver.cpp:112] Iteration 10810, lr = 0.01
I0522 23:22:54.722028 34819 solver.cpp:239] Iteration 10820 (2.53379 iter/s, 3.94666s/10 iters), loss = 8.987
I0522 23:22:54.722074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.987 (* 1 = 8.987 loss)
I0522 23:22:54.793375 34819 sgd_solver.cpp:112] Iteration 10820, lr = 0.01
I0522 23:22:59.847158 34819 solver.cpp:239] Iteration 10830 (1.95127 iter/s, 5.12486s/10 iters), loss = 8.86093
I0522 23:22:59.847213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86093 (* 1 = 8.86093 loss)
I0522 23:22:59.914043 34819 sgd_solver.cpp:112] Iteration 10830, lr = 0.01
I0522 23:23:03.749336 34819 solver.cpp:239] Iteration 10840 (2.56282 iter/s, 3.90195s/10 iters), loss = 9.17481
I0522 23:23:03.749378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17481 (* 1 = 9.17481 loss)
I0522 23:23:03.833847 34819 sgd_solver.cpp:112] Iteration 10840, lr = 0.01
I0522 23:23:07.211727 34819 solver.cpp:239] Iteration 10850 (2.88834 iter/s, 3.46219s/10 iters), loss = 9.16217
I0522 23:23:07.211771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16217 (* 1 = 9.16217 loss)
I0522 23:23:08.060031 34819 sgd_solver.cpp:112] Iteration 10850, lr = 0.01
I0522 23:23:12.374799 34819 solver.cpp:239] Iteration 10860 (1.93693 iter/s, 5.16281s/10 iters), loss = 8.73312
I0522 23:23:12.374856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73312 (* 1 = 8.73312 loss)
I0522 23:23:12.437907 34819 sgd_solver.cpp:112] Iteration 10860, lr = 0.01
I0522 23:23:17.795383 34819 solver.cpp:239] Iteration 10870 (1.84491 iter/s, 5.42031s/10 iters), loss = 9.00276
I0522 23:23:17.795553 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00276 (* 1 = 9.00276 loss)
I0522 23:23:18.504250 34819 sgd_solver.cpp:112] Iteration 10870, lr = 0.01
I0522 23:23:21.251303 34819 solver.cpp:239] Iteration 10880 (2.89386 iter/s, 3.45559s/10 iters), loss = 8.44749
I0522 23:23:21.251358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44749 (* 1 = 8.44749 loss)
I0522 23:23:21.319659 34819 sgd_solver.cpp:112] Iteration 10880, lr = 0.01
I0522 23:23:27.437207 34819 solver.cpp:239] Iteration 10890 (1.61666 iter/s, 6.18558s/10 iters), loss = 9.7604
I0522 23:23:27.437261 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.7604 (* 1 = 9.7604 loss)
I0522 23:23:28.173213 34819 sgd_solver.cpp:112] Iteration 10890, lr = 0.01
I0522 23:23:33.064338 34819 solver.cpp:239] Iteration 10900 (1.7772 iter/s, 5.62684s/10 iters), loss = 8.92769
I0522 23:23:33.064385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92769 (* 1 = 8.92769 loss)
I0522 23:23:33.127681 34819 sgd_solver.cpp:112] Iteration 10900, lr = 0.01
I0522 23:23:36.719877 34819 solver.cpp:239] Iteration 10910 (2.73573 iter/s, 3.65533s/10 iters), loss = 9.1312
I0522 23:23:36.719919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1312 (* 1 = 9.1312 loss)
I0522 23:23:36.784673 34819 sgd_solver.cpp:112] Iteration 10910, lr = 0.01
I0522 23:23:41.319789 34819 solver.cpp:239] Iteration 10920 (2.17407 iter/s, 4.59967s/10 iters), loss = 8.58743
I0522 23:23:41.319833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58743 (* 1 = 8.58743 loss)
I0522 23:23:41.384881 34819 sgd_solver.cpp:112] Iteration 10920, lr = 0.01
I0522 23:23:44.706306 34819 solver.cpp:239] Iteration 10930 (2.95306 iter/s, 3.38632s/10 iters), loss = 8.73318
I0522 23:23:44.706358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73318 (* 1 = 8.73318 loss)
I0522 23:23:44.772928 34819 sgd_solver.cpp:112] Iteration 10930, lr = 0.01
I0522 23:23:48.389950 34819 solver.cpp:239] Iteration 10940 (2.71486 iter/s, 3.68343s/10 iters), loss = 8.78958
I0522 23:23:48.390059 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78958 (* 1 = 8.78958 loss)
I0522 23:23:48.460577 34819 sgd_solver.cpp:112] Iteration 10940, lr = 0.01
I0522 23:23:51.186214 34819 solver.cpp:239] Iteration 10950 (3.5765 iter/s, 2.79603s/10 iters), loss = 9.50479
I0522 23:23:51.186262 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50479 (* 1 = 9.50479 loss)
I0522 23:23:51.266901 34819 sgd_solver.cpp:112] Iteration 10950, lr = 0.01
I0522 23:23:56.741379 34819 solver.cpp:239] Iteration 10960 (1.80022 iter/s, 5.55488s/10 iters), loss = 9.10813
I0522 23:23:56.741439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10813 (* 1 = 9.10813 loss)
I0522 23:23:57.601104 34819 sgd_solver.cpp:112] Iteration 10960, lr = 0.01
I0522 23:24:01.876299 34819 solver.cpp:239] Iteration 10970 (1.94755 iter/s, 5.13465s/10 iters), loss = 8.99869
I0522 23:24:01.876343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99869 (* 1 = 8.99869 loss)
I0522 23:24:01.938302 34819 sgd_solver.cpp:112] Iteration 10970, lr = 0.01
I0522 23:24:07.585209 34819 solver.cpp:239] Iteration 10980 (1.75173 iter/s, 5.70863s/10 iters), loss = 9.74068
I0522 23:24:07.585265 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74068 (* 1 = 9.74068 loss)
I0522 23:24:07.656792 34819 sgd_solver.cpp:112] Iteration 10980, lr = 0.01
I0522 23:24:12.475811 34819 solver.cpp:239] Iteration 10990 (2.04485 iter/s, 4.89034s/10 iters), loss = 8.90729
I0522 23:24:12.475867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90729 (* 1 = 8.90729 loss)
I0522 23:24:13.258898 34819 sgd_solver.cpp:112] Iteration 10990, lr = 0.01
I0522 23:24:20.398067 34819 solver.cpp:239] Iteration 11000 (1.26233 iter/s, 7.92186s/10 iters), loss = 8.73674
I0522 23:24:20.398252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73674 (* 1 = 8.73674 loss)
I0522 23:24:20.470649 34819 sgd_solver.cpp:112] Iteration 11000, lr = 0.01
I0522 23:24:22.936906 34819 solver.cpp:239] Iteration 11010 (3.93927 iter/s, 2.53854s/10 iters), loss = 9.09077
I0522 23:24:22.936964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09077 (* 1 = 9.09077 loss)
I0522 23:24:23.743369 34819 sgd_solver.cpp:112] Iteration 11010, lr = 0.01
I0522 23:24:28.649521 34819 solver.cpp:239] Iteration 11020 (1.7506 iter/s, 5.71232s/10 iters), loss = 9.57053
I0522 23:24:28.649577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57053 (* 1 = 9.57053 loss)
I0522 23:24:28.737401 34819 sgd_solver.cpp:112] Iteration 11020, lr = 0.01
I0522 23:24:32.663837 34819 solver.cpp:239] Iteration 11030 (2.49123 iter/s, 4.01409s/10 iters), loss = 9.80085
I0522 23:24:32.663883 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.80085 (* 1 = 9.80085 loss)
I0522 23:24:32.740581 34819 sgd_solver.cpp:112] Iteration 11030, lr = 0.01
I0522 23:24:38.218127 34819 solver.cpp:239] Iteration 11040 (1.8005 iter/s, 5.55401s/10 iters), loss = 8.68791
I0522 23:24:38.218169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68791 (* 1 = 8.68791 loss)
I0522 23:24:38.290314 34819 sgd_solver.cpp:112] Iteration 11040, lr = 0.01
I0522 23:24:41.679697 34819 solver.cpp:239] Iteration 11050 (2.88903 iter/s, 3.46137s/10 iters), loss = 10.113
I0522 23:24:41.679749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.113 (* 1 = 10.113 loss)
I0522 23:24:42.479770 34819 sgd_solver.cpp:112] Iteration 11050, lr = 0.01
I0522 23:24:48.081403 34819 solver.cpp:239] Iteration 11060 (1.56216 iter/s, 6.40139s/10 iters), loss = 8.48687
I0522 23:24:48.081446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48687 (* 1 = 8.48687 loss)
I0522 23:24:48.928133 34819 sgd_solver.cpp:112] Iteration 11060, lr = 0.01
I0522 23:24:51.464442 34819 solver.cpp:239] Iteration 11070 (2.95609 iter/s, 3.38285s/10 iters), loss = 9.04449
I0522 23:24:51.464597 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04449 (* 1 = 9.04449 loss)
I0522 23:24:51.529531 34819 sgd_solver.cpp:112] Iteration 11070, lr = 0.01
I0522 23:24:55.739806 34819 solver.cpp:239] Iteration 11080 (2.33917 iter/s, 4.27502s/10 iters), loss = 9.05847
I0522 23:24:55.739861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05847 (* 1 = 9.05847 loss)
I0522 23:24:56.563287 34819 sgd_solver.cpp:112] Iteration 11080, lr = 0.01
I0522 23:25:02.144304 34819 solver.cpp:239] Iteration 11090 (1.56148 iter/s, 6.40418s/10 iters), loss = 9.47657
I0522 23:25:02.144346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47657 (* 1 = 9.47657 loss)
I0522 23:25:02.954622 34819 sgd_solver.cpp:112] Iteration 11090, lr = 0.01
I0522 23:25:05.700572 34819 solver.cpp:239] Iteration 11100 (2.8121 iter/s, 3.55607s/10 iters), loss = 8.96989
I0522 23:25:05.700618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96989 (* 1 = 8.96989 loss)
I0522 23:25:06.481986 34819 sgd_solver.cpp:112] Iteration 11100, lr = 0.01
I0522 23:25:11.763510 34819 solver.cpp:239] Iteration 11110 (1.64945 iter/s, 6.06261s/10 iters), loss = 9.08013
I0522 23:25:11.763556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08013 (* 1 = 9.08013 loss)
I0522 23:25:12.555846 34819 sgd_solver.cpp:112] Iteration 11110, lr = 0.01
I0522 23:25:17.311544 34819 solver.cpp:239] Iteration 11120 (1.80253 iter/s, 5.54776s/10 iters), loss = 9.52556
I0522 23:25:17.311585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52556 (* 1 = 9.52556 loss)
I0522 23:25:17.386942 34819 sgd_solver.cpp:112] Iteration 11120, lr = 0.01
I0522 23:25:22.386348 34819 solver.cpp:239] Iteration 11130 (1.97062 iter/s, 5.07454s/10 iters), loss = 9.19811
I0522 23:25:22.386481 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19811 (* 1 = 9.19811 loss)
I0522 23:25:22.464217 34819 sgd_solver.cpp:112] Iteration 11130, lr = 0.01
I0522 23:25:28.029156 34819 solver.cpp:239] Iteration 11140 (1.77228 iter/s, 5.64245s/10 iters), loss = 9.51966
I0522 23:25:28.029201 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51966 (* 1 = 9.51966 loss)
I0522 23:25:28.875586 34819 sgd_solver.cpp:112] Iteration 11140, lr = 0.01
I0522 23:25:33.568423 34819 solver.cpp:239] Iteration 11150 (1.80538 iter/s, 5.53899s/10 iters), loss = 9.35264
I0522 23:25:33.568464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35264 (* 1 = 9.35264 loss)
I0522 23:25:33.626420 34819 sgd_solver.cpp:112] Iteration 11150, lr = 0.01
I0522 23:25:38.499440 34819 solver.cpp:239] Iteration 11160 (2.0281 iter/s, 4.93072s/10 iters), loss = 9.17712
I0522 23:25:38.499507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17712 (* 1 = 9.17712 loss)
I0522 23:25:39.252219 34819 sgd_solver.cpp:112] Iteration 11160, lr = 0.01
I0522 23:25:42.674533 34819 solver.cpp:239] Iteration 11170 (2.3953 iter/s, 4.17484s/10 iters), loss = 9.28402
I0522 23:25:42.674602 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28402 (* 1 = 9.28402 loss)
I0522 23:25:43.455273 34819 sgd_solver.cpp:112] Iteration 11170, lr = 0.01
I0522 23:25:46.921517 34819 solver.cpp:239] Iteration 11180 (2.35477 iter/s, 4.2467s/10 iters), loss = 9.46571
I0522 23:25:46.921571 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46571 (* 1 = 9.46571 loss)
I0522 23:25:46.978372 34819 sgd_solver.cpp:112] Iteration 11180, lr = 0.01
I0522 23:25:52.984966 34819 solver.cpp:239] Iteration 11190 (1.64931 iter/s, 6.06314s/10 iters), loss = 8.01878
I0522 23:25:52.985184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01878 (* 1 = 8.01878 loss)
I0522 23:25:53.736327 34819 sgd_solver.cpp:112] Iteration 11190, lr = 0.01
I0522 23:26:01.202473 34819 solver.cpp:239] Iteration 11200 (1.21699 iter/s, 8.21698s/10 iters), loss = 9.37813
I0522 23:26:01.202529 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37813 (* 1 = 9.37813 loss)
I0522 23:26:02.059253 34819 sgd_solver.cpp:112] Iteration 11200, lr = 0.01
I0522 23:26:09.718825 34819 solver.cpp:239] Iteration 11210 (1.17427 iter/s, 8.51595s/10 iters), loss = 8.56384
I0522 23:26:09.718876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56384 (* 1 = 8.56384 loss)
I0522 23:26:09.787297 34819 sgd_solver.cpp:112] Iteration 11210, lr = 0.01
I0522 23:26:13.296175 34819 solver.cpp:239] Iteration 11220 (2.79553 iter/s, 3.57714s/10 iters), loss = 8.68655
I0522 23:26:13.296221 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68655 (* 1 = 8.68655 loss)
I0522 23:26:13.371242 34819 sgd_solver.cpp:112] Iteration 11220, lr = 0.01
I0522 23:26:17.525261 34819 solver.cpp:239] Iteration 11230 (2.36471 iter/s, 4.22886s/10 iters), loss = 9.58793
I0522 23:26:17.525331 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58793 (* 1 = 9.58793 loss)
I0522 23:26:18.363696 34819 sgd_solver.cpp:112] Iteration 11230, lr = 0.01
I0522 23:26:23.597375 34819 solver.cpp:239] Iteration 11240 (1.64696 iter/s, 6.0718s/10 iters), loss = 9.48285
I0522 23:26:23.597510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48285 (* 1 = 9.48285 loss)
I0522 23:26:24.459148 34819 sgd_solver.cpp:112] Iteration 11240, lr = 0.01
I0522 23:26:28.437233 34819 solver.cpp:239] Iteration 11250 (2.06632 iter/s, 4.83952s/10 iters), loss = 8.46378
I0522 23:26:28.437279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46378 (* 1 = 8.46378 loss)
I0522 23:26:29.308048 34819 sgd_solver.cpp:112] Iteration 11250, lr = 0.01
I0522 23:26:35.483814 34819 solver.cpp:239] Iteration 11260 (1.4192 iter/s, 7.04625s/10 iters), loss = 8.63531
I0522 23:26:35.483866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63531 (* 1 = 8.63531 loss)
I0522 23:26:35.555497 34819 sgd_solver.cpp:112] Iteration 11260, lr = 0.01
I0522 23:26:39.375428 34819 solver.cpp:239] Iteration 11270 (2.56977 iter/s, 3.8914s/10 iters), loss = 9.28745
I0522 23:26:39.375468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28745 (* 1 = 9.28745 loss)
I0522 23:26:39.429014 34819 sgd_solver.cpp:112] Iteration 11270, lr = 0.01
I0522 23:26:43.350498 34819 solver.cpp:239] Iteration 11280 (2.51581 iter/s, 3.97486s/10 iters), loss = 8.45375
I0522 23:26:43.350550 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45375 (* 1 = 8.45375 loss)
I0522 23:26:43.415227 34819 sgd_solver.cpp:112] Iteration 11280, lr = 0.01
I0522 23:26:48.244123 34819 solver.cpp:239] Iteration 11290 (2.04359 iter/s, 4.89336s/10 iters), loss = 9.09971
I0522 23:26:48.244165 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09971 (* 1 = 9.09971 loss)
I0522 23:26:48.890442 34819 sgd_solver.cpp:112] Iteration 11290, lr = 0.01
I0522 23:26:53.483399 34819 solver.cpp:239] Iteration 11300 (1.90876 iter/s, 5.23899s/10 iters), loss = 9.71545
I0522 23:26:53.483461 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71545 (* 1 = 9.71545 loss)
I0522 23:26:54.267033 34819 sgd_solver.cpp:112] Iteration 11300, lr = 0.01
I0522 23:26:56.950330 34819 solver.cpp:239] Iteration 11310 (2.88457 iter/s, 3.46672s/10 iters), loss = 8.41015
I0522 23:26:56.950387 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41015 (* 1 = 8.41015 loss)
I0522 23:26:57.025182 34819 sgd_solver.cpp:112] Iteration 11310, lr = 0.01
I0522 23:27:01.676463 34819 solver.cpp:239] Iteration 11320 (2.11601 iter/s, 4.72588s/10 iters), loss = 8.90614
I0522 23:27:01.676506 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90614 (* 1 = 8.90614 loss)
I0522 23:27:01.748605 34819 sgd_solver.cpp:112] Iteration 11320, lr = 0.01
I0522 23:27:05.135188 34819 solver.cpp:239] Iteration 11330 (2.89142 iter/s, 3.4585s/10 iters), loss = 8.85418
I0522 23:27:05.135252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85418 (* 1 = 8.85418 loss)
I0522 23:27:05.945763 34819 sgd_solver.cpp:112] Iteration 11330, lr = 0.01
I0522 23:27:09.579764 34819 solver.cpp:239] Iteration 11340 (2.25006 iter/s, 4.44433s/10 iters), loss = 8.48054
I0522 23:27:09.579814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48054 (* 1 = 8.48054 loss)
I0522 23:27:10.436954 34819 sgd_solver.cpp:112] Iteration 11340, lr = 0.01
I0522 23:27:12.904918 34819 solver.cpp:239] Iteration 11350 (3.00756 iter/s, 3.32495s/10 iters), loss = 8.83607
I0522 23:27:12.904973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83607 (* 1 = 8.83607 loss)
I0522 23:27:13.764747 34819 sgd_solver.cpp:112] Iteration 11350, lr = 0.01
I0522 23:27:17.894188 34819 solver.cpp:239] Iteration 11360 (2.00441 iter/s, 4.98901s/10 iters), loss = 8.41833
I0522 23:27:17.894232 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41833 (* 1 = 8.41833 loss)
I0522 23:27:17.951094 34819 sgd_solver.cpp:112] Iteration 11360, lr = 0.01
I0522 23:27:22.720793 34819 solver.cpp:239] Iteration 11370 (2.07195 iter/s, 4.82636s/10 iters), loss = 8.77135
I0522 23:27:22.720836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77135 (* 1 = 8.77135 loss)
I0522 23:27:22.782204 34819 sgd_solver.cpp:112] Iteration 11370, lr = 0.01
I0522 23:27:26.566231 34819 solver.cpp:239] Iteration 11380 (2.60063 iter/s, 3.84522s/10 iters), loss = 8.90343
I0522 23:27:26.566443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90343 (* 1 = 8.90343 loss)
I0522 23:27:26.630751 34819 sgd_solver.cpp:112] Iteration 11380, lr = 0.01
I0522 23:27:32.915539 34819 solver.cpp:239] Iteration 11390 (1.57509 iter/s, 6.34885s/10 iters), loss = 9.55763
I0522 23:27:32.915593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55763 (* 1 = 9.55763 loss)
I0522 23:27:32.978400 34819 sgd_solver.cpp:112] Iteration 11390, lr = 0.01
I0522 23:27:38.091454 34819 solver.cpp:239] Iteration 11400 (1.93213 iter/s, 5.17562s/10 iters), loss = 9.27112
I0522 23:27:38.091512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27112 (* 1 = 9.27112 loss)
I0522 23:27:38.627668 34819 sgd_solver.cpp:112] Iteration 11400, lr = 0.01
I0522 23:27:41.265730 34819 solver.cpp:239] Iteration 11410 (3.15052 iter/s, 3.17408s/10 iters), loss = 8.74173
I0522 23:27:41.265774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74173 (* 1 = 8.74173 loss)
I0522 23:27:41.331548 34819 sgd_solver.cpp:112] Iteration 11410, lr = 0.01
I0522 23:27:46.113523 34819 solver.cpp:239] Iteration 11420 (2.0629 iter/s, 4.84755s/10 iters), loss = 8.15948
I0522 23:27:46.113565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15948 (* 1 = 8.15948 loss)
I0522 23:27:46.763636 34819 sgd_solver.cpp:112] Iteration 11420, lr = 0.01
I0522 23:27:50.918884 34819 solver.cpp:239] Iteration 11430 (2.08112 iter/s, 4.80511s/10 iters), loss = 8.95036
I0522 23:27:50.918934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95036 (* 1 = 8.95036 loss)
I0522 23:27:50.975949 34819 sgd_solver.cpp:112] Iteration 11430, lr = 0.01
I0522 23:27:54.956221 34819 solver.cpp:239] Iteration 11440 (2.47702 iter/s, 4.03712s/10 iters), loss = 8.76191
I0522 23:27:54.956276 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76191 (* 1 = 8.76191 loss)
I0522 23:27:55.038338 34819 sgd_solver.cpp:112] Iteration 11440, lr = 0.01
I0522 23:27:59.705657 34819 solver.cpp:239] Iteration 11450 (2.10563 iter/s, 4.74917s/10 iters), loss = 9.25274
I0522 23:27:59.705837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25274 (* 1 = 9.25274 loss)
I0522 23:27:59.759078 34819 sgd_solver.cpp:112] Iteration 11450, lr = 0.01
I0522 23:28:06.149212 34819 solver.cpp:239] Iteration 11460 (1.55204 iter/s, 6.44312s/10 iters), loss = 9.48934
I0522 23:28:06.149271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48934 (* 1 = 9.48934 loss)
I0522 23:28:06.911896 34819 sgd_solver.cpp:112] Iteration 11460, lr = 0.01
I0522 23:28:11.791985 34819 solver.cpp:239] Iteration 11470 (1.77227 iter/s, 5.64248s/10 iters), loss = 9.32761
I0522 23:28:11.792029 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32761 (* 1 = 9.32761 loss)
I0522 23:28:11.848044 34819 sgd_solver.cpp:112] Iteration 11470, lr = 0.01
I0522 23:28:15.929563 34819 solver.cpp:239] Iteration 11480 (2.417 iter/s, 4.13736s/10 iters), loss = 8.79869
I0522 23:28:15.929617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79869 (* 1 = 8.79869 loss)
I0522 23:28:16.004009 34819 sgd_solver.cpp:112] Iteration 11480, lr = 0.01
I0522 23:28:20.836424 34819 solver.cpp:239] Iteration 11490 (2.03807 iter/s, 4.9066s/10 iters), loss = 8.59459
I0522 23:28:20.836478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59459 (* 1 = 8.59459 loss)
I0522 23:28:21.674651 34819 sgd_solver.cpp:112] Iteration 11490, lr = 0.01
I0522 23:28:26.560886 34819 solver.cpp:239] Iteration 11500 (1.74698 iter/s, 5.72417s/10 iters), loss = 9.18125
I0522 23:28:26.560935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18125 (* 1 = 9.18125 loss)
I0522 23:28:26.620229 34819 sgd_solver.cpp:112] Iteration 11500, lr = 0.01
I0522 23:28:30.539285 34819 solver.cpp:239] Iteration 11510 (2.51371 iter/s, 3.97818s/10 iters), loss = 8.55324
I0522 23:28:30.539471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55324 (* 1 = 8.55324 loss)
I0522 23:28:31.107468 34819 sgd_solver.cpp:112] Iteration 11510, lr = 0.01
I0522 23:28:35.364609 34819 solver.cpp:239] Iteration 11520 (2.07256 iter/s, 4.82494s/10 iters), loss = 8.72552
I0522 23:28:35.364670 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72552 (* 1 = 8.72552 loss)
I0522 23:28:35.431437 34819 sgd_solver.cpp:112] Iteration 11520, lr = 0.01
I0522 23:28:39.841900 34819 solver.cpp:239] Iteration 11530 (2.23362 iter/s, 4.47703s/10 iters), loss = 8.50372
I0522 23:28:39.841954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50372 (* 1 = 8.50372 loss)
I0522 23:28:39.919473 34819 sgd_solver.cpp:112] Iteration 11530, lr = 0.01
I0522 23:28:44.664955 34819 solver.cpp:239] Iteration 11540 (2.07348 iter/s, 4.8228s/10 iters), loss = 8.89839
I0522 23:28:44.665000 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89839 (* 1 = 8.89839 loss)
I0522 23:28:44.726683 34819 sgd_solver.cpp:112] Iteration 11540, lr = 0.01
I0522 23:28:48.825454 34819 solver.cpp:239] Iteration 11550 (2.40368 iter/s, 4.16028s/10 iters), loss = 9.25619
I0522 23:28:48.825500 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25619 (* 1 = 9.25619 loss)
I0522 23:28:49.477478 34819 sgd_solver.cpp:112] Iteration 11550, lr = 0.01
I0522 23:28:54.453016 34819 solver.cpp:239] Iteration 11560 (1.77706 iter/s, 5.62729s/10 iters), loss = 8.72751
I0522 23:28:54.453061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72751 (* 1 = 8.72751 loss)
I0522 23:28:55.143538 34819 sgd_solver.cpp:112] Iteration 11560, lr = 0.01
I0522 23:28:59.921844 34819 solver.cpp:239] Iteration 11570 (1.82864 iter/s, 5.46854s/10 iters), loss = 8.48172
I0522 23:28:59.921897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48172 (* 1 = 8.48172 loss)
I0522 23:28:59.983235 34819 sgd_solver.cpp:112] Iteration 11570, lr = 0.01
I0522 23:29:03.674607 34819 solver.cpp:239] Iteration 11580 (2.66487 iter/s, 3.75253s/10 iters), loss = 8.79741
I0522 23:29:03.674755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79741 (* 1 = 8.79741 loss)
I0522 23:29:04.545042 34819 sgd_solver.cpp:112] Iteration 11580, lr = 0.01
I0522 23:29:08.775054 34819 solver.cpp:239] Iteration 11590 (1.96075 iter/s, 5.10009s/10 iters), loss = 9.56798
I0522 23:29:08.775110 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56798 (* 1 = 9.56798 loss)
I0522 23:29:08.847234 34819 sgd_solver.cpp:112] Iteration 11590, lr = 0.01
I0522 23:29:13.084806 34819 solver.cpp:239] Iteration 11600 (2.32045 iter/s, 4.30952s/10 iters), loss = 9.34201
I0522 23:29:13.084851 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34201 (* 1 = 9.34201 loss)
I0522 23:29:13.152642 34819 sgd_solver.cpp:112] Iteration 11600, lr = 0.01
I0522 23:29:16.734477 34819 solver.cpp:239] Iteration 11610 (2.74013 iter/s, 3.64947s/10 iters), loss = 8.98917
I0522 23:29:16.734526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98917 (* 1 = 8.98917 loss)
I0522 23:29:16.795879 34819 sgd_solver.cpp:112] Iteration 11610, lr = 0.01
I0522 23:29:20.918938 34819 solver.cpp:239] Iteration 11620 (2.38992 iter/s, 4.18423s/10 iters), loss = 9.3807
I0522 23:29:20.918990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3807 (* 1 = 9.3807 loss)
I0522 23:29:20.989132 34819 sgd_solver.cpp:112] Iteration 11620, lr = 0.01
I0522 23:29:27.732430 34819 solver.cpp:239] Iteration 11630 (1.46775 iter/s, 6.81315s/10 iters), loss = 9.2099
I0522 23:29:27.732489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2099 (* 1 = 9.2099 loss)
I0522 23:29:27.803846 34819 sgd_solver.cpp:112] Iteration 11630, lr = 0.01
I0522 23:29:31.515903 34819 solver.cpp:239] Iteration 11640 (2.64323 iter/s, 3.78326s/10 iters), loss = 8.96233
I0522 23:29:31.515957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96233 (* 1 = 8.96233 loss)
I0522 23:29:31.576220 34819 sgd_solver.cpp:112] Iteration 11640, lr = 0.01
I0522 23:29:34.981830 34819 solver.cpp:239] Iteration 11650 (2.8854 iter/s, 3.46572s/10 iters), loss = 8.96992
I0522 23:29:34.982059 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96992 (* 1 = 8.96992 loss)
I0522 23:29:35.790343 34819 sgd_solver.cpp:112] Iteration 11650, lr = 0.01
I0522 23:29:41.374469 34819 solver.cpp:239] Iteration 11660 (1.56441 iter/s, 6.39217s/10 iters), loss = 8.51103
I0522 23:29:41.374526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51103 (* 1 = 8.51103 loss)
I0522 23:29:41.453912 34819 sgd_solver.cpp:112] Iteration 11660, lr = 0.01
I0522 23:29:44.793810 34819 solver.cpp:239] Iteration 11670 (2.92473 iter/s, 3.41912s/10 iters), loss = 9.08879
I0522 23:29:44.793871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08879 (* 1 = 9.08879 loss)
I0522 23:29:44.851697 34819 sgd_solver.cpp:112] Iteration 11670, lr = 0.01
I0522 23:29:48.989984 34819 solver.cpp:239] Iteration 11680 (2.38326 iter/s, 4.19594s/10 iters), loss = 8.68846
I0522 23:29:48.990038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68846 (* 1 = 8.68846 loss)
I0522 23:29:49.047124 34819 sgd_solver.cpp:112] Iteration 11680, lr = 0.01
I0522 23:29:53.214146 34819 solver.cpp:239] Iteration 11690 (2.36747 iter/s, 4.22392s/10 iters), loss = 8.5013
I0522 23:29:53.214200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5013 (* 1 = 8.5013 loss)
I0522 23:29:53.507580 34819 sgd_solver.cpp:112] Iteration 11690, lr = 0.01
I0522 23:29:58.441339 34819 solver.cpp:239] Iteration 11700 (1.91318 iter/s, 5.2269s/10 iters), loss = 8.30133
I0522 23:29:58.441393 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30133 (* 1 = 8.30133 loss)
I0522 23:29:59.171062 34819 sgd_solver.cpp:112] Iteration 11700, lr = 0.01
I0522 23:30:02.701297 34819 solver.cpp:239] Iteration 11710 (2.34758 iter/s, 4.2597s/10 iters), loss = 8.95888
I0522 23:30:02.701356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95888 (* 1 = 8.95888 loss)
I0522 23:30:03.533404 34819 sgd_solver.cpp:112] Iteration 11710, lr = 0.01
I0522 23:30:06.793354 34819 solver.cpp:239] Iteration 11720 (2.44389 iter/s, 4.09183s/10 iters), loss = 8.3372
I0522 23:30:06.793499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3372 (* 1 = 8.3372 loss)
I0522 23:30:07.398116 34819 sgd_solver.cpp:112] Iteration 11720, lr = 0.01
I0522 23:30:13.103116 34819 solver.cpp:239] Iteration 11730 (1.58495 iter/s, 6.30935s/10 iters), loss = 9.09847
I0522 23:30:13.103171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09847 (* 1 = 9.09847 loss)
I0522 23:30:13.167260 34819 sgd_solver.cpp:112] Iteration 11730, lr = 0.01
I0522 23:30:17.708851 34819 solver.cpp:239] Iteration 11740 (2.17132 iter/s, 4.60549s/10 iters), loss = 9.63559
I0522 23:30:17.708897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63559 (* 1 = 9.63559 loss)
I0522 23:30:17.765677 34819 sgd_solver.cpp:112] Iteration 11740, lr = 0.01
I0522 23:30:22.613791 34819 solver.cpp:239] Iteration 11750 (2.03887 iter/s, 4.90467s/10 iters), loss = 9.35663
I0522 23:30:22.613848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35663 (* 1 = 9.35663 loss)
I0522 23:30:22.671916 34819 sgd_solver.cpp:112] Iteration 11750, lr = 0.01
I0522 23:30:28.038806 34819 solver.cpp:239] Iteration 11760 (1.84341 iter/s, 5.42473s/10 iters), loss = 9.23425
I0522 23:30:28.038849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23425 (* 1 = 9.23425 loss)
I0522 23:30:28.890442 34819 sgd_solver.cpp:112] Iteration 11760, lr = 0.01
I0522 23:30:34.298858 34819 solver.cpp:239] Iteration 11770 (1.59751 iter/s, 6.25973s/10 iters), loss = 8.98453
I0522 23:30:34.298925 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98453 (* 1 = 8.98453 loss)
I0522 23:30:35.147568 34819 sgd_solver.cpp:112] Iteration 11770, lr = 0.01
I0522 23:30:39.231796 34819 solver.cpp:239] Iteration 11780 (2.02731 iter/s, 4.93265s/10 iters), loss = 8.31001
I0522 23:30:39.231989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31001 (* 1 = 8.31001 loss)
I0522 23:30:39.958927 34819 sgd_solver.cpp:112] Iteration 11780, lr = 0.01
I0522 23:30:46.443599 34819 solver.cpp:239] Iteration 11790 (1.38671 iter/s, 7.21133s/10 iters), loss = 9.11426
I0522 23:30:46.443651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11426 (* 1 = 9.11426 loss)
I0522 23:30:46.508852 34819 sgd_solver.cpp:112] Iteration 11790, lr = 0.01
I0522 23:30:50.694149 34819 solver.cpp:239] Iteration 11800 (2.35276 iter/s, 4.25032s/10 iters), loss = 9.35082
I0522 23:30:50.694193 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35082 (* 1 = 9.35082 loss)
I0522 23:30:50.761927 34819 sgd_solver.cpp:112] Iteration 11800, lr = 0.01
I0522 23:30:54.979714 34819 solver.cpp:239] Iteration 11810 (2.33354 iter/s, 4.28534s/10 iters), loss = 8.69989
I0522 23:30:54.979758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69989 (* 1 = 8.69989 loss)
I0522 23:30:55.037004 34819 sgd_solver.cpp:112] Iteration 11810, lr = 0.01
I0522 23:30:58.810972 34819 solver.cpp:239] Iteration 11820 (2.61025 iter/s, 3.83105s/10 iters), loss = 9.09087
I0522 23:30:58.811027 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09087 (* 1 = 9.09087 loss)
I0522 23:30:59.622905 34819 sgd_solver.cpp:112] Iteration 11820, lr = 0.01
I0522 23:31:04.630806 34819 solver.cpp:239] Iteration 11830 (1.71835 iter/s, 5.81955s/10 iters), loss = 8.80689
I0522 23:31:04.630849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80689 (* 1 = 8.80689 loss)
I0522 23:31:05.421785 34819 sgd_solver.cpp:112] Iteration 11830, lr = 0.01
I0522 23:31:11.183583 34819 solver.cpp:239] Iteration 11840 (1.52614 iter/s, 6.55247s/10 iters), loss = 9.24817
I0522 23:31:11.183703 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24817 (* 1 = 9.24817 loss)
I0522 23:31:11.259490 34819 sgd_solver.cpp:112] Iteration 11840, lr = 0.01
I0522 23:31:16.717177 34819 solver.cpp:239] Iteration 11850 (1.80726 iter/s, 5.53324s/10 iters), loss = 9.32048
I0522 23:31:16.717247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32048 (* 1 = 9.32048 loss)
I0522 23:31:17.495442 34819 sgd_solver.cpp:112] Iteration 11850, lr = 0.01
I0522 23:31:21.524067 34819 solver.cpp:239] Iteration 11860 (2.08047 iter/s, 4.80662s/10 iters), loss = 9.31484
I0522 23:31:21.524130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31484 (* 1 = 9.31484 loss)
I0522 23:31:21.593065 34819 sgd_solver.cpp:112] Iteration 11860, lr = 0.01
I0522 23:31:26.647199 34819 solver.cpp:239] Iteration 11870 (1.95204 iter/s, 5.12286s/10 iters), loss = 8.86225
I0522 23:31:26.647254 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86225 (* 1 = 8.86225 loss)
I0522 23:31:27.453351 34819 sgd_solver.cpp:112] Iteration 11870, lr = 0.01
I0522 23:31:32.227011 34819 solver.cpp:239] Iteration 11880 (1.79227 iter/s, 5.57952s/10 iters), loss = 8.95866
I0522 23:31:32.227072 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95866 (* 1 = 8.95866 loss)
I0522 23:31:32.915762 34819 sgd_solver.cpp:112] Iteration 11880, lr = 0.01
I0522 23:31:38.546375 34819 solver.cpp:239] Iteration 11890 (1.58252 iter/s, 6.31905s/10 iters), loss = 9.24217
I0522 23:31:38.546419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24217 (* 1 = 9.24217 loss)
I0522 23:31:38.619390 34819 sgd_solver.cpp:112] Iteration 11890, lr = 0.01
I0522 23:31:42.633478 34819 solver.cpp:239] Iteration 11900 (2.44686 iter/s, 4.08688s/10 iters), loss = 8.62557
I0522 23:31:42.633689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62557 (* 1 = 8.62557 loss)
I0522 23:31:43.259419 34819 sgd_solver.cpp:112] Iteration 11900, lr = 0.01
I0522 23:31:49.149915 34819 solver.cpp:239] Iteration 11910 (1.53469 iter/s, 6.51597s/10 iters), loss = 9.22959
I0522 23:31:49.149969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22959 (* 1 = 9.22959 loss)
I0522 23:31:49.985805 34819 sgd_solver.cpp:112] Iteration 11910, lr = 0.01
I0522 23:31:54.124934 34819 solver.cpp:239] Iteration 11920 (2.01015 iter/s, 4.97476s/10 iters), loss = 8.84809
I0522 23:31:54.124990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84809 (* 1 = 8.84809 loss)
I0522 23:31:54.188910 34819 sgd_solver.cpp:112] Iteration 11920, lr = 0.01
I0522 23:31:59.199059 34819 solver.cpp:239] Iteration 11930 (1.97089 iter/s, 5.07386s/10 iters), loss = 8.67303
I0522 23:31:59.199103 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67303 (* 1 = 8.67303 loss)
I0522 23:31:59.257053 34819 sgd_solver.cpp:112] Iteration 11930, lr = 0.01
I0522 23:32:03.324873 34819 solver.cpp:239] Iteration 11940 (2.42389 iter/s, 4.12559s/10 iters), loss = 9.39022
I0522 23:32:03.324935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39022 (* 1 = 9.39022 loss)
I0522 23:32:04.194488 34819 sgd_solver.cpp:112] Iteration 11940, lr = 0.01
I0522 23:32:10.206986 34819 solver.cpp:239] Iteration 11950 (1.45312 iter/s, 6.88174s/10 iters), loss = 9.3398
I0522 23:32:10.207051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3398 (* 1 = 9.3398 loss)
I0522 23:32:10.968663 34819 sgd_solver.cpp:112] Iteration 11950, lr = 0.01
I0522 23:32:14.171187 34819 solver.cpp:239] Iteration 11960 (2.52273 iter/s, 3.96396s/10 iters), loss = 9.67631
I0522 23:32:14.171352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67631 (* 1 = 9.67631 loss)
I0522 23:32:14.776129 34819 sgd_solver.cpp:112] Iteration 11960, lr = 0.01
I0522 23:32:20.309603 34819 solver.cpp:239] Iteration 11970 (1.6292 iter/s, 6.138s/10 iters), loss = 9.54038
I0522 23:32:20.309660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54038 (* 1 = 9.54038 loss)
I0522 23:32:21.128417 34819 sgd_solver.cpp:112] Iteration 11970, lr = 0.01
I0522 23:32:25.183404 34819 solver.cpp:239] Iteration 11980 (2.0519 iter/s, 4.87354s/10 iters), loss = 8.59518
I0522 23:32:25.183454 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59518 (* 1 = 8.59518 loss)
I0522 23:32:25.235072 34819 sgd_solver.cpp:112] Iteration 11980, lr = 0.01
I0522 23:32:29.877470 34819 solver.cpp:239] Iteration 11990 (2.13047 iter/s, 4.69381s/10 iters), loss = 8.79352
I0522 23:32:29.877526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79352 (* 1 = 8.79352 loss)
I0522 23:32:29.933897 34819 sgd_solver.cpp:112] Iteration 11990, lr = 0.01
I0522 23:32:35.526140 34819 solver.cpp:239] Iteration 12000 (1.77042 iter/s, 5.64838s/10 iters), loss = 8.33472
I0522 23:32:35.526192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33472 (* 1 = 8.33472 loss)
I0522 23:32:35.581096 34819 sgd_solver.cpp:112] Iteration 12000, lr = 0.01
I0522 23:32:39.682627 34819 solver.cpp:239] Iteration 12010 (2.40601 iter/s, 4.15626s/10 iters), loss = 9.21804
I0522 23:32:39.682672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21804 (* 1 = 9.21804 loss)
I0522 23:32:39.787276 34819 sgd_solver.cpp:112] Iteration 12010, lr = 0.01
I0522 23:32:43.294761 34819 solver.cpp:239] Iteration 12020 (2.7686 iter/s, 3.61193s/10 iters), loss = 8.0008
I0522 23:32:43.294806 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0008 (* 1 = 8.0008 loss)
I0522 23:32:43.381980 34819 sgd_solver.cpp:112] Iteration 12020, lr = 0.01
I0522 23:32:48.739035 34819 solver.cpp:239] Iteration 12030 (1.83689 iter/s, 5.44399s/10 iters), loss = 8.90075
I0522 23:32:48.739248 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90075 (* 1 = 8.90075 loss)
I0522 23:32:49.489748 34819 sgd_solver.cpp:112] Iteration 12030, lr = 0.01
I0522 23:32:53.572088 34819 solver.cpp:239] Iteration 12040 (2.06925 iter/s, 4.83266s/10 iters), loss = 8.21596
I0522 23:32:53.572144 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21596 (* 1 = 8.21596 loss)
I0522 23:32:53.648877 34819 sgd_solver.cpp:112] Iteration 12040, lr = 0.01
I0522 23:32:59.185462 34819 solver.cpp:239] Iteration 12050 (1.78156 iter/s, 5.61307s/10 iters), loss = 9.29725
I0522 23:32:59.185519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29725 (* 1 = 9.29725 loss)
I0522 23:32:59.463629 34819 sgd_solver.cpp:112] Iteration 12050, lr = 0.01
I0522 23:33:04.358043 34819 solver.cpp:239] Iteration 12060 (1.93337 iter/s, 5.17231s/10 iters), loss = 9.32268
I0522 23:33:04.358085 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32268 (* 1 = 9.32268 loss)
I0522 23:33:04.425582 34819 sgd_solver.cpp:112] Iteration 12060, lr = 0.01
I0522 23:33:09.883352 34819 solver.cpp:239] Iteration 12070 (1.80995 iter/s, 5.52502s/10 iters), loss = 8.61309
I0522 23:33:09.883401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61309 (* 1 = 8.61309 loss)
I0522 23:33:10.687517 34819 sgd_solver.cpp:112] Iteration 12070, lr = 0.01
I0522 23:33:14.086382 34819 solver.cpp:239] Iteration 12080 (2.37936 iter/s, 4.20281s/10 iters), loss = 9.19552
I0522 23:33:14.086426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19552 (* 1 = 9.19552 loss)
I0522 23:33:14.152961 34819 sgd_solver.cpp:112] Iteration 12080, lr = 0.01
I0522 23:33:18.318446 34819 solver.cpp:239] Iteration 12090 (2.36304 iter/s, 4.23184s/10 iters), loss = 9.49937
I0522 23:33:18.318490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49937 (* 1 = 9.49937 loss)
I0522 23:33:19.142338 34819 sgd_solver.cpp:112] Iteration 12090, lr = 0.01
I0522 23:33:23.275668 34819 solver.cpp:239] Iteration 12100 (2.01736 iter/s, 4.95696s/10 iters), loss = 8.59628
I0522 23:33:23.275713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59628 (* 1 = 8.59628 loss)
I0522 23:33:23.341936 34819 sgd_solver.cpp:112] Iteration 12100, lr = 0.01
I0522 23:33:27.147855 34819 solver.cpp:239] Iteration 12110 (2.58266 iter/s, 3.87197s/10 iters), loss = 9.4684
I0522 23:33:27.147897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4684 (* 1 = 9.4684 loss)
I0522 23:33:27.245820 34819 sgd_solver.cpp:112] Iteration 12110, lr = 0.01
I0522 23:33:32.830184 34819 solver.cpp:239] Iteration 12120 (1.75993 iter/s, 5.68204s/10 iters), loss = 8.50568
I0522 23:33:32.830227 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50568 (* 1 = 8.50568 loss)
I0522 23:33:32.903297 34819 sgd_solver.cpp:112] Iteration 12120, lr = 0.01
I0522 23:33:38.501045 34819 solver.cpp:239] Iteration 12130 (1.76349 iter/s, 5.67057s/10 iters), loss = 8.1814
I0522 23:33:38.501092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1814 (* 1 = 8.1814 loss)
I0522 23:33:39.251901 34819 sgd_solver.cpp:112] Iteration 12130, lr = 0.01
I0522 23:33:45.680683 34819 solver.cpp:239] Iteration 12140 (1.39289 iter/s, 7.17929s/10 iters), loss = 9.39413
I0522 23:33:45.680728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39413 (* 1 = 9.39413 loss)
I0522 23:33:45.752799 34819 sgd_solver.cpp:112] Iteration 12140, lr = 0.01
I0522 23:33:48.417814 34819 solver.cpp:239] Iteration 12150 (3.6537 iter/s, 2.73695s/10 iters), loss = 9.17686
I0522 23:33:48.417855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17686 (* 1 = 9.17686 loss)
I0522 23:33:48.493970 34819 sgd_solver.cpp:112] Iteration 12150, lr = 0.01
I0522 23:33:55.628572 34819 solver.cpp:239] Iteration 12160 (1.38688 iter/s, 7.21041s/10 iters), loss = 8.93203
I0522 23:33:55.628708 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93203 (* 1 = 8.93203 loss)
I0522 23:33:55.687656 34819 sgd_solver.cpp:112] Iteration 12160, lr = 0.01
I0522 23:34:01.929391 34819 solver.cpp:239] Iteration 12170 (1.5872 iter/s, 6.30042s/10 iters), loss = 8.5704
I0522 23:34:01.929436 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5704 (* 1 = 8.5704 loss)
I0522 23:34:02.011430 34819 sgd_solver.cpp:112] Iteration 12170, lr = 0.01
I0522 23:34:06.082712 34819 solver.cpp:239] Iteration 12180 (2.40785 iter/s, 4.15308s/10 iters), loss = 8.67436
I0522 23:34:06.082757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67436 (* 1 = 8.67436 loss)
I0522 23:34:06.895246 34819 sgd_solver.cpp:112] Iteration 12180, lr = 0.01
I0522 23:34:11.532766 34819 solver.cpp:239] Iteration 12190 (1.83494 iter/s, 5.44978s/10 iters), loss = 8.98983
I0522 23:34:11.532809 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98983 (* 1 = 8.98983 loss)
I0522 23:34:11.583528 34819 sgd_solver.cpp:112] Iteration 12190, lr = 0.01
I0522 23:34:15.378239 34819 solver.cpp:239] Iteration 12200 (2.60061 iter/s, 3.84526s/10 iters), loss = 8.81309
I0522 23:34:15.378296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81309 (* 1 = 8.81309 loss)
I0522 23:34:16.155426 34819 sgd_solver.cpp:112] Iteration 12200, lr = 0.01
I0522 23:34:21.410115 34819 solver.cpp:239] Iteration 12210 (1.65794 iter/s, 6.03157s/10 iters), loss = 9.54153
I0522 23:34:21.410166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54153 (* 1 = 9.54153 loss)
I0522 23:34:21.468797 34819 sgd_solver.cpp:112] Iteration 12210, lr = 0.01
I0522 23:34:24.812029 34819 solver.cpp:239] Iteration 12220 (2.9397 iter/s, 3.40171s/10 iters), loss = 9.11095
I0522 23:34:24.812080 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11095 (* 1 = 9.11095 loss)
I0522 23:34:25.615084 34819 sgd_solver.cpp:112] Iteration 12220, lr = 0.01
I0522 23:34:29.126024 34819 solver.cpp:239] Iteration 12230 (2.31817 iter/s, 4.31375s/10 iters), loss = 8.80203
I0522 23:34:29.126212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80203 (* 1 = 8.80203 loss)
I0522 23:34:29.199256 34819 sgd_solver.cpp:112] Iteration 12230, lr = 0.01
I0522 23:34:31.839258 34819 solver.cpp:239] Iteration 12240 (3.68605 iter/s, 2.71293s/10 iters), loss = 9.17089
I0522 23:34:31.839303 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17089 (* 1 = 9.17089 loss)
I0522 23:34:31.911347 34819 sgd_solver.cpp:112] Iteration 12240, lr = 0.01
I0522 23:34:35.990150 34819 solver.cpp:239] Iteration 12250 (2.40926 iter/s, 4.15066s/10 iters), loss = 8.17696
I0522 23:34:35.990196 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17696 (* 1 = 8.17696 loss)
I0522 23:34:36.846091 34819 sgd_solver.cpp:112] Iteration 12250, lr = 0.01
I0522 23:34:40.395244 34819 solver.cpp:239] Iteration 12260 (2.27022 iter/s, 4.40485s/10 iters), loss = 9.07834
I0522 23:34:40.395301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07834 (* 1 = 9.07834 loss)
I0522 23:34:41.218164 34819 sgd_solver.cpp:112] Iteration 12260, lr = 0.01
I0522 23:34:45.377841 34819 solver.cpp:239] Iteration 12270 (2.00711 iter/s, 4.9823s/10 iters), loss = 9.42443
I0522 23:34:45.377893 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42443 (* 1 = 9.42443 loss)
I0522 23:34:46.252213 34819 sgd_solver.cpp:112] Iteration 12270, lr = 0.01
I0522 23:34:51.726374 34819 solver.cpp:239] Iteration 12280 (1.57525 iter/s, 6.34822s/10 iters), loss = 8.76495
I0522 23:34:51.726428 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76495 (* 1 = 8.76495 loss)
I0522 23:34:52.516458 34819 sgd_solver.cpp:112] Iteration 12280, lr = 0.01
I0522 23:34:58.358602 34819 solver.cpp:239] Iteration 12290 (1.50786 iter/s, 6.63191s/10 iters), loss = 9.13333
I0522 23:34:58.358651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13333 (* 1 = 9.13333 loss)
I0522 23:34:59.174866 34819 sgd_solver.cpp:112] Iteration 12290, lr = 0.01
I0522 23:35:02.437744 34819 solver.cpp:239] Iteration 12300 (2.45163 iter/s, 4.07892s/10 iters), loss = 9.13423
I0522 23:35:02.437798 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13423 (* 1 = 9.13423 loss)
I0522 23:35:02.517072 34819 sgd_solver.cpp:112] Iteration 12300, lr = 0.01
I0522 23:35:07.977365 34819 solver.cpp:239] Iteration 12310 (1.80527 iter/s, 5.53934s/10 iters), loss = 8.68233
I0522 23:35:07.977423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68233 (* 1 = 8.68233 loss)
I0522 23:35:08.050577 34819 sgd_solver.cpp:112] Iteration 12310, lr = 0.01
I0522 23:35:12.903306 34819 solver.cpp:239] Iteration 12320 (2.03018 iter/s, 4.92568s/10 iters), loss = 8.72167
I0522 23:35:12.903349 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72167 (* 1 = 8.72167 loss)
I0522 23:35:13.539141 34819 sgd_solver.cpp:112] Iteration 12320, lr = 0.01
I0522 23:35:18.228219 34819 solver.cpp:239] Iteration 12330 (1.87806 iter/s, 5.32463s/10 iters), loss = 8.78329
I0522 23:35:18.228273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78329 (* 1 = 8.78329 loss)
I0522 23:35:18.987882 34819 sgd_solver.cpp:112] Iteration 12330, lr = 0.01
I0522 23:35:23.253315 34819 solver.cpp:239] Iteration 12340 (1.99011 iter/s, 5.02484s/10 iters), loss = 9.42518
I0522 23:35:23.253358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42518 (* 1 = 9.42518 loss)
I0522 23:35:23.783241 34819 sgd_solver.cpp:112] Iteration 12340, lr = 0.01
I0522 23:35:25.974011 34819 solver.cpp:239] Iteration 12350 (3.67578 iter/s, 2.72051s/10 iters), loss = 8.10808
I0522 23:35:25.974066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10808 (* 1 = 8.10808 loss)
I0522 23:35:26.038331 34819 sgd_solver.cpp:112] Iteration 12350, lr = 0.01
I0522 23:35:30.802332 34819 solver.cpp:239] Iteration 12360 (2.07122 iter/s, 4.82806s/10 iters), loss = 9.26209
I0522 23:35:30.802630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26209 (* 1 = 9.26209 loss)
I0522 23:35:30.881474 34819 sgd_solver.cpp:112] Iteration 12360, lr = 0.01
I0522 23:35:37.383579 34819 solver.cpp:239] Iteration 12370 (1.51959 iter/s, 6.58071s/10 iters), loss = 8.31947
I0522 23:35:37.383630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31947 (* 1 = 8.31947 loss)
I0522 23:35:37.459990 34819 sgd_solver.cpp:112] Iteration 12370, lr = 0.01
I0522 23:35:42.357103 34819 solver.cpp:239] Iteration 12380 (2.01075 iter/s, 4.97327s/10 iters), loss = 8.85919
I0522 23:35:42.357161 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85919 (* 1 = 8.85919 loss)
I0522 23:35:43.206380 34819 sgd_solver.cpp:112] Iteration 12380, lr = 0.01
I0522 23:35:47.577450 34819 solver.cpp:239] Iteration 12390 (1.91568 iter/s, 5.22008s/10 iters), loss = 8.87849
I0522 23:35:47.577502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87849 (* 1 = 8.87849 loss)
I0522 23:35:48.428959 34819 sgd_solver.cpp:112] Iteration 12390, lr = 0.01
I0522 23:35:54.325492 34819 solver.cpp:239] Iteration 12400 (1.48198 iter/s, 6.74771s/10 iters), loss = 8.24042
I0522 23:35:54.325549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24042 (* 1 = 8.24042 loss)
I0522 23:35:55.106650 34819 sgd_solver.cpp:112] Iteration 12400, lr = 0.01
I0522 23:36:00.724956 34819 solver.cpp:239] Iteration 12410 (1.56271 iter/s, 6.39915s/10 iters), loss = 9.94512
I0522 23:36:00.725010 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.94512 (* 1 = 9.94512 loss)
I0522 23:36:00.795214 34819 sgd_solver.cpp:112] Iteration 12410, lr = 0.01
I0522 23:36:07.759336 34819 solver.cpp:239] Iteration 12420 (1.42166 iter/s, 7.03405s/10 iters), loss = 9.261
I0522 23:36:07.759526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.261 (* 1 = 9.261 loss)
I0522 23:36:07.812211 34819 sgd_solver.cpp:112] Iteration 12420, lr = 0.01
I0522 23:36:13.159734 34819 solver.cpp:239] Iteration 12430 (1.85185 iter/s, 5.40001s/10 iters), loss = 8.79549
I0522 23:36:13.159778 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79549 (* 1 = 8.79549 loss)
I0522 23:36:13.220844 34819 sgd_solver.cpp:112] Iteration 12430, lr = 0.01
I0522 23:36:16.811861 34819 solver.cpp:239] Iteration 12440 (2.73828 iter/s, 3.65192s/10 iters), loss = 9.21831
I0522 23:36:16.811914 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21831 (* 1 = 9.21831 loss)
I0522 23:36:16.895107 34819 sgd_solver.cpp:112] Iteration 12440, lr = 0.01
I0522 23:36:21.717937 34819 solver.cpp:239] Iteration 12450 (2.03841 iter/s, 4.90579s/10 iters), loss = 9.71278
I0522 23:36:21.717991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71278 (* 1 = 9.71278 loss)
I0522 23:36:21.795970 34819 sgd_solver.cpp:112] Iteration 12450, lr = 0.01
I0522 23:36:25.330816 34819 solver.cpp:239] Iteration 12460 (2.76804 iter/s, 3.61267s/10 iters), loss = 9.22997
I0522 23:36:25.330869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22997 (* 1 = 9.22997 loss)
I0522 23:36:25.395989 34819 sgd_solver.cpp:112] Iteration 12460, lr = 0.01
I0522 23:36:29.277312 34819 solver.cpp:239] Iteration 12470 (2.53403 iter/s, 3.94628s/10 iters), loss = 8.52068
I0522 23:36:29.277359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52068 (* 1 = 8.52068 loss)
I0522 23:36:29.358283 34819 sgd_solver.cpp:112] Iteration 12470, lr = 0.01
I0522 23:36:34.201113 34819 solver.cpp:239] Iteration 12480 (2.03106 iter/s, 4.92353s/10 iters), loss = 9.22891
I0522 23:36:34.201182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22891 (* 1 = 9.22891 loss)
I0522 23:36:34.271435 34819 sgd_solver.cpp:112] Iteration 12480, lr = 0.01
I0522 23:36:37.678006 34819 solver.cpp:239] Iteration 12490 (2.87632 iter/s, 3.47666s/10 iters), loss = 9.63799
I0522 23:36:37.678058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63799 (* 1 = 9.63799 loss)
I0522 23:36:38.525535 34819 sgd_solver.cpp:112] Iteration 12490, lr = 0.01
I0522 23:36:42.265631 34819 solver.cpp:239] Iteration 12500 (2.1799 iter/s, 4.58736s/10 iters), loss = 9.31387
I0522 23:36:42.265691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31387 (* 1 = 9.31387 loss)
I0522 23:36:43.058445 34819 sgd_solver.cpp:112] Iteration 12500, lr = 0.01
I0522 23:36:48.361560 34819 solver.cpp:239] Iteration 12510 (1.64053 iter/s, 6.0956s/10 iters), loss = 8.75536
I0522 23:36:48.361608 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75536 (* 1 = 8.75536 loss)
I0522 23:36:49.124330 34819 sgd_solver.cpp:112] Iteration 12510, lr = 0.01
I0522 23:36:54.734045 34819 solver.cpp:239] Iteration 12520 (1.56932 iter/s, 6.37217s/10 iters), loss = 8.43682
I0522 23:36:54.734087 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43682 (* 1 = 8.43682 loss)
I0522 23:36:54.790009 34819 sgd_solver.cpp:112] Iteration 12520, lr = 0.01
I0522 23:37:00.280305 34819 solver.cpp:239] Iteration 12530 (1.80311 iter/s, 5.54598s/10 iters), loss = 8.38996
I0522 23:37:00.280349 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38996 (* 1 = 8.38996 loss)
I0522 23:37:00.340291 34819 sgd_solver.cpp:112] Iteration 12530, lr = 0.01
I0522 23:37:06.723776 34819 solver.cpp:239] Iteration 12540 (1.55203 iter/s, 6.44316s/10 iters), loss = 8.68336
I0522 23:37:06.723821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68336 (* 1 = 8.68336 loss)
I0522 23:37:06.801070 34819 sgd_solver.cpp:112] Iteration 12540, lr = 0.01
I0522 23:37:10.992528 34819 solver.cpp:239] Iteration 12550 (2.34273 iter/s, 4.26852s/10 iters), loss = 9.11767
I0522 23:37:10.992664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11767 (* 1 = 9.11767 loss)
I0522 23:37:11.837136 34819 sgd_solver.cpp:112] Iteration 12550, lr = 0.01
I0522 23:37:16.779211 34819 solver.cpp:239] Iteration 12560 (1.72822 iter/s, 5.7863s/10 iters), loss = 9.51321
I0522 23:37:16.779263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51321 (* 1 = 9.51321 loss)
I0522 23:37:17.588292 34819 sgd_solver.cpp:112] Iteration 12560, lr = 0.01
I0522 23:37:20.499318 34819 solver.cpp:239] Iteration 12570 (2.68825 iter/s, 3.71989s/10 iters), loss = 8.75482
I0522 23:37:20.499363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75482 (* 1 = 8.75482 loss)
I0522 23:37:21.294752 34819 sgd_solver.cpp:112] Iteration 12570, lr = 0.01
I0522 23:37:25.567524 34819 solver.cpp:239] Iteration 12580 (1.97319 iter/s, 5.06794s/10 iters), loss = 9.03507
I0522 23:37:25.567565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03507 (* 1 = 9.03507 loss)
I0522 23:37:25.647367 34819 sgd_solver.cpp:112] Iteration 12580, lr = 0.01
I0522 23:37:32.453876 34819 solver.cpp:239] Iteration 12590 (1.45222 iter/s, 6.88602s/10 iters), loss = 8.97974
I0522 23:37:32.453917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97974 (* 1 = 8.97974 loss)
I0522 23:37:33.104466 34819 sgd_solver.cpp:112] Iteration 12590, lr = 0.01
I0522 23:37:37.159981 34819 solver.cpp:239] Iteration 12600 (2.12501 iter/s, 4.70587s/10 iters), loss = 9.45647
I0522 23:37:37.160023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45647 (* 1 = 9.45647 loss)
I0522 23:37:37.984298 34819 sgd_solver.cpp:112] Iteration 12600, lr = 0.01
I0522 23:37:43.877974 34819 solver.cpp:239] Iteration 12610 (1.48861 iter/s, 6.71767s/10 iters), loss = 9.89508
I0522 23:37:43.878211 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.89508 (* 1 = 9.89508 loss)
I0522 23:37:43.961632 34819 sgd_solver.cpp:112] Iteration 12610, lr = 0.01
I0522 23:37:47.922768 34819 solver.cpp:239] Iteration 12620 (2.47255 iter/s, 4.04441s/10 iters), loss = 9.07516
I0522 23:37:47.922816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07516 (* 1 = 9.07516 loss)
I0522 23:37:48.779168 34819 sgd_solver.cpp:112] Iteration 12620, lr = 0.01
I0522 23:37:54.482923 34819 solver.cpp:239] Iteration 12630 (1.52443 iter/s, 6.55984s/10 iters), loss = 9.35999
I0522 23:37:54.482966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35999 (* 1 = 9.35999 loss)
I0522 23:37:54.546798 34819 sgd_solver.cpp:112] Iteration 12630, lr = 0.01
I0522 23:37:59.191905 34819 solver.cpp:239] Iteration 12640 (2.12372 iter/s, 4.70872s/10 iters), loss = 8.75714
I0522 23:37:59.191956 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75714 (* 1 = 8.75714 loss)
I0522 23:37:59.818683 34819 sgd_solver.cpp:112] Iteration 12640, lr = 0.01
I0522 23:38:06.823310 34819 solver.cpp:239] Iteration 12650 (1.31044 iter/s, 7.63103s/10 iters), loss = 7.66461
I0522 23:38:06.823359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66461 (* 1 = 7.66461 loss)
I0522 23:38:06.878619 34819 sgd_solver.cpp:112] Iteration 12650, lr = 0.01
I0522 23:38:12.563800 34819 solver.cpp:239] Iteration 12660 (1.7421 iter/s, 5.7402s/10 iters), loss = 9.27395
I0522 23:38:12.563841 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27395 (* 1 = 9.27395 loss)
I0522 23:38:12.627305 34819 sgd_solver.cpp:112] Iteration 12660, lr = 0.01
I0522 23:38:16.859385 34819 solver.cpp:239] Iteration 12670 (2.3281 iter/s, 4.29536s/10 iters), loss = 8.40807
I0522 23:38:16.859495 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40807 (* 1 = 8.40807 loss)
I0522 23:38:17.589452 34819 sgd_solver.cpp:112] Iteration 12670, lr = 0.01
I0522 23:38:22.511864 34819 solver.cpp:239] Iteration 12680 (1.76924 iter/s, 5.65214s/10 iters), loss = 9.4036
I0522 23:38:22.511919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4036 (* 1 = 9.4036 loss)
I0522 23:38:22.587987 34819 sgd_solver.cpp:112] Iteration 12680, lr = 0.01
I0522 23:38:27.085783 34819 solver.cpp:239] Iteration 12690 (2.18643 iter/s, 4.57367s/10 iters), loss = 9.41222
I0522 23:38:27.085826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41222 (* 1 = 9.41222 loss)
I0522 23:38:27.140276 34819 sgd_solver.cpp:112] Iteration 12690, lr = 0.01
I0522 23:38:32.672166 34819 solver.cpp:239] Iteration 12700 (1.79016 iter/s, 5.5861s/10 iters), loss = 8.51939
I0522 23:38:32.672209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51939 (* 1 = 8.51939 loss)
I0522 23:38:32.741111 34819 sgd_solver.cpp:112] Iteration 12700, lr = 0.01
I0522 23:38:35.617825 34819 solver.cpp:239] Iteration 12710 (3.39503 iter/s, 2.94548s/10 iters), loss = 9.22403
I0522 23:38:35.617869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22403 (* 1 = 9.22403 loss)
I0522 23:38:36.447312 34819 sgd_solver.cpp:112] Iteration 12710, lr = 0.01
I0522 23:38:41.062453 34819 solver.cpp:239] Iteration 12720 (1.83676 iter/s, 5.44436s/10 iters), loss = 8.26458
I0522 23:38:41.062496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26458 (* 1 = 8.26458 loss)
I0522 23:38:41.242769 34819 sgd_solver.cpp:112] Iteration 12720, lr = 0.01
I0522 23:38:44.679662 34819 solver.cpp:239] Iteration 12730 (2.76472 iter/s, 3.61701s/10 iters), loss = 9.15462
I0522 23:38:44.679713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15462 (* 1 = 9.15462 loss)
I0522 23:38:45.335922 34819 sgd_solver.cpp:112] Iteration 12730, lr = 0.01
I0522 23:38:48.778307 34819 solver.cpp:239] Iteration 12740 (2.43997 iter/s, 4.09841s/10 iters), loss = 8.54592
I0522 23:38:48.778487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54592 (* 1 = 8.54592 loss)
I0522 23:38:48.857861 34819 sgd_solver.cpp:112] Iteration 12740, lr = 0.01
I0522 23:38:53.914669 34819 solver.cpp:239] Iteration 12750 (1.94705 iter/s, 5.13598s/10 iters), loss = 8.46883
I0522 23:38:53.914731 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46883 (* 1 = 8.46883 loss)
I0522 23:38:54.295308 34819 sgd_solver.cpp:112] Iteration 12750, lr = 0.01
I0522 23:38:59.025960 34819 solver.cpp:239] Iteration 12760 (1.95656 iter/s, 5.11101s/10 iters), loss = 8.73275
I0522 23:38:59.026026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73275 (* 1 = 8.73275 loss)
I0522 23:38:59.858428 34819 sgd_solver.cpp:112] Iteration 12760, lr = 0.01
I0522 23:39:04.839464 34819 solver.cpp:239] Iteration 12770 (1.72022 iter/s, 5.8132s/10 iters), loss = 8.17392
I0522 23:39:04.839534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17392 (* 1 = 8.17392 loss)
I0522 23:39:05.646149 34819 sgd_solver.cpp:112] Iteration 12770, lr = 0.01
I0522 23:39:12.190629 34819 solver.cpp:239] Iteration 12780 (1.3604 iter/s, 7.3508s/10 iters), loss = 9.33074
I0522 23:39:12.190691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33074 (* 1 = 9.33074 loss)
I0522 23:39:12.911981 34819 sgd_solver.cpp:112] Iteration 12780, lr = 0.01
I0522 23:39:17.821261 34819 solver.cpp:239] Iteration 12790 (1.77609 iter/s, 5.63034s/10 iters), loss = 8.51958
I0522 23:39:17.821306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51958 (* 1 = 8.51958 loss)
I0522 23:39:18.690491 34819 sgd_solver.cpp:112] Iteration 12790, lr = 0.01
I0522 23:39:24.654683 34819 solver.cpp:239] Iteration 12800 (1.46346 iter/s, 6.8331s/10 iters), loss = 8.82562
I0522 23:39:24.654814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82562 (* 1 = 8.82562 loss)
I0522 23:39:25.494093 34819 sgd_solver.cpp:112] Iteration 12800, lr = 0.01
I0522 23:39:29.869963 34819 solver.cpp:239] Iteration 12810 (1.91757 iter/s, 5.21492s/10 iters), loss = 8.90614
I0522 23:39:29.870016 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90614 (* 1 = 8.90614 loss)
I0522 23:39:29.923893 34819 sgd_solver.cpp:112] Iteration 12810, lr = 0.01
I0522 23:39:35.717594 34819 solver.cpp:239] Iteration 12820 (1.71018 iter/s, 5.84734s/10 iters), loss = 9.76047
I0522 23:39:35.717648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.76047 (* 1 = 9.76047 loss)
I0522 23:39:35.793220 34819 sgd_solver.cpp:112] Iteration 12820, lr = 0.01
I0522 23:39:39.865834 34819 solver.cpp:239] Iteration 12830 (2.41079 iter/s, 4.14801s/10 iters), loss = 8.14702
I0522 23:39:39.865880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14702 (* 1 = 8.14702 loss)
I0522 23:39:39.930225 34819 sgd_solver.cpp:112] Iteration 12830, lr = 0.01
I0522 23:39:44.602099 34819 solver.cpp:239] Iteration 12840 (2.11148 iter/s, 4.73602s/10 iters), loss = 8.3846
I0522 23:39:44.602141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3846 (* 1 = 8.3846 loss)
I0522 23:39:44.678805 34819 sgd_solver.cpp:112] Iteration 12840, lr = 0.01
I0522 23:39:49.579488 34819 solver.cpp:239] Iteration 12850 (2.00919 iter/s, 4.97713s/10 iters), loss = 9.45447
I0522 23:39:49.579543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45447 (* 1 = 9.45447 loss)
I0522 23:39:50.368439 34819 sgd_solver.cpp:112] Iteration 12850, lr = 0.01
I0522 23:39:53.768398 34819 solver.cpp:239] Iteration 12860 (2.38739 iter/s, 4.18868s/10 iters), loss = 8.90194
I0522 23:39:53.768443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90194 (* 1 = 8.90194 loss)
I0522 23:39:53.823742 34819 sgd_solver.cpp:112] Iteration 12860, lr = 0.01
I0522 23:39:57.365758 34819 solver.cpp:239] Iteration 12870 (2.77997 iter/s, 3.59716s/10 iters), loss = 9.20317
I0522 23:39:57.366008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20317 (* 1 = 9.20317 loss)
I0522 23:39:58.193846 34819 sgd_solver.cpp:112] Iteration 12870, lr = 0.01
I0522 23:40:05.359498 34819 solver.cpp:239] Iteration 12880 (1.25106 iter/s, 7.99319s/10 iters), loss = 8.61746
I0522 23:40:05.359549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61746 (* 1 = 8.61746 loss)
I0522 23:40:05.543071 34819 sgd_solver.cpp:112] Iteration 12880, lr = 0.01
I0522 23:40:09.192490 34819 solver.cpp:239] Iteration 12890 (2.60908 iter/s, 3.83278s/10 iters), loss = 9.07549
I0522 23:40:09.192554 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07549 (* 1 = 9.07549 loss)
I0522 23:40:09.254601 34819 sgd_solver.cpp:112] Iteration 12890, lr = 0.01
I0522 23:40:14.762665 34819 solver.cpp:239] Iteration 12900 (1.79538 iter/s, 5.56986s/10 iters), loss = 8.56788
I0522 23:40:14.762749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56788 (* 1 = 8.56788 loss)
I0522 23:40:15.577570 34819 sgd_solver.cpp:112] Iteration 12900, lr = 0.01
I0522 23:40:20.353011 34819 solver.cpp:239] Iteration 12910 (1.7889 iter/s, 5.59002s/10 iters), loss = 9.36407
I0522 23:40:20.353070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36407 (* 1 = 9.36407 loss)
I0522 23:40:20.422147 34819 sgd_solver.cpp:112] Iteration 12910, lr = 0.01
I0522 23:40:25.998420 34819 solver.cpp:239] Iteration 12920 (1.77144 iter/s, 5.64511s/10 iters), loss = 9.17277
I0522 23:40:25.998476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17277 (* 1 = 9.17277 loss)
I0522 23:40:26.647145 34819 sgd_solver.cpp:112] Iteration 12920, lr = 0.01
I0522 23:40:31.609148 34819 solver.cpp:239] Iteration 12930 (1.78239 iter/s, 5.61044s/10 iters), loss = 9.10894
I0522 23:40:31.609393 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10894 (* 1 = 9.10894 loss)
I0522 23:40:32.411278 34819 sgd_solver.cpp:112] Iteration 12930, lr = 0.01
I0522 23:40:39.340356 34819 solver.cpp:239] Iteration 12940 (1.29355 iter/s, 7.73069s/10 iters), loss = 9.24402
I0522 23:40:39.340410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24402 (* 1 = 9.24402 loss)
I0522 23:40:39.947700 34819 sgd_solver.cpp:112] Iteration 12940, lr = 0.01
I0522 23:40:45.737139 34819 solver.cpp:239] Iteration 12950 (1.56336 iter/s, 6.39647s/10 iters), loss = 9.10171
I0522 23:40:45.737180 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10171 (* 1 = 9.10171 loss)
I0522 23:40:46.377163 34819 sgd_solver.cpp:112] Iteration 12950, lr = 0.01
I0522 23:40:49.829576 34819 solver.cpp:239] Iteration 12960 (2.44366 iter/s, 4.09222s/10 iters), loss = 8.71453
I0522 23:40:49.829619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71453 (* 1 = 8.71453 loss)
I0522 23:40:50.541657 34819 sgd_solver.cpp:112] Iteration 12960, lr = 0.01
I0522 23:40:55.400601 34819 solver.cpp:239] Iteration 12970 (1.79509 iter/s, 5.57075s/10 iters), loss = 9.04044
I0522 23:40:55.400658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04044 (* 1 = 9.04044 loss)
I0522 23:40:55.799688 34819 sgd_solver.cpp:112] Iteration 12970, lr = 0.01
I0522 23:40:59.289538 34819 solver.cpp:239] Iteration 12980 (2.57154 iter/s, 3.88872s/10 iters), loss = 8.24017
I0522 23:40:59.289587 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24017 (* 1 = 8.24017 loss)
I0522 23:40:59.349999 34819 sgd_solver.cpp:112] Iteration 12980, lr = 0.01
I0522 23:41:02.683943 34819 solver.cpp:239] Iteration 12990 (2.9462 iter/s, 3.39421s/10 iters), loss = 9.30453
I0522 23:41:02.684104 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30453 (* 1 = 9.30453 loss)
I0522 23:41:03.544301 34819 sgd_solver.cpp:112] Iteration 12990, lr = 0.01
I0522 23:41:09.886940 34819 solver.cpp:239] Iteration 13000 (1.3884 iter/s, 7.20255s/10 iters), loss = 9.48605
I0522 23:41:09.886996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48605 (* 1 = 9.48605 loss)
I0522 23:41:09.956835 34819 sgd_solver.cpp:112] Iteration 13000, lr = 0.01
I0522 23:41:14.819648 34819 solver.cpp:239] Iteration 13010 (2.0274 iter/s, 4.93244s/10 iters), loss = 8.62854
I0522 23:41:14.819701 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62854 (* 1 = 8.62854 loss)
I0522 23:41:14.895033 34819 sgd_solver.cpp:112] Iteration 13010, lr = 0.01
I0522 23:41:20.986001 34819 solver.cpp:239] Iteration 13020 (1.62179 iter/s, 6.16604s/10 iters), loss = 8.99949
I0522 23:41:20.986045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99949 (* 1 = 8.99949 loss)
I0522 23:41:21.650998 34819 sgd_solver.cpp:112] Iteration 13020, lr = 0.01
I0522 23:41:25.690769 34819 solver.cpp:239] Iteration 13030 (2.12561 iter/s, 4.70452s/10 iters), loss = 7.94418
I0522 23:41:25.690812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94418 (* 1 = 7.94418 loss)
I0522 23:41:25.759270 34819 sgd_solver.cpp:112] Iteration 13030, lr = 0.01
I0522 23:41:30.794255 34819 solver.cpp:239] Iteration 13040 (1.95954 iter/s, 5.10323s/10 iters), loss = 8.63748
I0522 23:41:30.794298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63748 (* 1 = 8.63748 loss)
I0522 23:41:30.869024 34819 sgd_solver.cpp:112] Iteration 13040, lr = 0.01
I0522 23:41:35.996592 34819 solver.cpp:239] Iteration 13050 (1.92232 iter/s, 5.20205s/10 iters), loss = 9.22923
I0522 23:41:35.996814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22923 (* 1 = 9.22923 loss)
I0522 23:41:36.813637 34819 sgd_solver.cpp:112] Iteration 13050, lr = 0.01
I0522 23:41:40.742357 34819 solver.cpp:239] Iteration 13060 (2.10733 iter/s, 4.74535s/10 iters), loss = 8.9575
I0522 23:41:40.742414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9575 (* 1 = 8.9575 loss)
I0522 23:41:40.806030 34819 sgd_solver.cpp:112] Iteration 13060, lr = 0.01
I0522 23:41:44.310403 34819 solver.cpp:239] Iteration 13070 (2.80283 iter/s, 3.56782s/10 iters), loss = 8.43062
I0522 23:41:44.310456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43062 (* 1 = 8.43062 loss)
I0522 23:41:44.369591 34819 sgd_solver.cpp:112] Iteration 13070, lr = 0.01
I0522 23:41:48.043872 34819 solver.cpp:239] Iteration 13080 (2.67864 iter/s, 3.73323s/10 iters), loss = 8.72892
I0522 23:41:48.043943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72892 (* 1 = 8.72892 loss)
I0522 23:41:48.862572 34819 sgd_solver.cpp:112] Iteration 13080, lr = 0.01
I0522 23:41:54.195744 34819 solver.cpp:239] Iteration 13090 (1.62561 iter/s, 6.15153s/10 iters), loss = 8.87927
I0522 23:41:54.195808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87927 (* 1 = 8.87927 loss)
I0522 23:41:54.246636 34819 sgd_solver.cpp:112] Iteration 13090, lr = 0.01
I0522 23:41:56.026172 34819 solver.cpp:239] Iteration 13100 (5.46367 iter/s, 1.83027s/10 iters), loss = 8.84069
I0522 23:41:56.026221 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84069 (* 1 = 8.84069 loss)
I0522 23:41:56.786386 34819 sgd_solver.cpp:112] Iteration 13100, lr = 0.01
I0522 23:42:01.451766 34819 solver.cpp:239] Iteration 13110 (1.84321 iter/s, 5.42531s/10 iters), loss = 8.66266
I0522 23:42:01.451810 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66266 (* 1 = 8.66266 loss)
I0522 23:42:01.509523 34819 sgd_solver.cpp:112] Iteration 13110, lr = 0.01
I0522 23:42:05.560528 34819 solver.cpp:239] Iteration 13120 (2.43396 iter/s, 4.10853s/10 iters), loss = 8.43834
I0522 23:42:05.560582 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43834 (* 1 = 8.43834 loss)
I0522 23:42:05.629297 34819 sgd_solver.cpp:112] Iteration 13120, lr = 0.01
I0522 23:42:09.600780 34819 solver.cpp:239] Iteration 13130 (2.47523 iter/s, 4.04003s/10 iters), loss = 8.83737
I0522 23:42:09.600986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83737 (* 1 = 8.83737 loss)
I0522 23:42:09.681151 34819 sgd_solver.cpp:112] Iteration 13130, lr = 0.01
I0522 23:42:15.241237 34819 solver.cpp:239] Iteration 13140 (1.77304 iter/s, 5.64004s/10 iters), loss = 8.27929
I0522 23:42:15.241278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27929 (* 1 = 8.27929 loss)
I0522 23:42:15.327666 34819 sgd_solver.cpp:112] Iteration 13140, lr = 0.01
I0522 23:42:18.290194 34819 solver.cpp:239] Iteration 13150 (3.28 iter/s, 3.04878s/10 iters), loss = 9.29911
I0522 23:42:18.290235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29911 (* 1 = 9.29911 loss)
I0522 23:42:19.132104 34819 sgd_solver.cpp:112] Iteration 13150, lr = 0.01
I0522 23:42:23.973167 34819 solver.cpp:239] Iteration 13160 (1.75973 iter/s, 5.68269s/10 iters), loss = 9.16536
I0522 23:42:23.973224 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16536 (* 1 = 9.16536 loss)
I0522 23:42:24.041931 34819 sgd_solver.cpp:112] Iteration 13160, lr = 0.01
I0522 23:42:28.624575 34819 solver.cpp:239] Iteration 13170 (2.15001 iter/s, 4.65115s/10 iters), loss = 9.36651
I0522 23:42:28.624619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36651 (* 1 = 9.36651 loss)
I0522 23:42:28.694922 34819 sgd_solver.cpp:112] Iteration 13170, lr = 0.01
I0522 23:42:32.005823 34819 solver.cpp:239] Iteration 13180 (2.95766 iter/s, 3.38105s/10 iters), loss = 9.27229
I0522 23:42:32.005880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27229 (* 1 = 9.27229 loss)
I0522 23:42:32.809290 34819 sgd_solver.cpp:112] Iteration 13180, lr = 0.01
I0522 23:42:37.045950 34819 solver.cpp:239] Iteration 13190 (1.98419 iter/s, 5.03985s/10 iters), loss = 8.69653
I0522 23:42:37.046003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69653 (* 1 = 8.69653 loss)
I0522 23:42:37.867833 34819 sgd_solver.cpp:112] Iteration 13190, lr = 0.01
I0522 23:42:43.059463 34819 solver.cpp:239] Iteration 13200 (1.66301 iter/s, 6.0132s/10 iters), loss = 9.49081
I0522 23:42:43.059651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49081 (* 1 = 9.49081 loss)
I0522 23:42:43.846020 34819 sgd_solver.cpp:112] Iteration 13200, lr = 0.01
I0522 23:42:47.308336 34819 solver.cpp:239] Iteration 13210 (2.35377 iter/s, 4.24851s/10 iters), loss = 8.88659
I0522 23:42:47.308377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88659 (* 1 = 8.88659 loss)
I0522 23:42:47.541651 34819 sgd_solver.cpp:112] Iteration 13210, lr = 0.01
I0522 23:42:50.029201 34819 solver.cpp:239] Iteration 13220 (3.67559 iter/s, 2.72065s/10 iters), loss = 9.15515
I0522 23:42:50.029254 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15515 (* 1 = 9.15515 loss)
I0522 23:42:50.870637 34819 sgd_solver.cpp:112] Iteration 13220, lr = 0.01
I0522 23:42:55.997867 34819 solver.cpp:239] Iteration 13230 (1.6755 iter/s, 5.96836s/10 iters), loss = 9.28573
I0522 23:42:55.997911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28573 (* 1 = 9.28573 loss)
I0522 23:42:56.689909 34819 sgd_solver.cpp:112] Iteration 13230, lr = 0.01
I0522 23:43:00.501273 34819 solver.cpp:239] Iteration 13240 (2.22066 iter/s, 4.50317s/10 iters), loss = 9.252
I0522 23:43:00.501328 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.252 (* 1 = 9.252 loss)
I0522 23:43:00.573000 34819 sgd_solver.cpp:112] Iteration 13240, lr = 0.01
I0522 23:43:05.368057 34819 solver.cpp:239] Iteration 13250 (2.05486 iter/s, 4.86651s/10 iters), loss = 9.17021
I0522 23:43:05.368114 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17021 (* 1 = 9.17021 loss)
I0522 23:43:05.446161 34819 sgd_solver.cpp:112] Iteration 13250, lr = 0.01
I0522 23:43:11.363687 34819 solver.cpp:239] Iteration 13260 (1.66797 iter/s, 5.9953s/10 iters), loss = 8.84529
I0522 23:43:11.363754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84529 (* 1 = 8.84529 loss)
I0522 23:43:11.413063 34819 sgd_solver.cpp:112] Iteration 13260, lr = 0.01
I0522 23:43:17.181829 34819 solver.cpp:239] Iteration 13270 (1.71885 iter/s, 5.81783s/10 iters), loss = 8.58378
I0522 23:43:17.182029 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58378 (* 1 = 8.58378 loss)
I0522 23:43:17.866181 34819 sgd_solver.cpp:112] Iteration 13270, lr = 0.01
I0522 23:43:21.906436 34819 solver.cpp:239] Iteration 13280 (2.11674 iter/s, 4.72424s/10 iters), loss = 9.37914
I0522 23:43:21.906484 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37914 (* 1 = 9.37914 loss)
I0522 23:43:21.979236 34819 sgd_solver.cpp:112] Iteration 13280, lr = 0.01
I0522 23:43:25.888453 34819 solver.cpp:239] Iteration 13290 (2.51143 iter/s, 3.9818s/10 iters), loss = 9.67521
I0522 23:43:25.888497 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67521 (* 1 = 9.67521 loss)
I0522 23:43:25.947028 34819 sgd_solver.cpp:112] Iteration 13290, lr = 0.01
I0522 23:43:27.753955 34819 solver.cpp:239] Iteration 13300 (5.36087 iter/s, 1.86537s/10 iters), loss = 8.76797
I0522 23:43:27.754005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76797 (* 1 = 8.76797 loss)
I0522 23:43:27.823086 34819 sgd_solver.cpp:112] Iteration 13300, lr = 0.01
I0522 23:43:31.900297 34819 solver.cpp:239] Iteration 13310 (2.41191 iter/s, 4.14609s/10 iters), loss = 8.61812
I0522 23:43:31.900409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61812 (* 1 = 8.61812 loss)
I0522 23:43:32.640342 34819 sgd_solver.cpp:112] Iteration 13310, lr = 0.01
I0522 23:43:38.574082 34819 solver.cpp:239] Iteration 13320 (1.49848 iter/s, 6.67341s/10 iters), loss = 8.79246
I0522 23:43:38.574126 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79246 (* 1 = 8.79246 loss)
I0522 23:43:38.632146 34819 sgd_solver.cpp:112] Iteration 13320, lr = 0.01
I0522 23:43:44.992290 34819 solver.cpp:239] Iteration 13330 (1.55814 iter/s, 6.41789s/10 iters), loss = 9.13838
I0522 23:43:44.992338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13838 (* 1 = 9.13838 loss)
I0522 23:43:45.705024 34819 sgd_solver.cpp:112] Iteration 13330, lr = 0.01
I0522 23:43:49.806589 34819 solver.cpp:239] Iteration 13340 (2.07726 iter/s, 4.81404s/10 iters), loss = 8.80677
I0522 23:43:49.806824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80677 (* 1 = 8.80677 loss)
I0522 23:43:50.498522 34819 sgd_solver.cpp:112] Iteration 13340, lr = 0.01
I0522 23:43:56.820904 34819 solver.cpp:239] Iteration 13350 (1.42576 iter/s, 7.01381s/10 iters), loss = 9.09876
I0522 23:43:56.820971 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09876 (* 1 = 9.09876 loss)
I0522 23:43:56.879739 34819 sgd_solver.cpp:112] Iteration 13350, lr = 0.01
I0522 23:44:01.943325 34819 solver.cpp:239] Iteration 13360 (1.95231 iter/s, 5.12214s/10 iters), loss = 8.35004
I0522 23:44:01.943377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35004 (* 1 = 8.35004 loss)
I0522 23:44:02.012717 34819 sgd_solver.cpp:112] Iteration 13360, lr = 0.01
I0522 23:44:07.245843 34819 solver.cpp:239] Iteration 13370 (1.88599 iter/s, 5.30225s/10 iters), loss = 8.90359
I0522 23:44:07.245890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90359 (* 1 = 8.90359 loss)
I0522 23:44:08.106465 34819 sgd_solver.cpp:112] Iteration 13370, lr = 0.01
I0522 23:44:10.557574 34819 solver.cpp:239] Iteration 13380 (3.01975 iter/s, 3.31153s/10 iters), loss = 7.81709
I0522 23:44:10.557621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81709 (* 1 = 7.81709 loss)
I0522 23:44:10.616420 34819 sgd_solver.cpp:112] Iteration 13380, lr = 0.01
I0522 23:44:14.593755 34819 solver.cpp:239] Iteration 13390 (2.47773 iter/s, 4.03596s/10 iters), loss = 9.11259
I0522 23:44:14.593811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11259 (* 1 = 9.11259 loss)
I0522 23:44:14.678899 34819 sgd_solver.cpp:112] Iteration 13390, lr = 0.01
I0522 23:44:18.782284 34819 solver.cpp:239] Iteration 13400 (2.3876 iter/s, 4.1883s/10 iters), loss = 8.80295
I0522 23:44:18.782337 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80295 (* 1 = 8.80295 loss)
I0522 23:44:18.849565 34819 sgd_solver.cpp:112] Iteration 13400, lr = 0.01
I0522 23:44:21.384094 34819 solver.cpp:239] Iteration 13410 (3.84374 iter/s, 2.60163s/10 iters), loss = 7.91533
I0522 23:44:21.384351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91533 (* 1 = 7.91533 loss)
I0522 23:44:22.210019 34819 sgd_solver.cpp:112] Iteration 13410, lr = 0.01
I0522 23:44:27.442047 34819 solver.cpp:239] Iteration 13420 (1.65085 iter/s, 6.05747s/10 iters), loss = 8.62256
I0522 23:44:27.442101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62256 (* 1 = 8.62256 loss)
I0522 23:44:27.501102 34819 sgd_solver.cpp:112] Iteration 13420, lr = 0.01
I0522 23:44:32.285590 34819 solver.cpp:239] Iteration 13430 (2.06471 iter/s, 4.84329s/10 iters), loss = 8.15385
I0522 23:44:32.285637 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15385 (* 1 = 8.15385 loss)
I0522 23:44:32.345676 34819 sgd_solver.cpp:112] Iteration 13430, lr = 0.01
I0522 23:44:36.122891 34819 solver.cpp:239] Iteration 13440 (2.60614 iter/s, 3.83709s/10 iters), loss = 9.06671
I0522 23:44:36.122942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06671 (* 1 = 9.06671 loss)
I0522 23:44:36.664352 34819 sgd_solver.cpp:112] Iteration 13440, lr = 0.01
I0522 23:44:40.717248 34819 solver.cpp:239] Iteration 13450 (2.17671 iter/s, 4.59408s/10 iters), loss = 8.5489
I0522 23:44:40.717319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5489 (* 1 = 8.5489 loss)
I0522 23:44:41.507525 34819 sgd_solver.cpp:112] Iteration 13450, lr = 0.01
I0522 23:44:44.465715 34819 solver.cpp:239] Iteration 13460 (2.66792 iter/s, 3.74824s/10 iters), loss = 9.48858
I0522 23:44:44.465761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48858 (* 1 = 9.48858 loss)
I0522 23:44:44.721381 34819 sgd_solver.cpp:112] Iteration 13460, lr = 0.01
I0522 23:44:48.786785 34819 solver.cpp:239] Iteration 13470 (2.31437 iter/s, 4.32082s/10 iters), loss = 8.45624
I0522 23:44:48.786839 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45624 (* 1 = 8.45624 loss)
I0522 23:44:48.844214 34819 sgd_solver.cpp:112] Iteration 13470, lr = 0.01
I0522 23:44:53.312889 34819 solver.cpp:239] Iteration 13480 (2.20953 iter/s, 4.52585s/10 iters), loss = 8.76986
I0522 23:44:53.313052 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76986 (* 1 = 8.76986 loss)
I0522 23:44:53.375391 34819 sgd_solver.cpp:112] Iteration 13480, lr = 0.01
I0522 23:44:56.720701 34819 solver.cpp:239] Iteration 13490 (2.93468 iter/s, 3.40752s/10 iters), loss = 8.8299
I0522 23:44:56.720753 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8299 (* 1 = 8.8299 loss)
I0522 23:44:56.790642 34819 sgd_solver.cpp:112] Iteration 13490, lr = 0.01
I0522 23:45:00.444371 34819 solver.cpp:239] Iteration 13500 (2.68568 iter/s, 3.72345s/10 iters), loss = 8.68442
I0522 23:45:00.444427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68442 (* 1 = 8.68442 loss)
I0522 23:45:00.512269 34819 sgd_solver.cpp:112] Iteration 13500, lr = 0.01
I0522 23:45:05.406353 34819 solver.cpp:239] Iteration 13510 (2.01543 iter/s, 4.96172s/10 iters), loss = 9.31219
I0522 23:45:05.406400 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31219 (* 1 = 9.31219 loss)
I0522 23:45:05.469820 34819 sgd_solver.cpp:112] Iteration 13510, lr = 0.01
I0522 23:45:10.203997 34819 solver.cpp:239] Iteration 13520 (2.08447 iter/s, 4.79739s/10 iters), loss = 8.99146
I0522 23:45:10.204051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99146 (* 1 = 8.99146 loss)
I0522 23:45:10.268636 34819 sgd_solver.cpp:112] Iteration 13520, lr = 0.01
I0522 23:45:15.661851 34819 solver.cpp:239] Iteration 13530 (1.83232 iter/s, 5.45758s/10 iters), loss = 8.58326
I0522 23:45:15.661892 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58326 (* 1 = 8.58326 loss)
I0522 23:45:15.735699 34819 sgd_solver.cpp:112] Iteration 13530, lr = 0.01
I0522 23:45:19.768548 34819 solver.cpp:239] Iteration 13540 (2.43518 iter/s, 4.10648s/10 iters), loss = 8.62884
I0522 23:45:19.768605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62884 (* 1 = 8.62884 loss)
I0522 23:45:19.848649 34819 sgd_solver.cpp:112] Iteration 13540, lr = 0.01
I0522 23:45:25.061085 34819 solver.cpp:239] Iteration 13550 (1.88956 iter/s, 5.29225s/10 iters), loss = 9.60163
I0522 23:45:25.061344 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60163 (* 1 = 9.60163 loss)
I0522 23:45:25.119333 34819 sgd_solver.cpp:112] Iteration 13550, lr = 0.01
I0522 23:45:29.226538 34819 solver.cpp:239] Iteration 13560 (2.40094 iter/s, 4.16504s/10 iters), loss = 9.19423
I0522 23:45:29.226600 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19423 (* 1 = 9.19423 loss)
I0522 23:45:29.295817 34819 sgd_solver.cpp:112] Iteration 13560, lr = 0.01
I0522 23:45:32.508630 34819 solver.cpp:239] Iteration 13570 (3.04703 iter/s, 3.28189s/10 iters), loss = 8.39609
I0522 23:45:32.508679 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39609 (* 1 = 8.39609 loss)
I0522 23:45:33.272322 34819 sgd_solver.cpp:112] Iteration 13570, lr = 0.01
I0522 23:45:38.369791 34819 solver.cpp:239] Iteration 13580 (1.70623 iter/s, 5.86086s/10 iters), loss = 9.15956
I0522 23:45:38.369848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15956 (* 1 = 9.15956 loss)
I0522 23:45:38.437829 34819 sgd_solver.cpp:112] Iteration 13580, lr = 0.01
I0522 23:45:42.517200 34819 solver.cpp:239] Iteration 13590 (2.41128 iter/s, 4.14718s/10 iters), loss = 8.56203
I0522 23:45:42.517249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56203 (* 1 = 8.56203 loss)
I0522 23:45:42.573252 34819 sgd_solver.cpp:112] Iteration 13590, lr = 0.01
I0522 23:45:47.458204 34819 solver.cpp:239] Iteration 13600 (2.02399 iter/s, 4.94074s/10 iters), loss = 9.57679
I0522 23:45:47.458263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57679 (* 1 = 9.57679 loss)
I0522 23:45:47.656072 34819 sgd_solver.cpp:112] Iteration 13600, lr = 0.01
I0522 23:45:53.171838 34819 solver.cpp:239] Iteration 13610 (1.75029 iter/s, 5.71334s/10 iters), loss = 9.51925
I0522 23:45:53.171881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51925 (* 1 = 9.51925 loss)
I0522 23:45:53.244288 34819 sgd_solver.cpp:112] Iteration 13610, lr = 0.01
I0522 23:45:58.085171 34819 solver.cpp:239] Iteration 13620 (2.03538 iter/s, 4.91308s/10 iters), loss = 8.47953
I0522 23:45:58.085368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47953 (* 1 = 8.47953 loss)
I0522 23:45:58.896247 34819 sgd_solver.cpp:112] Iteration 13620, lr = 0.01
I0522 23:46:02.862716 34819 solver.cpp:239] Iteration 13630 (2.0933 iter/s, 4.77715s/10 iters), loss = 9.23004
I0522 23:46:02.862772 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23004 (* 1 = 9.23004 loss)
I0522 23:46:02.917606 34819 sgd_solver.cpp:112] Iteration 13630, lr = 0.01
I0522 23:46:06.813381 34819 solver.cpp:239] Iteration 13640 (2.53137 iter/s, 3.95043s/10 iters), loss = 8.92555
I0522 23:46:06.813431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92555 (* 1 = 8.92555 loss)
I0522 23:46:06.871814 34819 sgd_solver.cpp:112] Iteration 13640, lr = 0.01
I0522 23:46:10.284328 34819 solver.cpp:239] Iteration 13650 (2.88122 iter/s, 3.47075s/10 iters), loss = 8.45748
I0522 23:46:10.284376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45748 (* 1 = 8.45748 loss)
I0522 23:46:11.040884 34819 sgd_solver.cpp:112] Iteration 13650, lr = 0.01
I0522 23:46:17.388967 34819 solver.cpp:239] Iteration 13660 (1.4076 iter/s, 7.1043s/10 iters), loss = 9.27996
I0522 23:46:17.389011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27996 (* 1 = 9.27996 loss)
I0522 23:46:18.250138 34819 sgd_solver.cpp:112] Iteration 13660, lr = 0.01
I0522 23:46:23.663859 34819 solver.cpp:239] Iteration 13670 (1.59373 iter/s, 6.27458s/10 iters), loss = 8.78358
I0522 23:46:23.663911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78358 (* 1 = 8.78358 loss)
I0522 23:46:24.368676 34819 sgd_solver.cpp:112] Iteration 13670, lr = 0.01
I0522 23:46:28.901065 34819 solver.cpp:239] Iteration 13680 (1.90951 iter/s, 5.23694s/10 iters), loss = 8.51572
I0522 23:46:28.901216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51572 (* 1 = 8.51572 loss)
I0522 23:46:28.955621 34819 sgd_solver.cpp:112] Iteration 13680, lr = 0.01
I0522 23:46:34.778856 34819 solver.cpp:239] Iteration 13690 (1.70143 iter/s, 5.87739s/10 iters), loss = 8.60252
I0522 23:46:34.778913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60252 (* 1 = 8.60252 loss)
I0522 23:46:34.860209 34819 sgd_solver.cpp:112] Iteration 13690, lr = 0.01
I0522 23:46:39.519726 34819 solver.cpp:239] Iteration 13700 (2.10943 iter/s, 4.74061s/10 iters), loss = 8.32527
I0522 23:46:39.519775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32527 (* 1 = 8.32527 loss)
I0522 23:46:40.384320 34819 sgd_solver.cpp:112] Iteration 13700, lr = 0.01
I0522 23:46:43.260125 34819 solver.cpp:239] Iteration 13710 (2.67366 iter/s, 3.74018s/10 iters), loss = 8.27034
I0522 23:46:43.260175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27034 (* 1 = 8.27034 loss)
I0522 23:46:44.065037 34819 sgd_solver.cpp:112] Iteration 13710, lr = 0.01
I0522 23:46:49.473835 34819 solver.cpp:239] Iteration 13720 (1.60943 iter/s, 6.21338s/10 iters), loss = 9.02246
I0522 23:46:49.473888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02246 (* 1 = 9.02246 loss)
I0522 23:46:50.314821 34819 sgd_solver.cpp:112] Iteration 13720, lr = 0.01
I0522 23:46:56.335631 34819 solver.cpp:239] Iteration 13730 (1.45742 iter/s, 6.86145s/10 iters), loss = 8.32117
I0522 23:46:56.335687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32117 (* 1 = 8.32117 loss)
I0522 23:46:57.006423 34819 sgd_solver.cpp:112] Iteration 13730, lr = 0.01
I0522 23:47:01.106283 34819 solver.cpp:239] Iteration 13740 (2.09626 iter/s, 4.77039s/10 iters), loss = 8.30643
I0522 23:47:01.106442 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30643 (* 1 = 8.30643 loss)
I0522 23:47:01.170471 34819 sgd_solver.cpp:112] Iteration 13740, lr = 0.01
I0522 23:47:08.003868 34819 solver.cpp:239] Iteration 13750 (1.44987 iter/s, 6.89715s/10 iters), loss = 9.23857
I0522 23:47:08.003916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23857 (* 1 = 9.23857 loss)
I0522 23:47:08.076997 34819 sgd_solver.cpp:112] Iteration 13750, lr = 0.01
I0522 23:47:13.506738 34819 solver.cpp:239] Iteration 13760 (1.81733 iter/s, 5.50259s/10 iters), loss = 8.55018
I0522 23:47:13.506785 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55018 (* 1 = 8.55018 loss)
I0522 23:47:13.575641 34819 sgd_solver.cpp:112] Iteration 13760, lr = 0.01
I0522 23:47:18.525710 34819 solver.cpp:239] Iteration 13770 (1.99255 iter/s, 5.01871s/10 iters), loss = 8.74045
I0522 23:47:18.525774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74045 (* 1 = 8.74045 loss)
I0522 23:47:18.589577 34819 sgd_solver.cpp:112] Iteration 13770, lr = 0.01
I0522 23:47:21.967283 34819 solver.cpp:239] Iteration 13780 (2.90582 iter/s, 3.44137s/10 iters), loss = 8.99977
I0522 23:47:21.967330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99977 (* 1 = 8.99977 loss)
I0522 23:47:22.040624 34819 sgd_solver.cpp:112] Iteration 13780, lr = 0.01
I0522 23:47:26.083014 34819 solver.cpp:239] Iteration 13790 (2.42983 iter/s, 4.11551s/10 iters), loss = 9.40918
I0522 23:47:26.083065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40918 (* 1 = 9.40918 loss)
I0522 23:47:26.843602 34819 sgd_solver.cpp:112] Iteration 13790, lr = 0.01
I0522 23:47:31.907155 34819 solver.cpp:239] Iteration 13800 (1.71709 iter/s, 5.82382s/10 iters), loss = 8.64149
I0522 23:47:31.907358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64149 (* 1 = 8.64149 loss)
I0522 23:47:31.977223 34819 sgd_solver.cpp:112] Iteration 13800, lr = 0.01
I0522 23:47:36.191720 34819 solver.cpp:239] Iteration 13810 (2.33416 iter/s, 4.2842s/10 iters), loss = 9.07021
I0522 23:47:36.191766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07021 (* 1 = 9.07021 loss)
I0522 23:47:36.248908 34819 sgd_solver.cpp:112] Iteration 13810, lr = 0.01
I0522 23:47:39.683727 34819 solver.cpp:239] Iteration 13820 (2.86387 iter/s, 3.49178s/10 iters), loss = 9.32467
I0522 23:47:39.683795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32467 (* 1 = 9.32467 loss)
I0522 23:47:40.497673 34819 sgd_solver.cpp:112] Iteration 13820, lr = 0.01
I0522 23:47:45.138525 34819 solver.cpp:239] Iteration 13830 (1.83335 iter/s, 5.45451s/10 iters), loss = 8.6654
I0522 23:47:45.138581 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6654 (* 1 = 8.6654 loss)
I0522 23:47:45.967012 34819 sgd_solver.cpp:112] Iteration 13830, lr = 0.01
I0522 23:47:52.287932 34819 solver.cpp:239] Iteration 13840 (1.39879 iter/s, 7.14901s/10 iters), loss = 9.40875
I0522 23:47:52.287986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40875 (* 1 = 9.40875 loss)
I0522 23:47:53.076684 34819 sgd_solver.cpp:112] Iteration 13840, lr = 0.01
I0522 23:47:56.578943 34819 solver.cpp:239] Iteration 13850 (2.33059 iter/s, 4.29076s/10 iters), loss = 8.19607
I0522 23:47:56.578989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19607 (* 1 = 8.19607 loss)
I0522 23:47:57.410598 34819 sgd_solver.cpp:112] Iteration 13850, lr = 0.01
I0522 23:48:01.675293 34819 solver.cpp:239] Iteration 13860 (1.9623 iter/s, 5.09607s/10 iters), loss = 8.58067
I0522 23:48:01.675364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58067 (* 1 = 8.58067 loss)
I0522 23:48:02.451838 34819 sgd_solver.cpp:112] Iteration 13860, lr = 0.01
I0522 23:48:07.208467 34819 solver.cpp:239] Iteration 13870 (1.80738 iter/s, 5.53287s/10 iters), loss = 9.24814
I0522 23:48:07.208528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24814 (* 1 = 9.24814 loss)
I0522 23:48:07.340080 34819 sgd_solver.cpp:112] Iteration 13870, lr = 0.01
I0522 23:48:13.172633 34819 solver.cpp:239] Iteration 13880 (1.67677 iter/s, 5.96385s/10 iters), loss = 8.58683
I0522 23:48:13.172699 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58683 (* 1 = 8.58683 loss)
I0522 23:48:13.242470 34819 sgd_solver.cpp:112] Iteration 13880, lr = 0.01
I0522 23:48:17.751859 34819 solver.cpp:239] Iteration 13890 (2.1839 iter/s, 4.57897s/10 iters), loss = 8.67755
I0522 23:48:17.751910 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67755 (* 1 = 8.67755 loss)
I0522 23:48:17.823338 34819 sgd_solver.cpp:112] Iteration 13890, lr = 0.01
I0522 23:48:21.622854 34819 solver.cpp:239] Iteration 13900 (2.58346 iter/s, 3.87077s/10 iters), loss = 9.10473
I0522 23:48:21.622911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10473 (* 1 = 9.10473 loss)
I0522 23:48:22.209187 34819 sgd_solver.cpp:112] Iteration 13900, lr = 0.01
I0522 23:48:26.252168 34819 solver.cpp:239] Iteration 13910 (2.16026 iter/s, 4.62907s/10 iters), loss = 9.72474
I0522 23:48:26.252221 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72474 (* 1 = 9.72474 loss)
I0522 23:48:27.021373 34819 sgd_solver.cpp:112] Iteration 13910, lr = 0.01
I0522 23:48:30.933981 34819 solver.cpp:239] Iteration 13920 (2.13604 iter/s, 4.68157s/10 iters), loss = 8.3577
I0522 23:48:30.934026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3577 (* 1 = 8.3577 loss)
I0522 23:48:31.640523 34819 sgd_solver.cpp:112] Iteration 13920, lr = 0.01
I0522 23:48:35.004900 34819 solver.cpp:239] Iteration 13930 (2.45658 iter/s, 4.0707s/10 iters), loss = 9.72758
I0522 23:48:35.005038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72758 (* 1 = 9.72758 loss)
I0522 23:48:35.841678 34819 sgd_solver.cpp:112] Iteration 13930, lr = 0.01
I0522 23:48:41.683168 34819 solver.cpp:239] Iteration 13940 (1.49749 iter/s, 6.67785s/10 iters), loss = 8.92454
I0522 23:48:41.683224 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92454 (* 1 = 8.92454 loss)
I0522 23:48:42.499222 34819 sgd_solver.cpp:112] Iteration 13940, lr = 0.01
I0522 23:48:47.329751 34819 solver.cpp:239] Iteration 13950 (1.77107 iter/s, 5.6463s/10 iters), loss = 8.1517
I0522 23:48:47.329797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1517 (* 1 = 8.1517 loss)
I0522 23:48:48.116304 34819 sgd_solver.cpp:112] Iteration 13950, lr = 0.01
I0522 23:48:52.937894 34819 solver.cpp:239] Iteration 13960 (1.78322 iter/s, 5.60784s/10 iters), loss = 8.99388
I0522 23:48:52.937954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99388 (* 1 = 8.99388 loss)
I0522 23:48:53.007408 34819 sgd_solver.cpp:112] Iteration 13960, lr = 0.01
I0522 23:48:56.238109 34819 solver.cpp:239] Iteration 13970 (3.03031 iter/s, 3.3s/10 iters), loss = 8.77019
I0522 23:48:56.238160 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77019 (* 1 = 8.77019 loss)
I0522 23:48:56.308048 34819 sgd_solver.cpp:112] Iteration 13970, lr = 0.01
I0522 23:49:03.345502 34819 solver.cpp:239] Iteration 13980 (1.40706 iter/s, 7.10704s/10 iters), loss = 8.46156
I0522 23:49:03.345561 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46156 (* 1 = 8.46156 loss)
I0522 23:49:03.970257 34819 sgd_solver.cpp:112] Iteration 13980, lr = 0.01
I0522 23:49:06.710052 34819 solver.cpp:239] Iteration 13990 (2.97234 iter/s, 3.36435s/10 iters), loss = 9.0629
I0522 23:49:06.710297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0629 (* 1 = 9.0629 loss)
I0522 23:49:06.822382 34819 sgd_solver.cpp:112] Iteration 13990, lr = 0.01
I0522 23:49:09.796226 34819 solver.cpp:239] Iteration 14000 (3.24063 iter/s, 3.08582s/10 iters), loss = 8.57551
I0522 23:49:09.796279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57551 (* 1 = 8.57551 loss)
I0522 23:49:10.167223 34819 sgd_solver.cpp:112] Iteration 14000, lr = 0.01
I0522 23:49:13.915082 34819 solver.cpp:239] Iteration 14010 (2.42799 iter/s, 4.11863s/10 iters), loss = 8.43418
I0522 23:49:13.915134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43418 (* 1 = 8.43418 loss)
I0522 23:49:13.972610 34819 sgd_solver.cpp:112] Iteration 14010, lr = 0.01
I0522 23:49:19.604732 34819 solver.cpp:239] Iteration 14020 (1.75767 iter/s, 5.68936s/10 iters), loss = 9.07556
I0522 23:49:19.604786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07556 (* 1 = 9.07556 loss)
I0522 23:49:20.398725 34819 sgd_solver.cpp:112] Iteration 14020, lr = 0.01
I0522 23:49:24.351459 34819 solver.cpp:239] Iteration 14030 (2.10683 iter/s, 4.74647s/10 iters), loss = 8.35953
I0522 23:49:24.351501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35953 (* 1 = 8.35953 loss)
I0522 23:49:24.428843 34819 sgd_solver.cpp:112] Iteration 14030, lr = 0.01
I0522 23:49:29.665623 34819 solver.cpp:239] Iteration 14040 (1.88186 iter/s, 5.3139s/10 iters), loss = 8.73959
I0522 23:49:29.665665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73959 (* 1 = 8.73959 loss)
I0522 23:49:29.744750 34819 sgd_solver.cpp:112] Iteration 14040, lr = 0.01
I0522 23:49:34.512508 34819 solver.cpp:239] Iteration 14050 (2.06329 iter/s, 4.84663s/10 iters), loss = 8.89648
I0522 23:49:34.512552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89648 (* 1 = 8.89648 loss)
I0522 23:49:35.262702 34819 sgd_solver.cpp:112] Iteration 14050, lr = 0.01
I0522 23:49:39.217520 34819 solver.cpp:239] Iteration 14060 (2.12551 iter/s, 4.70476s/10 iters), loss = 9.08914
I0522 23:49:39.217615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08914 (* 1 = 9.08914 loss)
I0522 23:49:39.287657 34819 sgd_solver.cpp:112] Iteration 14060, lr = 0.01
I0522 23:49:42.692276 34819 solver.cpp:239] Iteration 14070 (2.87811 iter/s, 3.47451s/10 iters), loss = 9.2849
I0522 23:49:42.692322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2849 (* 1 = 9.2849 loss)
I0522 23:49:42.761162 34819 sgd_solver.cpp:112] Iteration 14070, lr = 0.01
I0522 23:49:48.385926 34819 solver.cpp:239] Iteration 14080 (1.75643 iter/s, 5.69336s/10 iters), loss = 7.87136
I0522 23:49:48.385968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87136 (* 1 = 7.87136 loss)
I0522 23:49:49.123164 34819 sgd_solver.cpp:112] Iteration 14080, lr = 0.01
I0522 23:49:53.201216 34819 solver.cpp:239] Iteration 14090 (2.07684 iter/s, 4.815s/10 iters), loss = 8.58096
I0522 23:49:53.201269 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58096 (* 1 = 8.58096 loss)
I0522 23:49:53.977221 34819 sgd_solver.cpp:112] Iteration 14090, lr = 0.01
I0522 23:49:58.412645 34819 solver.cpp:239] Iteration 14100 (1.91897 iter/s, 5.21112s/10 iters), loss = 8.89331
I0522 23:49:58.412698 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89331 (* 1 = 8.89331 loss)
I0522 23:49:59.183511 34819 sgd_solver.cpp:112] Iteration 14100, lr = 0.01
I0522 23:50:04.527259 34819 solver.cpp:239] Iteration 14110 (1.63551 iter/s, 6.11431s/10 iters), loss = 8.60749
I0522 23:50:04.527307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60749 (* 1 = 8.60749 loss)
I0522 23:50:05.357264 34819 sgd_solver.cpp:112] Iteration 14110, lr = 0.01
I0522 23:50:11.293139 34819 solver.cpp:239] Iteration 14120 (1.47808 iter/s, 6.76555s/10 iters), loss = 8.05702
I0522 23:50:11.293340 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05702 (* 1 = 8.05702 loss)
I0522 23:50:11.362648 34819 sgd_solver.cpp:112] Iteration 14120, lr = 0.01
I0522 23:50:16.399811 34819 solver.cpp:239] Iteration 14130 (1.95838 iter/s, 5.10627s/10 iters), loss = 8.61027
I0522 23:50:16.399866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61027 (* 1 = 8.61027 loss)
I0522 23:50:17.139129 34819 sgd_solver.cpp:112] Iteration 14130, lr = 0.01
I0522 23:50:23.468600 34819 solver.cpp:239] Iteration 14140 (1.41474 iter/s, 7.06844s/10 iters), loss = 8.73724
I0522 23:50:23.468652 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73724 (* 1 = 8.73724 loss)
I0522 23:50:23.546617 34819 sgd_solver.cpp:112] Iteration 14140, lr = 0.01
I0522 23:50:28.380661 34819 solver.cpp:239] Iteration 14150 (2.03591 iter/s, 4.9118s/10 iters), loss = 8.05601
I0522 23:50:28.380703 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05601 (* 1 = 8.05601 loss)
I0522 23:50:29.228022 34819 sgd_solver.cpp:112] Iteration 14150, lr = 0.01
I0522 23:50:32.491184 34819 solver.cpp:239] Iteration 14160 (2.43292 iter/s, 4.11029s/10 iters), loss = 9.17601
I0522 23:50:32.491230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17601 (* 1 = 9.17601 loss)
I0522 23:50:32.568784 34819 sgd_solver.cpp:112] Iteration 14160, lr = 0.01
I0522 23:50:35.278708 34819 solver.cpp:239] Iteration 14170 (3.58766 iter/s, 2.78734s/10 iters), loss = 9.1294
I0522 23:50:35.278755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1294 (* 1 = 9.1294 loss)
I0522 23:50:36.113080 34819 sgd_solver.cpp:112] Iteration 14170, lr = 0.01
I0522 23:50:40.894289 34819 solver.cpp:239] Iteration 14180 (1.78085 iter/s, 5.61529s/10 iters), loss = 8.63769
I0522 23:50:40.894343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63769 (* 1 = 8.63769 loss)
I0522 23:50:40.967067 34819 sgd_solver.cpp:112] Iteration 14180, lr = 0.01
I0522 23:50:46.367130 34819 solver.cpp:239] Iteration 14190 (1.8273 iter/s, 5.47255s/10 iters), loss = 8.79557
I0522 23:50:46.367391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79557 (* 1 = 8.79557 loss)
I0522 23:50:47.224925 34819 sgd_solver.cpp:112] Iteration 14190, lr = 0.01
I0522 23:50:52.764888 34819 solver.cpp:239] Iteration 14200 (1.56317 iter/s, 6.39725s/10 iters), loss = 8.93082
I0522 23:50:52.764952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93082 (* 1 = 8.93082 loss)
I0522 23:50:53.637744 34819 sgd_solver.cpp:112] Iteration 14200, lr = 0.01
I0522 23:50:59.902550 34819 solver.cpp:239] Iteration 14210 (1.40109 iter/s, 7.1373s/10 iters), loss = 8.39175
I0522 23:50:59.902619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39175 (* 1 = 8.39175 loss)
I0522 23:51:00.660004 34819 sgd_solver.cpp:112] Iteration 14210, lr = 0.01
I0522 23:51:05.394870 34819 solver.cpp:239] Iteration 14220 (1.82082 iter/s, 5.49203s/10 iters), loss = 9.07914
I0522 23:51:05.394915 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07914 (* 1 = 9.07914 loss)
I0522 23:51:05.471155 34819 sgd_solver.cpp:112] Iteration 14220, lr = 0.01
I0522 23:51:11.941889 34819 solver.cpp:239] Iteration 14230 (1.52749 iter/s, 6.5467s/10 iters), loss = 9.00481
I0522 23:51:11.941939 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00481 (* 1 = 9.00481 loss)
I0522 23:51:12.011374 34819 sgd_solver.cpp:112] Iteration 14230, lr = 0.01
I0522 23:51:15.704421 34819 solver.cpp:239] Iteration 14240 (2.65793 iter/s, 3.76232s/10 iters), loss = 8.88206
I0522 23:51:15.704468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88206 (* 1 = 8.88206 loss)
I0522 23:51:16.483752 34819 sgd_solver.cpp:112] Iteration 14240, lr = 0.01
I0522 23:51:19.937274 34819 solver.cpp:239] Iteration 14250 (2.3626 iter/s, 4.23262s/10 iters), loss = 8.74605
I0522 23:51:19.937336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74605 (* 1 = 8.74605 loss)
I0522 23:51:20.470414 34819 sgd_solver.cpp:112] Iteration 14250, lr = 0.01
I0522 23:51:25.804785 34819 solver.cpp:239] Iteration 14260 (1.70439 iter/s, 5.8672s/10 iters), loss = 9.01691
I0522 23:51:25.804836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01691 (* 1 = 9.01691 loss)
I0522 23:51:25.883097 34819 sgd_solver.cpp:112] Iteration 14260, lr = 0.01
I0522 23:51:29.926501 34819 solver.cpp:239] Iteration 14270 (2.42632 iter/s, 4.12148s/10 iters), loss = 9.00856
I0522 23:51:29.926558 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00856 (* 1 = 9.00856 loss)
I0522 23:51:30.012559 34819 sgd_solver.cpp:112] Iteration 14270, lr = 0.01
I0522 23:51:32.280941 34819 solver.cpp:239] Iteration 14280 (4.24763 iter/s, 2.35425s/10 iters), loss = 8.54218
I0522 23:51:32.280997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54218 (* 1 = 8.54218 loss)
I0522 23:51:33.023916 34819 sgd_solver.cpp:112] Iteration 14280, lr = 0.01
I0522 23:51:36.717207 34819 solver.cpp:239] Iteration 14290 (2.25428 iter/s, 4.436s/10 iters), loss = 8.99327
I0522 23:51:36.717268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99327 (* 1 = 8.99327 loss)
I0522 23:51:37.585430 34819 sgd_solver.cpp:112] Iteration 14290, lr = 0.01
I0522 23:51:42.279968 34819 solver.cpp:239] Iteration 14300 (1.79777 iter/s, 5.56246s/10 iters), loss = 8.11938
I0522 23:51:42.280021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11938 (* 1 = 8.11938 loss)
I0522 23:51:43.016319 34819 sgd_solver.cpp:112] Iteration 14300, lr = 0.01
I0522 23:51:46.878394 34819 solver.cpp:239] Iteration 14310 (2.17478 iter/s, 4.59816s/10 iters), loss = 8.47207
I0522 23:51:46.878551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47207 (* 1 = 8.47207 loss)
I0522 23:51:47.655576 34819 sgd_solver.cpp:112] Iteration 14310, lr = 0.01
I0522 23:51:51.532110 34819 solver.cpp:239] Iteration 14320 (2.14898 iter/s, 4.65337s/10 iters), loss = 9.11577
I0522 23:51:51.532155 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11577 (* 1 = 9.11577 loss)
I0522 23:51:52.293567 34819 sgd_solver.cpp:112] Iteration 14320, lr = 0.01
I0522 23:51:57.641391 34819 solver.cpp:239] Iteration 14330 (1.63694 iter/s, 6.10896s/10 iters), loss = 8.41691
I0522 23:51:57.641451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41691 (* 1 = 8.41691 loss)
I0522 23:51:58.099954 34819 sgd_solver.cpp:112] Iteration 14330, lr = 0.01
I0522 23:52:01.705958 34819 solver.cpp:239] Iteration 14340 (2.46043 iter/s, 4.06433s/10 iters), loss = 8.49176
I0522 23:52:01.706018 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49176 (* 1 = 8.49176 loss)
I0522 23:52:01.770735 34819 sgd_solver.cpp:112] Iteration 14340, lr = 0.01
I0522 23:52:05.648573 34819 solver.cpp:239] Iteration 14350 (2.53654 iter/s, 3.94238s/10 iters), loss = 8.81677
I0522 23:52:05.648622 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81677 (* 1 = 8.81677 loss)
I0522 23:52:05.697609 34819 sgd_solver.cpp:112] Iteration 14350, lr = 0.01
I0522 23:52:10.383777 34819 solver.cpp:239] Iteration 14360 (2.11195 iter/s, 4.73495s/10 iters), loss = 8.83366
I0522 23:52:10.383836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83366 (* 1 = 8.83366 loss)
I0522 23:52:11.140260 34819 sgd_solver.cpp:112] Iteration 14360, lr = 0.01
I0522 23:52:14.511449 34819 solver.cpp:239] Iteration 14370 (2.42282 iter/s, 4.12741s/10 iters), loss = 8.6175
I0522 23:52:14.511507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6175 (* 1 = 8.6175 loss)
I0522 23:52:15.055495 34819 sgd_solver.cpp:112] Iteration 14370, lr = 0.01
I0522 23:52:20.256433 34819 solver.cpp:239] Iteration 14380 (1.74074 iter/s, 5.7447s/10 iters), loss = 9.19016
I0522 23:52:20.256698 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19016 (* 1 = 9.19016 loss)
I0522 23:52:21.032191 34819 sgd_solver.cpp:112] Iteration 14380, lr = 0.01
I0522 23:52:27.293992 34819 solver.cpp:239] Iteration 14390 (1.42105 iter/s, 7.03704s/10 iters), loss = 8.4777
I0522 23:52:27.294034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4777 (* 1 = 8.4777 loss)
I0522 23:52:27.359900 34819 sgd_solver.cpp:112] Iteration 14390, lr = 0.01
I0522 23:52:31.646081 34819 solver.cpp:239] Iteration 14400 (2.29787 iter/s, 4.35186s/10 iters), loss = 8.27261
I0522 23:52:31.646131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27261 (* 1 = 8.27261 loss)
I0522 23:52:32.424386 34819 sgd_solver.cpp:112] Iteration 14400, lr = 0.01
I0522 23:52:37.854501 34819 solver.cpp:239] Iteration 14410 (1.6108 iter/s, 6.20811s/10 iters), loss = 8.33877
I0522 23:52:37.854547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33877 (* 1 = 8.33877 loss)
I0522 23:52:37.917241 34819 sgd_solver.cpp:112] Iteration 14410, lr = 0.01
I0522 23:52:45.099647 34819 solver.cpp:239] Iteration 14420 (1.3803 iter/s, 7.24479s/10 iters), loss = 8.18585
I0522 23:52:45.099697 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18585 (* 1 = 8.18585 loss)
I0522 23:52:45.935506 34819 sgd_solver.cpp:112] Iteration 14420, lr = 0.01
I0522 23:52:50.018168 34819 solver.cpp:239] Iteration 14430 (2.03324 iter/s, 4.91826s/10 iters), loss = 8.37346
I0522 23:52:50.018219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37346 (* 1 = 8.37346 loss)
I0522 23:52:50.829694 34819 sgd_solver.cpp:112] Iteration 14430, lr = 0.01
I0522 23:52:55.463713 34819 solver.cpp:239] Iteration 14440 (1.83647 iter/s, 5.44524s/10 iters), loss = 8.41104
I0522 23:52:55.463755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41104 (* 1 = 8.41104 loss)
I0522 23:52:55.561915 34819 sgd_solver.cpp:112] Iteration 14440, lr = 0.01
I0522 23:53:01.472582 34819 solver.cpp:239] Iteration 14450 (1.66429 iter/s, 6.00857s/10 iters), loss = 9.41948
I0522 23:53:01.472635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41948 (* 1 = 9.41948 loss)
I0522 23:53:01.547269 34819 sgd_solver.cpp:112] Iteration 14450, lr = 0.01
I0522 23:53:05.743026 34819 solver.cpp:239] Iteration 14460 (2.34181 iter/s, 4.27021s/10 iters), loss = 9.16942
I0522 23:53:05.743078 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16942 (* 1 = 9.16942 loss)
I0522 23:53:06.613313 34819 sgd_solver.cpp:112] Iteration 14460, lr = 0.01
I0522 23:53:10.006966 34819 solver.cpp:239] Iteration 14470 (2.34539 iter/s, 4.26369s/10 iters), loss = 8.67311
I0522 23:53:10.007021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67311 (* 1 = 8.67311 loss)
I0522 23:53:10.742911 34819 sgd_solver.cpp:112] Iteration 14470, lr = 0.01
I0522 23:53:15.154474 34819 solver.cpp:239] Iteration 14480 (1.94279 iter/s, 5.14723s/10 iters), loss = 8.86323
I0522 23:53:15.154547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86323 (* 1 = 8.86323 loss)
I0522 23:53:15.926662 34819 sgd_solver.cpp:112] Iteration 14480, lr = 0.01
I0522 23:53:20.160892 34819 solver.cpp:239] Iteration 14490 (1.99755 iter/s, 5.00613s/10 iters), loss = 8.70071
I0522 23:53:20.160931 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70071 (* 1 = 8.70071 loss)
I0522 23:53:20.418557 34819 sgd_solver.cpp:112] Iteration 14490, lr = 0.01
I0522 23:53:26.031615 34819 solver.cpp:239] Iteration 14500 (1.70345 iter/s, 5.87044s/10 iters), loss = 8.89413
I0522 23:53:26.031787 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89413 (* 1 = 8.89413 loss)
I0522 23:53:26.090684 34819 sgd_solver.cpp:112] Iteration 14500, lr = 0.01
I0522 23:53:31.857486 34819 solver.cpp:239] Iteration 14510 (1.7166 iter/s, 5.82547s/10 iters), loss = 9.33624
I0522 23:53:31.857551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33624 (* 1 = 9.33624 loss)
I0522 23:53:31.997953 34819 sgd_solver.cpp:112] Iteration 14510, lr = 0.01
I0522 23:53:36.774822 34819 solver.cpp:239] Iteration 14520 (2.03373 iter/s, 4.91707s/10 iters), loss = 7.9408
I0522 23:53:36.774865 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9408 (* 1 = 7.9408 loss)
I0522 23:53:36.835346 34819 sgd_solver.cpp:112] Iteration 14520, lr = 0.01
I0522 23:53:42.860414 34819 solver.cpp:239] Iteration 14530 (1.64331 iter/s, 6.08528s/10 iters), loss = 9.33084
I0522 23:53:42.860469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33084 (* 1 = 9.33084 loss)
I0522 23:53:42.929345 34819 sgd_solver.cpp:112] Iteration 14530, lr = 0.01
I0522 23:53:47.129830 34819 solver.cpp:239] Iteration 14540 (2.34237 iter/s, 4.26918s/10 iters), loss = 8.31263
I0522 23:53:47.129884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31263 (* 1 = 8.31263 loss)
I0522 23:53:47.195545 34819 sgd_solver.cpp:112] Iteration 14540, lr = 0.01
I0522 23:53:53.352787 34819 solver.cpp:239] Iteration 14550 (1.60704 iter/s, 6.22263s/10 iters), loss = 9.44921
I0522 23:53:53.352859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44921 (* 1 = 9.44921 loss)
I0522 23:53:53.411504 34819 sgd_solver.cpp:112] Iteration 14550, lr = 0.01
I0522 23:53:56.880370 34819 solver.cpp:239] Iteration 14560 (2.83498 iter/s, 3.52737s/10 iters), loss = 8.04566
I0522 23:53:56.880612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04566 (* 1 = 8.04566 loss)
I0522 23:53:57.590507 34819 sgd_solver.cpp:112] Iteration 14560, lr = 0.01
I0522 23:54:02.093116 34819 solver.cpp:239] Iteration 14570 (1.91854 iter/s, 5.21231s/10 iters), loss = 9.60962
I0522 23:54:02.093158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60962 (* 1 = 9.60962 loss)
I0522 23:54:02.793998 34819 sgd_solver.cpp:112] Iteration 14570, lr = 0.01
I0522 23:54:08.703315 34819 solver.cpp:239] Iteration 14580 (1.51289 iter/s, 6.60987s/10 iters), loss = 8.72539
I0522 23:54:08.703361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72539 (* 1 = 8.72539 loss)
I0522 23:54:08.754010 34819 sgd_solver.cpp:112] Iteration 14580, lr = 0.01
I0522 23:54:14.328168 34819 solver.cpp:239] Iteration 14590 (1.77791 iter/s, 5.62457s/10 iters), loss = 9.30657
I0522 23:54:14.328210 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30657 (* 1 = 9.30657 loss)
I0522 23:54:14.395373 34819 sgd_solver.cpp:112] Iteration 14590, lr = 0.01
I0522 23:54:20.717046 34819 solver.cpp:239] Iteration 14600 (1.5653 iter/s, 6.38856s/10 iters), loss = 8.23977
I0522 23:54:20.717092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23977 (* 1 = 8.23977 loss)
I0522 23:54:21.240160 34819 sgd_solver.cpp:112] Iteration 14600, lr = 0.01
I0522 23:54:26.107748 34819 solver.cpp:239] Iteration 14610 (1.85514 iter/s, 5.39043s/10 iters), loss = 9.22295
I0522 23:54:26.107790 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22295 (* 1 = 9.22295 loss)
I0522 23:54:26.175035 34819 sgd_solver.cpp:112] Iteration 14610, lr = 0.01
I0522 23:54:31.195819 34819 solver.cpp:239] Iteration 14620 (1.96548 iter/s, 5.08781s/10 iters), loss = 8.49306
I0522 23:54:31.195947 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49306 (* 1 = 8.49306 loss)
I0522 23:54:31.255635 34819 sgd_solver.cpp:112] Iteration 14620, lr = 0.01
I0522 23:54:36.453981 34819 solver.cpp:239] Iteration 14630 (1.90193 iter/s, 5.25782s/10 iters), loss = 8.59295
I0522 23:54:36.454035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59295 (* 1 = 8.59295 loss)
I0522 23:54:36.523310 34819 sgd_solver.cpp:112] Iteration 14630, lr = 0.01
I0522 23:54:41.282789 34819 solver.cpp:239] Iteration 14640 (2.07101 iter/s, 4.82856s/10 iters), loss = 9.12683
I0522 23:54:41.282831 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12683 (* 1 = 9.12683 loss)
I0522 23:54:42.111054 34819 sgd_solver.cpp:112] Iteration 14640, lr = 0.01
I0522 23:54:47.437605 34819 solver.cpp:239] Iteration 14650 (1.62482 iter/s, 6.15452s/10 iters), loss = 9.63537
I0522 23:54:47.437649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63537 (* 1 = 9.63537 loss)
I0522 23:54:47.511006 34819 sgd_solver.cpp:112] Iteration 14650, lr = 0.01
I0522 23:54:51.025960 34819 solver.cpp:239] Iteration 14660 (2.78695 iter/s, 3.58815s/10 iters), loss = 9.27379
I0522 23:54:51.026012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27379 (* 1 = 9.27379 loss)
I0522 23:54:51.101579 34819 sgd_solver.cpp:112] Iteration 14660, lr = 0.01
I0522 23:54:57.308897 34819 solver.cpp:239] Iteration 14670 (1.59169 iter/s, 6.28262s/10 iters), loss = 8.31084
I0522 23:54:57.308941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31084 (* 1 = 8.31084 loss)
I0522 23:54:57.379371 34819 sgd_solver.cpp:112] Iteration 14670, lr = 0.01
I0522 23:55:02.521019 34819 solver.cpp:239] Iteration 14680 (1.91871 iter/s, 5.21184s/10 iters), loss = 8.6077
I0522 23:55:02.521262 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6077 (* 1 = 8.6077 loss)
I0522 23:55:03.332669 34819 sgd_solver.cpp:112] Iteration 14680, lr = 0.01
I0522 23:55:08.135603 34819 solver.cpp:239] Iteration 14690 (1.78122 iter/s, 5.61414s/10 iters), loss = 8.9191
I0522 23:55:08.135648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9191 (* 1 = 8.9191 loss)
I0522 23:55:08.201632 34819 sgd_solver.cpp:112] Iteration 14690, lr = 0.01
I0522 23:55:10.829563 34819 solver.cpp:239] Iteration 14700 (3.71223 iter/s, 2.69379s/10 iters), loss = 8.32235
I0522 23:55:10.829607 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32235 (* 1 = 8.32235 loss)
I0522 23:55:11.589684 34819 sgd_solver.cpp:112] Iteration 14700, lr = 0.01
I0522 23:55:17.201750 34819 solver.cpp:239] Iteration 14710 (1.5694 iter/s, 6.37185s/10 iters), loss = 8.61077
I0522 23:55:17.201812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61077 (* 1 = 8.61077 loss)
I0522 23:55:17.253437 34819 sgd_solver.cpp:112] Iteration 14710, lr = 0.01
I0522 23:55:22.186853 34819 solver.cpp:239] Iteration 14720 (2.00608 iter/s, 4.98484s/10 iters), loss = 8.4383
I0522 23:55:22.186897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4383 (* 1 = 8.4383 loss)
I0522 23:55:22.257879 34819 sgd_solver.cpp:112] Iteration 14720, lr = 0.01
I0522 23:55:27.071141 34819 solver.cpp:239] Iteration 14730 (2.04749 iter/s, 4.88404s/10 iters), loss = 8.15734
I0522 23:55:27.071192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15734 (* 1 = 8.15734 loss)
I0522 23:55:27.136780 34819 sgd_solver.cpp:112] Iteration 14730, lr = 0.01
I0522 23:55:32.423923 34819 solver.cpp:239] Iteration 14740 (1.86828 iter/s, 5.35251s/10 iters), loss = 9.65297
I0522 23:55:32.423976 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65297 (* 1 = 9.65297 loss)
I0522 23:55:32.491928 34819 sgd_solver.cpp:112] Iteration 14740, lr = 0.01
I0522 23:55:35.325104 34819 solver.cpp:239] Iteration 14750 (3.44708 iter/s, 2.901s/10 iters), loss = 8.90466
I0522 23:55:35.325305 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90466 (* 1 = 8.90466 loss)
I0522 23:55:35.521423 34819 sgd_solver.cpp:112] Iteration 14750, lr = 0.01
I0522 23:55:38.890048 34819 solver.cpp:239] Iteration 14760 (2.80536 iter/s, 3.56461s/10 iters), loss = 8.67834
I0522 23:55:38.890091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67834 (* 1 = 8.67834 loss)
I0522 23:55:38.950718 34819 sgd_solver.cpp:112] Iteration 14760, lr = 0.01
I0522 23:55:42.525126 34819 solver.cpp:239] Iteration 14770 (2.75114 iter/s, 3.63486s/10 iters), loss = 8.53519
I0522 23:55:42.525176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53519 (* 1 = 8.53519 loss)
I0522 23:55:43.175169 34819 sgd_solver.cpp:112] Iteration 14770, lr = 0.01
I0522 23:55:47.309116 34819 solver.cpp:239] Iteration 14780 (2.09042 iter/s, 4.78374s/10 iters), loss = 7.7993
I0522 23:55:47.309159 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7993 (* 1 = 7.7993 loss)
I0522 23:55:47.369405 34819 sgd_solver.cpp:112] Iteration 14780, lr = 0.01
I0522 23:55:52.521126 34819 solver.cpp:239] Iteration 14790 (1.91874 iter/s, 5.21175s/10 iters), loss = 8.62854
I0522 23:55:52.521169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62854 (* 1 = 8.62854 loss)
I0522 23:55:53.323751 34819 sgd_solver.cpp:112] Iteration 14790, lr = 0.01
I0522 23:55:57.461462 34819 solver.cpp:239] Iteration 14800 (2.02426 iter/s, 4.94007s/10 iters), loss = 8.04656
I0522 23:55:57.461516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04656 (* 1 = 8.04656 loss)
I0522 23:55:57.527595 34819 sgd_solver.cpp:112] Iteration 14800, lr = 0.01
I0522 23:56:03.123703 34819 solver.cpp:239] Iteration 14810 (1.76618 iter/s, 5.66193s/10 iters), loss = 8.0824
I0522 23:56:03.123775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0824 (* 1 = 8.0824 loss)
I0522 23:56:03.185370 34819 sgd_solver.cpp:112] Iteration 14810, lr = 0.01
I0522 23:56:07.391655 34819 solver.cpp:239] Iteration 14820 (2.34318 iter/s, 4.2677s/10 iters), loss = 8.44333
I0522 23:56:07.391903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44333 (* 1 = 8.44333 loss)
I0522 23:56:07.469772 34819 sgd_solver.cpp:112] Iteration 14820, lr = 0.01
I0522 23:56:12.262498 34819 solver.cpp:239] Iteration 14830 (2.05321 iter/s, 4.87043s/10 iters), loss = 8.23729
I0522 23:56:12.262544 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23729 (* 1 = 8.23729 loss)
I0522 23:56:12.331193 34819 sgd_solver.cpp:112] Iteration 14830, lr = 0.01
I0522 23:56:16.481940 34819 solver.cpp:239] Iteration 14840 (2.37011 iter/s, 4.21921s/10 iters), loss = 9.24315
I0522 23:56:16.481995 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24315 (* 1 = 9.24315 loss)
I0522 23:56:16.535487 34819 sgd_solver.cpp:112] Iteration 14840, lr = 0.01
I0522 23:56:21.701539 34819 solver.cpp:239] Iteration 14850 (1.91595 iter/s, 5.21933s/10 iters), loss = 8.45117
I0522 23:56:21.701582 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45117 (* 1 = 8.45117 loss)
I0522 23:56:22.303125 34819 sgd_solver.cpp:112] Iteration 14850, lr = 0.01
I0522 23:56:25.678143 34819 solver.cpp:239] Iteration 14860 (2.51486 iter/s, 3.97636s/10 iters), loss = 8.711
I0522 23:56:25.678210 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.711 (* 1 = 8.711 loss)
I0522 23:56:25.986953 34819 sgd_solver.cpp:112] Iteration 14860, lr = 0.01
I0522 23:56:31.630266 34819 solver.cpp:239] Iteration 14870 (1.68016 iter/s, 5.95181s/10 iters), loss = 9.15361
I0522 23:56:31.630319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15361 (* 1 = 9.15361 loss)
I0522 23:56:32.466190 34819 sgd_solver.cpp:112] Iteration 14870, lr = 0.01
I0522 23:56:36.373412 34819 solver.cpp:239] Iteration 14880 (2.10841 iter/s, 4.7429s/10 iters), loss = 8.98433
I0522 23:56:36.373458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98433 (* 1 = 8.98433 loss)
I0522 23:56:36.436625 34819 sgd_solver.cpp:112] Iteration 14880, lr = 0.01
I0522 23:56:41.706181 34819 solver.cpp:239] Iteration 14890 (1.8753 iter/s, 5.33249s/10 iters), loss = 8.76155
I0522 23:56:41.706394 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76155 (* 1 = 8.76155 loss)
I0522 23:56:41.779633 34819 sgd_solver.cpp:112] Iteration 14890, lr = 0.01
I0522 23:56:46.399129 34819 solver.cpp:239] Iteration 14900 (2.13103 iter/s, 4.69256s/10 iters), loss = 8.35769
I0522 23:56:46.399185 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35769 (* 1 = 8.35769 loss)
I0522 23:56:46.462954 34819 sgd_solver.cpp:112] Iteration 14900, lr = 0.01
I0522 23:56:50.758466 34819 solver.cpp:239] Iteration 14910 (2.29406 iter/s, 4.35909s/10 iters), loss = 8.22601
I0522 23:56:50.758517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22601 (* 1 = 8.22601 loss)
I0522 23:56:50.830031 34819 sgd_solver.cpp:112] Iteration 14910, lr = 0.01
I0522 23:56:54.229890 34819 solver.cpp:239] Iteration 14920 (2.88083 iter/s, 3.47123s/10 iters), loss = 9.64212
I0522 23:56:54.229938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64212 (* 1 = 9.64212 loss)
I0522 23:56:54.301019 34819 sgd_solver.cpp:112] Iteration 14920, lr = 0.01
I0522 23:56:59.235194 34819 solver.cpp:239] Iteration 14930 (1.99798 iter/s, 5.00505s/10 iters), loss = 9.08743
I0522 23:56:59.235239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08743 (* 1 = 9.08743 loss)
I0522 23:57:00.050227 34819 sgd_solver.cpp:112] Iteration 14930, lr = 0.01
I0522 23:57:03.327543 34819 solver.cpp:239] Iteration 14940 (2.44372 iter/s, 4.09212s/10 iters), loss = 9.08473
I0522 23:57:03.327594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08473 (* 1 = 9.08473 loss)
I0522 23:57:03.407892 34819 sgd_solver.cpp:112] Iteration 14940, lr = 0.01
I0522 23:57:07.883631 34819 solver.cpp:239] Iteration 14950 (2.19498 iter/s, 4.55584s/10 iters), loss = 9.5752
I0522 23:57:07.883683 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.5752 (* 1 = 9.5752 loss)
I0522 23:57:07.956719 34819 sgd_solver.cpp:112] Iteration 14950, lr = 0.01
I0522 23:57:12.876824 34819 solver.cpp:239] Iteration 14960 (2.00283 iter/s, 4.99293s/10 iters), loss = 9.21687
I0522 23:57:12.877004 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21687 (* 1 = 9.21687 loss)
I0522 23:57:13.764729 34819 sgd_solver.cpp:112] Iteration 14960, lr = 0.01
I0522 23:57:18.927675 34819 solver.cpp:239] Iteration 14970 (1.65278 iter/s, 6.05042s/10 iters), loss = 8.67861
I0522 23:57:18.927721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67861 (* 1 = 8.67861 loss)
I0522 23:57:19.000852 34819 sgd_solver.cpp:112] Iteration 14970, lr = 0.01
I0522 23:57:23.678797 34819 solver.cpp:239] Iteration 14980 (2.10488 iter/s, 4.75086s/10 iters), loss = 8.28973
I0522 23:57:23.678853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28973 (* 1 = 8.28973 loss)
I0522 23:57:24.465122 34819 sgd_solver.cpp:112] Iteration 14980, lr = 0.01
I0522 23:57:27.496951 34819 solver.cpp:239] Iteration 14990 (2.61922 iter/s, 3.81793s/10 iters), loss = 8.56572
I0522 23:57:27.496996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56572 (* 1 = 8.56572 loss)
I0522 23:57:27.582602 34819 sgd_solver.cpp:112] Iteration 14990, lr = 0.01
I0522 23:57:31.093420 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_15000.caffemodel
I0522 23:57:35.551764 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_15000.solverstate
I0522 23:57:35.843636 34819 solver.cpp:239] Iteration 15000 (1.19814 iter/s, 8.34629s/10 iters), loss = 8.71632
I0522 23:57:35.843715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71632 (* 1 = 8.71632 loss)
I0522 23:57:36.325031 34819 sgd_solver.cpp:112] Iteration 15000, lr = 0.01
I0522 23:57:40.993672 34819 solver.cpp:239] Iteration 15010 (1.94185 iter/s, 5.14973s/10 iters), loss = 8.53011
I0522 23:57:40.993731 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53011 (* 1 = 8.53011 loss)
I0522 23:57:41.054679 34819 sgd_solver.cpp:112] Iteration 15010, lr = 0.01
I0522 23:57:45.547330 34819 solver.cpp:239] Iteration 15020 (2.19616 iter/s, 4.55341s/10 iters), loss = 8.05571
I0522 23:57:45.547572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05571 (* 1 = 8.05571 loss)
I0522 23:57:45.632573 34819 sgd_solver.cpp:112] Iteration 15020, lr = 0.01
I0522 23:57:49.666961 34819 solver.cpp:239] Iteration 15030 (2.42765 iter/s, 4.11921s/10 iters), loss = 9.66574
I0522 23:57:49.667047 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.66574 (* 1 = 9.66574 loss)
I0522 23:57:49.739562 34819 sgd_solver.cpp:112] Iteration 15030, lr = 0.01
I0522 23:57:55.590337 34819 solver.cpp:239] Iteration 15040 (1.68832 iter/s, 5.92305s/10 iters), loss = 9.33679
I0522 23:57:55.590379 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33679 (* 1 = 9.33679 loss)
I0522 23:57:55.647346 34819 sgd_solver.cpp:112] Iteration 15040, lr = 0.01
I0522 23:58:00.390185 34819 solver.cpp:239] Iteration 15050 (2.08352 iter/s, 4.79958s/10 iters), loss = 9.33685
I0522 23:58:00.390259 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33685 (* 1 = 9.33685 loss)
I0522 23:58:00.484268 34819 sgd_solver.cpp:112] Iteration 15050, lr = 0.01
I0522 23:58:05.269785 34819 solver.cpp:239] Iteration 15060 (2.04946 iter/s, 4.87933s/10 iters), loss = 9.14948
I0522 23:58:05.269843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14948 (* 1 = 9.14948 loss)
I0522 23:58:05.338251 34819 sgd_solver.cpp:112] Iteration 15060, lr = 0.01
I0522 23:58:11.631484 34819 solver.cpp:239] Iteration 15070 (1.57199 iter/s, 6.36137s/10 iters), loss = 8.45836
I0522 23:58:11.631539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45836 (* 1 = 8.45836 loss)
I0522 23:58:11.698557 34819 sgd_solver.cpp:112] Iteration 15070, lr = 0.01
I0522 23:58:15.539477 34819 solver.cpp:239] Iteration 15080 (2.559 iter/s, 3.90777s/10 iters), loss = 7.96318
I0522 23:58:15.539521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96318 (* 1 = 7.96318 loss)
I0522 23:58:16.230381 34819 sgd_solver.cpp:112] Iteration 15080, lr = 0.01
I0522 23:58:21.707623 34819 solver.cpp:239] Iteration 15090 (1.62131 iter/s, 6.16785s/10 iters), loss = 8.71956
I0522 23:58:21.707684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71956 (* 1 = 8.71956 loss)
I0522 23:58:21.757428 34819 sgd_solver.cpp:112] Iteration 15090, lr = 0.01
I0522 23:58:26.338337 34819 solver.cpp:239] Iteration 15100 (2.15961 iter/s, 4.63046s/10 iters), loss = 9.00106
I0522 23:58:26.338387 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00106 (* 1 = 9.00106 loss)
I0522 23:58:26.417448 34819 sgd_solver.cpp:112] Iteration 15100, lr = 0.01
I0522 23:58:30.485177 34819 solver.cpp:239] Iteration 15110 (2.41161 iter/s, 4.14662s/10 iters), loss = 8.29907
I0522 23:58:30.485219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29907 (* 1 = 8.29907 loss)
I0522 23:58:31.225581 34819 sgd_solver.cpp:112] Iteration 15110, lr = 0.01
I0522 23:58:33.359522 34819 solver.cpp:239] Iteration 15120 (3.47929 iter/s, 2.87415s/10 iters), loss = 8.56781
I0522 23:58:33.359593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56781 (* 1 = 8.56781 loss)
I0522 23:58:33.417572 34819 sgd_solver.cpp:112] Iteration 15120, lr = 0.01
I0522 23:58:37.239675 34819 solver.cpp:239] Iteration 15130 (2.57738 iter/s, 3.87991s/10 iters), loss = 8.81696
I0522 23:58:37.239732 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81696 (* 1 = 8.81696 loss)
I0522 23:58:37.307854 34819 sgd_solver.cpp:112] Iteration 15130, lr = 0.01
I0522 23:58:42.307273 34819 solver.cpp:239] Iteration 15140 (1.97342 iter/s, 5.06733s/10 iters), loss = 8.20694
I0522 23:58:42.307325 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20694 (* 1 = 8.20694 loss)
I0522 23:58:42.363620 34819 sgd_solver.cpp:112] Iteration 15140, lr = 0.01
I0522 23:58:47.573801 34819 solver.cpp:239] Iteration 15150 (1.89888 iter/s, 5.26625s/10 iters), loss = 8.28732
I0522 23:58:47.573940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28732 (* 1 = 8.28732 loss)
I0522 23:58:47.637219 34819 sgd_solver.cpp:112] Iteration 15150, lr = 0.01
I0522 23:58:50.659456 34819 solver.cpp:239] Iteration 15160 (3.24109 iter/s, 3.08538s/10 iters), loss = 8.46132
I0522 23:58:50.659505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46132 (* 1 = 8.46132 loss)
I0522 23:58:51.299394 34819 sgd_solver.cpp:112] Iteration 15160, lr = 0.01
I0522 23:58:53.865809 34819 solver.cpp:239] Iteration 15170 (3.11899 iter/s, 3.20616s/10 iters), loss = 8.77885
I0522 23:58:53.865873 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77885 (* 1 = 8.77885 loss)
I0522 23:58:53.920191 34819 sgd_solver.cpp:112] Iteration 15170, lr = 0.01
I0522 23:58:58.873939 34819 solver.cpp:239] Iteration 15180 (1.99687 iter/s, 5.00784s/10 iters), loss = 9.29146
I0522 23:58:58.873994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29146 (* 1 = 9.29146 loss)
I0522 23:58:58.939890 34819 sgd_solver.cpp:112] Iteration 15180, lr = 0.01
I0522 23:59:02.969454 34819 solver.cpp:239] Iteration 15190 (2.44183 iter/s, 4.09528s/10 iters), loss = 7.89292
I0522 23:59:02.969506 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89292 (* 1 = 7.89292 loss)
I0522 23:59:03.735803 34819 sgd_solver.cpp:112] Iteration 15190, lr = 0.01
I0522 23:59:09.197837 34819 solver.cpp:239] Iteration 15200 (1.60563 iter/s, 6.22807s/10 iters), loss = 8.40493
I0522 23:59:09.197897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40493 (* 1 = 8.40493 loss)
I0522 23:59:09.941447 34819 sgd_solver.cpp:112] Iteration 15200, lr = 0.01
I0522 23:59:12.308753 34819 solver.cpp:239] Iteration 15210 (3.2147 iter/s, 3.11071s/10 iters), loss = 8.92312
I0522 23:59:12.308807 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92312 (* 1 = 8.92312 loss)
I0522 23:59:12.390239 34819 sgd_solver.cpp:112] Iteration 15210, lr = 0.01
I0522 23:59:17.932273 34819 solver.cpp:239] Iteration 15220 (1.77834 iter/s, 5.62322s/10 iters), loss = 8.60297
I0522 23:59:17.932463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60297 (* 1 = 8.60297 loss)
I0522 23:59:18.000372 34819 sgd_solver.cpp:112] Iteration 15220, lr = 0.01
I0522 23:59:23.805701 34819 solver.cpp:239] Iteration 15230 (1.70271 iter/s, 5.873s/10 iters), loss = 8.05775
I0522 23:59:23.805744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05775 (* 1 = 8.05775 loss)
I0522 23:59:23.862589 34819 sgd_solver.cpp:112] Iteration 15230, lr = 0.01
I0522 23:59:28.705493 34819 solver.cpp:239] Iteration 15240 (2.04101 iter/s, 4.89954s/10 iters), loss = 9.17607
I0522 23:59:28.705549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17607 (* 1 = 9.17607 loss)
I0522 23:59:29.403231 34819 sgd_solver.cpp:112] Iteration 15240, lr = 0.01
I0522 23:59:34.958636 34819 solver.cpp:239] Iteration 15250 (1.59927 iter/s, 6.25283s/10 iters), loss = 9.04412
I0522 23:59:34.958698 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04412 (* 1 = 9.04412 loss)
I0522 23:59:35.023943 34819 sgd_solver.cpp:112] Iteration 15250, lr = 0.01
I0522 23:59:40.771445 34819 solver.cpp:239] Iteration 15260 (1.72043 iter/s, 5.81249s/10 iters), loss = 8.63628
I0522 23:59:40.771498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63628 (* 1 = 8.63628 loss)
I0522 23:59:40.847838 34819 sgd_solver.cpp:112] Iteration 15260, lr = 0.01
I0522 23:59:47.439796 34819 solver.cpp:239] Iteration 15270 (1.49969 iter/s, 6.66803s/10 iters), loss = 8.67038
I0522 23:59:47.439841 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67038 (* 1 = 8.67038 loss)
I0522 23:59:48.308781 34819 sgd_solver.cpp:112] Iteration 15270, lr = 0.01
I0522 23:59:53.683156 34819 solver.cpp:239] Iteration 15280 (1.60178 iter/s, 6.24306s/10 iters), loss = 8.858
I0522 23:59:53.683228 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.858 (* 1 = 8.858 loss)
I0522 23:59:53.756707 34819 sgd_solver.cpp:112] Iteration 15280, lr = 0.01
I0522 23:59:58.648953 34819 solver.cpp:239] Iteration 15290 (2.01389 iter/s, 4.96552s/10 iters), loss = 8.30647
I0522 23:59:58.649008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30647 (* 1 = 8.30647 loss)
I0522 23:59:59.444420 34819 sgd_solver.cpp:112] Iteration 15290, lr = 0.01
I0523 00:00:04.794229 34819 solver.cpp:239] Iteration 15300 (1.62735 iter/s, 6.14497s/10 iters), loss = 9.2755
I0523 00:00:04.794272 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2755 (* 1 = 9.2755 loss)
I0523 00:00:04.864650 34819 sgd_solver.cpp:112] Iteration 15300, lr = 0.01
I0523 00:00:08.284694 34819 solver.cpp:239] Iteration 15310 (2.86511 iter/s, 3.49027s/10 iters), loss = 8.70195
I0523 00:00:08.284735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70195 (* 1 = 8.70195 loss)
I0523 00:00:08.346254 34819 sgd_solver.cpp:112] Iteration 15310, lr = 0.01
I0523 00:00:12.992887 34819 solver.cpp:239] Iteration 15320 (2.12407 iter/s, 4.70795s/10 iters), loss = 8.06046
I0523 00:00:12.992931 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06046 (* 1 = 8.06046 loss)
I0523 00:00:13.066031 34819 sgd_solver.cpp:112] Iteration 15320, lr = 0.01
I0523 00:00:17.140815 34819 solver.cpp:239] Iteration 15330 (2.41097 iter/s, 4.1477s/10 iters), loss = 8.81769
I0523 00:00:17.140859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81769 (* 1 = 8.81769 loss)
I0523 00:00:17.193210 34819 sgd_solver.cpp:112] Iteration 15330, lr = 0.01
I0523 00:00:21.356621 34819 solver.cpp:239] Iteration 15340 (2.37216 iter/s, 4.21557s/10 iters), loss = 9.23135
I0523 00:00:21.356894 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23135 (* 1 = 9.23135 loss)
I0523 00:00:21.423836 34819 sgd_solver.cpp:112] Iteration 15340, lr = 0.01
I0523 00:00:26.699553 34819 solver.cpp:239] Iteration 15350 (1.8718 iter/s, 5.34246s/10 iters), loss = 9.65432
I0523 00:00:26.699606 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65432 (* 1 = 9.65432 loss)
I0523 00:00:26.761826 34819 sgd_solver.cpp:112] Iteration 15350, lr = 0.01
I0523 00:00:31.447990 34819 solver.cpp:239] Iteration 15360 (2.10608 iter/s, 4.74816s/10 iters), loss = 8.63004
I0523 00:00:31.448060 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63004 (* 1 = 8.63004 loss)
I0523 00:00:32.156579 34819 sgd_solver.cpp:112] Iteration 15360, lr = 0.01
I0523 00:00:39.558953 34819 solver.cpp:239] Iteration 15370 (1.23296 iter/s, 8.11057s/10 iters), loss = 8.56189
I0523 00:00:39.558996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56189 (* 1 = 8.56189 loss)
I0523 00:00:39.628046 34819 sgd_solver.cpp:112] Iteration 15370, lr = 0.01
I0523 00:00:44.502499 34819 solver.cpp:239] Iteration 15380 (2.02294 iter/s, 4.9433s/10 iters), loss = 8.73756
I0523 00:00:44.502542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73756 (* 1 = 8.73756 loss)
I0523 00:00:44.560932 34819 sgd_solver.cpp:112] Iteration 15380, lr = 0.01
I0523 00:00:50.164415 34819 solver.cpp:239] Iteration 15390 (1.76628 iter/s, 5.66162s/10 iters), loss = 8.34787
I0523 00:00:50.164474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34787 (* 1 = 8.34787 loss)
I0523 00:00:50.997342 34819 sgd_solver.cpp:112] Iteration 15390, lr = 0.01
I0523 00:00:55.071063 34819 solver.cpp:239] Iteration 15400 (2.03816 iter/s, 4.90638s/10 iters), loss = 8.99937
I0523 00:00:55.071204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99937 (* 1 = 8.99937 loss)
I0523 00:00:55.789288 34819 sgd_solver.cpp:112] Iteration 15400, lr = 0.01
I0523 00:00:59.837334 34819 solver.cpp:239] Iteration 15410 (2.09822 iter/s, 4.76594s/10 iters), loss = 8.04243
I0523 00:00:59.837383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04243 (* 1 = 8.04243 loss)
I0523 00:00:59.903422 34819 sgd_solver.cpp:112] Iteration 15410, lr = 0.01
I0523 00:01:03.279836 34819 solver.cpp:239] Iteration 15420 (2.90503 iter/s, 3.4423s/10 iters), loss = 9.30541
I0523 00:01:03.279880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30541 (* 1 = 9.30541 loss)
I0523 00:01:03.996614 34819 sgd_solver.cpp:112] Iteration 15420, lr = 0.01
I0523 00:01:07.069373 34819 solver.cpp:239] Iteration 15430 (2.639 iter/s, 3.78932s/10 iters), loss = 8.78559
I0523 00:01:07.069419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78559 (* 1 = 8.78559 loss)
I0523 00:01:07.879449 34819 sgd_solver.cpp:112] Iteration 15430, lr = 0.01
I0523 00:01:15.169461 34819 solver.cpp:239] Iteration 15440 (1.23461 iter/s, 8.09971s/10 iters), loss = 8.73886
I0523 00:01:15.169518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73886 (* 1 = 8.73886 loss)
I0523 00:01:16.015875 34819 sgd_solver.cpp:112] Iteration 15440, lr = 0.01
I0523 00:01:21.062723 34819 solver.cpp:239] Iteration 15450 (1.69694 iter/s, 5.89295s/10 iters), loss = 9.04262
I0523 00:01:21.062768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04262 (* 1 = 9.04262 loss)
I0523 00:01:21.138931 34819 sgd_solver.cpp:112] Iteration 15450, lr = 0.01
I0523 00:01:25.311775 34819 solver.cpp:239] Iteration 15460 (2.35359 iter/s, 4.24882s/10 iters), loss = 10.1332
I0523 00:01:25.311982 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1332 (* 1 = 10.1332 loss)
I0523 00:01:25.366781 34819 sgd_solver.cpp:112] Iteration 15460, lr = 0.01
I0523 00:01:30.460239 34819 solver.cpp:239] Iteration 15470 (1.94249 iter/s, 5.14803s/10 iters), loss = 8.12748
I0523 00:01:30.460294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12748 (* 1 = 8.12748 loss)
I0523 00:01:30.530561 34819 sgd_solver.cpp:112] Iteration 15470, lr = 0.01
I0523 00:01:38.371312 34819 solver.cpp:239] Iteration 15480 (1.26411 iter/s, 7.91069s/10 iters), loss = 8.86452
I0523 00:01:38.371368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86452 (* 1 = 8.86452 loss)
I0523 00:01:39.171936 34819 sgd_solver.cpp:112] Iteration 15480, lr = 0.01
I0523 00:01:43.258028 34819 solver.cpp:239] Iteration 15490 (2.04648 iter/s, 4.88645s/10 iters), loss = 9.68081
I0523 00:01:43.258071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68081 (* 1 = 9.68081 loss)
I0523 00:01:43.338203 34819 sgd_solver.cpp:112] Iteration 15490, lr = 0.01
I0523 00:01:47.842800 34819 solver.cpp:239] Iteration 15500 (2.18125 iter/s, 4.58454s/10 iters), loss = 9.31418
I0523 00:01:47.842852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31418 (* 1 = 9.31418 loss)
I0523 00:01:48.600244 34819 sgd_solver.cpp:112] Iteration 15500, lr = 0.01
I0523 00:01:52.815145 34819 solver.cpp:239] Iteration 15510 (2.01123 iter/s, 4.97209s/10 iters), loss = 8.41669
I0523 00:01:52.815188 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41669 (* 1 = 8.41669 loss)
I0523 00:01:53.683856 34819 sgd_solver.cpp:112] Iteration 15510, lr = 0.01
I0523 00:01:58.336364 34819 solver.cpp:239] Iteration 15520 (1.81129 iter/s, 5.52093s/10 iters), loss = 8.70961
I0523 00:01:58.336494 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70961 (* 1 = 8.70961 loss)
I0523 00:01:58.394302 34819 sgd_solver.cpp:112] Iteration 15520, lr = 0.01
I0523 00:02:04.100767 34819 solver.cpp:239] Iteration 15530 (1.7349 iter/s, 5.76403s/10 iters), loss = 9.17013
I0523 00:02:04.100821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17013 (* 1 = 9.17013 loss)
I0523 00:02:04.164171 34819 sgd_solver.cpp:112] Iteration 15530, lr = 0.01
I0523 00:02:07.838639 34819 solver.cpp:239] Iteration 15540 (2.67547 iter/s, 3.73766s/10 iters), loss = 8.67034
I0523 00:02:07.838716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67034 (* 1 = 8.67034 loss)
I0523 00:02:07.910603 34819 sgd_solver.cpp:112] Iteration 15540, lr = 0.01
I0523 00:02:13.597618 34819 solver.cpp:239] Iteration 15550 (1.73725 iter/s, 5.75624s/10 iters), loss = 8.2478
I0523 00:02:13.597664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2478 (* 1 = 8.2478 loss)
I0523 00:02:14.487172 34819 sgd_solver.cpp:112] Iteration 15550, lr = 0.01
I0523 00:02:19.492180 34819 solver.cpp:239] Iteration 15560 (1.69657 iter/s, 5.89425s/10 iters), loss = 8.51651
I0523 00:02:19.492246 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51651 (* 1 = 8.51651 loss)
I0523 00:02:20.244870 34819 sgd_solver.cpp:112] Iteration 15560, lr = 0.01
I0523 00:02:24.251996 34819 solver.cpp:239] Iteration 15570 (2.10104 iter/s, 4.75955s/10 iters), loss = 8.98504
I0523 00:02:24.252048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98504 (* 1 = 8.98504 loss)
I0523 00:02:24.322580 34819 sgd_solver.cpp:112] Iteration 15570, lr = 0.01
I0523 00:02:28.590065 34819 solver.cpp:239] Iteration 15580 (2.3053 iter/s, 4.33782s/10 iters), loss = 8.33224
I0523 00:02:28.590235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33224 (* 1 = 8.33224 loss)
I0523 00:02:29.376054 34819 sgd_solver.cpp:112] Iteration 15580, lr = 0.01
I0523 00:02:33.548843 34819 solver.cpp:239] Iteration 15590 (2.01678 iter/s, 4.9584s/10 iters), loss = 8.96534
I0523 00:02:33.548894 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96534 (* 1 = 8.96534 loss)
I0523 00:02:33.620151 34819 sgd_solver.cpp:112] Iteration 15590, lr = 0.01
I0523 00:02:36.165642 34819 solver.cpp:239] Iteration 15600 (3.82172 iter/s, 2.61662s/10 iters), loss = 9.22654
I0523 00:02:36.165691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22654 (* 1 = 9.22654 loss)
I0523 00:02:36.478884 34819 sgd_solver.cpp:112] Iteration 15600, lr = 0.01
I0523 00:02:39.713449 34819 solver.cpp:239] Iteration 15610 (2.8188 iter/s, 3.54761s/10 iters), loss = 8.77893
I0523 00:02:39.713492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77893 (* 1 = 8.77893 loss)
I0523 00:02:39.893303 34819 sgd_solver.cpp:112] Iteration 15610, lr = 0.01
I0523 00:02:43.235266 34819 solver.cpp:239] Iteration 15620 (2.8396 iter/s, 3.52162s/10 iters), loss = 8.57666
I0523 00:02:43.235321 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57666 (* 1 = 8.57666 loss)
I0523 00:02:44.038744 34819 sgd_solver.cpp:112] Iteration 15620, lr = 0.01
I0523 00:02:52.512122 34819 solver.cpp:239] Iteration 15630 (1.078 iter/s, 9.27642s/10 iters), loss = 8.936
I0523 00:02:52.512169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.936 (* 1 = 8.936 loss)
I0523 00:02:52.581084 34819 sgd_solver.cpp:112] Iteration 15630, lr = 0.01
I0523 00:02:57.459233 34819 solver.cpp:239] Iteration 15640 (2.02149 iter/s, 4.94684s/10 iters), loss = 8.65269
I0523 00:02:57.459275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65269 (* 1 = 8.65269 loss)
I0523 00:02:57.523113 34819 sgd_solver.cpp:112] Iteration 15640, lr = 0.01
I0523 00:03:00.720692 34819 solver.cpp:239] Iteration 15650 (3.06629 iter/s, 3.26128s/10 iters), loss = 8.14572
I0523 00:03:00.720809 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14572 (* 1 = 8.14572 loss)
I0523 00:03:00.780586 34819 sgd_solver.cpp:112] Iteration 15650, lr = 0.01
I0523 00:03:03.951898 34819 solver.cpp:239] Iteration 15660 (3.09507 iter/s, 3.23095s/10 iters), loss = 8.86033
I0523 00:03:03.951939 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86033 (* 1 = 8.86033 loss)
I0523 00:03:04.005930 34819 sgd_solver.cpp:112] Iteration 15660, lr = 0.01
I0523 00:03:08.853404 34819 solver.cpp:239] Iteration 15670 (2.04029 iter/s, 4.90126s/10 iters), loss = 8.1912
I0523 00:03:08.853456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1912 (* 1 = 8.1912 loss)
I0523 00:03:09.522868 34819 sgd_solver.cpp:112] Iteration 15670, lr = 0.01
I0523 00:03:12.123685 34819 solver.cpp:239] Iteration 15680 (3.05804 iter/s, 3.27007s/10 iters), loss = 8.3692
I0523 00:03:12.123744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3692 (* 1 = 8.3692 loss)
I0523 00:03:12.208163 34819 sgd_solver.cpp:112] Iteration 15680, lr = 0.01
I0523 00:03:16.290760 34819 solver.cpp:239] Iteration 15690 (2.3999 iter/s, 4.16684s/10 iters), loss = 8.10333
I0523 00:03:16.290807 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10333 (* 1 = 8.10333 loss)
I0523 00:03:16.404220 34819 sgd_solver.cpp:112] Iteration 15690, lr = 0.01
I0523 00:03:22.046942 34819 solver.cpp:239] Iteration 15700 (1.73735 iter/s, 5.75589s/10 iters), loss = 9.17763
I0523 00:03:22.046996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17763 (* 1 = 9.17763 loss)
I0523 00:03:22.878758 34819 sgd_solver.cpp:112] Iteration 15700, lr = 0.01
I0523 00:03:27.500345 34819 solver.cpp:239] Iteration 15710 (1.83381 iter/s, 5.45312s/10 iters), loss = 8.33333
I0523 00:03:27.500388 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33333 (* 1 = 8.33333 loss)
I0523 00:03:27.580683 34819 sgd_solver.cpp:112] Iteration 15710, lr = 0.01
I0523 00:03:31.766067 34819 solver.cpp:239] Iteration 15720 (2.3444 iter/s, 4.26548s/10 iters), loss = 8.69028
I0523 00:03:31.766269 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69028 (* 1 = 8.69028 loss)
I0523 00:03:31.985041 34819 sgd_solver.cpp:112] Iteration 15720, lr = 0.01
I0523 00:03:37.200726 34819 solver.cpp:239] Iteration 15730 (1.84019 iter/s, 5.43423s/10 iters), loss = 8.50446
I0523 00:03:37.200780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50446 (* 1 = 8.50446 loss)
I0523 00:03:37.997737 34819 sgd_solver.cpp:112] Iteration 15730, lr = 0.01
I0523 00:03:39.917976 34819 solver.cpp:239] Iteration 15740 (3.68042 iter/s, 2.71708s/10 iters), loss = 8.5099
I0523 00:03:39.918022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5099 (* 1 = 8.5099 loss)
I0523 00:03:39.994804 34819 sgd_solver.cpp:112] Iteration 15740, lr = 0.01
I0523 00:03:44.312664 34819 solver.cpp:239] Iteration 15750 (2.2756 iter/s, 4.39445s/10 iters), loss = 9.58545
I0523 00:03:44.312705 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58545 (* 1 = 9.58545 loss)
I0523 00:03:44.382902 34819 sgd_solver.cpp:112] Iteration 15750, lr = 0.01
I0523 00:03:51.542567 34819 solver.cpp:239] Iteration 15760 (1.38321 iter/s, 7.22956s/10 iters), loss = 9.10174
I0523 00:03:51.542609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10174 (* 1 = 9.10174 loss)
I0523 00:03:51.617229 34819 sgd_solver.cpp:112] Iteration 15760, lr = 0.01
I0523 00:03:56.795444 34819 solver.cpp:239] Iteration 15770 (1.90382 iter/s, 5.25261s/10 iters), loss = 9.19764
I0523 00:03:56.795487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19764 (* 1 = 9.19764 loss)
I0523 00:03:56.997108 34819 sgd_solver.cpp:112] Iteration 15770, lr = 0.01
I0523 00:04:00.334647 34819 solver.cpp:239] Iteration 15780 (2.82565 iter/s, 3.539s/10 iters), loss = 8.31358
I0523 00:04:00.334688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31358 (* 1 = 8.31358 loss)
I0523 00:04:00.828018 34819 sgd_solver.cpp:112] Iteration 15780, lr = 0.01
I0523 00:04:03.969647 34819 solver.cpp:239] Iteration 15790 (2.75118 iter/s, 3.6348s/10 iters), loss = 8.31888
I0523 00:04:03.969837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31888 (* 1 = 8.31888 loss)
I0523 00:04:04.029356 34819 sgd_solver.cpp:112] Iteration 15790, lr = 0.01
I0523 00:04:09.561964 34819 solver.cpp:239] Iteration 15800 (1.7883 iter/s, 5.59191s/10 iters), loss = 9.23461
I0523 00:04:09.562016 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23461 (* 1 = 9.23461 loss)
I0523 00:04:09.620904 34819 sgd_solver.cpp:112] Iteration 15800, lr = 0.01
I0523 00:04:15.329330 34819 solver.cpp:239] Iteration 15810 (1.73398 iter/s, 5.76707s/10 iters), loss = 8.60853
I0523 00:04:15.329377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60853 (* 1 = 8.60853 loss)
I0523 00:04:15.389832 34819 sgd_solver.cpp:112] Iteration 15810, lr = 0.01
I0523 00:04:19.217680 34819 solver.cpp:239] Iteration 15820 (2.57193 iter/s, 3.88813s/10 iters), loss = 8.65552
I0523 00:04:19.217742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65552 (* 1 = 8.65552 loss)
I0523 00:04:19.994365 34819 sgd_solver.cpp:112] Iteration 15820, lr = 0.01
I0523 00:04:24.299136 34819 solver.cpp:239] Iteration 15830 (1.96805 iter/s, 5.08117s/10 iters), loss = 8.51018
I0523 00:04:24.299212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51018 (* 1 = 8.51018 loss)
I0523 00:04:24.357893 34819 sgd_solver.cpp:112] Iteration 15830, lr = 0.01
I0523 00:04:28.348171 34819 solver.cpp:239] Iteration 15840 (2.46987 iter/s, 4.04879s/10 iters), loss = 7.9828
I0523 00:04:28.348215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9828 (* 1 = 7.9828 loss)
I0523 00:04:29.229889 34819 sgd_solver.cpp:112] Iteration 15840, lr = 0.01
I0523 00:04:34.946519 34819 solver.cpp:239] Iteration 15850 (1.5156 iter/s, 6.59803s/10 iters), loss = 8.27662
I0523 00:04:34.946687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27662 (* 1 = 8.27662 loss)
I0523 00:04:35.018029 34819 sgd_solver.cpp:112] Iteration 15850, lr = 0.01
I0523 00:04:39.200260 34819 solver.cpp:239] Iteration 15860 (2.35106 iter/s, 4.2534s/10 iters), loss = 8.64236
I0523 00:04:39.200311 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64236 (* 1 = 8.64236 loss)
I0523 00:04:40.013962 34819 sgd_solver.cpp:112] Iteration 15860, lr = 0.01
I0523 00:04:44.311560 34819 solver.cpp:239] Iteration 15870 (1.95656 iter/s, 5.11102s/10 iters), loss = 8.5739
I0523 00:04:44.311610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5739 (* 1 = 8.5739 loss)
I0523 00:04:45.004925 34819 sgd_solver.cpp:112] Iteration 15870, lr = 0.01
I0523 00:04:47.805513 34819 solver.cpp:239] Iteration 15880 (2.86226 iter/s, 3.49375s/10 iters), loss = 8.87603
I0523 00:04:47.805559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87603 (* 1 = 8.87603 loss)
I0523 00:04:47.870676 34819 sgd_solver.cpp:112] Iteration 15880, lr = 0.01
I0523 00:04:52.207289 34819 solver.cpp:239] Iteration 15890 (2.27193 iter/s, 4.40154s/10 iters), loss = 9.11526
I0523 00:04:52.207343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11526 (* 1 = 9.11526 loss)
I0523 00:04:52.535050 34819 sgd_solver.cpp:112] Iteration 15890, lr = 0.01
I0523 00:04:56.730232 34819 solver.cpp:239] Iteration 15900 (2.21107 iter/s, 4.52269s/10 iters), loss = 8.17087
I0523 00:04:56.730293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17087 (* 1 = 8.17087 loss)
I0523 00:04:56.790386 34819 sgd_solver.cpp:112] Iteration 15900, lr = 0.01
I0523 00:05:00.795851 34819 solver.cpp:239] Iteration 15910 (2.45979 iter/s, 4.06539s/10 iters), loss = 8.06607
I0523 00:05:00.795905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06607 (* 1 = 8.06607 loss)
I0523 00:05:00.859010 34819 sgd_solver.cpp:112] Iteration 15910, lr = 0.01
I0523 00:05:07.170049 34819 solver.cpp:239] Iteration 15920 (1.56891 iter/s, 6.37387s/10 iters), loss = 8.4359
I0523 00:05:07.170292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4359 (* 1 = 8.4359 loss)
I0523 00:05:07.246806 34819 sgd_solver.cpp:112] Iteration 15920, lr = 0.01
I0523 00:05:11.946468 34819 solver.cpp:239] Iteration 15930 (2.09381 iter/s, 4.77599s/10 iters), loss = 8.5476
I0523 00:05:11.946535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5476 (* 1 = 8.5476 loss)
I0523 00:05:12.826479 34819 sgd_solver.cpp:112] Iteration 15930, lr = 0.01
I0523 00:05:19.494293 34819 solver.cpp:239] Iteration 15940 (1.32495 iter/s, 7.54745s/10 iters), loss = 8.53041
I0523 00:05:19.494349 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53041 (* 1 = 8.53041 loss)
I0523 00:05:20.360213 34819 sgd_solver.cpp:112] Iteration 15940, lr = 0.01
I0523 00:05:26.463949 34819 solver.cpp:239] Iteration 15950 (1.43486 iter/s, 6.96931s/10 iters), loss = 9.03819
I0523 00:05:26.463992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03819 (* 1 = 9.03819 loss)
I0523 00:05:27.310631 34819 sgd_solver.cpp:112] Iteration 15950, lr = 0.01
I0523 00:05:31.749384 34819 solver.cpp:239] Iteration 15960 (1.89209 iter/s, 5.28517s/10 iters), loss = 8.43716
I0523 00:05:31.749430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43716 (* 1 = 8.43716 loss)
I0523 00:05:31.812327 34819 sgd_solver.cpp:112] Iteration 15960, lr = 0.01
I0523 00:05:35.833245 34819 solver.cpp:239] Iteration 15970 (2.44879 iter/s, 4.08364s/10 iters), loss = 8.31381
I0523 00:05:35.833295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31381 (* 1 = 8.31381 loss)
I0523 00:05:35.902321 34819 sgd_solver.cpp:112] Iteration 15970, lr = 0.01
I0523 00:05:39.989776 34819 solver.cpp:239] Iteration 15980 (2.40598 iter/s, 4.15631s/10 iters), loss = 8.96093
I0523 00:05:39.989984 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96093 (* 1 = 8.96093 loss)
I0523 00:05:40.062399 34819 sgd_solver.cpp:112] Iteration 15980, lr = 0.01
I0523 00:05:45.773183 34819 solver.cpp:239] Iteration 15990 (1.72921 iter/s, 5.78298s/10 iters), loss = 8.82488
I0523 00:05:45.773244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82488 (* 1 = 8.82488 loss)
I0523 00:05:45.837188 34819 sgd_solver.cpp:112] Iteration 15990, lr = 0.01
I0523 00:05:51.989228 34819 solver.cpp:239] Iteration 16000 (1.60883 iter/s, 6.21571s/10 iters), loss = 8.56774
I0523 00:05:51.989284 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56774 (* 1 = 8.56774 loss)
I0523 00:05:52.057051 34819 sgd_solver.cpp:112] Iteration 16000, lr = 0.01
I0523 00:05:56.137547 34819 solver.cpp:239] Iteration 16010 (2.41075 iter/s, 4.14809s/10 iters), loss = 9.52022
I0523 00:05:56.137598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52022 (* 1 = 9.52022 loss)
I0523 00:05:56.212841 34819 sgd_solver.cpp:112] Iteration 16010, lr = 0.01
I0523 00:06:01.756831 34819 solver.cpp:239] Iteration 16020 (1.77968 iter/s, 5.619s/10 iters), loss = 8.99965
I0523 00:06:01.756884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99965 (* 1 = 8.99965 loss)
I0523 00:06:02.623775 34819 sgd_solver.cpp:112] Iteration 16020, lr = 0.01
I0523 00:06:06.113411 34819 solver.cpp:239] Iteration 16030 (2.29551 iter/s, 4.35634s/10 iters), loss = 8.70592
I0523 00:06:06.113476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70592 (* 1 = 8.70592 loss)
I0523 00:06:06.916618 34819 sgd_solver.cpp:112] Iteration 16030, lr = 0.01
I0523 00:06:11.438349 34819 solver.cpp:239] Iteration 16040 (1.87887 iter/s, 5.32235s/10 iters), loss = 9.16534
I0523 00:06:11.438565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16534 (* 1 = 9.16534 loss)
I0523 00:06:11.499109 34819 sgd_solver.cpp:112] Iteration 16040, lr = 0.01
I0523 00:06:16.425700 34819 solver.cpp:239] Iteration 16050 (2.00523 iter/s, 4.98695s/10 iters), loss = 8.73903
I0523 00:06:16.425768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73903 (* 1 = 8.73903 loss)
I0523 00:06:16.487498 34819 sgd_solver.cpp:112] Iteration 16050, lr = 0.01
I0523 00:06:22.568929 34819 solver.cpp:239] Iteration 16060 (1.6279 iter/s, 6.1429s/10 iters), loss = 8.23452
I0523 00:06:22.568986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23452 (* 1 = 8.23452 loss)
I0523 00:06:22.637820 34819 sgd_solver.cpp:112] Iteration 16060, lr = 0.01
I0523 00:06:29.343453 34819 solver.cpp:239] Iteration 16070 (1.47619 iter/s, 6.77419s/10 iters), loss = 8.25106
I0523 00:06:29.343509 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25106 (* 1 = 8.25106 loss)
I0523 00:06:29.412801 34819 sgd_solver.cpp:112] Iteration 16070, lr = 0.01
I0523 00:06:33.622264 34819 solver.cpp:239] Iteration 16080 (2.33723 iter/s, 4.27857s/10 iters), loss = 9.46685
I0523 00:06:33.622309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46685 (* 1 = 9.46685 loss)
I0523 00:06:33.702545 34819 sgd_solver.cpp:112] Iteration 16080, lr = 0.01
I0523 00:06:37.881041 34819 solver.cpp:239] Iteration 16090 (2.34822 iter/s, 4.25854s/10 iters), loss = 7.62404
I0523 00:06:37.881084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62404 (* 1 = 7.62404 loss)
I0523 00:06:37.939522 34819 sgd_solver.cpp:112] Iteration 16090, lr = 0.01
I0523 00:06:42.531038 34819 solver.cpp:239] Iteration 16100 (2.15065 iter/s, 4.64976s/10 iters), loss = 9.28291
I0523 00:06:42.531157 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28291 (* 1 = 9.28291 loss)
I0523 00:06:42.586125 34819 sgd_solver.cpp:112] Iteration 16100, lr = 0.01
I0523 00:06:48.746044 34819 solver.cpp:239] Iteration 16110 (1.60911 iter/s, 6.21463s/10 iters), loss = 8.90826
I0523 00:06:48.746091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90826 (* 1 = 8.90826 loss)
I0523 00:06:48.817018 34819 sgd_solver.cpp:112] Iteration 16110, lr = 0.01
I0523 00:06:51.538744 34819 solver.cpp:239] Iteration 16120 (3.58101 iter/s, 2.79251s/10 iters), loss = 9.02037
I0523 00:06:51.538805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02037 (* 1 = 9.02037 loss)
I0523 00:06:52.334015 34819 sgd_solver.cpp:112] Iteration 16120, lr = 0.01
I0523 00:06:57.652989 34819 solver.cpp:239] Iteration 16130 (1.63561 iter/s, 6.11392s/10 iters), loss = 8.86106
I0523 00:06:57.653045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86106 (* 1 = 8.86106 loss)
I0523 00:06:57.725844 34819 sgd_solver.cpp:112] Iteration 16130, lr = 0.01
I0523 00:07:00.357170 34819 solver.cpp:239] Iteration 16140 (3.69821 iter/s, 2.70401s/10 iters), loss = 9.64138
I0523 00:07:00.357213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64138 (* 1 = 9.64138 loss)
I0523 00:07:00.409734 34819 sgd_solver.cpp:112] Iteration 16140, lr = 0.01
I0523 00:07:03.870081 34819 solver.cpp:239] Iteration 16150 (2.8468 iter/s, 3.51272s/10 iters), loss = 8.81239
I0523 00:07:03.870121 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81239 (* 1 = 8.81239 loss)
I0523 00:07:03.924670 34819 sgd_solver.cpp:112] Iteration 16150, lr = 0.01
I0523 00:07:09.010193 34819 solver.cpp:239] Iteration 16160 (1.94558 iter/s, 5.13986s/10 iters), loss = 8.31004
I0523 00:07:09.010236 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31004 (* 1 = 8.31004 loss)
I0523 00:07:09.576786 34819 sgd_solver.cpp:112] Iteration 16160, lr = 0.01
I0523 00:07:14.104982 34819 solver.cpp:239] Iteration 16170 (1.9629 iter/s, 5.09452s/10 iters), loss = 9.24789
I0523 00:07:14.105201 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24789 (* 1 = 9.24789 loss)
I0523 00:07:14.388033 34819 sgd_solver.cpp:112] Iteration 16170, lr = 0.01
I0523 00:07:17.889585 34819 solver.cpp:239] Iteration 16180 (2.64256 iter/s, 3.78422s/10 iters), loss = 9.24096
I0523 00:07:17.889639 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24096 (* 1 = 9.24096 loss)
I0523 00:07:17.942498 34819 sgd_solver.cpp:112] Iteration 16180, lr = 0.01
I0523 00:07:23.639351 34819 solver.cpp:239] Iteration 16190 (1.73929 iter/s, 5.74946s/10 iters), loss = 8.79754
I0523 00:07:23.639405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79754 (* 1 = 8.79754 loss)
I0523 00:07:24.488515 34819 sgd_solver.cpp:112] Iteration 16190, lr = 0.01
I0523 00:07:27.571111 34819 solver.cpp:239] Iteration 16200 (2.54354 iter/s, 3.93153s/10 iters), loss = 9.37845
I0523 00:07:27.571166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37845 (* 1 = 9.37845 loss)
I0523 00:07:27.644068 34819 sgd_solver.cpp:112] Iteration 16200, lr = 0.01
I0523 00:07:32.472738 34819 solver.cpp:239] Iteration 16210 (2.04025 iter/s, 4.90136s/10 iters), loss = 8.63275
I0523 00:07:32.472782 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63275 (* 1 = 8.63275 loss)
I0523 00:07:32.532222 34819 sgd_solver.cpp:112] Iteration 16210, lr = 0.01
I0523 00:07:32.580075 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 00:07:38.100105 34819 solver.cpp:239] Iteration 16220 (1.77712 iter/s, 5.62709s/10 iters), loss = 8.92364
I0523 00:07:38.100158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92364 (* 1 = 8.92364 loss)
I0523 00:07:38.171778 34819 sgd_solver.cpp:112] Iteration 16220, lr = 0.01
I0523 00:07:42.987726 34819 solver.cpp:239] Iteration 16230 (2.0461 iter/s, 4.88735s/10 iters), loss = 8.7954
I0523 00:07:42.987779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7954 (* 1 = 8.7954 loss)
I0523 00:07:43.057030 34819 sgd_solver.cpp:112] Iteration 16230, lr = 0.01
I0523 00:07:46.086589 34819 solver.cpp:239] Iteration 16240 (3.2272 iter/s, 3.09866s/10 iters), loss = 7.95305
I0523 00:07:46.086742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95305 (* 1 = 7.95305 loss)
I0523 00:07:46.152313 34819 sgd_solver.cpp:112] Iteration 16240, lr = 0.01
I0523 00:07:49.545483 34819 solver.cpp:239] Iteration 16250 (2.89135 iter/s, 3.4586s/10 iters), loss = 9.50569
I0523 00:07:49.545541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50569 (* 1 = 9.50569 loss)
I0523 00:07:49.617105 34819 sgd_solver.cpp:112] Iteration 16250, lr = 0.01
I0523 00:07:53.614040 34819 solver.cpp:239] Iteration 16260 (2.45802 iter/s, 4.06831s/10 iters), loss = 8.40542
I0523 00:07:53.614095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40542 (* 1 = 8.40542 loss)
I0523 00:07:53.689163 34819 sgd_solver.cpp:112] Iteration 16260, lr = 0.01
I0523 00:08:00.638603 34819 solver.cpp:239] Iteration 16270 (1.42365 iter/s, 7.02419s/10 iters), loss = 8.54194
I0523 00:08:00.638669 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54194 (* 1 = 8.54194 loss)
I0523 00:08:01.463351 34819 sgd_solver.cpp:112] Iteration 16270, lr = 0.01
I0523 00:08:03.993193 34819 solver.cpp:239] Iteration 16280 (2.98118 iter/s, 3.35438s/10 iters), loss = 8.05784
I0523 00:08:03.993252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05784 (* 1 = 8.05784 loss)
I0523 00:08:04.062324 34819 sgd_solver.cpp:112] Iteration 16280, lr = 0.01
I0523 00:08:09.671249 34819 solver.cpp:239] Iteration 16290 (1.76126 iter/s, 5.67775s/10 iters), loss = 9.0269
I0523 00:08:09.671319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0269 (* 1 = 9.0269 loss)
I0523 00:08:09.734561 34819 sgd_solver.cpp:112] Iteration 16290, lr = 0.01
I0523 00:08:13.254101 34819 solver.cpp:239] Iteration 16300 (2.79125 iter/s, 3.58263s/10 iters), loss = 8.98762
I0523 00:08:13.254142 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98762 (* 1 = 8.98762 loss)
I0523 00:08:13.836833 34819 sgd_solver.cpp:112] Iteration 16300, lr = 0.01
I0523 00:08:18.077483 34819 solver.cpp:239] Iteration 16310 (2.07334 iter/s, 4.82313s/10 iters), loss = 8.18898
I0523 00:08:18.077641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18898 (* 1 = 8.18898 loss)
I0523 00:08:18.816089 34819 sgd_solver.cpp:112] Iteration 16310, lr = 0.01
I0523 00:08:22.429478 34819 solver.cpp:239] Iteration 16320 (2.29798 iter/s, 4.35164s/10 iters), loss = 8.83065
I0523 00:08:22.429536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83065 (* 1 = 8.83065 loss)
I0523 00:08:22.555800 34819 sgd_solver.cpp:112] Iteration 16320, lr = 0.01
I0523 00:08:27.601075 34819 solver.cpp:239] Iteration 16330 (1.93374 iter/s, 5.17132s/10 iters), loss = 8.50664
I0523 00:08:27.601128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50664 (* 1 = 8.50664 loss)
I0523 00:08:28.501360 34819 sgd_solver.cpp:112] Iteration 16330, lr = 0.01
I0523 00:08:35.825717 34819 solver.cpp:239] Iteration 16340 (1.21592 iter/s, 8.22425s/10 iters), loss = 9.01565
I0523 00:08:35.825773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01565 (* 1 = 9.01565 loss)
I0523 00:08:35.884896 34819 sgd_solver.cpp:112] Iteration 16340, lr = 0.01
I0523 00:08:40.479903 34819 solver.cpp:239] Iteration 16350 (2.14872 iter/s, 4.65393s/10 iters), loss = 9.10726
I0523 00:08:40.479955 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10726 (* 1 = 9.10726 loss)
I0523 00:08:40.541463 34819 sgd_solver.cpp:112] Iteration 16350, lr = 0.01
I0523 00:08:46.267671 34819 solver.cpp:239] Iteration 16360 (1.72787 iter/s, 5.78746s/10 iters), loss = 9.19887
I0523 00:08:46.267726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19887 (* 1 = 9.19887 loss)
I0523 00:08:47.044411 34819 sgd_solver.cpp:112] Iteration 16360, lr = 0.01
I0523 00:08:50.403331 34819 solver.cpp:239] Iteration 16370 (2.41814 iter/s, 4.13542s/10 iters), loss = 8.56825
I0523 00:08:50.403540 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56825 (* 1 = 8.56825 loss)
I0523 00:08:51.116730 34819 sgd_solver.cpp:112] Iteration 16370, lr = 0.01
I0523 00:08:56.798035 34819 solver.cpp:239] Iteration 16380 (1.56391 iter/s, 6.39425s/10 iters), loss = 8.45488
I0523 00:08:56.798090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45488 (* 1 = 8.45488 loss)
I0523 00:08:56.867542 34819 sgd_solver.cpp:112] Iteration 16380, lr = 0.01
I0523 00:09:01.681565 34819 solver.cpp:239] Iteration 16390 (2.04781 iter/s, 4.88328s/10 iters), loss = 8.24337
I0523 00:09:01.681605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24337 (* 1 = 8.24337 loss)
I0523 00:09:02.431206 34819 sgd_solver.cpp:112] Iteration 16390, lr = 0.01
I0523 00:09:08.078150 34819 solver.cpp:239] Iteration 16400 (1.56341 iter/s, 6.39627s/10 iters), loss = 8.82718
I0523 00:09:08.078202 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82718 (* 1 = 8.82718 loss)
I0523 00:09:08.908972 34819 sgd_solver.cpp:112] Iteration 16400, lr = 0.01
I0523 00:09:13.931921 34819 solver.cpp:239] Iteration 16410 (1.70839 iter/s, 5.85347s/10 iters), loss = 8.36258
I0523 00:09:13.931972 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36258 (* 1 = 8.36258 loss)
I0523 00:09:13.989394 34819 sgd_solver.cpp:112] Iteration 16410, lr = 0.01
I0523 00:09:18.858161 34819 solver.cpp:239] Iteration 16420 (2.03005 iter/s, 4.92598s/10 iters), loss = 8.33236
I0523 00:09:18.858218 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33236 (* 1 = 8.33236 loss)
I0523 00:09:19.686218 34819 sgd_solver.cpp:112] Iteration 16420, lr = 0.01
I0523 00:09:23.227521 34819 solver.cpp:239] Iteration 16430 (2.2888 iter/s, 4.36911s/10 iters), loss = 8.30978
I0523 00:09:23.227762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30978 (* 1 = 8.30978 loss)
I0523 00:09:23.801892 34819 sgd_solver.cpp:112] Iteration 16430, lr = 0.01
I0523 00:09:29.900140 34819 solver.cpp:239] Iteration 16440 (1.49877 iter/s, 6.67212s/10 iters), loss = 8.57425
I0523 00:09:29.900197 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57425 (* 1 = 8.57425 loss)
I0523 00:09:29.968926 34819 sgd_solver.cpp:112] Iteration 16440, lr = 0.01
I0523 00:09:33.972923 34819 solver.cpp:239] Iteration 16450 (2.45547 iter/s, 4.07254s/10 iters), loss = 9.0985
I0523 00:09:33.972997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0985 (* 1 = 9.0985 loss)
I0523 00:09:34.256403 34819 sgd_solver.cpp:112] Iteration 16450, lr = 0.01
I0523 00:09:39.380924 34819 solver.cpp:239] Iteration 16460 (1.84921 iter/s, 5.40771s/10 iters), loss = 8.82265
I0523 00:09:39.380969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82265 (* 1 = 8.82265 loss)
I0523 00:09:39.453291 34819 sgd_solver.cpp:112] Iteration 16460, lr = 0.01
I0523 00:09:42.183666 34819 solver.cpp:239] Iteration 16470 (3.56815 iter/s, 2.80257s/10 iters), loss = 9.12522
I0523 00:09:42.183714 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12522 (* 1 = 9.12522 loss)
I0523 00:09:42.242760 34819 sgd_solver.cpp:112] Iteration 16470, lr = 0.01
I0523 00:09:48.098791 34819 solver.cpp:239] Iteration 16480 (1.69067 iter/s, 5.91482s/10 iters), loss = 8.89558
I0523 00:09:48.098845 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89558 (* 1 = 8.89558 loss)
I0523 00:09:48.953251 34819 sgd_solver.cpp:112] Iteration 16480, lr = 0.01
I0523 00:09:53.101843 34819 solver.cpp:239] Iteration 16490 (1.99889 iter/s, 5.00278s/10 iters), loss = 8.26393
I0523 00:09:53.101897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26393 (* 1 = 8.26393 loss)
I0523 00:09:53.158686 34819 sgd_solver.cpp:112] Iteration 16490, lr = 0.01
I0523 00:09:55.826586 34819 solver.cpp:239] Iteration 16500 (3.67031 iter/s, 2.72457s/10 iters), loss = 9.11614
I0523 00:09:55.826756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11614 (* 1 = 9.11614 loss)
I0523 00:09:56.518522 34819 sgd_solver.cpp:112] Iteration 16500, lr = 0.01
I0523 00:10:00.734886 34819 solver.cpp:239] Iteration 16510 (2.03752 iter/s, 4.90793s/10 iters), loss = 9.10057
I0523 00:10:00.734937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10057 (* 1 = 9.10057 loss)
I0523 00:10:00.807610 34819 sgd_solver.cpp:112] Iteration 16510, lr = 0.01
I0523 00:10:04.281399 34819 solver.cpp:239] Iteration 16520 (2.81983 iter/s, 3.54631s/10 iters), loss = 8.92443
I0523 00:10:04.281445 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92443 (* 1 = 8.92443 loss)
I0523 00:10:05.073249 34819 sgd_solver.cpp:112] Iteration 16520, lr = 0.01
I0523 00:10:09.190140 34819 solver.cpp:239] Iteration 16530 (2.03728 iter/s, 4.90849s/10 iters), loss = 9.92487
I0523 00:10:09.190182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.92487 (* 1 = 9.92487 loss)
I0523 00:10:09.250197 34819 sgd_solver.cpp:112] Iteration 16530, lr = 0.01
I0523 00:10:15.601696 34819 solver.cpp:239] Iteration 16540 (1.55976 iter/s, 6.41124s/10 iters), loss = 9.46701
I0523 00:10:15.601745 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46701 (* 1 = 9.46701 loss)
I0523 00:10:15.662521 34819 sgd_solver.cpp:112] Iteration 16540, lr = 0.01
I0523 00:10:18.788617 34819 solver.cpp:239] Iteration 16550 (3.13801 iter/s, 3.18674s/10 iters), loss = 8.97161
I0523 00:10:18.788662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97161 (* 1 = 8.97161 loss)
I0523 00:10:18.858381 34819 sgd_solver.cpp:112] Iteration 16550, lr = 0.01
I0523 00:10:23.917604 34819 solver.cpp:239] Iteration 16560 (1.9498 iter/s, 5.12872s/10 iters), loss = 8.59973
I0523 00:10:23.917647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59973 (* 1 = 8.59973 loss)
I0523 00:10:24.363795 34819 sgd_solver.cpp:112] Iteration 16560, lr = 0.01
I0523 00:10:28.450335 34819 solver.cpp:239] Iteration 16570 (2.20629 iter/s, 4.5325s/10 iters), loss = 8.7582
I0523 00:10:28.450462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7582 (* 1 = 8.7582 loss)
I0523 00:10:28.520069 34819 sgd_solver.cpp:112] Iteration 16570, lr = 0.01
I0523 00:10:31.339639 34819 solver.cpp:239] Iteration 16580 (3.46135 iter/s, 2.88905s/10 iters), loss = 8.61628
I0523 00:10:31.339692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61628 (* 1 = 8.61628 loss)
I0523 00:10:31.413425 34819 sgd_solver.cpp:112] Iteration 16580, lr = 0.01
I0523 00:10:37.715255 34819 solver.cpp:239] Iteration 16590 (1.56855 iter/s, 6.37531s/10 iters), loss = 8.72944
I0523 00:10:37.715296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72944 (* 1 = 8.72944 loss)
I0523 00:10:37.779386 34819 sgd_solver.cpp:112] Iteration 16590, lr = 0.01
I0523 00:10:43.439299 34819 solver.cpp:239] Iteration 16600 (1.7471 iter/s, 5.72377s/10 iters), loss = 8.92413
I0523 00:10:43.439354 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92413 (* 1 = 8.92413 loss)
I0523 00:10:43.514835 34819 sgd_solver.cpp:112] Iteration 16600, lr = 0.01
I0523 00:10:48.157802 34819 solver.cpp:239] Iteration 16610 (2.11943 iter/s, 4.71825s/10 iters), loss = 9.22387
I0523 00:10:48.157858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22387 (* 1 = 9.22387 loss)
I0523 00:10:49.028887 34819 sgd_solver.cpp:112] Iteration 16610, lr = 0.01
I0523 00:10:54.577848 34819 solver.cpp:239] Iteration 16620 (1.5577 iter/s, 6.41973s/10 iters), loss = 9.26019
I0523 00:10:54.577903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26019 (* 1 = 9.26019 loss)
I0523 00:10:54.646533 34819 sgd_solver.cpp:112] Iteration 16620, lr = 0.01
I0523 00:10:59.284869 34819 solver.cpp:239] Iteration 16630 (2.1246 iter/s, 4.70677s/10 iters), loss = 9.015
I0523 00:10:59.285053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.015 (* 1 = 9.015 loss)
I0523 00:11:00.106384 34819 sgd_solver.cpp:112] Iteration 16630, lr = 0.01
I0523 00:11:03.432036 34819 solver.cpp:239] Iteration 16640 (2.41148 iter/s, 4.14683s/10 iters), loss = 8.4409
I0523 00:11:03.432081 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4409 (* 1 = 8.4409 loss)
I0523 00:11:03.500762 34819 sgd_solver.cpp:112] Iteration 16640, lr = 0.01
I0523 00:11:07.020269 34819 solver.cpp:239] Iteration 16650 (2.78705 iter/s, 3.58803s/10 iters), loss = 8.39086
I0523 00:11:07.020323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39086 (* 1 = 8.39086 loss)
I0523 00:11:07.686741 34819 sgd_solver.cpp:112] Iteration 16650, lr = 0.01
I0523 00:11:13.210717 34819 solver.cpp:239] Iteration 16660 (1.61548 iter/s, 6.19012s/10 iters), loss = 8.91764
I0523 00:11:13.210763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91764 (* 1 = 8.91764 loss)
I0523 00:11:13.955302 34819 sgd_solver.cpp:112] Iteration 16660, lr = 0.01
I0523 00:11:19.130507 34819 solver.cpp:239] Iteration 16670 (1.68933 iter/s, 5.91949s/10 iters), loss = 9.16823
I0523 00:11:19.130550 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16823 (* 1 = 9.16823 loss)
I0523 00:11:19.838238 34819 sgd_solver.cpp:112] Iteration 16670, lr = 0.01
I0523 00:11:25.572718 34819 solver.cpp:239] Iteration 16680 (1.55234 iter/s, 6.4419s/10 iters), loss = 8.82029
I0523 00:11:25.572757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82029 (* 1 = 8.82029 loss)
I0523 00:11:26.342176 34819 sgd_solver.cpp:112] Iteration 16680, lr = 0.01
I0523 00:11:29.477468 34819 solver.cpp:239] Iteration 16690 (2.56112 iter/s, 3.90454s/10 iters), loss = 8.54247
I0523 00:11:29.477574 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54247 (* 1 = 8.54247 loss)
I0523 00:11:29.530176 34819 sgd_solver.cpp:112] Iteration 16690, lr = 0.01
I0523 00:11:33.205971 34819 solver.cpp:239] Iteration 16700 (2.68223 iter/s, 3.72824s/10 iters), loss = 7.91655
I0523 00:11:33.206014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91655 (* 1 = 7.91655 loss)
I0523 00:11:33.856413 34819 sgd_solver.cpp:112] Iteration 16700, lr = 0.01
I0523 00:11:37.801605 34819 solver.cpp:239] Iteration 16710 (2.17609 iter/s, 4.59539s/10 iters), loss = 9.12161
I0523 00:11:37.801647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12161 (* 1 = 9.12161 loss)
I0523 00:11:37.878064 34819 sgd_solver.cpp:112] Iteration 16710, lr = 0.01
I0523 00:11:43.459543 34819 solver.cpp:239] Iteration 16720 (1.76888 iter/s, 5.6533s/10 iters), loss = 8.91646
I0523 00:11:43.459589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91646 (* 1 = 8.91646 loss)
I0523 00:11:43.523998 34819 sgd_solver.cpp:112] Iteration 16720, lr = 0.01
I0523 00:11:47.039564 34819 solver.cpp:239] Iteration 16730 (2.79343 iter/s, 3.57983s/10 iters), loss = 8.87344
I0523 00:11:47.039608 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87344 (* 1 = 8.87344 loss)
I0523 00:11:47.103528 34819 sgd_solver.cpp:112] Iteration 16730, lr = 0.01
I0523 00:11:51.702752 34819 solver.cpp:239] Iteration 16740 (2.14457 iter/s, 4.66294s/10 iters), loss = 8.26734
I0523 00:11:51.702803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26734 (* 1 = 8.26734 loss)
I0523 00:11:51.778440 34819 sgd_solver.cpp:112] Iteration 16740, lr = 0.01
I0523 00:11:56.867822 34819 solver.cpp:239] Iteration 16750 (1.93618 iter/s, 5.1648s/10 iters), loss = 8.27178
I0523 00:11:56.867859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27178 (* 1 = 8.27178 loss)
I0523 00:11:56.939298 34819 sgd_solver.cpp:112] Iteration 16750, lr = 0.01
I0523 00:12:01.626238 34819 solver.cpp:239] Iteration 16760 (2.10164 iter/s, 4.75818s/10 iters), loss = 8.9129
I0523 00:12:01.626435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9129 (* 1 = 8.9129 loss)
I0523 00:12:02.490192 34819 sgd_solver.cpp:112] Iteration 16760, lr = 0.01
I0523 00:12:08.418651 34819 solver.cpp:239] Iteration 16770 (1.47233 iter/s, 6.79195s/10 iters), loss = 8.72091
I0523 00:12:08.418704 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72091 (* 1 = 8.72091 loss)
I0523 00:12:08.477413 34819 sgd_solver.cpp:112] Iteration 16770, lr = 0.01
I0523 00:12:12.195423 34819 solver.cpp:239] Iteration 16780 (2.64791 iter/s, 3.77656s/10 iters), loss = 9.19261
I0523 00:12:12.195472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19261 (* 1 = 9.19261 loss)
I0523 00:12:12.256242 34819 sgd_solver.cpp:112] Iteration 16780, lr = 0.01
I0523 00:12:16.301913 34819 solver.cpp:239] Iteration 16790 (2.4353 iter/s, 4.10627s/10 iters), loss = 8.43647
I0523 00:12:16.301964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43647 (* 1 = 8.43647 loss)
I0523 00:12:16.357408 34819 sgd_solver.cpp:112] Iteration 16790, lr = 0.01
I0523 00:12:19.663450 34819 solver.cpp:239] Iteration 16800 (2.975 iter/s, 3.36134s/10 iters), loss = 8.66538
I0523 00:12:19.663499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66538 (* 1 = 8.66538 loss)
I0523 00:12:19.728943 34819 sgd_solver.cpp:112] Iteration 16800, lr = 0.01
I0523 00:12:22.280541 34819 solver.cpp:239] Iteration 16810 (3.82128 iter/s, 2.61693s/10 iters), loss = 9.46621
I0523 00:12:22.280589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46621 (* 1 = 9.46621 loss)
I0523 00:12:22.340482 34819 sgd_solver.cpp:112] Iteration 16810, lr = 0.01
I0523 00:12:25.671228 34819 solver.cpp:239] Iteration 16820 (2.94942 iter/s, 3.3905s/10 iters), loss = 8.51813
I0523 00:12:25.671279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51813 (* 1 = 8.51813 loss)
I0523 00:12:26.441721 34819 sgd_solver.cpp:112] Iteration 16820, lr = 0.01
I0523 00:12:31.640132 34819 solver.cpp:239] Iteration 16830 (1.67543 iter/s, 5.96861s/10 iters), loss = 7.91156
I0523 00:12:31.640311 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91156 (* 1 = 7.91156 loss)
I0523 00:12:31.708293 34819 sgd_solver.cpp:112] Iteration 16830, lr = 0.01
I0523 00:12:35.115641 34819 solver.cpp:239] Iteration 16840 (2.87755 iter/s, 3.47517s/10 iters), loss = 9.47135
I0523 00:12:35.115706 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47135 (* 1 = 9.47135 loss)
I0523 00:12:35.833417 34819 sgd_solver.cpp:112] Iteration 16840, lr = 0.01
I0523 00:12:38.559551 34819 solver.cpp:239] Iteration 16850 (2.90388 iter/s, 3.44367s/10 iters), loss = 9.59728
I0523 00:12:38.559600 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.59728 (* 1 = 9.59728 loss)
I0523 00:12:39.362854 34819 sgd_solver.cpp:112] Iteration 16850, lr = 0.01
I0523 00:12:45.844422 34819 solver.cpp:239] Iteration 16860 (1.37277 iter/s, 7.28453s/10 iters), loss = 8.97151
I0523 00:12:45.844476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97151 (* 1 = 8.97151 loss)
I0523 00:12:45.903988 34819 sgd_solver.cpp:112] Iteration 16860, lr = 0.01
I0523 00:12:50.173285 34819 solver.cpp:239] Iteration 16870 (2.31021 iter/s, 4.32861s/10 iters), loss = 9.81708
I0523 00:12:50.173341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.81708 (* 1 = 9.81708 loss)
I0523 00:12:50.239822 34819 sgd_solver.cpp:112] Iteration 16870, lr = 0.01
I0523 00:12:55.294126 34819 solver.cpp:239] Iteration 16880 (1.95291 iter/s, 5.12057s/10 iters), loss = 7.93064
I0523 00:12:55.294167 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93064 (* 1 = 7.93064 loss)
I0523 00:12:55.970046 34819 sgd_solver.cpp:112] Iteration 16880, lr = 0.01
I0523 00:13:00.847561 34819 solver.cpp:239] Iteration 16890 (1.80077 iter/s, 5.55317s/10 iters), loss = 9.13805
I0523 00:13:00.847612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13805 (* 1 = 9.13805 loss)
I0523 00:13:01.741593 34819 sgd_solver.cpp:112] Iteration 16890, lr = 0.01
I0523 00:13:05.874688 34819 solver.cpp:239] Iteration 16900 (1.98931 iter/s, 5.02687s/10 iters), loss = 8.6584
I0523 00:13:05.874771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6584 (* 1 = 8.6584 loss)
I0523 00:13:05.936344 34819 sgd_solver.cpp:112] Iteration 16900, lr = 0.01
I0523 00:13:11.168161 34819 solver.cpp:239] Iteration 16910 (1.89079 iter/s, 5.28878s/10 iters), loss = 8.3009
I0523 00:13:11.168203 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3009 (* 1 = 8.3009 loss)
I0523 00:13:11.234253 34819 sgd_solver.cpp:112] Iteration 16910, lr = 0.01
I0523 00:13:16.927093 34819 solver.cpp:239] Iteration 16920 (1.73652 iter/s, 5.75864s/10 iters), loss = 7.795
I0523 00:13:16.927139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.795 (* 1 = 7.795 loss)
I0523 00:13:17.701113 34819 sgd_solver.cpp:112] Iteration 16920, lr = 0.01
I0523 00:13:22.983299 34819 solver.cpp:239] Iteration 16930 (1.65128 iter/s, 6.05591s/10 iters), loss = 8.31458
I0523 00:13:22.983353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31458 (* 1 = 8.31458 loss)
I0523 00:13:23.055830 34819 sgd_solver.cpp:112] Iteration 16930, lr = 0.01
I0523 00:13:26.450825 34819 solver.cpp:239] Iteration 16940 (2.88407 iter/s, 3.46732s/10 iters), loss = 8.55391
I0523 00:13:26.450881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55391 (* 1 = 8.55391 loss)
I0523 00:13:26.512274 34819 sgd_solver.cpp:112] Iteration 16940, lr = 0.01
I0523 00:13:31.798570 34819 solver.cpp:239] Iteration 16950 (1.87005 iter/s, 5.34745s/10 iters), loss = 8.75491
I0523 00:13:31.798776 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75491 (* 1 = 8.75491 loss)
I0523 00:13:31.870355 34819 sgd_solver.cpp:112] Iteration 16950, lr = 0.01
I0523 00:13:36.714612 34819 solver.cpp:239] Iteration 16960 (2.03433 iter/s, 4.91563s/10 iters), loss = 8.06335
I0523 00:13:36.714666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06335 (* 1 = 8.06335 loss)
I0523 00:13:37.526837 34819 sgd_solver.cpp:112] Iteration 16960, lr = 0.01
I0523 00:13:43.317761 34819 solver.cpp:239] Iteration 16970 (1.51451 iter/s, 6.60281s/10 iters), loss = 9.4865
I0523 00:13:43.317823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4865 (* 1 = 9.4865 loss)
I0523 00:13:44.051592 34819 sgd_solver.cpp:112] Iteration 16970, lr = 0.01
I0523 00:13:48.057114 34819 solver.cpp:239] Iteration 16980 (2.11011 iter/s, 4.73909s/10 iters), loss = 8.12303
I0523 00:13:48.057164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12303 (* 1 = 8.12303 loss)
I0523 00:13:48.133975 34819 sgd_solver.cpp:112] Iteration 16980, lr = 0.01
I0523 00:13:55.054736 34819 solver.cpp:239] Iteration 16990 (1.42913 iter/s, 6.99725s/10 iters), loss = 9.03542
I0523 00:13:55.054805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03542 (* 1 = 9.03542 loss)
I0523 00:13:55.115964 34819 sgd_solver.cpp:112] Iteration 16990, lr = 0.01
I0523 00:13:59.294072 34819 solver.cpp:239] Iteration 17000 (2.36021 iter/s, 4.23692s/10 iters), loss = 8.78276
I0523 00:13:59.294127 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78276 (* 1 = 8.78276 loss)
I0523 00:14:00.114977 34819 sgd_solver.cpp:112] Iteration 17000, lr = 0.01
I0523 00:14:06.540818 34819 solver.cpp:239] Iteration 17010 (1.38 iter/s, 7.2464s/10 iters), loss = 7.40374
I0523 00:14:06.541024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40374 (* 1 = 7.40374 loss)
I0523 00:14:06.604645 34819 sgd_solver.cpp:112] Iteration 17010, lr = 0.01
I0523 00:14:11.569033 34819 solver.cpp:239] Iteration 17020 (1.98893 iter/s, 5.02782s/10 iters), loss = 8.2367
I0523 00:14:11.569087 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2367 (* 1 = 8.2367 loss)
I0523 00:14:12.358862 34819 sgd_solver.cpp:112] Iteration 17020, lr = 0.01
I0523 00:14:15.824188 34819 solver.cpp:239] Iteration 17030 (2.35022 iter/s, 4.25491s/10 iters), loss = 8.58656
I0523 00:14:15.824249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58656 (* 1 = 8.58656 loss)
I0523 00:14:16.603047 34819 sgd_solver.cpp:112] Iteration 17030, lr = 0.01
I0523 00:14:21.206648 34819 solver.cpp:239] Iteration 17040 (1.85798 iter/s, 5.38218s/10 iters), loss = 8.32747
I0523 00:14:21.206713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32747 (* 1 = 8.32747 loss)
I0523 00:14:21.257791 34819 sgd_solver.cpp:112] Iteration 17040, lr = 0.01
I0523 00:14:26.535432 34819 solver.cpp:239] Iteration 17050 (1.8767 iter/s, 5.3285s/10 iters), loss = 9.62568
I0523 00:14:26.535492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.62568 (* 1 = 9.62568 loss)
I0523 00:14:27.382939 34819 sgd_solver.cpp:112] Iteration 17050, lr = 0.01
I0523 00:14:31.516273 34819 solver.cpp:239] Iteration 17060 (2.0078 iter/s, 4.98058s/10 iters), loss = 8.55788
I0523 00:14:31.516324 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55788 (* 1 = 8.55788 loss)
I0523 00:14:32.313853 34819 sgd_solver.cpp:112] Iteration 17060, lr = 0.01
I0523 00:14:37.107141 34819 solver.cpp:239] Iteration 17070 (1.78873 iter/s, 5.59057s/10 iters), loss = 8.23683
I0523 00:14:37.107223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23683 (* 1 = 8.23683 loss)
I0523 00:14:37.181931 34819 sgd_solver.cpp:112] Iteration 17070, lr = 0.01
I0523 00:14:41.332005 34819 solver.cpp:239] Iteration 17080 (2.36709 iter/s, 4.2246s/10 iters), loss = 9.14054
I0523 00:14:41.332051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14054 (* 1 = 9.14054 loss)
I0523 00:14:41.402865 34819 sgd_solver.cpp:112] Iteration 17080, lr = 0.01
I0523 00:14:47.190313 34819 solver.cpp:239] Iteration 17090 (1.70706 iter/s, 5.85802s/10 iters), loss = 8.69328
I0523 00:14:47.190364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69328 (* 1 = 8.69328 loss)
I0523 00:14:47.934237 34819 sgd_solver.cpp:112] Iteration 17090, lr = 0.01
I0523 00:14:54.372249 34819 solver.cpp:239] Iteration 17100 (1.39245 iter/s, 7.18159s/10 iters), loss = 9.5974
I0523 00:14:54.372292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.5974 (* 1 = 9.5974 loss)
I0523 00:14:54.430716 34819 sgd_solver.cpp:112] Iteration 17100, lr = 0.01
I0523 00:15:01.100877 34819 solver.cpp:239] Iteration 17110 (1.48626 iter/s, 6.7283s/10 iters), loss = 8.90385
I0523 00:15:01.100917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90385 (* 1 = 8.90385 loss)
I0523 00:15:01.958744 34819 sgd_solver.cpp:112] Iteration 17110, lr = 0.01
I0523 00:15:07.735409 34819 solver.cpp:239] Iteration 17120 (1.50734 iter/s, 6.63422s/10 iters), loss = 8.43619
I0523 00:15:07.735596 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43619 (* 1 = 8.43619 loss)
I0523 00:15:07.796538 34819 sgd_solver.cpp:112] Iteration 17120, lr = 0.01
I0523 00:15:13.236518 34819 solver.cpp:239] Iteration 17130 (1.81795 iter/s, 5.50071s/10 iters), loss = 8.64558
I0523 00:15:13.236565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64558 (* 1 = 8.64558 loss)
I0523 00:15:14.021270 34819 sgd_solver.cpp:112] Iteration 17130, lr = 0.01
I0523 00:15:17.240115 34819 solver.cpp:239] Iteration 17140 (2.4979 iter/s, 4.00336s/10 iters), loss = 8.71806
I0523 00:15:17.240185 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71806 (* 1 = 8.71806 loss)
I0523 00:15:18.082564 34819 sgd_solver.cpp:112] Iteration 17140, lr = 0.01
I0523 00:15:22.811020 34819 solver.cpp:239] Iteration 17150 (1.79514 iter/s, 5.5706s/10 iters), loss = 8.46239
I0523 00:15:22.811077 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46239 (* 1 = 8.46239 loss)
I0523 00:15:23.512660 34819 sgd_solver.cpp:112] Iteration 17150, lr = 0.01
I0523 00:15:28.348266 34819 solver.cpp:239] Iteration 17160 (1.80604 iter/s, 5.53696s/10 iters), loss = 8.1634
I0523 00:15:28.348321 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1634 (* 1 = 8.1634 loss)
I0523 00:15:28.416780 34819 sgd_solver.cpp:112] Iteration 17160, lr = 0.01
I0523 00:15:31.945269 34819 solver.cpp:239] Iteration 17170 (2.78026 iter/s, 3.59679s/10 iters), loss = 8.6318
I0523 00:15:31.945330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6318 (* 1 = 8.6318 loss)
I0523 00:15:32.747565 34819 sgd_solver.cpp:112] Iteration 17170, lr = 0.01
I0523 00:15:35.962277 34819 solver.cpp:239] Iteration 17180 (2.48956 iter/s, 4.01677s/10 iters), loss = 8.1686
I0523 00:15:35.962323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1686 (* 1 = 8.1686 loss)
I0523 00:15:36.569631 34819 sgd_solver.cpp:112] Iteration 17180, lr = 0.01
I0523 00:15:40.674571 34819 solver.cpp:239] Iteration 17190 (2.12223 iter/s, 4.71202s/10 iters), loss = 9.37358
I0523 00:15:40.674772 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37358 (* 1 = 9.37358 loss)
I0523 00:15:41.517685 34819 sgd_solver.cpp:112] Iteration 17190, lr = 0.01
I0523 00:15:45.546941 34819 solver.cpp:239] Iteration 17200 (2.05256 iter/s, 4.87197s/10 iters), loss = 8.76889
I0523 00:15:45.546986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76889 (* 1 = 8.76889 loss)
I0523 00:15:45.608412 34819 sgd_solver.cpp:112] Iteration 17200, lr = 0.01
I0523 00:15:50.720671 34819 solver.cpp:239] Iteration 17210 (1.93294 iter/s, 5.17346s/10 iters), loss = 7.94421
I0523 00:15:50.720715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94421 (* 1 = 7.94421 loss)
I0523 00:15:51.537385 34819 sgd_solver.cpp:112] Iteration 17210, lr = 0.01
I0523 00:15:54.743926 34819 solver.cpp:239] Iteration 17220 (2.48569 iter/s, 4.02303s/10 iters), loss = 9.41698
I0523 00:15:54.743969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41698 (* 1 = 9.41698 loss)
I0523 00:15:54.992177 34819 sgd_solver.cpp:112] Iteration 17220, lr = 0.01
I0523 00:15:59.047226 34819 solver.cpp:239] Iteration 17230 (2.32392 iter/s, 4.30307s/10 iters), loss = 8.89152
I0523 00:15:59.047266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89152 (* 1 = 8.89152 loss)
I0523 00:15:59.797021 34819 sgd_solver.cpp:112] Iteration 17230, lr = 0.01
I0523 00:16:04.632884 34819 solver.cpp:239] Iteration 17240 (1.79039 iter/s, 5.58538s/10 iters), loss = 8.58087
I0523 00:16:04.632927 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58087 (* 1 = 8.58087 loss)
I0523 00:16:05.476107 34819 sgd_solver.cpp:112] Iteration 17240, lr = 0.01
I0523 00:16:08.822803 34819 solver.cpp:239] Iteration 17250 (2.38681 iter/s, 4.18969s/10 iters), loss = 8.79006
I0523 00:16:08.822861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79006 (* 1 = 8.79006 loss)
I0523 00:16:08.887861 34819 sgd_solver.cpp:112] Iteration 17250, lr = 0.01
I0523 00:16:13.003780 34819 solver.cpp:239] Iteration 17260 (2.39192 iter/s, 4.18075s/10 iters), loss = 8.51388
I0523 00:16:13.003913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51388 (* 1 = 8.51388 loss)
I0523 00:16:13.082648 34819 sgd_solver.cpp:112] Iteration 17260, lr = 0.01
I0523 00:16:18.766479 34819 solver.cpp:239] Iteration 17270 (1.73541 iter/s, 5.76233s/10 iters), loss = 9.02688
I0523 00:16:18.766520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02688 (* 1 = 9.02688 loss)
I0523 00:16:18.844256 34819 sgd_solver.cpp:112] Iteration 17270, lr = 0.01
I0523 00:16:22.213294 34819 solver.cpp:239] Iteration 17280 (2.9014 iter/s, 3.44662s/10 iters), loss = 8.4954
I0523 00:16:22.213336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4954 (* 1 = 8.4954 loss)
I0523 00:16:22.691473 34819 sgd_solver.cpp:112] Iteration 17280, lr = 0.01
I0523 00:16:26.206770 34819 solver.cpp:239] Iteration 17290 (2.50422 iter/s, 3.99326s/10 iters), loss = 8.34625
I0523 00:16:26.206812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34625 (* 1 = 8.34625 loss)
I0523 00:16:26.269232 34819 sgd_solver.cpp:112] Iteration 17290, lr = 0.01
I0523 00:16:29.488991 34819 solver.cpp:239] Iteration 17300 (3.0469 iter/s, 3.28203s/10 iters), loss = 9.41078
I0523 00:16:29.489037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41078 (* 1 = 9.41078 loss)
I0523 00:16:29.578830 34819 sgd_solver.cpp:112] Iteration 17300, lr = 0.01
I0523 00:16:32.974810 34819 solver.cpp:239] Iteration 17310 (2.86894 iter/s, 3.48561s/10 iters), loss = 8.71661
I0523 00:16:32.974853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71661 (* 1 = 8.71661 loss)
I0523 00:16:33.063908 34819 sgd_solver.cpp:112] Iteration 17310, lr = 0.01
I0523 00:16:37.886106 34819 solver.cpp:239] Iteration 17320 (2.03622 iter/s, 4.91105s/10 iters), loss = 9.48154
I0523 00:16:37.886152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48154 (* 1 = 9.48154 loss)
I0523 00:16:37.955397 34819 sgd_solver.cpp:112] Iteration 17320, lr = 0.01
I0523 00:16:41.336591 34819 solver.cpp:239] Iteration 17330 (2.8983 iter/s, 3.45029s/10 iters), loss = 8.15771
I0523 00:16:41.336633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15771 (* 1 = 8.15771 loss)
I0523 00:16:41.507483 34819 sgd_solver.cpp:112] Iteration 17330, lr = 0.01
I0523 00:16:46.563149 34819 solver.cpp:239] Iteration 17340 (1.9134 iter/s, 5.22629s/10 iters), loss = 8.18623
I0523 00:16:46.563330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18623 (* 1 = 8.18623 loss)
I0523 00:16:46.626852 34819 sgd_solver.cpp:112] Iteration 17340, lr = 0.01
I0523 00:16:49.441249 34819 solver.cpp:239] Iteration 17350 (3.47487 iter/s, 2.8778s/10 iters), loss = 8.50784
I0523 00:16:49.441301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50784 (* 1 = 8.50784 loss)
I0523 00:16:49.868196 34819 sgd_solver.cpp:112] Iteration 17350, lr = 0.01
I0523 00:16:54.199582 34819 solver.cpp:239] Iteration 17360 (2.10169 iter/s, 4.75807s/10 iters), loss = 8.21011
I0523 00:16:54.199631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21011 (* 1 = 8.21011 loss)
I0523 00:16:54.261025 34819 sgd_solver.cpp:112] Iteration 17360, lr = 0.01
I0523 00:16:57.794466 34819 solver.cpp:239] Iteration 17370 (2.78189 iter/s, 3.59467s/10 iters), loss = 8.99998
I0523 00:16:57.794524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99998 (* 1 = 8.99998 loss)
I0523 00:16:58.682188 34819 sgd_solver.cpp:112] Iteration 17370, lr = 0.01
I0523 00:17:02.786811 34819 solver.cpp:239] Iteration 17380 (2.00318 iter/s, 4.99207s/10 iters), loss = 8.36482
I0523 00:17:02.786870 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36482 (* 1 = 8.36482 loss)
I0523 00:17:02.836494 34819 sgd_solver.cpp:112] Iteration 17380, lr = 0.01
I0523 00:17:09.055647 34819 solver.cpp:239] Iteration 17390 (1.59528 iter/s, 6.26848s/10 iters), loss = 8.4255
I0523 00:17:09.055747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4255 (* 1 = 8.4255 loss)
I0523 00:17:09.133319 34819 sgd_solver.cpp:112] Iteration 17390, lr = 0.01
I0523 00:17:12.053225 34819 solver.cpp:239] Iteration 17400 (3.33628 iter/s, 2.99735s/10 iters), loss = 9.39477
I0523 00:17:12.053280 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39477 (* 1 = 9.39477 loss)
I0523 00:17:12.127823 34819 sgd_solver.cpp:112] Iteration 17400, lr = 0.01
I0523 00:17:17.677760 34819 solver.cpp:239] Iteration 17410 (1.77801 iter/s, 5.62425s/10 iters), loss = 8.65038
I0523 00:17:17.677917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65038 (* 1 = 8.65038 loss)
I0523 00:17:17.738958 34819 sgd_solver.cpp:112] Iteration 17410, lr = 0.01
I0523 00:17:23.263047 34819 solver.cpp:239] Iteration 17420 (1.79054 iter/s, 5.5849s/10 iters), loss = 8.84727
I0523 00:17:23.263092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84727 (* 1 = 8.84727 loss)
I0523 00:17:23.322580 34819 sgd_solver.cpp:112] Iteration 17420, lr = 0.01
I0523 00:17:28.100682 34819 solver.cpp:239] Iteration 17430 (2.06725 iter/s, 4.83735s/10 iters), loss = 9.65071
I0523 00:17:28.100744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65071 (* 1 = 9.65071 loss)
I0523 00:17:28.988368 34819 sgd_solver.cpp:112] Iteration 17430, lr = 0.01
I0523 00:17:33.515832 34819 solver.cpp:239] Iteration 17440 (1.84677 iter/s, 5.41487s/10 iters), loss = 8.47049
I0523 00:17:33.515892 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47049 (* 1 = 8.47049 loss)
I0523 00:17:33.589494 34819 sgd_solver.cpp:112] Iteration 17440, lr = 0.01
I0523 00:17:38.467936 34819 solver.cpp:239] Iteration 17450 (2.01945 iter/s, 4.95183s/10 iters), loss = 9.05505
I0523 00:17:38.467990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05505 (* 1 = 9.05505 loss)
I0523 00:17:38.536226 34819 sgd_solver.cpp:112] Iteration 17450, lr = 0.01
I0523 00:17:41.926164 34819 solver.cpp:239] Iteration 17460 (2.89183 iter/s, 3.45802s/10 iters), loss = 9.21408
I0523 00:17:41.926219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21408 (* 1 = 9.21408 loss)
I0523 00:17:41.988443 34819 sgd_solver.cpp:112] Iteration 17460, lr = 0.01
I0523 00:17:46.159317 34819 solver.cpp:239] Iteration 17470 (2.36244 iter/s, 4.2329s/10 iters), loss = 8.38771
I0523 00:17:46.159366 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38771 (* 1 = 8.38771 loss)
I0523 00:17:46.233949 34819 sgd_solver.cpp:112] Iteration 17470, lr = 0.01
I0523 00:17:50.452170 34819 solver.cpp:239] Iteration 17480 (2.32958 iter/s, 4.29262s/10 iters), loss = 8.48914
I0523 00:17:50.452235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48914 (* 1 = 8.48914 loss)
I0523 00:17:51.286686 34819 sgd_solver.cpp:112] Iteration 17480, lr = 0.01
I0523 00:17:55.468794 34819 solver.cpp:239] Iteration 17490 (1.99348 iter/s, 5.01635s/10 iters), loss = 8.12
I0523 00:17:55.468837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12 (* 1 = 8.12 loss)
I0523 00:17:55.534153 34819 sgd_solver.cpp:112] Iteration 17490, lr = 0.01
I0523 00:17:58.969259 34819 solver.cpp:239] Iteration 17500 (2.85692 iter/s, 3.50027s/10 iters), loss = 9.17843
I0523 00:17:58.969303 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17843 (* 1 = 9.17843 loss)
I0523 00:17:59.020290 34819 sgd_solver.cpp:112] Iteration 17500, lr = 0.01
I0523 00:18:06.090468 34819 solver.cpp:239] Iteration 17510 (1.40433 iter/s, 7.12086s/10 iters), loss = 8.04901
I0523 00:18:06.090524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04901 (* 1 = 8.04901 loss)
I0523 00:18:06.724143 34819 sgd_solver.cpp:112] Iteration 17510, lr = 0.01
I0523 00:18:11.518165 34819 solver.cpp:239] Iteration 17520 (1.84251 iter/s, 5.42737s/10 iters), loss = 8.35584
I0523 00:18:11.518223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35584 (* 1 = 8.35584 loss)
I0523 00:18:12.317248 34819 sgd_solver.cpp:112] Iteration 17520, lr = 0.01
I0523 00:18:15.841734 34819 solver.cpp:239] Iteration 17530 (2.31303 iter/s, 4.32333s/10 iters), loss = 8.21367
I0523 00:18:15.841789 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21367 (* 1 = 8.21367 loss)
I0523 00:18:15.914465 34819 sgd_solver.cpp:112] Iteration 17530, lr = 0.01
I0523 00:18:20.723506 34819 solver.cpp:239] Iteration 17540 (2.04854 iter/s, 4.88152s/10 iters), loss = 8.62326
I0523 00:18:20.723672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62326 (* 1 = 8.62326 loss)
I0523 00:18:21.094281 34819 sgd_solver.cpp:112] Iteration 17540, lr = 0.01
I0523 00:18:25.009739 34819 solver.cpp:239] Iteration 17550 (2.33324 iter/s, 4.28589s/10 iters), loss = 8.84216
I0523 00:18:25.009790 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84216 (* 1 = 8.84216 loss)
I0523 00:18:25.079614 34819 sgd_solver.cpp:112] Iteration 17550, lr = 0.01
I0523 00:18:29.560696 34819 solver.cpp:239] Iteration 17560 (2.19746 iter/s, 4.5507s/10 iters), loss = 8.31666
I0523 00:18:29.560742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31666 (* 1 = 8.31666 loss)
I0523 00:18:29.628705 34819 sgd_solver.cpp:112] Iteration 17560, lr = 0.01
I0523 00:18:35.761657 34819 solver.cpp:239] Iteration 17570 (1.61273 iter/s, 6.20066s/10 iters), loss = 8.33071
I0523 00:18:35.761698 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33071 (* 1 = 8.33071 loss)
I0523 00:18:36.637831 34819 sgd_solver.cpp:112] Iteration 17570, lr = 0.01
I0523 00:18:41.115448 34819 solver.cpp:239] Iteration 17580 (1.86793 iter/s, 5.35353s/10 iters), loss = 9.15002
I0523 00:18:41.115501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15002 (* 1 = 9.15002 loss)
I0523 00:18:41.199533 34819 sgd_solver.cpp:112] Iteration 17580, lr = 0.01
I0523 00:18:48.091873 34819 solver.cpp:239] Iteration 17590 (1.43347 iter/s, 6.97609s/10 iters), loss = 8.99335
I0523 00:18:48.091925 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99335 (* 1 = 8.99335 loss)
I0523 00:18:48.163868 34819 sgd_solver.cpp:112] Iteration 17590, lr = 0.01
I0523 00:18:52.374749 34819 solver.cpp:239] Iteration 17600 (2.33503 iter/s, 4.28259s/10 iters), loss = 8.91136
I0523 00:18:52.374855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91136 (* 1 = 8.91136 loss)
I0523 00:18:52.876464 34819 sgd_solver.cpp:112] Iteration 17600, lr = 0.01
I0523 00:18:57.314306 34819 solver.cpp:239] Iteration 17610 (2.0246 iter/s, 4.93924s/10 iters), loss = 8.66749
I0523 00:18:57.314348 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66749 (* 1 = 8.66749 loss)
I0523 00:18:57.379261 34819 sgd_solver.cpp:112] Iteration 17610, lr = 0.01
I0523 00:19:03.609879 34819 solver.cpp:239] Iteration 17620 (1.58849 iter/s, 6.29527s/10 iters), loss = 7.75124
I0523 00:19:03.609926 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75124 (* 1 = 7.75124 loss)
I0523 00:19:04.464947 34819 sgd_solver.cpp:112] Iteration 17620, lr = 0.01
I0523 00:19:08.871227 34819 solver.cpp:239] Iteration 17630 (1.90075 iter/s, 5.26108s/10 iters), loss = 8.75216
I0523 00:19:08.871278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75216 (* 1 = 8.75216 loss)
I0523 00:19:09.478850 34819 sgd_solver.cpp:112] Iteration 17630, lr = 0.01
I0523 00:19:13.635166 34819 solver.cpp:239] Iteration 17640 (2.09922 iter/s, 4.76368s/10 iters), loss = 8.40698
I0523 00:19:13.635215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40698 (* 1 = 8.40698 loss)
I0523 00:19:13.706120 34819 sgd_solver.cpp:112] Iteration 17640, lr = 0.01
I0523 00:19:16.322746 34819 solver.cpp:239] Iteration 17650 (3.72106 iter/s, 2.68741s/10 iters), loss = 8.87324
I0523 00:19:16.322795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87324 (* 1 = 8.87324 loss)
I0523 00:19:17.159502 34819 sgd_solver.cpp:112] Iteration 17650, lr = 0.01
I0523 00:19:20.372562 34819 solver.cpp:239] Iteration 17660 (2.46939 iter/s, 4.04957s/10 iters), loss = 8.65817
I0523 00:19:20.372611 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65817 (* 1 = 8.65817 loss)
I0523 00:19:21.149868 34819 sgd_solver.cpp:112] Iteration 17660, lr = 0.01
I0523 00:19:25.926592 34819 solver.cpp:239] Iteration 17670 (1.80058 iter/s, 5.55375s/10 iters), loss = 7.6225
I0523 00:19:25.926816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6225 (* 1 = 7.6225 loss)
I0523 00:19:26.407452 34819 sgd_solver.cpp:112] Iteration 17670, lr = 0.01
I0523 00:19:29.404520 34819 solver.cpp:239] Iteration 17680 (2.87557 iter/s, 3.47757s/10 iters), loss = 9.22249
I0523 00:19:29.404567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22249 (* 1 = 9.22249 loss)
I0523 00:19:29.482517 34819 sgd_solver.cpp:112] Iteration 17680, lr = 0.01
I0523 00:19:32.743501 34819 solver.cpp:239] Iteration 17690 (2.99511 iter/s, 3.33878s/10 iters), loss = 9.11983
I0523 00:19:32.743562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11983 (* 1 = 9.11983 loss)
I0523 00:19:33.574028 34819 sgd_solver.cpp:112] Iteration 17690, lr = 0.01
I0523 00:19:37.540200 34819 solver.cpp:239] Iteration 17700 (2.08488 iter/s, 4.79644s/10 iters), loss = 9.44401
I0523 00:19:37.540247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44401 (* 1 = 9.44401 loss)
I0523 00:19:37.594830 34819 sgd_solver.cpp:112] Iteration 17700, lr = 0.01
I0523 00:19:41.433885 34819 solver.cpp:239] Iteration 17710 (2.5684 iter/s, 3.89347s/10 iters), loss = 8.89775
I0523 00:19:41.433935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89775 (* 1 = 8.89775 loss)
I0523 00:19:41.490993 34819 sgd_solver.cpp:112] Iteration 17710, lr = 0.01
I0523 00:19:47.233054 34819 solver.cpp:239] Iteration 17720 (1.72448 iter/s, 5.79886s/10 iters), loss = 8.63333
I0523 00:19:47.233106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63333 (* 1 = 8.63333 loss)
I0523 00:19:47.301304 34819 sgd_solver.cpp:112] Iteration 17720, lr = 0.01
I0523 00:19:50.933037 34819 solver.cpp:239] Iteration 17730 (2.70287 iter/s, 3.69976s/10 iters), loss = 9.58071
I0523 00:19:50.933084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58071 (* 1 = 9.58071 loss)
I0523 00:19:51.767835 34819 sgd_solver.cpp:112] Iteration 17730, lr = 0.01
I0523 00:19:56.778810 34819 solver.cpp:239] Iteration 17740 (1.71072 iter/s, 5.84548s/10 iters), loss = 8.41653
I0523 00:19:56.778954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41653 (* 1 = 8.41653 loss)
I0523 00:19:56.839314 34819 sgd_solver.cpp:112] Iteration 17740, lr = 0.01
I0523 00:20:01.076887 34819 solver.cpp:239] Iteration 17750 (2.3268 iter/s, 4.29775s/10 iters), loss = 8.65294
I0523 00:20:01.076941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65294 (* 1 = 8.65294 loss)
I0523 00:20:01.874830 34819 sgd_solver.cpp:112] Iteration 17750, lr = 0.01
I0523 00:20:07.298877 34819 solver.cpp:239] Iteration 17760 (1.60728 iter/s, 6.22168s/10 iters), loss = 8.19505
I0523 00:20:07.298933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19505 (* 1 = 8.19505 loss)
I0523 00:20:08.013351 34819 sgd_solver.cpp:112] Iteration 17760, lr = 0.01
I0523 00:20:12.039706 34819 solver.cpp:239] Iteration 17770 (2.10945 iter/s, 4.74057s/10 iters), loss = 8.09576
I0523 00:20:12.039760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09576 (* 1 = 8.09576 loss)
I0523 00:20:12.100858 34819 sgd_solver.cpp:112] Iteration 17770, lr = 0.01
I0523 00:20:15.436971 34819 solver.cpp:239] Iteration 17780 (2.94372 iter/s, 3.39706s/10 iters), loss = 9.75452
I0523 00:20:15.437026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75452 (* 1 = 9.75452 loss)
I0523 00:20:15.504808 34819 sgd_solver.cpp:112] Iteration 17780, lr = 0.01
I0523 00:20:20.677089 34819 solver.cpp:239] Iteration 17790 (1.90846 iter/s, 5.23982s/10 iters), loss = 8.8143
I0523 00:20:20.677150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8143 (* 1 = 8.8143 loss)
I0523 00:20:21.443631 34819 sgd_solver.cpp:112] Iteration 17790, lr = 0.01
I0523 00:20:25.569927 34819 solver.cpp:239] Iteration 17800 (2.04391 iter/s, 4.89257s/10 iters), loss = 8.76252
I0523 00:20:25.569979 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76252 (* 1 = 8.76252 loss)
I0523 00:20:25.661839 34819 sgd_solver.cpp:112] Iteration 17800, lr = 0.01
I0523 00:20:29.790089 34819 solver.cpp:239] Iteration 17810 (2.36971 iter/s, 4.21993s/10 iters), loss = 7.84446
I0523 00:20:29.790233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84446 (* 1 = 7.84446 loss)
I0523 00:20:29.864919 34819 sgd_solver.cpp:112] Iteration 17810, lr = 0.01
I0523 00:20:35.633586 34819 solver.cpp:239] Iteration 17820 (1.71141 iter/s, 5.84312s/10 iters), loss = 9.26352
I0523 00:20:35.633641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26352 (* 1 = 9.26352 loss)
I0523 00:20:35.704013 34819 sgd_solver.cpp:112] Iteration 17820, lr = 0.01
I0523 00:20:41.283004 34819 solver.cpp:239] Iteration 17830 (1.77019 iter/s, 5.64912s/10 iters), loss = 8.79717
I0523 00:20:41.283056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79717 (* 1 = 8.79717 loss)
I0523 00:20:41.356288 34819 sgd_solver.cpp:112] Iteration 17830, lr = 0.01
I0523 00:20:48.148545 34819 solver.cpp:239] Iteration 17840 (1.45662 iter/s, 6.8652s/10 iters), loss = 9.16463
I0523 00:20:48.148589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16463 (* 1 = 9.16463 loss)
I0523 00:20:48.203141 34819 sgd_solver.cpp:112] Iteration 17840, lr = 0.01
I0523 00:20:52.241171 34819 solver.cpp:239] Iteration 17850 (2.44355 iter/s, 4.09241s/10 iters), loss = 7.94006
I0523 00:20:52.241219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94006 (* 1 = 7.94006 loss)
I0523 00:20:53.020125 34819 sgd_solver.cpp:112] Iteration 17850, lr = 0.01
I0523 00:20:56.112212 34819 solver.cpp:239] Iteration 17860 (2.58344 iter/s, 3.87081s/10 iters), loss = 9.22148
I0523 00:20:56.112275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22148 (* 1 = 9.22148 loss)
I0523 00:20:56.176295 34819 sgd_solver.cpp:112] Iteration 17860, lr = 0.01
I0523 00:21:01.580302 34819 solver.cpp:239] Iteration 17870 (1.82889 iter/s, 5.46779s/10 iters), loss = 8.69844
I0523 00:21:01.580500 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69844 (* 1 = 8.69844 loss)
I0523 00:21:02.322391 34819 sgd_solver.cpp:112] Iteration 17870, lr = 0.01
I0523 00:21:05.847663 34819 solver.cpp:239] Iteration 17880 (2.34358 iter/s, 4.26698s/10 iters), loss = 8.66312
I0523 00:21:05.847733 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66312 (* 1 = 8.66312 loss)
I0523 00:21:05.932698 34819 sgd_solver.cpp:112] Iteration 17880, lr = 0.01
I0523 00:21:08.101969 34819 solver.cpp:239] Iteration 17890 (4.43631 iter/s, 2.25413s/10 iters), loss = 9.43189
I0523 00:21:08.102021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43189 (* 1 = 9.43189 loss)
I0523 00:21:08.169077 34819 sgd_solver.cpp:112] Iteration 17890, lr = 0.01
I0523 00:21:13.624819 34819 solver.cpp:239] Iteration 17900 (1.81075 iter/s, 5.52257s/10 iters), loss = 9.24408
I0523 00:21:13.624862 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24408 (* 1 = 9.24408 loss)
I0523 00:21:13.696672 34819 sgd_solver.cpp:112] Iteration 17900, lr = 0.01
I0523 00:21:19.302130 34819 solver.cpp:239] Iteration 17910 (1.76148 iter/s, 5.67703s/10 iters), loss = 8.95065
I0523 00:21:19.302177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95065 (* 1 = 8.95065 loss)
I0523 00:21:20.082300 34819 sgd_solver.cpp:112] Iteration 17910, lr = 0.01
I0523 00:21:25.225127 34819 solver.cpp:239] Iteration 17920 (1.68842 iter/s, 5.9227s/10 iters), loss = 7.52913
I0523 00:21:25.225184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52913 (* 1 = 7.52913 loss)
I0523 00:21:25.738076 34819 sgd_solver.cpp:112] Iteration 17920, lr = 0.01
I0523 00:21:29.913512 34819 solver.cpp:239] Iteration 17930 (2.13304 iter/s, 4.68814s/10 iters), loss = 8.87599
I0523 00:21:29.913568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87599 (* 1 = 8.87599 loss)
I0523 00:21:29.988128 34819 sgd_solver.cpp:112] Iteration 17930, lr = 0.01
I0523 00:21:35.178006 34819 solver.cpp:239] Iteration 17940 (1.89962 iter/s, 5.26421s/10 iters), loss = 8.88127
I0523 00:21:35.178194 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88127 (* 1 = 8.88127 loss)
I0523 00:21:36.074045 34819 sgd_solver.cpp:112] Iteration 17940, lr = 0.01
I0523 00:21:41.004843 34819 solver.cpp:239] Iteration 17950 (1.71632 iter/s, 5.82641s/10 iters), loss = 8.353
I0523 00:21:41.004899 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.353 (* 1 = 8.353 loss)
I0523 00:21:41.084518 34819 sgd_solver.cpp:112] Iteration 17950, lr = 0.01
I0523 00:21:46.830063 34819 solver.cpp:239] Iteration 17960 (1.71676 iter/s, 5.82492s/10 iters), loss = 8.517
I0523 00:21:46.830121 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.517 (* 1 = 8.517 loss)
I0523 00:21:46.898519 34819 sgd_solver.cpp:112] Iteration 17960, lr = 0.01
I0523 00:21:51.409380 34819 solver.cpp:239] Iteration 17970 (2.18385 iter/s, 4.57907s/10 iters), loss = 8.59326
I0523 00:21:51.409440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59326 (* 1 = 8.59326 loss)
I0523 00:21:51.485389 34819 sgd_solver.cpp:112] Iteration 17970, lr = 0.01
I0523 00:21:54.633036 34819 solver.cpp:239] Iteration 17980 (3.10226 iter/s, 3.22346s/10 iters), loss = 9.46935
I0523 00:21:54.633091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46935 (* 1 = 9.46935 loss)
I0523 00:21:54.693605 34819 sgd_solver.cpp:112] Iteration 17980, lr = 0.01
I0523 00:21:58.957561 34819 solver.cpp:239] Iteration 17990 (2.31253 iter/s, 4.32427s/10 iters), loss = 8.30697
I0523 00:21:58.957615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30697 (* 1 = 8.30697 loss)
I0523 00:21:59.665225 34819 sgd_solver.cpp:112] Iteration 17990, lr = 0.01
I0523 00:22:02.275590 34819 solver.cpp:239] Iteration 18000 (3.01402 iter/s, 3.31782s/10 iters), loss = 9.61163
I0523 00:22:02.275656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61163 (* 1 = 9.61163 loss)
I0523 00:22:02.353135 34819 sgd_solver.cpp:112] Iteration 18000, lr = 0.01
I0523 00:22:06.118216 34819 solver.cpp:239] Iteration 18010 (2.60254 iter/s, 3.8424s/10 iters), loss = 9.14927
I0523 00:22:06.118355 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14927 (* 1 = 9.14927 loss)
I0523 00:22:06.251085 34819 sgd_solver.cpp:112] Iteration 18010, lr = 0.01
I0523 00:22:11.240238 34819 solver.cpp:239] Iteration 18020 (1.95249 iter/s, 5.12166s/10 iters), loss = 8.64886
I0523 00:22:11.240290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64886 (* 1 = 8.64886 loss)
I0523 00:22:11.299423 34819 sgd_solver.cpp:112] Iteration 18020, lr = 0.01
I0523 00:22:16.869334 34819 solver.cpp:239] Iteration 18030 (1.77658 iter/s, 5.62881s/10 iters), loss = 8.54503
I0523 00:22:16.869392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54503 (* 1 = 8.54503 loss)
I0523 00:22:16.937700 34819 sgd_solver.cpp:112] Iteration 18030, lr = 0.01
I0523 00:22:20.285446 34819 solver.cpp:239] Iteration 18040 (2.92751 iter/s, 3.41588s/10 iters), loss = 7.59609
I0523 00:22:20.285531 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59609 (* 1 = 7.59609 loss)
I0523 00:22:20.358896 34819 sgd_solver.cpp:112] Iteration 18040, lr = 0.01
I0523 00:22:24.766207 34819 solver.cpp:239] Iteration 18050 (2.2319 iter/s, 4.48048s/10 iters), loss = 8.10963
I0523 00:22:24.766263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10963 (* 1 = 8.10963 loss)
I0523 00:22:25.447089 34819 sgd_solver.cpp:112] Iteration 18050, lr = 0.01
I0523 00:22:29.066983 34819 solver.cpp:239] Iteration 18060 (2.3253 iter/s, 4.30053s/10 iters), loss = 8.51341
I0523 00:22:29.067036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51341 (* 1 = 8.51341 loss)
I0523 00:22:29.140385 34819 sgd_solver.cpp:112] Iteration 18060, lr = 0.01
I0523 00:22:34.345523 34819 solver.cpp:239] Iteration 18070 (1.89456 iter/s, 5.27827s/10 iters), loss = 8.77074
I0523 00:22:34.345577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77074 (* 1 = 8.77074 loss)
I0523 00:22:34.419052 34819 sgd_solver.cpp:112] Iteration 18070, lr = 0.01
I0523 00:22:40.063220 34819 solver.cpp:239] Iteration 18080 (1.74905 iter/s, 5.7174s/10 iters), loss = 8.32796
I0523 00:22:40.063390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32796 (* 1 = 8.32796 loss)
I0523 00:22:40.797365 34819 sgd_solver.cpp:112] Iteration 18080, lr = 0.01
I0523 00:22:45.508476 34819 solver.cpp:239] Iteration 18090 (1.83659 iter/s, 5.44487s/10 iters), loss = 8.91848
I0523 00:22:45.508520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91848 (* 1 = 8.91848 loss)
I0523 00:22:45.579056 34819 sgd_solver.cpp:112] Iteration 18090, lr = 0.01
I0523 00:22:51.766561 34819 solver.cpp:239] Iteration 18100 (1.59801 iter/s, 6.25777s/10 iters), loss = 8.40572
I0523 00:22:51.766616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40572 (* 1 = 8.40572 loss)
I0523 00:22:52.606369 34819 sgd_solver.cpp:112] Iteration 18100, lr = 0.01
I0523 00:22:58.384544 34819 solver.cpp:239] Iteration 18110 (1.51111 iter/s, 6.61766s/10 iters), loss = 7.966
I0523 00:22:58.384593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.966 (* 1 = 7.966 loss)
I0523 00:22:59.212322 34819 sgd_solver.cpp:112] Iteration 18110, lr = 0.01
I0523 00:23:02.590104 34819 solver.cpp:239] Iteration 18120 (2.37794 iter/s, 4.20533s/10 iters), loss = 7.78226
I0523 00:23:02.590152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78226 (* 1 = 7.78226 loss)
I0523 00:23:03.412564 34819 sgd_solver.cpp:112] Iteration 18120, lr = 0.01
I0523 00:23:06.492619 34819 solver.cpp:239] Iteration 18130 (2.5626 iter/s, 3.90228s/10 iters), loss = 8.36759
I0523 00:23:06.492669 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36759 (* 1 = 8.36759 loss)
I0523 00:23:06.562269 34819 sgd_solver.cpp:112] Iteration 18130, lr = 0.01
I0523 00:23:11.167351 34819 solver.cpp:239] Iteration 18140 (2.13928 iter/s, 4.67448s/10 iters), loss = 8.58698
I0523 00:23:11.167505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58698 (* 1 = 8.58698 loss)
I0523 00:23:11.890769 34819 sgd_solver.cpp:112] Iteration 18140, lr = 0.01
I0523 00:23:17.212931 34819 solver.cpp:239] Iteration 18150 (1.65421 iter/s, 6.04518s/10 iters), loss = 8.6643
I0523 00:23:17.213014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6643 (* 1 = 8.6643 loss)
I0523 00:23:18.040592 34819 sgd_solver.cpp:112] Iteration 18150, lr = 0.01
I0523 00:23:22.390498 34819 solver.cpp:239] Iteration 18160 (1.93152 iter/s, 5.17727s/10 iters), loss = 8.0512
I0523 00:23:22.390559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0512 (* 1 = 8.0512 loss)
I0523 00:23:23.218322 34819 sgd_solver.cpp:112] Iteration 18160, lr = 0.01
I0523 00:23:28.272706 34819 solver.cpp:239] Iteration 18170 (1.70013 iter/s, 5.88191s/10 iters), loss = 9.3027
I0523 00:23:28.272763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3027 (* 1 = 9.3027 loss)
I0523 00:23:29.100472 34819 sgd_solver.cpp:112] Iteration 18170, lr = 0.01
I0523 00:23:33.211704 34819 solver.cpp:239] Iteration 18180 (2.02481 iter/s, 4.93873s/10 iters), loss = 9.19684
I0523 00:23:33.211760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19684 (* 1 = 9.19684 loss)
I0523 00:23:33.276027 34819 sgd_solver.cpp:112] Iteration 18180, lr = 0.01
I0523 00:23:36.731436 34819 solver.cpp:239] Iteration 18190 (2.84132 iter/s, 3.5195s/10 iters), loss = 8.62513
I0523 00:23:36.731498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62513 (* 1 = 8.62513 loss)
I0523 00:23:37.542011 34819 sgd_solver.cpp:112] Iteration 18190, lr = 0.01
I0523 00:23:43.333279 34819 solver.cpp:239] Iteration 18200 (1.5148 iter/s, 6.60152s/10 iters), loss = 8.71527
I0523 00:23:43.333484 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71527 (* 1 = 8.71527 loss)
I0523 00:23:43.500298 34819 sgd_solver.cpp:112] Iteration 18200, lr = 0.01
I0523 00:23:48.311429 34819 solver.cpp:239] Iteration 18210 (2.00893 iter/s, 4.97777s/10 iters), loss = 9.1908
I0523 00:23:48.311473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1908 (* 1 = 9.1908 loss)
I0523 00:23:49.093801 34819 sgd_solver.cpp:112] Iteration 18210, lr = 0.01
I0523 00:23:53.506924 34819 solver.cpp:239] Iteration 18220 (1.92484 iter/s, 5.19524s/10 iters), loss = 9.09762
I0523 00:23:53.506979 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09762 (* 1 = 9.09762 loss)
I0523 00:23:54.294684 34819 sgd_solver.cpp:112] Iteration 18220, lr = 0.01
I0523 00:24:00.830795 34819 solver.cpp:239] Iteration 18230 (1.36546 iter/s, 7.32352s/10 iters), loss = 8.87961
I0523 00:24:00.830835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87961 (* 1 = 8.87961 loss)
I0523 00:24:00.898022 34819 sgd_solver.cpp:112] Iteration 18230, lr = 0.01
I0523 00:24:06.789340 34819 solver.cpp:239] Iteration 18240 (1.67834 iter/s, 5.95825s/10 iters), loss = 9.30058
I0523 00:24:06.789386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30058 (* 1 = 9.30058 loss)
I0523 00:24:07.605159 34819 sgd_solver.cpp:112] Iteration 18240, lr = 0.01
I0523 00:24:14.335132 34819 solver.cpp:239] Iteration 18250 (1.32531 iter/s, 7.54543s/10 iters), loss = 8.71177
I0523 00:24:14.335247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71177 (* 1 = 8.71177 loss)
I0523 00:24:15.039264 34819 sgd_solver.cpp:112] Iteration 18250, lr = 0.01
I0523 00:24:18.668782 34819 solver.cpp:239] Iteration 18260 (2.30769 iter/s, 4.33334s/10 iters), loss = 8.91015
I0523 00:24:18.668844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91015 (* 1 = 8.91015 loss)
I0523 00:24:18.726924 34819 sgd_solver.cpp:112] Iteration 18260, lr = 0.01
I0523 00:24:22.971735 34819 solver.cpp:239] Iteration 18270 (2.32413 iter/s, 4.30269s/10 iters), loss = 8.43911
I0523 00:24:22.971796 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43911 (* 1 = 8.43911 loss)
I0523 00:24:23.739008 34819 sgd_solver.cpp:112] Iteration 18270, lr = 0.01
I0523 00:24:28.709065 34819 solver.cpp:239] Iteration 18280 (1.74306 iter/s, 5.73703s/10 iters), loss = 8.51733
I0523 00:24:28.709118 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51733 (* 1 = 8.51733 loss)
I0523 00:24:28.772059 34819 sgd_solver.cpp:112] Iteration 18280, lr = 0.01
I0523 00:24:33.183219 34819 solver.cpp:239] Iteration 18290 (2.23518 iter/s, 4.47391s/10 iters), loss = 9.11031
I0523 00:24:33.183272 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11031 (* 1 = 9.11031 loss)
I0523 00:24:33.255923 34819 sgd_solver.cpp:112] Iteration 18290, lr = 0.01
I0523 00:24:38.704905 34819 solver.cpp:239] Iteration 18300 (1.81114 iter/s, 5.52139s/10 iters), loss = 9.09271
I0523 00:24:38.704962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09271 (* 1 = 9.09271 loss)
I0523 00:24:39.398696 34819 sgd_solver.cpp:112] Iteration 18300, lr = 0.01
I0523 00:24:44.257661 34819 solver.cpp:239] Iteration 18310 (1.801 iter/s, 5.55246s/10 iters), loss = 9.14231
I0523 00:24:44.257727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14231 (* 1 = 9.14231 loss)
I0523 00:24:45.061444 34819 sgd_solver.cpp:112] Iteration 18310, lr = 0.01
I0523 00:24:50.200104 34819 solver.cpp:239] Iteration 18320 (1.6829 iter/s, 5.94213s/10 iters), loss = 8.40016
I0523 00:24:50.200148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40016 (* 1 = 8.40016 loss)
I0523 00:24:51.018740 34819 sgd_solver.cpp:112] Iteration 18320, lr = 0.01
I0523 00:24:54.443228 34819 solver.cpp:239] Iteration 18330 (2.35688 iter/s, 4.2429s/10 iters), loss = 9.09298
I0523 00:24:54.443274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09298 (* 1 = 9.09298 loss)
I0523 00:24:54.528141 34819 sgd_solver.cpp:112] Iteration 18330, lr = 0.01
I0523 00:24:58.641561 34819 solver.cpp:239] Iteration 18340 (2.38203 iter/s, 4.1981s/10 iters), loss = 9.60507
I0523 00:24:58.641615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60507 (* 1 = 9.60507 loss)
I0523 00:24:59.478338 34819 sgd_solver.cpp:112] Iteration 18340, lr = 0.01
I0523 00:25:04.791177 34819 solver.cpp:239] Iteration 18350 (1.6262 iter/s, 6.14931s/10 iters), loss = 8.51436
I0523 00:25:04.791220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51436 (* 1 = 8.51436 loss)
I0523 00:25:05.660194 34819 sgd_solver.cpp:112] Iteration 18350, lr = 0.01
I0523 00:25:11.593454 34819 solver.cpp:239] Iteration 18360 (1.47017 iter/s, 6.80195s/10 iters), loss = 8.49286
I0523 00:25:11.593510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49286 (* 1 = 8.49286 loss)
I0523 00:25:11.662760 34819 sgd_solver.cpp:112] Iteration 18360, lr = 0.01
I0523 00:25:15.597645 34819 solver.cpp:239] Iteration 18370 (2.49752 iter/s, 4.00397s/10 iters), loss = 9.03607
I0523 00:25:15.597848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03607 (* 1 = 9.03607 loss)
I0523 00:25:15.662890 34819 sgd_solver.cpp:112] Iteration 18370, lr = 0.01
I0523 00:25:20.709444 34819 solver.cpp:239] Iteration 18380 (1.95641 iter/s, 5.11141s/10 iters), loss = 8.65327
I0523 00:25:20.709488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65327 (* 1 = 8.65327 loss)
I0523 00:25:20.776463 34819 sgd_solver.cpp:112] Iteration 18380, lr = 0.01
I0523 00:25:24.934341 34819 solver.cpp:239] Iteration 18390 (2.36952 iter/s, 4.22027s/10 iters), loss = 8.97537
I0523 00:25:24.934386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97537 (* 1 = 8.97537 loss)
I0523 00:25:25.822438 34819 sgd_solver.cpp:112] Iteration 18390, lr = 0.01
I0523 00:25:29.149323 34819 solver.cpp:239] Iteration 18400 (2.37263 iter/s, 4.21474s/10 iters), loss = 9.0519
I0523 00:25:29.149377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0519 (* 1 = 9.0519 loss)
I0523 00:25:29.213795 34819 sgd_solver.cpp:112] Iteration 18400, lr = 0.01
I0523 00:25:34.356053 34819 solver.cpp:239] Iteration 18410 (1.92069 iter/s, 5.20645s/10 iters), loss = 8.69665
I0523 00:25:34.356106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69665 (* 1 = 8.69665 loss)
I0523 00:25:35.152171 34819 sgd_solver.cpp:112] Iteration 18410, lr = 0.01
I0523 00:25:39.047422 34819 solver.cpp:239] Iteration 18420 (2.1317 iter/s, 4.6911s/10 iters), loss = 8.23408
I0523 00:25:39.047475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23408 (* 1 = 8.23408 loss)
I0523 00:25:39.094017 34819 sgd_solver.cpp:112] Iteration 18420, lr = 0.01
I0523 00:25:42.813874 34819 solver.cpp:239] Iteration 18430 (2.65517 iter/s, 3.76624s/10 iters), loss = 9.14732
I0523 00:25:42.813916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14732 (* 1 = 9.14732 loss)
I0523 00:25:42.997999 34819 sgd_solver.cpp:112] Iteration 18430, lr = 0.01
I0523 00:25:48.192988 34819 solver.cpp:239] Iteration 18440 (1.85914 iter/s, 5.37884s/10 iters), loss = 8.65156
I0523 00:25:48.193197 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65156 (* 1 = 8.65156 loss)
I0523 00:25:48.948307 34819 sgd_solver.cpp:112] Iteration 18440, lr = 0.01
I0523 00:25:53.988241 34819 solver.cpp:239] Iteration 18450 (1.72568 iter/s, 5.79483s/10 iters), loss = 8.82923
I0523 00:25:53.988291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82923 (* 1 = 8.82923 loss)
I0523 00:25:54.792485 34819 sgd_solver.cpp:112] Iteration 18450, lr = 0.01
I0523 00:25:59.084170 34819 solver.cpp:239] Iteration 18460 (1.96245 iter/s, 5.09567s/10 iters), loss = 8.97941
I0523 00:25:59.084215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97941 (* 1 = 8.97941 loss)
I0523 00:25:59.743908 34819 sgd_solver.cpp:112] Iteration 18460, lr = 0.01
I0523 00:26:04.443997 34819 solver.cpp:239] Iteration 18470 (1.86583 iter/s, 5.35956s/10 iters), loss = 8.11638
I0523 00:26:04.444044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11638 (* 1 = 8.11638 loss)
I0523 00:26:04.501873 34819 sgd_solver.cpp:112] Iteration 18470, lr = 0.01
I0523 00:26:08.592406 34819 solver.cpp:239] Iteration 18480 (2.41069 iter/s, 4.14818s/10 iters), loss = 8.99471
I0523 00:26:08.592466 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99471 (* 1 = 8.99471 loss)
I0523 00:26:08.661790 34819 sgd_solver.cpp:112] Iteration 18480, lr = 0.01
I0523 00:26:14.438848 34819 solver.cpp:239] Iteration 18490 (1.71053 iter/s, 5.84614s/10 iters), loss = 8.45042
I0523 00:26:14.438905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45042 (* 1 = 8.45042 loss)
I0523 00:26:14.507019 34819 sgd_solver.cpp:112] Iteration 18490, lr = 0.01
I0523 00:26:17.904559 34819 solver.cpp:239] Iteration 18500 (2.88558 iter/s, 3.46551s/10 iters), loss = 8.26942
I0523 00:26:17.904613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26942 (* 1 = 8.26942 loss)
I0523 00:26:17.979280 34819 sgd_solver.cpp:112] Iteration 18500, lr = 0.01
I0523 00:26:21.498914 34819 solver.cpp:239] Iteration 18510 (2.78231 iter/s, 3.59414s/10 iters), loss = 8.77704
I0523 00:26:21.499162 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77704 (* 1 = 8.77704 loss)
I0523 00:26:22.180387 34819 sgd_solver.cpp:112] Iteration 18510, lr = 0.01
I0523 00:26:27.111615 34819 solver.cpp:239] Iteration 18520 (1.78182 iter/s, 5.61224s/10 iters), loss = 7.40987
I0523 00:26:27.111668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40987 (* 1 = 7.40987 loss)
I0523 00:26:27.184840 34819 sgd_solver.cpp:112] Iteration 18520, lr = 0.01
I0523 00:26:33.226234 34819 solver.cpp:239] Iteration 18530 (1.63551 iter/s, 6.11431s/10 iters), loss = 9.06596
I0523 00:26:33.226284 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06596 (* 1 = 9.06596 loss)
I0523 00:26:33.921968 34819 sgd_solver.cpp:112] Iteration 18530, lr = 0.01
I0523 00:26:37.683866 34819 solver.cpp:239] Iteration 18540 (2.24346 iter/s, 4.4574s/10 iters), loss = 8.43346
I0523 00:26:37.683907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43346 (* 1 = 8.43346 loss)
I0523 00:26:38.459997 34819 sgd_solver.cpp:112] Iteration 18540, lr = 0.01
I0523 00:26:44.271996 34819 solver.cpp:239] Iteration 18550 (1.51795 iter/s, 6.58782s/10 iters), loss = 9.01463
I0523 00:26:44.272038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01463 (* 1 = 9.01463 loss)
I0523 00:26:44.349015 34819 sgd_solver.cpp:112] Iteration 18550, lr = 0.01
I0523 00:26:48.327188 34819 solver.cpp:239] Iteration 18560 (2.4661 iter/s, 4.05498s/10 iters), loss = 8.18172
I0523 00:26:48.327232 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18172 (* 1 = 8.18172 loss)
I0523 00:26:48.389863 34819 sgd_solver.cpp:112] Iteration 18560, lr = 0.01
I0523 00:26:52.568197 34819 solver.cpp:239] Iteration 18570 (2.35806 iter/s, 4.24078s/10 iters), loss = 8.69257
I0523 00:26:52.568434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69257 (* 1 = 8.69257 loss)
I0523 00:26:53.242417 34819 sgd_solver.cpp:112] Iteration 18570, lr = 0.01
I0523 00:26:57.452154 34819 solver.cpp:239] Iteration 18580 (2.04771 iter/s, 4.8835s/10 iters), loss = 8.8726
I0523 00:26:57.452208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8726 (* 1 = 8.8726 loss)
I0523 00:26:58.281774 34819 sgd_solver.cpp:112] Iteration 18580, lr = 0.01
I0523 00:27:03.960901 34819 solver.cpp:239] Iteration 18590 (1.53647 iter/s, 6.50843s/10 iters), loss = 8.06347
I0523 00:27:03.960959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06347 (* 1 = 8.06347 loss)
I0523 00:27:04.025310 34819 sgd_solver.cpp:112] Iteration 18590, lr = 0.01
I0523 00:27:09.357609 34819 solver.cpp:239] Iteration 18600 (1.85308 iter/s, 5.39642s/10 iters), loss = 8.57265
I0523 00:27:09.357666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57265 (* 1 = 8.57265 loss)
I0523 00:27:09.423923 34819 sgd_solver.cpp:112] Iteration 18600, lr = 0.01
I0523 00:27:13.493016 34819 solver.cpp:239] Iteration 18610 (2.41828 iter/s, 4.13517s/10 iters), loss = 8.53919
I0523 00:27:13.493078 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53919 (* 1 = 8.53919 loss)
I0523 00:27:13.556923 34819 sgd_solver.cpp:112] Iteration 18610, lr = 0.01
I0523 00:27:19.061188 34819 solver.cpp:239] Iteration 18620 (1.79601 iter/s, 5.56788s/10 iters), loss = 8.02375
I0523 00:27:19.061230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02375 (* 1 = 8.02375 loss)
I0523 00:27:19.135989 34819 sgd_solver.cpp:112] Iteration 18620, lr = 0.01
I0523 00:27:22.224190 34819 solver.cpp:239] Iteration 18630 (3.16174 iter/s, 3.16282s/10 iters), loss = 9.43323
I0523 00:27:22.224234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43323 (* 1 = 9.43323 loss)
I0523 00:27:22.304726 34819 sgd_solver.cpp:112] Iteration 18630, lr = 0.01
I0523 00:27:28.094657 34819 solver.cpp:239] Iteration 18640 (1.70353 iter/s, 5.87018s/10 iters), loss = 8.73381
I0523 00:27:28.094892 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73381 (* 1 = 8.73381 loss)
I0523 00:27:28.156095 34819 sgd_solver.cpp:112] Iteration 18640, lr = 0.01
I0523 00:27:32.170907 34819 solver.cpp:239] Iteration 18650 (2.45471 iter/s, 4.0738s/10 iters), loss = 9.68884
I0523 00:27:32.170954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68884 (* 1 = 9.68884 loss)
I0523 00:27:32.947427 34819 sgd_solver.cpp:112] Iteration 18650, lr = 0.01
I0523 00:27:37.139598 34819 solver.cpp:239] Iteration 18660 (2.0127 iter/s, 4.96844s/10 iters), loss = 8.22471
I0523 00:27:37.139642 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22471 (* 1 = 8.22471 loss)
I0523 00:27:37.914610 34819 sgd_solver.cpp:112] Iteration 18660, lr = 0.01
I0523 00:27:43.070587 34819 solver.cpp:239] Iteration 18670 (1.68614 iter/s, 5.9307s/10 iters), loss = 8.88441
I0523 00:27:43.070631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88441 (* 1 = 8.88441 loss)
I0523 00:27:43.141836 34819 sgd_solver.cpp:112] Iteration 18670, lr = 0.01
I0523 00:27:47.073369 34819 solver.cpp:239] Iteration 18680 (2.4984 iter/s, 4.00256s/10 iters), loss = 8.86169
I0523 00:27:47.073415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86169 (* 1 = 8.86169 loss)
I0523 00:27:47.141602 34819 sgd_solver.cpp:112] Iteration 18680, lr = 0.01
I0523 00:27:51.751320 34819 solver.cpp:239] Iteration 18690 (2.1378 iter/s, 4.6777s/10 iters), loss = 8.67839
I0523 00:27:51.751376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67839 (* 1 = 8.67839 loss)
I0523 00:27:51.823897 34819 sgd_solver.cpp:112] Iteration 18690, lr = 0.01
I0523 00:27:58.312413 34819 solver.cpp:239] Iteration 18700 (1.52478 iter/s, 6.5583s/10 iters), loss = 8.80661
I0523 00:27:58.312556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80661 (* 1 = 8.80661 loss)
I0523 00:27:58.360724 34819 sgd_solver.cpp:112] Iteration 18700, lr = 0.01
I0523 00:28:02.469708 34819 solver.cpp:239] Iteration 18710 (2.40559 iter/s, 4.15698s/10 iters), loss = 8.19267
I0523 00:28:02.469748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19267 (* 1 = 8.19267 loss)
I0523 00:28:02.543005 34819 sgd_solver.cpp:112] Iteration 18710, lr = 0.01
I0523 00:28:06.785712 34819 solver.cpp:239] Iteration 18720 (2.31709 iter/s, 4.31576s/10 iters), loss = 9.39071
I0523 00:28:06.785769 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39071 (* 1 = 9.39071 loss)
I0523 00:28:07.641402 34819 sgd_solver.cpp:112] Iteration 18720, lr = 0.01
I0523 00:28:12.296347 34819 solver.cpp:239] Iteration 18730 (1.81476 iter/s, 5.51036s/10 iters), loss = 8.60364
I0523 00:28:12.296391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60364 (* 1 = 8.60364 loss)
I0523 00:28:12.361141 34819 sgd_solver.cpp:112] Iteration 18730, lr = 0.01
I0523 00:28:18.300721 34819 solver.cpp:239] Iteration 18740 (1.66554 iter/s, 6.00407s/10 iters), loss = 8.69404
I0523 00:28:18.300776 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69404 (* 1 = 8.69404 loss)
I0523 00:28:19.096313 34819 sgd_solver.cpp:112] Iteration 18740, lr = 0.01
I0523 00:28:25.552881 34819 solver.cpp:239] Iteration 18750 (1.37897 iter/s, 7.25179s/10 iters), loss = 8.30611
I0523 00:28:25.552938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30611 (* 1 = 8.30611 loss)
I0523 00:28:26.412487 34819 sgd_solver.cpp:112] Iteration 18750, lr = 0.01
I0523 00:28:31.571581 34819 solver.cpp:239] Iteration 18760 (1.66158 iter/s, 6.01837s/10 iters), loss = 8.59548
I0523 00:28:31.571816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59548 (* 1 = 8.59548 loss)
I0523 00:28:31.644446 34819 sgd_solver.cpp:112] Iteration 18760, lr = 0.01
I0523 00:28:36.394359 34819 solver.cpp:239] Iteration 18770 (2.07368 iter/s, 4.82235s/10 iters), loss = 8.20034
I0523 00:28:36.394405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20034 (* 1 = 8.20034 loss)
I0523 00:28:36.452059 34819 sgd_solver.cpp:112] Iteration 18770, lr = 0.01
I0523 00:28:41.388367 34819 solver.cpp:239] Iteration 18780 (2.00252 iter/s, 4.99372s/10 iters), loss = 8.61177
I0523 00:28:41.388432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61177 (* 1 = 8.61177 loss)
I0523 00:28:42.250123 34819 sgd_solver.cpp:112] Iteration 18780, lr = 0.01
I0523 00:28:46.243114 34819 solver.cpp:239] Iteration 18790 (2.05996 iter/s, 4.85446s/10 iters), loss = 7.74419
I0523 00:28:46.243191 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74419 (* 1 = 7.74419 loss)
I0523 00:28:46.313872 34819 sgd_solver.cpp:112] Iteration 18790, lr = 0.01
I0523 00:28:50.221465 34819 solver.cpp:239] Iteration 18800 (2.51376 iter/s, 3.97811s/10 iters), loss = 8.62041
I0523 00:28:50.221513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62041 (* 1 = 8.62041 loss)
I0523 00:28:50.278323 34819 sgd_solver.cpp:112] Iteration 18800, lr = 0.01
I0523 00:28:56.677042 34819 solver.cpp:239] Iteration 18810 (1.54912 iter/s, 6.45527s/10 iters), loss = 9.00012
I0523 00:28:56.677093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00012 (* 1 = 9.00012 loss)
I0523 00:28:56.741549 34819 sgd_solver.cpp:112] Iteration 18810, lr = 0.01
I0523 00:29:02.025979 34819 solver.cpp:239] Iteration 18820 (1.86963 iter/s, 5.34866s/10 iters), loss = 8.92813
I0523 00:29:02.026161 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92813 (* 1 = 8.92813 loss)
I0523 00:29:02.100908 34819 sgd_solver.cpp:112] Iteration 18820, lr = 0.01
I0523 00:29:06.207124 34819 solver.cpp:239] Iteration 18830 (2.39188 iter/s, 4.18081s/10 iters), loss = 9.0148
I0523 00:29:06.207167 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0148 (* 1 = 9.0148 loss)
I0523 00:29:06.263882 34819 sgd_solver.cpp:112] Iteration 18830, lr = 0.01
I0523 00:29:09.921941 34819 solver.cpp:239] Iteration 18840 (2.69208 iter/s, 3.7146s/10 iters), loss = 8.19558
I0523 00:29:09.921998 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19558 (* 1 = 8.19558 loss)
I0523 00:29:10.698971 34819 sgd_solver.cpp:112] Iteration 18840, lr = 0.01
I0523 00:29:13.761495 34819 solver.cpp:239] Iteration 18850 (2.60462 iter/s, 3.83933s/10 iters), loss = 9.17334
I0523 00:29:13.761554 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17334 (* 1 = 9.17334 loss)
I0523 00:29:14.549515 34819 sgd_solver.cpp:112] Iteration 18850, lr = 0.01
I0523 00:29:19.691468 34819 solver.cpp:239] Iteration 18860 (1.68643 iter/s, 5.92967s/10 iters), loss = 9.09451
I0523 00:29:19.691525 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09451 (* 1 = 9.09451 loss)
I0523 00:29:20.507902 34819 sgd_solver.cpp:112] Iteration 18860, lr = 0.01
I0523 00:29:25.129705 34819 solver.cpp:239] Iteration 18870 (1.83893 iter/s, 5.43795s/10 iters), loss = 8.4636
I0523 00:29:25.129758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4636 (* 1 = 8.4636 loss)
I0523 00:29:26.012375 34819 sgd_solver.cpp:112] Iteration 18870, lr = 0.01
I0523 00:29:29.379442 34819 solver.cpp:239] Iteration 18880 (2.35321 iter/s, 4.24951s/10 iters), loss = 8.27954
I0523 00:29:29.379492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27954 (* 1 = 8.27954 loss)
I0523 00:29:29.441422 34819 sgd_solver.cpp:112] Iteration 18880, lr = 0.01
I0523 00:29:34.315259 34819 solver.cpp:239] Iteration 18890 (2.02613 iter/s, 4.93553s/10 iters), loss = 9.45383
I0523 00:29:34.315528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45383 (* 1 = 9.45383 loss)
I0523 00:29:34.386992 34819 sgd_solver.cpp:112] Iteration 18890, lr = 0.01
I0523 00:29:37.972122 34819 solver.cpp:239] Iteration 18900 (2.7349 iter/s, 3.65645s/10 iters), loss = 9.21603
I0523 00:29:37.972179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21603 (* 1 = 9.21603 loss)
I0523 00:29:38.748761 34819 sgd_solver.cpp:112] Iteration 18900, lr = 0.01
I0523 00:29:43.710865 34819 solver.cpp:239] Iteration 18910 (1.74263 iter/s, 5.73845s/10 iters), loss = 9.09119
I0523 00:29:43.710912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09119 (* 1 = 9.09119 loss)
I0523 00:29:44.387576 34819 sgd_solver.cpp:112] Iteration 18910, lr = 0.01
I0523 00:29:48.879396 34819 solver.cpp:239] Iteration 18920 (1.93489 iter/s, 5.16825s/10 iters), loss = 8.47186
I0523 00:29:48.879451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47186 (* 1 = 8.47186 loss)
I0523 00:29:49.648363 34819 sgd_solver.cpp:112] Iteration 18920, lr = 0.01
I0523 00:29:53.430578 34819 solver.cpp:239] Iteration 18930 (2.19735 iter/s, 4.55094s/10 iters), loss = 9.05567
I0523 00:29:53.430635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05567 (* 1 = 9.05567 loss)
I0523 00:29:53.505359 34819 sgd_solver.cpp:112] Iteration 18930, lr = 0.01
I0523 00:29:59.885807 34819 solver.cpp:239] Iteration 18940 (1.54921 iter/s, 6.4549s/10 iters), loss = 9.25659
I0523 00:29:59.885862 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25659 (* 1 = 9.25659 loss)
I0523 00:29:59.946372 34819 sgd_solver.cpp:112] Iteration 18940, lr = 0.01
I0523 00:30:04.890838 34819 solver.cpp:239] Iteration 18950 (1.9981 iter/s, 5.00477s/10 iters), loss = 8.06006
I0523 00:30:04.891053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06006 (* 1 = 8.06006 loss)
I0523 00:30:05.750711 34819 sgd_solver.cpp:112] Iteration 18950, lr = 0.01
I0523 00:30:10.408898 34819 solver.cpp:239] Iteration 18960 (1.81237 iter/s, 5.51765s/10 iters), loss = 7.93433
I0523 00:30:10.408942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93433 (* 1 = 7.93433 loss)
I0523 00:30:10.455581 34819 sgd_solver.cpp:112] Iteration 18960, lr = 0.01
I0523 00:30:11.757258 34819 solver.cpp:239] Iteration 18970 (7.41712 iter/s, 1.34823s/10 iters), loss = 7.5538
I0523 00:30:11.757316 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5538 (* 1 = 7.5538 loss)
I0523 00:30:11.830289 34819 sgd_solver.cpp:112] Iteration 18970, lr = 0.01
I0523 00:30:15.768224 34819 solver.cpp:239] Iteration 18980 (2.49331 iter/s, 4.01073s/10 iters), loss = 9.07698
I0523 00:30:15.768268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07698 (* 1 = 9.07698 loss)
I0523 00:30:16.591158 34819 sgd_solver.cpp:112] Iteration 18980, lr = 0.01
I0523 00:30:22.779880 34819 solver.cpp:239] Iteration 18990 (1.42626 iter/s, 7.01133s/10 iters), loss = 8.88787
I0523 00:30:22.779923 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88787 (* 1 = 8.88787 loss)
I0523 00:30:23.482628 34819 sgd_solver.cpp:112] Iteration 18990, lr = 0.01
I0523 00:30:28.129935 34819 solver.cpp:239] Iteration 19000 (1.86924 iter/s, 5.34978s/10 iters), loss = 8.91742
I0523 00:30:28.129989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91742 (* 1 = 8.91742 loss)
I0523 00:30:28.199662 34819 sgd_solver.cpp:112] Iteration 19000, lr = 0.01
I0523 00:30:33.239737 34819 solver.cpp:239] Iteration 19010 (1.95713 iter/s, 5.10953s/10 iters), loss = 9.19355
I0523 00:30:33.239779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19355 (* 1 = 9.19355 loss)
I0523 00:30:33.308239 34819 sgd_solver.cpp:112] Iteration 19010, lr = 0.01
I0523 00:30:39.081660 34819 solver.cpp:239] Iteration 19020 (1.71185 iter/s, 5.84163s/10 iters), loss = 8.23742
I0523 00:30:39.081837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23742 (* 1 = 8.23742 loss)
I0523 00:30:39.148602 34819 sgd_solver.cpp:112] Iteration 19020, lr = 0.01
I0523 00:30:44.767990 34819 solver.cpp:239] Iteration 19030 (1.75873 iter/s, 5.68593s/10 iters), loss = 8.45028
I0523 00:30:44.768033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45028 (* 1 = 8.45028 loss)
I0523 00:30:45.401037 34819 sgd_solver.cpp:112] Iteration 19030, lr = 0.01
I0523 00:30:51.054989 34819 solver.cpp:239] Iteration 19040 (1.59066 iter/s, 6.2867s/10 iters), loss = 8.98504
I0523 00:30:51.055033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98504 (* 1 = 8.98504 loss)
I0523 00:30:51.117002 34819 sgd_solver.cpp:112] Iteration 19040, lr = 0.01
I0523 00:30:55.798907 34819 solver.cpp:239] Iteration 19050 (2.10807 iter/s, 4.74367s/10 iters), loss = 8.89889
I0523 00:30:55.798950 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89889 (* 1 = 8.89889 loss)
I0523 00:30:56.539815 34819 sgd_solver.cpp:112] Iteration 19050, lr = 0.01
I0523 00:31:02.170898 34819 solver.cpp:239] Iteration 19060 (1.56944 iter/s, 6.37169s/10 iters), loss = 8.71664
I0523 00:31:02.170943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71664 (* 1 = 8.71664 loss)
I0523 00:31:02.973611 34819 sgd_solver.cpp:112] Iteration 19060, lr = 0.01
I0523 00:31:06.150869 34819 solver.cpp:239] Iteration 19070 (2.51272 iter/s, 3.97976s/10 iters), loss = 8.62577
I0523 00:31:06.150913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62577 (* 1 = 8.62577 loss)
I0523 00:31:06.211153 34819 sgd_solver.cpp:112] Iteration 19070, lr = 0.01
I0523 00:31:08.776329 34819 solver.cpp:239] Iteration 19080 (3.80909 iter/s, 2.6253s/10 iters), loss = 8.70987
I0523 00:31:08.776374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70987 (* 1 = 8.70987 loss)
I0523 00:31:08.846570 34819 sgd_solver.cpp:112] Iteration 19080, lr = 0.01
I0523 00:31:13.047267 34819 solver.cpp:239] Iteration 19090 (2.34153 iter/s, 4.27071s/10 iters), loss = 8.65921
I0523 00:31:13.047422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65921 (* 1 = 8.65921 loss)
I0523 00:31:13.121978 34819 sgd_solver.cpp:112] Iteration 19090, lr = 0.01
I0523 00:31:18.047940 34819 solver.cpp:239] Iteration 19100 (1.99988 iter/s, 5.00031s/10 iters), loss = 8.60965
I0523 00:31:18.047983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60965 (* 1 = 8.60965 loss)
I0523 00:31:18.823487 34819 sgd_solver.cpp:112] Iteration 19100, lr = 0.01
I0523 00:31:23.144289 34819 solver.cpp:239] Iteration 19110 (1.96229 iter/s, 5.09609s/10 iters), loss = 9.24736
I0523 00:31:23.144345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24736 (* 1 = 9.24736 loss)
I0523 00:31:23.217928 34819 sgd_solver.cpp:112] Iteration 19110, lr = 0.01
I0523 00:31:27.198491 34819 solver.cpp:239] Iteration 19120 (2.46673 iter/s, 4.05396s/10 iters), loss = 8.89456
I0523 00:31:27.198549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89456 (* 1 = 8.89456 loss)
I0523 00:31:28.049929 34819 sgd_solver.cpp:112] Iteration 19120, lr = 0.01
I0523 00:31:31.806111 34819 solver.cpp:239] Iteration 19130 (2.17044 iter/s, 4.60736s/10 iters), loss = 8.3609
I0523 00:31:31.806175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3609 (* 1 = 8.3609 loss)
I0523 00:31:31.868072 34819 sgd_solver.cpp:112] Iteration 19130, lr = 0.01
I0523 00:31:35.919268 34819 solver.cpp:239] Iteration 19140 (2.43136 iter/s, 4.11292s/10 iters), loss = 9.48702
I0523 00:31:35.919327 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48702 (* 1 = 9.48702 loss)
I0523 00:31:35.997742 34819 sgd_solver.cpp:112] Iteration 19140, lr = 0.01
I0523 00:31:41.105393 34819 solver.cpp:239] Iteration 19150 (1.92833 iter/s, 5.18585s/10 iters), loss = 9.00566
I0523 00:31:41.105463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00566 (* 1 = 9.00566 loss)
I0523 00:31:41.926543 34819 sgd_solver.cpp:112] Iteration 19150, lr = 0.01
I0523 00:31:43.721922 34819 solver.cpp:239] Iteration 19160 (3.82214 iter/s, 2.61633s/10 iters), loss = 8.1909
I0523 00:31:43.722120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1909 (* 1 = 8.1909 loss)
I0523 00:31:43.809026 34819 sgd_solver.cpp:112] Iteration 19160, lr = 0.01
I0523 00:31:46.908655 34819 solver.cpp:239] Iteration 19170 (3.13834 iter/s, 3.1864s/10 iters), loss = 9.07039
I0523 00:31:46.908709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07039 (* 1 = 9.07039 loss)
I0523 00:31:47.752406 34819 sgd_solver.cpp:112] Iteration 19170, lr = 0.01
I0523 00:31:52.759801 34819 solver.cpp:239] Iteration 19180 (1.70915 iter/s, 5.85086s/10 iters), loss = 8.86351
I0523 00:31:52.759846 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86351 (* 1 = 8.86351 loss)
I0523 00:31:53.599792 34819 sgd_solver.cpp:112] Iteration 19180, lr = 0.01
I0523 00:32:00.592326 34819 solver.cpp:239] Iteration 19190 (1.27679 iter/s, 7.83216s/10 iters), loss = 9.17449
I0523 00:32:00.592370 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17449 (* 1 = 9.17449 loss)
I0523 00:32:00.651757 34819 sgd_solver.cpp:112] Iteration 19190, lr = 0.01
I0523 00:32:04.723011 34819 solver.cpp:239] Iteration 19200 (2.42104 iter/s, 4.13046s/10 iters), loss = 8.36791
I0523 00:32:04.723071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36791 (* 1 = 8.36791 loss)
I0523 00:32:05.569505 34819 sgd_solver.cpp:112] Iteration 19200, lr = 0.01
I0523 00:32:11.313617 34819 solver.cpp:239] Iteration 19210 (1.51739 iter/s, 6.59028s/10 iters), loss = 8.506
I0523 00:32:11.313664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.506 (* 1 = 8.506 loss)
I0523 00:32:11.381124 34819 sgd_solver.cpp:112] Iteration 19210, lr = 0.01
I0523 00:32:16.147562 34819 solver.cpp:239] Iteration 19220 (2.06882 iter/s, 4.83368s/10 iters), loss = 9.26252
I0523 00:32:16.147827 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26252 (* 1 = 9.26252 loss)
I0523 00:32:16.344691 34819 sgd_solver.cpp:112] Iteration 19220, lr = 0.01
I0523 00:32:23.069480 34819 solver.cpp:239] Iteration 19230 (1.44479 iter/s, 6.9214s/10 iters), loss = 8.11356
I0523 00:32:23.069531 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11356 (* 1 = 8.11356 loss)
I0523 00:32:23.137759 34819 sgd_solver.cpp:112] Iteration 19230, lr = 0.01
I0523 00:32:27.577353 34819 solver.cpp:239] Iteration 19240 (2.21846 iter/s, 4.50763s/10 iters), loss = 9.12725
I0523 00:32:27.577406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12725 (* 1 = 9.12725 loss)
I0523 00:32:28.440433 34819 sgd_solver.cpp:112] Iteration 19240, lr = 0.01
I0523 00:32:33.220146 34819 solver.cpp:239] Iteration 19250 (1.77227 iter/s, 5.6425s/10 iters), loss = 8.71371
I0523 00:32:33.220208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71371 (* 1 = 8.71371 loss)
I0523 00:32:33.289063 34819 sgd_solver.cpp:112] Iteration 19250, lr = 0.01
I0523 00:32:38.721909 34819 solver.cpp:239] Iteration 19260 (1.81769 iter/s, 5.50147s/10 iters), loss = 8.64754
I0523 00:32:38.721956 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64754 (* 1 = 8.64754 loss)
I0523 00:32:38.783459 34819 sgd_solver.cpp:112] Iteration 19260, lr = 0.01
I0523 00:32:44.469946 34819 solver.cpp:239] Iteration 19270 (1.73981 iter/s, 5.74774s/10 iters), loss = 9.03701
I0523 00:32:44.469990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03701 (* 1 = 9.03701 loss)
I0523 00:32:45.246569 34819 sgd_solver.cpp:112] Iteration 19270, lr = 0.01
I0523 00:32:51.720862 34819 solver.cpp:239] Iteration 19280 (1.3792 iter/s, 7.25055s/10 iters), loss = 8.73859
I0523 00:32:51.721060 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73859 (* 1 = 8.73859 loss)
I0523 00:32:52.568334 34819 sgd_solver.cpp:112] Iteration 19280, lr = 0.01
I0523 00:32:57.176939 34819 solver.cpp:239] Iteration 19290 (1.83296 iter/s, 5.45566s/10 iters), loss = 8.5319
I0523 00:32:57.176995 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5319 (* 1 = 8.5319 loss)
I0523 00:32:57.246542 34819 sgd_solver.cpp:112] Iteration 19290, lr = 0.01
I0523 00:33:01.536264 34819 solver.cpp:239] Iteration 19300 (2.29406 iter/s, 4.35909s/10 iters), loss = 8.85711
I0523 00:33:01.536309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85711 (* 1 = 8.85711 loss)
I0523 00:33:01.610882 34819 sgd_solver.cpp:112] Iteration 19300, lr = 0.01
I0523 00:33:05.859657 34819 solver.cpp:239] Iteration 19310 (2.31312 iter/s, 4.32316s/10 iters), loss = 7.87688
I0523 00:33:05.859709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87688 (* 1 = 7.87688 loss)
I0523 00:33:06.713711 34819 sgd_solver.cpp:112] Iteration 19310, lr = 0.01
I0523 00:33:10.306236 34819 solver.cpp:239] Iteration 19320 (2.24904 iter/s, 4.44634s/10 iters), loss = 8.79019
I0523 00:33:10.306293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79019 (* 1 = 8.79019 loss)
I0523 00:33:10.374027 34819 sgd_solver.cpp:112] Iteration 19320, lr = 0.01
I0523 00:33:16.720928 34819 solver.cpp:239] Iteration 19330 (1.559 iter/s, 6.41437s/10 iters), loss = 9.18461
I0523 00:33:16.720971 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18461 (* 1 = 9.18461 loss)
I0523 00:33:16.783365 34819 sgd_solver.cpp:112] Iteration 19330, lr = 0.01
I0523 00:33:19.656421 34819 solver.cpp:239] Iteration 19340 (3.40678 iter/s, 2.93532s/10 iters), loss = 9.12767
I0523 00:33:19.656468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12767 (* 1 = 9.12767 loss)
I0523 00:33:19.729065 34819 sgd_solver.cpp:112] Iteration 19340, lr = 0.01
I0523 00:33:23.642056 34819 solver.cpp:239] Iteration 19350 (2.50915 iter/s, 3.98541s/10 iters), loss = 9.84359
I0523 00:33:23.642210 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84359 (* 1 = 9.84359 loss)
I0523 00:33:23.724913 34819 sgd_solver.cpp:112] Iteration 19350, lr = 0.01
I0523 00:33:30.615921 34819 solver.cpp:239] Iteration 19360 (1.43402 iter/s, 6.97341s/10 iters), loss = 9.28062
I0523 00:33:30.615974 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28062 (* 1 = 9.28062 loss)
I0523 00:33:30.687958 34819 sgd_solver.cpp:112] Iteration 19360, lr = 0.01
I0523 00:33:34.839819 34819 solver.cpp:239] Iteration 19370 (2.36761 iter/s, 4.22367s/10 iters), loss = 9.39237
I0523 00:33:34.839870 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39237 (* 1 = 9.39237 loss)
I0523 00:33:35.609241 34819 sgd_solver.cpp:112] Iteration 19370, lr = 0.01
I0523 00:33:39.481006 34819 solver.cpp:239] Iteration 19380 (2.15473 iter/s, 4.64095s/10 iters), loss = 9.35454
I0523 00:33:39.481050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35454 (* 1 = 9.35454 loss)
I0523 00:33:40.323168 34819 sgd_solver.cpp:112] Iteration 19380, lr = 0.01
I0523 00:33:43.561260 34819 solver.cpp:239] Iteration 19390 (2.45096 iter/s, 4.08004s/10 iters), loss = 7.87186
I0523 00:33:43.561300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87186 (* 1 = 7.87186 loss)
I0523 00:33:44.414572 34819 sgd_solver.cpp:112] Iteration 19390, lr = 0.01
I0523 00:33:48.422505 34819 solver.cpp:239] Iteration 19400 (2.05719 iter/s, 4.861s/10 iters), loss = 9.09872
I0523 00:33:48.422556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09872 (* 1 = 9.09872 loss)
I0523 00:33:48.509376 34819 sgd_solver.cpp:112] Iteration 19400, lr = 0.01
I0523 00:33:52.677026 34819 solver.cpp:239] Iteration 19410 (2.35057 iter/s, 4.2543s/10 iters), loss = 8.75837
I0523 00:33:52.677070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75837 (* 1 = 8.75837 loss)
I0523 00:33:52.734365 34819 sgd_solver.cpp:112] Iteration 19410, lr = 0.01
I0523 00:33:56.173961 34819 solver.cpp:239] Iteration 19420 (2.85981 iter/s, 3.49673s/10 iters), loss = 9.11259
I0523 00:33:56.174096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11259 (* 1 = 9.11259 loss)
I0523 00:33:56.249505 34819 sgd_solver.cpp:112] Iteration 19420, lr = 0.01
I0523 00:34:00.455925 34819 solver.cpp:239] Iteration 19430 (2.33555 iter/s, 4.28165s/10 iters), loss = 8.79374
I0523 00:34:00.455968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79374 (* 1 = 8.79374 loss)
I0523 00:34:00.542292 34819 sgd_solver.cpp:112] Iteration 19430, lr = 0.01
I0523 00:34:05.230482 34819 solver.cpp:239] Iteration 19440 (2.09454 iter/s, 4.77432s/10 iters), loss = 8.61454
I0523 00:34:05.230526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61454 (* 1 = 8.61454 loss)
I0523 00:34:06.032261 34819 sgd_solver.cpp:112] Iteration 19440, lr = 0.01
I0523 00:34:10.751557 34819 solver.cpp:239] Iteration 19450 (1.81133 iter/s, 5.52081s/10 iters), loss = 8.45468
I0523 00:34:10.751603 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45468 (* 1 = 8.45468 loss)
I0523 00:34:10.831559 34819 sgd_solver.cpp:112] Iteration 19450, lr = 0.01
I0523 00:34:14.906344 34819 solver.cpp:239] Iteration 19460 (2.40699 iter/s, 4.15456s/10 iters), loss = 9.51732
I0523 00:34:14.906390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51732 (* 1 = 9.51732 loss)
I0523 00:34:14.994323 34819 sgd_solver.cpp:112] Iteration 19460, lr = 0.01
I0523 00:34:20.443277 34819 solver.cpp:239] Iteration 19470 (1.80615 iter/s, 5.53664s/10 iters), loss = 9.31226
I0523 00:34:20.443330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31226 (* 1 = 9.31226 loss)
I0523 00:34:20.512348 34819 sgd_solver.cpp:112] Iteration 19470, lr = 0.01
I0523 00:34:24.708201 34819 solver.cpp:239] Iteration 19480 (2.34485 iter/s, 4.26467s/10 iters), loss = 8.82985
I0523 00:34:24.708266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82985 (* 1 = 8.82985 loss)
I0523 00:34:25.525581 34819 sgd_solver.cpp:112] Iteration 19480, lr = 0.01
I0523 00:34:29.927763 34819 solver.cpp:239] Iteration 19490 (1.91597 iter/s, 5.21928s/10 iters), loss = 8.39646
I0523 00:34:29.927924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39646 (* 1 = 8.39646 loss)
I0523 00:34:30.314733 34819 sgd_solver.cpp:112] Iteration 19490, lr = 0.01
I0523 00:34:33.628021 34819 solver.cpp:239] Iteration 19500 (2.70276 iter/s, 3.69992s/10 iters), loss = 8.97204
I0523 00:34:33.628077 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97204 (* 1 = 8.97204 loss)
I0523 00:34:34.146082 34819 sgd_solver.cpp:112] Iteration 19500, lr = 0.01
I0523 00:34:37.603200 34819 solver.cpp:239] Iteration 19510 (2.51575 iter/s, 3.97495s/10 iters), loss = 8.64246
I0523 00:34:37.603253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64246 (* 1 = 8.64246 loss)
I0523 00:34:37.677238 34819 sgd_solver.cpp:112] Iteration 19510, lr = 0.01
I0523 00:34:41.156611 34819 solver.cpp:239] Iteration 19520 (2.81437 iter/s, 3.55319s/10 iters), loss = 8.54773
I0523 00:34:41.156666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54773 (* 1 = 8.54773 loss)
I0523 00:34:41.848804 34819 sgd_solver.cpp:112] Iteration 19520, lr = 0.01
I0523 00:34:48.469514 34819 solver.cpp:239] Iteration 19530 (1.36751 iter/s, 7.31255s/10 iters), loss = 8.61194
I0523 00:34:48.469571 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61194 (* 1 = 8.61194 loss)
I0523 00:34:48.540374 34819 sgd_solver.cpp:112] Iteration 19530, lr = 0.01
I0523 00:34:52.913978 34819 solver.cpp:239] Iteration 19540 (2.25012 iter/s, 4.44421s/10 iters), loss = 8.42239
I0523 00:34:52.914041 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42239 (* 1 = 8.42239 loss)
I0523 00:34:53.619243 34819 sgd_solver.cpp:112] Iteration 19540, lr = 0.01
I0523 00:35:00.237488 34819 solver.cpp:239] Iteration 19550 (1.36554 iter/s, 7.32314s/10 iters), loss = 8.8238
I0523 00:35:00.237766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8238 (* 1 = 8.8238 loss)
I0523 00:35:00.297415 34819 sgd_solver.cpp:112] Iteration 19550, lr = 0.01
I0523 00:35:05.213783 34819 solver.cpp:239] Iteration 19560 (2.00971 iter/s, 4.97584s/10 iters), loss = 8.82045
I0523 00:35:05.213829 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82045 (* 1 = 8.82045 loss)
I0523 00:35:05.616252 34819 sgd_solver.cpp:112] Iteration 19560, lr = 0.01
I0523 00:35:11.835357 34819 solver.cpp:239] Iteration 19570 (1.51029 iter/s, 6.62124s/10 iters), loss = 8.22975
I0523 00:35:11.835419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22975 (* 1 = 8.22975 loss)
I0523 00:35:12.474982 34819 sgd_solver.cpp:112] Iteration 19570, lr = 0.01
I0523 00:35:18.926581 34819 solver.cpp:239] Iteration 19580 (1.41026 iter/s, 7.09087s/10 iters), loss = 8.4582
I0523 00:35:18.926627 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4582 (* 1 = 8.4582 loss)
I0523 00:35:18.988900 34819 sgd_solver.cpp:112] Iteration 19580, lr = 0.01
I0523 00:35:25.596484 34819 solver.cpp:239] Iteration 19590 (1.49935 iter/s, 6.66957s/10 iters), loss = 9.16355
I0523 00:35:25.596535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16355 (* 1 = 9.16355 loss)
I0523 00:35:25.665273 34819 sgd_solver.cpp:112] Iteration 19590, lr = 0.01
I0523 00:35:29.882575 34819 solver.cpp:239] Iteration 19600 (2.33326 iter/s, 4.28586s/10 iters), loss = 8.10895
I0523 00:35:29.882633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10895 (* 1 = 8.10895 loss)
I0523 00:35:29.951164 34819 sgd_solver.cpp:112] Iteration 19600, lr = 0.01
I0523 00:35:35.073850 34819 solver.cpp:239] Iteration 19610 (1.92641 iter/s, 5.19099s/10 iters), loss = 8.61208
I0523 00:35:35.074071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61208 (* 1 = 8.61208 loss)
I0523 00:35:35.882071 34819 sgd_solver.cpp:112] Iteration 19610, lr = 0.01
I0523 00:35:39.559500 34819 solver.cpp:239] Iteration 19620 (2.22953 iter/s, 4.48525s/10 iters), loss = 9.07556
I0523 00:35:39.559545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07556 (* 1 = 9.07556 loss)
I0523 00:35:39.627950 34819 sgd_solver.cpp:112] Iteration 19620, lr = 0.01
I0523 00:35:44.651651 34819 solver.cpp:239] Iteration 19630 (1.96391 iter/s, 5.09189s/10 iters), loss = 8.06771
I0523 00:35:44.651700 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06771 (* 1 = 8.06771 loss)
I0523 00:35:44.720484 34819 sgd_solver.cpp:112] Iteration 19630, lr = 0.01
I0523 00:35:49.613169 34819 solver.cpp:239] Iteration 19640 (2.01562 iter/s, 4.96125s/10 iters), loss = 8.56366
I0523 00:35:49.613229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56366 (* 1 = 8.56366 loss)
I0523 00:35:50.380594 34819 sgd_solver.cpp:112] Iteration 19640, lr = 0.01
I0523 00:35:55.470264 34819 solver.cpp:239] Iteration 19650 (1.70742 iter/s, 5.85679s/10 iters), loss = 8.67601
I0523 00:35:55.470310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67601 (* 1 = 8.67601 loss)
I0523 00:35:55.531322 34819 sgd_solver.cpp:112] Iteration 19650, lr = 0.01
I0523 00:36:00.397384 34819 solver.cpp:239] Iteration 19660 (2.02969 iter/s, 4.92685s/10 iters), loss = 8.59171
I0523 00:36:00.397452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59171 (* 1 = 8.59171 loss)
I0523 00:36:01.255915 34819 sgd_solver.cpp:112] Iteration 19660, lr = 0.01
I0523 00:36:05.401224 34819 solver.cpp:239] Iteration 19670 (1.99858 iter/s, 5.00356s/10 iters), loss = 9.28837
I0523 00:36:05.401438 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28837 (* 1 = 9.28837 loss)
I0523 00:36:05.462608 34819 sgd_solver.cpp:112] Iteration 19670, lr = 0.01
I0523 00:36:11.320869 34819 solver.cpp:239] Iteration 19680 (1.68942 iter/s, 5.91921s/10 iters), loss = 8.94475
I0523 00:36:11.320927 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94475 (* 1 = 8.94475 loss)
I0523 00:36:12.149535 34819 sgd_solver.cpp:112] Iteration 19680, lr = 0.01
I0523 00:36:16.031981 34819 solver.cpp:239] Iteration 19690 (2.12275 iter/s, 4.71086s/10 iters), loss = 8.69624
I0523 00:36:16.032030 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69624 (* 1 = 8.69624 loss)
I0523 00:36:16.102315 34819 sgd_solver.cpp:112] Iteration 19690, lr = 0.01
I0523 00:36:21.152375 34819 solver.cpp:239] Iteration 19700 (1.95308 iter/s, 5.12012s/10 iters), loss = 8.83276
I0523 00:36:21.152433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83276 (* 1 = 8.83276 loss)
I0523 00:36:21.981139 34819 sgd_solver.cpp:112] Iteration 19700, lr = 0.01
I0523 00:36:26.533747 34819 solver.cpp:239] Iteration 19710 (1.85836 iter/s, 5.38109s/10 iters), loss = 8.41788
I0523 00:36:26.533795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41788 (* 1 = 8.41788 loss)
I0523 00:36:27.274348 34819 sgd_solver.cpp:112] Iteration 19710, lr = 0.01
I0523 00:36:31.500115 34819 solver.cpp:239] Iteration 19720 (2.01367 iter/s, 4.96606s/10 iters), loss = 8.14721
I0523 00:36:31.500174 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14721 (* 1 = 8.14721 loss)
I0523 00:36:32.237242 34819 sgd_solver.cpp:112] Iteration 19720, lr = 0.01
I0523 00:36:36.055666 34819 solver.cpp:239] Iteration 19730 (2.19524 iter/s, 4.5553s/10 iters), loss = 9.24207
I0523 00:36:36.055853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24207 (* 1 = 9.24207 loss)
I0523 00:36:36.112087 34819 sgd_solver.cpp:112] Iteration 19730, lr = 0.01
I0523 00:36:41.572971 34819 solver.cpp:239] Iteration 19740 (1.81262 iter/s, 5.51688s/10 iters), loss = 8.7979
I0523 00:36:41.573024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7979 (* 1 = 8.7979 loss)
I0523 00:36:41.627255 34819 sgd_solver.cpp:112] Iteration 19740, lr = 0.01
I0523 00:36:46.581362 34819 solver.cpp:239] Iteration 19750 (1.99676 iter/s, 5.00811s/10 iters), loss = 8.51865
I0523 00:36:46.581414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51865 (* 1 = 8.51865 loss)
I0523 00:36:46.812389 34819 sgd_solver.cpp:112] Iteration 19750, lr = 0.01
I0523 00:36:51.613106 34819 solver.cpp:239] Iteration 19760 (1.98749 iter/s, 5.03147s/10 iters), loss = 9.24843
I0523 00:36:51.613160 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24843 (* 1 = 9.24843 loss)
I0523 00:36:51.682477 34819 sgd_solver.cpp:112] Iteration 19760, lr = 0.01
I0523 00:36:55.866366 34819 solver.cpp:239] Iteration 19770 (2.35126 iter/s, 4.25303s/10 iters), loss = 8.71449
I0523 00:36:55.866413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71449 (* 1 = 8.71449 loss)
I0523 00:36:55.930740 34819 sgd_solver.cpp:112] Iteration 19770, lr = 0.01
I0523 00:37:01.738811 34819 solver.cpp:239] Iteration 19780 (1.70295 iter/s, 5.87215s/10 iters), loss = 7.8018
I0523 00:37:01.738867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8018 (* 1 = 7.8018 loss)
I0523 00:37:02.483052 34819 sgd_solver.cpp:112] Iteration 19780, lr = 0.01
I0523 00:37:06.821841 34819 solver.cpp:239] Iteration 19790 (1.96745 iter/s, 5.08273s/10 iters), loss = 8.36931
I0523 00:37:06.822100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36931 (* 1 = 8.36931 loss)
I0523 00:37:07.050246 34819 sgd_solver.cpp:112] Iteration 19790, lr = 0.01
I0523 00:37:12.690731 34819 solver.cpp:239] Iteration 19800 (1.70405 iter/s, 5.86838s/10 iters), loss = 8.31119
I0523 00:37:12.690785 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31119 (* 1 = 8.31119 loss)
I0523 00:37:12.874867 34819 sgd_solver.cpp:112] Iteration 19800, lr = 0.01
I0523 00:37:19.354046 34819 solver.cpp:239] Iteration 19810 (1.50083 iter/s, 6.66299s/10 iters), loss = 8.77171
I0523 00:37:19.354090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77171 (* 1 = 8.77171 loss)
I0523 00:37:19.408327 34819 sgd_solver.cpp:112] Iteration 19810, lr = 0.01
I0523 00:37:23.721431 34819 solver.cpp:239] Iteration 19820 (2.28983 iter/s, 4.36714s/10 iters), loss = 9.04672
I0523 00:37:23.721482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04672 (* 1 = 9.04672 loss)
I0523 00:37:24.580947 34819 sgd_solver.cpp:112] Iteration 19820, lr = 0.01
I0523 00:37:30.097438 34819 solver.cpp:239] Iteration 19830 (1.56846 iter/s, 6.3757s/10 iters), loss = 8.83923
I0523 00:37:30.097482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83923 (* 1 = 8.83923 loss)
I0523 00:37:30.176353 34819 sgd_solver.cpp:112] Iteration 19830, lr = 0.01
I0523 00:37:36.220600 34819 solver.cpp:239] Iteration 19840 (1.63322 iter/s, 6.12287s/10 iters), loss = 8.65544
I0523 00:37:36.220644 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65544 (* 1 = 8.65544 loss)
I0523 00:37:37.052718 34819 sgd_solver.cpp:112] Iteration 19840, lr = 0.01
I0523 00:37:40.662789 34819 solver.cpp:239] Iteration 19850 (2.25127 iter/s, 4.44195s/10 iters), loss = 7.91433
I0523 00:37:40.662847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91433 (* 1 = 7.91433 loss)
I0523 00:37:41.517387 34819 sgd_solver.cpp:112] Iteration 19850, lr = 0.01
I0523 00:37:46.774502 34819 solver.cpp:239] Iteration 19860 (1.63628 iter/s, 6.11141s/10 iters), loss = 8.71971
I0523 00:37:46.774549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71971 (* 1 = 8.71971 loss)
I0523 00:37:46.843724 34819 sgd_solver.cpp:112] Iteration 19860, lr = 0.01
I0523 00:37:51.840602 34819 solver.cpp:239] Iteration 19870 (1.97574 iter/s, 5.06138s/10 iters), loss = 9.10502
I0523 00:37:51.840658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10502 (* 1 = 9.10502 loss)
I0523 00:37:52.201871 34819 sgd_solver.cpp:112] Iteration 19870, lr = 0.01
I0523 00:37:58.565479 34819 solver.cpp:239] Iteration 19880 (1.48709 iter/s, 6.72455s/10 iters), loss = 9.25512
I0523 00:37:58.565526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25512 (* 1 = 9.25512 loss)
I0523 00:37:58.822211 34819 sgd_solver.cpp:112] Iteration 19880, lr = 0.01
I0523 00:38:04.834640 34819 solver.cpp:239] Iteration 19890 (1.59519 iter/s, 6.26884s/10 iters), loss = 7.92117
I0523 00:38:04.834725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92117 (* 1 = 7.92117 loss)
I0523 00:38:05.643034 34819 sgd_solver.cpp:112] Iteration 19890, lr = 0.01
I0523 00:38:08.940724 34819 solver.cpp:239] Iteration 19900 (2.43555 iter/s, 4.10585s/10 iters), loss = 8.22172
I0523 00:38:08.940860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22172 (* 1 = 8.22172 loss)
I0523 00:38:09.012543 34819 sgd_solver.cpp:112] Iteration 19900, lr = 0.01
I0523 00:38:12.353206 34819 solver.cpp:239] Iteration 19910 (2.93066 iter/s, 3.4122s/10 iters), loss = 8.5156
I0523 00:38:12.353271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5156 (* 1 = 8.5156 loss)
I0523 00:38:12.411372 34819 sgd_solver.cpp:112] Iteration 19910, lr = 0.01
I0523 00:38:16.517261 34819 solver.cpp:239] Iteration 19920 (2.40165 iter/s, 4.1638s/10 iters), loss = 8.19698
I0523 00:38:16.517314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19698 (* 1 = 8.19698 loss)
I0523 00:38:16.578852 34819 sgd_solver.cpp:112] Iteration 19920, lr = 0.01
I0523 00:38:22.164557 34819 solver.cpp:239] Iteration 19930 (1.77085 iter/s, 5.647s/10 iters), loss = 8.42218
I0523 00:38:22.164616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42218 (* 1 = 8.42218 loss)
I0523 00:38:22.988443 34819 sgd_solver.cpp:112] Iteration 19930, lr = 0.01
I0523 00:38:27.787051 34819 solver.cpp:239] Iteration 19940 (1.77866 iter/s, 5.6222s/10 iters), loss = 8.62711
I0523 00:38:27.787106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62711 (* 1 = 8.62711 loss)
I0523 00:38:27.861752 34819 sgd_solver.cpp:112] Iteration 19940, lr = 0.01
I0523 00:38:33.459192 34819 solver.cpp:239] Iteration 19950 (1.7631 iter/s, 5.67184s/10 iters), loss = 8.57913
I0523 00:38:33.459252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57913 (* 1 = 8.57913 loss)
I0523 00:38:34.280055 34819 sgd_solver.cpp:112] Iteration 19950, lr = 0.01
I0523 00:38:38.229851 34819 solver.cpp:239] Iteration 19960 (2.09626 iter/s, 4.7704s/10 iters), loss = 8.44212
I0523 00:38:38.229894 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44212 (* 1 = 8.44212 loss)
I0523 00:38:38.282873 34819 sgd_solver.cpp:112] Iteration 19960, lr = 0.01
I0523 00:38:43.104109 34819 solver.cpp:239] Iteration 19970 (2.0517 iter/s, 4.874s/10 iters), loss = 8.93443
I0523 00:38:43.104250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93443 (* 1 = 8.93443 loss)
I0523 00:38:43.176594 34819 sgd_solver.cpp:112] Iteration 19970, lr = 0.01
I0523 00:38:47.355590 34819 solver.cpp:239] Iteration 19980 (2.3523 iter/s, 4.25115s/10 iters), loss = 8.78691
I0523 00:38:47.355644 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78691 (* 1 = 8.78691 loss)
I0523 00:38:47.861279 34819 sgd_solver.cpp:112] Iteration 19980, lr = 0.01
I0523 00:38:52.472427 34819 solver.cpp:239] Iteration 19990 (1.95444 iter/s, 5.11655s/10 iters), loss = 8.7814
I0523 00:38:52.472488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7814 (* 1 = 8.7814 loss)
I0523 00:38:53.210157 34819 sgd_solver.cpp:112] Iteration 19990, lr = 0.01
I0523 00:38:57.349578 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_20000.caffemodel
I0523 00:38:58.261682 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_20000.solverstate
I0523 00:38:58.482017 34819 solver.cpp:239] Iteration 20000 (1.66409 iter/s, 6.00929s/10 iters), loss = 8.19296
I0523 00:38:58.482059 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19296 (* 1 = 8.19296 loss)
I0523 00:38:58.553467 34819 sgd_solver.cpp:112] Iteration 20000, lr = 0.01
I0523 00:39:02.501210 34819 solver.cpp:239] Iteration 20010 (2.4882 iter/s, 4.01897s/10 iters), loss = 8.68102
I0523 00:39:02.501256 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68102 (* 1 = 8.68102 loss)
I0523 00:39:02.565807 34819 sgd_solver.cpp:112] Iteration 20010, lr = 0.01
I0523 00:39:07.266847 34819 solver.cpp:239] Iteration 20020 (2.09846 iter/s, 4.76539s/10 iters), loss = 9.4521
I0523 00:39:07.266899 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4521 (* 1 = 9.4521 loss)
I0523 00:39:07.326547 34819 sgd_solver.cpp:112] Iteration 20020, lr = 0.01
I0523 00:39:13.902977 34819 solver.cpp:239] Iteration 20030 (1.50698 iter/s, 6.6358s/10 iters), loss = 7.84063
I0523 00:39:13.903141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84063 (* 1 = 7.84063 loss)
I0523 00:39:14.741307 34819 sgd_solver.cpp:112] Iteration 20030, lr = 0.01
I0523 00:39:19.438073 34819 solver.cpp:239] Iteration 20040 (1.80678 iter/s, 5.53471s/10 iters), loss = 9.27384
I0523 00:39:19.438130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27384 (* 1 = 9.27384 loss)
I0523 00:39:19.495934 34819 sgd_solver.cpp:112] Iteration 20040, lr = 0.01
I0523 00:39:22.709162 34819 solver.cpp:239] Iteration 20050 (3.05727 iter/s, 3.27089s/10 iters), loss = 9.51997
I0523 00:39:22.709205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51997 (* 1 = 9.51997 loss)
I0523 00:39:22.763159 34819 sgd_solver.cpp:112] Iteration 20050, lr = 0.01
I0523 00:39:27.012308 34819 solver.cpp:239] Iteration 20060 (2.32401 iter/s, 4.30291s/10 iters), loss = 8.80223
I0523 00:39:27.012351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80223 (* 1 = 8.80223 loss)
I0523 00:39:27.073015 34819 sgd_solver.cpp:112] Iteration 20060, lr = 0.01
I0523 00:39:31.854871 34819 solver.cpp:239] Iteration 20070 (2.06513 iter/s, 4.84231s/10 iters), loss = 8.76478
I0523 00:39:31.854913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76478 (* 1 = 8.76478 loss)
I0523 00:39:31.922204 34819 sgd_solver.cpp:112] Iteration 20070, lr = 0.01
I0523 00:39:37.221107 34819 solver.cpp:239] Iteration 20080 (1.8636 iter/s, 5.36596s/10 iters), loss = 9.38098
I0523 00:39:37.221161 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38098 (* 1 = 9.38098 loss)
I0523 00:39:37.278501 34819 sgd_solver.cpp:112] Iteration 20080, lr = 0.01
I0523 00:39:42.080915 34819 solver.cpp:239] Iteration 20090 (2.0578 iter/s, 4.85955s/10 iters), loss = 9.33511
I0523 00:39:42.080965 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33511 (* 1 = 9.33511 loss)
I0523 00:39:42.139904 34819 sgd_solver.cpp:112] Iteration 20090, lr = 0.01
I0523 00:39:46.291756 34819 solver.cpp:239] Iteration 20100 (2.37496 iter/s, 4.21061s/10 iters), loss = 8.58154
I0523 00:39:46.291946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58154 (* 1 = 8.58154 loss)
I0523 00:39:47.055312 34819 sgd_solver.cpp:112] Iteration 20100, lr = 0.01
I0523 00:39:51.153600 34819 solver.cpp:239] Iteration 20110 (2.057 iter/s, 4.86145s/10 iters), loss = 9.38105
I0523 00:39:51.153645 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38105 (* 1 = 9.38105 loss)
I0523 00:39:51.222652 34819 sgd_solver.cpp:112] Iteration 20110, lr = 0.01
I0523 00:39:56.969688 34819 solver.cpp:239] Iteration 20120 (1.71946 iter/s, 5.81579s/10 iters), loss = 8.48337
I0523 00:39:56.969759 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48337 (* 1 = 8.48337 loss)
I0523 00:39:57.046883 34819 sgd_solver.cpp:112] Iteration 20120, lr = 0.01
I0523 00:40:00.984107 34819 solver.cpp:239] Iteration 20130 (2.49117 iter/s, 4.01418s/10 iters), loss = 8.23327
I0523 00:40:00.984171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23327 (* 1 = 8.23327 loss)
I0523 00:40:01.053495 34819 sgd_solver.cpp:112] Iteration 20130, lr = 0.01
I0523 00:40:06.118887 34819 solver.cpp:239] Iteration 20140 (1.94761 iter/s, 5.13449s/10 iters), loss = 8.73704
I0523 00:40:06.118944 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73704 (* 1 = 8.73704 loss)
I0523 00:40:06.188284 34819 sgd_solver.cpp:112] Iteration 20140, lr = 0.01
I0523 00:40:11.890152 34819 solver.cpp:239] Iteration 20150 (1.73281 iter/s, 5.77096s/10 iters), loss = 8.94169
I0523 00:40:11.890208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94169 (* 1 = 8.94169 loss)
I0523 00:40:11.955579 34819 sgd_solver.cpp:112] Iteration 20150, lr = 0.01
I0523 00:40:18.090329 34819 solver.cpp:239] Iteration 20160 (1.61294 iter/s, 6.19987s/10 iters), loss = 8.883
I0523 00:40:18.090482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.883 (* 1 = 8.883 loss)
I0523 00:40:18.160755 34819 sgd_solver.cpp:112] Iteration 20160, lr = 0.01
I0523 00:40:24.319144 34819 solver.cpp:239] Iteration 20170 (1.60555 iter/s, 6.2284s/10 iters), loss = 8.93108
I0523 00:40:24.319190 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93108 (* 1 = 8.93108 loss)
I0523 00:40:24.392410 34819 sgd_solver.cpp:112] Iteration 20170, lr = 0.01
I0523 00:40:29.446889 34819 solver.cpp:239] Iteration 20180 (1.95027 iter/s, 5.12749s/10 iters), loss = 7.88923
I0523 00:40:29.446931 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88923 (* 1 = 7.88923 loss)
I0523 00:40:30.284780 34819 sgd_solver.cpp:112] Iteration 20180, lr = 0.01
I0523 00:40:37.231497 34819 solver.cpp:239] Iteration 20190 (1.28465 iter/s, 7.78423s/10 iters), loss = 7.84713
I0523 00:40:37.231556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84713 (* 1 = 7.84713 loss)
I0523 00:40:38.008460 34819 sgd_solver.cpp:112] Iteration 20190, lr = 0.01
I0523 00:40:43.574157 34819 solver.cpp:239] Iteration 20200 (1.57671 iter/s, 6.34232s/10 iters), loss = 8.55432
I0523 00:40:43.574223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55432 (* 1 = 8.55432 loss)
I0523 00:40:43.870781 34819 sgd_solver.cpp:112] Iteration 20200, lr = 0.01
I0523 00:40:47.837213 34819 solver.cpp:239] Iteration 20210 (2.34587 iter/s, 4.2628s/10 iters), loss = 8.87914
I0523 00:40:47.837257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87914 (* 1 = 8.87914 loss)
I0523 00:40:47.898705 34819 sgd_solver.cpp:112] Iteration 20210, lr = 0.01
I0523 00:40:50.360245 34819 solver.cpp:239] Iteration 20220 (3.96374 iter/s, 2.52287s/10 iters), loss = 7.95387
I0523 00:40:50.360442 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95387 (* 1 = 7.95387 loss)
I0523 00:40:50.440145 34819 sgd_solver.cpp:112] Iteration 20220, lr = 0.01
I0523 00:40:57.460255 34819 solver.cpp:239] Iteration 20230 (1.40855 iter/s, 7.09952s/10 iters), loss = 8.71567
I0523 00:40:57.460309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71567 (* 1 = 8.71567 loss)
I0523 00:40:57.521863 34819 sgd_solver.cpp:112] Iteration 20230, lr = 0.01
I0523 00:41:03.106372 34819 solver.cpp:239] Iteration 20240 (1.77122 iter/s, 5.64583s/10 iters), loss = 9.33808
I0523 00:41:03.106431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33808 (* 1 = 9.33808 loss)
I0523 00:41:03.183935 34819 sgd_solver.cpp:112] Iteration 20240, lr = 0.01
I0523 00:41:08.682775 34819 solver.cpp:239] Iteration 20250 (1.79337 iter/s, 5.57611s/10 iters), loss = 8.81974
I0523 00:41:08.682818 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81974 (* 1 = 8.81974 loss)
I0523 00:41:09.494626 34819 sgd_solver.cpp:112] Iteration 20250, lr = 0.01
I0523 00:41:15.078084 34819 solver.cpp:239] Iteration 20260 (1.56372 iter/s, 6.39499s/10 iters), loss = 8.05462
I0523 00:41:15.078138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05462 (* 1 = 8.05462 loss)
I0523 00:41:15.668237 34819 sgd_solver.cpp:112] Iteration 20260, lr = 0.01
I0523 00:41:20.546591 34819 solver.cpp:239] Iteration 20270 (1.82875 iter/s, 5.46822s/10 iters), loss = 8.16081
I0523 00:41:20.546716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16081 (* 1 = 8.16081 loss)
I0523 00:41:20.686149 34819 sgd_solver.cpp:112] Iteration 20270, lr = 0.01
I0523 00:41:24.831398 34819 solver.cpp:239] Iteration 20280 (2.33399 iter/s, 4.28451s/10 iters), loss = 7.83633
I0523 00:41:24.831439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83633 (* 1 = 7.83633 loss)
I0523 00:41:25.653723 34819 sgd_solver.cpp:112] Iteration 20280, lr = 0.01
I0523 00:41:29.858574 34819 solver.cpp:239] Iteration 20290 (1.98929 iter/s, 5.02692s/10 iters), loss = 8.07532
I0523 00:41:29.858620 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07532 (* 1 = 8.07532 loss)
I0523 00:41:30.741039 34819 sgd_solver.cpp:112] Iteration 20290, lr = 0.01
I0523 00:41:36.456478 34819 solver.cpp:239] Iteration 20300 (1.5157 iter/s, 6.59759s/10 iters), loss = 8.37805
I0523 00:41:36.456521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37805 (* 1 = 8.37805 loss)
I0523 00:41:36.533828 34819 sgd_solver.cpp:112] Iteration 20300, lr = 0.01
I0523 00:41:40.336616 34819 solver.cpp:239] Iteration 20310 (2.57737 iter/s, 3.87992s/10 iters), loss = 9.66577
I0523 00:41:40.336663 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.66577 (* 1 = 9.66577 loss)
I0523 00:41:40.411520 34819 sgd_solver.cpp:112] Iteration 20310, lr = 0.01
I0523 00:41:44.214838 34819 solver.cpp:239] Iteration 20320 (2.57864 iter/s, 3.87801s/10 iters), loss = 8.77987
I0523 00:41:44.214880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77987 (* 1 = 8.77987 loss)
I0523 00:41:44.281908 34819 sgd_solver.cpp:112] Iteration 20320, lr = 0.01
I0523 00:41:50.513993 34819 solver.cpp:239] Iteration 20330 (1.58759 iter/s, 6.29885s/10 iters), loss = 9.02796
I0523 00:41:50.514039 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02796 (* 1 = 9.02796 loss)
I0523 00:41:50.590647 34819 sgd_solver.cpp:112] Iteration 20330, lr = 0.01
I0523 00:41:56.183643 34819 solver.cpp:239] Iteration 20340 (1.76388 iter/s, 5.66933s/10 iters), loss = 8.46717
I0523 00:41:56.183696 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46717 (* 1 = 8.46717 loss)
I0523 00:41:57.020586 34819 sgd_solver.cpp:112] Iteration 20340, lr = 0.01
I0523 00:42:00.173094 34819 solver.cpp:239] Iteration 20350 (2.50675 iter/s, 3.98922s/10 iters), loss = 7.87946
I0523 00:42:00.173138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87946 (* 1 = 7.87946 loss)
I0523 00:42:00.224450 34819 sgd_solver.cpp:112] Iteration 20350, lr = 0.01
I0523 00:42:05.272156 34819 solver.cpp:239] Iteration 20360 (1.96124 iter/s, 5.09881s/10 iters), loss = 8.12154
I0523 00:42:05.272198 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12154 (* 1 = 8.12154 loss)
I0523 00:42:05.906443 34819 sgd_solver.cpp:112] Iteration 20360, lr = 0.01
I0523 00:42:10.499864 34819 solver.cpp:239] Iteration 20370 (1.91298 iter/s, 5.22745s/10 iters), loss = 9.50206
I0523 00:42:10.499907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50206 (* 1 = 9.50206 loss)
I0523 00:42:10.567065 34819 sgd_solver.cpp:112] Iteration 20370, lr = 0.01
I0523 00:42:13.976109 34819 solver.cpp:239] Iteration 20380 (2.87683 iter/s, 3.47604s/10 iters), loss = 8.48747
I0523 00:42:13.976153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48747 (* 1 = 8.48747 loss)
I0523 00:42:14.804014 34819 sgd_solver.cpp:112] Iteration 20380, lr = 0.01
I0523 00:42:18.943167 34819 solver.cpp:239] Iteration 20390 (2.01337 iter/s, 4.96679s/10 iters), loss = 8.89075
I0523 00:42:18.943218 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89075 (* 1 = 8.89075 loss)
I0523 00:42:18.993512 34819 sgd_solver.cpp:112] Iteration 20390, lr = 0.01
I0523 00:42:23.963670 34819 solver.cpp:239] Iteration 20400 (1.99194 iter/s, 5.02024s/10 iters), loss = 8.45242
I0523 00:42:23.963834 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45242 (* 1 = 8.45242 loss)
I0523 00:42:24.814900 34819 sgd_solver.cpp:112] Iteration 20400, lr = 0.01
I0523 00:42:30.154446 34819 solver.cpp:239] Iteration 20410 (1.61542 iter/s, 6.19035s/10 iters), loss = 8.58255
I0523 00:42:30.154487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58255 (* 1 = 8.58255 loss)
I0523 00:42:30.227316 34819 sgd_solver.cpp:112] Iteration 20410, lr = 0.01
I0523 00:42:35.032953 34819 solver.cpp:239] Iteration 20420 (2.04991 iter/s, 4.87825s/10 iters), loss = 8.7229
I0523 00:42:35.032999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7229 (* 1 = 8.7229 loss)
I0523 00:42:35.100019 34819 sgd_solver.cpp:112] Iteration 20420, lr = 0.01
I0523 00:42:41.060276 34819 solver.cpp:239] Iteration 20430 (1.65919 iter/s, 6.02702s/10 iters), loss = 8.88052
I0523 00:42:41.060322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88052 (* 1 = 8.88052 loss)
I0523 00:42:41.644779 34819 sgd_solver.cpp:112] Iteration 20430, lr = 0.01
I0523 00:42:48.718405 34819 solver.cpp:239] Iteration 20440 (1.30586 iter/s, 7.65777s/10 iters), loss = 9.48577
I0523 00:42:48.718448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48577 (* 1 = 9.48577 loss)
I0523 00:42:49.579082 34819 sgd_solver.cpp:112] Iteration 20440, lr = 0.01
I0523 00:42:53.671802 34819 solver.cpp:239] Iteration 20450 (2.01892 iter/s, 4.95315s/10 iters), loss = 9.03991
I0523 00:42:53.671849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03991 (* 1 = 9.03991 loss)
I0523 00:42:53.734139 34819 sgd_solver.cpp:112] Iteration 20450, lr = 0.01
I0523 00:42:57.878489 34819 solver.cpp:239] Iteration 20460 (2.37729 iter/s, 4.20646s/10 iters), loss = 8.62858
I0523 00:42:57.878643 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62858 (* 1 = 8.62858 loss)
I0523 00:42:58.508491 34819 sgd_solver.cpp:112] Iteration 20460, lr = 0.01
I0523 00:43:04.013811 34819 solver.cpp:239] Iteration 20470 (1.63002 iter/s, 6.13491s/10 iters), loss = 8.55836
I0523 00:43:04.013854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55836 (* 1 = 8.55836 loss)
I0523 00:43:04.084292 34819 sgd_solver.cpp:112] Iteration 20470, lr = 0.01
I0523 00:43:08.847014 34819 solver.cpp:239] Iteration 20480 (2.06913 iter/s, 4.83295s/10 iters), loss = 8.75177
I0523 00:43:08.847059 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75177 (* 1 = 8.75177 loss)
I0523 00:43:09.291322 34819 sgd_solver.cpp:112] Iteration 20480, lr = 0.01
I0523 00:43:14.683912 34819 solver.cpp:239] Iteration 20490 (1.71332 iter/s, 5.8366s/10 iters), loss = 8.74757
I0523 00:43:14.683969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74757 (* 1 = 8.74757 loss)
I0523 00:43:14.745664 34819 sgd_solver.cpp:112] Iteration 20490, lr = 0.01
I0523 00:43:18.363730 34819 solver.cpp:239] Iteration 20500 (2.71769 iter/s, 3.6796s/10 iters), loss = 8.12164
I0523 00:43:18.363785 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12164 (* 1 = 8.12164 loss)
I0523 00:43:18.427435 34819 sgd_solver.cpp:112] Iteration 20500, lr = 0.01
I0523 00:43:22.884691 34819 solver.cpp:239] Iteration 20510 (2.21205 iter/s, 4.5207s/10 iters), loss = 9.29124
I0523 00:43:22.884758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29124 (* 1 = 9.29124 loss)
I0523 00:43:23.686010 34819 sgd_solver.cpp:112] Iteration 20510, lr = 0.01
I0523 00:43:29.350805 34819 solver.cpp:239] Iteration 20520 (1.54661 iter/s, 6.46577s/10 iters), loss = 7.55097
I0523 00:43:29.351003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55097 (* 1 = 7.55097 loss)
I0523 00:43:29.687050 34819 sgd_solver.cpp:112] Iteration 20520, lr = 0.01
I0523 00:43:34.408233 34819 solver.cpp:239] Iteration 20530 (1.97916 iter/s, 5.05265s/10 iters), loss = 8.87942
I0523 00:43:34.408285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87942 (* 1 = 8.87942 loss)
I0523 00:43:35.273808 34819 sgd_solver.cpp:112] Iteration 20530, lr = 0.01
I0523 00:43:38.712340 34819 solver.cpp:239] Iteration 20540 (2.32349 iter/s, 4.30386s/10 iters), loss = 8.36752
I0523 00:43:38.712395 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36752 (* 1 = 8.36752 loss)
I0523 00:43:38.773980 34819 sgd_solver.cpp:112] Iteration 20540, lr = 0.01
I0523 00:43:43.256623 34819 solver.cpp:239] Iteration 20550 (2.20069 iter/s, 4.54403s/10 iters), loss = 7.79641
I0523 00:43:43.256692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79641 (* 1 = 7.79641 loss)
I0523 00:43:43.317153 34819 sgd_solver.cpp:112] Iteration 20550, lr = 0.01
I0523 00:43:48.347072 34819 solver.cpp:239] Iteration 20560 (1.96458 iter/s, 5.09014s/10 iters), loss = 8.60861
I0523 00:43:48.347157 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60861 (* 1 = 8.60861 loss)
I0523 00:43:48.570734 34819 sgd_solver.cpp:112] Iteration 20560, lr = 0.01
I0523 00:43:53.265290 34819 solver.cpp:239] Iteration 20570 (2.03338 iter/s, 4.91792s/10 iters), loss = 8.85341
I0523 00:43:53.265354 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85341 (* 1 = 8.85341 loss)
I0523 00:43:53.323082 34819 sgd_solver.cpp:112] Iteration 20570, lr = 0.01
I0523 00:43:59.735769 34819 solver.cpp:239] Iteration 20580 (1.54556 iter/s, 6.47015s/10 iters), loss = 7.56152
I0523 00:43:59.735941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56152 (* 1 = 7.56152 loss)
I0523 00:44:00.493718 34819 sgd_solver.cpp:112] Iteration 20580, lr = 0.01
I0523 00:44:06.293642 34819 solver.cpp:239] Iteration 20590 (1.52499 iter/s, 6.55743s/10 iters), loss = 8.7319
I0523 00:44:06.293691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7319 (* 1 = 8.7319 loss)
I0523 00:44:06.349205 34819 sgd_solver.cpp:112] Iteration 20590, lr = 0.01
I0523 00:44:11.935204 34819 solver.cpp:239] Iteration 20600 (1.77266 iter/s, 5.64124s/10 iters), loss = 8.31861
I0523 00:44:11.935312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31861 (* 1 = 8.31861 loss)
I0523 00:44:12.002243 34819 sgd_solver.cpp:112] Iteration 20600, lr = 0.01
I0523 00:44:18.053427 34819 solver.cpp:239] Iteration 20610 (1.63456 iter/s, 6.11787s/10 iters), loss = 8.8703
I0523 00:44:18.053495 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8703 (* 1 = 8.8703 loss)
I0523 00:44:18.126299 34819 sgd_solver.cpp:112] Iteration 20610, lr = 0.01
I0523 00:44:23.822862 34819 solver.cpp:239] Iteration 20620 (1.73336 iter/s, 5.76913s/10 iters), loss = 8.41823
I0523 00:44:23.822908 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41823 (* 1 = 8.41823 loss)
I0523 00:44:23.886967 34819 sgd_solver.cpp:112] Iteration 20620, lr = 0.01
I0523 00:44:28.702021 34819 solver.cpp:239] Iteration 20630 (2.04965 iter/s, 4.87888s/10 iters), loss = 8.87004
I0523 00:44:28.702105 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87004 (* 1 = 8.87004 loss)
I0523 00:44:29.480563 34819 sgd_solver.cpp:112] Iteration 20630, lr = 0.01
I0523 00:44:35.563156 34819 solver.cpp:239] Iteration 20640 (1.45756 iter/s, 6.86077s/10 iters), loss = 8.89073
I0523 00:44:35.563350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89073 (* 1 = 8.89073 loss)
I0523 00:44:36.381352 34819 sgd_solver.cpp:112] Iteration 20640, lr = 0.01
I0523 00:44:39.490213 34819 solver.cpp:239] Iteration 20650 (2.54667 iter/s, 3.92669s/10 iters), loss = 8.88027
I0523 00:44:39.490283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88027 (* 1 = 8.88027 loss)
I0523 00:44:40.280977 34819 sgd_solver.cpp:112] Iteration 20650, lr = 0.01
I0523 00:44:43.497936 34819 solver.cpp:239] Iteration 20660 (2.49534 iter/s, 4.00747s/10 iters), loss = 9.29915
I0523 00:44:43.497993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29915 (* 1 = 9.29915 loss)
I0523 00:44:43.555238 34819 sgd_solver.cpp:112] Iteration 20660, lr = 0.01
I0523 00:44:48.354431 34819 solver.cpp:239] Iteration 20670 (2.05921 iter/s, 4.85623s/10 iters), loss = 9.63589
I0523 00:44:48.354480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63589 (* 1 = 9.63589 loss)
I0523 00:44:48.429476 34819 sgd_solver.cpp:112] Iteration 20670, lr = 0.01
I0523 00:44:54.012923 34819 solver.cpp:239] Iteration 20680 (1.76734 iter/s, 5.65821s/10 iters), loss = 8.59818
I0523 00:44:54.012971 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59818 (* 1 = 8.59818 loss)
I0523 00:44:54.853577 34819 sgd_solver.cpp:112] Iteration 20680, lr = 0.01
I0523 00:45:00.550730 34819 solver.cpp:239] Iteration 20690 (1.52965 iter/s, 6.53746s/10 iters), loss = 9.27695
I0523 00:45:00.550794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27695 (* 1 = 9.27695 loss)
I0523 00:45:01.260195 34819 sgd_solver.cpp:112] Iteration 20690, lr = 0.01
I0523 00:45:05.251971 34819 solver.cpp:239] Iteration 20700 (2.12722 iter/s, 4.70097s/10 iters), loss = 8.54613
I0523 00:45:05.252045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54613 (* 1 = 8.54613 loss)
I0523 00:45:05.322654 34819 sgd_solver.cpp:112] Iteration 20700, lr = 0.01
I0523 00:45:09.494626 34819 solver.cpp:239] Iteration 20710 (2.35716 iter/s, 4.2424s/10 iters), loss = 8.63183
I0523 00:45:09.494802 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63183 (* 1 = 8.63183 loss)
I0523 00:45:09.566440 34819 sgd_solver.cpp:112] Iteration 20710, lr = 0.01
I0523 00:45:13.483911 34819 solver.cpp:239] Iteration 20720 (2.50693 iter/s, 3.98894s/10 iters), loss = 8.52242
I0523 00:45:13.483958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52242 (* 1 = 8.52242 loss)
I0523 00:45:13.548041 34819 sgd_solver.cpp:112] Iteration 20720, lr = 0.01
I0523 00:45:18.234076 34819 solver.cpp:239] Iteration 20730 (2.1053 iter/s, 4.74991s/10 iters), loss = 9.23528
I0523 00:45:18.234134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23528 (* 1 = 9.23528 loss)
I0523 00:45:18.889786 34819 sgd_solver.cpp:112] Iteration 20730, lr = 0.01
I0523 00:45:23.838646 34819 solver.cpp:239] Iteration 20740 (1.78435 iter/s, 5.60428s/10 iters), loss = 9.10431
I0523 00:45:23.838716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10431 (* 1 = 9.10431 loss)
I0523 00:45:23.901562 34819 sgd_solver.cpp:112] Iteration 20740, lr = 0.01
I0523 00:45:30.088042 34819 solver.cpp:239] Iteration 20750 (1.60023 iter/s, 6.24908s/10 iters), loss = 8.78012
I0523 00:45:30.088099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78012 (* 1 = 8.78012 loss)
I0523 00:45:30.738111 34819 sgd_solver.cpp:112] Iteration 20750, lr = 0.01
I0523 00:45:36.389683 34819 solver.cpp:239] Iteration 20760 (1.58697 iter/s, 6.30133s/10 iters), loss = 8.79475
I0523 00:45:36.389735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79475 (* 1 = 8.79475 loss)
I0523 00:45:37.286350 34819 sgd_solver.cpp:112] Iteration 20760, lr = 0.01
I0523 00:45:41.028342 34819 solver.cpp:239] Iteration 20770 (2.15591 iter/s, 4.63841s/10 iters), loss = 9.31433
I0523 00:45:41.028630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31433 (* 1 = 9.31433 loss)
I0523 00:45:41.816526 34819 sgd_solver.cpp:112] Iteration 20770, lr = 0.01
I0523 00:45:46.405684 34819 solver.cpp:239] Iteration 20780 (1.85983 iter/s, 5.37684s/10 iters), loss = 8.14075
I0523 00:45:46.405752 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14075 (* 1 = 8.14075 loss)
I0523 00:45:47.233302 34819 sgd_solver.cpp:112] Iteration 20780, lr = 0.01
I0523 00:45:50.605856 34819 solver.cpp:239] Iteration 20790 (2.38099 iter/s, 4.19993s/10 iters), loss = 8.19912
I0523 00:45:50.605912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19912 (* 1 = 8.19912 loss)
I0523 00:45:51.382355 34819 sgd_solver.cpp:112] Iteration 20790, lr = 0.01
I0523 00:45:55.673283 34819 solver.cpp:239] Iteration 20800 (1.9735 iter/s, 5.06715s/10 iters), loss = 9.06971
I0523 00:45:55.673347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06971 (* 1 = 9.06971 loss)
I0523 00:45:55.743055 34819 sgd_solver.cpp:112] Iteration 20800, lr = 0.01
I0523 00:46:02.060804 34819 solver.cpp:239] Iteration 20810 (1.56563 iter/s, 6.38719s/10 iters), loss = 8.74496
I0523 00:46:02.060861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74496 (* 1 = 8.74496 loss)
I0523 00:46:02.706480 34819 sgd_solver.cpp:112] Iteration 20810, lr = 0.01
I0523 00:46:07.015480 34819 solver.cpp:239] Iteration 20820 (2.01841 iter/s, 4.95441s/10 iters), loss = 8.80524
I0523 00:46:07.015543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80524 (* 1 = 8.80524 loss)
I0523 00:46:07.100334 34819 sgd_solver.cpp:112] Iteration 20820, lr = 0.01
I0523 00:46:12.688050 34819 solver.cpp:239] Iteration 20830 (1.76297 iter/s, 5.67226s/10 iters), loss = 8.87832
I0523 00:46:12.688307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87832 (* 1 = 8.87832 loss)
I0523 00:46:13.422621 34819 sgd_solver.cpp:112] Iteration 20830, lr = 0.01
I0523 00:46:17.576779 34819 solver.cpp:239] Iteration 20840 (2.0457 iter/s, 4.8883s/10 iters), loss = 8.57112
I0523 00:46:17.576822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57112 (* 1 = 8.57112 loss)
I0523 00:46:17.651036 34819 sgd_solver.cpp:112] Iteration 20840, lr = 0.01
I0523 00:46:21.826814 34819 solver.cpp:239] Iteration 20850 (2.35305 iter/s, 4.2498s/10 iters), loss = 9.06362
I0523 00:46:21.826862 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06362 (* 1 = 9.06362 loss)
I0523 00:46:22.336855 34819 sgd_solver.cpp:112] Iteration 20850, lr = 0.01
I0523 00:46:27.352383 34819 solver.cpp:239] Iteration 20860 (1.80986 iter/s, 5.52528s/10 iters), loss = 8.49249
I0523 00:46:27.352428 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49249 (* 1 = 8.49249 loss)
I0523 00:46:27.414707 34819 sgd_solver.cpp:112] Iteration 20860, lr = 0.01
I0523 00:46:32.458114 34819 solver.cpp:239] Iteration 20870 (1.95868 iter/s, 5.10547s/10 iters), loss = 9.08537
I0523 00:46:32.458158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08537 (* 1 = 9.08537 loss)
I0523 00:46:32.515110 34819 sgd_solver.cpp:112] Iteration 20870, lr = 0.01
I0523 00:46:35.978421 34819 solver.cpp:239] Iteration 20880 (2.84082 iter/s, 3.52011s/10 iters), loss = 8.16995
I0523 00:46:35.978474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16995 (* 1 = 8.16995 loss)
I0523 00:46:36.044488 34819 sgd_solver.cpp:112] Iteration 20880, lr = 0.01
I0523 00:46:39.574436 34819 solver.cpp:239] Iteration 20890 (2.78103 iter/s, 3.5958s/10 iters), loss = 9.39038
I0523 00:46:39.574487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39038 (* 1 = 9.39038 loss)
I0523 00:46:39.637627 34819 sgd_solver.cpp:112] Iteration 20890, lr = 0.01
I0523 00:46:46.225333 34819 solver.cpp:239] Iteration 20900 (1.50363 iter/s, 6.65056s/10 iters), loss = 8.47285
I0523 00:46:46.225572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47285 (* 1 = 8.47285 loss)
I0523 00:46:46.837451 34819 sgd_solver.cpp:112] Iteration 20900, lr = 0.01
I0523 00:46:52.308007 34819 solver.cpp:239] Iteration 20910 (1.64414 iter/s, 6.08219s/10 iters), loss = 8.90024
I0523 00:46:52.308068 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90024 (* 1 = 8.90024 loss)
I0523 00:46:52.381248 34819 sgd_solver.cpp:112] Iteration 20910, lr = 0.01
I0523 00:46:56.446023 34819 solver.cpp:239] Iteration 20920 (2.41676 iter/s, 4.13778s/10 iters), loss = 9.14334
I0523 00:46:56.446092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14334 (* 1 = 9.14334 loss)
I0523 00:46:56.519670 34819 sgd_solver.cpp:112] Iteration 20920, lr = 0.01
I0523 00:46:59.896162 34819 solver.cpp:239] Iteration 20930 (2.90053 iter/s, 3.44765s/10 iters), loss = 9.17408
I0523 00:46:59.896224 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17408 (* 1 = 9.17408 loss)
I0523 00:47:00.735174 34819 sgd_solver.cpp:112] Iteration 20930, lr = 0.01
I0523 00:47:04.355808 34819 solver.cpp:239] Iteration 20940 (2.24246 iter/s, 4.45939s/10 iters), loss = 8.93758
I0523 00:47:04.355873 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93758 (* 1 = 8.93758 loss)
I0523 00:47:05.177214 34819 sgd_solver.cpp:112] Iteration 20940, lr = 0.01
I0523 00:47:08.229012 34819 solver.cpp:239] Iteration 20950 (2.58199 iter/s, 3.87297s/10 iters), loss = 8.48478
I0523 00:47:08.229069 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48478 (* 1 = 8.48478 loss)
I0523 00:47:08.307225 34819 sgd_solver.cpp:112] Iteration 20950, lr = 0.01
I0523 00:47:12.385419 34819 solver.cpp:239] Iteration 20960 (2.40606 iter/s, 4.15618s/10 iters), loss = 9.71258
I0523 00:47:12.385475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71258 (* 1 = 9.71258 loss)
I0523 00:47:12.457132 34819 sgd_solver.cpp:112] Iteration 20960, lr = 0.01
I0523 00:47:18.838022 34819 solver.cpp:239] Iteration 20970 (1.54984 iter/s, 6.45228s/10 iters), loss = 9.50791
I0523 00:47:18.838150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50791 (* 1 = 9.50791 loss)
I0523 00:47:19.668095 34819 sgd_solver.cpp:112] Iteration 20970, lr = 0.01
I0523 00:47:25.326653 34819 solver.cpp:239] Iteration 20980 (1.54125 iter/s, 6.48824s/10 iters), loss = 8.65637
I0523 00:47:25.326732 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65637 (* 1 = 8.65637 loss)
I0523 00:47:25.389353 34819 sgd_solver.cpp:112] Iteration 20980, lr = 0.01
I0523 00:47:31.326251 34819 solver.cpp:239] Iteration 20990 (1.66687 iter/s, 5.99927s/10 iters), loss = 8.47375
I0523 00:47:31.326308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47375 (* 1 = 8.47375 loss)
I0523 00:47:31.415078 34819 sgd_solver.cpp:112] Iteration 20990, lr = 0.01
I0523 00:47:36.342094 34819 solver.cpp:239] Iteration 21000 (1.99379 iter/s, 5.01558s/10 iters), loss = 8.51717
I0523 00:47:36.342141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51717 (* 1 = 8.51717 loss)
I0523 00:47:36.397713 34819 sgd_solver.cpp:112] Iteration 21000, lr = 0.01
I0523 00:47:41.208093 34819 solver.cpp:239] Iteration 21010 (2.05518 iter/s, 4.86575s/10 iters), loss = 8.64729
I0523 00:47:41.208148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64729 (* 1 = 8.64729 loss)
I0523 00:47:41.278014 34819 sgd_solver.cpp:112] Iteration 21010, lr = 0.01
I0523 00:47:45.595609 34819 solver.cpp:239] Iteration 21020 (2.27933 iter/s, 4.38726s/10 iters), loss = 8.52218
I0523 00:47:45.595662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52218 (* 1 = 8.52218 loss)
I0523 00:47:46.394157 34819 sgd_solver.cpp:112] Iteration 21020, lr = 0.01
I0523 00:47:50.548017 34819 solver.cpp:239] Iteration 21030 (2.01933 iter/s, 4.95215s/10 iters), loss = 8.94095
I0523 00:47:50.548189 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94095 (* 1 = 8.94095 loss)
I0523 00:47:51.346186 34819 sgd_solver.cpp:112] Iteration 21030, lr = 0.01
I0523 00:47:53.139868 34819 solver.cpp:239] Iteration 21040 (3.85867 iter/s, 2.59157s/10 iters), loss = 9.63517
I0523 00:47:53.139921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63517 (* 1 = 9.63517 loss)
I0523 00:47:53.207175 34819 sgd_solver.cpp:112] Iteration 21040, lr = 0.01
I0523 00:47:57.951660 34819 solver.cpp:239] Iteration 21050 (2.07834 iter/s, 4.81154s/10 iters), loss = 8.65738
I0523 00:47:57.951712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65738 (* 1 = 8.65738 loss)
I0523 00:47:58.018940 34819 sgd_solver.cpp:112] Iteration 21050, lr = 0.01
I0523 00:48:02.089076 34819 solver.cpp:239] Iteration 21060 (2.41711 iter/s, 4.13718s/10 iters), loss = 8.94071
I0523 00:48:02.089135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94071 (* 1 = 8.94071 loss)
I0523 00:48:02.145110 34819 sgd_solver.cpp:112] Iteration 21060, lr = 0.01
I0523 00:48:06.272258 34819 solver.cpp:239] Iteration 21070 (2.39067 iter/s, 4.18293s/10 iters), loss = 8.13343
I0523 00:48:06.272310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13343 (* 1 = 8.13343 loss)
I0523 00:48:06.328588 34819 sgd_solver.cpp:112] Iteration 21070, lr = 0.01
I0523 00:48:11.407855 34819 solver.cpp:239] Iteration 21080 (1.9473 iter/s, 5.13531s/10 iters), loss = 8.2213
I0523 00:48:11.407912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2213 (* 1 = 8.2213 loss)
I0523 00:48:11.501562 34819 sgd_solver.cpp:112] Iteration 21080, lr = 0.01
I0523 00:48:15.489604 34819 solver.cpp:239] Iteration 21090 (2.45007 iter/s, 4.08152s/10 iters), loss = 8.01511
I0523 00:48:15.489648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01511 (* 1 = 8.01511 loss)
I0523 00:48:15.554318 34819 sgd_solver.cpp:112] Iteration 21090, lr = 0.01
I0523 00:48:21.314465 34819 solver.cpp:239] Iteration 21100 (1.71688 iter/s, 5.82453s/10 iters), loss = 8.26945
I0523 00:48:21.314640 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26945 (* 1 = 8.26945 loss)
I0523 00:48:22.171578 34819 sgd_solver.cpp:112] Iteration 21100, lr = 0.01
I0523 00:48:26.373841 34819 solver.cpp:239] Iteration 21110 (1.97668 iter/s, 5.05898s/10 iters), loss = 8.58878
I0523 00:48:26.373904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58878 (* 1 = 8.58878 loss)
I0523 00:48:26.437396 34819 sgd_solver.cpp:112] Iteration 21110, lr = 0.01
I0523 00:48:31.286541 34819 solver.cpp:239] Iteration 21120 (2.03565 iter/s, 4.91243s/10 iters), loss = 9.00776
I0523 00:48:31.286593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00776 (* 1 = 9.00776 loss)
I0523 00:48:31.365058 34819 sgd_solver.cpp:112] Iteration 21120, lr = 0.01
I0523 00:48:35.247290 34819 solver.cpp:239] Iteration 21130 (2.52492 iter/s, 3.96052s/10 iters), loss = 9.38063
I0523 00:48:35.247352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38063 (* 1 = 9.38063 loss)
I0523 00:48:36.017231 34819 sgd_solver.cpp:112] Iteration 21130, lr = 0.01
I0523 00:48:41.855048 34819 solver.cpp:239] Iteration 21140 (1.51345 iter/s, 6.60743s/10 iters), loss = 8.44028
I0523 00:48:41.855105 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44028 (* 1 = 8.44028 loss)
I0523 00:48:42.650504 34819 sgd_solver.cpp:112] Iteration 21140, lr = 0.01
I0523 00:48:47.285058 34819 solver.cpp:239] Iteration 21150 (1.84172 iter/s, 5.42972s/10 iters), loss = 9.04393
I0523 00:48:47.285101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04393 (* 1 = 9.04393 loss)
I0523 00:48:47.359892 34819 sgd_solver.cpp:112] Iteration 21150, lr = 0.01
I0523 00:48:51.666342 34819 solver.cpp:239] Iteration 21160 (2.28255 iter/s, 4.38106s/10 iters), loss = 8.904
I0523 00:48:51.666549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.904 (* 1 = 8.904 loss)
I0523 00:48:52.479085 34819 sgd_solver.cpp:112] Iteration 21160, lr = 0.01
I0523 00:48:56.071491 34819 solver.cpp:239] Iteration 21170 (2.27026 iter/s, 4.40479s/10 iters), loss = 8.6468
I0523 00:48:56.071538 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6468 (* 1 = 8.6468 loss)
I0523 00:48:56.774271 34819 sgd_solver.cpp:112] Iteration 21170, lr = 0.01
I0523 00:49:00.054632 34819 solver.cpp:239] Iteration 21180 (2.51072 iter/s, 3.98292s/10 iters), loss = 8.05379
I0523 00:49:00.054680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05379 (* 1 = 8.05379 loss)
I0523 00:49:00.116556 34819 sgd_solver.cpp:112] Iteration 21180, lr = 0.01
I0523 00:49:07.010882 34819 solver.cpp:239] Iteration 21190 (1.43762 iter/s, 6.95592s/10 iters), loss = 8.37154
I0523 00:49:07.010941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37154 (* 1 = 8.37154 loss)
I0523 00:49:07.086401 34819 sgd_solver.cpp:112] Iteration 21190, lr = 0.01
I0523 00:49:12.391542 34819 solver.cpp:239] Iteration 21200 (1.85861 iter/s, 5.38035s/10 iters), loss = 8.55504
I0523 00:49:12.391594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55504 (* 1 = 8.55504 loss)
I0523 00:49:12.682117 34819 sgd_solver.cpp:112] Iteration 21200, lr = 0.01
I0523 00:49:19.196207 34819 solver.cpp:239] Iteration 21210 (1.46965 iter/s, 6.80434s/10 iters), loss = 8.4364
I0523 00:49:19.196249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4364 (* 1 = 8.4364 loss)
I0523 00:49:20.080126 34819 sgd_solver.cpp:112] Iteration 21210, lr = 0.01
I0523 00:49:26.348018 34819 solver.cpp:239] Iteration 21220 (1.39831 iter/s, 7.15148s/10 iters), loss = 7.95969
I0523 00:49:26.348254 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95969 (* 1 = 7.95969 loss)
I0523 00:49:26.425323 34819 sgd_solver.cpp:112] Iteration 21220, lr = 0.01
I0523 00:49:29.035359 34819 solver.cpp:239] Iteration 21230 (3.72162 iter/s, 2.687s/10 iters), loss = 8.9528
I0523 00:49:29.035415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9528 (* 1 = 8.9528 loss)
I0523 00:49:29.096616 34819 sgd_solver.cpp:112] Iteration 21230, lr = 0.01
I0523 00:49:33.756108 34819 solver.cpp:239] Iteration 21240 (2.11842 iter/s, 4.72049s/10 iters), loss = 8.794
I0523 00:49:33.756163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.794 (* 1 = 8.794 loss)
I0523 00:49:34.342651 34819 sgd_solver.cpp:112] Iteration 21240, lr = 0.01
I0523 00:49:38.973558 34819 solver.cpp:239] Iteration 21250 (1.91674 iter/s, 5.21718s/10 iters), loss = 8.55583
I0523 00:49:38.973616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55583 (* 1 = 8.55583 loss)
I0523 00:49:39.056650 34819 sgd_solver.cpp:112] Iteration 21250, lr = 0.01
I0523 00:49:44.045651 34819 solver.cpp:239] Iteration 21260 (1.97168 iter/s, 5.07182s/10 iters), loss = 9.15358
I0523 00:49:44.045703 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15358 (* 1 = 9.15358 loss)
I0523 00:49:44.106986 34819 sgd_solver.cpp:112] Iteration 21260, lr = 0.01
I0523 00:49:47.768461 34819 solver.cpp:239] Iteration 21270 (2.6863 iter/s, 3.7226s/10 iters), loss = 9.10501
I0523 00:49:47.768510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10501 (* 1 = 9.10501 loss)
I0523 00:49:48.603626 34819 sgd_solver.cpp:112] Iteration 21270, lr = 0.01
I0523 00:49:52.637760 34819 solver.cpp:239] Iteration 21280 (2.0538 iter/s, 4.86903s/10 iters), loss = 7.61893
I0523 00:49:52.637814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61893 (* 1 = 7.61893 loss)
I0523 00:49:52.721343 34819 sgd_solver.cpp:112] Iteration 21280, lr = 0.01
I0523 00:49:56.497094 34819 solver.cpp:239] Iteration 21290 (2.59127 iter/s, 3.85911s/10 iters), loss = 8.70173
I0523 00:49:56.497231 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70173 (* 1 = 8.70173 loss)
I0523 00:49:56.578831 34819 sgd_solver.cpp:112] Iteration 21290, lr = 0.01
I0523 00:49:59.237709 34819 solver.cpp:239] Iteration 21300 (3.6492 iter/s, 2.74032s/10 iters), loss = 9.56524
I0523 00:49:59.237763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56524 (* 1 = 9.56524 loss)
I0523 00:50:00.072283 34819 sgd_solver.cpp:112] Iteration 21300, lr = 0.01
I0523 00:50:03.949033 34819 solver.cpp:239] Iteration 21310 (2.12266 iter/s, 4.71107s/10 iters), loss = 8.61629
I0523 00:50:03.949090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61629 (* 1 = 8.61629 loss)
I0523 00:50:04.587393 34819 sgd_solver.cpp:112] Iteration 21310, lr = 0.01
I0523 00:50:09.745805 34819 solver.cpp:239] Iteration 21320 (1.72519 iter/s, 5.79648s/10 iters), loss = 8.45261
I0523 00:50:09.745851 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45261 (* 1 = 8.45261 loss)
I0523 00:50:09.801419 34819 sgd_solver.cpp:112] Iteration 21320, lr = 0.01
I0523 00:50:13.570618 34819 solver.cpp:239] Iteration 21330 (2.61465 iter/s, 3.8246s/10 iters), loss = 8.72704
I0523 00:50:13.570672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72704 (* 1 = 8.72704 loss)
I0523 00:50:13.646286 34819 sgd_solver.cpp:112] Iteration 21330, lr = 0.01
I0523 00:50:17.561879 34819 solver.cpp:239] Iteration 21340 (2.50562 iter/s, 3.99103s/10 iters), loss = 8.65718
I0523 00:50:17.561923 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65718 (* 1 = 8.65718 loss)
I0523 00:50:17.627717 34819 sgd_solver.cpp:112] Iteration 21340, lr = 0.01
I0523 00:50:21.266722 34819 solver.cpp:239] Iteration 21350 (2.69933 iter/s, 3.70462s/10 iters), loss = 8.18636
I0523 00:50:21.266777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18636 (* 1 = 8.18636 loss)
I0523 00:50:21.343040 34819 sgd_solver.cpp:112] Iteration 21350, lr = 0.01
I0523 00:50:24.977345 34819 solver.cpp:239] Iteration 21360 (2.69512 iter/s, 3.71041s/10 iters), loss = 9.11417
I0523 00:50:24.977401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11417 (* 1 = 9.11417 loss)
I0523 00:50:25.053376 34819 sgd_solver.cpp:112] Iteration 21360, lr = 0.01
I0523 00:50:30.627704 34819 solver.cpp:239] Iteration 21370 (1.76989 iter/s, 5.65006s/10 iters), loss = 9.57872
I0523 00:50:30.627884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57872 (* 1 = 9.57872 loss)
I0523 00:50:31.397083 34819 sgd_solver.cpp:112] Iteration 21370, lr = 0.01
I0523 00:50:34.934202 34819 solver.cpp:239] Iteration 21380 (2.32227 iter/s, 4.30614s/10 iters), loss = 8.07263
I0523 00:50:34.934258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07263 (* 1 = 8.07263 loss)
I0523 00:50:35.791751 34819 sgd_solver.cpp:112] Iteration 21380, lr = 0.01
I0523 00:50:40.557909 34819 solver.cpp:239] Iteration 21390 (1.77828 iter/s, 5.62341s/10 iters), loss = 8.22615
I0523 00:50:40.557952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22615 (* 1 = 8.22615 loss)
I0523 00:50:40.615502 34819 sgd_solver.cpp:112] Iteration 21390, lr = 0.01
I0523 00:50:45.661456 34819 solver.cpp:239] Iteration 21400 (1.95953 iter/s, 5.10327s/10 iters), loss = 7.26646
I0523 00:50:45.661499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26646 (* 1 = 7.26646 loss)
I0523 00:50:46.363682 34819 sgd_solver.cpp:112] Iteration 21400, lr = 0.01
I0523 00:50:50.565094 34819 solver.cpp:239] Iteration 21410 (2.03941 iter/s, 4.90339s/10 iters), loss = 8.12163
I0523 00:50:50.565151 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12163 (* 1 = 8.12163 loss)
I0523 00:50:50.626798 34819 sgd_solver.cpp:112] Iteration 21410, lr = 0.01
I0523 00:50:54.674239 34819 solver.cpp:239] Iteration 21420 (2.43374 iter/s, 4.1089s/10 iters), loss = 8.50134
I0523 00:50:54.674294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50134 (* 1 = 8.50134 loss)
I0523 00:50:54.746665 34819 sgd_solver.cpp:112] Iteration 21420, lr = 0.01
I0523 00:50:58.619138 34819 solver.cpp:239] Iteration 21430 (2.53506 iter/s, 3.94467s/10 iters), loss = 8.69019
I0523 00:50:58.619200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69019 (* 1 = 8.69019 loss)
I0523 00:50:58.670874 34819 sgd_solver.cpp:112] Iteration 21430, lr = 0.01
I0523 00:51:01.689909 34819 solver.cpp:239] Iteration 21440 (3.25672 iter/s, 3.07057s/10 iters), loss = 9.08385
I0523 00:51:01.690075 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08385 (* 1 = 9.08385 loss)
I0523 00:51:02.442991 34819 sgd_solver.cpp:112] Iteration 21440, lr = 0.01
I0523 00:51:07.934944 34819 solver.cpp:239] Iteration 21450 (1.60138 iter/s, 6.24461s/10 iters), loss = 8.43197
I0523 00:51:07.934988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43197 (* 1 = 8.43197 loss)
I0523 00:51:07.995296 34819 sgd_solver.cpp:112] Iteration 21450, lr = 0.01
I0523 00:51:12.565037 34819 solver.cpp:239] Iteration 21460 (2.15991 iter/s, 4.62982s/10 iters), loss = 9.62037
I0523 00:51:12.565079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.62037 (* 1 = 9.62037 loss)
I0523 00:51:12.633496 34819 sgd_solver.cpp:112] Iteration 21460, lr = 0.01
I0523 00:51:16.839100 34819 solver.cpp:239] Iteration 21470 (2.33983 iter/s, 4.27381s/10 iters), loss = 8.56535
I0523 00:51:16.839146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56535 (* 1 = 8.56535 loss)
I0523 00:51:17.698516 34819 sgd_solver.cpp:112] Iteration 21470, lr = 0.01
I0523 00:51:23.148871 34819 solver.cpp:239] Iteration 21480 (1.58492 iter/s, 6.30947s/10 iters), loss = 8.49872
I0523 00:51:23.148922 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49872 (* 1 = 8.49872 loss)
I0523 00:51:23.204671 34819 sgd_solver.cpp:112] Iteration 21480, lr = 0.01
I0523 00:51:29.479557 34819 solver.cpp:239] Iteration 21490 (1.57969 iter/s, 6.33036s/10 iters), loss = 8.46895
I0523 00:51:29.479610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46895 (* 1 = 8.46895 loss)
I0523 00:51:29.548625 34819 sgd_solver.cpp:112] Iteration 21490, lr = 0.01
I0523 00:51:35.156235 34819 solver.cpp:239] Iteration 21500 (1.76169 iter/s, 5.67638s/10 iters), loss = 8.43048
I0523 00:51:35.156353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43048 (* 1 = 8.43048 loss)
I0523 00:51:35.995600 34819 sgd_solver.cpp:112] Iteration 21500, lr = 0.01
I0523 00:51:39.166622 34819 solver.cpp:239] Iteration 21510 (2.49371 iter/s, 4.01008s/10 iters), loss = 8.3285
I0523 00:51:39.166682 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3285 (* 1 = 8.3285 loss)
I0523 00:51:39.236062 34819 sgd_solver.cpp:112] Iteration 21510, lr = 0.01
I0523 00:51:44.817245 34819 solver.cpp:239] Iteration 21520 (1.76981 iter/s, 5.65031s/10 iters), loss = 8.86324
I0523 00:51:44.817308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86324 (* 1 = 8.86324 loss)
I0523 00:51:45.589215 34819 sgd_solver.cpp:112] Iteration 21520, lr = 0.01
I0523 00:51:48.691309 34819 solver.cpp:239] Iteration 21530 (2.58143 iter/s, 3.87383s/10 iters), loss = 9.03747
I0523 00:51:48.691362 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03747 (* 1 = 9.03747 loss)
I0523 00:51:49.208081 34819 sgd_solver.cpp:112] Iteration 21530, lr = 0.01
I0523 00:51:51.794642 34819 solver.cpp:239] Iteration 21540 (3.22254 iter/s, 3.10314s/10 iters), loss = 7.96183
I0523 00:51:51.794709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96183 (* 1 = 7.96183 loss)
I0523 00:51:51.871208 34819 sgd_solver.cpp:112] Iteration 21540, lr = 0.01
I0523 00:51:56.596240 34819 solver.cpp:239] Iteration 21550 (2.08275 iter/s, 4.80133s/10 iters), loss = 8.05292
I0523 00:51:56.596289 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05292 (* 1 = 8.05292 loss)
I0523 00:51:56.653955 34819 sgd_solver.cpp:112] Iteration 21550, lr = 0.01
I0523 00:52:02.294066 34819 solver.cpp:239] Iteration 21560 (1.75514 iter/s, 5.69754s/10 iters), loss = 8.81926
I0523 00:52:02.294107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81926 (* 1 = 8.81926 loss)
I0523 00:52:02.841563 34819 sgd_solver.cpp:112] Iteration 21560, lr = 0.01
I0523 00:52:07.256939 34819 solver.cpp:239] Iteration 21570 (2.01507 iter/s, 4.96262s/10 iters), loss = 8.56803
I0523 00:52:07.257071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56803 (* 1 = 8.56803 loss)
I0523 00:52:08.031946 34819 sgd_solver.cpp:112] Iteration 21570, lr = 0.01
I0523 00:52:13.687218 34819 solver.cpp:239] Iteration 21580 (1.55524 iter/s, 6.42987s/10 iters), loss = 8.35539
I0523 00:52:13.687269 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35539 (* 1 = 8.35539 loss)
I0523 00:52:14.421648 34819 sgd_solver.cpp:112] Iteration 21580, lr = 0.01
I0523 00:52:19.352897 34819 solver.cpp:239] Iteration 21590 (1.76511 iter/s, 5.66538s/10 iters), loss = 8.79086
I0523 00:52:19.352960 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79086 (* 1 = 8.79086 loss)
I0523 00:52:19.423071 34819 sgd_solver.cpp:112] Iteration 21590, lr = 0.01
I0523 00:52:24.403707 34819 solver.cpp:239] Iteration 21600 (1.97999 iter/s, 5.05054s/10 iters), loss = 8.85445
I0523 00:52:24.403761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85445 (* 1 = 8.85445 loss)
I0523 00:52:24.475956 34819 sgd_solver.cpp:112] Iteration 21600, lr = 0.01
I0523 00:52:29.561800 34819 solver.cpp:239] Iteration 21610 (1.9388 iter/s, 5.15782s/10 iters), loss = 8.11384
I0523 00:52:29.561842 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11384 (* 1 = 8.11384 loss)
I0523 00:52:30.410845 34819 sgd_solver.cpp:112] Iteration 21610, lr = 0.01
I0523 00:52:35.129961 34819 solver.cpp:239] Iteration 21620 (1.79602 iter/s, 5.56788s/10 iters), loss = 9.74596
I0523 00:52:35.130003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74596 (* 1 = 9.74596 loss)
I0523 00:52:35.744374 34819 sgd_solver.cpp:112] Iteration 21620, lr = 0.01
I0523 00:52:40.110123 34819 solver.cpp:239] Iteration 21630 (2.00807 iter/s, 4.9799s/10 iters), loss = 9.26094
I0523 00:52:40.110347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26094 (* 1 = 9.26094 loss)
I0523 00:52:40.187289 34819 sgd_solver.cpp:112] Iteration 21630, lr = 0.01
I0523 00:52:43.761852 34819 solver.cpp:239] Iteration 21640 (2.7387 iter/s, 3.65137s/10 iters), loss = 6.99685
I0523 00:52:43.761906 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.99685 (* 1 = 6.99685 loss)
I0523 00:52:44.595196 34819 sgd_solver.cpp:112] Iteration 21640, lr = 0.01
I0523 00:52:48.776568 34819 solver.cpp:239] Iteration 21650 (1.99424 iter/s, 5.01444s/10 iters), loss = 7.91007
I0523 00:52:48.776623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91007 (* 1 = 7.91007 loss)
I0523 00:52:48.834123 34819 sgd_solver.cpp:112] Iteration 21650, lr = 0.01
I0523 00:52:53.745015 34819 solver.cpp:239] Iteration 21660 (2.01281 iter/s, 4.96817s/10 iters), loss = 8.28541
I0523 00:52:53.745069 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28541 (* 1 = 8.28541 loss)
I0523 00:52:53.805681 34819 sgd_solver.cpp:112] Iteration 21660, lr = 0.01
I0523 00:52:58.359727 34819 solver.cpp:239] Iteration 21670 (2.1671 iter/s, 4.61446s/10 iters), loss = 8.93809
I0523 00:52:58.359779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93809 (* 1 = 8.93809 loss)
I0523 00:52:58.422607 34819 sgd_solver.cpp:112] Iteration 21670, lr = 0.01
I0523 00:53:05.582787 34819 solver.cpp:239] Iteration 21680 (1.38452 iter/s, 7.2227s/10 iters), loss = 8.36039
I0523 00:53:05.582837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36039 (* 1 = 8.36039 loss)
I0523 00:53:06.126039 34819 sgd_solver.cpp:112] Iteration 21680, lr = 0.01
I0523 00:53:09.531126 34819 solver.cpp:239] Iteration 21690 (2.53286 iter/s, 3.94811s/10 iters), loss = 8.70131
I0523 00:53:09.531181 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70131 (* 1 = 8.70131 loss)
I0523 00:53:10.145517 34819 sgd_solver.cpp:112] Iteration 21690, lr = 0.01
I0523 00:53:14.406574 34819 solver.cpp:239] Iteration 21700 (2.05121 iter/s, 4.87516s/10 iters), loss = 8.36244
I0523 00:53:14.406627 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36244 (* 1 = 8.36244 loss)
I0523 00:53:15.206696 34819 sgd_solver.cpp:112] Iteration 21700, lr = 0.01
I0523 00:53:18.934242 34819 solver.cpp:239] Iteration 21710 (2.20876 iter/s, 4.52742s/10 iters), loss = 8.58344
I0523 00:53:18.934286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58344 (* 1 = 8.58344 loss)
I0523 00:53:19.002650 34819 sgd_solver.cpp:112] Iteration 21710, lr = 0.01
I0523 00:53:24.406675 34819 solver.cpp:239] Iteration 21720 (1.82743 iter/s, 5.47215s/10 iters), loss = 8.34132
I0523 00:53:24.406733 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34132 (* 1 = 8.34132 loss)
I0523 00:53:24.965344 34819 sgd_solver.cpp:112] Iteration 21720, lr = 0.01
I0523 00:53:28.924242 34819 solver.cpp:239] Iteration 21730 (2.21371 iter/s, 4.51731s/10 iters), loss = 9.02026
I0523 00:53:28.924289 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02026 (* 1 = 9.02026 loss)
I0523 00:53:28.992857 34819 sgd_solver.cpp:112] Iteration 21730, lr = 0.01
I0523 00:53:37.314641 34819 solver.cpp:239] Iteration 21740 (1.1919 iter/s, 8.39s/10 iters), loss = 8.30347
I0523 00:53:37.314712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30347 (* 1 = 8.30347 loss)
I0523 00:53:37.386668 34819 sgd_solver.cpp:112] Iteration 21740, lr = 0.01
I0523 00:53:41.675175 34819 solver.cpp:239] Iteration 21750 (2.29343 iter/s, 4.36029s/10 iters), loss = 9.20024
I0523 00:53:41.675420 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20024 (* 1 = 9.20024 loss)
I0523 00:53:41.737344 34819 sgd_solver.cpp:112] Iteration 21750, lr = 0.01
I0523 00:53:47.470269 34819 solver.cpp:239] Iteration 21760 (1.72573 iter/s, 5.79465s/10 iters), loss = 8.63323
I0523 00:53:47.470315 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63323 (* 1 = 8.63323 loss)
I0523 00:53:47.530319 34819 sgd_solver.cpp:112] Iteration 21760, lr = 0.01
I0523 00:53:51.876195 34819 solver.cpp:239] Iteration 21770 (2.26979 iter/s, 4.4057s/10 iters), loss = 7.13077
I0523 00:53:51.876240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13077 (* 1 = 7.13077 loss)
I0523 00:53:51.934326 34819 sgd_solver.cpp:112] Iteration 21770, lr = 0.01
I0523 00:53:55.141826 34819 solver.cpp:239] Iteration 21780 (3.06237 iter/s, 3.26544s/10 iters), loss = 7.0184
I0523 00:53:55.141872 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.0184 (* 1 = 7.0184 loss)
I0523 00:53:56.026141 34819 sgd_solver.cpp:112] Iteration 21780, lr = 0.01
I0523 00:53:58.965075 34819 solver.cpp:239] Iteration 21790 (2.61572 iter/s, 3.82304s/10 iters), loss = 8.86847
I0523 00:53:58.965131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86847 (* 1 = 8.86847 loss)
I0523 00:53:59.050202 34819 sgd_solver.cpp:112] Iteration 21790, lr = 0.01
I0523 00:54:03.067986 34819 solver.cpp:239] Iteration 21800 (2.43743 iter/s, 4.10269s/10 iters), loss = 9.21576
I0523 00:54:03.068032 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21576 (* 1 = 9.21576 loss)
I0523 00:54:03.907752 34819 sgd_solver.cpp:112] Iteration 21800, lr = 0.01
I0523 00:54:10.020237 34819 solver.cpp:239] Iteration 21810 (1.43845 iter/s, 6.95192s/10 iters), loss = 7.54495
I0523 00:54:10.020282 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54495 (* 1 = 7.54495 loss)
I0523 00:54:10.842259 34819 sgd_solver.cpp:112] Iteration 21810, lr = 0.01
I0523 00:54:15.816494 34819 solver.cpp:239] Iteration 21820 (1.72534 iter/s, 5.79597s/10 iters), loss = 8.62899
I0523 00:54:15.816637 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62899 (* 1 = 8.62899 loss)
I0523 00:54:16.586832 34819 sgd_solver.cpp:112] Iteration 21820, lr = 0.01
I0523 00:54:21.910063 34819 solver.cpp:239] Iteration 21830 (1.64118 iter/s, 6.09317s/10 iters), loss = 9.87863
I0523 00:54:21.910106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.87863 (* 1 = 9.87863 loss)
I0523 00:54:21.984047 34819 sgd_solver.cpp:112] Iteration 21830, lr = 0.01
I0523 00:54:25.753417 34819 solver.cpp:239] Iteration 21840 (2.60204 iter/s, 3.84314s/10 iters), loss = 8.2803
I0523 00:54:25.753475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2803 (* 1 = 8.2803 loss)
I0523 00:54:26.471649 34819 sgd_solver.cpp:112] Iteration 21840, lr = 0.01
I0523 00:54:31.154291 34819 solver.cpp:239] Iteration 21850 (1.85165 iter/s, 5.40058s/10 iters), loss = 8.42658
I0523 00:54:31.154350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42658 (* 1 = 8.42658 loss)
I0523 00:54:31.227809 34819 sgd_solver.cpp:112] Iteration 21850, lr = 0.01
I0523 00:54:37.652211 34819 solver.cpp:239] Iteration 21860 (1.53903 iter/s, 6.4976s/10 iters), loss = 9.40086
I0523 00:54:37.652258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40086 (* 1 = 9.40086 loss)
I0523 00:54:37.703588 34819 sgd_solver.cpp:112] Iteration 21860, lr = 0.01
I0523 00:54:40.381531 34819 solver.cpp:239] Iteration 21870 (3.66415 iter/s, 2.72915s/10 iters), loss = 9.22754
I0523 00:54:40.381602 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22754 (* 1 = 9.22754 loss)
I0523 00:54:40.439486 34819 sgd_solver.cpp:112] Iteration 21870, lr = 0.01
I0523 00:54:45.051761 34819 solver.cpp:239] Iteration 21880 (2.14136 iter/s, 4.66992s/10 iters), loss = 8.88748
I0523 00:54:45.051870 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88748 (* 1 = 8.88748 loss)
I0523 00:54:45.583384 34819 sgd_solver.cpp:112] Iteration 21880, lr = 0.01
I0523 00:54:50.040585 34819 solver.cpp:239] Iteration 21890 (2.0046 iter/s, 4.98852s/10 iters), loss = 9.27729
I0523 00:54:50.040813 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27729 (* 1 = 9.27729 loss)
I0523 00:54:50.835687 34819 sgd_solver.cpp:112] Iteration 21890, lr = 0.01
I0523 00:54:56.098929 34819 solver.cpp:239] Iteration 21900 (1.65074 iter/s, 6.05788s/10 iters), loss = 8.65848
I0523 00:54:56.098975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65848 (* 1 = 8.65848 loss)
I0523 00:54:56.157972 34819 sgd_solver.cpp:112] Iteration 21900, lr = 0.01
I0523 00:55:01.769145 34819 solver.cpp:239] Iteration 21910 (1.76369 iter/s, 5.66994s/10 iters), loss = 8.81732
I0523 00:55:01.769199 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81732 (* 1 = 8.81732 loss)
I0523 00:55:02.525804 34819 sgd_solver.cpp:112] Iteration 21910, lr = 0.01
I0523 00:55:07.724335 34819 solver.cpp:239] Iteration 21920 (1.67929 iter/s, 5.9549s/10 iters), loss = 9.46856
I0523 00:55:07.724382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46856 (* 1 = 9.46856 loss)
I0523 00:55:07.781436 34819 sgd_solver.cpp:112] Iteration 21920, lr = 0.01
I0523 00:55:12.090445 34819 solver.cpp:239] Iteration 21930 (2.29049 iter/s, 4.36588s/10 iters), loss = 8.55321
I0523 00:55:12.090500 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55321 (* 1 = 8.55321 loss)
I0523 00:55:12.301903 34819 sgd_solver.cpp:112] Iteration 21930, lr = 0.01
I0523 00:55:17.296820 34819 solver.cpp:239] Iteration 21940 (1.92082 iter/s, 5.20611s/10 iters), loss = 8.62199
I0523 00:55:17.296864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62199 (* 1 = 8.62199 loss)
I0523 00:55:17.348199 34819 sgd_solver.cpp:112] Iteration 21940, lr = 0.01
I0523 00:55:22.182772 34819 solver.cpp:239] Iteration 21950 (2.04679 iter/s, 4.88569s/10 iters), loss = 9.67995
I0523 00:55:22.182924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67995 (* 1 = 9.67995 loss)
I0523 00:55:22.908856 34819 sgd_solver.cpp:112] Iteration 21950, lr = 0.01
I0523 00:55:28.391299 34819 solver.cpp:239] Iteration 21960 (1.6108 iter/s, 6.2081s/10 iters), loss = 7.84261
I0523 00:55:28.391361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84261 (* 1 = 7.84261 loss)
I0523 00:55:29.113664 34819 sgd_solver.cpp:112] Iteration 21960, lr = 0.01
I0523 00:55:33.839993 34819 solver.cpp:239] Iteration 21970 (1.8354 iter/s, 5.4484s/10 iters), loss = 8.386
I0523 00:55:33.840036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.386 (* 1 = 8.386 loss)
I0523 00:55:33.895401 34819 sgd_solver.cpp:112] Iteration 21970, lr = 0.01
I0523 00:55:38.720976 34819 solver.cpp:239] Iteration 21980 (2.04887 iter/s, 4.88074s/10 iters), loss = 8.24392
I0523 00:55:38.721019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24392 (* 1 = 8.24392 loss)
I0523 00:55:39.379811 34819 sgd_solver.cpp:112] Iteration 21980, lr = 0.01
I0523 00:55:42.602790 34819 solver.cpp:239] Iteration 21990 (2.57626 iter/s, 3.8816s/10 iters), loss = 9.56601
I0523 00:55:42.602840 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56601 (* 1 = 9.56601 loss)
I0523 00:55:43.302301 34819 sgd_solver.cpp:112] Iteration 21990, lr = 0.01
I0523 00:55:48.496616 34819 solver.cpp:239] Iteration 22000 (1.69678 iter/s, 5.89353s/10 iters), loss = 8.29926
I0523 00:55:48.496659 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29926 (* 1 = 8.29926 loss)
I0523 00:55:48.559744 34819 sgd_solver.cpp:112] Iteration 22000, lr = 0.01
I0523 00:55:52.831574 34819 solver.cpp:239] Iteration 22010 (2.30695 iter/s, 4.33473s/10 iters), loss = 9.09758
I0523 00:55:52.831739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09758 (* 1 = 9.09758 loss)
I0523 00:55:52.892753 34819 sgd_solver.cpp:112] Iteration 22010, lr = 0.01
I0523 00:55:57.097589 34819 solver.cpp:239] Iteration 22020 (2.3443 iter/s, 4.26567s/10 iters), loss = 8.77702
I0523 00:55:57.097631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77702 (* 1 = 8.77702 loss)
I0523 00:55:57.964905 34819 sgd_solver.cpp:112] Iteration 22020, lr = 0.01
I0523 00:56:02.833235 34819 solver.cpp:239] Iteration 22030 (1.74357 iter/s, 5.73537s/10 iters), loss = 9.13882
I0523 00:56:02.833283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13882 (* 1 = 9.13882 loss)
I0523 00:56:03.667809 34819 sgd_solver.cpp:112] Iteration 22030, lr = 0.01
I0523 00:56:09.389521 34819 solver.cpp:239] Iteration 22040 (1.52533 iter/s, 6.55595s/10 iters), loss = 8.65633
I0523 00:56:09.389581 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65633 (* 1 = 8.65633 loss)
I0523 00:56:10.229949 34819 sgd_solver.cpp:112] Iteration 22040, lr = 0.01
I0523 00:56:15.670023 34819 solver.cpp:239] Iteration 22050 (1.59231 iter/s, 6.28018s/10 iters), loss = 7.92249
I0523 00:56:15.670081 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92249 (* 1 = 7.92249 loss)
I0523 00:56:16.325778 34819 sgd_solver.cpp:112] Iteration 22050, lr = 0.01
I0523 00:56:19.529093 34819 solver.cpp:239] Iteration 22060 (2.59145 iter/s, 3.85884s/10 iters), loss = 9.27087
I0523 00:56:19.529145 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27087 (* 1 = 9.27087 loss)
I0523 00:56:19.595124 34819 sgd_solver.cpp:112] Iteration 22060, lr = 0.01
I0523 00:56:24.597477 34819 solver.cpp:239] Iteration 22070 (1.97312 iter/s, 5.06811s/10 iters), loss = 9.05017
I0523 00:56:24.597628 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05017 (* 1 = 9.05017 loss)
I0523 00:56:24.883070 34819 sgd_solver.cpp:112] Iteration 22070, lr = 0.01
I0523 00:56:29.434866 34819 solver.cpp:239] Iteration 22080 (2.06738 iter/s, 4.83704s/10 iters), loss = 9.62675
I0523 00:56:29.434933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.62675 (* 1 = 9.62675 loss)
I0523 00:56:29.493129 34819 sgd_solver.cpp:112] Iteration 22080, lr = 0.01
I0523 00:56:34.552080 34819 solver.cpp:239] Iteration 22090 (1.9543 iter/s, 5.11693s/10 iters), loss = 9.60236
I0523 00:56:34.552130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60236 (* 1 = 9.60236 loss)
I0523 00:56:34.610260 34819 sgd_solver.cpp:112] Iteration 22090, lr = 0.01
I0523 00:56:41.117645 34819 solver.cpp:239] Iteration 22100 (1.52317 iter/s, 6.56525s/10 iters), loss = 8.45497
I0523 00:56:41.117702 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45497 (* 1 = 8.45497 loss)
I0523 00:56:41.465317 34819 sgd_solver.cpp:112] Iteration 22100, lr = 0.01
I0523 00:56:46.117391 34819 solver.cpp:239] Iteration 22110 (2.00021 iter/s, 4.99948s/10 iters), loss = 8.75044
I0523 00:56:46.117447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75044 (* 1 = 8.75044 loss)
I0523 00:56:46.195336 34819 sgd_solver.cpp:112] Iteration 22110, lr = 0.01
I0523 00:56:52.335398 34819 solver.cpp:239] Iteration 22120 (1.60831 iter/s, 6.2177s/10 iters), loss = 8.00858
I0523 00:56:52.335451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00858 (* 1 = 8.00858 loss)
I0523 00:56:52.560120 34819 sgd_solver.cpp:112] Iteration 22120, lr = 0.01
I0523 00:56:56.458348 34819 solver.cpp:239] Iteration 22130 (2.42558 iter/s, 4.12272s/10 iters), loss = 8.63776
I0523 00:56:56.458492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63776 (* 1 = 8.63776 loss)
I0523 00:56:56.544908 34819 sgd_solver.cpp:112] Iteration 22130, lr = 0.01
I0523 00:56:59.947854 34819 solver.cpp:239] Iteration 22140 (2.86598 iter/s, 3.48921s/10 iters), loss = 8.85717
I0523 00:56:59.947898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85717 (* 1 = 8.85717 loss)
I0523 00:57:00.002020 34819 sgd_solver.cpp:112] Iteration 22140, lr = 0.01
I0523 00:57:03.634016 34819 solver.cpp:239] Iteration 22150 (2.71301 iter/s, 3.68595s/10 iters), loss = 8.53912
I0523 00:57:03.634063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53912 (* 1 = 8.53912 loss)
I0523 00:57:04.473579 34819 sgd_solver.cpp:112] Iteration 22150, lr = 0.01
I0523 00:57:10.390630 34819 solver.cpp:239] Iteration 22160 (1.4801 iter/s, 6.75629s/10 iters), loss = 8.41542
I0523 00:57:10.390686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41542 (* 1 = 8.41542 loss)
I0523 00:57:10.452165 34819 sgd_solver.cpp:112] Iteration 22160, lr = 0.01
I0523 00:57:15.727444 34819 solver.cpp:239] Iteration 22170 (1.87388 iter/s, 5.33652s/10 iters), loss = 8.87965
I0523 00:57:15.727504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87965 (* 1 = 8.87965 loss)
I0523 00:57:16.495199 34819 sgd_solver.cpp:112] Iteration 22170, lr = 0.01
I0523 00:57:22.484381 34819 solver.cpp:239] Iteration 22180 (1.48003 iter/s, 6.7566s/10 iters), loss = 9.26344
I0523 00:57:22.484436 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26344 (* 1 = 9.26344 loss)
I0523 00:57:22.553488 34819 sgd_solver.cpp:112] Iteration 22180, lr = 0.01
I0523 00:57:27.281926 34819 solver.cpp:239] Iteration 22190 (2.08451 iter/s, 4.79729s/10 iters), loss = 9.19531
I0523 00:57:27.282073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19531 (* 1 = 9.19531 loss)
I0523 00:57:27.352887 34819 sgd_solver.cpp:112] Iteration 22190, lr = 0.01
I0523 00:57:33.792776 34819 solver.cpp:239] Iteration 22200 (1.536 iter/s, 6.51043s/10 iters), loss = 8.35454
I0523 00:57:33.792836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35454 (* 1 = 8.35454 loss)
I0523 00:57:34.373648 34819 sgd_solver.cpp:112] Iteration 22200, lr = 0.01
I0523 00:57:37.646886 34819 solver.cpp:239] Iteration 22210 (2.59479 iter/s, 3.85388s/10 iters), loss = 8.47639
I0523 00:57:37.646941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47639 (* 1 = 8.47639 loss)
I0523 00:57:38.483844 34819 sgd_solver.cpp:112] Iteration 22210, lr = 0.01
I0523 00:57:41.379721 34819 solver.cpp:239] Iteration 22220 (2.67908 iter/s, 3.73262s/10 iters), loss = 7.92065
I0523 00:57:41.379779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92065 (* 1 = 7.92065 loss)
I0523 00:57:41.585322 34819 sgd_solver.cpp:112] Iteration 22220, lr = 0.01
I0523 00:57:47.023679 34819 solver.cpp:239] Iteration 22230 (1.7719 iter/s, 5.64366s/10 iters), loss = 8.46877
I0523 00:57:47.023725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46877 (* 1 = 8.46877 loss)
I0523 00:57:47.835530 34819 sgd_solver.cpp:112] Iteration 22230, lr = 0.01
I0523 00:57:52.056109 34819 solver.cpp:239] Iteration 22240 (1.98721 iter/s, 5.03217s/10 iters), loss = 8.14853
I0523 00:57:52.056151 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14853 (* 1 = 8.14853 loss)
I0523 00:57:52.843952 34819 sgd_solver.cpp:112] Iteration 22240, lr = 0.01
I0523 00:57:57.178664 34819 solver.cpp:239] Iteration 22250 (1.95225 iter/s, 5.1223s/10 iters), loss = 7.77377
I0523 00:57:57.178743 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77377 (* 1 = 7.77377 loss)
I0523 00:57:58.013456 34819 sgd_solver.cpp:112] Iteration 22250, lr = 0.01
I0523 00:58:02.900710 34819 solver.cpp:239] Iteration 22260 (1.74773 iter/s, 5.72172s/10 iters), loss = 8.49609
I0523 00:58:02.900756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49609 (* 1 = 8.49609 loss)
I0523 00:58:02.971894 34819 sgd_solver.cpp:112] Iteration 22260, lr = 0.01
I0523 00:58:07.660286 34819 solver.cpp:239] Iteration 22270 (2.10114 iter/s, 4.75932s/10 iters), loss = 9.6849
I0523 00:58:07.660352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6849 (* 1 = 9.6849 loss)
I0523 00:58:08.488188 34819 sgd_solver.cpp:112] Iteration 22270, lr = 0.01
I0523 00:58:15.623456 34819 solver.cpp:239] Iteration 22280 (1.25584 iter/s, 7.96279s/10 iters), loss = 8.35461
I0523 00:58:15.623497 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35461 (* 1 = 8.35461 loss)
I0523 00:58:16.471926 34819 sgd_solver.cpp:112] Iteration 22280, lr = 0.01
I0523 00:58:22.262059 34819 solver.cpp:239] Iteration 22290 (1.50641 iter/s, 6.6383s/10 iters), loss = 8.09199
I0523 00:58:22.262104 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09199 (* 1 = 8.09199 loss)
I0523 00:58:22.324635 34819 sgd_solver.cpp:112] Iteration 22290, lr = 0.01
I0523 00:58:25.709168 34819 solver.cpp:239] Iteration 22300 (2.90115 iter/s, 3.44691s/10 iters), loss = 8.41953
I0523 00:58:25.709223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41953 (* 1 = 8.41953 loss)
I0523 00:58:26.510979 34819 sgd_solver.cpp:112] Iteration 22300, lr = 0.01
I0523 00:58:33.218513 34819 solver.cpp:239] Iteration 22310 (1.33174 iter/s, 7.50897s/10 iters), loss = 8.49971
I0523 00:58:33.218649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49971 (* 1 = 8.49971 loss)
I0523 00:58:33.422849 34819 sgd_solver.cpp:112] Iteration 22310, lr = 0.01
I0523 00:58:37.185425 34819 solver.cpp:239] Iteration 22320 (2.52105 iter/s, 3.96661s/10 iters), loss = 9.60791
I0523 00:58:37.185479 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60791 (* 1 = 9.60791 loss)
I0523 00:58:37.270779 34819 sgd_solver.cpp:112] Iteration 22320, lr = 0.01
I0523 00:58:42.849303 34819 solver.cpp:239] Iteration 22330 (1.76567 iter/s, 5.66359s/10 iters), loss = 9.72418
I0523 00:58:42.849356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72418 (* 1 = 9.72418 loss)
I0523 00:58:43.658100 34819 sgd_solver.cpp:112] Iteration 22330, lr = 0.01
I0523 00:58:49.997406 34819 solver.cpp:239] Iteration 22340 (1.39904 iter/s, 7.14774s/10 iters), loss = 8.70526
I0523 00:58:49.997474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70526 (* 1 = 8.70526 loss)
I0523 00:58:50.067289 34819 sgd_solver.cpp:112] Iteration 22340, lr = 0.01
I0523 00:58:54.889511 34819 solver.cpp:239] Iteration 22350 (2.04422 iter/s, 4.89183s/10 iters), loss = 8.56293
I0523 00:58:54.889567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56293 (* 1 = 8.56293 loss)
I0523 00:58:54.966307 34819 sgd_solver.cpp:112] Iteration 22350, lr = 0.01
I0523 00:58:59.085196 34819 solver.cpp:239] Iteration 22360 (2.38354 iter/s, 4.19544s/10 iters), loss = 8.73733
I0523 00:58:59.085263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73733 (* 1 = 8.73733 loss)
I0523 00:58:59.135741 34819 sgd_solver.cpp:112] Iteration 22360, lr = 0.01
I0523 00:59:01.404378 34819 solver.cpp:239] Iteration 22370 (4.31218 iter/s, 2.31901s/10 iters), loss = 8.04243
I0523 00:59:01.404438 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04243 (* 1 = 8.04243 loss)
I0523 00:59:01.479318 34819 sgd_solver.cpp:112] Iteration 22370, lr = 0.01
I0523 00:59:05.421447 34819 solver.cpp:239] Iteration 22380 (2.48952 iter/s, 4.01684s/10 iters), loss = 8.15236
I0523 00:59:05.421633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15236 (* 1 = 8.15236 loss)
I0523 00:59:05.477126 34819 sgd_solver.cpp:112] Iteration 22380, lr = 0.01
I0523 00:59:11.193132 34819 solver.cpp:239] Iteration 22390 (1.73272 iter/s, 5.77128s/10 iters), loss = 9.40573
I0523 00:59:11.193186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40573 (* 1 = 9.40573 loss)
I0523 00:59:11.246075 34819 sgd_solver.cpp:112] Iteration 22390, lr = 0.01
I0523 00:59:17.404029 34819 solver.cpp:239] Iteration 22400 (1.61016 iter/s, 6.21057s/10 iters), loss = 8.64261
I0523 00:59:17.404080 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64261 (* 1 = 8.64261 loss)
I0523 00:59:17.470127 34819 sgd_solver.cpp:112] Iteration 22400, lr = 0.01
I0523 00:59:22.263226 34819 solver.cpp:239] Iteration 22410 (2.05806 iter/s, 4.85894s/10 iters), loss = 8.1317
I0523 00:59:22.263263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1317 (* 1 = 8.1317 loss)
I0523 00:59:22.340134 34819 sgd_solver.cpp:112] Iteration 22410, lr = 0.01
I0523 00:59:27.703055 34819 solver.cpp:239] Iteration 22420 (1.83838 iter/s, 5.43957s/10 iters), loss = 8.40794
I0523 00:59:27.703106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40794 (* 1 = 8.40794 loss)
I0523 00:59:27.785663 34819 sgd_solver.cpp:112] Iteration 22420, lr = 0.01
I0523 00:59:34.011801 34819 solver.cpp:239] Iteration 22430 (1.58518 iter/s, 6.30843s/10 iters), loss = 8.55087
I0523 00:59:34.011871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55087 (* 1 = 8.55087 loss)
I0523 00:59:34.085676 34819 sgd_solver.cpp:112] Iteration 22430, lr = 0.01
I0523 00:59:38.194236 34819 solver.cpp:239] Iteration 22440 (2.39109 iter/s, 4.18219s/10 iters), loss = 9.39572
I0523 00:59:38.194422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39572 (* 1 = 9.39572 loss)
I0523 00:59:38.244314 34819 sgd_solver.cpp:112] Iteration 22440, lr = 0.01
I0523 00:59:43.104362 34819 solver.cpp:239] Iteration 22450 (2.03677 iter/s, 4.90974s/10 iters), loss = 8.31681
I0523 00:59:43.104409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31681 (* 1 = 8.31681 loss)
I0523 00:59:43.169077 34819 sgd_solver.cpp:112] Iteration 22450, lr = 0.01
I0523 00:59:47.557339 34819 solver.cpp:239] Iteration 22460 (2.24583 iter/s, 4.45271s/10 iters), loss = 8.29028
I0523 00:59:47.557392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29028 (* 1 = 8.29028 loss)
I0523 00:59:48.297240 34819 sgd_solver.cpp:112] Iteration 22460, lr = 0.01
I0523 00:59:51.865268 34819 solver.cpp:239] Iteration 22470 (2.32143 iter/s, 4.30769s/10 iters), loss = 8.89474
I0523 00:59:51.865325 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89474 (* 1 = 8.89474 loss)
I0523 00:59:52.744024 34819 sgd_solver.cpp:112] Iteration 22470, lr = 0.01
I0523 00:59:56.843730 34819 solver.cpp:239] Iteration 22480 (2.00876 iter/s, 4.9782s/10 iters), loss = 8.29308
I0523 00:59:56.843785 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29308 (* 1 = 8.29308 loss)
I0523 00:59:56.915922 34819 sgd_solver.cpp:112] Iteration 22480, lr = 0.01
I0523 01:00:01.144345 34819 solver.cpp:239] Iteration 22490 (2.3254 iter/s, 4.30034s/10 iters), loss = 7.87351
I0523 01:00:01.144392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87351 (* 1 = 7.87351 loss)
I0523 01:00:01.949389 34819 sgd_solver.cpp:112] Iteration 22490, lr = 0.01
I0523 01:00:05.895965 34819 solver.cpp:239] Iteration 22500 (2.10466 iter/s, 4.75136s/10 iters), loss = 8.68157
I0523 01:00:05.896020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68157 (* 1 = 8.68157 loss)
I0523 01:00:06.378998 34819 sgd_solver.cpp:112] Iteration 22500, lr = 0.01
I0523 01:00:10.427485 34819 solver.cpp:239] Iteration 22510 (2.20688 iter/s, 4.53128s/10 iters), loss = 8.75053
I0523 01:00:10.427578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75053 (* 1 = 8.75053 loss)
I0523 01:00:10.501411 34819 sgd_solver.cpp:112] Iteration 22510, lr = 0.01
I0523 01:00:16.166776 34819 solver.cpp:239] Iteration 22520 (1.74248 iter/s, 5.73896s/10 iters), loss = 8.65118
I0523 01:00:16.166829 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65118 (* 1 = 8.65118 loss)
I0523 01:00:16.226337 34819 sgd_solver.cpp:112] Iteration 22520, lr = 0.01
I0523 01:00:20.807992 34819 solver.cpp:239] Iteration 22530 (2.15472 iter/s, 4.64097s/10 iters), loss = 8.88576
I0523 01:00:20.808048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88576 (* 1 = 8.88576 loss)
I0523 01:00:21.632529 34819 sgd_solver.cpp:112] Iteration 22530, lr = 0.01
I0523 01:00:26.947229 34819 solver.cpp:239] Iteration 22540 (1.62895 iter/s, 6.13893s/10 iters), loss = 9.2996
I0523 01:00:26.947273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2996 (* 1 = 9.2996 loss)
I0523 01:00:27.020095 34819 sgd_solver.cpp:112] Iteration 22540, lr = 0.01
I0523 01:00:32.642549 34819 solver.cpp:239] Iteration 22550 (1.75591 iter/s, 5.69504s/10 iters), loss = 7.95208
I0523 01:00:32.642602 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95208 (* 1 = 7.95208 loss)
I0523 01:00:32.717326 34819 sgd_solver.cpp:112] Iteration 22550, lr = 0.01
I0523 01:00:35.923125 34819 solver.cpp:239] Iteration 22560 (3.04843 iter/s, 3.28038s/10 iters), loss = 9.06906
I0523 01:00:35.923190 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06906 (* 1 = 9.06906 loss)
I0523 01:00:35.987215 34819 sgd_solver.cpp:112] Iteration 22560, lr = 0.01
I0523 01:00:39.519832 34819 solver.cpp:239] Iteration 22570 (2.78049 iter/s, 3.59649s/10 iters), loss = 8.40864
I0523 01:00:39.519889 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40864 (* 1 = 8.40864 loss)
I0523 01:00:40.354604 34819 sgd_solver.cpp:112] Iteration 22570, lr = 0.01
I0523 01:00:43.815366 34819 solver.cpp:239] Iteration 22580 (2.32813 iter/s, 4.29529s/10 iters), loss = 9.05099
I0523 01:00:43.815603 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05099 (* 1 = 9.05099 loss)
I0523 01:00:44.652218 34819 sgd_solver.cpp:112] Iteration 22580, lr = 0.01
I0523 01:00:47.420475 34819 solver.cpp:239] Iteration 22590 (2.77414 iter/s, 3.60473s/10 iters), loss = 9.16693
I0523 01:00:47.420536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16693 (* 1 = 9.16693 loss)
I0523 01:00:47.489027 34819 sgd_solver.cpp:112] Iteration 22590, lr = 0.01
I0523 01:00:51.214213 34819 solver.cpp:239] Iteration 22600 (2.63607 iter/s, 3.79352s/10 iters), loss = 8.66274
I0523 01:00:51.214267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66274 (* 1 = 8.66274 loss)
I0523 01:00:52.042842 34819 sgd_solver.cpp:112] Iteration 22600, lr = 0.01
I0523 01:00:57.719988 34819 solver.cpp:239] Iteration 22610 (1.53717 iter/s, 6.50545s/10 iters), loss = 9.16201
I0523 01:00:57.720032 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16201 (* 1 = 9.16201 loss)
I0523 01:00:57.827240 34819 sgd_solver.cpp:112] Iteration 22610, lr = 0.01
I0523 01:01:02.496425 34819 solver.cpp:239] Iteration 22620 (2.09372 iter/s, 4.77619s/10 iters), loss = 7.82431
I0523 01:01:02.496469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82431 (* 1 = 7.82431 loss)
I0523 01:01:03.332952 34819 sgd_solver.cpp:112] Iteration 22620, lr = 0.01
I0523 01:01:07.438664 34819 solver.cpp:239] Iteration 22630 (2.02348 iter/s, 4.94198s/10 iters), loss = 9.41212
I0523 01:01:07.438733 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41212 (* 1 = 9.41212 loss)
I0523 01:01:08.307010 34819 sgd_solver.cpp:112] Iteration 22630, lr = 0.01
I0523 01:01:12.150494 34819 solver.cpp:239] Iteration 22640 (2.12245 iter/s, 4.71154s/10 iters), loss = 8.57566
I0523 01:01:12.150555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57566 (* 1 = 8.57566 loss)
I0523 01:01:12.224437 34819 sgd_solver.cpp:112] Iteration 22640, lr = 0.01
I0523 01:01:16.998953 34819 solver.cpp:239] Iteration 22650 (2.06263 iter/s, 4.84818s/10 iters), loss = 9.2522
I0523 01:01:16.999102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2522 (* 1 = 9.2522 loss)
I0523 01:01:17.059142 34819 sgd_solver.cpp:112] Iteration 22650, lr = 0.01
I0523 01:01:21.112720 34819 solver.cpp:239] Iteration 22660 (2.43105 iter/s, 4.11344s/10 iters), loss = 9.64274
I0523 01:01:21.112764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64274 (* 1 = 9.64274 loss)
I0523 01:01:21.173003 34819 sgd_solver.cpp:112] Iteration 22660, lr = 0.01
I0523 01:01:26.789567 34819 solver.cpp:239] Iteration 22670 (1.76163 iter/s, 5.67657s/10 iters), loss = 8.14931
I0523 01:01:26.789610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14931 (* 1 = 8.14931 loss)
I0523 01:01:27.444505 34819 sgd_solver.cpp:112] Iteration 22670, lr = 0.01
I0523 01:01:32.594461 34819 solver.cpp:239] Iteration 22680 (1.72277 iter/s, 5.80461s/10 iters), loss = 8.97385
I0523 01:01:32.594503 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97385 (* 1 = 8.97385 loss)
I0523 01:01:32.656484 34819 sgd_solver.cpp:112] Iteration 22680, lr = 0.01
I0523 01:01:35.846084 34819 solver.cpp:239] Iteration 22690 (3.07557 iter/s, 3.25143s/10 iters), loss = 8.15628
I0523 01:01:35.846134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15628 (* 1 = 8.15628 loss)
I0523 01:01:36.040855 34819 sgd_solver.cpp:112] Iteration 22690, lr = 0.01
I0523 01:01:39.540478 34819 solver.cpp:239] Iteration 22700 (2.70696 iter/s, 3.69419s/10 iters), loss = 9.29781
I0523 01:01:39.540520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29781 (* 1 = 9.29781 loss)
I0523 01:01:40.066840 34819 sgd_solver.cpp:112] Iteration 22700, lr = 0.01
I0523 01:01:43.681722 34819 solver.cpp:239] Iteration 22710 (2.41486 iter/s, 4.14103s/10 iters), loss = 8.59796
I0523 01:01:43.681777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59796 (* 1 = 8.59796 loss)
I0523 01:01:43.755973 34819 sgd_solver.cpp:112] Iteration 22710, lr = 0.01
I0523 01:01:48.617733 34819 solver.cpp:239] Iteration 22720 (2.02604 iter/s, 4.93574s/10 iters), loss = 9.29194
I0523 01:01:48.617910 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29194 (* 1 = 9.29194 loss)
I0523 01:01:48.688927 34819 sgd_solver.cpp:112] Iteration 22720, lr = 0.01
I0523 01:01:53.452077 34819 solver.cpp:239] Iteration 22730 (2.0687 iter/s, 4.83396s/10 iters), loss = 8.30248
I0523 01:01:53.452148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30248 (* 1 = 8.30248 loss)
I0523 01:01:54.289949 34819 sgd_solver.cpp:112] Iteration 22730, lr = 0.01
I0523 01:01:59.328128 34819 solver.cpp:239] Iteration 22740 (1.70191 iter/s, 5.87574s/10 iters), loss = 8.64821
I0523 01:01:59.328171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64821 (* 1 = 8.64821 loss)
I0523 01:02:00.115100 34819 sgd_solver.cpp:112] Iteration 22740, lr = 0.01
I0523 01:02:06.284699 34819 solver.cpp:239] Iteration 22750 (1.43756 iter/s, 6.95622s/10 iters), loss = 8.234
I0523 01:02:06.284750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.234 (* 1 = 8.234 loss)
I0523 01:02:06.346848 34819 sgd_solver.cpp:112] Iteration 22750, lr = 0.01
I0523 01:02:10.357080 34819 solver.cpp:239] Iteration 22760 (2.45571 iter/s, 4.07215s/10 iters), loss = 9.19145
I0523 01:02:10.357136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19145 (* 1 = 9.19145 loss)
I0523 01:02:11.222251 34819 sgd_solver.cpp:112] Iteration 22760, lr = 0.01
I0523 01:02:17.287693 34819 solver.cpp:239] Iteration 22770 (1.44295 iter/s, 6.93027s/10 iters), loss = 8.71578
I0523 01:02:17.287734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71578 (* 1 = 8.71578 loss)
I0523 01:02:18.122611 34819 sgd_solver.cpp:112] Iteration 22770, lr = 0.01
I0523 01:02:22.836339 34819 solver.cpp:239] Iteration 22780 (1.80233 iter/s, 5.54837s/10 iters), loss = 9.15949
I0523 01:02:22.836485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15949 (* 1 = 9.15949 loss)
I0523 01:02:22.893621 34819 sgd_solver.cpp:112] Iteration 22780, lr = 0.01
I0523 01:02:27.412441 34819 solver.cpp:239] Iteration 22790 (2.18543 iter/s, 4.57576s/10 iters), loss = 8.6308
I0523 01:02:27.412490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6308 (* 1 = 8.6308 loss)
I0523 01:02:27.592931 34819 sgd_solver.cpp:112] Iteration 22790, lr = 0.01
I0523 01:02:32.656741 34819 solver.cpp:239] Iteration 22800 (1.90693 iter/s, 5.24403s/10 iters), loss = 8.58135
I0523 01:02:32.656798 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58135 (* 1 = 8.58135 loss)
I0523 01:02:33.173667 34819 sgd_solver.cpp:112] Iteration 22800, lr = 0.01
I0523 01:02:38.535037 34819 solver.cpp:239] Iteration 22810 (1.70126 iter/s, 5.878s/10 iters), loss = 8.83464
I0523 01:02:38.535096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83464 (* 1 = 8.83464 loss)
I0523 01:02:38.627573 34819 sgd_solver.cpp:112] Iteration 22810, lr = 0.01
I0523 01:02:42.771219 34819 solver.cpp:239] Iteration 22820 (2.36075 iter/s, 4.23594s/10 iters), loss = 8.45937
I0523 01:02:42.771275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45937 (* 1 = 8.45937 loss)
I0523 01:02:43.530249 34819 sgd_solver.cpp:112] Iteration 22820, lr = 0.01
I0523 01:02:46.169556 34819 solver.cpp:239] Iteration 22830 (2.94282 iter/s, 3.3981s/10 iters), loss = 8.6688
I0523 01:02:46.169617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6688 (* 1 = 8.6688 loss)
I0523 01:02:46.976089 34819 sgd_solver.cpp:112] Iteration 22830, lr = 0.01
I0523 01:02:51.648109 34819 solver.cpp:239] Iteration 22840 (1.82539 iter/s, 5.47827s/10 iters), loss = 8.96737
I0523 01:02:51.648154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96737 (* 1 = 8.96737 loss)
I0523 01:02:52.379335 34819 sgd_solver.cpp:112] Iteration 22840, lr = 0.01
I0523 01:02:56.595377 34819 solver.cpp:239] Iteration 22850 (2.02142 iter/s, 4.94701s/10 iters), loss = 9.08814
I0523 01:02:56.595580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08814 (* 1 = 9.08814 loss)
I0523 01:02:56.646920 34819 sgd_solver.cpp:112] Iteration 22850, lr = 0.01
I0523 01:03:02.950069 34819 solver.cpp:239] Iteration 22860 (1.57376 iter/s, 6.35421s/10 iters), loss = 7.99546
I0523 01:03:02.950139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99546 (* 1 = 7.99546 loss)
I0523 01:03:03.076869 34819 sgd_solver.cpp:112] Iteration 22860, lr = 0.01
I0523 01:03:09.103652 34819 solver.cpp:239] Iteration 22870 (1.62515 iter/s, 6.15326s/10 iters), loss = 8.68136
I0523 01:03:09.103711 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68136 (* 1 = 8.68136 loss)
I0523 01:03:09.168934 34819 sgd_solver.cpp:112] Iteration 22870, lr = 0.01
I0523 01:03:13.377454 34819 solver.cpp:239] Iteration 22880 (2.33997 iter/s, 4.27356s/10 iters), loss = 9.08538
I0523 01:03:13.377516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08538 (* 1 = 9.08538 loss)
I0523 01:03:13.437088 34819 sgd_solver.cpp:112] Iteration 22880, lr = 0.01
I0523 01:03:19.484385 34819 solver.cpp:239] Iteration 22890 (1.63757 iter/s, 6.1066s/10 iters), loss = 9.04826
I0523 01:03:19.484467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04826 (* 1 = 9.04826 loss)
I0523 01:03:19.546430 34819 sgd_solver.cpp:112] Iteration 22890, lr = 0.01
I0523 01:03:24.055946 34819 solver.cpp:239] Iteration 22900 (2.18756 iter/s, 4.5713s/10 iters), loss = 9.00062
I0523 01:03:24.055989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00062 (* 1 = 9.00062 loss)
I0523 01:03:24.116467 34819 sgd_solver.cpp:112] Iteration 22900, lr = 0.01
I0523 01:03:28.194020 34819 solver.cpp:239] Iteration 22910 (2.41672 iter/s, 4.13785s/10 iters), loss = 8.36684
I0523 01:03:28.194175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36684 (* 1 = 8.36684 loss)
I0523 01:03:28.267185 34819 sgd_solver.cpp:112] Iteration 22910, lr = 0.01
I0523 01:03:32.402271 34819 solver.cpp:239] Iteration 22920 (2.37647 iter/s, 4.20792s/10 iters), loss = 8.31486
I0523 01:03:32.402328 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31486 (* 1 = 8.31486 loss)
I0523 01:03:33.266474 34819 sgd_solver.cpp:112] Iteration 22920, lr = 0.01
I0523 01:03:37.225082 34819 solver.cpp:239] Iteration 22930 (2.0736 iter/s, 4.82253s/10 iters), loss = 8.50764
I0523 01:03:37.225149 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50764 (* 1 = 8.50764 loss)
I0523 01:03:38.040765 34819 sgd_solver.cpp:112] Iteration 22930, lr = 0.01
I0523 01:03:42.877578 34819 solver.cpp:239] Iteration 22940 (1.76923 iter/s, 5.65218s/10 iters), loss = 8.15283
I0523 01:03:42.877647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15283 (* 1 = 8.15283 loss)
I0523 01:03:43.688774 34819 sgd_solver.cpp:112] Iteration 22940, lr = 0.01
I0523 01:03:46.721954 34819 solver.cpp:239] Iteration 22950 (2.60138 iter/s, 3.84411s/10 iters), loss = 8.61994
I0523 01:03:46.722019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61994 (* 1 = 8.61994 loss)
I0523 01:03:46.784315 34819 sgd_solver.cpp:112] Iteration 22950, lr = 0.01
I0523 01:03:52.489353 34819 solver.cpp:239] Iteration 22960 (1.73397 iter/s, 5.7671s/10 iters), loss = 8.88424
I0523 01:03:52.489409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88424 (* 1 = 8.88424 loss)
I0523 01:03:53.050742 34819 sgd_solver.cpp:112] Iteration 22960, lr = 0.01
I0523 01:03:57.398607 34819 solver.cpp:239] Iteration 22970 (2.03708 iter/s, 4.90898s/10 iters), loss = 9.11329
I0523 01:03:57.398667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11329 (* 1 = 9.11329 loss)
I0523 01:03:57.456975 34819 sgd_solver.cpp:112] Iteration 22970, lr = 0.01
I0523 01:04:02.115346 34819 solver.cpp:239] Iteration 22980 (2.12023 iter/s, 4.71646s/10 iters), loss = 7.94655
I0523 01:04:02.115623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94655 (* 1 = 7.94655 loss)
I0523 01:04:02.174700 34819 sgd_solver.cpp:112] Iteration 22980, lr = 0.01
I0523 01:04:08.564540 34819 solver.cpp:239] Iteration 22990 (1.55071 iter/s, 6.44868s/10 iters), loss = 8.42874
I0523 01:04:08.564600 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42874 (* 1 = 8.42874 loss)
I0523 01:04:08.638058 34819 sgd_solver.cpp:112] Iteration 22990, lr = 0.01
I0523 01:04:14.179374 34819 solver.cpp:239] Iteration 23000 (1.78109 iter/s, 5.61453s/10 iters), loss = 9.27152
I0523 01:04:14.179432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27152 (* 1 = 9.27152 loss)
I0523 01:04:14.952311 34819 sgd_solver.cpp:112] Iteration 23000, lr = 0.01
I0523 01:04:20.713932 34819 solver.cpp:239] Iteration 23010 (1.5304 iter/s, 6.53422s/10 iters), loss = 8.35982
I0523 01:04:20.713991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35982 (* 1 = 8.35982 loss)
I0523 01:04:20.774075 34819 sgd_solver.cpp:112] Iteration 23010, lr = 0.01
I0523 01:04:25.810819 34819 solver.cpp:239] Iteration 23020 (1.96209 iter/s, 5.09661s/10 iters), loss = 8.95693
I0523 01:04:25.810874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95693 (* 1 = 8.95693 loss)
I0523 01:04:25.868868 34819 sgd_solver.cpp:112] Iteration 23020, lr = 0.01
I0523 01:04:31.055454 34819 solver.cpp:239] Iteration 23030 (1.90681 iter/s, 5.24436s/10 iters), loss = 8.00683
I0523 01:04:31.055512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00683 (* 1 = 8.00683 loss)
I0523 01:04:31.113500 34819 sgd_solver.cpp:112] Iteration 23030, lr = 0.01
I0523 01:04:36.023998 34819 solver.cpp:239] Iteration 23040 (2.01277 iter/s, 4.96828s/10 iters), loss = 8.7989
I0523 01:04:36.024111 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7989 (* 1 = 8.7989 loss)
I0523 01:04:36.102581 34819 sgd_solver.cpp:112] Iteration 23040, lr = 0.01
I0523 01:04:41.320597 34819 solver.cpp:239] Iteration 23050 (1.88812 iter/s, 5.29627s/10 iters), loss = 9.28607
I0523 01:04:41.320655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28607 (* 1 = 9.28607 loss)
I0523 01:04:41.385133 34819 sgd_solver.cpp:112] Iteration 23050, lr = 0.01
I0523 01:04:44.599164 34819 solver.cpp:239] Iteration 23060 (3.05031 iter/s, 3.27835s/10 iters), loss = 8.78363
I0523 01:04:44.599220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78363 (* 1 = 8.78363 loss)
I0523 01:04:45.470465 34819 sgd_solver.cpp:112] Iteration 23060, lr = 0.01
I0523 01:04:49.841797 34819 solver.cpp:239] Iteration 23070 (1.90754 iter/s, 5.24236s/10 iters), loss = 8.65112
I0523 01:04:49.841847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65112 (* 1 = 8.65112 loss)
I0523 01:04:49.910282 34819 sgd_solver.cpp:112] Iteration 23070, lr = 0.01
I0523 01:04:55.606765 34819 solver.cpp:239] Iteration 23080 (1.7347 iter/s, 5.76468s/10 iters), loss = 9.40877
I0523 01:04:55.606814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40877 (* 1 = 9.40877 loss)
I0523 01:04:55.678294 34819 sgd_solver.cpp:112] Iteration 23080, lr = 0.01
I0523 01:04:59.792906 34819 solver.cpp:239] Iteration 23090 (2.38897 iter/s, 4.18591s/10 iters), loss = 8.80215
I0523 01:04:59.792964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80215 (* 1 = 8.80215 loss)
I0523 01:05:00.312649 34819 sgd_solver.cpp:112] Iteration 23090, lr = 0.01
I0523 01:05:05.028493 34819 solver.cpp:239] Iteration 23100 (1.91011 iter/s, 5.23531s/10 iters), loss = 8.4877
I0523 01:05:05.028537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4877 (* 1 = 8.4877 loss)
I0523 01:05:05.099849 34819 sgd_solver.cpp:112] Iteration 23100, lr = 0.01
I0523 01:05:09.050225 34819 solver.cpp:239] Iteration 23110 (2.48662 iter/s, 4.02152s/10 iters), loss = 8.70128
I0523 01:05:09.050518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70128 (* 1 = 8.70128 loss)
I0523 01:05:09.816452 34819 sgd_solver.cpp:112] Iteration 23110, lr = 0.01
I0523 01:05:13.141209 34819 solver.cpp:239] Iteration 23120 (2.44466 iter/s, 4.09054s/10 iters), loss = 8.8219
I0523 01:05:13.141269 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8219 (* 1 = 8.8219 loss)
I0523 01:05:13.997508 34819 sgd_solver.cpp:112] Iteration 23120, lr = 0.01
I0523 01:05:17.943210 34819 solver.cpp:239] Iteration 23130 (2.08259 iter/s, 4.80171s/10 iters), loss = 8.63776
I0523 01:05:17.943286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63776 (* 1 = 8.63776 loss)
I0523 01:05:18.707613 34819 sgd_solver.cpp:112] Iteration 23130, lr = 0.01
I0523 01:05:23.979743 34819 solver.cpp:239] Iteration 23140 (1.65667 iter/s, 6.0362s/10 iters), loss = 9.21834
I0523 01:05:23.979811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21834 (* 1 = 9.21834 loss)
I0523 01:05:24.050868 34819 sgd_solver.cpp:112] Iteration 23140, lr = 0.01
I0523 01:05:30.377041 34819 solver.cpp:239] Iteration 23150 (1.56324 iter/s, 6.39696s/10 iters), loss = 8.72755
I0523 01:05:30.377099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72755 (* 1 = 8.72755 loss)
I0523 01:05:31.203418 34819 sgd_solver.cpp:112] Iteration 23150, lr = 0.01
I0523 01:05:34.500725 34819 solver.cpp:239] Iteration 23160 (2.42516 iter/s, 4.12343s/10 iters), loss = 8.87136
I0523 01:05:34.500792 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87136 (* 1 = 8.87136 loss)
I0523 01:05:35.351958 34819 sgd_solver.cpp:112] Iteration 23160, lr = 0.01
I0523 01:05:40.142686 34819 solver.cpp:239] Iteration 23170 (1.77253 iter/s, 5.64165s/10 iters), loss = 7.7897
I0523 01:05:40.142907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7897 (* 1 = 7.7897 loss)
I0523 01:05:40.206465 34819 sgd_solver.cpp:112] Iteration 23170, lr = 0.01
I0523 01:05:44.822579 34819 solver.cpp:239] Iteration 23180 (2.137 iter/s, 4.67946s/10 iters), loss = 8.42414
I0523 01:05:44.822649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42414 (* 1 = 8.42414 loss)
I0523 01:05:45.642545 34819 sgd_solver.cpp:112] Iteration 23180, lr = 0.01
I0523 01:05:48.777766 34819 solver.cpp:239] Iteration 23190 (2.52848 iter/s, 3.95495s/10 iters), loss = 8.2376
I0523 01:05:48.777837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2376 (* 1 = 8.2376 loss)
I0523 01:05:48.846683 34819 sgd_solver.cpp:112] Iteration 23190, lr = 0.01
I0523 01:05:55.553550 34819 solver.cpp:239] Iteration 23200 (1.47592 iter/s, 6.77543s/10 iters), loss = 7.88329
I0523 01:05:55.553616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88329 (* 1 = 7.88329 loss)
I0523 01:05:55.630087 34819 sgd_solver.cpp:112] Iteration 23200, lr = 0.01
I0523 01:06:01.671614 34819 solver.cpp:239] Iteration 23210 (1.63459 iter/s, 6.11774s/10 iters), loss = 9.85622
I0523 01:06:01.671667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.85622 (* 1 = 9.85622 loss)
I0523 01:06:02.420873 34819 sgd_solver.cpp:112] Iteration 23210, lr = 0.01
I0523 01:06:07.003728 34819 solver.cpp:239] Iteration 23220 (1.87553 iter/s, 5.33182s/10 iters), loss = 8.83224
I0523 01:06:07.003793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83224 (* 1 = 8.83224 loss)
I0523 01:06:07.072074 34819 sgd_solver.cpp:112] Iteration 23220, lr = 0.01
I0523 01:06:09.539222 34819 solver.cpp:239] Iteration 23230 (3.94805 iter/s, 2.5329s/10 iters), loss = 8.67813
I0523 01:06:09.539286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67813 (* 1 = 8.67813 loss)
I0523 01:06:10.277149 34819 sgd_solver.cpp:112] Iteration 23230, lr = 0.01
I0523 01:06:14.253279 34819 solver.cpp:239] Iteration 23240 (2.12144 iter/s, 4.71378s/10 iters), loss = 8.12054
I0523 01:06:14.253335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12054 (* 1 = 8.12054 loss)
I0523 01:06:14.317054 34819 sgd_solver.cpp:112] Iteration 23240, lr = 0.01
I0523 01:06:19.902906 34819 solver.cpp:239] Iteration 23250 (1.77012 iter/s, 5.64934s/10 iters), loss = 8.24572
I0523 01:06:19.902952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24572 (* 1 = 8.24572 loss)
I0523 01:06:20.015413 34819 sgd_solver.cpp:112] Iteration 23250, lr = 0.01
I0523 01:06:25.404124 34819 solver.cpp:239] Iteration 23260 (1.81788 iter/s, 5.50092s/10 iters), loss = 9.6624
I0523 01:06:25.404196 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6624 (* 1 = 9.6624 loss)
I0523 01:06:25.744961 34819 sgd_solver.cpp:112] Iteration 23260, lr = 0.01
I0523 01:06:30.692885 34819 solver.cpp:239] Iteration 23270 (1.89091 iter/s, 5.28847s/10 iters), loss = 8.1478
I0523 01:06:30.692939 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1478 (* 1 = 8.1478 loss)
I0523 01:06:30.917266 34819 sgd_solver.cpp:112] Iteration 23270, lr = 0.01
I0523 01:06:35.804543 34819 solver.cpp:239] Iteration 23280 (1.95642 iter/s, 5.11138s/10 iters), loss = 8.19714
I0523 01:06:35.804591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19714 (* 1 = 8.19714 loss)
I0523 01:06:36.633599 34819 sgd_solver.cpp:112] Iteration 23280, lr = 0.01
I0523 01:06:41.343111 34819 solver.cpp:239] Iteration 23290 (1.80562 iter/s, 5.53828s/10 iters), loss = 8.6922
I0523 01:06:41.343295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6922 (* 1 = 8.6922 loss)
I0523 01:06:41.415606 34819 sgd_solver.cpp:112] Iteration 23290, lr = 0.01
I0523 01:06:46.308562 34819 solver.cpp:239] Iteration 23300 (2.01407 iter/s, 4.96507s/10 iters), loss = 8.88025
I0523 01:06:46.308606 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88025 (* 1 = 8.88025 loss)
I0523 01:06:47.175894 34819 sgd_solver.cpp:112] Iteration 23300, lr = 0.01
I0523 01:06:52.074478 34819 solver.cpp:239] Iteration 23310 (1.73442 iter/s, 5.76561s/10 iters), loss = 8.89329
I0523 01:06:52.074539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89329 (* 1 = 8.89329 loss)
I0523 01:06:52.143184 34819 sgd_solver.cpp:112] Iteration 23310, lr = 0.01
I0523 01:06:55.579746 34819 solver.cpp:239] Iteration 23320 (2.85302 iter/s, 3.50506s/10 iters), loss = 8.71329
I0523 01:06:55.579787 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71329 (* 1 = 8.71329 loss)
I0523 01:06:55.644306 34819 sgd_solver.cpp:112] Iteration 23320, lr = 0.01
I0523 01:07:00.477887 34819 solver.cpp:239] Iteration 23330 (2.0417 iter/s, 4.89788s/10 iters), loss = 7.87375
I0523 01:07:00.477947 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87375 (* 1 = 7.87375 loss)
I0523 01:07:01.269834 34819 sgd_solver.cpp:112] Iteration 23330, lr = 0.01
I0523 01:07:06.204452 34819 solver.cpp:239] Iteration 23340 (1.74634 iter/s, 5.72626s/10 iters), loss = 8.68256
I0523 01:07:06.204493 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68256 (* 1 = 8.68256 loss)
I0523 01:07:06.268404 34819 sgd_solver.cpp:112] Iteration 23340, lr = 0.01
I0523 01:07:11.326915 34819 solver.cpp:239] Iteration 23350 (1.9523 iter/s, 5.12217s/10 iters), loss = 8.48118
I0523 01:07:11.326974 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48118 (* 1 = 8.48118 loss)
I0523 01:07:11.388891 34819 sgd_solver.cpp:112] Iteration 23350, lr = 0.01
I0523 01:07:16.182651 34819 solver.cpp:239] Iteration 23360 (2.05953 iter/s, 4.85547s/10 iters), loss = 9.36545
I0523 01:07:16.182709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36545 (* 1 = 9.36545 loss)
I0523 01:07:16.252848 34819 sgd_solver.cpp:112] Iteration 23360, lr = 0.01
I0523 01:07:21.392722 34819 solver.cpp:239] Iteration 23370 (1.91946 iter/s, 5.2098s/10 iters), loss = 8.67524
I0523 01:07:21.392774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67524 (* 1 = 8.67524 loss)
I0523 01:07:21.462502 34819 sgd_solver.cpp:112] Iteration 23370, lr = 0.01
I0523 01:07:26.248617 34819 solver.cpp:239] Iteration 23380 (2.05947 iter/s, 4.85562s/10 iters), loss = 8.78397
I0523 01:07:26.248677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78397 (* 1 = 8.78397 loss)
I0523 01:07:26.315340 34819 sgd_solver.cpp:112] Iteration 23380, lr = 0.01
I0523 01:07:30.359506 34819 solver.cpp:239] Iteration 23390 (2.4327 iter/s, 4.11066s/10 iters), loss = 8.55113
I0523 01:07:30.359551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55113 (* 1 = 8.55113 loss)
I0523 01:07:31.210109 34819 sgd_solver.cpp:112] Iteration 23390, lr = 0.01
I0523 01:07:33.794502 34819 solver.cpp:239] Iteration 23400 (2.91138 iter/s, 3.43479s/10 iters), loss = 8.70062
I0523 01:07:33.794545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70062 (* 1 = 8.70062 loss)
I0523 01:07:33.865368 34819 sgd_solver.cpp:112] Iteration 23400, lr = 0.01
I0523 01:07:39.625303 34819 solver.cpp:239] Iteration 23410 (1.71512 iter/s, 5.8305s/10 iters), loss = 9.23769
I0523 01:07:39.625360 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23769 (* 1 = 9.23769 loss)
I0523 01:07:39.690330 34819 sgd_solver.cpp:112] Iteration 23410, lr = 0.01
I0523 01:07:44.079948 34819 solver.cpp:239] Iteration 23420 (2.24497 iter/s, 4.45441s/10 iters), loss = 8.82447
I0523 01:07:44.080071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82447 (* 1 = 8.82447 loss)
I0523 01:07:44.138837 34819 sgd_solver.cpp:112] Iteration 23420, lr = 0.01
I0523 01:07:49.532835 34819 solver.cpp:239] Iteration 23430 (1.83401 iter/s, 5.45253s/10 iters), loss = 8.63573
I0523 01:07:49.532888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63573 (* 1 = 8.63573 loss)
I0523 01:07:49.594213 34819 sgd_solver.cpp:112] Iteration 23430, lr = 0.01
I0523 01:07:53.594491 34819 solver.cpp:239] Iteration 23440 (2.46219 iter/s, 4.06143s/10 iters), loss = 9.27119
I0523 01:07:53.594537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27119 (* 1 = 9.27119 loss)
I0523 01:07:53.670131 34819 sgd_solver.cpp:112] Iteration 23440, lr = 0.01
I0523 01:07:59.374004 34819 solver.cpp:239] Iteration 23450 (1.73033 iter/s, 5.77923s/10 iters), loss = 9.20793
I0523 01:07:59.374058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20793 (* 1 = 9.20793 loss)
I0523 01:07:59.431169 34819 sgd_solver.cpp:112] Iteration 23450, lr = 0.01
I0523 01:08:03.698761 34819 solver.cpp:239] Iteration 23460 (2.3124 iter/s, 4.32451s/10 iters), loss = 8.81791
I0523 01:08:03.698822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81791 (* 1 = 8.81791 loss)
I0523 01:08:03.964449 34819 sgd_solver.cpp:112] Iteration 23460, lr = 0.01
I0523 01:08:07.736482 34819 solver.cpp:239] Iteration 23470 (2.47679 iter/s, 4.03749s/10 iters), loss = 8.00214
I0523 01:08:07.736541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00214 (* 1 = 8.00214 loss)
I0523 01:08:07.804742 34819 sgd_solver.cpp:112] Iteration 23470, lr = 0.01
I0523 01:08:13.142324 34819 solver.cpp:239] Iteration 23480 (1.84995 iter/s, 5.40556s/10 iters), loss = 8.05999
I0523 01:08:13.142376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05999 (* 1 = 8.05999 loss)
I0523 01:08:13.968237 34819 sgd_solver.cpp:112] Iteration 23480, lr = 0.01
I0523 01:08:19.271493 34819 solver.cpp:239] Iteration 23490 (1.63162 iter/s, 6.12887s/10 iters), loss = 8.75911
I0523 01:08:19.271649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75911 (* 1 = 8.75911 loss)
I0523 01:08:19.959918 34819 sgd_solver.cpp:112] Iteration 23490, lr = 0.01
I0523 01:08:24.839280 34819 solver.cpp:239] Iteration 23500 (1.79617 iter/s, 5.56741s/10 iters), loss = 8.88109
I0523 01:08:24.839323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88109 (* 1 = 8.88109 loss)
I0523 01:08:24.901932 34819 sgd_solver.cpp:112] Iteration 23500, lr = 0.01
I0523 01:08:30.531302 34819 solver.cpp:239] Iteration 23510 (1.75693 iter/s, 5.69174s/10 iters), loss = 8.28207
I0523 01:08:30.531378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28207 (* 1 = 8.28207 loss)
I0523 01:08:30.589895 34819 sgd_solver.cpp:112] Iteration 23510, lr = 0.01
I0523 01:08:33.229883 34819 solver.cpp:239] Iteration 23520 (3.70592 iter/s, 2.69839s/10 iters), loss = 9.14491
I0523 01:08:33.229930 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14491 (* 1 = 9.14491 loss)
I0523 01:08:33.294503 34819 sgd_solver.cpp:112] Iteration 23520, lr = 0.01
I0523 01:08:39.755218 34819 solver.cpp:239] Iteration 23530 (1.53256 iter/s, 6.52501s/10 iters), loss = 8.67673
I0523 01:08:39.755264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67673 (* 1 = 8.67673 loss)
I0523 01:08:40.496134 34819 sgd_solver.cpp:112] Iteration 23530, lr = 0.01
I0523 01:08:44.443725 34819 solver.cpp:239] Iteration 23540 (2.133 iter/s, 4.68824s/10 iters), loss = 9.03319
I0523 01:08:44.443778 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03319 (* 1 = 9.03319 loss)
I0523 01:08:45.266755 34819 sgd_solver.cpp:112] Iteration 23540, lr = 0.01
I0523 01:08:49.712416 34819 solver.cpp:239] Iteration 23550 (1.89811 iter/s, 5.26841s/10 iters), loss = 8.54311
I0523 01:08:49.712654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54311 (* 1 = 8.54311 loss)
I0523 01:08:49.776993 34819 sgd_solver.cpp:112] Iteration 23550, lr = 0.01
I0523 01:08:54.857317 34819 solver.cpp:239] Iteration 23560 (1.94383 iter/s, 5.14447s/10 iters), loss = 8.21755
I0523 01:08:54.857363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21755 (* 1 = 8.21755 loss)
I0523 01:08:54.930294 34819 sgd_solver.cpp:112] Iteration 23560, lr = 0.01
I0523 01:09:00.735028 34819 solver.cpp:239] Iteration 23570 (1.70143 iter/s, 5.87742s/10 iters), loss = 8.18166
I0523 01:09:00.735074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18166 (* 1 = 8.18166 loss)
I0523 01:09:00.790513 34819 sgd_solver.cpp:112] Iteration 23570, lr = 0.01
I0523 01:09:03.933631 34819 solver.cpp:239] Iteration 23580 (3.12657 iter/s, 3.1984s/10 iters), loss = 8.38451
I0523 01:09:03.933684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38451 (* 1 = 8.38451 loss)
I0523 01:09:04.775455 34819 sgd_solver.cpp:112] Iteration 23580, lr = 0.01
I0523 01:09:07.868441 34819 solver.cpp:239] Iteration 23590 (2.54157 iter/s, 3.93457s/10 iters), loss = 8.81349
I0523 01:09:07.868504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81349 (* 1 = 8.81349 loss)
I0523 01:09:08.715416 34819 sgd_solver.cpp:112] Iteration 23590, lr = 0.01
I0523 01:09:12.879794 34819 solver.cpp:239] Iteration 23600 (1.99557 iter/s, 5.01109s/10 iters), loss = 9.0989
I0523 01:09:12.879837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0989 (* 1 = 9.0989 loss)
I0523 01:09:13.709745 34819 sgd_solver.cpp:112] Iteration 23600, lr = 0.01
I0523 01:09:17.166524 34819 solver.cpp:239] Iteration 23610 (2.33291 iter/s, 4.2865s/10 iters), loss = 9.12258
I0523 01:09:17.166568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12258 (* 1 = 9.12258 loss)
I0523 01:09:17.997861 34819 sgd_solver.cpp:112] Iteration 23610, lr = 0.01
I0523 01:09:23.912927 34819 solver.cpp:239] Iteration 23620 (1.48234 iter/s, 6.74607s/10 iters), loss = 8.51287
I0523 01:09:23.913074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51287 (* 1 = 8.51287 loss)
I0523 01:09:23.985669 34819 sgd_solver.cpp:112] Iteration 23620, lr = 0.01
I0523 01:09:27.801781 34819 solver.cpp:239] Iteration 23630 (2.57165 iter/s, 3.88855s/10 iters), loss = 8.73486
I0523 01:09:27.801826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73486 (* 1 = 8.73486 loss)
I0523 01:09:28.572331 34819 sgd_solver.cpp:112] Iteration 23630, lr = 0.01
I0523 01:09:32.419234 34819 solver.cpp:239] Iteration 23640 (2.16581 iter/s, 4.61722s/10 iters), loss = 8.06593
I0523 01:09:32.419279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06593 (* 1 = 8.06593 loss)
I0523 01:09:32.491426 34819 sgd_solver.cpp:112] Iteration 23640, lr = 0.01
I0523 01:09:36.216902 34819 solver.cpp:239] Iteration 23650 (2.63335 iter/s, 3.79745s/10 iters), loss = 8.57931
I0523 01:09:36.216950 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57931 (* 1 = 8.57931 loss)
I0523 01:09:37.051373 34819 sgd_solver.cpp:112] Iteration 23650, lr = 0.01
I0523 01:09:42.288352 34819 solver.cpp:239] Iteration 23660 (1.64713 iter/s, 6.07115s/10 iters), loss = 8.52139
I0523 01:09:42.288394 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52139 (* 1 = 8.52139 loss)
I0523 01:09:42.352205 34819 sgd_solver.cpp:112] Iteration 23660, lr = 0.01
I0523 01:09:46.348193 34819 solver.cpp:239] Iteration 23670 (2.4633 iter/s, 4.0596s/10 iters), loss = 7.92513
I0523 01:09:46.348237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92513 (* 1 = 7.92513 loss)
I0523 01:09:47.220865 34819 sgd_solver.cpp:112] Iteration 23670, lr = 0.01
I0523 01:09:53.218606 34819 solver.cpp:239] Iteration 23680 (1.45559 iter/s, 6.87008s/10 iters), loss = 9.36549
I0523 01:09:53.218647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36549 (* 1 = 9.36549 loss)
I0523 01:09:53.411247 34819 sgd_solver.cpp:112] Iteration 23680, lr = 0.01
I0523 01:09:57.954525 34819 solver.cpp:239] Iteration 23690 (2.11358 iter/s, 4.7313s/10 iters), loss = 9.39657
I0523 01:09:57.954856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39657 (* 1 = 9.39657 loss)
I0523 01:09:58.026957 34819 sgd_solver.cpp:112] Iteration 23690, lr = 0.01
I0523 01:10:02.346264 34819 solver.cpp:239] Iteration 23700 (2.27725 iter/s, 4.39127s/10 iters), loss = 8.30024
I0523 01:10:02.346323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30024 (* 1 = 8.30024 loss)
I0523 01:10:02.426983 34819 sgd_solver.cpp:112] Iteration 23700, lr = 0.01
I0523 01:10:08.188293 34819 solver.cpp:239] Iteration 23710 (1.71182 iter/s, 5.84173s/10 iters), loss = 8.63854
I0523 01:10:08.188349 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63854 (* 1 = 8.63854 loss)
I0523 01:10:08.249999 34819 sgd_solver.cpp:112] Iteration 23710, lr = 0.01
I0523 01:10:13.027961 34819 solver.cpp:239] Iteration 23720 (2.06638 iter/s, 4.83939s/10 iters), loss = 8.3958
I0523 01:10:13.028015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3958 (* 1 = 8.3958 loss)
I0523 01:10:13.856585 34819 sgd_solver.cpp:112] Iteration 23720, lr = 0.01
I0523 01:10:18.451184 34819 solver.cpp:239] Iteration 23730 (1.84402 iter/s, 5.42295s/10 iters), loss = 8.49711
I0523 01:10:18.451239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49711 (* 1 = 8.49711 loss)
I0523 01:10:19.129104 34819 sgd_solver.cpp:112] Iteration 23730, lr = 0.01
I0523 01:10:24.880663 34819 solver.cpp:239] Iteration 23740 (1.55541 iter/s, 6.42916s/10 iters), loss = 8.76218
I0523 01:10:24.880703 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76218 (* 1 = 8.76218 loss)
I0523 01:10:24.938959 34819 sgd_solver.cpp:112] Iteration 23740, lr = 0.01
I0523 01:10:29.648557 34819 solver.cpp:239] Iteration 23750 (2.09747 iter/s, 4.76765s/10 iters), loss = 9.3413
I0523 01:10:29.648775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3413 (* 1 = 9.3413 loss)
I0523 01:10:29.835443 34819 sgd_solver.cpp:112] Iteration 23750, lr = 0.01
I0523 01:10:34.325664 34819 solver.cpp:239] Iteration 23760 (2.13826 iter/s, 4.67671s/10 iters), loss = 8.60023
I0523 01:10:34.325718 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60023 (* 1 = 8.60023 loss)
I0523 01:10:34.384678 34819 sgd_solver.cpp:112] Iteration 23760, lr = 0.01
I0523 01:10:40.110507 34819 solver.cpp:239] Iteration 23770 (1.72874 iter/s, 5.78455s/10 iters), loss = 8.80933
I0523 01:10:40.110548 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80933 (* 1 = 8.80933 loss)
I0523 01:10:40.720626 34819 sgd_solver.cpp:112] Iteration 23770, lr = 0.01
I0523 01:10:44.997526 34819 solver.cpp:239] Iteration 23780 (2.04635 iter/s, 4.88676s/10 iters), loss = 8.6857
I0523 01:10:44.997570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6857 (* 1 = 8.6857 loss)
I0523 01:10:45.074623 34819 sgd_solver.cpp:112] Iteration 23780, lr = 0.01
I0523 01:10:47.728000 34819 solver.cpp:239] Iteration 23790 (3.6626 iter/s, 2.7303s/10 iters), loss = 8.57457
I0523 01:10:47.728044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57457 (* 1 = 8.57457 loss)
I0523 01:10:48.432324 34819 sgd_solver.cpp:112] Iteration 23790, lr = 0.01
I0523 01:10:53.410616 34819 solver.cpp:239] Iteration 23800 (1.75984 iter/s, 5.68233s/10 iters), loss = 9.38517
I0523 01:10:53.410662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38517 (* 1 = 9.38517 loss)
I0523 01:10:53.467854 34819 sgd_solver.cpp:112] Iteration 23800, lr = 0.01
I0523 01:10:59.655479 34819 solver.cpp:239] Iteration 23810 (1.60139 iter/s, 6.24456s/10 iters), loss = 8.51198
I0523 01:10:59.655763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51198 (* 1 = 8.51198 loss)
I0523 01:10:59.732806 34819 sgd_solver.cpp:112] Iteration 23810, lr = 0.01
I0523 01:11:06.107831 34819 solver.cpp:239] Iteration 23820 (1.54994 iter/s, 6.45185s/10 iters), loss = 8.73455
I0523 01:11:06.107875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73455 (* 1 = 8.73455 loss)
I0523 01:11:06.174612 34819 sgd_solver.cpp:112] Iteration 23820, lr = 0.01
I0523 01:11:09.616680 34819 solver.cpp:239] Iteration 23830 (2.85011 iter/s, 3.50863s/10 iters), loss = 8.95737
I0523 01:11:09.616746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95737 (* 1 = 8.95737 loss)
I0523 01:11:10.428802 34819 sgd_solver.cpp:112] Iteration 23830, lr = 0.01
I0523 01:11:15.016471 34819 solver.cpp:239] Iteration 23840 (1.85202 iter/s, 5.3995s/10 iters), loss = 8.4893
I0523 01:11:15.016525 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4893 (* 1 = 8.4893 loss)
I0523 01:11:15.076274 34819 sgd_solver.cpp:112] Iteration 23840, lr = 0.01
I0523 01:11:19.714148 34819 solver.cpp:239] Iteration 23850 (2.12882 iter/s, 4.69743s/10 iters), loss = 8.5544
I0523 01:11:19.714195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5544 (* 1 = 8.5544 loss)
I0523 01:11:19.772704 34819 sgd_solver.cpp:112] Iteration 23850, lr = 0.01
I0523 01:11:23.641494 34819 solver.cpp:239] Iteration 23860 (2.54639 iter/s, 3.92713s/10 iters), loss = 8.89264
I0523 01:11:23.641549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89264 (* 1 = 8.89264 loss)
I0523 01:11:23.715688 34819 sgd_solver.cpp:112] Iteration 23860, lr = 0.01
I0523 01:11:26.891315 34819 solver.cpp:239] Iteration 23870 (3.07729 iter/s, 3.24961s/10 iters), loss = 9.47077
I0523 01:11:26.891373 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47077 (* 1 = 9.47077 loss)
I0523 01:11:26.966569 34819 sgd_solver.cpp:112] Iteration 23870, lr = 0.01
I0523 01:11:32.558362 34819 solver.cpp:239] Iteration 23880 (1.76468 iter/s, 5.66676s/10 iters), loss = 9.439
I0523 01:11:32.558497 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.439 (* 1 = 9.439 loss)
I0523 01:11:32.607713 34819 sgd_solver.cpp:112] Iteration 23880, lr = 0.01
I0523 01:11:38.602105 34819 solver.cpp:239] Iteration 23890 (1.65471 iter/s, 6.04336s/10 iters), loss = 8.39934
I0523 01:11:38.602159 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39934 (* 1 = 8.39934 loss)
I0523 01:11:38.677109 34819 sgd_solver.cpp:112] Iteration 23890, lr = 0.01
I0523 01:11:43.590148 34819 solver.cpp:239] Iteration 23900 (2.0049 iter/s, 4.98778s/10 iters), loss = 8.39222
I0523 01:11:43.590190 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39222 (* 1 = 8.39222 loss)
I0523 01:11:43.673730 34819 sgd_solver.cpp:112] Iteration 23900, lr = 0.01
I0523 01:11:47.246539 34819 solver.cpp:239] Iteration 23910 (2.7351 iter/s, 3.65618s/10 iters), loss = 8.52419
I0523 01:11:47.246594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52419 (* 1 = 8.52419 loss)
I0523 01:11:47.325950 34819 sgd_solver.cpp:112] Iteration 23910, lr = 0.01
I0523 01:11:49.947616 34819 solver.cpp:239] Iteration 23920 (3.70248 iter/s, 2.70089s/10 iters), loss = 8.61763
I0523 01:11:49.947664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61763 (* 1 = 8.61763 loss)
I0523 01:11:50.016324 34819 sgd_solver.cpp:112] Iteration 23920, lr = 0.01
I0523 01:11:55.483466 34819 solver.cpp:239] Iteration 23930 (1.8065 iter/s, 5.53556s/10 iters), loss = 9.0163
I0523 01:11:55.483517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0163 (* 1 = 9.0163 loss)
I0523 01:11:56.366017 34819 sgd_solver.cpp:112] Iteration 23930, lr = 0.01
I0523 01:12:01.472561 34819 solver.cpp:239] Iteration 23940 (1.66978 iter/s, 5.9888s/10 iters), loss = 8.56041
I0523 01:12:01.472617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56041 (* 1 = 8.56041 loss)
I0523 01:12:01.541455 34819 sgd_solver.cpp:112] Iteration 23940, lr = 0.01
I0523 01:12:04.656803 34819 solver.cpp:239] Iteration 23950 (3.14066 iter/s, 3.18405s/10 iters), loss = 8.8992
I0523 01:12:04.656971 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8992 (* 1 = 8.8992 loss)
I0523 01:12:04.731026 34819 sgd_solver.cpp:112] Iteration 23950, lr = 0.01
I0523 01:12:09.441892 34819 solver.cpp:239] Iteration 23960 (2.09189 iter/s, 4.78037s/10 iters), loss = 7.79937
I0523 01:12:09.441951 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79937 (* 1 = 7.79937 loss)
I0523 01:12:10.184836 34819 sgd_solver.cpp:112] Iteration 23960, lr = 0.01
I0523 01:12:13.364935 34819 solver.cpp:239] Iteration 23970 (2.54919 iter/s, 3.92281s/10 iters), loss = 9.51597
I0523 01:12:13.364979 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51597 (* 1 = 9.51597 loss)
I0523 01:12:13.404881 34819 sgd_solver.cpp:112] Iteration 23970, lr = 0.01
I0523 01:12:16.079928 34819 solver.cpp:239] Iteration 23980 (3.68349 iter/s, 2.71482s/10 iters), loss = 9.26739
I0523 01:12:16.079972 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26739 (* 1 = 9.26739 loss)
I0523 01:12:16.152470 34819 sgd_solver.cpp:112] Iteration 23980, lr = 0.01
I0523 01:12:21.849671 34819 solver.cpp:239] Iteration 23990 (1.73327 iter/s, 5.76945s/10 iters), loss = 9.20599
I0523 01:12:21.849714 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20599 (* 1 = 9.20599 loss)
I0523 01:12:22.680742 34819 sgd_solver.cpp:112] Iteration 23990, lr = 0.01
I0523 01:12:28.102108 34819 solver.cpp:239] Iteration 24000 (1.59945 iter/s, 6.25213s/10 iters), loss = 8.22645
I0523 01:12:28.102150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22645 (* 1 = 8.22645 loss)
I0523 01:12:28.179049 34819 sgd_solver.cpp:112] Iteration 24000, lr = 0.01
I0523 01:12:33.776952 34819 solver.cpp:239] Iteration 24010 (1.76225 iter/s, 5.67456s/10 iters), loss = 9.25332
I0523 01:12:33.776994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25332 (* 1 = 9.25332 loss)
I0523 01:12:33.850654 34819 sgd_solver.cpp:112] Iteration 24010, lr = 0.01
I0523 01:12:38.661383 34819 solver.cpp:239] Iteration 24020 (2.04743 iter/s, 4.88417s/10 iters), loss = 8.38815
I0523 01:12:38.661510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38815 (* 1 = 8.38815 loss)
I0523 01:12:38.720407 34819 sgd_solver.cpp:112] Iteration 24020, lr = 0.01
I0523 01:12:41.780050 34819 solver.cpp:239] Iteration 24030 (3.20677 iter/s, 3.11841s/10 iters), loss = 8.01622
I0523 01:12:41.780093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01622 (* 1 = 8.01622 loss)
I0523 01:12:42.622316 34819 sgd_solver.cpp:112] Iteration 24030, lr = 0.01
I0523 01:12:48.845955 34819 solver.cpp:239] Iteration 24040 (1.41532 iter/s, 7.06555s/10 iters), loss = 9.36832
I0523 01:12:48.846009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36832 (* 1 = 9.36832 loss)
I0523 01:12:49.691817 34819 sgd_solver.cpp:112] Iteration 24040, lr = 0.01
I0523 01:12:54.500190 34819 solver.cpp:239] Iteration 24050 (1.76868 iter/s, 5.65394s/10 iters), loss = 9.12447
I0523 01:12:54.500234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12447 (* 1 = 9.12447 loss)
I0523 01:12:54.562961 34819 sgd_solver.cpp:112] Iteration 24050, lr = 0.01
I0523 01:13:00.286418 34819 solver.cpp:239] Iteration 24060 (1.72833 iter/s, 5.78595s/10 iters), loss = 9.75829
I0523 01:13:00.286463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75829 (* 1 = 9.75829 loss)
I0523 01:13:00.348798 34819 sgd_solver.cpp:112] Iteration 24060, lr = 0.01
I0523 01:13:06.086732 34819 solver.cpp:239] Iteration 24070 (1.72414 iter/s, 5.8s/10 iters), loss = 8.75113
I0523 01:13:06.086787 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75113 (* 1 = 8.75113 loss)
I0523 01:13:06.486822 34819 sgd_solver.cpp:112] Iteration 24070, lr = 0.01
I0523 01:13:09.598050 34819 solver.cpp:239] Iteration 24080 (2.8481 iter/s, 3.51111s/10 iters), loss = 8.51309
I0523 01:13:09.598275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51309 (* 1 = 8.51309 loss)
I0523 01:13:10.312297 34819 sgd_solver.cpp:112] Iteration 24080, lr = 0.01
I0523 01:13:15.124733 34819 solver.cpp:239] Iteration 24090 (1.80955 iter/s, 5.52625s/10 iters), loss = 8.87724
I0523 01:13:15.124774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87724 (* 1 = 8.87724 loss)
I0523 01:13:15.188360 34819 sgd_solver.cpp:112] Iteration 24090, lr = 0.01
I0523 01:13:20.083262 34819 solver.cpp:239] Iteration 24100 (2.01683 iter/s, 4.95827s/10 iters), loss = 7.94735
I0523 01:13:20.083314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94735 (* 1 = 7.94735 loss)
I0523 01:13:20.150022 34819 sgd_solver.cpp:112] Iteration 24100, lr = 0.01
I0523 01:13:25.885794 34819 solver.cpp:239] Iteration 24110 (1.72347 iter/s, 5.80224s/10 iters), loss = 9.29277
I0523 01:13:25.885850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29277 (* 1 = 9.29277 loss)
I0523 01:13:25.966418 34819 sgd_solver.cpp:112] Iteration 24110, lr = 0.01
I0523 01:13:31.469524 34819 solver.cpp:239] Iteration 24120 (1.79101 iter/s, 5.58343s/10 iters), loss = 8.61949
I0523 01:13:31.469578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61949 (* 1 = 8.61949 loss)
I0523 01:13:31.528676 34819 sgd_solver.cpp:112] Iteration 24120, lr = 0.01
I0523 01:13:36.716773 34819 solver.cpp:239] Iteration 24130 (1.90587 iter/s, 5.24696s/10 iters), loss = 8.09172
I0523 01:13:36.716866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09172 (* 1 = 8.09172 loss)
I0523 01:13:37.499071 34819 sgd_solver.cpp:112] Iteration 24130, lr = 0.01
I0523 01:13:40.841212 34819 solver.cpp:239] Iteration 24140 (2.42475 iter/s, 4.12414s/10 iters), loss = 9.77157
I0523 01:13:40.841357 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.77157 (* 1 = 9.77157 loss)
I0523 01:13:40.896994 34819 sgd_solver.cpp:112] Iteration 24140, lr = 0.01
I0523 01:13:46.483325 34819 solver.cpp:239] Iteration 24150 (1.77251 iter/s, 5.64173s/10 iters), loss = 8.95286
I0523 01:13:46.483386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95286 (* 1 = 8.95286 loss)
I0523 01:13:47.295562 34819 sgd_solver.cpp:112] Iteration 24150, lr = 0.01
I0523 01:13:52.580397 34819 solver.cpp:239] Iteration 24160 (1.64022 iter/s, 6.09676s/10 iters), loss = 8.43898
I0523 01:13:52.580453 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43898 (* 1 = 8.43898 loss)
I0523 01:13:52.659294 34819 sgd_solver.cpp:112] Iteration 24160, lr = 0.01
I0523 01:13:57.630827 34819 solver.cpp:239] Iteration 24170 (1.98014 iter/s, 5.05015s/10 iters), loss = 9.97945
I0523 01:13:57.630897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.97945 (* 1 = 9.97945 loss)
I0523 01:13:57.695042 34819 sgd_solver.cpp:112] Iteration 24170, lr = 0.01
I0523 01:14:02.635476 34819 solver.cpp:239] Iteration 24180 (1.99825 iter/s, 5.00438s/10 iters), loss = 9.63629
I0523 01:14:02.635519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63629 (* 1 = 9.63629 loss)
I0523 01:14:02.714448 34819 sgd_solver.cpp:112] Iteration 24180, lr = 0.01
I0523 01:14:07.920683 34819 solver.cpp:239] Iteration 24190 (1.89217 iter/s, 5.28494s/10 iters), loss = 9.71607
I0523 01:14:07.920737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71607 (* 1 = 9.71607 loss)
I0523 01:14:07.978932 34819 sgd_solver.cpp:112] Iteration 24190, lr = 0.01
I0523 01:14:14.304247 34819 solver.cpp:239] Iteration 24200 (1.5666 iter/s, 6.38325s/10 iters), loss = 7.89404
I0523 01:14:14.304522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89404 (* 1 = 7.89404 loss)
I0523 01:14:14.918162 34819 sgd_solver.cpp:112] Iteration 24200, lr = 0.01
I0523 01:14:19.523344 34819 solver.cpp:239] Iteration 24210 (1.91621 iter/s, 5.21864s/10 iters), loss = 8.76357
I0523 01:14:19.523396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76357 (* 1 = 8.76357 loss)
I0523 01:14:19.595912 34819 sgd_solver.cpp:112] Iteration 24210, lr = 0.01
I0523 01:14:23.768617 34819 solver.cpp:239] Iteration 24220 (2.35569 iter/s, 4.24504s/10 iters), loss = 8.21972
I0523 01:14:23.768672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21972 (* 1 = 8.21972 loss)
I0523 01:14:24.577343 34819 sgd_solver.cpp:112] Iteration 24220, lr = 0.01
I0523 01:14:29.104889 34819 solver.cpp:239] Iteration 24230 (1.87406 iter/s, 5.336s/10 iters), loss = 8.7628
I0523 01:14:29.104931 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7628 (* 1 = 8.7628 loss)
I0523 01:14:29.178247 34819 sgd_solver.cpp:112] Iteration 24230, lr = 0.01
I0523 01:14:33.723912 34819 solver.cpp:239] Iteration 24240 (2.16507 iter/s, 4.61878s/10 iters), loss = 8.55471
I0523 01:14:33.723958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55471 (* 1 = 8.55471 loss)
I0523 01:14:33.786772 34819 sgd_solver.cpp:112] Iteration 24240, lr = 0.01
I0523 01:14:37.847913 34819 solver.cpp:239] Iteration 24250 (2.42496 iter/s, 4.12378s/10 iters), loss = 9.74263
I0523 01:14:37.847965 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74263 (* 1 = 9.74263 loss)
I0523 01:14:37.916416 34819 sgd_solver.cpp:112] Iteration 24250, lr = 0.01
I0523 01:14:44.239130 34819 solver.cpp:239] Iteration 24260 (1.56473 iter/s, 6.39089s/10 iters), loss = 8.10662
I0523 01:14:44.239187 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10662 (* 1 = 8.10662 loss)
I0523 01:14:44.311623 34819 sgd_solver.cpp:112] Iteration 24260, lr = 0.01
I0523 01:14:49.836603 34819 solver.cpp:239] Iteration 24270 (1.78662 iter/s, 5.59717s/10 iters), loss = 9.16698
I0523 01:14:49.836658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16698 (* 1 = 9.16698 loss)
I0523 01:14:49.907824 34819 sgd_solver.cpp:112] Iteration 24270, lr = 0.01
I0523 01:14:54.532603 34819 solver.cpp:239] Iteration 24280 (2.12959 iter/s, 4.69574s/10 iters), loss = 8.51805
I0523 01:14:54.532655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51805 (* 1 = 8.51805 loss)
I0523 01:14:54.601421 34819 sgd_solver.cpp:112] Iteration 24280, lr = 0.01
I0523 01:15:00.250361 34819 solver.cpp:239] Iteration 24290 (1.74902 iter/s, 5.71747s/10 iters), loss = 8.73272
I0523 01:15:00.250414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73272 (* 1 = 8.73272 loss)
I0523 01:15:00.317132 34819 sgd_solver.cpp:112] Iteration 24290, lr = 0.01
I0523 01:15:05.580044 34819 solver.cpp:239] Iteration 24300 (1.87639 iter/s, 5.32938s/10 iters), loss = 8.55289
I0523 01:15:05.580116 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55289 (* 1 = 8.55289 loss)
I0523 01:15:06.197921 34819 sgd_solver.cpp:112] Iteration 24300, lr = 0.01
I0523 01:15:10.907394 34819 solver.cpp:239] Iteration 24310 (1.87721 iter/s, 5.32706s/10 iters), loss = 9.08393
I0523 01:15:10.907449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08393 (* 1 = 9.08393 loss)
I0523 01:15:10.976305 34819 sgd_solver.cpp:112] Iteration 24310, lr = 0.01
I0523 01:15:15.326038 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 01:15:16.367189 34819 solver.cpp:239] Iteration 24320 (1.83166 iter/s, 5.45952s/10 iters), loss = 9.08439
I0523 01:15:16.367233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08439 (* 1 = 9.08439 loss)
I0523 01:15:16.427229 34819 sgd_solver.cpp:112] Iteration 24320, lr = 0.01
I0523 01:15:22.125562 34819 solver.cpp:239] Iteration 24330 (1.73669 iter/s, 5.75809s/10 iters), loss = 8.34469
I0523 01:15:22.125627 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34469 (* 1 = 8.34469 loss)
I0523 01:15:22.196974 34819 sgd_solver.cpp:112] Iteration 24330, lr = 0.01
I0523 01:15:25.903851 34819 solver.cpp:239] Iteration 24340 (2.64687 iter/s, 3.77805s/10 iters), loss = 8.96067
I0523 01:15:25.903909 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96067 (* 1 = 8.96067 loss)
I0523 01:15:26.649102 34819 sgd_solver.cpp:112] Iteration 24340, lr = 0.01
I0523 01:15:32.308089 34819 solver.cpp:239] Iteration 24350 (1.56154 iter/s, 6.40391s/10 iters), loss = 8.53944
I0523 01:15:32.308147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53944 (* 1 = 8.53944 loss)
I0523 01:15:33.160064 34819 sgd_solver.cpp:112] Iteration 24350, lr = 0.01
I0523 01:15:39.978776 34819 solver.cpp:239] Iteration 24360 (1.30373 iter/s, 7.67031s/10 iters), loss = 9.66735
I0523 01:15:39.978821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.66735 (* 1 = 9.66735 loss)
I0523 01:15:40.049093 34819 sgd_solver.cpp:112] Iteration 24360, lr = 0.01
I0523 01:15:45.213078 34819 solver.cpp:239] Iteration 24370 (1.91057 iter/s, 5.23403s/10 iters), loss = 8.8628
I0523 01:15:45.213124 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8628 (* 1 = 8.8628 loss)
I0523 01:15:45.275220 34819 sgd_solver.cpp:112] Iteration 24370, lr = 0.01
I0523 01:15:49.152817 34819 solver.cpp:239] Iteration 24380 (2.53839 iter/s, 3.9395s/10 iters), loss = 8.07624
I0523 01:15:49.152943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07624 (* 1 = 8.07624 loss)
I0523 01:15:49.230578 34819 sgd_solver.cpp:112] Iteration 24380, lr = 0.01
I0523 01:15:53.255950 34819 solver.cpp:239] Iteration 24390 (2.43734 iter/s, 4.10283s/10 iters), loss = 9.16074
I0523 01:15:53.256007 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16074 (* 1 = 9.16074 loss)
I0523 01:15:54.051403 34819 sgd_solver.cpp:112] Iteration 24390, lr = 0.01
I0523 01:15:58.779220 34819 solver.cpp:239] Iteration 24400 (1.81062 iter/s, 5.52297s/10 iters), loss = 9.17092
I0523 01:15:58.779278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17092 (* 1 = 9.17092 loss)
I0523 01:15:58.841231 34819 sgd_solver.cpp:112] Iteration 24400, lr = 0.01
I0523 01:16:03.981993 34819 solver.cpp:239] Iteration 24410 (1.92216 iter/s, 5.20249s/10 iters), loss = 9.25694
I0523 01:16:03.982043 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25694 (* 1 = 9.25694 loss)
I0523 01:16:04.722103 34819 sgd_solver.cpp:112] Iteration 24410, lr = 0.01
I0523 01:16:06.949276 34819 solver.cpp:239] Iteration 24420 (3.37029 iter/s, 2.96711s/10 iters), loss = 9.26663
I0523 01:16:06.949318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26663 (* 1 = 9.26663 loss)
I0523 01:16:07.765482 34819 sgd_solver.cpp:112] Iteration 24420, lr = 0.01
I0523 01:16:14.807555 34819 solver.cpp:239] Iteration 24430 (1.2726 iter/s, 7.85791s/10 iters), loss = 9.10813
I0523 01:16:14.807607 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10813 (* 1 = 9.10813 loss)
I0523 01:16:15.630441 34819 sgd_solver.cpp:112] Iteration 24430, lr = 0.01
I0523 01:16:18.865180 34819 solver.cpp:239] Iteration 24440 (2.46464 iter/s, 4.05739s/10 iters), loss = 9.18237
I0523 01:16:18.865224 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18237 (* 1 = 9.18237 loss)
I0523 01:16:18.951304 34819 sgd_solver.cpp:112] Iteration 24440, lr = 0.01
I0523 01:16:23.960243 34819 solver.cpp:239] Iteration 24450 (1.96279 iter/s, 5.09479s/10 iters), loss = 9.60983
I0523 01:16:23.960489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60983 (* 1 = 9.60983 loss)
I0523 01:16:24.030262 34819 sgd_solver.cpp:112] Iteration 24450, lr = 0.01
I0523 01:16:30.432366 34819 solver.cpp:239] Iteration 24460 (1.54521 iter/s, 6.47162s/10 iters), loss = 9.01463
I0523 01:16:30.432425 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01463 (* 1 = 9.01463 loss)
I0523 01:16:31.290513 34819 sgd_solver.cpp:112] Iteration 24460, lr = 0.01
I0523 01:16:34.480126 34819 solver.cpp:239] Iteration 24470 (2.47065 iter/s, 4.04752s/10 iters), loss = 8.86744
I0523 01:16:34.480180 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86744 (* 1 = 8.86744 loss)
I0523 01:16:34.558784 34819 sgd_solver.cpp:112] Iteration 24470, lr = 0.01
I0523 01:16:39.233870 34819 solver.cpp:239] Iteration 24480 (2.10372 iter/s, 4.75349s/10 iters), loss = 9.2031
I0523 01:16:39.233924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2031 (* 1 = 9.2031 loss)
I0523 01:16:40.057328 34819 sgd_solver.cpp:112] Iteration 24480, lr = 0.01
I0523 01:16:44.174228 34819 solver.cpp:239] Iteration 24490 (2.02425 iter/s, 4.9401s/10 iters), loss = 9.38086
I0523 01:16:44.174273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38086 (* 1 = 9.38086 loss)
I0523 01:16:44.234019 34819 sgd_solver.cpp:112] Iteration 24490, lr = 0.01
I0523 01:16:48.302670 34819 solver.cpp:239] Iteration 24500 (2.42236 iter/s, 4.12821s/10 iters), loss = 8.63212
I0523 01:16:48.302747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63212 (* 1 = 8.63212 loss)
I0523 01:16:49.092926 34819 sgd_solver.cpp:112] Iteration 24500, lr = 0.01
I0523 01:16:54.903144 34819 solver.cpp:239] Iteration 24510 (1.51513 iter/s, 6.60012s/10 iters), loss = 8.38274
I0523 01:16:54.903295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38274 (* 1 = 8.38274 loss)
I0523 01:16:54.969897 34819 sgd_solver.cpp:112] Iteration 24510, lr = 0.01
I0523 01:16:59.427203 34819 solver.cpp:239] Iteration 24520 (2.21058 iter/s, 4.52371s/10 iters), loss = 8.77701
I0523 01:16:59.427255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77701 (* 1 = 8.77701 loss)
I0523 01:16:59.493425 34819 sgd_solver.cpp:112] Iteration 24520, lr = 0.01
I0523 01:17:02.863524 34819 solver.cpp:239] Iteration 24530 (2.91026 iter/s, 3.43612s/10 iters), loss = 8.10597
I0523 01:17:02.863577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10597 (* 1 = 8.10597 loss)
I0523 01:17:03.725281 34819 sgd_solver.cpp:112] Iteration 24530, lr = 0.01
I0523 01:17:08.740119 34819 solver.cpp:239] Iteration 24540 (1.70175 iter/s, 5.8763s/10 iters), loss = 8.69215
I0523 01:17:08.740172 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69215 (* 1 = 8.69215 loss)
I0523 01:17:08.798956 34819 sgd_solver.cpp:112] Iteration 24540, lr = 0.01
I0523 01:17:12.408368 34819 solver.cpp:239] Iteration 24550 (2.72625 iter/s, 3.66804s/10 iters), loss = 9.01359
I0523 01:17:12.408411 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01359 (* 1 = 9.01359 loss)
I0523 01:17:12.479328 34819 sgd_solver.cpp:112] Iteration 24550, lr = 0.01
I0523 01:17:17.392832 34819 solver.cpp:239] Iteration 24560 (2.00633 iter/s, 4.98422s/10 iters), loss = 8.10446
I0523 01:17:17.392875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10446 (* 1 = 8.10446 loss)
I0523 01:17:17.462810 34819 sgd_solver.cpp:112] Iteration 24560, lr = 0.01
I0523 01:17:21.701400 34819 solver.cpp:239] Iteration 24570 (2.32108 iter/s, 4.30834s/10 iters), loss = 8.2403
I0523 01:17:21.701450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2403 (* 1 = 8.2403 loss)
I0523 01:17:21.762210 34819 sgd_solver.cpp:112] Iteration 24570, lr = 0.01
I0523 01:17:26.067051 34819 solver.cpp:239] Iteration 24580 (2.29073 iter/s, 4.36542s/10 iters), loss = 9.07469
I0523 01:17:26.067291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07469 (* 1 = 9.07469 loss)
I0523 01:17:26.138335 34819 sgd_solver.cpp:112] Iteration 24580, lr = 0.01
I0523 01:17:32.472810 34819 solver.cpp:239] Iteration 24590 (1.56121 iter/s, 6.40528s/10 iters), loss = 8.19269
I0523 01:17:32.472862 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19269 (* 1 = 8.19269 loss)
I0523 01:17:32.531302 34819 sgd_solver.cpp:112] Iteration 24590, lr = 0.01
I0523 01:17:36.463654 34819 solver.cpp:239] Iteration 24600 (2.50587 iter/s, 3.99062s/10 iters), loss = 8.95567
I0523 01:17:36.463706 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95567 (* 1 = 8.95567 loss)
I0523 01:17:36.683174 34819 sgd_solver.cpp:112] Iteration 24600, lr = 0.01
I0523 01:17:40.932971 34819 solver.cpp:239] Iteration 24610 (2.2376 iter/s, 4.46907s/10 iters), loss = 9.12805
I0523 01:17:40.933027 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12805 (* 1 = 9.12805 loss)
I0523 01:17:41.013486 34819 sgd_solver.cpp:112] Iteration 24610, lr = 0.01
I0523 01:17:46.689553 34819 solver.cpp:239] Iteration 24620 (1.73724 iter/s, 5.75627s/10 iters), loss = 7.97608
I0523 01:17:46.689604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97608 (* 1 = 7.97608 loss)
I0523 01:17:46.752151 34819 sgd_solver.cpp:112] Iteration 24620, lr = 0.01
I0523 01:17:52.500645 34819 solver.cpp:239] Iteration 24630 (1.72094 iter/s, 5.81078s/10 iters), loss = 8.58418
I0523 01:17:52.500705 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58418 (* 1 = 8.58418 loss)
I0523 01:17:53.311962 34819 sgd_solver.cpp:112] Iteration 24630, lr = 0.01
I0523 01:17:58.001950 34819 solver.cpp:239] Iteration 24640 (1.81785 iter/s, 5.50102s/10 iters), loss = 8.9339
I0523 01:17:58.002085 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9339 (* 1 = 8.9339 loss)
I0523 01:17:58.065696 34819 sgd_solver.cpp:112] Iteration 24640, lr = 0.01
I0523 01:18:03.758410 34819 solver.cpp:239] Iteration 24650 (1.73729 iter/s, 5.75608s/10 iters), loss = 7.92375
I0523 01:18:03.758450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92375 (* 1 = 7.92375 loss)
I0523 01:18:04.404279 34819 sgd_solver.cpp:112] Iteration 24650, lr = 0.01
I0523 01:18:11.495043 34819 solver.cpp:239] Iteration 24660 (1.29261 iter/s, 7.73628s/10 iters), loss = 8.58559
I0523 01:18:11.495085 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58559 (* 1 = 8.58559 loss)
I0523 01:18:11.565193 34819 sgd_solver.cpp:112] Iteration 24660, lr = 0.01
I0523 01:18:17.753108 34819 solver.cpp:239] Iteration 24670 (1.59801 iter/s, 6.25777s/10 iters), loss = 9.10155
I0523 01:18:17.753154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10155 (* 1 = 9.10155 loss)
I0523 01:18:17.822976 34819 sgd_solver.cpp:112] Iteration 24670, lr = 0.01
I0523 01:18:23.267745 34819 solver.cpp:239] Iteration 24680 (1.81345 iter/s, 5.51436s/10 iters), loss = 9.23048
I0523 01:18:23.267791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23048 (* 1 = 9.23048 loss)
I0523 01:18:23.342588 34819 sgd_solver.cpp:112] Iteration 24680, lr = 0.01
I0523 01:18:28.808269 34819 solver.cpp:239] Iteration 24690 (1.80497 iter/s, 5.54025s/10 iters), loss = 8.58186
I0523 01:18:28.808493 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58186 (* 1 = 8.58186 loss)
I0523 01:18:28.877723 34819 sgd_solver.cpp:112] Iteration 24690, lr = 0.01
I0523 01:18:34.347097 34819 solver.cpp:239] Iteration 24700 (1.80558 iter/s, 5.53839s/10 iters), loss = 9.21742
I0523 01:18:34.347146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21742 (* 1 = 9.21742 loss)
I0523 01:18:34.422144 34819 sgd_solver.cpp:112] Iteration 24700, lr = 0.01
I0523 01:18:38.253803 34819 solver.cpp:239] Iteration 24710 (2.55984 iter/s, 3.90649s/10 iters), loss = 8.42162
I0523 01:18:38.253844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42162 (* 1 = 8.42162 loss)
I0523 01:18:38.326009 34819 sgd_solver.cpp:112] Iteration 24710, lr = 0.01
I0523 01:18:41.649492 34819 solver.cpp:239] Iteration 24720 (2.94508 iter/s, 3.3955s/10 iters), loss = 9.13369
I0523 01:18:41.649536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13369 (* 1 = 9.13369 loss)
I0523 01:18:42.468062 34819 sgd_solver.cpp:112] Iteration 24720, lr = 0.01
I0523 01:18:45.639098 34819 solver.cpp:239] Iteration 24730 (2.50666 iter/s, 3.98937s/10 iters), loss = 8.9195
I0523 01:18:45.639168 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9195 (* 1 = 8.9195 loss)
I0523 01:18:45.703166 34819 sgd_solver.cpp:112] Iteration 24730, lr = 0.01
I0523 01:18:49.815110 34819 solver.cpp:239] Iteration 24740 (2.39477 iter/s, 4.17576s/10 iters), loss = 8.37962
I0523 01:18:49.815166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37962 (* 1 = 8.37962 loss)
I0523 01:18:50.637029 34819 sgd_solver.cpp:112] Iteration 24740, lr = 0.01
I0523 01:18:54.525382 34819 solver.cpp:239] Iteration 24750 (2.12313 iter/s, 4.71002s/10 iters), loss = 8.92702
I0523 01:18:54.525423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92702 (* 1 = 8.92702 loss)
I0523 01:18:55.110419 34819 sgd_solver.cpp:112] Iteration 24750, lr = 0.01
I0523 01:18:58.563931 34819 solver.cpp:239] Iteration 24760 (2.47627 iter/s, 4.03834s/10 iters), loss = 8.35502
I0523 01:18:58.563974 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35502 (* 1 = 8.35502 loss)
I0523 01:18:59.417799 34819 sgd_solver.cpp:112] Iteration 24760, lr = 0.01
I0523 01:19:02.044034 34819 solver.cpp:239] Iteration 24770 (2.87364 iter/s, 3.47991s/10 iters), loss = 8.82517
I0523 01:19:02.044083 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82517 (* 1 = 8.82517 loss)
I0523 01:19:02.105435 34819 sgd_solver.cpp:112] Iteration 24770, lr = 0.01
I0523 01:19:08.505267 34819 solver.cpp:239] Iteration 24780 (1.54777 iter/s, 6.46091s/10 iters), loss = 8.65593
I0523 01:19:08.505338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65593 (* 1 = 8.65593 loss)
I0523 01:19:08.569205 34819 sgd_solver.cpp:112] Iteration 24780, lr = 0.01
I0523 01:19:13.736294 34819 solver.cpp:239] Iteration 24790 (1.91178 iter/s, 5.23073s/10 iters), loss = 8.76494
I0523 01:19:13.736346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76494 (* 1 = 8.76494 loss)
I0523 01:19:14.439018 34819 sgd_solver.cpp:112] Iteration 24790, lr = 0.01
I0523 01:19:21.635620 34819 solver.cpp:239] Iteration 24800 (1.26599 iter/s, 7.89896s/10 iters), loss = 8.84973
I0523 01:19:21.635673 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84973 (* 1 = 8.84973 loss)
I0523 01:19:21.702118 34819 sgd_solver.cpp:112] Iteration 24800, lr = 0.01
I0523 01:19:27.981685 34819 solver.cpp:239] Iteration 24810 (1.57586 iter/s, 6.34574s/10 iters), loss = 8.46606
I0523 01:19:27.981747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46606 (* 1 = 8.46606 loss)
I0523 01:19:28.847892 34819 sgd_solver.cpp:112] Iteration 24810, lr = 0.01
I0523 01:19:33.861372 34819 solver.cpp:239] Iteration 24820 (1.70086 iter/s, 5.87938s/10 iters), loss = 8.4802
I0523 01:19:33.861546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4802 (* 1 = 8.4802 loss)
I0523 01:19:34.649790 34819 sgd_solver.cpp:112] Iteration 24820, lr = 0.01
I0523 01:19:41.461541 34819 solver.cpp:239] Iteration 24830 (1.31584 iter/s, 7.59971s/10 iters), loss = 9.78601
I0523 01:19:41.461587 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.78601 (* 1 = 9.78601 loss)
I0523 01:19:41.535229 34819 sgd_solver.cpp:112] Iteration 24830, lr = 0.01
I0523 01:19:47.359277 34819 solver.cpp:239] Iteration 24840 (1.69565 iter/s, 5.89745s/10 iters), loss = 9.69738
I0523 01:19:47.359333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.69738 (* 1 = 9.69738 loss)
I0523 01:19:47.429105 34819 sgd_solver.cpp:112] Iteration 24840, lr = 0.01
I0523 01:19:52.793089 34819 solver.cpp:239] Iteration 24850 (1.84043 iter/s, 5.43353s/10 iters), loss = 9.15342
I0523 01:19:52.793136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15342 (* 1 = 9.15342 loss)
I0523 01:19:52.852061 34819 sgd_solver.cpp:112] Iteration 24850, lr = 0.01
I0523 01:19:58.173491 34819 solver.cpp:239] Iteration 24860 (1.85869 iter/s, 5.38013s/10 iters), loss = 8.99335
I0523 01:19:58.173542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99335 (* 1 = 8.99335 loss)
I0523 01:19:58.235229 34819 sgd_solver.cpp:112] Iteration 24860, lr = 0.01
I0523 01:20:01.418630 34819 solver.cpp:239] Iteration 24870 (3.08172 iter/s, 3.24494s/10 iters), loss = 8.43276
I0523 01:20:01.418692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43276 (* 1 = 8.43276 loss)
I0523 01:20:01.488224 34819 sgd_solver.cpp:112] Iteration 24870, lr = 0.01
I0523 01:20:05.418403 34819 solver.cpp:239] Iteration 24880 (2.50031 iter/s, 3.99951s/10 iters), loss = 9.69234
I0523 01:20:05.418665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.69234 (* 1 = 9.69234 loss)
I0523 01:20:06.268882 34819 sgd_solver.cpp:112] Iteration 24880, lr = 0.01
I0523 01:20:09.360765 34819 solver.cpp:239] Iteration 24890 (2.53681 iter/s, 3.94196s/10 iters), loss = 8.01926
I0523 01:20:09.360810 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01926 (* 1 = 8.01926 loss)
I0523 01:20:09.950760 34819 sgd_solver.cpp:112] Iteration 24890, lr = 0.01
I0523 01:20:14.426328 34819 solver.cpp:239] Iteration 24900 (1.97422 iter/s, 5.0653s/10 iters), loss = 7.62396
I0523 01:20:14.426371 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62396 (* 1 = 7.62396 loss)
I0523 01:20:14.490715 34819 sgd_solver.cpp:112] Iteration 24900, lr = 0.01
I0523 01:20:20.277889 34819 solver.cpp:239] Iteration 24910 (1.70903 iter/s, 5.85128s/10 iters), loss = 8.64852
I0523 01:20:20.277942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64852 (* 1 = 8.64852 loss)
I0523 01:20:21.098577 34819 sgd_solver.cpp:112] Iteration 24910, lr = 0.01
I0523 01:20:27.389202 34819 solver.cpp:239] Iteration 24920 (1.40628 iter/s, 7.11097s/10 iters), loss = 8.8429
I0523 01:20:27.389247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8429 (* 1 = 8.8429 loss)
I0523 01:20:27.456507 34819 sgd_solver.cpp:112] Iteration 24920, lr = 0.01
I0523 01:20:33.047773 34819 solver.cpp:239] Iteration 24930 (1.76732 iter/s, 5.65829s/10 iters), loss = 8.68938
I0523 01:20:33.047817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68938 (* 1 = 8.68938 loss)
I0523 01:20:33.106042 34819 sgd_solver.cpp:112] Iteration 24930, lr = 0.01
I0523 01:20:38.085940 34819 solver.cpp:239] Iteration 24940 (1.98495 iter/s, 5.03791s/10 iters), loss = 9.34624
I0523 01:20:38.086033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34624 (* 1 = 9.34624 loss)
I0523 01:20:38.162065 34819 sgd_solver.cpp:112] Iteration 24940, lr = 0.01
I0523 01:20:43.288660 34819 solver.cpp:239] Iteration 24950 (1.92219 iter/s, 5.2024s/10 iters), loss = 8.96688
I0523 01:20:43.288704 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96688 (* 1 = 8.96688 loss)
I0523 01:20:43.905447 34819 sgd_solver.cpp:112] Iteration 24950, lr = 0.01
I0523 01:20:47.876319 34819 solver.cpp:239] Iteration 24960 (2.17988 iter/s, 4.58742s/10 iters), loss = 8.99743
I0523 01:20:47.876363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99743 (* 1 = 8.99743 loss)
I0523 01:20:48.372771 34819 sgd_solver.cpp:112] Iteration 24960, lr = 0.01
I0523 01:20:51.714489 34819 solver.cpp:239] Iteration 24970 (2.60555 iter/s, 3.83797s/10 iters), loss = 8.89516
I0523 01:20:51.714531 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89516 (* 1 = 8.89516 loss)
I0523 01:20:52.269258 34819 sgd_solver.cpp:112] Iteration 24970, lr = 0.01
I0523 01:20:56.792403 34819 solver.cpp:239] Iteration 24980 (1.96941 iter/s, 5.07766s/10 iters), loss = 8.8915
I0523 01:20:56.792448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8915 (* 1 = 8.8915 loss)
I0523 01:20:56.855574 34819 sgd_solver.cpp:112] Iteration 24980, lr = 0.01
I0523 01:21:00.386847 34819 solver.cpp:239] Iteration 24990 (2.78224 iter/s, 3.59423s/10 iters), loss = 8.75569
I0523 01:21:00.386901 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75569 (* 1 = 8.75569 loss)
I0523 01:21:01.149782 34819 sgd_solver.cpp:112] Iteration 24990, lr = 0.01
I0523 01:21:06.160709 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_25000.caffemodel
I0523 01:21:11.403203 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_25000.solverstate
I0523 01:21:11.607228 34819 solver.cpp:239] Iteration 25000 (0.891274 iter/s, 11.2199s/10 iters), loss = 8.5478
I0523 01:21:11.607270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5478 (* 1 = 8.5478 loss)
I0523 01:21:11.688251 34819 sgd_solver.cpp:112] Iteration 25000, lr = 0.01
I0523 01:21:15.978829 34819 solver.cpp:239] Iteration 25010 (2.28761 iter/s, 4.37137s/10 iters), loss = 8.80508
I0523 01:21:15.978873 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80508 (* 1 = 8.80508 loss)
I0523 01:21:16.049870 34819 sgd_solver.cpp:112] Iteration 25010, lr = 0.01
I0523 01:21:20.161984 34819 solver.cpp:239] Iteration 25020 (2.39066 iter/s, 4.18294s/10 iters), loss = 8.75542
I0523 01:21:20.162026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75542 (* 1 = 8.75542 loss)
I0523 01:21:20.428894 34819 sgd_solver.cpp:112] Iteration 25020, lr = 0.01
I0523 01:21:25.224813 34819 solver.cpp:239] Iteration 25030 (1.97529 iter/s, 5.06254s/10 iters), loss = 9.16855
I0523 01:21:25.224866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16855 (* 1 = 9.16855 loss)
I0523 01:21:26.087635 34819 sgd_solver.cpp:112] Iteration 25030, lr = 0.01
I0523 01:21:30.390765 34819 solver.cpp:239] Iteration 25040 (1.93586 iter/s, 5.16566s/10 iters), loss = 9.22571
I0523 01:21:30.390815 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22571 (* 1 = 9.22571 loss)
I0523 01:21:31.147135 34819 sgd_solver.cpp:112] Iteration 25040, lr = 0.01
I0523 01:21:36.167511 34819 solver.cpp:239] Iteration 25050 (1.73117 iter/s, 5.77645s/10 iters), loss = 9.107
I0523 01:21:36.167554 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.107 (* 1 = 9.107 loss)
I0523 01:21:36.243176 34819 sgd_solver.cpp:112] Iteration 25050, lr = 0.01
I0523 01:21:41.651892 34819 solver.cpp:239] Iteration 25060 (1.82345 iter/s, 5.48411s/10 iters), loss = 8.22992
I0523 01:21:41.652031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22992 (* 1 = 8.22992 loss)
I0523 01:21:41.728973 34819 sgd_solver.cpp:112] Iteration 25060, lr = 0.01
I0523 01:21:48.304256 34819 solver.cpp:239] Iteration 25070 (1.50332 iter/s, 6.65195s/10 iters), loss = 9.07059
I0523 01:21:48.304301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07059 (* 1 = 9.07059 loss)
I0523 01:21:48.379729 34819 sgd_solver.cpp:112] Iteration 25070, lr = 0.01
I0523 01:21:53.261876 34819 solver.cpp:239] Iteration 25080 (2.01721 iter/s, 4.95734s/10 iters), loss = 9.31849
I0523 01:21:53.261930 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31849 (* 1 = 9.31849 loss)
I0523 01:21:54.131711 34819 sgd_solver.cpp:112] Iteration 25080, lr = 0.01
I0523 01:21:57.879426 34819 solver.cpp:239] Iteration 25090 (2.16577 iter/s, 4.61729s/10 iters), loss = 8.38215
I0523 01:21:57.879469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38215 (* 1 = 8.38215 loss)
I0523 01:21:58.745571 34819 sgd_solver.cpp:112] Iteration 25090, lr = 0.01
I0523 01:22:02.587838 34819 solver.cpp:239] Iteration 25100 (2.12397 iter/s, 4.70816s/10 iters), loss = 9.60067
I0523 01:22:02.587882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60067 (* 1 = 9.60067 loss)
I0523 01:22:03.225965 34819 sgd_solver.cpp:112] Iteration 25100, lr = 0.01
I0523 01:22:07.672657 34819 solver.cpp:239] Iteration 25110 (1.96674 iter/s, 5.08455s/10 iters), loss = 8.51898
I0523 01:22:07.672711 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51898 (* 1 = 8.51898 loss)
I0523 01:22:08.484694 34819 sgd_solver.cpp:112] Iteration 25110, lr = 0.01
I0523 01:22:12.587472 34819 solver.cpp:239] Iteration 25120 (2.03477 iter/s, 4.91455s/10 iters), loss = 9.19353
I0523 01:22:12.587707 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19353 (* 1 = 9.19353 loss)
I0523 01:22:13.442790 34819 sgd_solver.cpp:112] Iteration 25120, lr = 0.01
I0523 01:22:17.861769 34819 solver.cpp:239] Iteration 25130 (1.89614 iter/s, 5.27387s/10 iters), loss = 9.72764
I0523 01:22:17.861814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72764 (* 1 = 9.72764 loss)
I0523 01:22:18.686125 34819 sgd_solver.cpp:112] Iteration 25130, lr = 0.01
I0523 01:22:22.094867 34819 solver.cpp:239] Iteration 25140 (2.36247 iter/s, 4.23286s/10 iters), loss = 8.07431
I0523 01:22:22.094936 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07431 (* 1 = 8.07431 loss)
I0523 01:22:22.870805 34819 sgd_solver.cpp:112] Iteration 25140, lr = 0.01
I0523 01:22:25.429150 34819 solver.cpp:239] Iteration 25150 (2.99933 iter/s, 3.33407s/10 iters), loss = 8.66187
I0523 01:22:25.429205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66187 (* 1 = 8.66187 loss)
I0523 01:22:26.018785 34819 sgd_solver.cpp:112] Iteration 25150, lr = 0.01
I0523 01:22:29.559540 34819 solver.cpp:239] Iteration 25160 (2.42122 iter/s, 4.13015s/10 iters), loss = 8.94477
I0523 01:22:29.559599 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94477 (* 1 = 8.94477 loss)
I0523 01:22:30.398558 34819 sgd_solver.cpp:112] Iteration 25160, lr = 0.01
I0523 01:22:35.125483 34819 solver.cpp:239] Iteration 25170 (1.79674 iter/s, 5.56564s/10 iters), loss = 8.41111
I0523 01:22:35.125540 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41111 (* 1 = 8.41111 loss)
I0523 01:22:35.935565 34819 sgd_solver.cpp:112] Iteration 25170, lr = 0.01
I0523 01:22:41.677613 34819 solver.cpp:239] Iteration 25180 (1.5263 iter/s, 6.55181s/10 iters), loss = 8.64399
I0523 01:22:41.677664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64399 (* 1 = 8.64399 loss)
I0523 01:22:41.733582 34819 sgd_solver.cpp:112] Iteration 25180, lr = 0.01
I0523 01:22:46.624248 34819 solver.cpp:239] Iteration 25190 (2.02169 iter/s, 4.94635s/10 iters), loss = 8.50774
I0523 01:22:46.624428 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50774 (* 1 = 8.50774 loss)
I0523 01:22:46.680172 34819 sgd_solver.cpp:112] Iteration 25190, lr = 0.01
I0523 01:22:52.931193 34819 solver.cpp:239] Iteration 25200 (1.58566 iter/s, 6.30651s/10 iters), loss = 8.80998
I0523 01:22:52.931246 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80998 (* 1 = 8.80998 loss)
I0523 01:22:53.004465 34819 sgd_solver.cpp:112] Iteration 25200, lr = 0.01
I0523 01:22:56.967630 34819 solver.cpp:239] Iteration 25210 (2.47758 iter/s, 4.0362s/10 iters), loss = 8.65349
I0523 01:22:56.967685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65349 (* 1 = 8.65349 loss)
I0523 01:22:57.144222 34819 sgd_solver.cpp:112] Iteration 25210, lr = 0.01
I0523 01:23:00.898258 34819 solver.cpp:239] Iteration 25220 (2.54428 iter/s, 3.93039s/10 iters), loss = 8.82358
I0523 01:23:00.898329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82358 (* 1 = 8.82358 loss)
I0523 01:23:01.751760 34819 sgd_solver.cpp:112] Iteration 25220, lr = 0.01
I0523 01:23:05.966398 34819 solver.cpp:239] Iteration 25230 (1.97323 iter/s, 5.06784s/10 iters), loss = 7.71507
I0523 01:23:05.966467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71507 (* 1 = 7.71507 loss)
I0523 01:23:06.035698 34819 sgd_solver.cpp:112] Iteration 25230, lr = 0.01
I0523 01:23:09.385363 34819 solver.cpp:239] Iteration 25240 (2.92505 iter/s, 3.41875s/10 iters), loss = 8.18682
I0523 01:23:09.385422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18682 (* 1 = 8.18682 loss)
I0523 01:23:10.269940 34819 sgd_solver.cpp:112] Iteration 25240, lr = 0.01
I0523 01:23:14.081048 34819 solver.cpp:239] Iteration 25250 (2.12973 iter/s, 4.69543s/10 iters), loss = 8.08926
I0523 01:23:14.081104 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08926 (* 1 = 8.08926 loss)
I0523 01:23:14.821178 34819 sgd_solver.cpp:112] Iteration 25250, lr = 0.01
I0523 01:23:18.209401 34819 solver.cpp:239] Iteration 25260 (2.42242 iter/s, 4.1281s/10 iters), loss = 8.30447
I0523 01:23:18.209580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30447 (* 1 = 8.30447 loss)
I0523 01:23:18.962095 34819 sgd_solver.cpp:112] Iteration 25260, lr = 0.01
I0523 01:23:25.766475 34819 solver.cpp:239] Iteration 25270 (1.32335 iter/s, 7.55659s/10 iters), loss = 8.28554
I0523 01:23:25.766528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28554 (* 1 = 8.28554 loss)
I0523 01:23:26.576627 34819 sgd_solver.cpp:112] Iteration 25270, lr = 0.01
I0523 01:23:31.239562 34819 solver.cpp:239] Iteration 25280 (1.82722 iter/s, 5.4728s/10 iters), loss = 7.98736
I0523 01:23:31.239617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98736 (* 1 = 7.98736 loss)
I0523 01:23:32.003764 34819 sgd_solver.cpp:112] Iteration 25280, lr = 0.01
I0523 01:23:35.137117 34819 solver.cpp:239] Iteration 25290 (2.56586 iter/s, 3.89733s/10 iters), loss = 9.26339
I0523 01:23:35.137184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26339 (* 1 = 9.26339 loss)
I0523 01:23:35.196733 34819 sgd_solver.cpp:112] Iteration 25290, lr = 0.01
I0523 01:23:39.955235 34819 solver.cpp:239] Iteration 25300 (2.07562 iter/s, 4.81783s/10 iters), loss = 8.67685
I0523 01:23:39.955293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67685 (* 1 = 8.67685 loss)
I0523 01:23:40.578315 34819 sgd_solver.cpp:112] Iteration 25300, lr = 0.01
I0523 01:23:45.359710 34819 solver.cpp:239] Iteration 25310 (1.85043 iter/s, 5.40416s/10 iters), loss = 9.17616
I0523 01:23:45.359783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17616 (* 1 = 9.17616 loss)
I0523 01:23:46.140672 34819 sgd_solver.cpp:112] Iteration 25310, lr = 0.01
I0523 01:23:48.757891 34819 solver.cpp:239] Iteration 25320 (2.94295 iter/s, 3.39795s/10 iters), loss = 9.58532
I0523 01:23:48.758054 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58532 (* 1 = 9.58532 loss)
I0523 01:23:48.828814 34819 sgd_solver.cpp:112] Iteration 25320, lr = 0.01
I0523 01:23:52.126297 34819 solver.cpp:239] Iteration 25330 (2.96903 iter/s, 3.36811s/10 iters), loss = 8.5837
I0523 01:23:52.126351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5837 (* 1 = 8.5837 loss)
I0523 01:23:52.186506 34819 sgd_solver.cpp:112] Iteration 25330, lr = 0.01
I0523 01:23:56.135165 34819 solver.cpp:239] Iteration 25340 (2.49461 iter/s, 4.00864s/10 iters), loss = 8.7689
I0523 01:23:56.135244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7689 (* 1 = 8.7689 loss)
I0523 01:23:56.204782 34819 sgd_solver.cpp:112] Iteration 25340, lr = 0.01
I0523 01:24:01.680881 34819 solver.cpp:239] Iteration 25350 (1.80329 iter/s, 5.54541s/10 iters), loss = 9.00831
I0523 01:24:01.680943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00831 (* 1 = 9.00831 loss)
I0523 01:24:01.744431 34819 sgd_solver.cpp:112] Iteration 25350, lr = 0.01
I0523 01:24:05.192162 34819 solver.cpp:239] Iteration 25360 (2.84814 iter/s, 3.51107s/10 iters), loss = 8.98261
I0523 01:24:05.192222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98261 (* 1 = 8.98261 loss)
I0523 01:24:05.260512 34819 sgd_solver.cpp:112] Iteration 25360, lr = 0.01
I0523 01:24:11.985453 34819 solver.cpp:239] Iteration 25370 (1.47212 iter/s, 6.79292s/10 iters), loss = 9.0057
I0523 01:24:11.985523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0057 (* 1 = 9.0057 loss)
I0523 01:24:12.819725 34819 sgd_solver.cpp:112] Iteration 25370, lr = 0.01
I0523 01:24:16.921111 34819 solver.cpp:239] Iteration 25380 (2.02619 iter/s, 4.93537s/10 iters), loss = 10.2589
I0523 01:24:16.921175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2589 (* 1 = 10.2589 loss)
I0523 01:24:16.991066 34819 sgd_solver.cpp:112] Iteration 25380, lr = 0.01
I0523 01:24:22.533501 34819 solver.cpp:239] Iteration 25390 (1.78187 iter/s, 5.61208s/10 iters), loss = 8.57691
I0523 01:24:22.533789 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57691 (* 1 = 8.57691 loss)
I0523 01:24:23.402210 34819 sgd_solver.cpp:112] Iteration 25390, lr = 0.01
I0523 01:24:27.655925 34819 solver.cpp:239] Iteration 25400 (1.95239 iter/s, 5.12193s/10 iters), loss = 9.21794
I0523 01:24:27.655987 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21794 (* 1 = 9.21794 loss)
I0523 01:24:27.740577 34819 sgd_solver.cpp:112] Iteration 25400, lr = 0.01
I0523 01:24:32.090582 34819 solver.cpp:239] Iteration 25410 (2.25509 iter/s, 4.43441s/10 iters), loss = 9.38885
I0523 01:24:32.090637 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38885 (* 1 = 9.38885 loss)
I0523 01:24:32.930582 34819 sgd_solver.cpp:112] Iteration 25410, lr = 0.01
I0523 01:24:36.690201 34819 solver.cpp:239] Iteration 25420 (2.17421 iter/s, 4.59937s/10 iters), loss = 8.84747
I0523 01:24:36.690271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84747 (* 1 = 8.84747 loss)
I0523 01:24:36.758734 34819 sgd_solver.cpp:112] Iteration 25420, lr = 0.01
I0523 01:24:42.348853 34819 solver.cpp:239] Iteration 25430 (1.7673 iter/s, 5.65835s/10 iters), loss = 9.3803
I0523 01:24:42.348917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3803 (* 1 = 9.3803 loss)
I0523 01:24:43.190484 34819 sgd_solver.cpp:112] Iteration 25430, lr = 0.01
I0523 01:24:47.983178 34819 solver.cpp:239] Iteration 25440 (1.77493 iter/s, 5.63402s/10 iters), loss = 9.0717
I0523 01:24:47.983230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0717 (* 1 = 9.0717 loss)
I0523 01:24:48.048671 34819 sgd_solver.cpp:112] Iteration 25440, lr = 0.01
I0523 01:24:51.375406 34819 solver.cpp:239] Iteration 25450 (2.9481 iter/s, 3.39202s/10 iters), loss = 9.11373
I0523 01:24:51.375485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11373 (* 1 = 9.11373 loss)
I0523 01:24:52.202872 34819 sgd_solver.cpp:112] Iteration 25450, lr = 0.01
I0523 01:24:56.930510 34819 solver.cpp:239] Iteration 25460 (1.80025 iter/s, 5.5548s/10 iters), loss = 8.41656
I0523 01:24:56.930687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41656 (* 1 = 8.41656 loss)
I0523 01:24:57.515373 34819 sgd_solver.cpp:112] Iteration 25460, lr = 0.01
I0523 01:25:02.383014 34819 solver.cpp:239] Iteration 25470 (1.83416 iter/s, 5.4521s/10 iters), loss = 8.64034
I0523 01:25:02.383081 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64034 (* 1 = 8.64034 loss)
I0523 01:25:02.458966 34819 sgd_solver.cpp:112] Iteration 25470, lr = 0.01
I0523 01:25:07.443403 34819 solver.cpp:239] Iteration 25480 (1.97625 iter/s, 5.06009s/10 iters), loss = 9.21895
I0523 01:25:07.443461 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21895 (* 1 = 9.21895 loss)
I0523 01:25:08.120074 34819 sgd_solver.cpp:112] Iteration 25480, lr = 0.01
I0523 01:25:14.279402 34819 solver.cpp:239] Iteration 25490 (1.46292 iter/s, 6.83566s/10 iters), loss = 8.69716
I0523 01:25:14.279448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69716 (* 1 = 8.69716 loss)
I0523 01:25:14.363601 34819 sgd_solver.cpp:112] Iteration 25490, lr = 0.01
I0523 01:25:18.482081 34819 solver.cpp:239] Iteration 25500 (2.37957 iter/s, 4.20244s/10 iters), loss = 7.74202
I0523 01:25:18.482136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74202 (* 1 = 7.74202 loss)
I0523 01:25:18.552479 34819 sgd_solver.cpp:112] Iteration 25500, lr = 0.01
I0523 01:25:24.010254 34819 solver.cpp:239] Iteration 25510 (1.80901 iter/s, 5.52788s/10 iters), loss = 7.89159
I0523 01:25:24.010303 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89159 (* 1 = 7.89159 loss)
I0523 01:25:24.749539 34819 sgd_solver.cpp:112] Iteration 25510, lr = 0.01
I0523 01:25:28.522936 34819 solver.cpp:239] Iteration 25520 (2.2161 iter/s, 4.51243s/10 iters), loss = 9.21889
I0523 01:25:28.523195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21889 (* 1 = 9.21889 loss)
I0523 01:25:28.593453 34819 sgd_solver.cpp:112] Iteration 25520, lr = 0.01
I0523 01:25:33.764993 34819 solver.cpp:239] Iteration 25530 (1.90781 iter/s, 5.2416s/10 iters), loss = 8.64457
I0523 01:25:33.765048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64457 (* 1 = 8.64457 loss)
I0523 01:25:33.823783 34819 sgd_solver.cpp:112] Iteration 25530, lr = 0.01
I0523 01:25:39.497721 34819 solver.cpp:239] Iteration 25540 (1.74446 iter/s, 5.73244s/10 iters), loss = 8.46881
I0523 01:25:39.497766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46881 (* 1 = 8.46881 loss)
I0523 01:25:40.234508 34819 sgd_solver.cpp:112] Iteration 25540, lr = 0.01
I0523 01:25:45.504899 34819 solver.cpp:239] Iteration 25550 (1.66476 iter/s, 6.00689s/10 iters), loss = 8.69262
I0523 01:25:45.504945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69262 (* 1 = 8.69262 loss)
I0523 01:25:45.588464 34819 sgd_solver.cpp:112] Iteration 25550, lr = 0.01
I0523 01:25:50.636277 34819 solver.cpp:239] Iteration 25560 (1.9489 iter/s, 5.13111s/10 iters), loss = 8.2544
I0523 01:25:50.636322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2544 (* 1 = 8.2544 loss)
I0523 01:25:50.738669 34819 sgd_solver.cpp:112] Iteration 25560, lr = 0.01
I0523 01:25:54.736737 34819 solver.cpp:239] Iteration 25570 (2.43888 iter/s, 4.10024s/10 iters), loss = 8.73336
I0523 01:25:54.736779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73336 (* 1 = 8.73336 loss)
I0523 01:25:54.786970 34819 sgd_solver.cpp:112] Iteration 25570, lr = 0.01
I0523 01:25:58.117094 34819 solver.cpp:239] Iteration 25580 (2.95844 iter/s, 3.38016s/10 iters), loss = 8.53224
I0523 01:25:58.117147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53224 (* 1 = 8.53224 loss)
I0523 01:25:58.583704 34819 sgd_solver.cpp:112] Iteration 25580, lr = 0.01
I0523 01:26:03.097618 34819 solver.cpp:239] Iteration 25590 (2.00792 iter/s, 4.98027s/10 iters), loss = 8.38131
I0523 01:26:03.097672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38131 (* 1 = 8.38131 loss)
I0523 01:26:03.174834 34819 sgd_solver.cpp:112] Iteration 25590, lr = 0.01
I0523 01:26:08.073143 34819 solver.cpp:239] Iteration 25600 (2.00994 iter/s, 4.97527s/10 iters), loss = 9.73285
I0523 01:26:08.073186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.73285 (* 1 = 9.73285 loss)
I0523 01:26:08.122349 34819 sgd_solver.cpp:112] Iteration 25600, lr = 0.01
I0523 01:26:12.215466 34819 solver.cpp:239] Iteration 25610 (2.41424 iter/s, 4.1421s/10 iters), loss = 9.38676
I0523 01:26:12.215507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38676 (* 1 = 9.38676 loss)
I0523 01:26:12.285898 34819 sgd_solver.cpp:112] Iteration 25610, lr = 0.01
I0523 01:26:15.055400 34819 solver.cpp:239] Iteration 25620 (3.52143 iter/s, 2.83976s/10 iters), loss = 8.55204
I0523 01:26:15.055457 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55204 (* 1 = 8.55204 loss)
I0523 01:26:15.884716 34819 sgd_solver.cpp:112] Iteration 25620, lr = 0.01
I0523 01:26:22.973937 34819 solver.cpp:239] Iteration 25630 (1.26292 iter/s, 7.91815s/10 iters), loss = 9.06498
I0523 01:26:22.973991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06498 (* 1 = 9.06498 loss)
I0523 01:26:23.028478 34819 sgd_solver.cpp:112] Iteration 25630, lr = 0.01
I0523 01:26:27.771742 34819 solver.cpp:239] Iteration 25640 (2.0844 iter/s, 4.79755s/10 iters), loss = 8.25683
I0523 01:26:27.771788 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25683 (* 1 = 8.25683 loss)
I0523 01:26:28.645124 34819 sgd_solver.cpp:112] Iteration 25640, lr = 0.01
I0523 01:26:31.869542 34819 solver.cpp:239] Iteration 25650 (2.44046 iter/s, 4.09758s/10 iters), loss = 9.10132
I0523 01:26:31.869585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10132 (* 1 = 9.10132 loss)
I0523 01:26:32.680009 34819 sgd_solver.cpp:112] Iteration 25650, lr = 0.01
I0523 01:26:37.957793 34819 solver.cpp:239] Iteration 25660 (1.64259 iter/s, 6.08796s/10 iters), loss = 8.71227
I0523 01:26:37.957844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71227 (* 1 = 8.71227 loss)
I0523 01:26:38.019040 34819 sgd_solver.cpp:112] Iteration 25660, lr = 0.01
I0523 01:26:43.478000 34819 solver.cpp:239] Iteration 25670 (1.81238 iter/s, 5.51762s/10 iters), loss = 8.93454
I0523 01:26:43.478046 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93454 (* 1 = 8.93454 loss)
I0523 01:26:43.534201 34819 sgd_solver.cpp:112] Iteration 25670, lr = 0.01
I0523 01:26:46.967128 34819 solver.cpp:239] Iteration 25680 (2.86621 iter/s, 3.48893s/10 iters), loss = 9.32277
I0523 01:26:46.967173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32277 (* 1 = 9.32277 loss)
I0523 01:26:47.774221 34819 sgd_solver.cpp:112] Iteration 25680, lr = 0.01
I0523 01:26:50.706878 34819 solver.cpp:239] Iteration 25690 (2.67412 iter/s, 3.73954s/10 iters), loss = 7.62705
I0523 01:26:50.706935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62705 (* 1 = 7.62705 loss)
I0523 01:26:50.777199 34819 sgd_solver.cpp:112] Iteration 25690, lr = 0.01
I0523 01:26:54.631090 34819 solver.cpp:239] Iteration 25700 (2.54843 iter/s, 3.92398s/10 iters), loss = 8.71921
I0523 01:26:54.631144 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71921 (* 1 = 8.71921 loss)
I0523 01:26:55.481292 34819 sgd_solver.cpp:112] Iteration 25700, lr = 0.01
I0523 01:27:00.383105 34819 solver.cpp:239] Iteration 25710 (1.73861 iter/s, 5.75172s/10 iters), loss = 8.63558
I0523 01:27:00.383355 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63558 (* 1 = 8.63558 loss)
I0523 01:27:01.254956 34819 sgd_solver.cpp:112] Iteration 25710, lr = 0.01
I0523 01:27:05.892421 34819 solver.cpp:239] Iteration 25720 (1.81526 iter/s, 5.50884s/10 iters), loss = 8.4043
I0523 01:27:05.892485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4043 (* 1 = 8.4043 loss)
I0523 01:27:05.952440 34819 sgd_solver.cpp:112] Iteration 25720, lr = 0.01
I0523 01:27:11.595283 34819 solver.cpp:239] Iteration 25730 (1.7536 iter/s, 5.70255s/10 iters), loss = 8.6718
I0523 01:27:11.595333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6718 (* 1 = 8.6718 loss)
I0523 01:27:11.658921 34819 sgd_solver.cpp:112] Iteration 25730, lr = 0.01
I0523 01:27:15.854315 34819 solver.cpp:239] Iteration 25740 (2.34808 iter/s, 4.25879s/10 iters), loss = 8.79314
I0523 01:27:15.854375 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79314 (* 1 = 8.79314 loss)
I0523 01:27:15.920091 34819 sgd_solver.cpp:112] Iteration 25740, lr = 0.01
I0523 01:27:19.369354 34819 solver.cpp:239] Iteration 25750 (2.84509 iter/s, 3.51483s/10 iters), loss = 8.63598
I0523 01:27:19.369410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63598 (* 1 = 8.63598 loss)
I0523 01:27:19.445475 34819 sgd_solver.cpp:112] Iteration 25750, lr = 0.01
I0523 01:27:24.784044 34819 solver.cpp:239] Iteration 25760 (1.84692 iter/s, 5.41442s/10 iters), loss = 8.89735
I0523 01:27:24.784090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89735 (* 1 = 8.89735 loss)
I0523 01:27:24.858777 34819 sgd_solver.cpp:112] Iteration 25760, lr = 0.01
I0523 01:27:30.370818 34819 solver.cpp:239] Iteration 25770 (1.79004 iter/s, 5.58647s/10 iters), loss = 9.21493
I0523 01:27:30.370884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21493 (* 1 = 9.21493 loss)
I0523 01:27:31.245120 34819 sgd_solver.cpp:112] Iteration 25770, lr = 0.01
I0523 01:27:34.827386 34819 solver.cpp:239] Iteration 25780 (2.24402 iter/s, 4.45629s/10 iters), loss = 8.91213
I0523 01:27:34.827448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91213 (* 1 = 8.91213 loss)
I0523 01:27:35.214597 34819 sgd_solver.cpp:112] Iteration 25780, lr = 0.01
I0523 01:27:41.045267 34819 solver.cpp:239] Iteration 25790 (1.60835 iter/s, 6.21757s/10 iters), loss = 9.21074
I0523 01:27:41.045322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21074 (* 1 = 9.21074 loss)
I0523 01:27:41.118934 34819 sgd_solver.cpp:112] Iteration 25790, lr = 0.01
I0523 01:27:44.464597 34819 solver.cpp:239] Iteration 25800 (2.92472 iter/s, 3.41913s/10 iters), loss = 9.33595
I0523 01:27:44.464640 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33595 (* 1 = 9.33595 loss)
I0523 01:27:44.541688 34819 sgd_solver.cpp:112] Iteration 25800, lr = 0.01
I0523 01:27:48.664954 34819 solver.cpp:239] Iteration 25810 (2.38088 iter/s, 4.20013s/10 iters), loss = 8.03044
I0523 01:27:48.665009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03044 (* 1 = 8.03044 loss)
I0523 01:27:48.727829 34819 sgd_solver.cpp:112] Iteration 25810, lr = 0.01
I0523 01:27:54.464030 34819 solver.cpp:239] Iteration 25820 (1.7245 iter/s, 5.79878s/10 iters), loss = 7.99846
I0523 01:27:54.464089 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99846 (* 1 = 7.99846 loss)
I0523 01:27:55.260614 34819 sgd_solver.cpp:112] Iteration 25820, lr = 0.01
I0523 01:27:58.724704 34819 solver.cpp:239] Iteration 25830 (2.34718 iter/s, 4.26042s/10 iters), loss = 8.39752
I0523 01:27:58.724761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39752 (* 1 = 8.39752 loss)
I0523 01:27:58.999001 34819 sgd_solver.cpp:112] Iteration 25830, lr = 0.01
I0523 01:28:05.484755 34819 solver.cpp:239] Iteration 25840 (1.47935 iter/s, 6.75972s/10 iters), loss = 9.22694
I0523 01:28:05.484894 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22694 (* 1 = 9.22694 loss)
I0523 01:28:05.559904 34819 sgd_solver.cpp:112] Iteration 25840, lr = 0.01
I0523 01:28:09.148169 34819 solver.cpp:239] Iteration 25850 (2.72992 iter/s, 3.66312s/10 iters), loss = 8.4682
I0523 01:28:09.148223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4682 (* 1 = 8.4682 loss)
I0523 01:28:09.222611 34819 sgd_solver.cpp:112] Iteration 25850, lr = 0.01
I0523 01:28:14.591323 34819 solver.cpp:239] Iteration 25860 (1.83727 iter/s, 5.44286s/10 iters), loss = 9.02311
I0523 01:28:14.591378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02311 (* 1 = 9.02311 loss)
I0523 01:28:14.661362 34819 sgd_solver.cpp:112] Iteration 25860, lr = 0.01
I0523 01:28:18.569173 34819 solver.cpp:239] Iteration 25870 (2.51407 iter/s, 3.97761s/10 iters), loss = 9.18407
I0523 01:28:18.569229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18407 (* 1 = 9.18407 loss)
I0523 01:28:18.628806 34819 sgd_solver.cpp:112] Iteration 25870, lr = 0.01
I0523 01:28:21.158831 34819 solver.cpp:239] Iteration 25880 (3.86177 iter/s, 2.58949s/10 iters), loss = 8.61015
I0523 01:28:21.158884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61015 (* 1 = 8.61015 loss)
I0523 01:28:21.218730 34819 sgd_solver.cpp:112] Iteration 25880, lr = 0.01
I0523 01:28:24.851636 34819 solver.cpp:239] Iteration 25890 (2.70812 iter/s, 3.69259s/10 iters), loss = 8.40446
I0523 01:28:24.851687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40446 (* 1 = 8.40446 loss)
I0523 01:28:24.907119 34819 sgd_solver.cpp:112] Iteration 25890, lr = 0.01
I0523 01:28:28.570554 34819 solver.cpp:239] Iteration 25900 (2.68911 iter/s, 3.71871s/10 iters), loss = 7.80507
I0523 01:28:28.570605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80507 (* 1 = 7.80507 loss)
I0523 01:28:28.626611 34819 sgd_solver.cpp:112] Iteration 25900, lr = 0.01
I0523 01:28:32.115998 34819 solver.cpp:239] Iteration 25910 (2.82071 iter/s, 3.5452s/10 iters), loss = 8.3349
I0523 01:28:32.116051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3349 (* 1 = 8.3349 loss)
I0523 01:28:32.725699 34819 sgd_solver.cpp:112] Iteration 25910, lr = 0.01
I0523 01:28:36.873091 34819 solver.cpp:239] Iteration 25920 (2.10223 iter/s, 4.75684s/10 iters), loss = 9.18756
I0523 01:28:36.873342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18756 (* 1 = 9.18756 loss)
I0523 01:28:36.941567 34819 sgd_solver.cpp:112] Iteration 25920, lr = 0.01
I0523 01:28:42.032454 34819 solver.cpp:239] Iteration 25930 (1.93839 iter/s, 5.15893s/10 iters), loss = 8.73109
I0523 01:28:42.032505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73109 (* 1 = 8.73109 loss)
I0523 01:28:42.105119 34819 sgd_solver.cpp:112] Iteration 25930, lr = 0.01
I0523 01:28:47.621063 34819 solver.cpp:239] Iteration 25940 (1.78944 iter/s, 5.58833s/10 iters), loss = 8.91239
I0523 01:28:47.621107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91239 (* 1 = 8.91239 loss)
I0523 01:28:47.679917 34819 sgd_solver.cpp:112] Iteration 25940, lr = 0.01
I0523 01:28:52.101227 34819 solver.cpp:239] Iteration 25950 (2.23218 iter/s, 4.47992s/10 iters), loss = 8.93124
I0523 01:28:52.101282 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93124 (* 1 = 8.93124 loss)
I0523 01:28:52.163619 34819 sgd_solver.cpp:112] Iteration 25950, lr = 0.01
I0523 01:28:55.755733 34819 solver.cpp:239] Iteration 25960 (2.73651 iter/s, 3.65429s/10 iters), loss = 9.3292
I0523 01:28:55.755785 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3292 (* 1 = 9.3292 loss)
I0523 01:28:55.814477 34819 sgd_solver.cpp:112] Iteration 25960, lr = 0.01
I0523 01:29:01.003512 34819 solver.cpp:239] Iteration 25970 (1.90567 iter/s, 5.24749s/10 iters), loss = 8.92741
I0523 01:29:01.003583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92741 (* 1 = 8.92741 loss)
I0523 01:29:01.744406 34819 sgd_solver.cpp:112] Iteration 25970, lr = 0.01
I0523 01:29:06.678661 34819 solver.cpp:239] Iteration 25980 (1.76216 iter/s, 5.67485s/10 iters), loss = 8.99676
I0523 01:29:06.678737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99676 (* 1 = 8.99676 loss)
I0523 01:29:06.754252 34819 sgd_solver.cpp:112] Iteration 25980, lr = 0.01
I0523 01:29:12.256764 34819 solver.cpp:239] Iteration 25990 (1.79282 iter/s, 5.57779s/10 iters), loss = 8.59691
I0523 01:29:12.256983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59691 (* 1 = 8.59691 loss)
I0523 01:29:12.958876 34819 sgd_solver.cpp:112] Iteration 25990, lr = 0.01
I0523 01:29:19.025935 34819 solver.cpp:239] Iteration 26000 (1.47739 iter/s, 6.7687s/10 iters), loss = 9.37982
I0523 01:29:19.025988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37982 (* 1 = 9.37982 loss)
I0523 01:29:19.099133 34819 sgd_solver.cpp:112] Iteration 26000, lr = 0.01
I0523 01:29:23.851982 34819 solver.cpp:239] Iteration 26010 (2.0722 iter/s, 4.82578s/10 iters), loss = 8.59439
I0523 01:29:23.852036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59439 (* 1 = 8.59439 loss)
I0523 01:29:24.654441 34819 sgd_solver.cpp:112] Iteration 26010, lr = 0.01
I0523 01:29:29.497704 34819 solver.cpp:239] Iteration 26020 (1.77135 iter/s, 5.64542s/10 iters), loss = 8.13025
I0523 01:29:29.497759 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13025 (* 1 = 8.13025 loss)
I0523 01:29:29.557271 34819 sgd_solver.cpp:112] Iteration 26020, lr = 0.01
I0523 01:29:35.089538 34819 solver.cpp:239] Iteration 26030 (1.78841 iter/s, 5.59155s/10 iters), loss = 8.8159
I0523 01:29:35.089589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8159 (* 1 = 8.8159 loss)
I0523 01:29:35.726439 34819 sgd_solver.cpp:112] Iteration 26030, lr = 0.01
I0523 01:29:41.486515 34819 solver.cpp:239] Iteration 26040 (1.56332 iter/s, 6.39665s/10 iters), loss = 8.41147
I0523 01:29:41.486568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41147 (* 1 = 8.41147 loss)
I0523 01:29:42.301980 34819 sgd_solver.cpp:112] Iteration 26040, lr = 0.01
I0523 01:29:45.600538 34819 solver.cpp:239] Iteration 26050 (2.43085 iter/s, 4.11379s/10 iters), loss = 9.05963
I0523 01:29:45.600584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05963 (* 1 = 9.05963 loss)
I0523 01:29:45.660157 34819 sgd_solver.cpp:112] Iteration 26050, lr = 0.01
I0523 01:29:50.392256 34819 solver.cpp:239] Iteration 26060 (2.08704 iter/s, 4.79147s/10 iters), loss = 9.01028
I0523 01:29:50.392312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01028 (* 1 = 9.01028 loss)
I0523 01:29:50.455143 34819 sgd_solver.cpp:112] Iteration 26060, lr = 0.01
I0523 01:29:55.055810 34819 solver.cpp:239] Iteration 26070 (2.1444 iter/s, 4.6633s/10 iters), loss = 9.12991
I0523 01:29:55.055855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12991 (* 1 = 9.12991 loss)
I0523 01:29:55.134071 34819 sgd_solver.cpp:112] Iteration 26070, lr = 0.01
I0523 01:30:00.031961 34819 solver.cpp:239] Iteration 26080 (2.0097 iter/s, 4.97588s/10 iters), loss = 9.54414
I0523 01:30:00.032019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54414 (* 1 = 9.54414 loss)
I0523 01:30:00.902042 34819 sgd_solver.cpp:112] Iteration 26080, lr = 0.01
I0523 01:30:05.502914 34819 solver.cpp:239] Iteration 26090 (1.82793 iter/s, 5.47067s/10 iters), loss = 8.87506
I0523 01:30:05.502959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87506 (* 1 = 8.87506 loss)
I0523 01:30:05.569234 34819 sgd_solver.cpp:112] Iteration 26090, lr = 0.01
I0523 01:30:10.398764 34819 solver.cpp:239] Iteration 26100 (2.04265 iter/s, 4.89559s/10 iters), loss = 9.08859
I0523 01:30:10.398824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08859 (* 1 = 9.08859 loss)
I0523 01:30:10.467269 34819 sgd_solver.cpp:112] Iteration 26100, lr = 0.01
I0523 01:30:15.254427 34819 solver.cpp:239] Iteration 26110 (2.06142 iter/s, 4.85104s/10 iters), loss = 8.89931
I0523 01:30:15.254642 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89931 (* 1 = 8.89931 loss)
I0523 01:30:16.030266 34819 sgd_solver.cpp:112] Iteration 26110, lr = 0.01
I0523 01:30:20.247939 34819 solver.cpp:239] Iteration 26120 (2.00276 iter/s, 4.99312s/10 iters), loss = 8.28543
I0523 01:30:20.247984 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28543 (* 1 = 8.28543 loss)
I0523 01:30:20.319948 34819 sgd_solver.cpp:112] Iteration 26120, lr = 0.01
I0523 01:30:25.249670 34819 solver.cpp:239] Iteration 26130 (1.99941 iter/s, 5.00148s/10 iters), loss = 8.03948
I0523 01:30:25.249718 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03948 (* 1 = 8.03948 loss)
I0523 01:30:26.045754 34819 sgd_solver.cpp:112] Iteration 26130, lr = 0.01
I0523 01:30:29.287070 34819 solver.cpp:239] Iteration 26140 (2.47699 iter/s, 4.03716s/10 iters), loss = 9.5234
I0523 01:30:29.287113 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.5234 (* 1 = 9.5234 loss)
I0523 01:30:29.357946 34819 sgd_solver.cpp:112] Iteration 26140, lr = 0.01
I0523 01:30:34.179196 34819 solver.cpp:239] Iteration 26150 (2.04421 iter/s, 4.89187s/10 iters), loss = 8.60885
I0523 01:30:34.179250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60885 (* 1 = 8.60885 loss)
I0523 01:30:34.249656 34819 sgd_solver.cpp:112] Iteration 26150, lr = 0.01
I0523 01:30:39.003446 34819 solver.cpp:239] Iteration 26160 (2.07297 iter/s, 4.824s/10 iters), loss = 8.71847
I0523 01:30:39.003491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71847 (* 1 = 8.71847 loss)
I0523 01:30:39.840672 34819 sgd_solver.cpp:112] Iteration 26160, lr = 0.01
I0523 01:30:41.747452 34819 solver.cpp:239] Iteration 26170 (3.64454 iter/s, 2.74383s/10 iters), loss = 9.56
I0523 01:30:41.747514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56 (* 1 = 9.56 loss)
I0523 01:30:42.551460 34819 sgd_solver.cpp:112] Iteration 26170, lr = 0.01
I0523 01:30:45.953531 34819 solver.cpp:239] Iteration 26180 (2.37764 iter/s, 4.20585s/10 iters), loss = 9.26785
I0523 01:30:45.953680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26785 (* 1 = 9.26785 loss)
I0523 01:30:46.688501 34819 sgd_solver.cpp:112] Iteration 26180, lr = 0.01
I0523 01:30:53.161763 34819 solver.cpp:239] Iteration 26190 (1.38739 iter/s, 7.20778s/10 iters), loss = 8.43452
I0523 01:30:53.161821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43452 (* 1 = 8.43452 loss)
I0523 01:30:53.234539 34819 sgd_solver.cpp:112] Iteration 26190, lr = 0.01
I0523 01:30:59.242677 34819 solver.cpp:239] Iteration 26200 (1.64457 iter/s, 6.08061s/10 iters), loss = 8.70161
I0523 01:30:59.242735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70161 (* 1 = 8.70161 loss)
I0523 01:30:59.306295 34819 sgd_solver.cpp:112] Iteration 26200, lr = 0.01
I0523 01:31:04.135697 34819 solver.cpp:239] Iteration 26210 (2.04384 iter/s, 4.89275s/10 iters), loss = 8.73301
I0523 01:31:04.135738 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73301 (* 1 = 8.73301 loss)
I0523 01:31:04.770588 34819 sgd_solver.cpp:112] Iteration 26210, lr = 0.01
I0523 01:31:09.290321 34819 solver.cpp:239] Iteration 26220 (1.94011 iter/s, 5.15436s/10 iters), loss = 8.98575
I0523 01:31:09.290390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98575 (* 1 = 8.98575 loss)
I0523 01:31:10.068254 34819 sgd_solver.cpp:112] Iteration 26220, lr = 0.01
I0523 01:31:14.799924 34819 solver.cpp:239] Iteration 26230 (1.81511 iter/s, 5.5093s/10 iters), loss = 8.89
I0523 01:31:14.799966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89 (* 1 = 8.89 loss)
I0523 01:31:14.860960 34819 sgd_solver.cpp:112] Iteration 26230, lr = 0.01
I0523 01:31:20.185323 34819 solver.cpp:239] Iteration 26240 (1.85697 iter/s, 5.38513s/10 iters), loss = 8.5736
I0523 01:31:20.185554 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5736 (* 1 = 8.5736 loss)
I0523 01:31:20.248001 34819 sgd_solver.cpp:112] Iteration 26240, lr = 0.01
I0523 01:31:26.575889 34819 solver.cpp:239] Iteration 26250 (1.56492 iter/s, 6.3901s/10 iters), loss = 8.92582
I0523 01:31:26.575934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92582 (* 1 = 8.92582 loss)
I0523 01:31:27.396983 34819 sgd_solver.cpp:112] Iteration 26250, lr = 0.01
I0523 01:31:30.414939 34819 solver.cpp:239] Iteration 26260 (2.60496 iter/s, 3.83884s/10 iters), loss = 9.4235
I0523 01:31:30.414993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4235 (* 1 = 9.4235 loss)
I0523 01:31:30.485991 34819 sgd_solver.cpp:112] Iteration 26260, lr = 0.01
I0523 01:31:35.383548 34819 solver.cpp:239] Iteration 26270 (2.01274 iter/s, 4.96835s/10 iters), loss = 8.78672
I0523 01:31:35.383599 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78672 (* 1 = 8.78672 loss)
I0523 01:31:35.463773 34819 sgd_solver.cpp:112] Iteration 26270, lr = 0.01
I0523 01:31:40.063552 34819 solver.cpp:239] Iteration 26280 (2.13687 iter/s, 4.67974s/10 iters), loss = 8.61594
I0523 01:31:40.063604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61594 (* 1 = 8.61594 loss)
I0523 01:31:40.875326 34819 sgd_solver.cpp:112] Iteration 26280, lr = 0.01
I0523 01:31:44.894089 34819 solver.cpp:239] Iteration 26290 (2.07027 iter/s, 4.83028s/10 iters), loss = 8.58965
I0523 01:31:44.894140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58965 (* 1 = 8.58965 loss)
I0523 01:31:45.715308 34819 sgd_solver.cpp:112] Iteration 26290, lr = 0.01
I0523 01:31:49.579151 34819 solver.cpp:239] Iteration 26300 (2.13456 iter/s, 4.6848s/10 iters), loss = 7.85977
I0523 01:31:49.579208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85977 (* 1 = 7.85977 loss)
I0523 01:31:49.643173 34819 sgd_solver.cpp:112] Iteration 26300, lr = 0.01
I0523 01:31:54.252265 34819 solver.cpp:239] Iteration 26310 (2.14002 iter/s, 4.67285s/10 iters), loss = 8.35659
I0523 01:31:54.252454 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35659 (* 1 = 8.35659 loss)
I0523 01:31:54.966315 34819 sgd_solver.cpp:112] Iteration 26310, lr = 0.01
I0523 01:32:01.702499 34819 solver.cpp:239] Iteration 26320 (1.34232 iter/s, 7.44976s/10 iters), loss = 8.57371
I0523 01:32:01.702548 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57371 (* 1 = 8.57371 loss)
I0523 01:32:01.773195 34819 sgd_solver.cpp:112] Iteration 26320, lr = 0.01
I0523 01:32:05.929564 34819 solver.cpp:239] Iteration 26330 (2.36584 iter/s, 4.22683s/10 iters), loss = 8.09804
I0523 01:32:05.929620 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09804 (* 1 = 8.09804 loss)
I0523 01:32:05.989508 34819 sgd_solver.cpp:112] Iteration 26330, lr = 0.01
I0523 01:32:12.163004 34819 solver.cpp:239] Iteration 26340 (1.60433 iter/s, 6.23312s/10 iters), loss = 8.55486
I0523 01:32:12.163053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55486 (* 1 = 8.55486 loss)
I0523 01:32:12.789731 34819 sgd_solver.cpp:112] Iteration 26340, lr = 0.01
I0523 01:32:16.842245 34819 solver.cpp:239] Iteration 26350 (2.13722 iter/s, 4.67898s/10 iters), loss = 8.44197
I0523 01:32:16.842308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44197 (* 1 = 8.44197 loss)
I0523 01:32:17.669073 34819 sgd_solver.cpp:112] Iteration 26350, lr = 0.01
I0523 01:32:22.312556 34819 solver.cpp:239] Iteration 26360 (1.82814 iter/s, 5.47003s/10 iters), loss = 9.01921
I0523 01:32:22.312603 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01921 (* 1 = 9.01921 loss)
I0523 01:32:22.901902 34819 sgd_solver.cpp:112] Iteration 26360, lr = 0.01
I0523 01:32:29.675932 34819 solver.cpp:239] Iteration 26370 (1.35814 iter/s, 7.36303s/10 iters), loss = 9.36279
I0523 01:32:29.676190 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36279 (* 1 = 9.36279 loss)
I0523 01:32:29.753834 34819 sgd_solver.cpp:112] Iteration 26370, lr = 0.01
I0523 01:32:34.078270 34819 solver.cpp:239] Iteration 26380 (2.27174 iter/s, 4.40191s/10 iters), loss = 8.77256
I0523 01:32:34.078322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77256 (* 1 = 8.77256 loss)
I0523 01:32:34.155747 34819 sgd_solver.cpp:112] Iteration 26380, lr = 0.01
I0523 01:32:38.104717 34819 solver.cpp:239] Iteration 26390 (2.48372 iter/s, 4.02622s/10 iters), loss = 8.96656
I0523 01:32:38.104761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96656 (* 1 = 8.96656 loss)
I0523 01:32:38.162611 34819 sgd_solver.cpp:112] Iteration 26390, lr = 0.01
I0523 01:32:42.992979 34819 solver.cpp:239] Iteration 26400 (2.04582 iter/s, 4.88801s/10 iters), loss = 8.85674
I0523 01:32:42.993021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85674 (* 1 = 8.85674 loss)
I0523 01:32:43.066113 34819 sgd_solver.cpp:112] Iteration 26400, lr = 0.01
I0523 01:32:46.210768 34819 solver.cpp:239] Iteration 26410 (3.10791 iter/s, 3.2176s/10 iters), loss = 9.19847
I0523 01:32:46.210820 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19847 (* 1 = 9.19847 loss)
I0523 01:32:46.993314 34819 sgd_solver.cpp:112] Iteration 26410, lr = 0.01
I0523 01:32:52.522150 34819 solver.cpp:239] Iteration 26420 (1.58452 iter/s, 6.31106s/10 iters), loss = 8.12475
I0523 01:32:52.522205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12475 (* 1 = 8.12475 loss)
I0523 01:32:52.587150 34819 sgd_solver.cpp:112] Iteration 26420, lr = 0.01
I0523 01:32:56.008280 34819 solver.cpp:239] Iteration 26430 (2.86868 iter/s, 3.48592s/10 iters), loss = 9.23645
I0523 01:32:56.008329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23645 (* 1 = 9.23645 loss)
I0523 01:32:56.826591 34819 sgd_solver.cpp:112] Iteration 26430, lr = 0.01
I0523 01:32:59.538408 34819 solver.cpp:239] Iteration 26440 (2.83292 iter/s, 3.52993s/10 iters), loss = 10.092
I0523 01:32:59.538455 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.092 (* 1 = 10.092 loss)
I0523 01:32:59.594543 34819 sgd_solver.cpp:112] Iteration 26440, lr = 0.01
I0523 01:33:04.707330 34819 solver.cpp:239] Iteration 26450 (1.93474 iter/s, 5.16866s/10 iters), loss = 9.00073
I0523 01:33:04.707532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00073 (* 1 = 9.00073 loss)
I0523 01:33:04.780748 34819 sgd_solver.cpp:112] Iteration 26450, lr = 0.01
I0523 01:33:09.682808 34819 solver.cpp:239] Iteration 26460 (2.01002 iter/s, 4.97508s/10 iters), loss = 8.6995
I0523 01:33:09.682862 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6995 (* 1 = 8.6995 loss)
I0523 01:33:09.753345 34819 sgd_solver.cpp:112] Iteration 26460, lr = 0.01
I0523 01:33:12.305619 34819 solver.cpp:239] Iteration 26470 (3.81295 iter/s, 2.62264s/10 iters), loss = 8.56969
I0523 01:33:12.305663 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56969 (* 1 = 8.56969 loss)
I0523 01:33:12.368768 34819 sgd_solver.cpp:112] Iteration 26470, lr = 0.01
I0523 01:33:16.311048 34819 solver.cpp:239] Iteration 26480 (2.49675 iter/s, 4.00521s/10 iters), loss = 9.71647
I0523 01:33:16.311091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71647 (* 1 = 9.71647 loss)
I0523 01:33:16.386322 34819 sgd_solver.cpp:112] Iteration 26480, lr = 0.01
I0523 01:33:21.122400 34819 solver.cpp:239] Iteration 26490 (2.07853 iter/s, 4.8111s/10 iters), loss = 8.66368
I0523 01:33:21.122447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66368 (* 1 = 8.66368 loss)
I0523 01:33:21.950779 34819 sgd_solver.cpp:112] Iteration 26490, lr = 0.01
I0523 01:33:26.325729 34819 solver.cpp:239] Iteration 26500 (1.92195 iter/s, 5.20306s/10 iters), loss = 9.08607
I0523 01:33:26.325773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08607 (* 1 = 9.08607 loss)
I0523 01:33:26.386162 34819 sgd_solver.cpp:112] Iteration 26500, lr = 0.01
I0523 01:33:32.514163 34819 solver.cpp:239] Iteration 26510 (1.616 iter/s, 6.18814s/10 iters), loss = 8.39201
I0523 01:33:32.514222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39201 (* 1 = 8.39201 loss)
I0523 01:33:33.229141 34819 sgd_solver.cpp:112] Iteration 26510, lr = 0.01
I0523 01:33:38.625082 34819 solver.cpp:239] Iteration 26520 (1.6365 iter/s, 6.11061s/10 iters), loss = 8.62344
I0523 01:33:38.625233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62344 (* 1 = 8.62344 loss)
I0523 01:33:38.677754 34819 sgd_solver.cpp:112] Iteration 26520, lr = 0.01
I0523 01:33:42.691310 34819 solver.cpp:239] Iteration 26530 (2.45948 iter/s, 4.0659s/10 iters), loss = 8.71278
I0523 01:33:42.691364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71278 (* 1 = 8.71278 loss)
I0523 01:33:42.748720 34819 sgd_solver.cpp:112] Iteration 26530, lr = 0.01
I0523 01:33:45.885756 34819 solver.cpp:239] Iteration 26540 (3.13063 iter/s, 3.19425s/10 iters), loss = 8.39229
I0523 01:33:45.885797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39229 (* 1 = 8.39229 loss)
I0523 01:33:46.255921 34819 sgd_solver.cpp:112] Iteration 26540, lr = 0.01
I0523 01:33:50.955922 34819 solver.cpp:239] Iteration 26550 (1.97242 iter/s, 5.06991s/10 iters), loss = 9.3919
I0523 01:33:50.955981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3919 (* 1 = 9.3919 loss)
I0523 01:33:51.712997 34819 sgd_solver.cpp:112] Iteration 26550, lr = 0.01
I0523 01:33:54.590641 34819 solver.cpp:239] Iteration 26560 (2.75141 iter/s, 3.63451s/10 iters), loss = 7.87025
I0523 01:33:54.590713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87025 (* 1 = 7.87025 loss)
I0523 01:33:54.652076 34819 sgd_solver.cpp:112] Iteration 26560, lr = 0.01
I0523 01:33:59.268798 34819 solver.cpp:239] Iteration 26570 (2.13771 iter/s, 4.67791s/10 iters), loss = 9.20771
I0523 01:33:59.268852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20771 (* 1 = 9.20771 loss)
I0523 01:33:59.342075 34819 sgd_solver.cpp:112] Iteration 26570, lr = 0.01
I0523 01:34:05.124274 34819 solver.cpp:239] Iteration 26580 (1.7079 iter/s, 5.85515s/10 iters), loss = 9.36329
I0523 01:34:05.124336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36329 (* 1 = 9.36329 loss)
I0523 01:34:05.984083 34819 sgd_solver.cpp:112] Iteration 26580, lr = 0.01
I0523 01:34:09.319344 34819 solver.cpp:239] Iteration 26590 (2.38389 iter/s, 4.19482s/10 iters), loss = 8.9901
I0523 01:34:09.319514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9901 (* 1 = 8.9901 loss)
I0523 01:34:09.392320 34819 sgd_solver.cpp:112] Iteration 26590, lr = 0.01
I0523 01:34:13.059239 34819 solver.cpp:239] Iteration 26600 (2.6741 iter/s, 3.73957s/10 iters), loss = 9.01618
I0523 01:34:13.059288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01618 (* 1 = 9.01618 loss)
I0523 01:34:13.122272 34819 sgd_solver.cpp:112] Iteration 26600, lr = 0.01
I0523 01:34:17.549494 34819 solver.cpp:239] Iteration 26610 (2.22717 iter/s, 4.49001s/10 iters), loss = 8.36512
I0523 01:34:17.549542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36512 (* 1 = 8.36512 loss)
I0523 01:34:17.621923 34819 sgd_solver.cpp:112] Iteration 26610, lr = 0.01
I0523 01:34:23.381027 34819 solver.cpp:239] Iteration 26620 (1.7149 iter/s, 5.83124s/10 iters), loss = 8.74146
I0523 01:34:23.381083 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74146 (* 1 = 8.74146 loss)
I0523 01:34:24.206257 34819 sgd_solver.cpp:112] Iteration 26620, lr = 0.01
I0523 01:34:28.205083 34819 solver.cpp:239] Iteration 26630 (2.07306 iter/s, 4.8238s/10 iters), loss = 9.10631
I0523 01:34:28.205147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10631 (* 1 = 9.10631 loss)
I0523 01:34:28.266189 34819 sgd_solver.cpp:112] Iteration 26630, lr = 0.01
I0523 01:34:30.770710 34819 solver.cpp:239] Iteration 26640 (3.89797 iter/s, 2.56544s/10 iters), loss = 8.42904
I0523 01:34:30.770768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42904 (* 1 = 8.42904 loss)
I0523 01:34:31.604449 34819 sgd_solver.cpp:112] Iteration 26640, lr = 0.01
I0523 01:34:36.733458 34819 solver.cpp:239] Iteration 26650 (1.67717 iter/s, 5.96242s/10 iters), loss = 8.89016
I0523 01:34:36.733525 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89016 (* 1 = 8.89016 loss)
I0523 01:34:36.800773 34819 sgd_solver.cpp:112] Iteration 26650, lr = 0.01
I0523 01:34:40.103935 34819 solver.cpp:239] Iteration 26660 (2.96712 iter/s, 3.37027s/10 iters), loss = 8.64467
I0523 01:34:40.104110 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64467 (* 1 = 8.64467 loss)
I0523 01:34:40.164535 34819 sgd_solver.cpp:112] Iteration 26660, lr = 0.01
I0523 01:34:46.057469 34819 solver.cpp:239] Iteration 26670 (1.67979 iter/s, 5.95311s/10 iters), loss = 9.61991
I0523 01:34:46.057512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61991 (* 1 = 9.61991 loss)
I0523 01:34:46.129444 34819 sgd_solver.cpp:112] Iteration 26670, lr = 0.01
I0523 01:34:51.068192 34819 solver.cpp:239] Iteration 26680 (1.99582 iter/s, 5.01047s/10 iters), loss = 9.11144
I0523 01:34:51.068234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11144 (* 1 = 9.11144 loss)
I0523 01:34:51.734660 34819 sgd_solver.cpp:112] Iteration 26680, lr = 0.01
I0523 01:34:57.296154 34819 solver.cpp:239] Iteration 26690 (1.60574 iter/s, 6.22766s/10 iters), loss = 8.85867
I0523 01:34:57.296200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85867 (* 1 = 8.85867 loss)
I0523 01:34:58.076236 34819 sgd_solver.cpp:112] Iteration 26690, lr = 0.01
I0523 01:35:05.897652 34819 solver.cpp:239] Iteration 26700 (1.16264 iter/s, 8.60109s/10 iters), loss = 8.54243
I0523 01:35:05.897702 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54243 (* 1 = 8.54243 loss)
I0523 01:35:06.667951 34819 sgd_solver.cpp:112] Iteration 26700, lr = 0.01
I0523 01:35:11.888713 34819 solver.cpp:239] Iteration 26710 (1.66924 iter/s, 5.99076s/10 iters), loss = 8.81178
I0523 01:35:11.888885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81178 (* 1 = 8.81178 loss)
I0523 01:35:11.961125 34819 sgd_solver.cpp:112] Iteration 26710, lr = 0.01
I0523 01:35:16.866874 34819 solver.cpp:239] Iteration 26720 (2.00892 iter/s, 4.97779s/10 iters), loss = 8.55362
I0523 01:35:16.866933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55362 (* 1 = 8.55362 loss)
I0523 01:35:16.927323 34819 sgd_solver.cpp:112] Iteration 26720, lr = 0.01
I0523 01:35:20.138064 34819 solver.cpp:239] Iteration 26730 (3.05718 iter/s, 3.27099s/10 iters), loss = 9.65254
I0523 01:35:20.138116 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65254 (* 1 = 9.65254 loss)
I0523 01:35:20.209393 34819 sgd_solver.cpp:112] Iteration 26730, lr = 0.01
I0523 01:35:24.054360 34819 solver.cpp:239] Iteration 26740 (2.55359 iter/s, 3.91606s/10 iters), loss = 8.9136
I0523 01:35:24.054419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9136 (* 1 = 8.9136 loss)
I0523 01:35:24.124364 34819 sgd_solver.cpp:112] Iteration 26740, lr = 0.01
I0523 01:35:29.521431 34819 solver.cpp:239] Iteration 26750 (1.82923 iter/s, 5.46678s/10 iters), loss = 9.68065
I0523 01:35:29.521488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68065 (* 1 = 9.68065 loss)
I0523 01:35:29.589251 34819 sgd_solver.cpp:112] Iteration 26750, lr = 0.01
I0523 01:35:35.850173 34819 solver.cpp:239] Iteration 26760 (1.58018 iter/s, 6.3284s/10 iters), loss = 8.53476
I0523 01:35:35.850236 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53476 (* 1 = 8.53476 loss)
I0523 01:35:36.742116 34819 sgd_solver.cpp:112] Iteration 26760, lr = 0.01
I0523 01:35:42.143766 34819 solver.cpp:239] Iteration 26770 (1.589 iter/s, 6.29326s/10 iters), loss = 8.14555
I0523 01:35:42.144048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14555 (* 1 = 8.14555 loss)
I0523 01:35:42.820485 34819 sgd_solver.cpp:112] Iteration 26770, lr = 0.01
I0523 01:35:47.460526 34819 solver.cpp:239] Iteration 26780 (1.88101 iter/s, 5.31629s/10 iters), loss = 9.21389
I0523 01:35:47.460572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21389 (* 1 = 9.21389 loss)
I0523 01:35:48.119710 34819 sgd_solver.cpp:112] Iteration 26780, lr = 0.01
I0523 01:35:51.460292 34819 solver.cpp:239] Iteration 26790 (2.50028 iter/s, 3.99955s/10 iters), loss = 8.47958
I0523 01:35:51.460348 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47958 (* 1 = 8.47958 loss)
I0523 01:35:52.323400 34819 sgd_solver.cpp:112] Iteration 26790, lr = 0.01
I0523 01:35:56.004037 34819 solver.cpp:239] Iteration 26800 (2.20095 iter/s, 4.5435s/10 iters), loss = 8.15033
I0523 01:35:56.004091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15033 (* 1 = 8.15033 loss)
I0523 01:35:56.866933 34819 sgd_solver.cpp:112] Iteration 26800, lr = 0.01
I0523 01:36:01.935196 34819 solver.cpp:239] Iteration 26810 (1.6861 iter/s, 5.93086s/10 iters), loss = 9.07563
I0523 01:36:01.935258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07563 (* 1 = 9.07563 loss)
I0523 01:36:02.006743 34819 sgd_solver.cpp:112] Iteration 26810, lr = 0.01
I0523 01:36:06.907742 34819 solver.cpp:239] Iteration 26820 (2.01115 iter/s, 4.97228s/10 iters), loss = 8.23553
I0523 01:36:06.907795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23553 (* 1 = 8.23553 loss)
I0523 01:36:06.979089 34819 sgd_solver.cpp:112] Iteration 26820, lr = 0.01
I0523 01:36:13.483708 34819 solver.cpp:239] Iteration 26830 (1.52077 iter/s, 6.57564s/10 iters), loss = 8.91136
I0523 01:36:13.483942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91136 (* 1 = 8.91136 loss)
I0523 01:36:14.253857 34819 sgd_solver.cpp:112] Iteration 26830, lr = 0.01
I0523 01:36:18.328450 34819 solver.cpp:239] Iteration 26840 (2.06427 iter/s, 4.84433s/10 iters), loss = 8.5553
I0523 01:36:18.328491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5553 (* 1 = 8.5553 loss)
I0523 01:36:18.598116 34819 sgd_solver.cpp:112] Iteration 26840, lr = 0.01
I0523 01:36:23.400580 34819 solver.cpp:239] Iteration 26850 (1.97166 iter/s, 5.07187s/10 iters), loss = 8.53363
I0523 01:36:23.400624 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53363 (* 1 = 8.53363 loss)
I0523 01:36:23.459894 34819 sgd_solver.cpp:112] Iteration 26850, lr = 0.01
I0523 01:36:27.220125 34819 solver.cpp:239] Iteration 26860 (2.61826 iter/s, 3.81933s/10 iters), loss = 8.72055
I0523 01:36:27.220162 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72055 (* 1 = 8.72055 loss)
I0523 01:36:27.622383 34819 sgd_solver.cpp:112] Iteration 26860, lr = 0.01
I0523 01:36:29.589767 34819 solver.cpp:239] Iteration 26870 (4.22032 iter/s, 2.36949s/10 iters), loss = 8.74147
I0523 01:36:29.589807 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74147 (* 1 = 8.74147 loss)
I0523 01:36:29.652087 34819 sgd_solver.cpp:112] Iteration 26870, lr = 0.01
I0523 01:36:35.429416 34819 solver.cpp:239] Iteration 26880 (1.71252 iter/s, 5.83935s/10 iters), loss = 8.11394
I0523 01:36:35.429476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11394 (* 1 = 8.11394 loss)
I0523 01:36:36.259369 34819 sgd_solver.cpp:112] Iteration 26880, lr = 0.01
I0523 01:36:39.289396 34819 solver.cpp:239] Iteration 26890 (2.59084 iter/s, 3.85975s/10 iters), loss = 9.0382
I0523 01:36:39.289451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0382 (* 1 = 9.0382 loss)
I0523 01:36:40.087316 34819 sgd_solver.cpp:112] Iteration 26890, lr = 0.01
I0523 01:36:44.229109 34819 solver.cpp:239] Iteration 26900 (2.02452 iter/s, 4.93945s/10 iters), loss = 7.81954
I0523 01:36:44.229342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81954 (* 1 = 7.81954 loss)
I0523 01:36:44.286484 34819 sgd_solver.cpp:112] Iteration 26900, lr = 0.01
I0523 01:36:49.290423 34819 solver.cpp:239] Iteration 26910 (1.97594 iter/s, 5.06088s/10 iters), loss = 8.30539
I0523 01:36:49.290482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30539 (* 1 = 8.30539 loss)
I0523 01:36:50.128374 34819 sgd_solver.cpp:112] Iteration 26910, lr = 0.01
I0523 01:36:54.862859 34819 solver.cpp:239] Iteration 26920 (1.79464 iter/s, 5.57214s/10 iters), loss = 8.25352
I0523 01:36:54.862905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25352 (* 1 = 8.25352 loss)
I0523 01:36:54.914746 34819 sgd_solver.cpp:112] Iteration 26920, lr = 0.01
I0523 01:36:58.688092 34819 solver.cpp:239] Iteration 26930 (2.61437 iter/s, 3.82502s/10 iters), loss = 8.1706
I0523 01:36:58.688148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1706 (* 1 = 8.1706 loss)
I0523 01:36:58.747648 34819 sgd_solver.cpp:112] Iteration 26930, lr = 0.01
I0523 01:37:03.734031 34819 solver.cpp:239] Iteration 26940 (1.9819 iter/s, 5.04566s/10 iters), loss = 9.64206
I0523 01:37:03.734081 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64206 (* 1 = 9.64206 loss)
I0523 01:37:03.803337 34819 sgd_solver.cpp:112] Iteration 26940, lr = 0.01
I0523 01:37:07.783417 34819 solver.cpp:239] Iteration 26950 (2.46964 iter/s, 4.04917s/10 iters), loss = 8.78616
I0523 01:37:07.783462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78616 (* 1 = 8.78616 loss)
I0523 01:37:08.322733 34819 sgd_solver.cpp:112] Iteration 26950, lr = 0.01
I0523 01:37:11.596987 34819 solver.cpp:239] Iteration 26960 (2.62236 iter/s, 3.81336s/10 iters), loss = 9.72833
I0523 01:37:11.597036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72833 (* 1 = 9.72833 loss)
I0523 01:37:12.471134 34819 sgd_solver.cpp:112] Iteration 26960, lr = 0.01
I0523 01:37:15.909277 34819 solver.cpp:239] Iteration 26970 (2.31909 iter/s, 4.31204s/10 iters), loss = 8.60969
I0523 01:37:15.909447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60969 (* 1 = 8.60969 loss)
I0523 01:37:16.767483 34819 sgd_solver.cpp:112] Iteration 26970, lr = 0.01
I0523 01:37:21.543545 34819 solver.cpp:239] Iteration 26980 (1.77498 iter/s, 5.63387s/10 iters), loss = 8.06655
I0523 01:37:21.543596 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06655 (* 1 = 8.06655 loss)
I0523 01:37:22.335887 34819 sgd_solver.cpp:112] Iteration 26980, lr = 0.01
I0523 01:37:26.346604 34819 solver.cpp:239] Iteration 26990 (2.08211 iter/s, 4.80281s/10 iters), loss = 8.8643
I0523 01:37:26.346657 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8643 (* 1 = 8.8643 loss)
I0523 01:37:26.420104 34819 sgd_solver.cpp:112] Iteration 26990, lr = 0.01
I0523 01:37:29.821648 34819 solver.cpp:239] Iteration 27000 (2.87783 iter/s, 3.47484s/10 iters), loss = 8.19834
I0523 01:37:29.821691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19834 (* 1 = 8.19834 loss)
I0523 01:37:29.878330 34819 sgd_solver.cpp:112] Iteration 27000, lr = 0.01
I0523 01:37:33.285748 34819 solver.cpp:239] Iteration 27010 (2.88691 iter/s, 3.46391s/10 iters), loss = 9.03449
I0523 01:37:33.285792 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03449 (* 1 = 9.03449 loss)
I0523 01:37:33.353232 34819 sgd_solver.cpp:112] Iteration 27010, lr = 0.01
I0523 01:37:38.362680 34819 solver.cpp:239] Iteration 27020 (1.9698 iter/s, 5.07667s/10 iters), loss = 7.87428
I0523 01:37:38.362746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87428 (* 1 = 7.87428 loss)
I0523 01:37:39.164140 34819 sgd_solver.cpp:112] Iteration 27020, lr = 0.01
I0523 01:37:44.002884 34819 solver.cpp:239] Iteration 27030 (1.77308 iter/s, 5.63989s/10 iters), loss = 9.23006
I0523 01:37:44.002940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23006 (* 1 = 9.23006 loss)
I0523 01:37:44.804497 34819 sgd_solver.cpp:112] Iteration 27030, lr = 0.01
I0523 01:37:48.929641 34819 solver.cpp:239] Iteration 27040 (2.02984 iter/s, 4.9265s/10 iters), loss = 8.1904
I0523 01:37:48.929780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1904 (* 1 = 8.1904 loss)
I0523 01:37:48.986536 34819 sgd_solver.cpp:112] Iteration 27040, lr = 0.01
I0523 01:37:53.189148 34819 solver.cpp:239] Iteration 27050 (2.34787 iter/s, 4.25917s/10 iters), loss = 8.60359
I0523 01:37:53.189205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60359 (* 1 = 8.60359 loss)
I0523 01:37:53.257093 34819 sgd_solver.cpp:112] Iteration 27050, lr = 0.01
I0523 01:37:57.792166 34819 solver.cpp:239] Iteration 27060 (2.17261 iter/s, 4.60277s/10 iters), loss = 8.48824
I0523 01:37:57.792217 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48824 (* 1 = 8.48824 loss)
I0523 01:37:58.025610 34819 sgd_solver.cpp:112] Iteration 27060, lr = 0.01
I0523 01:38:03.415217 34819 solver.cpp:239] Iteration 27070 (1.77848 iter/s, 5.62277s/10 iters), loss = 9.55401
I0523 01:38:03.415259 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55401 (* 1 = 9.55401 loss)
I0523 01:38:03.482699 34819 sgd_solver.cpp:112] Iteration 27070, lr = 0.01
I0523 01:38:06.551095 34819 solver.cpp:239] Iteration 27080 (3.18909 iter/s, 3.13569s/10 iters), loss = 8.92145
I0523 01:38:06.551138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92145 (* 1 = 8.92145 loss)
I0523 01:38:07.422035 34819 sgd_solver.cpp:112] Iteration 27080, lr = 0.01
I0523 01:38:11.569667 34819 solver.cpp:239] Iteration 27090 (1.9927 iter/s, 5.01832s/10 iters), loss = 8.65882
I0523 01:38:11.569715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65882 (* 1 = 8.65882 loss)
I0523 01:38:11.640316 34819 sgd_solver.cpp:112] Iteration 27090, lr = 0.01
I0523 01:38:16.993041 34819 solver.cpp:239] Iteration 27100 (1.84396 iter/s, 5.4231s/10 iters), loss = 8.66051
I0523 01:38:16.993084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66051 (* 1 = 8.66051 loss)
I0523 01:38:17.065407 34819 sgd_solver.cpp:112] Iteration 27100, lr = 0.01
I0523 01:38:21.162169 34819 solver.cpp:239] Iteration 27110 (2.39871 iter/s, 4.16891s/10 iters), loss = 8.98127
I0523 01:38:21.162374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98127 (* 1 = 8.98127 loss)
I0523 01:38:21.920343 34819 sgd_solver.cpp:112] Iteration 27110, lr = 0.01
I0523 01:38:26.817906 34819 solver.cpp:239] Iteration 27120 (1.76824 iter/s, 5.65533s/10 iters), loss = 8.9938
I0523 01:38:26.817951 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9938 (* 1 = 8.9938 loss)
I0523 01:38:26.872012 34819 sgd_solver.cpp:112] Iteration 27120, lr = 0.01
I0523 01:38:32.829573 34819 solver.cpp:239] Iteration 27130 (1.66351 iter/s, 6.01138s/10 iters), loss = 9.01486
I0523 01:38:32.829618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01486 (* 1 = 9.01486 loss)
I0523 01:38:33.673436 34819 sgd_solver.cpp:112] Iteration 27130, lr = 0.01
I0523 01:38:38.613134 34819 solver.cpp:239] Iteration 27140 (1.72912 iter/s, 5.78328s/10 iters), loss = 8.55769
I0523 01:38:38.613181 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55769 (* 1 = 8.55769 loss)
I0523 01:38:38.687304 34819 sgd_solver.cpp:112] Iteration 27140, lr = 0.01
I0523 01:38:43.404642 34819 solver.cpp:239] Iteration 27150 (2.08714 iter/s, 4.79125s/10 iters), loss = 7.60017
I0523 01:38:43.404708 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60017 (* 1 = 7.60017 loss)
I0523 01:38:44.273617 34819 sgd_solver.cpp:112] Iteration 27150, lr = 0.01
I0523 01:38:49.077375 34819 solver.cpp:239] Iteration 27160 (1.76291 iter/s, 5.67243s/10 iters), loss = 8.39981
I0523 01:38:49.077432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39981 (* 1 = 8.39981 loss)
I0523 01:38:49.840284 34819 sgd_solver.cpp:112] Iteration 27160, lr = 0.01
I0523 01:38:55.280717 34819 solver.cpp:239] Iteration 27170 (1.61212 iter/s, 6.20302s/10 iters), loss = 8.38078
I0523 01:38:55.280894 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38078 (* 1 = 8.38078 loss)
I0523 01:38:55.329371 34819 sgd_solver.cpp:112] Iteration 27170, lr = 0.01
I0523 01:38:59.590648 34819 solver.cpp:239] Iteration 27180 (2.32041 iter/s, 4.30958s/10 iters), loss = 8.86246
I0523 01:38:59.590713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86246 (* 1 = 8.86246 loss)
I0523 01:39:00.252663 34819 sgd_solver.cpp:112] Iteration 27180, lr = 0.01
I0523 01:39:04.932991 34819 solver.cpp:239] Iteration 27190 (1.87194 iter/s, 5.34206s/10 iters), loss = 8.03605
I0523 01:39:04.933048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03605 (* 1 = 8.03605 loss)
I0523 01:39:04.992425 34819 sgd_solver.cpp:112] Iteration 27190, lr = 0.01
I0523 01:39:10.516858 34819 solver.cpp:239] Iteration 27200 (1.79097 iter/s, 5.58357s/10 iters), loss = 8.22575
I0523 01:39:10.516909 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22575 (* 1 = 8.22575 loss)
I0523 01:39:10.660542 34819 sgd_solver.cpp:112] Iteration 27200, lr = 0.01
I0523 01:39:16.165086 34819 solver.cpp:239] Iteration 27210 (1.77056 iter/s, 5.64794s/10 iters), loss = 9.32229
I0523 01:39:16.165141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32229 (* 1 = 9.32229 loss)
I0523 01:39:16.233556 34819 sgd_solver.cpp:112] Iteration 27210, lr = 0.01
I0523 01:39:20.937324 34819 solver.cpp:239] Iteration 27220 (2.09556 iter/s, 4.77199s/10 iters), loss = 8.30956
I0523 01:39:20.937366 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30956 (* 1 = 8.30956 loss)
I0523 01:39:21.010793 34819 sgd_solver.cpp:112] Iteration 27220, lr = 0.01
I0523 01:39:26.510624 34819 solver.cpp:239] Iteration 27230 (1.79436 iter/s, 5.57303s/10 iters), loss = 9.50073
I0523 01:39:26.510852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50073 (* 1 = 9.50073 loss)
I0523 01:39:26.585856 34819 sgd_solver.cpp:112] Iteration 27230, lr = 0.01
I0523 01:39:31.235358 34819 solver.cpp:239] Iteration 27240 (2.1167 iter/s, 4.72433s/10 iters), loss = 8.74571
I0523 01:39:31.235406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74571 (* 1 = 8.74571 loss)
I0523 01:39:31.307540 34819 sgd_solver.cpp:112] Iteration 27240, lr = 0.01
I0523 01:39:35.607672 34819 solver.cpp:239] Iteration 27250 (2.28724 iter/s, 4.37208s/10 iters), loss = 8.70098
I0523 01:39:35.607739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70098 (* 1 = 8.70098 loss)
I0523 01:39:35.687443 34819 sgd_solver.cpp:112] Iteration 27250, lr = 0.01
I0523 01:39:40.744755 34819 solver.cpp:239] Iteration 27260 (1.94674 iter/s, 5.13679s/10 iters), loss = 9.32576
I0523 01:39:40.744804 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32576 (* 1 = 9.32576 loss)
I0523 01:39:40.799676 34819 sgd_solver.cpp:112] Iteration 27260, lr = 0.01
I0523 01:39:44.367573 34819 solver.cpp:239] Iteration 27270 (2.76045 iter/s, 3.6226s/10 iters), loss = 9.04984
I0523 01:39:44.367645 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04984 (* 1 = 9.04984 loss)
I0523 01:39:44.544703 34819 sgd_solver.cpp:112] Iteration 27270, lr = 0.01
I0523 01:39:48.638104 34819 solver.cpp:239] Iteration 27280 (2.34178 iter/s, 4.27026s/10 iters), loss = 9.72297
I0523 01:39:48.638175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72297 (* 1 = 9.72297 loss)
I0523 01:39:48.701028 34819 sgd_solver.cpp:112] Iteration 27280, lr = 0.01
I0523 01:39:53.758074 34819 solver.cpp:239] Iteration 27290 (1.95325 iter/s, 5.11968s/10 iters), loss = 8.61556
I0523 01:39:53.758131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61556 (* 1 = 8.61556 loss)
I0523 01:39:53.830703 34819 sgd_solver.cpp:112] Iteration 27290, lr = 0.01
I0523 01:39:59.239591 34819 solver.cpp:239] Iteration 27300 (1.82441 iter/s, 5.48123s/10 iters), loss = 9.842
I0523 01:39:59.240474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.842 (* 1 = 9.842 loss)
I0523 01:39:59.314882 34819 sgd_solver.cpp:112] Iteration 27300, lr = 0.01
I0523 01:40:04.491051 34819 solver.cpp:239] Iteration 27310 (1.90463 iter/s, 5.25036s/10 iters), loss = 9.28163
I0523 01:40:04.491114 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28163 (* 1 = 9.28163 loss)
I0523 01:40:04.560107 34819 sgd_solver.cpp:112] Iteration 27310, lr = 0.01
I0523 01:40:08.554558 34819 solver.cpp:239] Iteration 27320 (2.46369 iter/s, 4.05896s/10 iters), loss = 9.00152
I0523 01:40:08.554605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00152 (* 1 = 9.00152 loss)
I0523 01:40:08.639847 34819 sgd_solver.cpp:112] Iteration 27320, lr = 0.01
I0523 01:40:12.901633 34819 solver.cpp:239] Iteration 27330 (2.30052 iter/s, 4.34684s/10 iters), loss = 8.84671
I0523 01:40:12.901697 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84671 (* 1 = 8.84671 loss)
I0523 01:40:13.729943 34819 sgd_solver.cpp:112] Iteration 27330, lr = 0.01
I0523 01:40:17.900368 34819 solver.cpp:239] Iteration 27340 (2.00062 iter/s, 4.99845s/10 iters), loss = 8.52427
I0523 01:40:17.900431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52427 (* 1 = 8.52427 loss)
I0523 01:40:18.728644 34819 sgd_solver.cpp:112] Iteration 27340, lr = 0.01
I0523 01:40:25.017482 34819 solver.cpp:239] Iteration 27350 (1.40514 iter/s, 7.11674s/10 iters), loss = 7.64189
I0523 01:40:25.017547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64189 (* 1 = 7.64189 loss)
I0523 01:40:25.083976 34819 sgd_solver.cpp:112] Iteration 27350, lr = 0.01
I0523 01:40:29.931231 34819 solver.cpp:239] Iteration 27360 (2.03522 iter/s, 4.91347s/10 iters), loss = 10.096
I0523 01:40:29.931381 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.096 (* 1 = 10.096 loss)
I0523 01:40:29.992111 34819 sgd_solver.cpp:112] Iteration 27360, lr = 0.01
I0523 01:40:34.651773 34819 solver.cpp:239] Iteration 27370 (2.11855 iter/s, 4.7202s/10 iters), loss = 8.06182
I0523 01:40:34.651816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06182 (* 1 = 8.06182 loss)
I0523 01:40:35.507625 34819 sgd_solver.cpp:112] Iteration 27370, lr = 0.01
I0523 01:40:39.121088 34819 solver.cpp:239] Iteration 27380 (2.2376 iter/s, 4.46908s/10 iters), loss = 9.45076
I0523 01:40:39.121137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45076 (* 1 = 9.45076 loss)
I0523 01:40:39.181505 34819 sgd_solver.cpp:112] Iteration 27380, lr = 0.01
I0523 01:40:45.030792 34819 solver.cpp:239] Iteration 27390 (1.69222 iter/s, 5.90941s/10 iters), loss = 7.69902
I0523 01:40:45.030843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69902 (* 1 = 7.69902 loss)
I0523 01:40:45.100961 34819 sgd_solver.cpp:112] Iteration 27390, lr = 0.01
I0523 01:40:51.111919 34819 solver.cpp:239] Iteration 27400 (1.64451 iter/s, 6.08082s/10 iters), loss = 8.78418
I0523 01:40:51.111963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78418 (* 1 = 8.78418 loss)
I0523 01:40:51.931529 34819 sgd_solver.cpp:112] Iteration 27400, lr = 0.01
I0523 01:40:54.638588 34819 solver.cpp:239] Iteration 27410 (2.83569 iter/s, 3.52647s/10 iters), loss = 8.27711
I0523 01:40:54.638634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27711 (* 1 = 8.27711 loss)
I0523 01:40:55.258466 34819 sgd_solver.cpp:112] Iteration 27410, lr = 0.01
I0523 01:41:00.391280 34819 solver.cpp:239] Iteration 27420 (1.7384 iter/s, 5.75241s/10 iters), loss = 7.95634
I0523 01:41:00.391458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95634 (* 1 = 7.95634 loss)
I0523 01:41:00.461081 34819 sgd_solver.cpp:112] Iteration 27420, lr = 0.01
I0523 01:41:02.289474 34819 solver.cpp:239] Iteration 27430 (5.2689 iter/s, 1.89793s/10 iters), loss = 8.96157
I0523 01:41:02.289521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96157 (* 1 = 8.96157 loss)
I0523 01:41:03.093006 34819 sgd_solver.cpp:112] Iteration 27430, lr = 0.01
I0523 01:41:08.173813 34819 solver.cpp:239] Iteration 27440 (1.69951 iter/s, 5.88405s/10 iters), loss = 8.71941
I0523 01:41:08.173864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71941 (* 1 = 8.71941 loss)
I0523 01:41:08.954634 34819 sgd_solver.cpp:112] Iteration 27440, lr = 0.01
I0523 01:41:14.192407 34819 solver.cpp:239] Iteration 27450 (1.6616 iter/s, 6.01829s/10 iters), loss = 8.64096
I0523 01:41:14.192461 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64096 (* 1 = 8.64096 loss)
I0523 01:41:14.260980 34819 sgd_solver.cpp:112] Iteration 27450, lr = 0.01
I0523 01:41:18.374176 34819 solver.cpp:239] Iteration 27460 (2.39147 iter/s, 4.18153s/10 iters), loss = 7.61306
I0523 01:41:18.374222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61306 (* 1 = 7.61306 loss)
I0523 01:41:18.442042 34819 sgd_solver.cpp:112] Iteration 27460, lr = 0.01
I0523 01:41:23.386252 34819 solver.cpp:239] Iteration 27470 (1.99529 iter/s, 5.01181s/10 iters), loss = 8.61273
I0523 01:41:23.386306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61273 (* 1 = 8.61273 loss)
I0523 01:41:23.459120 34819 sgd_solver.cpp:112] Iteration 27470, lr = 0.01
I0523 01:41:27.483074 34819 solver.cpp:239] Iteration 27480 (2.44106 iter/s, 4.09658s/10 iters), loss = 9.72722
I0523 01:41:27.483129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72722 (* 1 = 9.72722 loss)
I0523 01:41:27.561516 34819 sgd_solver.cpp:112] Iteration 27480, lr = 0.01
I0523 01:41:33.493878 34819 solver.cpp:239] Iteration 27490 (1.66375 iter/s, 6.0105s/10 iters), loss = 9.2732
I0523 01:41:33.494052 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2732 (* 1 = 9.2732 loss)
I0523 01:41:34.221061 34819 sgd_solver.cpp:112] Iteration 27490, lr = 0.01
I0523 01:41:39.148584 34819 solver.cpp:239] Iteration 27500 (1.76857 iter/s, 5.6543s/10 iters), loss = 9.22388
I0523 01:41:39.148625 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22388 (* 1 = 9.22388 loss)
I0523 01:41:39.216862 34819 sgd_solver.cpp:112] Iteration 27500, lr = 0.01
I0523 01:41:44.008445 34819 solver.cpp:239] Iteration 27510 (2.05778 iter/s, 4.85961s/10 iters), loss = 8.78695
I0523 01:41:44.008488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78695 (* 1 = 8.78695 loss)
I0523 01:41:44.655705 34819 sgd_solver.cpp:112] Iteration 27510, lr = 0.01
I0523 01:41:49.573180 34819 solver.cpp:239] Iteration 27520 (1.79712 iter/s, 5.56445s/10 iters), loss = 9.17201
I0523 01:41:49.573227 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17201 (* 1 = 9.17201 loss)
I0523 01:41:49.628458 34819 sgd_solver.cpp:112] Iteration 27520, lr = 0.01
I0523 01:41:54.303513 34819 solver.cpp:239] Iteration 27530 (2.11413 iter/s, 4.73007s/10 iters), loss = 8.6934
I0523 01:41:54.303563 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6934 (* 1 = 8.6934 loss)
I0523 01:41:54.379747 34819 sgd_solver.cpp:112] Iteration 27530, lr = 0.01
I0523 01:41:58.852013 34819 solver.cpp:239] Iteration 27540 (2.19864 iter/s, 4.54826s/10 iters), loss = 8.09184
I0523 01:41:58.852066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09184 (* 1 = 8.09184 loss)
I0523 01:41:58.933876 34819 sgd_solver.cpp:112] Iteration 27540, lr = 0.01
I0523 01:42:04.392271 34819 solver.cpp:239] Iteration 27550 (1.80507 iter/s, 5.53996s/10 iters), loss = 8.87296
I0523 01:42:04.392407 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87296 (* 1 = 8.87296 loss)
I0523 01:42:04.459691 34819 sgd_solver.cpp:112] Iteration 27550, lr = 0.01
I0523 01:42:09.243965 34819 solver.cpp:239] Iteration 27560 (2.06128 iter/s, 4.85135s/10 iters), loss = 9.12575
I0523 01:42:09.244019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12575 (* 1 = 9.12575 loss)
I0523 01:42:09.410396 34819 sgd_solver.cpp:112] Iteration 27560, lr = 0.01
I0523 01:42:15.455045 34819 solver.cpp:239] Iteration 27570 (1.61011 iter/s, 6.21076s/10 iters), loss = 9.18415
I0523 01:42:15.455096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18415 (* 1 = 9.18415 loss)
I0523 01:42:15.522334 34819 sgd_solver.cpp:112] Iteration 27570, lr = 0.01
I0523 01:42:21.334578 34819 solver.cpp:239] Iteration 27580 (1.7009 iter/s, 5.87924s/10 iters), loss = 9.0582
I0523 01:42:21.334648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0582 (* 1 = 9.0582 loss)
I0523 01:42:21.402518 34819 sgd_solver.cpp:112] Iteration 27580, lr = 0.01
I0523 01:42:25.909797 34819 solver.cpp:239] Iteration 27590 (2.18581 iter/s, 4.57496s/10 iters), loss = 8.08258
I0523 01:42:25.909859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08258 (* 1 = 8.08258 loss)
I0523 01:42:25.968560 34819 sgd_solver.cpp:112] Iteration 27590, lr = 0.01
I0523 01:42:29.323910 34819 solver.cpp:239] Iteration 27600 (2.9292 iter/s, 3.4139s/10 iters), loss = 8.75117
I0523 01:42:29.323964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75117 (* 1 = 8.75117 loss)
I0523 01:42:30.166061 34819 sgd_solver.cpp:112] Iteration 27600, lr = 0.01
I0523 01:42:33.584074 34819 solver.cpp:239] Iteration 27610 (2.34747 iter/s, 4.2599s/10 iters), loss = 8.32895
I0523 01:42:33.584131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32895 (* 1 = 8.32895 loss)
I0523 01:42:34.400364 34819 sgd_solver.cpp:112] Iteration 27610, lr = 0.01
I0523 01:42:37.908630 34819 solver.cpp:239] Iteration 27620 (2.31251 iter/s, 4.32431s/10 iters), loss = 9.21126
I0523 01:42:37.908684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21126 (* 1 = 9.21126 loss)
I0523 01:42:38.599402 34819 sgd_solver.cpp:112] Iteration 27620, lr = 0.01
I0523 01:42:41.895495 34819 solver.cpp:239] Iteration 27630 (2.50838 iter/s, 3.98664s/10 iters), loss = 9.38277
I0523 01:42:41.895546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38277 (* 1 = 9.38277 loss)
I0523 01:42:42.741420 34819 sgd_solver.cpp:112] Iteration 27630, lr = 0.01
I0523 01:42:47.455399 34819 solver.cpp:239] Iteration 27640 (1.79868 iter/s, 5.55962s/10 iters), loss = 8.93608
I0523 01:42:47.455440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93608 (* 1 = 8.93608 loss)
I0523 01:42:47.524564 34819 sgd_solver.cpp:112] Iteration 27640, lr = 0.01
I0523 01:42:54.133973 34819 solver.cpp:239] Iteration 27650 (1.4974 iter/s, 6.67825s/10 iters), loss = 8.28394
I0523 01:42:54.134017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28394 (* 1 = 8.28394 loss)
I0523 01:42:54.197648 34819 sgd_solver.cpp:112] Iteration 27650, lr = 0.01
I0523 01:42:56.892721 34819 solver.cpp:239] Iteration 27660 (3.62505 iter/s, 2.75858s/10 iters), loss = 8.71582
I0523 01:42:56.892767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71582 (* 1 = 8.71582 loss)
I0523 01:42:57.165778 34819 sgd_solver.cpp:112] Iteration 27660, lr = 0.01
I0523 01:43:01.303433 34819 solver.cpp:239] Iteration 27670 (2.26733 iter/s, 4.41048s/10 iters), loss = 8.58726
I0523 01:43:01.303483 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58726 (* 1 = 8.58726 loss)
I0523 01:43:01.361694 34819 sgd_solver.cpp:112] Iteration 27670, lr = 0.01
I0523 01:43:05.463856 34819 solver.cpp:239] Iteration 27680 (2.40374 iter/s, 4.16018s/10 iters), loss = 8.73115
I0523 01:43:05.464100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73115 (* 1 = 8.73115 loss)
I0523 01:43:06.318671 34819 sgd_solver.cpp:112] Iteration 27680, lr = 0.01
I0523 01:43:10.921663 34819 solver.cpp:239] Iteration 27690 (1.83239 iter/s, 5.45736s/10 iters), loss = 8.88371
I0523 01:43:10.921715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88371 (* 1 = 8.88371 loss)
I0523 01:43:11.757534 34819 sgd_solver.cpp:112] Iteration 27690, lr = 0.01
I0523 01:43:16.149955 34819 solver.cpp:239] Iteration 27700 (1.91277 iter/s, 5.22802s/10 iters), loss = 7.67175
I0523 01:43:16.149997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67175 (* 1 = 7.67175 loss)
I0523 01:43:16.857477 34819 sgd_solver.cpp:112] Iteration 27700, lr = 0.01
I0523 01:43:20.427799 34819 solver.cpp:239] Iteration 27710 (2.33776 iter/s, 4.27759s/10 iters), loss = 9.07414
I0523 01:43:20.427876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07414 (* 1 = 9.07414 loss)
I0523 01:43:21.200109 34819 sgd_solver.cpp:112] Iteration 27710, lr = 0.01
I0523 01:43:26.180654 34819 solver.cpp:239] Iteration 27720 (1.73837 iter/s, 5.75253s/10 iters), loss = 8.92432
I0523 01:43:26.180717 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92432 (* 1 = 8.92432 loss)
I0523 01:43:26.532766 34819 sgd_solver.cpp:112] Iteration 27720, lr = 0.01
I0523 01:43:33.655069 34819 solver.cpp:239] Iteration 27730 (1.33796 iter/s, 7.47404s/10 iters), loss = 9.2508
I0523 01:43:33.655124 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2508 (* 1 = 9.2508 loss)
I0523 01:43:34.485963 34819 sgd_solver.cpp:112] Iteration 27730, lr = 0.01
I0523 01:43:41.017669 34819 solver.cpp:239] Iteration 27740 (1.35828 iter/s, 7.36224s/10 iters), loss = 8.62946
I0523 01:43:41.017943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62946 (* 1 = 8.62946 loss)
I0523 01:43:41.091476 34819 sgd_solver.cpp:112] Iteration 27740, lr = 0.01
I0523 01:43:44.267230 34819 solver.cpp:239] Iteration 27750 (3.0777 iter/s, 3.24918s/10 iters), loss = 8.81565
I0523 01:43:44.267278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81565 (* 1 = 8.81565 loss)
I0523 01:43:44.327569 34819 sgd_solver.cpp:112] Iteration 27750, lr = 0.01
I0523 01:43:46.512476 34819 solver.cpp:239] Iteration 27760 (4.45418 iter/s, 2.24508s/10 iters), loss = 8.11016
I0523 01:43:46.512544 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11016 (* 1 = 8.11016 loss)
I0523 01:43:46.584311 34819 sgd_solver.cpp:112] Iteration 27760, lr = 0.01
I0523 01:43:51.464932 34819 solver.cpp:239] Iteration 27770 (2.01932 iter/s, 4.95216s/10 iters), loss = 9.08408
I0523 01:43:51.465000 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08408 (* 1 = 9.08408 loss)
I0523 01:43:51.542127 34819 sgd_solver.cpp:112] Iteration 27770, lr = 0.01
I0523 01:43:55.933132 34819 solver.cpp:239] Iteration 27780 (2.23817 iter/s, 4.46794s/10 iters), loss = 8.50975
I0523 01:43:55.933185 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50975 (* 1 = 8.50975 loss)
I0523 01:43:56.010527 34819 sgd_solver.cpp:112] Iteration 27780, lr = 0.01
I0523 01:44:00.820143 34819 solver.cpp:239] Iteration 27790 (2.04635 iter/s, 4.88674s/10 iters), loss = 8.48493
I0523 01:44:00.820195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48493 (* 1 = 8.48493 loss)
I0523 01:44:00.881186 34819 sgd_solver.cpp:112] Iteration 27790, lr = 0.01
I0523 01:44:04.289796 34819 solver.cpp:239] Iteration 27800 (2.88232 iter/s, 3.46943s/10 iters), loss = 7.74926
I0523 01:44:04.289852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74926 (* 1 = 7.74926 loss)
I0523 01:44:04.364063 34819 sgd_solver.cpp:112] Iteration 27800, lr = 0.01
I0523 01:44:09.039438 34819 solver.cpp:239] Iteration 27810 (2.10554 iter/s, 4.74937s/10 iters), loss = 8.77242
I0523 01:44:09.039492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77242 (* 1 = 8.77242 loss)
I0523 01:44:09.108826 34819 sgd_solver.cpp:112] Iteration 27810, lr = 0.01
I0523 01:44:13.146121 34819 solver.cpp:239] Iteration 27820 (2.43519 iter/s, 4.10645s/10 iters), loss = 8.11491
I0523 01:44:13.146298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11491 (* 1 = 8.11491 loss)
I0523 01:44:13.964555 34819 sgd_solver.cpp:112] Iteration 27820, lr = 0.01
I0523 01:44:19.501099 34819 solver.cpp:239] Iteration 27830 (1.57368 iter/s, 6.35454s/10 iters), loss = 9.35449
I0523 01:44:19.501164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35449 (* 1 = 9.35449 loss)
I0523 01:44:20.289896 34819 sgd_solver.cpp:112] Iteration 27830, lr = 0.01
I0523 01:44:24.329473 34819 solver.cpp:239] Iteration 27840 (2.07121 iter/s, 4.82809s/10 iters), loss = 8.16899
I0523 01:44:24.329545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16899 (* 1 = 8.16899 loss)
I0523 01:44:24.387614 34819 sgd_solver.cpp:112] Iteration 27840, lr = 0.01
I0523 01:44:29.001153 34819 solver.cpp:239] Iteration 27850 (2.14068 iter/s, 4.67141s/10 iters), loss = 8.79878
I0523 01:44:29.001217 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79878 (* 1 = 8.79878 loss)
I0523 01:44:29.798701 34819 sgd_solver.cpp:112] Iteration 27850, lr = 0.01
I0523 01:44:34.555701 34819 solver.cpp:239] Iteration 27860 (1.80042 iter/s, 5.55425s/10 iters), loss = 9.3068
I0523 01:44:34.555752 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3068 (* 1 = 9.3068 loss)
I0523 01:44:35.297199 34819 sgd_solver.cpp:112] Iteration 27860, lr = 0.01
I0523 01:44:41.417706 34819 solver.cpp:239] Iteration 27870 (1.45738 iter/s, 6.86165s/10 iters), loss = 8.51171
I0523 01:44:41.417762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51171 (* 1 = 8.51171 loss)
I0523 01:44:42.181531 34819 sgd_solver.cpp:112] Iteration 27870, lr = 0.01
I0523 01:44:46.489611 34819 solver.cpp:239] Iteration 27880 (1.97177 iter/s, 5.0716s/10 iters), loss = 9.04237
I0523 01:44:46.489806 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04237 (* 1 = 9.04237 loss)
I0523 01:44:47.223371 34819 sgd_solver.cpp:112] Iteration 27880, lr = 0.01
I0523 01:44:52.768400 34819 solver.cpp:239] Iteration 27890 (1.59278 iter/s, 6.27833s/10 iters), loss = 9.37053
I0523 01:44:52.768458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37053 (* 1 = 9.37053 loss)
I0523 01:44:52.831305 34819 sgd_solver.cpp:112] Iteration 27890, lr = 0.01
I0523 01:44:58.792488 34819 solver.cpp:239] Iteration 27900 (1.66009 iter/s, 6.02378s/10 iters), loss = 9.30764
I0523 01:44:58.792546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30764 (* 1 = 9.30764 loss)
I0523 01:44:58.871351 34819 sgd_solver.cpp:112] Iteration 27900, lr = 0.01
I0523 01:45:04.479432 34819 solver.cpp:239] Iteration 27910 (1.7585 iter/s, 5.68665s/10 iters), loss = 9.2664
I0523 01:45:04.479478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2664 (* 1 = 9.2664 loss)
I0523 01:45:04.532452 34819 sgd_solver.cpp:112] Iteration 27910, lr = 0.01
I0523 01:45:07.946820 34819 solver.cpp:239] Iteration 27920 (2.8842 iter/s, 3.46717s/10 iters), loss = 7.6046
I0523 01:45:07.946882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6046 (* 1 = 7.6046 loss)
I0523 01:45:08.009840 34819 sgd_solver.cpp:112] Iteration 27920, lr = 0.01
I0523 01:45:12.104738 34819 solver.cpp:239] Iteration 27930 (2.40519 iter/s, 4.15768s/10 iters), loss = 8.94014
I0523 01:45:12.104794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94014 (* 1 = 8.94014 loss)
I0523 01:45:12.923617 34819 sgd_solver.cpp:112] Iteration 27930, lr = 0.01
I0523 01:45:19.340119 34819 solver.cpp:239] Iteration 27940 (1.38216 iter/s, 7.23503s/10 iters), loss = 8.34551
I0523 01:45:19.340268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34551 (* 1 = 8.34551 loss)
I0523 01:45:20.137917 34819 sgd_solver.cpp:112] Iteration 27940, lr = 0.01
I0523 01:45:24.302925 34819 solver.cpp:239] Iteration 27950 (2.01513 iter/s, 4.96245s/10 iters), loss = 8.79022
I0523 01:45:24.302969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79022 (* 1 = 8.79022 loss)
I0523 01:45:24.358433 34819 sgd_solver.cpp:112] Iteration 27950, lr = 0.01
I0523 01:45:27.897805 34819 solver.cpp:239] Iteration 27960 (2.78189 iter/s, 3.59468s/10 iters), loss = 9.07816
I0523 01:45:27.897853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07816 (* 1 = 9.07816 loss)
I0523 01:45:27.957222 34819 sgd_solver.cpp:112] Iteration 27960, lr = 0.01
I0523 01:45:33.042068 34819 solver.cpp:239] Iteration 27970 (1.94401 iter/s, 5.14399s/10 iters), loss = 9.09523
I0523 01:45:33.042111 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09523 (* 1 = 9.09523 loss)
I0523 01:45:33.116041 34819 sgd_solver.cpp:112] Iteration 27970, lr = 0.01
I0523 01:45:38.302600 34819 solver.cpp:239] Iteration 27980 (1.90104 iter/s, 5.26027s/10 iters), loss = 9.15899
I0523 01:45:38.302655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15899 (* 1 = 9.15899 loss)
I0523 01:45:38.370981 34819 sgd_solver.cpp:112] Iteration 27980, lr = 0.01
I0523 01:45:43.983723 34819 solver.cpp:239] Iteration 27990 (1.7603 iter/s, 5.68084s/10 iters), loss = 8.13007
I0523 01:45:43.983775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13007 (* 1 = 8.13007 loss)
I0523 01:45:44.059900 34819 sgd_solver.cpp:112] Iteration 27990, lr = 0.01
I0523 01:45:48.498378 34819 solver.cpp:239] Iteration 28000 (2.21513 iter/s, 4.51441s/10 iters), loss = 8.44269
I0523 01:45:48.498420 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44269 (* 1 = 8.44269 loss)
I0523 01:45:49.364092 34819 sgd_solver.cpp:112] Iteration 28000, lr = 0.01
I0523 01:45:52.648020 34819 solver.cpp:239] Iteration 28010 (2.40997 iter/s, 4.14942s/10 iters), loss = 9.25443
I0523 01:45:52.648069 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25443 (* 1 = 9.25443 loss)
I0523 01:45:53.430865 34819 sgd_solver.cpp:112] Iteration 28010, lr = 0.01
I0523 01:45:57.999881 34819 solver.cpp:239] Iteration 28020 (1.8686 iter/s, 5.35159s/10 iters), loss = 8.21892
I0523 01:45:57.999930 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21892 (* 1 = 8.21892 loss)
I0523 01:45:58.757941 34819 sgd_solver.cpp:112] Iteration 28020, lr = 0.01
I0523 01:46:05.069594 34819 solver.cpp:239] Iteration 28030 (1.41455 iter/s, 7.06937s/10 iters), loss = 8.65097
I0523 01:46:05.069638 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65097 (* 1 = 8.65097 loss)
I0523 01:46:05.793800 34819 sgd_solver.cpp:112] Iteration 28030, lr = 0.01
I0523 01:46:09.223470 34819 solver.cpp:239] Iteration 28040 (2.40752 iter/s, 4.15366s/10 iters), loss = 8.09029
I0523 01:46:09.223513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09029 (* 1 = 8.09029 loss)
I0523 01:46:09.290724 34819 sgd_solver.cpp:112] Iteration 28040, lr = 0.01
I0523 01:46:14.193147 34819 solver.cpp:239] Iteration 28050 (2.01231 iter/s, 4.96941s/10 iters), loss = 8.68668
I0523 01:46:14.193202 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68668 (* 1 = 8.68668 loss)
I0523 01:46:14.268863 34819 sgd_solver.cpp:112] Iteration 28050, lr = 0.01
I0523 01:46:19.132002 34819 solver.cpp:239] Iteration 28060 (2.02487 iter/s, 4.93859s/10 iters), loss = 9.32282
I0523 01:46:19.132058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32282 (* 1 = 9.32282 loss)
I0523 01:46:19.202342 34819 sgd_solver.cpp:112] Iteration 28060, lr = 0.01
I0523 01:46:22.157296 34819 solver.cpp:239] Iteration 28070 (3.30568 iter/s, 3.0251s/10 iters), loss = 9.61995
I0523 01:46:22.157498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61995 (* 1 = 9.61995 loss)
I0523 01:46:22.887163 34819 sgd_solver.cpp:112] Iteration 28070, lr = 0.01
I0523 01:46:27.654429 34819 solver.cpp:239] Iteration 28080 (1.81927 iter/s, 5.4967s/10 iters), loss = 9.33687
I0523 01:46:27.654481 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33687 (* 1 = 9.33687 loss)
I0523 01:46:27.737391 34819 sgd_solver.cpp:112] Iteration 28080, lr = 0.01
I0523 01:46:32.967249 34819 solver.cpp:239] Iteration 28090 (1.88234 iter/s, 5.31255s/10 iters), loss = 9.58598
I0523 01:46:32.967294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58598 (* 1 = 9.58598 loss)
I0523 01:46:33.743261 34819 sgd_solver.cpp:112] Iteration 28090, lr = 0.01
I0523 01:46:38.107523 34819 solver.cpp:239] Iteration 28100 (1.94552 iter/s, 5.14001s/10 iters), loss = 8.81522
I0523 01:46:38.107578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81522 (* 1 = 8.81522 loss)
I0523 01:46:38.187299 34819 sgd_solver.cpp:112] Iteration 28100, lr = 0.01
I0523 01:46:42.763850 34819 solver.cpp:239] Iteration 28110 (2.14774 iter/s, 4.65607s/10 iters), loss = 8.74032
I0523 01:46:42.763906 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74032 (* 1 = 8.74032 loss)
I0523 01:46:42.844715 34819 sgd_solver.cpp:112] Iteration 28110, lr = 0.01
I0523 01:46:46.641175 34819 solver.cpp:239] Iteration 28120 (2.57925 iter/s, 3.8771s/10 iters), loss = 9.12986
I0523 01:46:46.641223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12986 (* 1 = 9.12986 loss)
I0523 01:46:47.239776 34819 sgd_solver.cpp:112] Iteration 28120, lr = 0.01
I0523 01:46:52.094681 34819 solver.cpp:239] Iteration 28130 (1.83378 iter/s, 5.45322s/10 iters), loss = 8.72341
I0523 01:46:52.094756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72341 (* 1 = 8.72341 loss)
I0523 01:46:52.166388 34819 sgd_solver.cpp:112] Iteration 28130, lr = 0.01
I0523 01:46:56.427523 34819 solver.cpp:239] Iteration 28140 (2.3081 iter/s, 4.33258s/10 iters), loss = 8.82798
I0523 01:46:56.427573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82798 (* 1 = 8.82798 loss)
I0523 01:46:56.502039 34819 sgd_solver.cpp:112] Iteration 28140, lr = 0.01
I0523 01:47:01.400949 34819 solver.cpp:239] Iteration 28150 (2.01079 iter/s, 4.97316s/10 iters), loss = 7.77874
I0523 01:47:01.400993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77874 (* 1 = 7.77874 loss)
I0523 01:47:01.458770 34819 sgd_solver.cpp:112] Iteration 28150, lr = 0.01
I0523 01:47:06.205088 34819 solver.cpp:239] Iteration 28160 (2.08164 iter/s, 4.8039s/10 iters), loss = 9.38322
I0523 01:47:06.205140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38322 (* 1 = 9.38322 loss)
I0523 01:47:06.265782 34819 sgd_solver.cpp:112] Iteration 28160, lr = 0.01
I0523 01:47:10.310919 34819 solver.cpp:239] Iteration 28170 (2.4357 iter/s, 4.10559s/10 iters), loss = 8.44036
I0523 01:47:10.310976 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44036 (* 1 = 8.44036 loss)
I0523 01:47:10.379463 34819 sgd_solver.cpp:112] Iteration 28170, lr = 0.01
I0523 01:47:14.511068 34819 solver.cpp:239] Iteration 28180 (2.38101 iter/s, 4.19991s/10 iters), loss = 8.56572
I0523 01:47:14.511129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56572 (* 1 = 8.56572 loss)
I0523 01:47:15.346331 34819 sgd_solver.cpp:112] Iteration 28180, lr = 0.01
I0523 01:47:20.811458 34819 solver.cpp:239] Iteration 28190 (1.58728 iter/s, 6.30007s/10 iters), loss = 9.34979
I0523 01:47:20.811516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34979 (* 1 = 9.34979 loss)
I0523 01:47:20.887715 34819 sgd_solver.cpp:112] Iteration 28190, lr = 0.01
I0523 01:47:25.744509 34819 solver.cpp:239] Iteration 28200 (2.02725 iter/s, 4.93279s/10 iters), loss = 8.73503
I0523 01:47:25.744719 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73503 (* 1 = 8.73503 loss)
I0523 01:47:25.816367 34819 sgd_solver.cpp:112] Iteration 28200, lr = 0.01
I0523 01:47:31.239789 34819 solver.cpp:239] Iteration 28210 (1.81988 iter/s, 5.49487s/10 iters), loss = 9.13853
I0523 01:47:31.239833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13853 (* 1 = 9.13853 loss)
I0523 01:47:32.083799 34819 sgd_solver.cpp:112] Iteration 28210, lr = 0.01
I0523 01:47:38.828058 34819 solver.cpp:239] Iteration 28220 (1.31789 iter/s, 7.58791s/10 iters), loss = 8.65703
I0523 01:47:38.828099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65703 (* 1 = 8.65703 loss)
I0523 01:47:38.885007 34819 sgd_solver.cpp:112] Iteration 28220, lr = 0.01
I0523 01:47:42.935768 34819 solver.cpp:239] Iteration 28230 (2.43718 iter/s, 4.10311s/10 iters), loss = 10.2148
I0523 01:47:42.935820 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2148 (* 1 = 10.2148 loss)
I0523 01:47:43.002712 34819 sgd_solver.cpp:112] Iteration 28230, lr = 0.01
I0523 01:47:46.700985 34819 solver.cpp:239] Iteration 28240 (2.65604 iter/s, 3.76501s/10 iters), loss = 8.6959
I0523 01:47:46.701031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6959 (* 1 = 8.6959 loss)
I0523 01:47:46.759721 34819 sgd_solver.cpp:112] Iteration 28240, lr = 0.01
I0523 01:47:50.176417 34819 solver.cpp:239] Iteration 28250 (2.8775 iter/s, 3.47524s/10 iters), loss = 9.11556
I0523 01:47:50.176470 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11556 (* 1 = 9.11556 loss)
I0523 01:47:50.234863 34819 sgd_solver.cpp:112] Iteration 28250, lr = 0.01
I0523 01:47:55.732522 34819 solver.cpp:239] Iteration 28260 (1.79992 iter/s, 5.55581s/10 iters), loss = 9.13052
I0523 01:47:55.732576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13052 (* 1 = 9.13052 loss)
I0523 01:47:55.794807 34819 sgd_solver.cpp:112] Iteration 28260, lr = 0.01
I0523 01:48:01.344034 34819 solver.cpp:239] Iteration 28270 (1.78215 iter/s, 5.61119s/10 iters), loss = 8.33544
I0523 01:48:01.344101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33544 (* 1 = 8.33544 loss)
I0523 01:48:02.195981 34819 sgd_solver.cpp:112] Iteration 28270, lr = 0.01
I0523 01:48:06.746132 34819 solver.cpp:239] Iteration 28280 (1.85123 iter/s, 5.4018s/10 iters), loss = 9.07227
I0523 01:48:06.746173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07227 (* 1 = 9.07227 loss)
I0523 01:48:06.825580 34819 sgd_solver.cpp:112] Iteration 28280, lr = 0.01
I0523 01:48:09.530421 34819 solver.cpp:239] Iteration 28290 (3.59181 iter/s, 2.78411s/10 iters), loss = 8.53309
I0523 01:48:09.530472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53309 (* 1 = 8.53309 loss)
I0523 01:48:10.263890 34819 sgd_solver.cpp:112] Iteration 28290, lr = 0.01
I0523 01:48:15.632452 34819 solver.cpp:239] Iteration 28300 (1.63888 iter/s, 6.10172s/10 iters), loss = 8.90566
I0523 01:48:15.632498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90566 (* 1 = 8.90566 loss)
I0523 01:48:15.687362 34819 sgd_solver.cpp:112] Iteration 28300, lr = 0.01
I0523 01:48:18.416934 34819 solver.cpp:239] Iteration 28310 (3.59155 iter/s, 2.78432s/10 iters), loss = 9.41762
I0523 01:48:18.416975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41762 (* 1 = 9.41762 loss)
I0523 01:48:19.183990 34819 sgd_solver.cpp:112] Iteration 28310, lr = 0.01
I0523 01:48:25.027148 34819 solver.cpp:239] Iteration 28320 (1.51289 iter/s, 6.60989s/10 iters), loss = 9.54819
I0523 01:48:25.027211 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54819 (* 1 = 9.54819 loss)
I0523 01:48:25.729560 34819 sgd_solver.cpp:112] Iteration 28320, lr = 0.01
I0523 01:48:30.502619 34819 solver.cpp:239] Iteration 28330 (1.82643 iter/s, 5.47518s/10 iters), loss = 9.10001
I0523 01:48:30.502748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10001 (* 1 = 9.10001 loss)
I0523 01:48:30.572748 34819 sgd_solver.cpp:112] Iteration 28330, lr = 0.01
I0523 01:48:34.957865 34819 solver.cpp:239] Iteration 28340 (2.24471 iter/s, 4.45492s/10 iters), loss = 8.68088
I0523 01:48:34.957911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68088 (* 1 = 8.68088 loss)
I0523 01:48:35.018347 34819 sgd_solver.cpp:112] Iteration 28340, lr = 0.01
I0523 01:48:39.946018 34819 solver.cpp:239] Iteration 28350 (2.00486 iter/s, 4.98789s/10 iters), loss = 9.2537
I0523 01:48:39.946060 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2537 (* 1 = 9.2537 loss)
I0523 01:48:40.727639 34819 sgd_solver.cpp:112] Iteration 28350, lr = 0.01
I0523 01:48:47.161545 34819 solver.cpp:239] Iteration 28360 (1.38597 iter/s, 7.21517s/10 iters), loss = 7.69725
I0523 01:48:47.161589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69725 (* 1 = 7.69725 loss)
I0523 01:48:47.231519 34819 sgd_solver.cpp:112] Iteration 28360, lr = 0.01
I0523 01:48:52.787595 34819 solver.cpp:239] Iteration 28370 (1.77754 iter/s, 5.62576s/10 iters), loss = 9.28967
I0523 01:48:52.787639 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28967 (* 1 = 9.28967 loss)
I0523 01:48:52.850495 34819 sgd_solver.cpp:112] Iteration 28370, lr = 0.01
I0523 01:48:57.488787 34819 solver.cpp:239] Iteration 28380 (2.12723 iter/s, 4.70095s/10 iters), loss = 8.36273
I0523 01:48:57.488831 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36273 (* 1 = 8.36273 loss)
I0523 01:48:57.551436 34819 sgd_solver.cpp:112] Iteration 28380, lr = 0.01
I0523 01:49:02.552959 34819 solver.cpp:239] Iteration 28390 (1.97476 iter/s, 5.0639s/10 iters), loss = 9.53348
I0523 01:49:02.553099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.53348 (* 1 = 9.53348 loss)
I0523 01:49:03.264119 34819 sgd_solver.cpp:112] Iteration 28390, lr = 0.01
I0523 01:49:08.374353 34819 solver.cpp:239] Iteration 28400 (1.71791 iter/s, 5.82101s/10 iters), loss = 8.29803
I0523 01:49:08.374404 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29803 (* 1 = 8.29803 loss)
I0523 01:49:09.152309 34819 sgd_solver.cpp:112] Iteration 28400, lr = 0.01
I0523 01:49:15.680951 34819 solver.cpp:239] Iteration 28410 (1.3687 iter/s, 7.30621s/10 iters), loss = 8.76348
I0523 01:49:15.681001 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76348 (* 1 = 8.76348 loss)
I0523 01:49:16.556869 34819 sgd_solver.cpp:112] Iteration 28410, lr = 0.01
I0523 01:49:22.108024 34819 solver.cpp:239] Iteration 28420 (1.55599 iter/s, 6.42676s/10 iters), loss = 8.56079
I0523 01:49:22.108067 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56079 (* 1 = 8.56079 loss)
I0523 01:49:22.371116 34819 sgd_solver.cpp:112] Iteration 28420, lr = 0.01
I0523 01:49:25.736831 34819 solver.cpp:239] Iteration 28430 (2.7559 iter/s, 3.62858s/10 iters), loss = 8.25139
I0523 01:49:25.736897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25139 (* 1 = 8.25139 loss)
I0523 01:49:26.528514 34819 sgd_solver.cpp:112] Iteration 28430, lr = 0.01
I0523 01:49:30.640558 34819 solver.cpp:239] Iteration 28440 (2.03938 iter/s, 4.90344s/10 iters), loss = 9.10326
I0523 01:49:30.640614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10326 (* 1 = 9.10326 loss)
I0523 01:49:31.404482 34819 sgd_solver.cpp:112] Iteration 28440, lr = 0.01
I0523 01:49:36.088897 34819 solver.cpp:239] Iteration 28450 (1.83552 iter/s, 5.44805s/10 iters), loss = 7.94916
I0523 01:49:36.089061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94916 (* 1 = 7.94916 loss)
I0523 01:49:36.889358 34819 sgd_solver.cpp:112] Iteration 28450, lr = 0.01
I0523 01:49:40.154312 34819 solver.cpp:239] Iteration 28460 (2.45996 iter/s, 4.0651s/10 iters), loss = 9.18472
I0523 01:49:40.154366 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18472 (* 1 = 9.18472 loss)
I0523 01:49:40.218596 34819 sgd_solver.cpp:112] Iteration 28460, lr = 0.01
I0523 01:49:45.861471 34819 solver.cpp:239] Iteration 28470 (1.75228 iter/s, 5.70686s/10 iters), loss = 8.89373
I0523 01:49:45.861526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89373 (* 1 = 8.89373 loss)
I0523 01:49:45.927546 34819 sgd_solver.cpp:112] Iteration 28470, lr = 0.01
I0523 01:49:49.927809 34819 solver.cpp:239] Iteration 28480 (2.45936 iter/s, 4.0661s/10 iters), loss = 8.57858
I0523 01:49:49.927868 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57858 (* 1 = 8.57858 loss)
I0523 01:49:50.000255 34819 sgd_solver.cpp:112] Iteration 28480, lr = 0.01
I0523 01:49:53.093283 34819 solver.cpp:239] Iteration 28490 (3.1593 iter/s, 3.16526s/10 iters), loss = 9.64028
I0523 01:49:53.093351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64028 (* 1 = 9.64028 loss)
I0523 01:49:53.152846 34819 sgd_solver.cpp:112] Iteration 28490, lr = 0.01
I0523 01:49:58.833503 34819 solver.cpp:239] Iteration 28500 (1.74219 iter/s, 5.73991s/10 iters), loss = 8.81317
I0523 01:49:58.833544 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81317 (* 1 = 8.81317 loss)
I0523 01:49:59.663388 34819 sgd_solver.cpp:112] Iteration 28500, lr = 0.01
I0523 01:50:04.917407 34819 solver.cpp:239] Iteration 28510 (1.64376 iter/s, 6.08361s/10 iters), loss = 8.31051
I0523 01:50:04.917451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31051 (* 1 = 8.31051 loss)
I0523 01:50:05.488080 34819 sgd_solver.cpp:112] Iteration 28510, lr = 0.01
I0523 01:50:10.176525 34819 solver.cpp:239] Iteration 28520 (1.90156 iter/s, 5.25884s/10 iters), loss = 8.90143
I0523 01:50:10.176748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90143 (* 1 = 8.90143 loss)
I0523 01:50:10.934433 34819 sgd_solver.cpp:112] Iteration 28520, lr = 0.01
I0523 01:50:13.900805 34819 solver.cpp:239] Iteration 28530 (2.68534 iter/s, 3.72393s/10 iters), loss = 9.61831
I0523 01:50:13.900847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61831 (* 1 = 9.61831 loss)
I0523 01:50:14.769949 34819 sgd_solver.cpp:112] Iteration 28530, lr = 0.01
I0523 01:50:20.151361 34819 solver.cpp:239] Iteration 28540 (1.59993 iter/s, 6.25026s/10 iters), loss = 8.69032
I0523 01:50:20.151406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69032 (* 1 = 8.69032 loss)
I0523 01:50:20.214135 34819 sgd_solver.cpp:112] Iteration 28540, lr = 0.01
I0523 01:50:24.426314 34819 solver.cpp:239] Iteration 28550 (2.33934 iter/s, 4.27471s/10 iters), loss = 8.73463
I0523 01:50:24.426371 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73463 (* 1 = 8.73463 loss)
I0523 01:50:25.298506 34819 sgd_solver.cpp:112] Iteration 28550, lr = 0.01
I0523 01:50:31.573786 34819 solver.cpp:239] Iteration 28560 (1.39917 iter/s, 7.14711s/10 iters), loss = 9.12034
I0523 01:50:31.573846 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12034 (* 1 = 9.12034 loss)
I0523 01:50:31.647382 34819 sgd_solver.cpp:112] Iteration 28560, lr = 0.01
I0523 01:50:36.552870 34819 solver.cpp:239] Iteration 28570 (2.00851 iter/s, 4.97881s/10 iters), loss = 8.84598
I0523 01:50:36.552914 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84598 (* 1 = 8.84598 loss)
I0523 01:50:36.695307 34819 sgd_solver.cpp:112] Iteration 28570, lr = 0.01
I0523 01:50:42.397766 34819 solver.cpp:239] Iteration 28580 (1.71098 iter/s, 5.84461s/10 iters), loss = 10.0836
I0523 01:50:42.397920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0836 (* 1 = 10.0836 loss)
I0523 01:50:42.457059 34819 sgd_solver.cpp:112] Iteration 28580, lr = 0.01
I0523 01:50:48.118708 34819 solver.cpp:239] Iteration 28590 (1.74808 iter/s, 5.72055s/10 iters), loss = 8.97495
I0523 01:50:48.118757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97495 (* 1 = 8.97495 loss)
I0523 01:50:48.997809 34819 sgd_solver.cpp:112] Iteration 28590, lr = 0.01
I0523 01:50:56.352900 34819 solver.cpp:239] Iteration 28600 (1.21451 iter/s, 8.2338s/10 iters), loss = 9.35056
I0523 01:50:56.352957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35056 (* 1 = 9.35056 loss)
I0523 01:50:56.413919 34819 sgd_solver.cpp:112] Iteration 28600, lr = 0.01
I0523 01:51:00.889866 34819 solver.cpp:239] Iteration 28610 (2.20424 iter/s, 4.53672s/10 iters), loss = 8.83023
I0523 01:51:00.889919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83023 (* 1 = 8.83023 loss)
I0523 01:51:00.955008 34819 sgd_solver.cpp:112] Iteration 28610, lr = 0.01
I0523 01:51:05.699810 34819 solver.cpp:239] Iteration 28620 (2.07914 iter/s, 4.80968s/10 iters), loss = 9.29135
I0523 01:51:05.699861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29135 (* 1 = 9.29135 loss)
I0523 01:51:05.773152 34819 sgd_solver.cpp:112] Iteration 28620, lr = 0.01
I0523 01:51:09.191716 34819 solver.cpp:239] Iteration 28630 (2.86396 iter/s, 3.49167s/10 iters), loss = 9.10857
I0523 01:51:09.191771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10857 (* 1 = 9.10857 loss)
I0523 01:51:09.443541 34819 sgd_solver.cpp:112] Iteration 28630, lr = 0.01
I0523 01:51:13.313765 34819 solver.cpp:239] Iteration 28640 (2.42612 iter/s, 4.12181s/10 iters), loss = 8.77013
I0523 01:51:13.313979 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77013 (* 1 = 8.77013 loss)
I0523 01:51:13.372334 34819 sgd_solver.cpp:112] Iteration 28640, lr = 0.01
I0523 01:51:18.027690 34819 solver.cpp:239] Iteration 28650 (2.12154 iter/s, 4.71355s/10 iters), loss = 9.63637
I0523 01:51:18.027740 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63637 (* 1 = 9.63637 loss)
I0523 01:51:18.103097 34819 sgd_solver.cpp:112] Iteration 28650, lr = 0.01
I0523 01:51:23.268301 34819 solver.cpp:239] Iteration 28660 (1.90827 iter/s, 5.24034s/10 iters), loss = 9.90316
I0523 01:51:23.268353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.90316 (* 1 = 9.90316 loss)
I0523 01:51:24.110477 34819 sgd_solver.cpp:112] Iteration 28660, lr = 0.01
I0523 01:51:29.696522 34819 solver.cpp:239] Iteration 28670 (1.55572 iter/s, 6.42791s/10 iters), loss = 8.76472
I0523 01:51:29.696579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76472 (* 1 = 8.76472 loss)
I0523 01:51:30.077059 34819 sgd_solver.cpp:112] Iteration 28670, lr = 0.01
I0523 01:51:33.714799 34819 solver.cpp:239] Iteration 28680 (2.48877 iter/s, 4.01805s/10 iters), loss = 8.01213
I0523 01:51:33.714854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01213 (* 1 = 8.01213 loss)
I0523 01:51:33.814749 34819 sgd_solver.cpp:112] Iteration 28680, lr = 0.01
I0523 01:51:37.202448 34819 solver.cpp:239] Iteration 28690 (2.86744 iter/s, 3.48743s/10 iters), loss = 8.71708
I0523 01:51:37.202502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71708 (* 1 = 8.71708 loss)
I0523 01:51:37.274777 34819 sgd_solver.cpp:112] Iteration 28690, lr = 0.01
I0523 01:51:42.743266 34819 solver.cpp:239] Iteration 28700 (1.80489 iter/s, 5.54052s/10 iters), loss = 8.79574
I0523 01:51:42.743321 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79574 (* 1 = 8.79574 loss)
I0523 01:51:42.806568 34819 sgd_solver.cpp:112] Iteration 28700, lr = 0.01
I0523 01:51:46.578891 34819 solver.cpp:239] Iteration 28710 (2.60729 iter/s, 3.83539s/10 iters), loss = 8.32768
I0523 01:51:46.579149 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32768 (* 1 = 8.32768 loss)
I0523 01:51:47.067697 34819 sgd_solver.cpp:112] Iteration 28710, lr = 0.01
I0523 01:51:50.185310 34819 solver.cpp:239] Iteration 28720 (2.77314 iter/s, 3.60602s/10 iters), loss = 8.14072
I0523 01:51:50.185361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14072 (* 1 = 8.14072 loss)
I0523 01:51:50.244813 34819 sgd_solver.cpp:112] Iteration 28720, lr = 0.01
I0523 01:51:54.277846 34819 solver.cpp:239] Iteration 28730 (2.44361 iter/s, 4.09231s/10 iters), loss = 8.96295
I0523 01:51:54.277891 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96295 (* 1 = 8.96295 loss)
I0523 01:51:54.333308 34819 sgd_solver.cpp:112] Iteration 28730, lr = 0.01
I0523 01:51:57.485200 34819 solver.cpp:239] Iteration 28740 (3.11802 iter/s, 3.20717s/10 iters), loss = 9.70933
I0523 01:51:57.485256 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70933 (* 1 = 9.70933 loss)
I0523 01:51:57.537484 34819 sgd_solver.cpp:112] Iteration 28740, lr = 0.01
I0523 01:52:01.619143 34819 solver.cpp:239] Iteration 28750 (2.41914 iter/s, 4.1337s/10 iters), loss = 8.16029
I0523 01:52:01.619206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16029 (* 1 = 8.16029 loss)
I0523 01:52:02.358517 34819 sgd_solver.cpp:112] Iteration 28750, lr = 0.01
I0523 01:52:06.565693 34819 solver.cpp:239] Iteration 28760 (2.02173 iter/s, 4.94625s/10 iters), loss = 9.07722
I0523 01:52:06.565758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07722 (* 1 = 9.07722 loss)
I0523 01:52:07.383191 34819 sgd_solver.cpp:112] Iteration 28760, lr = 0.01
I0523 01:52:10.665105 34819 solver.cpp:239] Iteration 28770 (2.43954 iter/s, 4.09913s/10 iters), loss = 9.04088
I0523 01:52:10.665163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04088 (* 1 = 9.04088 loss)
I0523 01:52:10.737376 34819 sgd_solver.cpp:112] Iteration 28770, lr = 0.01
I0523 01:52:15.021215 34819 solver.cpp:239] Iteration 28780 (2.29575 iter/s, 4.35587s/10 iters), loss = 8.68435
I0523 01:52:15.021267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68435 (* 1 = 8.68435 loss)
I0523 01:52:15.895946 34819 sgd_solver.cpp:112] Iteration 28780, lr = 0.01
I0523 01:52:21.051215 34819 solver.cpp:239] Iteration 28790 (1.65846 iter/s, 6.0297s/10 iters), loss = 8.66882
I0523 01:52:21.051424 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66882 (* 1 = 8.66882 loss)
I0523 01:52:21.925739 34819 sgd_solver.cpp:112] Iteration 28790, lr = 0.01
I0523 01:52:26.981391 34819 solver.cpp:239] Iteration 28800 (1.68642 iter/s, 5.92974s/10 iters), loss = 9.07648
I0523 01:52:26.981437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07648 (* 1 = 9.07648 loss)
I0523 01:52:27.843703 34819 sgd_solver.cpp:112] Iteration 28800, lr = 0.01
I0523 01:52:30.491335 34819 solver.cpp:239] Iteration 28810 (2.84921 iter/s, 3.50974s/10 iters), loss = 8.8147
I0523 01:52:30.491382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8147 (* 1 = 8.8147 loss)
I0523 01:52:31.307476 34819 sgd_solver.cpp:112] Iteration 28810, lr = 0.01
I0523 01:52:35.385054 34819 solver.cpp:239] Iteration 28820 (2.04354 iter/s, 4.89346s/10 iters), loss = 8.80547
I0523 01:52:35.385095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80547 (* 1 = 8.80547 loss)
I0523 01:52:35.442987 34819 sgd_solver.cpp:112] Iteration 28820, lr = 0.01
I0523 01:52:39.365968 34819 solver.cpp:239] Iteration 28830 (2.51212 iter/s, 3.9807s/10 iters), loss = 8.52394
I0523 01:52:39.366020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52394 (* 1 = 8.52394 loss)
I0523 01:52:40.202322 34819 sgd_solver.cpp:112] Iteration 28830, lr = 0.01
I0523 01:52:43.896623 34819 solver.cpp:239] Iteration 28840 (2.2073 iter/s, 4.53042s/10 iters), loss = 9.27782
I0523 01:52:43.896666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27782 (* 1 = 9.27782 loss)
I0523 01:52:43.966861 34819 sgd_solver.cpp:112] Iteration 28840, lr = 0.01
I0523 01:52:48.154247 34819 solver.cpp:239] Iteration 28850 (2.34886 iter/s, 4.25738s/10 iters), loss = 9.3281
I0523 01:52:48.154299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3281 (* 1 = 9.3281 loss)
I0523 01:52:48.973816 34819 sgd_solver.cpp:112] Iteration 28850, lr = 0.01
I0523 01:52:54.370012 34819 solver.cpp:239] Iteration 28860 (1.60889 iter/s, 6.21547s/10 iters), loss = 7.97875
I0523 01:52:54.370270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97875 (* 1 = 7.97875 loss)
I0523 01:52:55.234894 34819 sgd_solver.cpp:112] Iteration 28860, lr = 0.01
I0523 01:52:59.277350 34819 solver.cpp:239] Iteration 28870 (2.03795 iter/s, 4.9069s/10 iters), loss = 9.06983
I0523 01:52:59.277411 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06983 (* 1 = 9.06983 loss)
I0523 01:52:59.340715 34819 sgd_solver.cpp:112] Iteration 28870, lr = 0.01
I0523 01:53:04.761471 34819 solver.cpp:239] Iteration 28880 (1.82355 iter/s, 5.48381s/10 iters), loss = 8.3625
I0523 01:53:04.761528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3625 (* 1 = 8.3625 loss)
I0523 01:53:04.830850 34819 sgd_solver.cpp:112] Iteration 28880, lr = 0.01
I0523 01:53:08.726092 34819 solver.cpp:239] Iteration 28890 (2.52247 iter/s, 3.96437s/10 iters), loss = 8.72987
I0523 01:53:08.726152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72987 (* 1 = 8.72987 loss)
I0523 01:53:08.868844 34819 sgd_solver.cpp:112] Iteration 28890, lr = 0.01
I0523 01:53:14.533262 34819 solver.cpp:239] Iteration 28900 (1.7221 iter/s, 5.80687s/10 iters), loss = 9.40413
I0523 01:53:14.533303 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40413 (* 1 = 9.40413 loss)
I0523 01:53:15.236385 34819 sgd_solver.cpp:112] Iteration 28900, lr = 0.01
I0523 01:53:19.466634 34819 solver.cpp:239] Iteration 28910 (2.02711 iter/s, 4.93312s/10 iters), loss = 8.25848
I0523 01:53:19.466687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25848 (* 1 = 8.25848 loss)
I0523 01:53:19.528667 34819 sgd_solver.cpp:112] Iteration 28910, lr = 0.01
I0523 01:53:25.139523 34819 solver.cpp:239] Iteration 28920 (1.76286 iter/s, 5.67259s/10 iters), loss = 8.28954
I0523 01:53:25.139721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28954 (* 1 = 8.28954 loss)
I0523 01:53:25.211076 34819 sgd_solver.cpp:112] Iteration 28920, lr = 0.01
I0523 01:53:29.642386 34819 solver.cpp:239] Iteration 28930 (2.22099 iter/s, 4.5025s/10 iters), loss = 9.55564
I0523 01:53:29.642438 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55564 (* 1 = 9.55564 loss)
I0523 01:53:29.705838 34819 sgd_solver.cpp:112] Iteration 28930, lr = 0.01
I0523 01:53:33.188495 34819 solver.cpp:239] Iteration 28940 (2.82015 iter/s, 3.54591s/10 iters), loss = 8.94621
I0523 01:53:33.188542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94621 (* 1 = 8.94621 loss)
I0523 01:53:33.297446 34819 sgd_solver.cpp:112] Iteration 28940, lr = 0.01
I0523 01:53:34.972203 34819 solver.cpp:239] Iteration 28950 (5.61361 iter/s, 1.78139s/10 iters), loss = 8.0786
I0523 01:53:34.972244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0786 (* 1 = 8.0786 loss)
I0523 01:53:35.775207 34819 sgd_solver.cpp:112] Iteration 28950, lr = 0.01
I0523 01:53:39.407893 34819 solver.cpp:239] Iteration 28960 (2.25456 iter/s, 4.43546s/10 iters), loss = 8.92463
I0523 01:53:39.407945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92463 (* 1 = 8.92463 loss)
I0523 01:53:39.463836 34819 sgd_solver.cpp:112] Iteration 28960, lr = 0.01
I0523 01:53:45.265029 34819 solver.cpp:239] Iteration 28970 (1.70741 iter/s, 5.85683s/10 iters), loss = 9.09929
I0523 01:53:45.265080 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09929 (* 1 = 9.09929 loss)
I0523 01:53:46.103461 34819 sgd_solver.cpp:112] Iteration 28970, lr = 0.01
I0523 01:53:50.842391 34819 solver.cpp:239] Iteration 28980 (1.79305 iter/s, 5.57708s/10 iters), loss = 8.76899
I0523 01:53:50.842437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76899 (* 1 = 8.76899 loss)
I0523 01:53:51.615916 34819 sgd_solver.cpp:112] Iteration 28980, lr = 0.01
I0523 01:53:56.427376 34819 solver.cpp:239] Iteration 28990 (1.79061 iter/s, 5.58469s/10 iters), loss = 8.90689
I0523 01:53:56.427599 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90689 (* 1 = 8.90689 loss)
I0523 01:53:56.493407 34819 sgd_solver.cpp:112] Iteration 28990, lr = 0.01
I0523 01:53:58.904834 34819 solver.cpp:239] Iteration 29000 (4.03691 iter/s, 2.47714s/10 iters), loss = 9.4503
I0523 01:53:58.904887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4503 (* 1 = 9.4503 loss)
I0523 01:53:58.966490 34819 sgd_solver.cpp:112] Iteration 29000, lr = 0.01
I0523 01:54:03.359290 34819 solver.cpp:239] Iteration 29010 (2.24507 iter/s, 4.45421s/10 iters), loss = 8.25608
I0523 01:54:03.359334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25608 (* 1 = 8.25608 loss)
I0523 01:54:04.071202 34819 sgd_solver.cpp:112] Iteration 29010, lr = 0.01
I0523 01:54:09.505714 34819 solver.cpp:239] Iteration 29020 (1.62704 iter/s, 6.14613s/10 iters), loss = 8.52573
I0523 01:54:09.505755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52573 (* 1 = 8.52573 loss)
I0523 01:54:09.573935 34819 sgd_solver.cpp:112] Iteration 29020, lr = 0.01
I0523 01:54:12.964715 34819 solver.cpp:239] Iteration 29030 (2.89117 iter/s, 3.45881s/10 iters), loss = 8.37528
I0523 01:54:12.964763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37528 (* 1 = 8.37528 loss)
I0523 01:54:13.470443 34819 sgd_solver.cpp:112] Iteration 29030, lr = 0.01
I0523 01:54:17.626366 34819 solver.cpp:239] Iteration 29040 (2.14527 iter/s, 4.66141s/10 iters), loss = 8.32897
I0523 01:54:17.626410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32897 (* 1 = 8.32897 loss)
I0523 01:54:17.698794 34819 sgd_solver.cpp:112] Iteration 29040, lr = 0.01
I0523 01:54:23.455608 34819 solver.cpp:239] Iteration 29050 (1.71557 iter/s, 5.82896s/10 iters), loss = 9.21496
I0523 01:54:23.455653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21496 (* 1 = 9.21496 loss)
I0523 01:54:23.529362 34819 sgd_solver.cpp:112] Iteration 29050, lr = 0.01
I0523 01:54:27.704537 34819 solver.cpp:239] Iteration 29060 (2.35366 iter/s, 4.2487s/10 iters), loss = 9.26507
I0523 01:54:27.704658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26507 (* 1 = 9.26507 loss)
I0523 01:54:27.784353 34819 sgd_solver.cpp:112] Iteration 29060, lr = 0.01
I0523 01:54:31.296332 34819 solver.cpp:239] Iteration 29070 (2.78433 iter/s, 3.59152s/10 iters), loss = 9.05473
I0523 01:54:31.296388 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05473 (* 1 = 9.05473 loss)
I0523 01:54:31.368320 34819 sgd_solver.cpp:112] Iteration 29070, lr = 0.01
I0523 01:54:35.420291 34819 solver.cpp:239] Iteration 29080 (2.42499 iter/s, 4.12372s/10 iters), loss = 8.13049
I0523 01:54:35.420346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13049 (* 1 = 8.13049 loss)
I0523 01:54:35.745672 34819 sgd_solver.cpp:112] Iteration 29080, lr = 0.01
I0523 01:54:38.875954 34819 solver.cpp:239] Iteration 29090 (2.89397 iter/s, 3.45546s/10 iters), loss = 8.858
I0523 01:54:38.876009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.858 (* 1 = 8.858 loss)
I0523 01:54:38.958364 34819 sgd_solver.cpp:112] Iteration 29090, lr = 0.01
I0523 01:54:43.747875 34819 solver.cpp:239] Iteration 29100 (2.05269 iter/s, 4.87166s/10 iters), loss = 8.14944
I0523 01:54:43.747931 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14944 (* 1 = 8.14944 loss)
I0523 01:54:43.823400 34819 sgd_solver.cpp:112] Iteration 29100, lr = 0.01
I0523 01:54:48.892681 34819 solver.cpp:239] Iteration 29110 (1.94381 iter/s, 5.14454s/10 iters), loss = 9.40854
I0523 01:54:48.892735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40854 (* 1 = 9.40854 loss)
I0523 01:54:48.959944 34819 sgd_solver.cpp:112] Iteration 29110, lr = 0.01
I0523 01:54:54.363330 34819 solver.cpp:239] Iteration 29120 (1.82803 iter/s, 5.47036s/10 iters), loss = 8.98345
I0523 01:54:54.363374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98345 (* 1 = 8.98345 loss)
I0523 01:54:55.157145 34819 sgd_solver.cpp:112] Iteration 29120, lr = 0.01
I0523 01:55:00.138950 34819 solver.cpp:239] Iteration 29130 (1.73151 iter/s, 5.77532s/10 iters), loss = 8.87597
I0523 01:55:00.139178 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87597 (* 1 = 8.87597 loss)
I0523 01:55:00.203444 34819 sgd_solver.cpp:112] Iteration 29130, lr = 0.01
I0523 01:55:04.989183 34819 solver.cpp:239] Iteration 29140 (2.06194 iter/s, 4.84981s/10 iters), loss = 8.70329
I0523 01:55:04.989239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70329 (* 1 = 8.70329 loss)
I0523 01:55:05.057750 34819 sgd_solver.cpp:112] Iteration 29140, lr = 0.01
I0523 01:55:09.927613 34819 solver.cpp:239] Iteration 29150 (2.02504 iter/s, 4.93817s/10 iters), loss = 8.8668
I0523 01:55:09.927670 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8668 (* 1 = 8.8668 loss)
I0523 01:55:10.749722 34819 sgd_solver.cpp:112] Iteration 29150, lr = 0.01
I0523 01:55:16.381238 34819 solver.cpp:239] Iteration 29160 (1.54959 iter/s, 6.4533s/10 iters), loss = 8.71482
I0523 01:55:16.381279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71482 (* 1 = 8.71482 loss)
I0523 01:55:16.440589 34819 sgd_solver.cpp:112] Iteration 29160, lr = 0.01
I0523 01:55:20.544538 34819 solver.cpp:239] Iteration 29170 (2.40208 iter/s, 4.16306s/10 iters), loss = 9.17516
I0523 01:55:20.544591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17516 (* 1 = 9.17516 loss)
I0523 01:55:21.017386 34819 sgd_solver.cpp:112] Iteration 29170, lr = 0.01
I0523 01:55:25.176892 34819 solver.cpp:239] Iteration 29180 (2.15885 iter/s, 4.63209s/10 iters), loss = 9.06666
I0523 01:55:25.176942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06666 (* 1 = 9.06666 loss)
I0523 01:55:25.976300 34819 sgd_solver.cpp:112] Iteration 29180, lr = 0.01
I0523 01:55:32.575609 34819 solver.cpp:239] Iteration 29190 (1.35165 iter/s, 7.39836s/10 iters), loss = 8.53595
I0523 01:55:32.575742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53595 (* 1 = 8.53595 loss)
I0523 01:55:33.095252 34819 sgd_solver.cpp:112] Iteration 29190, lr = 0.01
I0523 01:55:38.423115 34819 solver.cpp:239] Iteration 29200 (1.71024 iter/s, 5.84713s/10 iters), loss = 9.13671
I0523 01:55:38.423166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13671 (* 1 = 9.13671 loss)
I0523 01:55:39.166738 34819 sgd_solver.cpp:112] Iteration 29200, lr = 0.01
I0523 01:55:42.178812 34819 solver.cpp:239] Iteration 29210 (2.66277 iter/s, 3.75549s/10 iters), loss = 9.09702
I0523 01:55:42.178863 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09702 (* 1 = 9.09702 loss)
I0523 01:55:42.242432 34819 sgd_solver.cpp:112] Iteration 29210, lr = 0.01
I0523 01:55:47.520624 34819 solver.cpp:239] Iteration 29220 (1.87212 iter/s, 5.34154s/10 iters), loss = 9.28705
I0523 01:55:47.520678 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28705 (* 1 = 9.28705 loss)
I0523 01:55:47.594671 34819 sgd_solver.cpp:112] Iteration 29220, lr = 0.01
I0523 01:55:50.968894 34819 solver.cpp:239] Iteration 29230 (2.90018 iter/s, 3.44806s/10 iters), loss = 8.91671
I0523 01:55:50.968933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91671 (* 1 = 8.91671 loss)
I0523 01:55:51.801139 34819 sgd_solver.cpp:112] Iteration 29230, lr = 0.01
I0523 01:55:55.856606 34819 solver.cpp:239] Iteration 29240 (2.04605 iter/s, 4.88746s/10 iters), loss = 10.1335
I0523 01:55:55.856653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1335 (* 1 = 10.1335 loss)
I0523 01:55:56.611675 34819 sgd_solver.cpp:112] Iteration 29240, lr = 0.01
I0523 01:56:02.210417 34819 solver.cpp:239] Iteration 29250 (1.57394 iter/s, 6.35349s/10 iters), loss = 8.85003
I0523 01:56:02.210472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85003 (* 1 = 8.85003 loss)
I0523 01:56:02.285665 34819 sgd_solver.cpp:112] Iteration 29250, lr = 0.01
I0523 01:56:08.467588 34819 solver.cpp:239] Iteration 29260 (1.59825 iter/s, 6.25686s/10 iters), loss = 9.1645
I0523 01:56:08.467838 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1645 (* 1 = 9.1645 loss)
I0523 01:56:08.536499 34819 sgd_solver.cpp:112] Iteration 29260, lr = 0.01
I0523 01:56:12.403669 34819 solver.cpp:239] Iteration 29270 (2.54086 iter/s, 3.93567s/10 iters), loss = 9.22582
I0523 01:56:12.403728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22582 (* 1 = 9.22582 loss)
I0523 01:56:12.476650 34819 sgd_solver.cpp:112] Iteration 29270, lr = 0.01
I0523 01:56:16.891930 34819 solver.cpp:239] Iteration 29280 (2.22816 iter/s, 4.48801s/10 iters), loss = 8.20222
I0523 01:56:16.891975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20222 (* 1 = 8.20222 loss)
I0523 01:56:16.957568 34819 sgd_solver.cpp:112] Iteration 29280, lr = 0.01
I0523 01:56:20.949035 34819 solver.cpp:239] Iteration 29290 (2.46495 iter/s, 4.05688s/10 iters), loss = 8.32711
I0523 01:56:20.949079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32711 (* 1 = 8.32711 loss)
I0523 01:56:21.009671 34819 sgd_solver.cpp:112] Iteration 29290, lr = 0.01
I0523 01:56:25.869436 34819 solver.cpp:239] Iteration 29300 (2.03246 iter/s, 4.92014s/10 iters), loss = 8.59721
I0523 01:56:25.869499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59721 (* 1 = 8.59721 loss)
I0523 01:56:25.926216 34819 sgd_solver.cpp:112] Iteration 29300, lr = 0.01
I0523 01:56:29.966282 34819 solver.cpp:239] Iteration 29310 (2.44105 iter/s, 4.09659s/10 iters), loss = 9.21232
I0523 01:56:29.966347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21232 (* 1 = 9.21232 loss)
I0523 01:56:30.039633 34819 sgd_solver.cpp:112] Iteration 29310, lr = 0.01
I0523 01:56:34.203889 34819 solver.cpp:239] Iteration 29320 (2.35995 iter/s, 4.23737s/10 iters), loss = 8.53921
I0523 01:56:34.203933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53921 (* 1 = 8.53921 loss)
I0523 01:56:34.280460 34819 sgd_solver.cpp:112] Iteration 29320, lr = 0.01
I0523 01:56:40.937865 34819 solver.cpp:239] Iteration 29330 (1.48508 iter/s, 6.73365s/10 iters), loss = 9.40968
I0523 01:56:40.938097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40968 (* 1 = 9.40968 loss)
I0523 01:56:41.012533 34819 sgd_solver.cpp:112] Iteration 29330, lr = 0.01
I0523 01:56:44.947798 34819 solver.cpp:239] Iteration 29340 (2.49405 iter/s, 4.00955s/10 iters), loss = 8.83991
I0523 01:56:44.947850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83991 (* 1 = 8.83991 loss)
I0523 01:56:45.010350 34819 sgd_solver.cpp:112] Iteration 29340, lr = 0.01
I0523 01:56:50.330143 34819 solver.cpp:239] Iteration 29350 (1.85803 iter/s, 5.38206s/10 iters), loss = 9.14478
I0523 01:56:50.330199 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14478 (* 1 = 9.14478 loss)
I0523 01:56:50.413007 34819 sgd_solver.cpp:112] Iteration 29350, lr = 0.01
I0523 01:56:55.912968 34819 solver.cpp:239] Iteration 29360 (1.7913 iter/s, 5.58253s/10 iters), loss = 8.82868
I0523 01:56:55.913017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82868 (* 1 = 8.82868 loss)
I0523 01:56:55.982410 34819 sgd_solver.cpp:112] Iteration 29360, lr = 0.01
I0523 01:57:02.042973 34819 solver.cpp:239] Iteration 29370 (1.6314 iter/s, 6.12969s/10 iters), loss = 9.60779
I0523 01:57:02.043028 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60779 (* 1 = 9.60779 loss)
I0523 01:57:02.896004 34819 sgd_solver.cpp:112] Iteration 29370, lr = 0.01
I0523 01:57:07.314507 34819 solver.cpp:239] Iteration 29380 (1.89709 iter/s, 5.27124s/10 iters), loss = 8.83051
I0523 01:57:07.314568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83051 (* 1 = 8.83051 loss)
I0523 01:57:08.132547 34819 sgd_solver.cpp:112] Iteration 29380, lr = 0.01
I0523 01:57:12.387434 34819 solver.cpp:239] Iteration 29390 (1.97135 iter/s, 5.07266s/10 iters), loss = 8.52948
I0523 01:57:12.387712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52948 (* 1 = 8.52948 loss)
I0523 01:57:12.450839 34819 sgd_solver.cpp:112] Iteration 29390, lr = 0.01
I0523 01:57:15.620366 34819 solver.cpp:239] Iteration 29400 (3.09354 iter/s, 3.23254s/10 iters), loss = 8.81507
I0523 01:57:15.620419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81507 (* 1 = 8.81507 loss)
I0523 01:57:15.676816 34819 sgd_solver.cpp:112] Iteration 29400, lr = 0.01
I0523 01:57:18.495729 34819 solver.cpp:239] Iteration 29410 (3.47805 iter/s, 2.87518s/10 iters), loss = 8.75438
I0523 01:57:18.495771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75438 (* 1 = 8.75438 loss)
I0523 01:57:19.258182 34819 sgd_solver.cpp:112] Iteration 29410, lr = 0.01
I0523 01:57:23.949182 34819 solver.cpp:239] Iteration 29420 (1.83379 iter/s, 5.45318s/10 iters), loss = 9.69643
I0523 01:57:23.949234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.69643 (* 1 = 9.69643 loss)
I0523 01:57:24.011734 34819 sgd_solver.cpp:112] Iteration 29420, lr = 0.01
I0523 01:57:27.487545 34819 solver.cpp:239] Iteration 29430 (2.82635 iter/s, 3.53814s/10 iters), loss = 9.39437
I0523 01:57:27.487598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39437 (* 1 = 9.39437 loss)
I0523 01:57:28.194659 34819 sgd_solver.cpp:112] Iteration 29430, lr = 0.01
I0523 01:57:31.697273 34819 solver.cpp:239] Iteration 29440 (2.37558 iter/s, 4.20949s/10 iters), loss = 8.64446
I0523 01:57:31.697345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64446 (* 1 = 8.64446 loss)
I0523 01:57:31.773536 34819 sgd_solver.cpp:112] Iteration 29440, lr = 0.01
I0523 01:57:37.369346 34819 solver.cpp:239] Iteration 29450 (1.76313 iter/s, 5.67174s/10 iters), loss = 9.04002
I0523 01:57:37.369415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04002 (* 1 = 9.04002 loss)
I0523 01:57:38.158267 34819 sgd_solver.cpp:112] Iteration 29450, lr = 0.01
I0523 01:57:43.733315 34819 solver.cpp:239] Iteration 29460 (1.57143 iter/s, 6.36363s/10 iters), loss = 9.25958
I0523 01:57:43.733525 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25958 (* 1 = 9.25958 loss)
I0523 01:57:43.804023 34819 sgd_solver.cpp:112] Iteration 29460, lr = 0.01
I0523 01:57:46.489233 34819 solver.cpp:239] Iteration 29470 (3.62896 iter/s, 2.75561s/10 iters), loss = 7.97443
I0523 01:57:46.489285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97443 (* 1 = 7.97443 loss)
I0523 01:57:46.561328 34819 sgd_solver.cpp:112] Iteration 29470, lr = 0.01
I0523 01:57:50.608412 34819 solver.cpp:239] Iteration 29480 (2.42781 iter/s, 4.11895s/10 iters), loss = 9.51011
I0523 01:57:50.608454 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51011 (* 1 = 9.51011 loss)
I0523 01:57:50.671346 34819 sgd_solver.cpp:112] Iteration 29480, lr = 0.01
I0523 01:57:54.988355 34819 solver.cpp:239] Iteration 29490 (2.28327 iter/s, 4.37969s/10 iters), loss = 9.10534
I0523 01:57:54.988417 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10534 (* 1 = 9.10534 loss)
I0523 01:57:55.882208 34819 sgd_solver.cpp:112] Iteration 29490, lr = 0.01
I0523 01:58:00.717885 34819 solver.cpp:239] Iteration 29500 (1.74543 iter/s, 5.72923s/10 iters), loss = 8.50782
I0523 01:58:00.717938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50782 (* 1 = 8.50782 loss)
I0523 01:58:00.767793 34819 sgd_solver.cpp:112] Iteration 29500, lr = 0.01
I0523 01:58:04.491082 34819 solver.cpp:239] Iteration 29510 (2.65042 iter/s, 3.77299s/10 iters), loss = 8.3172
I0523 01:58:04.491129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3172 (* 1 = 8.3172 loss)
I0523 01:58:04.557998 34819 sgd_solver.cpp:112] Iteration 29510, lr = 0.01
I0523 01:58:09.012665 34819 solver.cpp:239] Iteration 29520 (2.21173 iter/s, 4.52135s/10 iters), loss = 9.14734
I0523 01:58:09.012708 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14734 (* 1 = 9.14734 loss)
I0523 01:58:09.840951 34819 sgd_solver.cpp:112] Iteration 29520, lr = 0.01
I0523 01:58:13.643978 34819 solver.cpp:239] Iteration 29530 (2.15933 iter/s, 4.63107s/10 iters), loss = 9.01969
I0523 01:58:13.644031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01969 (* 1 = 9.01969 loss)
I0523 01:58:13.699396 34819 sgd_solver.cpp:112] Iteration 29530, lr = 0.01
I0523 01:58:19.471560 34819 solver.cpp:239] Iteration 29540 (1.71606 iter/s, 5.82729s/10 iters), loss = 8.67537
I0523 01:58:19.471763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67537 (* 1 = 8.67537 loss)
I0523 01:58:19.539168 34819 sgd_solver.cpp:112] Iteration 29540, lr = 0.01
I0523 01:58:25.792220 34819 solver.cpp:239] Iteration 29550 (1.58222 iter/s, 6.32021s/10 iters), loss = 8.71213
I0523 01:58:25.792279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71213 (* 1 = 8.71213 loss)
I0523 01:58:25.862987 34819 sgd_solver.cpp:112] Iteration 29550, lr = 0.01
I0523 01:58:28.959412 34819 solver.cpp:239] Iteration 29560 (3.15757 iter/s, 3.16699s/10 iters), loss = 9.19063
I0523 01:58:28.959470 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19063 (* 1 = 9.19063 loss)
I0523 01:58:29.790019 34819 sgd_solver.cpp:112] Iteration 29560, lr = 0.01
I0523 01:58:35.051558 34819 solver.cpp:239] Iteration 29570 (1.64154 iter/s, 6.09184s/10 iters), loss = 7.82976
I0523 01:58:35.051610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82976 (* 1 = 7.82976 loss)
I0523 01:58:35.123934 34819 sgd_solver.cpp:112] Iteration 29570, lr = 0.01
I0523 01:58:40.529867 34819 solver.cpp:239] Iteration 29580 (1.82548 iter/s, 5.47802s/10 iters), loss = 8.89693
I0523 01:58:40.529932 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89693 (* 1 = 8.89693 loss)
I0523 01:58:41.354013 34819 sgd_solver.cpp:112] Iteration 29580, lr = 0.01
I0523 01:58:45.147004 34819 solver.cpp:239] Iteration 29590 (2.16597 iter/s, 4.61688s/10 iters), loss = 8.58874
I0523 01:58:45.147053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58874 (* 1 = 8.58874 loss)
I0523 01:58:45.234133 34819 sgd_solver.cpp:112] Iteration 29590, lr = 0.01
I0523 01:58:49.643111 34819 solver.cpp:239] Iteration 29600 (2.22427 iter/s, 4.49585s/10 iters), loss = 9.66979
I0523 01:58:49.643316 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.66979 (* 1 = 9.66979 loss)
I0523 01:58:49.716437 34819 sgd_solver.cpp:112] Iteration 29600, lr = 0.01
I0523 01:58:52.966367 34819 solver.cpp:239] Iteration 29610 (3.00939 iter/s, 3.32294s/10 iters), loss = 9.25733
I0523 01:58:52.966413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25733 (* 1 = 9.25733 loss)
I0523 01:58:53.016379 34819 sgd_solver.cpp:112] Iteration 29610, lr = 0.01
I0523 01:58:56.347501 34819 solver.cpp:239] Iteration 29620 (2.95778 iter/s, 3.38091s/10 iters), loss = 8.76997
I0523 01:58:56.347551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76997 (* 1 = 8.76997 loss)
I0523 01:58:57.149580 34819 sgd_solver.cpp:112] Iteration 29620, lr = 0.01
I0523 01:59:00.573222 34819 solver.cpp:239] Iteration 29630 (2.36659 iter/s, 4.22549s/10 iters), loss = 8.52232
I0523 01:59:00.573264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52232 (* 1 = 8.52232 loss)
I0523 01:59:01.446094 34819 sgd_solver.cpp:112] Iteration 29630, lr = 0.01
I0523 01:59:06.972831 34819 solver.cpp:239] Iteration 29640 (1.56267 iter/s, 6.3993s/10 iters), loss = 9.05625
I0523 01:59:06.972877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05625 (* 1 = 9.05625 loss)
I0523 01:59:07.113462 34819 sgd_solver.cpp:112] Iteration 29640, lr = 0.01
I0523 01:59:13.473403 34819 solver.cpp:239] Iteration 29650 (1.5384 iter/s, 6.50026s/10 iters), loss = 9.11318
I0523 01:59:13.473445 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11318 (* 1 = 9.11318 loss)
I0523 01:59:13.539070 34819 sgd_solver.cpp:112] Iteration 29650, lr = 0.01
I0523 01:59:19.354105 34819 solver.cpp:239] Iteration 29660 (1.70056 iter/s, 5.88041s/10 iters), loss = 8.49791
I0523 01:59:19.354151 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49791 (* 1 = 8.49791 loss)
I0523 01:59:20.205062 34819 sgd_solver.cpp:112] Iteration 29660, lr = 0.01
I0523 01:59:23.892207 34819 solver.cpp:239] Iteration 29670 (2.20368 iter/s, 4.53787s/10 iters), loss = 8.37531
I0523 01:59:23.892252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37531 (* 1 = 8.37531 loss)
I0523 01:59:23.966859 34819 sgd_solver.cpp:112] Iteration 29670, lr = 0.01
I0523 01:59:27.874207 34819 solver.cpp:239] Iteration 29680 (2.51144 iter/s, 3.98179s/10 iters), loss = 8.63694
I0523 01:59:27.874248 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63694 (* 1 = 8.63694 loss)
I0523 01:59:27.971724 34819 sgd_solver.cpp:112] Iteration 29680, lr = 0.01
I0523 01:59:34.269204 34819 solver.cpp:239] Iteration 29690 (1.5638 iter/s, 6.39469s/10 iters), loss = 8.96893
I0523 01:59:34.269249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96893 (* 1 = 8.96893 loss)
I0523 01:59:34.326109 34819 sgd_solver.cpp:112] Iteration 29690, lr = 0.01
I0523 01:59:37.829694 34819 solver.cpp:239] Iteration 29700 (2.80877 iter/s, 3.56028s/10 iters), loss = 8.29731
I0523 01:59:37.829735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29731 (* 1 = 8.29731 loss)
I0523 01:59:38.406908 34819 sgd_solver.cpp:112] Iteration 29700, lr = 0.01
I0523 01:59:44.904352 34819 solver.cpp:239] Iteration 29710 (1.41356 iter/s, 7.07432s/10 iters), loss = 9.06812
I0523 01:59:44.904397 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06812 (* 1 = 9.06812 loss)
I0523 01:59:44.977671 34819 sgd_solver.cpp:112] Iteration 29710, lr = 0.01
I0523 01:59:50.676518 34819 solver.cpp:239] Iteration 29720 (1.73254 iter/s, 5.77188s/10 iters), loss = 9.44717
I0523 01:59:50.676733 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44717 (* 1 = 9.44717 loss)
I0523 01:59:50.754124 34819 sgd_solver.cpp:112] Iteration 29720, lr = 0.01
I0523 01:59:56.124863 34819 solver.cpp:239] Iteration 29730 (1.83556 iter/s, 5.44792s/10 iters), loss = 9.13599
I0523 01:59:56.124917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13599 (* 1 = 9.13599 loss)
I0523 01:59:56.932745 34819 sgd_solver.cpp:112] Iteration 29730, lr = 0.01
I0523 02:00:00.905400 34819 solver.cpp:239] Iteration 29740 (2.09193 iter/s, 4.78028s/10 iters), loss = 9.21846
I0523 02:00:00.905457 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21846 (* 1 = 9.21846 loss)
I0523 02:00:00.971122 34819 sgd_solver.cpp:112] Iteration 29740, lr = 0.01
I0523 02:00:05.089071 34819 solver.cpp:239] Iteration 29750 (2.39039 iter/s, 4.18342s/10 iters), loss = 9.08645
I0523 02:00:05.089126 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08645 (* 1 = 9.08645 loss)
I0523 02:00:05.156566 34819 sgd_solver.cpp:112] Iteration 29750, lr = 0.01
I0523 02:00:08.373986 34819 solver.cpp:239] Iteration 29760 (3.0444 iter/s, 3.28472s/10 iters), loss = 8.58704
I0523 02:00:08.374027 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58704 (* 1 = 8.58704 loss)
I0523 02:00:09.158613 34819 sgd_solver.cpp:112] Iteration 29760, lr = 0.01
I0523 02:00:11.693294 34819 solver.cpp:239] Iteration 29770 (3.01285 iter/s, 3.31911s/10 iters), loss = 8.68597
I0523 02:00:11.693344 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68597 (* 1 = 8.68597 loss)
I0523 02:00:12.343488 34819 sgd_solver.cpp:112] Iteration 29770, lr = 0.01
I0523 02:00:15.660456 34819 solver.cpp:239] Iteration 29780 (2.52083 iter/s, 3.96695s/10 iters), loss = 10.0648
I0523 02:00:15.660504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0648 (* 1 = 10.0648 loss)
I0523 02:00:15.735080 34819 sgd_solver.cpp:112] Iteration 29780, lr = 0.01
I0523 02:00:19.907151 34819 solver.cpp:239] Iteration 29790 (2.35491 iter/s, 4.24645s/10 iters), loss = 8.61439
I0523 02:00:19.907215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61439 (* 1 = 8.61439 loss)
I0523 02:00:19.984843 34819 sgd_solver.cpp:112] Iteration 29790, lr = 0.01
I0523 02:00:25.681391 34819 solver.cpp:239] Iteration 29800 (1.73192 iter/s, 5.77394s/10 iters), loss = 8.97198
I0523 02:00:25.681674 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97198 (* 1 = 8.97198 loss)
I0523 02:00:25.745348 34819 sgd_solver.cpp:112] Iteration 29800, lr = 0.01
I0523 02:00:29.670238 34819 solver.cpp:239] Iteration 29810 (2.50726 iter/s, 3.98842s/10 iters), loss = 8.06536
I0523 02:00:29.670301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06536 (* 1 = 8.06536 loss)
I0523 02:00:30.481035 34819 sgd_solver.cpp:112] Iteration 29810, lr = 0.01
I0523 02:00:34.478423 34819 solver.cpp:239] Iteration 29820 (2.07991 iter/s, 4.8079s/10 iters), loss = 8.63831
I0523 02:00:34.478478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63831 (* 1 = 8.63831 loss)
I0523 02:00:35.189602 34819 sgd_solver.cpp:112] Iteration 29820, lr = 0.01
I0523 02:00:40.696992 34819 solver.cpp:239] Iteration 29830 (1.60817 iter/s, 6.21825s/10 iters), loss = 8.75385
I0523 02:00:40.697037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75385 (* 1 = 8.75385 loss)
I0523 02:00:40.753711 34819 sgd_solver.cpp:112] Iteration 29830, lr = 0.01
I0523 02:00:46.606487 34819 solver.cpp:239] Iteration 29840 (1.69228 iter/s, 5.9092s/10 iters), loss = 8.97114
I0523 02:00:46.606546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97114 (* 1 = 8.97114 loss)
I0523 02:00:47.188421 34819 sgd_solver.cpp:112] Iteration 29840, lr = 0.01
I0523 02:00:52.544060 34819 solver.cpp:239] Iteration 29850 (1.68428 iter/s, 5.93726s/10 iters), loss = 9.03802
I0523 02:00:52.544102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03802 (* 1 = 9.03802 loss)
I0523 02:00:53.384557 34819 sgd_solver.cpp:112] Iteration 29850, lr = 0.01
I0523 02:00:56.561089 34819 solver.cpp:239] Iteration 29860 (2.48954 iter/s, 4.0168s/10 iters), loss = 8.79736
I0523 02:00:56.561219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79736 (* 1 = 8.79736 loss)
I0523 02:00:56.625102 34819 sgd_solver.cpp:112] Iteration 29860, lr = 0.01
I0523 02:01:00.970450 34819 solver.cpp:239] Iteration 29870 (2.26807 iter/s, 4.40904s/10 iters), loss = 8.27072
I0523 02:01:00.970504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27072 (* 1 = 8.27072 loss)
I0523 02:01:01.850908 34819 sgd_solver.cpp:112] Iteration 29870, lr = 0.01
I0523 02:01:05.847312 34819 solver.cpp:239] Iteration 29880 (2.05061 iter/s, 4.87661s/10 iters), loss = 9.32047
I0523 02:01:05.847364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32047 (* 1 = 9.32047 loss)
I0523 02:01:05.923266 34819 sgd_solver.cpp:112] Iteration 29880, lr = 0.01
I0523 02:01:09.341758 34819 solver.cpp:239] Iteration 29890 (2.86186 iter/s, 3.49423s/10 iters), loss = 8.66035
I0523 02:01:09.341817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66035 (* 1 = 8.66035 loss)
I0523 02:01:10.076218 34819 sgd_solver.cpp:112] Iteration 29890, lr = 0.01
I0523 02:01:14.310021 34819 solver.cpp:239] Iteration 29900 (2.01288 iter/s, 4.96799s/10 iters), loss = 8.8876
I0523 02:01:14.310065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8876 (* 1 = 8.8876 loss)
I0523 02:01:14.373332 34819 sgd_solver.cpp:112] Iteration 29900, lr = 0.01
I0523 02:01:19.411173 34819 solver.cpp:239] Iteration 29910 (1.96045 iter/s, 5.10088s/10 iters), loss = 8.80303
I0523 02:01:19.411228 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80303 (* 1 = 8.80303 loss)
I0523 02:01:19.469256 34819 sgd_solver.cpp:112] Iteration 29910, lr = 0.01
I0523 02:01:25.214689 34819 solver.cpp:239] Iteration 29920 (1.72318 iter/s, 5.80323s/10 iters), loss = 8.47626
I0523 02:01:25.214749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47626 (* 1 = 8.47626 loss)
I0523 02:01:26.020679 34819 sgd_solver.cpp:112] Iteration 29920, lr = 0.01
I0523 02:01:28.813948 34819 solver.cpp:239] Iteration 29930 (2.77852 iter/s, 3.59904s/10 iters), loss = 8.41318
I0523 02:01:28.814134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41318 (* 1 = 8.41318 loss)
I0523 02:01:28.886004 34819 sgd_solver.cpp:112] Iteration 29930, lr = 0.01
I0523 02:01:32.818140 34819 solver.cpp:239] Iteration 29940 (2.4976 iter/s, 4.00384s/10 iters), loss = 9.22097
I0523 02:01:32.818188 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22097 (* 1 = 9.22097 loss)
I0523 02:01:32.887197 34819 sgd_solver.cpp:112] Iteration 29940, lr = 0.01
I0523 02:01:37.317457 34819 solver.cpp:239] Iteration 29950 (2.22268 iter/s, 4.49907s/10 iters), loss = 8.9205
I0523 02:01:37.317513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9205 (* 1 = 8.9205 loss)
I0523 02:01:38.130244 34819 sgd_solver.cpp:112] Iteration 29950, lr = 0.01
I0523 02:01:41.352505 34819 solver.cpp:239] Iteration 29960 (2.47842 iter/s, 4.03482s/10 iters), loss = 9.303
I0523 02:01:41.352551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.303 (* 1 = 9.303 loss)
I0523 02:01:41.953261 34819 sgd_solver.cpp:112] Iteration 29960, lr = 0.01
I0523 02:01:46.921303 34819 solver.cpp:239] Iteration 29970 (1.79581 iter/s, 5.56852s/10 iters), loss = 8.91484
I0523 02:01:46.921358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91484 (* 1 = 8.91484 loss)
I0523 02:01:47.648278 34819 sgd_solver.cpp:112] Iteration 29970, lr = 0.01
I0523 02:01:52.429016 34819 solver.cpp:239] Iteration 29980 (1.81574 iter/s, 5.5074s/10 iters), loss = 7.7849
I0523 02:01:52.429075 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7849 (* 1 = 7.7849 loss)
I0523 02:01:52.484207 34819 sgd_solver.cpp:112] Iteration 29980, lr = 0.01
I0523 02:01:57.472059 34819 solver.cpp:239] Iteration 29990 (1.98304 iter/s, 5.04277s/10 iters), loss = 8.12507
I0523 02:01:57.472118 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12507 (* 1 = 8.12507 loss)
I0523 02:01:57.539371 34819 sgd_solver.cpp:112] Iteration 29990, lr = 0.01
I0523 02:02:01.587267 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_30000.caffemodel
I0523 02:02:04.005484 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_30000.solverstate
I0523 02:02:04.209575 34819 solver.cpp:239] Iteration 30000 (1.4843 iter/s, 6.73719s/10 iters), loss = 8.96869
I0523 02:02:04.209619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96869 (* 1 = 8.96869 loss)
I0523 02:02:04.276367 34819 sgd_solver.cpp:112] Iteration 30000, lr = 0.01
I0523 02:02:09.021427 34819 solver.cpp:239] Iteration 30010 (2.07832 iter/s, 4.81159s/10 iters), loss = 8.12562
I0523 02:02:09.021484 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12562 (* 1 = 8.12562 loss)
I0523 02:02:09.845261 34819 sgd_solver.cpp:112] Iteration 30010, lr = 0.01
I0523 02:02:14.723421 34819 solver.cpp:239] Iteration 30020 (1.75386 iter/s, 5.7017s/10 iters), loss = 9.74546
I0523 02:02:14.723472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74546 (* 1 = 9.74546 loss)
I0523 02:02:14.780120 34819 sgd_solver.cpp:112] Iteration 30020, lr = 0.01
I0523 02:02:20.316215 34819 solver.cpp:239] Iteration 30030 (1.78811 iter/s, 5.59251s/10 iters), loss = 8.92964
I0523 02:02:20.316265 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92964 (* 1 = 8.92964 loss)
I0523 02:02:20.389010 34819 sgd_solver.cpp:112] Iteration 30030, lr = 0.01
I0523 02:02:24.787264 34819 solver.cpp:239] Iteration 30040 (2.23674 iter/s, 4.4708s/10 iters), loss = 8.82174
I0523 02:02:24.787317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82174 (* 1 = 8.82174 loss)
I0523 02:02:24.856127 34819 sgd_solver.cpp:112] Iteration 30040, lr = 0.01
I0523 02:02:29.758141 34819 solver.cpp:239] Iteration 30050 (2.01183 iter/s, 4.97061s/10 iters), loss = 7.84525
I0523 02:02:29.758193 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84525 (* 1 = 7.84525 loss)
I0523 02:02:29.831665 34819 sgd_solver.cpp:112] Iteration 30050, lr = 0.01
I0523 02:02:33.948107 34819 solver.cpp:239] Iteration 30060 (2.38679 iter/s, 4.18972s/10 iters), loss = 9.15015
I0523 02:02:33.948339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15015 (* 1 = 9.15015 loss)
I0523 02:02:34.011438 34819 sgd_solver.cpp:112] Iteration 30060, lr = 0.01
I0523 02:02:38.160730 34819 solver.cpp:239] Iteration 30070 (2.37405 iter/s, 4.21222s/10 iters), loss = 8.79003
I0523 02:02:38.160801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79003 (* 1 = 8.79003 loss)
I0523 02:02:38.706328 34819 sgd_solver.cpp:112] Iteration 30070, lr = 0.01
I0523 02:02:42.047632 34819 solver.cpp:239] Iteration 30080 (2.57291 iter/s, 3.88665s/10 iters), loss = 8.80499
I0523 02:02:42.047688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80499 (* 1 = 8.80499 loss)
I0523 02:02:42.877157 34819 sgd_solver.cpp:112] Iteration 30080, lr = 0.01
I0523 02:02:46.934226 34819 solver.cpp:239] Iteration 30090 (2.04653 iter/s, 4.88632s/10 iters), loss = 9.30326
I0523 02:02:46.934288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30326 (* 1 = 9.30326 loss)
I0523 02:02:46.989308 34819 sgd_solver.cpp:112] Iteration 30090, lr = 0.01
I0523 02:02:51.182469 34819 solver.cpp:239] Iteration 30100 (2.35404 iter/s, 4.24801s/10 iters), loss = 10.0424
I0523 02:02:51.182516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0424 (* 1 = 10.0424 loss)
I0523 02:02:51.258622 34819 sgd_solver.cpp:112] Iteration 30100, lr = 0.01
I0523 02:02:55.721041 34819 solver.cpp:239] Iteration 30110 (2.20345 iter/s, 4.53833s/10 iters), loss = 7.9495
I0523 02:02:55.721082 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9495 (* 1 = 7.9495 loss)
I0523 02:02:55.797475 34819 sgd_solver.cpp:112] Iteration 30110, lr = 0.01
I0523 02:02:59.172271 34819 solver.cpp:239] Iteration 30120 (2.89769 iter/s, 3.45102s/10 iters), loss = 9.17115
I0523 02:02:59.172320 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17115 (* 1 = 9.17115 loss)
I0523 02:02:59.822160 34819 sgd_solver.cpp:112] Iteration 30120, lr = 0.01
I0523 02:03:05.541043 34819 solver.cpp:239] Iteration 30130 (1.57024 iter/s, 6.36846s/10 iters), loss = 9.20239
I0523 02:03:05.541172 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20239 (* 1 = 9.20239 loss)
I0523 02:03:05.817770 34819 sgd_solver.cpp:112] Iteration 30130, lr = 0.01
I0523 02:03:11.617364 34819 solver.cpp:239] Iteration 30140 (1.64584 iter/s, 6.07593s/10 iters), loss = 8.66822
I0523 02:03:11.617432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66822 (* 1 = 8.66822 loss)
I0523 02:03:12.412832 34819 sgd_solver.cpp:112] Iteration 30140, lr = 0.01
I0523 02:03:17.548629 34819 solver.cpp:239] Iteration 30150 (1.68607 iter/s, 5.93095s/10 iters), loss = 8.68673
I0523 02:03:17.548679 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68673 (* 1 = 8.68673 loss)
I0523 02:03:17.612584 34819 sgd_solver.cpp:112] Iteration 30150, lr = 0.01
I0523 02:03:22.646643 34819 solver.cpp:239] Iteration 30160 (1.96165 iter/s, 5.09775s/10 iters), loss = 8.40184
I0523 02:03:22.646687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40184 (* 1 = 8.40184 loss)
I0523 02:03:22.729694 34819 sgd_solver.cpp:112] Iteration 30160, lr = 0.01
I0523 02:03:29.322140 34819 solver.cpp:239] Iteration 30170 (1.49809 iter/s, 6.67518s/10 iters), loss = 9.01167
I0523 02:03:29.322182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01167 (* 1 = 9.01167 loss)
I0523 02:03:29.398246 34819 sgd_solver.cpp:112] Iteration 30170, lr = 0.01
I0523 02:03:31.964237 34819 solver.cpp:239] Iteration 30180 (3.78512 iter/s, 2.64193s/10 iters), loss = 9.17425
I0523 02:03:31.964289 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17425 (* 1 = 9.17425 loss)
I0523 02:03:32.032794 34819 sgd_solver.cpp:112] Iteration 30180, lr = 0.01
I0523 02:03:35.851811 34819 solver.cpp:239] Iteration 30190 (2.57245 iter/s, 3.88735s/10 iters), loss = 8.88954
I0523 02:03:35.851964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88954 (* 1 = 8.88954 loss)
I0523 02:03:35.911232 34819 sgd_solver.cpp:112] Iteration 30190, lr = 0.01
I0523 02:03:40.386461 34819 solver.cpp:239] Iteration 30200 (2.20541 iter/s, 4.53431s/10 iters), loss = 9.64617
I0523 02:03:40.386504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64617 (* 1 = 9.64617 loss)
I0523 02:03:40.445886 34819 sgd_solver.cpp:112] Iteration 30200, lr = 0.01
I0523 02:03:45.146322 34819 solver.cpp:239] Iteration 30210 (2.10101 iter/s, 4.75961s/10 iters), loss = 8.98657
I0523 02:03:45.146363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98657 (* 1 = 8.98657 loss)
I0523 02:03:45.226881 34819 sgd_solver.cpp:112] Iteration 30210, lr = 0.01
I0523 02:03:49.698964 34819 solver.cpp:239] Iteration 30220 (2.19665 iter/s, 4.55239s/10 iters), loss = 8.36884
I0523 02:03:49.699012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36884 (* 1 = 8.36884 loss)
I0523 02:03:50.356672 34819 sgd_solver.cpp:112] Iteration 30220, lr = 0.01
I0523 02:03:55.318296 34819 solver.cpp:239] Iteration 30230 (1.77966 iter/s, 5.61904s/10 iters), loss = 9.72631
I0523 02:03:55.318351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72631 (* 1 = 9.72631 loss)
I0523 02:03:55.389091 34819 sgd_solver.cpp:112] Iteration 30230, lr = 0.01
I0523 02:03:59.372890 34819 solver.cpp:239] Iteration 30240 (2.46647 iter/s, 4.05437s/10 iters), loss = 9.50343
I0523 02:03:59.372937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50343 (* 1 = 9.50343 loss)
I0523 02:03:59.443904 34819 sgd_solver.cpp:112] Iteration 30240, lr = 0.01
I0523 02:04:04.206238 34819 solver.cpp:239] Iteration 30250 (2.06907 iter/s, 4.83308s/10 iters), loss = 8.84027
I0523 02:04:04.206302 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84027 (* 1 = 8.84027 loss)
I0523 02:04:04.263659 34819 sgd_solver.cpp:112] Iteration 30250, lr = 0.01
I0523 02:04:10.650797 34819 solver.cpp:239] Iteration 30260 (1.55178 iter/s, 6.44423s/10 iters), loss = 8.69526
I0523 02:04:10.650928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69526 (* 1 = 8.69526 loss)
I0523 02:04:10.708995 34819 sgd_solver.cpp:112] Iteration 30260, lr = 0.01
I0523 02:04:14.390013 34819 solver.cpp:239] Iteration 30270 (2.67458 iter/s, 3.73891s/10 iters), loss = 8.86803
I0523 02:04:14.390075 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86803 (* 1 = 8.86803 loss)
I0523 02:04:15.178995 34819 sgd_solver.cpp:112] Iteration 30270, lr = 0.01
I0523 02:04:17.735373 34819 solver.cpp:239] Iteration 30280 (2.98942 iter/s, 3.34513s/10 iters), loss = 8.43427
I0523 02:04:17.735431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43427 (* 1 = 8.43427 loss)
I0523 02:04:17.803239 34819 sgd_solver.cpp:112] Iteration 30280, lr = 0.01
I0523 02:04:23.253911 34819 solver.cpp:239] Iteration 30290 (1.81217 iter/s, 5.51824s/10 iters), loss = 9.29521
I0523 02:04:23.253958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29521 (* 1 = 9.29521 loss)
I0523 02:04:23.322176 34819 sgd_solver.cpp:112] Iteration 30290, lr = 0.01
I0523 02:04:28.365748 34819 solver.cpp:239] Iteration 30300 (1.95635 iter/s, 5.11156s/10 iters), loss = 8.81348
I0523 02:04:28.365803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81348 (* 1 = 8.81348 loss)
I0523 02:04:29.226716 34819 sgd_solver.cpp:112] Iteration 30300, lr = 0.01
I0523 02:04:32.791061 34819 solver.cpp:239] Iteration 30310 (2.25985 iter/s, 4.42507s/10 iters), loss = 8.46214
I0523 02:04:32.791112 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46214 (* 1 = 8.46214 loss)
I0523 02:04:32.861835 34819 sgd_solver.cpp:112] Iteration 30310, lr = 0.01
I0523 02:04:39.682430 34819 solver.cpp:239] Iteration 30320 (1.45116 iter/s, 6.89103s/10 iters), loss = 9.28225
I0523 02:04:39.682472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28225 (* 1 = 9.28225 loss)
I0523 02:04:39.739343 34819 sgd_solver.cpp:112] Iteration 30320, lr = 0.01
I0523 02:04:43.897024 34819 solver.cpp:239] Iteration 30330 (2.37284 iter/s, 4.21436s/10 iters), loss = 8.91664
I0523 02:04:43.897213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91664 (* 1 = 8.91664 loss)
I0523 02:04:44.719336 34819 sgd_solver.cpp:112] Iteration 30330, lr = 0.01
I0523 02:04:48.753899 34819 solver.cpp:239] Iteration 30340 (2.05911 iter/s, 4.85646s/10 iters), loss = 8.51627
I0523 02:04:48.753957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51627 (* 1 = 8.51627 loss)
I0523 02:04:49.526273 34819 sgd_solver.cpp:112] Iteration 30340, lr = 0.01
I0523 02:04:52.778065 34819 solver.cpp:239] Iteration 30350 (2.48513 iter/s, 4.02394s/10 iters), loss = 8.18783
I0523 02:04:52.778117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18783 (* 1 = 8.18783 loss)
I0523 02:04:52.842392 34819 sgd_solver.cpp:112] Iteration 30350, lr = 0.01
I0523 02:04:58.314556 34819 solver.cpp:239] Iteration 30360 (1.80629 iter/s, 5.5362s/10 iters), loss = 8.72778
I0523 02:04:58.314610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72778 (* 1 = 8.72778 loss)
I0523 02:04:58.388262 34819 sgd_solver.cpp:112] Iteration 30360, lr = 0.01
I0523 02:05:03.493042 34819 solver.cpp:239] Iteration 30370 (1.93117 iter/s, 5.17821s/10 iters), loss = 8.41773
I0523 02:05:03.493103 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41773 (* 1 = 8.41773 loss)
I0523 02:05:03.562803 34819 sgd_solver.cpp:112] Iteration 30370, lr = 0.01
I0523 02:05:07.124608 34819 solver.cpp:239] Iteration 30380 (2.7538 iter/s, 3.63135s/10 iters), loss = 9.23292
I0523 02:05:07.124665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23292 (* 1 = 9.23292 loss)
I0523 02:05:07.201362 34819 sgd_solver.cpp:112] Iteration 30380, lr = 0.01
I0523 02:05:12.963529 34819 solver.cpp:239] Iteration 30390 (1.71273 iter/s, 5.83862s/10 iters), loss = 7.36358
I0523 02:05:12.963596 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36358 (* 1 = 7.36358 loss)
I0523 02:05:13.744827 34819 sgd_solver.cpp:112] Iteration 30390, lr = 0.01
I0523 02:05:17.555382 34819 solver.cpp:239] Iteration 30400 (2.1779 iter/s, 4.59159s/10 iters), loss = 8.29057
I0523 02:05:17.555565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29057 (* 1 = 8.29057 loss)
I0523 02:05:17.619756 34819 sgd_solver.cpp:112] Iteration 30400, lr = 0.01
I0523 02:05:22.536691 34819 solver.cpp:239] Iteration 30410 (2.00766 iter/s, 4.98093s/10 iters), loss = 8.27104
I0523 02:05:22.536768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27104 (* 1 = 8.27104 loss)
I0523 02:05:22.705058 34819 sgd_solver.cpp:112] Iteration 30410, lr = 0.01
I0523 02:05:26.655102 34819 solver.cpp:239] Iteration 30420 (2.42827 iter/s, 4.11815s/10 iters), loss = 8.66914
I0523 02:05:26.655166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66914 (* 1 = 8.66914 loss)
I0523 02:05:26.732795 34819 sgd_solver.cpp:112] Iteration 30420, lr = 0.01
I0523 02:05:34.041296 34819 solver.cpp:239] Iteration 30430 (1.35394 iter/s, 7.38584s/10 iters), loss = 9.50048
I0523 02:05:34.041342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50048 (* 1 = 9.50048 loss)
I0523 02:05:34.894846 34819 sgd_solver.cpp:112] Iteration 30430, lr = 0.01
I0523 02:05:38.955746 34819 solver.cpp:239] Iteration 30440 (2.03493 iter/s, 4.91419s/10 iters), loss = 9.08284
I0523 02:05:38.955797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08284 (* 1 = 9.08284 loss)
I0523 02:05:39.759001 34819 sgd_solver.cpp:112] Iteration 30440, lr = 0.01
I0523 02:05:43.160884 34819 solver.cpp:239] Iteration 30450 (2.37817 iter/s, 4.20491s/10 iters), loss = 9.08895
I0523 02:05:43.160936 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08895 (* 1 = 9.08895 loss)
I0523 02:05:43.229918 34819 sgd_solver.cpp:112] Iteration 30450, lr = 0.01
I0523 02:05:48.814671 34819 solver.cpp:239] Iteration 30460 (1.76882 iter/s, 5.6535s/10 iters), loss = 9.0945
I0523 02:05:48.814867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0945 (* 1 = 9.0945 loss)
I0523 02:05:48.891109 34819 sgd_solver.cpp:112] Iteration 30460, lr = 0.01
I0523 02:05:52.781589 34819 solver.cpp:239] Iteration 30470 (2.52108 iter/s, 3.96656s/10 iters), loss = 8.67671
I0523 02:05:52.781642 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67671 (* 1 = 8.67671 loss)
I0523 02:05:52.854128 34819 sgd_solver.cpp:112] Iteration 30470, lr = 0.01
I0523 02:05:59.238567 34819 solver.cpp:239] Iteration 30480 (1.54879 iter/s, 6.45667s/10 iters), loss = 8.85066
I0523 02:05:59.238607 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85066 (* 1 = 8.85066 loss)
I0523 02:06:00.086871 34819 sgd_solver.cpp:112] Iteration 30480, lr = 0.01
I0523 02:06:03.292485 34819 solver.cpp:239] Iteration 30490 (2.46688 iter/s, 4.0537s/10 iters), loss = 8.2436
I0523 02:06:03.292539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2436 (* 1 = 8.2436 loss)
I0523 02:06:03.353972 34819 sgd_solver.cpp:112] Iteration 30490, lr = 0.01
I0523 02:06:08.051759 34819 solver.cpp:239] Iteration 30500 (2.10128 iter/s, 4.75901s/10 iters), loss = 8.2842
I0523 02:06:08.051811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2842 (* 1 = 8.2842 loss)
I0523 02:06:08.821949 34819 sgd_solver.cpp:112] Iteration 30500, lr = 0.01
I0523 02:06:11.851181 34819 solver.cpp:239] Iteration 30510 (2.63213 iter/s, 3.7992s/10 iters), loss = 8.65922
I0523 02:06:11.851235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65922 (* 1 = 8.65922 loss)
I0523 02:06:12.749611 34819 sgd_solver.cpp:112] Iteration 30510, lr = 0.01
I0523 02:06:18.395798 34819 solver.cpp:239] Iteration 30520 (1.52805 iter/s, 6.54429s/10 iters), loss = 9.04223
I0523 02:06:18.395849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04223 (* 1 = 9.04223 loss)
I0523 02:06:18.469216 34819 sgd_solver.cpp:112] Iteration 30520, lr = 0.01
I0523 02:06:24.532404 34819 solver.cpp:239] Iteration 30530 (1.62965 iter/s, 6.13629s/10 iters), loss = 9.24626
I0523 02:06:24.532552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24626 (* 1 = 9.24626 loss)
I0523 02:06:24.598208 34819 sgd_solver.cpp:112] Iteration 30530, lr = 0.01
I0523 02:06:27.884325 34819 solver.cpp:239] Iteration 30540 (2.98362 iter/s, 3.35163s/10 iters), loss = 9.33808
I0523 02:06:27.884372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33808 (* 1 = 9.33808 loss)
I0523 02:06:27.951484 34819 sgd_solver.cpp:112] Iteration 30540, lr = 0.01
I0523 02:06:34.311235 34819 solver.cpp:239] Iteration 30550 (1.55604 iter/s, 6.42659s/10 iters), loss = 7.95889
I0523 02:06:34.311290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95889 (* 1 = 7.95889 loss)
I0523 02:06:34.391707 34819 sgd_solver.cpp:112] Iteration 30550, lr = 0.01
I0523 02:06:38.697129 34819 solver.cpp:239] Iteration 30560 (2.28017 iter/s, 4.38564s/10 iters), loss = 8.14395
I0523 02:06:38.697182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14395 (* 1 = 8.14395 loss)
I0523 02:06:38.751430 34819 sgd_solver.cpp:112] Iteration 30560, lr = 0.01
I0523 02:06:44.126956 34819 solver.cpp:239] Iteration 30570 (1.84178 iter/s, 5.42954s/10 iters), loss = 8.72751
I0523 02:06:44.127005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72751 (* 1 = 8.72751 loss)
I0523 02:06:44.838323 34819 sgd_solver.cpp:112] Iteration 30570, lr = 0.01
I0523 02:06:48.141867 34819 solver.cpp:239] Iteration 30580 (2.49086 iter/s, 4.01468s/10 iters), loss = 8.47299
I0523 02:06:48.141919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47299 (* 1 = 8.47299 loss)
I0523 02:06:48.937273 34819 sgd_solver.cpp:112] Iteration 30580, lr = 0.01
I0523 02:06:53.116658 34819 solver.cpp:239] Iteration 30590 (2.01025 iter/s, 4.97452s/10 iters), loss = 8.87725
I0523 02:06:53.116711 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87725 (* 1 = 8.87725 loss)
I0523 02:06:53.827975 34819 sgd_solver.cpp:112] Iteration 30590, lr = 0.01
I0523 02:06:57.306648 34819 solver.cpp:239] Iteration 30600 (2.38678 iter/s, 4.18974s/10 iters), loss = 9.01859
I0523 02:06:57.306890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01859 (* 1 = 9.01859 loss)
I0523 02:06:58.047353 34819 sgd_solver.cpp:112] Iteration 30600, lr = 0.01
I0523 02:07:01.362864 34819 solver.cpp:239] Iteration 30610 (2.46559 iter/s, 4.05582s/10 iters), loss = 8.76797
I0523 02:07:01.362917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76797 (* 1 = 8.76797 loss)
I0523 02:07:02.203131 34819 sgd_solver.cpp:112] Iteration 30610, lr = 0.01
I0523 02:07:07.493057 34819 solver.cpp:239] Iteration 30620 (1.63135 iter/s, 6.12989s/10 iters), loss = 9.47943
I0523 02:07:07.493113 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47943 (* 1 = 9.47943 loss)
I0523 02:07:07.579193 34819 sgd_solver.cpp:112] Iteration 30620, lr = 0.01
I0523 02:07:12.428421 34819 solver.cpp:239] Iteration 30630 (2.0263 iter/s, 4.9351s/10 iters), loss = 9.33928
I0523 02:07:12.428473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33928 (* 1 = 9.33928 loss)
I0523 02:07:12.847705 34819 sgd_solver.cpp:112] Iteration 30630, lr = 0.01
I0523 02:07:16.855861 34819 solver.cpp:239] Iteration 30640 (2.25877 iter/s, 4.42718s/10 iters), loss = 8.7768
I0523 02:07:16.855921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7768 (* 1 = 8.7768 loss)
I0523 02:07:17.640564 34819 sgd_solver.cpp:112] Iteration 30640, lr = 0.01
I0523 02:07:20.880343 34819 solver.cpp:239] Iteration 30650 (2.48493 iter/s, 4.02425s/10 iters), loss = 9.07201
I0523 02:07:20.880388 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07201 (* 1 = 9.07201 loss)
I0523 02:07:21.676746 34819 sgd_solver.cpp:112] Iteration 30650, lr = 0.01
I0523 02:07:27.875578 34819 solver.cpp:239] Iteration 30660 (1.42961 iter/s, 6.99491s/10 iters), loss = 8.77529
I0523 02:07:27.875710 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77529 (* 1 = 8.77529 loss)
I0523 02:07:28.625124 34819 sgd_solver.cpp:112] Iteration 30660, lr = 0.01
I0523 02:07:33.629861 34819 solver.cpp:239] Iteration 30670 (1.73795 iter/s, 5.75392s/10 iters), loss = 8.57505
I0523 02:07:33.629905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57505 (* 1 = 8.57505 loss)
I0523 02:07:33.688772 34819 sgd_solver.cpp:112] Iteration 30670, lr = 0.01
I0523 02:07:35.718081 34819 solver.cpp:239] Iteration 30680 (4.7891 iter/s, 2.08808s/10 iters), loss = 9.15203
I0523 02:07:35.718137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15203 (* 1 = 9.15203 loss)
I0523 02:07:36.560180 34819 sgd_solver.cpp:112] Iteration 30680, lr = 0.01
I0523 02:07:40.205067 34819 solver.cpp:239] Iteration 30690 (2.22879 iter/s, 4.48674s/10 iters), loss = 9.06844
I0523 02:07:40.205128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06844 (* 1 = 9.06844 loss)
I0523 02:07:40.276938 34819 sgd_solver.cpp:112] Iteration 30690, lr = 0.01
I0523 02:07:44.429049 34819 solver.cpp:239] Iteration 30700 (2.36757 iter/s, 4.22375s/10 iters), loss = 8.7673
I0523 02:07:44.429092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7673 (* 1 = 8.7673 loss)
I0523 02:07:44.488296 34819 sgd_solver.cpp:112] Iteration 30700, lr = 0.01
I0523 02:07:49.382547 34819 solver.cpp:239] Iteration 30710 (2.01979 iter/s, 4.95102s/10 iters), loss = 9.12452
I0523 02:07:49.382589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12452 (* 1 = 9.12452 loss)
I0523 02:07:49.445082 34819 sgd_solver.cpp:112] Iteration 30710, lr = 0.01
I0523 02:07:55.565834 34819 solver.cpp:239] Iteration 30720 (1.61734 iter/s, 6.183s/10 iters), loss = 8.837
I0523 02:07:55.565876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.837 (* 1 = 8.837 loss)
I0523 02:07:56.386391 34819 sgd_solver.cpp:112] Iteration 30720, lr = 0.01
I0523 02:08:01.162572 34819 solver.cpp:239] Iteration 30730 (1.78685 iter/s, 5.59645s/10 iters), loss = 9.24938
I0523 02:08:01.162822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24938 (* 1 = 9.24938 loss)
I0523 02:08:01.238023 34819 sgd_solver.cpp:112] Iteration 30730, lr = 0.01
I0523 02:08:03.996754 34819 solver.cpp:239] Iteration 30740 (3.52879 iter/s, 2.83383s/10 iters), loss = 8.09061
I0523 02:08:03.996801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09061 (* 1 = 8.09061 loss)
I0523 02:08:04.806957 34819 sgd_solver.cpp:112] Iteration 30740, lr = 0.01
I0523 02:08:09.227413 34819 solver.cpp:239] Iteration 30750 (1.9119 iter/s, 5.2304s/10 iters), loss = 8.11103
I0523 02:08:09.227458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11103 (* 1 = 8.11103 loss)
I0523 02:08:10.093031 34819 sgd_solver.cpp:112] Iteration 30750, lr = 0.01
I0523 02:08:15.481655 34819 solver.cpp:239] Iteration 30760 (1.59899 iter/s, 6.25393s/10 iters), loss = 8.40083
I0523 02:08:15.481699 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40083 (* 1 = 8.40083 loss)
I0523 02:08:16.252048 34819 sgd_solver.cpp:112] Iteration 30760, lr = 0.01
I0523 02:08:21.424494 34819 solver.cpp:239] Iteration 30770 (1.68278 iter/s, 5.94253s/10 iters), loss = 9.61818
I0523 02:08:21.424559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61818 (* 1 = 9.61818 loss)
I0523 02:08:22.234721 34819 sgd_solver.cpp:112] Iteration 30770, lr = 0.01
I0523 02:08:27.520566 34819 solver.cpp:239] Iteration 30780 (1.64048 iter/s, 6.09576s/10 iters), loss = 8.46056
I0523 02:08:27.520617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46056 (* 1 = 8.46056 loss)
I0523 02:08:27.582748 34819 sgd_solver.cpp:112] Iteration 30780, lr = 0.01
I0523 02:08:32.546598 34819 solver.cpp:239] Iteration 30790 (1.98974 iter/s, 5.02578s/10 iters), loss = 8.81689
I0523 02:08:32.546844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81689 (* 1 = 8.81689 loss)
I0523 02:08:33.396518 34819 sgd_solver.cpp:112] Iteration 30790, lr = 0.01
I0523 02:08:36.657289 34819 solver.cpp:239] Iteration 30800 (2.4329 iter/s, 4.11033s/10 iters), loss = 8.27223
I0523 02:08:36.657338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27223 (* 1 = 8.27223 loss)
I0523 02:08:36.723155 34819 sgd_solver.cpp:112] Iteration 30800, lr = 0.01
I0523 02:08:42.032428 34819 solver.cpp:239] Iteration 30810 (1.86051 iter/s, 5.37486s/10 iters), loss = 8.98149
I0523 02:08:42.032472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98149 (* 1 = 8.98149 loss)
I0523 02:08:42.120513 34819 sgd_solver.cpp:112] Iteration 30810, lr = 0.01
I0523 02:08:46.384693 34819 solver.cpp:239] Iteration 30820 (2.29778 iter/s, 4.35203s/10 iters), loss = 8.5344
I0523 02:08:46.384748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5344 (* 1 = 8.5344 loss)
I0523 02:08:46.458236 34819 sgd_solver.cpp:112] Iteration 30820, lr = 0.01
I0523 02:08:51.382691 34819 solver.cpp:239] Iteration 30830 (2.0009 iter/s, 4.99774s/10 iters), loss = 8.21017
I0523 02:08:51.382753 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21017 (* 1 = 8.21017 loss)
I0523 02:08:51.439070 34819 sgd_solver.cpp:112] Iteration 30830, lr = 0.01
I0523 02:08:57.694558 34819 solver.cpp:239] Iteration 30840 (1.5844 iter/s, 6.31154s/10 iters), loss = 9.22516
I0523 02:08:57.694599 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22516 (* 1 = 9.22516 loss)
I0523 02:08:57.767889 34819 sgd_solver.cpp:112] Iteration 30840, lr = 0.01
I0523 02:09:00.352917 34819 solver.cpp:239] Iteration 30850 (3.76196 iter/s, 2.65819s/10 iters), loss = 8.97979
I0523 02:09:00.352977 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97979 (* 1 = 8.97979 loss)
I0523 02:09:01.165163 34819 sgd_solver.cpp:112] Iteration 30850, lr = 0.01
I0523 02:09:04.352653 34819 solver.cpp:239] Iteration 30860 (2.50031 iter/s, 3.99951s/10 iters), loss = 9.46866
I0523 02:09:04.352761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46866 (* 1 = 9.46866 loss)
I0523 02:09:04.420058 34819 sgd_solver.cpp:112] Iteration 30860, lr = 0.01
I0523 02:09:08.773212 34819 solver.cpp:239] Iteration 30870 (2.26231 iter/s, 4.42027s/10 iters), loss = 8.56317
I0523 02:09:08.773254 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56317 (* 1 = 8.56317 loss)
I0523 02:09:09.597503 34819 sgd_solver.cpp:112] Iteration 30870, lr = 0.01
I0523 02:09:13.106518 34819 solver.cpp:239] Iteration 30880 (2.30783 iter/s, 4.33308s/10 iters), loss = 8.28534
I0523 02:09:13.106560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28534 (* 1 = 8.28534 loss)
I0523 02:09:13.171679 34819 sgd_solver.cpp:112] Iteration 30880, lr = 0.01
I0523 02:09:17.992341 34819 solver.cpp:239] Iteration 30890 (2.04685 iter/s, 4.88557s/10 iters), loss = 9.54136
I0523 02:09:17.992385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54136 (* 1 = 9.54136 loss)
I0523 02:09:18.061761 34819 sgd_solver.cpp:112] Iteration 30890, lr = 0.01
I0523 02:09:23.393309 34819 solver.cpp:239] Iteration 30900 (1.85312 iter/s, 5.39632s/10 iters), loss = 8.94077
I0523 02:09:23.393362 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94077 (* 1 = 8.94077 loss)
I0523 02:09:24.224018 34819 sgd_solver.cpp:112] Iteration 30900, lr = 0.01
I0523 02:09:30.434118 34819 solver.cpp:239] Iteration 30910 (1.42036 iter/s, 7.04045s/10 iters), loss = 8.72584
I0523 02:09:30.434196 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72584 (* 1 = 8.72584 loss)
I0523 02:09:31.308939 34819 sgd_solver.cpp:112] Iteration 30910, lr = 0.01
I0523 02:09:35.532914 34819 solver.cpp:239] Iteration 30920 (1.96136 iter/s, 5.09851s/10 iters), loss = 8.52069
I0523 02:09:35.533071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52069 (* 1 = 8.52069 loss)
I0523 02:09:35.603612 34819 sgd_solver.cpp:112] Iteration 30920, lr = 0.01
I0523 02:09:40.571065 34819 solver.cpp:239] Iteration 30930 (1.985 iter/s, 5.03779s/10 iters), loss = 8.7872
I0523 02:09:40.571115 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7872 (* 1 = 8.7872 loss)
I0523 02:09:41.314656 34819 sgd_solver.cpp:112] Iteration 30930, lr = 0.01
I0523 02:09:46.050593 34819 solver.cpp:239] Iteration 30940 (1.82507 iter/s, 5.47924s/10 iters), loss = 7.98701
I0523 02:09:46.050655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98701 (* 1 = 7.98701 loss)
I0523 02:09:46.125422 34819 sgd_solver.cpp:112] Iteration 30940, lr = 0.01
I0523 02:09:50.938103 34819 solver.cpp:239] Iteration 30950 (2.04615 iter/s, 4.88723s/10 iters), loss = 8.801
I0523 02:09:50.938163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.801 (* 1 = 8.801 loss)
I0523 02:09:51.011785 34819 sgd_solver.cpp:112] Iteration 30950, lr = 0.01
I0523 02:09:55.891582 34819 solver.cpp:239] Iteration 30960 (2.01889 iter/s, 4.95321s/10 iters), loss = 9.23124
I0523 02:09:55.891641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23124 (* 1 = 9.23124 loss)
I0523 02:09:56.683939 34819 sgd_solver.cpp:112] Iteration 30960, lr = 0.01
I0523 02:09:59.878075 34819 solver.cpp:239] Iteration 30970 (2.50862 iter/s, 3.98626s/10 iters), loss = 8.63144
I0523 02:09:59.878132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63144 (* 1 = 8.63144 loss)
I0523 02:10:00.646577 34819 sgd_solver.cpp:112] Iteration 30970, lr = 0.01
I0523 02:10:05.467651 34819 solver.cpp:239] Iteration 30980 (1.78914 iter/s, 5.58929s/10 iters), loss = 8.19954
I0523 02:10:05.467705 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19954 (* 1 = 8.19954 loss)
I0523 02:10:05.646219 34819 sgd_solver.cpp:112] Iteration 30980, lr = 0.01
I0523 02:10:09.693359 34819 solver.cpp:239] Iteration 30990 (2.3666 iter/s, 4.22547s/10 iters), loss = 8.93752
I0523 02:10:09.693403 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93752 (* 1 = 8.93752 loss)
I0523 02:10:09.750639 34819 sgd_solver.cpp:112] Iteration 30990, lr = 0.01
I0523 02:10:13.860311 34819 solver.cpp:239] Iteration 31000 (2.4021 iter/s, 4.16302s/10 iters), loss = 8.88094
I0523 02:10:13.860352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88094 (* 1 = 8.88094 loss)
I0523 02:10:14.214298 34819 sgd_solver.cpp:112] Iteration 31000, lr = 0.01
I0523 02:10:20.422178 34819 solver.cpp:239] Iteration 31010 (1.52403 iter/s, 6.56155s/10 iters), loss = 8.89929
I0523 02:10:20.422219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89929 (* 1 = 8.89929 loss)
I0523 02:10:21.003610 34819 sgd_solver.cpp:112] Iteration 31010, lr = 0.01
I0523 02:10:25.169498 34819 solver.cpp:239] Iteration 31020 (2.10656 iter/s, 4.74709s/10 iters), loss = 8.35723
I0523 02:10:25.169553 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35723 (* 1 = 8.35723 loss)
I0523 02:10:25.233533 34819 sgd_solver.cpp:112] Iteration 31020, lr = 0.01
I0523 02:10:31.645730 34819 solver.cpp:239] Iteration 31030 (1.54419 iter/s, 6.47588s/10 iters), loss = 8.79064
I0523 02:10:31.645799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79064 (* 1 = 8.79064 loss)
I0523 02:10:32.482987 34819 sgd_solver.cpp:112] Iteration 31030, lr = 0.01
I0523 02:10:37.828374 34819 solver.cpp:239] Iteration 31040 (1.61751 iter/s, 6.18233s/10 iters), loss = 8.78252
I0523 02:10:37.828505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78252 (* 1 = 8.78252 loss)
I0523 02:10:37.900458 34819 sgd_solver.cpp:112] Iteration 31040, lr = 0.01
I0523 02:10:43.463984 34819 solver.cpp:239] Iteration 31050 (1.77455 iter/s, 5.63524s/10 iters), loss = 8.71143
I0523 02:10:43.464035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71143 (* 1 = 8.71143 loss)
I0523 02:10:43.533248 34819 sgd_solver.cpp:112] Iteration 31050, lr = 0.01
I0523 02:10:48.739008 34819 solver.cpp:239] Iteration 31060 (1.89582 iter/s, 5.27476s/10 iters), loss = 8.68757
I0523 02:10:48.739054 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68757 (* 1 = 8.68757 loss)
I0523 02:10:49.262256 34819 sgd_solver.cpp:112] Iteration 31060, lr = 0.01
I0523 02:10:51.829653 34819 solver.cpp:239] Iteration 31070 (3.23577 iter/s, 3.09045s/10 iters), loss = 9.49202
I0523 02:10:51.829695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49202 (* 1 = 9.49202 loss)
I0523 02:10:51.900410 34819 sgd_solver.cpp:112] Iteration 31070, lr = 0.01
I0523 02:10:56.712502 34819 solver.cpp:239] Iteration 31080 (2.04809 iter/s, 4.88259s/10 iters), loss = 8.58058
I0523 02:10:56.712543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58058 (* 1 = 8.58058 loss)
I0523 02:10:57.498773 34819 sgd_solver.cpp:112] Iteration 31080, lr = 0.01
I0523 02:11:01.640844 34819 solver.cpp:239] Iteration 31090 (2.02919 iter/s, 4.92808s/10 iters), loss = 10.1776
I0523 02:11:01.640900 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1776 (* 1 = 10.1776 loss)
I0523 02:11:02.324932 34819 sgd_solver.cpp:112] Iteration 31090, lr = 0.01
I0523 02:11:07.231400 34819 solver.cpp:239] Iteration 31100 (1.78882 iter/s, 5.59027s/10 iters), loss = 9.09683
I0523 02:11:07.231452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09683 (* 1 = 9.09683 loss)
I0523 02:11:07.914062 34819 sgd_solver.cpp:112] Iteration 31100, lr = 0.01
I0523 02:11:12.891100 34819 solver.cpp:239] Iteration 31110 (1.76697 iter/s, 5.65942s/10 iters), loss = 9.33018
I0523 02:11:12.891152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33018 (* 1 = 9.33018 loss)
I0523 02:11:12.958858 34819 sgd_solver.cpp:112] Iteration 31110, lr = 0.01
I0523 02:11:17.600975 34819 solver.cpp:239] Iteration 31120 (2.12332 iter/s, 4.70961s/10 iters), loss = 9.45746
I0523 02:11:17.601030 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45746 (* 1 = 9.45746 loss)
I0523 02:11:18.380204 34819 sgd_solver.cpp:112] Iteration 31120, lr = 0.01
I0523 02:11:23.231246 34819 solver.cpp:239] Iteration 31130 (1.7762 iter/s, 5.62999s/10 iters), loss = 8.72734
I0523 02:11:23.231302 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72734 (* 1 = 8.72734 loss)
I0523 02:11:23.294911 34819 sgd_solver.cpp:112] Iteration 31130, lr = 0.01
I0523 02:11:26.621881 34819 solver.cpp:239] Iteration 31140 (2.94947 iter/s, 3.39043s/10 iters), loss = 8.62741
I0523 02:11:26.621935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62741 (* 1 = 8.62741 loss)
I0523 02:11:27.241991 34819 sgd_solver.cpp:112] Iteration 31140, lr = 0.01
I0523 02:11:31.919651 34819 solver.cpp:239] Iteration 31150 (1.88768 iter/s, 5.2975s/10 iters), loss = 8.16924
I0523 02:11:31.919692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16924 (* 1 = 8.16924 loss)
I0523 02:11:31.995816 34819 sgd_solver.cpp:112] Iteration 31150, lr = 0.01
I0523 02:11:35.773538 34819 solver.cpp:239] Iteration 31160 (2.59492 iter/s, 3.85368s/10 iters), loss = 8.2207
I0523 02:11:35.773579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2207 (* 1 = 8.2207 loss)
I0523 02:11:35.850564 34819 sgd_solver.cpp:112] Iteration 31160, lr = 0.01
I0523 02:11:41.733835 34819 solver.cpp:239] Iteration 31170 (1.67785 iter/s, 5.96001s/10 iters), loss = 8.98724
I0523 02:11:41.734022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98724 (* 1 = 8.98724 loss)
I0523 02:11:41.798379 34819 sgd_solver.cpp:112] Iteration 31170, lr = 0.01
I0523 02:11:46.533104 34819 solver.cpp:239] Iteration 31180 (2.08381 iter/s, 4.79891s/10 iters), loss = 8.7665
I0523 02:11:46.533149 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7665 (* 1 = 8.7665 loss)
I0523 02:11:46.613099 34819 sgd_solver.cpp:112] Iteration 31180, lr = 0.01
I0523 02:11:50.610805 34819 solver.cpp:239] Iteration 31190 (2.4525 iter/s, 4.07748s/10 iters), loss = 8.86564
I0523 02:11:50.610862 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86564 (* 1 = 8.86564 loss)
I0523 02:11:50.677973 34819 sgd_solver.cpp:112] Iteration 31190, lr = 0.01
I0523 02:11:54.661890 34819 solver.cpp:239] Iteration 31200 (2.46862 iter/s, 4.05085s/10 iters), loss = 9.22173
I0523 02:11:54.661933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22173 (* 1 = 9.22173 loss)
I0523 02:11:54.734575 34819 sgd_solver.cpp:112] Iteration 31200, lr = 0.01
I0523 02:12:00.003254 34819 solver.cpp:239] Iteration 31210 (1.87227 iter/s, 5.3411s/10 iters), loss = 9.21066
I0523 02:12:00.003307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21066 (* 1 = 9.21066 loss)
I0523 02:12:00.851666 34819 sgd_solver.cpp:112] Iteration 31210, lr = 0.01
I0523 02:12:05.778225 34819 solver.cpp:239] Iteration 31220 (1.7317 iter/s, 5.77467s/10 iters), loss = 9.17405
I0523 02:12:05.778280 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17405 (* 1 = 9.17405 loss)
I0523 02:12:05.855403 34819 sgd_solver.cpp:112] Iteration 31220, lr = 0.01
I0523 02:12:10.580338 34819 solver.cpp:239] Iteration 31230 (2.08253 iter/s, 4.80186s/10 iters), loss = 8.34168
I0523 02:12:10.580389 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34168 (* 1 = 8.34168 loss)
I0523 02:12:10.649534 34819 sgd_solver.cpp:112] Iteration 31230, lr = 0.01
I0523 02:12:13.873054 34819 solver.cpp:239] Iteration 31240 (3.03719 iter/s, 3.29252s/10 iters), loss = 8.95729
I0523 02:12:13.873286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95729 (* 1 = 8.95729 loss)
I0523 02:12:14.758715 34819 sgd_solver.cpp:112] Iteration 31240, lr = 0.01
I0523 02:12:21.813879 34819 solver.cpp:239] Iteration 31250 (1.2594 iter/s, 7.9403s/10 iters), loss = 8.08358
I0523 02:12:21.813922 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08358 (* 1 = 8.08358 loss)
I0523 02:12:21.899019 34819 sgd_solver.cpp:112] Iteration 31250, lr = 0.01
I0523 02:12:26.875039 34819 solver.cpp:239] Iteration 31260 (1.97593 iter/s, 5.06091s/10 iters), loss = 8.69955
I0523 02:12:26.875092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69955 (* 1 = 8.69955 loss)
I0523 02:12:26.943989 34819 sgd_solver.cpp:112] Iteration 31260, lr = 0.01
I0523 02:12:30.557909 34819 solver.cpp:239] Iteration 31270 (2.71543 iter/s, 3.68266s/10 iters), loss = 9.41927
I0523 02:12:30.557961 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41927 (* 1 = 9.41927 loss)
I0523 02:12:31.409179 34819 sgd_solver.cpp:112] Iteration 31270, lr = 0.01
I0523 02:12:36.150056 34819 solver.cpp:239] Iteration 31280 (1.78831 iter/s, 5.59187s/10 iters), loss = 8.87569
I0523 02:12:36.150097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87569 (* 1 = 8.87569 loss)
I0523 02:12:36.920469 34819 sgd_solver.cpp:112] Iteration 31280, lr = 0.01
I0523 02:12:41.791225 34819 solver.cpp:239] Iteration 31290 (1.77278 iter/s, 5.64085s/10 iters), loss = 9.38911
I0523 02:12:41.791286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38911 (* 1 = 9.38911 loss)
I0523 02:12:41.844730 34819 sgd_solver.cpp:112] Iteration 31290, lr = 0.01
I0523 02:12:46.872898 34819 solver.cpp:239] Iteration 31300 (1.96797 iter/s, 5.08138s/10 iters), loss = 8.40758
I0523 02:12:46.873045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40758 (* 1 = 8.40758 loss)
I0523 02:12:47.661792 34819 sgd_solver.cpp:112] Iteration 31300, lr = 0.01
I0523 02:12:53.359782 34819 solver.cpp:239] Iteration 31310 (1.54167 iter/s, 6.48648s/10 iters), loss = 8.48476
I0523 02:12:53.359836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48476 (* 1 = 8.48476 loss)
I0523 02:12:53.439182 34819 sgd_solver.cpp:112] Iteration 31310, lr = 0.01
I0523 02:12:57.724673 34819 solver.cpp:239] Iteration 31320 (2.29113 iter/s, 4.36465s/10 iters), loss = 8.91225
I0523 02:12:57.724735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91225 (* 1 = 8.91225 loss)
I0523 02:12:58.495492 34819 sgd_solver.cpp:112] Iteration 31320, lr = 0.01
I0523 02:13:02.103204 34819 solver.cpp:239] Iteration 31330 (2.284 iter/s, 4.37828s/10 iters), loss = 9.05194
I0523 02:13:02.103258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05194 (* 1 = 9.05194 loss)
I0523 02:13:02.178969 34819 sgd_solver.cpp:112] Iteration 31330, lr = 0.01
I0523 02:13:05.654938 34819 solver.cpp:239] Iteration 31340 (2.81571 iter/s, 3.5515s/10 iters), loss = 9.43714
I0523 02:13:05.654994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43714 (* 1 = 9.43714 loss)
I0523 02:13:05.923180 34819 sgd_solver.cpp:112] Iteration 31340, lr = 0.01
I0523 02:13:10.800078 34819 solver.cpp:239] Iteration 31350 (1.94368 iter/s, 5.14487s/10 iters), loss = 9.27462
I0523 02:13:10.800132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27462 (* 1 = 9.27462 loss)
I0523 02:13:10.865046 34819 sgd_solver.cpp:112] Iteration 31350, lr = 0.01
I0523 02:13:14.773610 34819 solver.cpp:239] Iteration 31360 (2.51679 iter/s, 3.97331s/10 iters), loss = 8.36839
I0523 02:13:14.773656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36839 (* 1 = 8.36839 loss)
I0523 02:13:15.627790 34819 sgd_solver.cpp:112] Iteration 31360, lr = 0.01
I0523 02:13:20.001654 34819 solver.cpp:239] Iteration 31370 (1.91286 iter/s, 5.22778s/10 iters), loss = 9.43128
I0523 02:13:20.001897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43128 (* 1 = 9.43128 loss)
I0523 02:13:20.634732 34819 sgd_solver.cpp:112] Iteration 31370, lr = 0.01
I0523 02:13:24.749629 34819 solver.cpp:239] Iteration 31380 (2.10634 iter/s, 4.74756s/10 iters), loss = 8.1732
I0523 02:13:24.749696 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1732 (* 1 = 8.1732 loss)
I0523 02:13:25.646059 34819 sgd_solver.cpp:112] Iteration 31380, lr = 0.01
I0523 02:13:29.021528 34819 solver.cpp:239] Iteration 31390 (2.34102 iter/s, 4.27164s/10 iters), loss = 9.37778
I0523 02:13:29.021575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37778 (* 1 = 9.37778 loss)
I0523 02:13:29.109143 34819 sgd_solver.cpp:112] Iteration 31390, lr = 0.01
I0523 02:13:31.958797 34819 solver.cpp:239] Iteration 31400 (3.40474 iter/s, 2.93708s/10 iters), loss = 9.37278
I0523 02:13:31.958850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37278 (* 1 = 9.37278 loss)
I0523 02:13:32.040289 34819 sgd_solver.cpp:112] Iteration 31400, lr = 0.01
I0523 02:13:37.632982 34819 solver.cpp:239] Iteration 31410 (1.76246 iter/s, 5.6739s/10 iters), loss = 9.28083
I0523 02:13:37.633044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28083 (* 1 = 9.28083 loss)
I0523 02:13:37.749961 34819 sgd_solver.cpp:112] Iteration 31410, lr = 0.01
I0523 02:13:42.537107 34819 solver.cpp:239] Iteration 31420 (2.03921 iter/s, 4.90385s/10 iters), loss = 8.6226
I0523 02:13:42.537164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6226 (* 1 = 8.6226 loss)
I0523 02:13:43.233312 34819 sgd_solver.cpp:112] Iteration 31420, lr = 0.01
I0523 02:13:47.384079 34819 solver.cpp:239] Iteration 31430 (2.06325 iter/s, 4.84671s/10 iters), loss = 8.92439
I0523 02:13:47.384135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92439 (* 1 = 8.92439 loss)
I0523 02:13:47.685667 34819 sgd_solver.cpp:112] Iteration 31430, lr = 0.01
I0523 02:13:52.207023 34819 solver.cpp:239] Iteration 31440 (2.07354 iter/s, 4.82267s/10 iters), loss = 8.58079
I0523 02:13:52.207271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58079 (* 1 = 8.58079 loss)
I0523 02:13:52.986636 34819 sgd_solver.cpp:112] Iteration 31440, lr = 0.01
I0523 02:13:57.123054 34819 solver.cpp:239] Iteration 31450 (2.03435 iter/s, 4.91559s/10 iters), loss = 9.1862
I0523 02:13:57.123109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1862 (* 1 = 9.1862 loss)
I0523 02:13:57.992377 34819 sgd_solver.cpp:112] Iteration 31450, lr = 0.01
I0523 02:14:01.443253 34819 solver.cpp:239] Iteration 31460 (2.31485 iter/s, 4.31994s/10 iters), loss = 8.68841
I0523 02:14:01.443315 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68841 (* 1 = 8.68841 loss)
I0523 02:14:02.291493 34819 sgd_solver.cpp:112] Iteration 31460, lr = 0.01
I0523 02:14:05.374953 34819 solver.cpp:239] Iteration 31470 (2.54357 iter/s, 3.93147s/10 iters), loss = 8.90845
I0523 02:14:05.375003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90845 (* 1 = 8.90845 loss)
I0523 02:14:05.432641 34819 sgd_solver.cpp:112] Iteration 31470, lr = 0.01
I0523 02:14:08.491632 34819 solver.cpp:239] Iteration 31480 (3.20873 iter/s, 3.11649s/10 iters), loss = 8.68509
I0523 02:14:08.491686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68509 (* 1 = 8.68509 loss)
I0523 02:14:08.572321 34819 sgd_solver.cpp:112] Iteration 31480, lr = 0.01
I0523 02:14:13.500855 34819 solver.cpp:239] Iteration 31490 (1.99643 iter/s, 5.00895s/10 iters), loss = 9.20838
I0523 02:14:13.500918 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20838 (* 1 = 9.20838 loss)
I0523 02:14:14.189028 34819 sgd_solver.cpp:112] Iteration 31490, lr = 0.01
I0523 02:14:19.585150 34819 solver.cpp:239] Iteration 31500 (1.64366 iter/s, 6.08397s/10 iters), loss = 9.40489
I0523 02:14:19.585204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40489 (* 1 = 9.40489 loss)
I0523 02:14:20.439810 34819 sgd_solver.cpp:112] Iteration 31500, lr = 0.01
I0523 02:14:23.147071 34819 solver.cpp:239] Iteration 31510 (2.80764 iter/s, 3.56171s/10 iters), loss = 9.2963
I0523 02:14:23.147183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2963 (* 1 = 9.2963 loss)
I0523 02:14:23.946548 34819 sgd_solver.cpp:112] Iteration 31510, lr = 0.01
I0523 02:14:27.878793 34819 solver.cpp:239] Iteration 31520 (2.11353 iter/s, 4.73141s/10 iters), loss = 8.83223
I0523 02:14:27.878849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83223 (* 1 = 8.83223 loss)
I0523 02:14:28.661110 34819 sgd_solver.cpp:112] Iteration 31520, lr = 0.01
I0523 02:14:33.145656 34819 solver.cpp:239] Iteration 31530 (1.89876 iter/s, 5.26659s/10 iters), loss = 8.43731
I0523 02:14:33.145714 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43731 (* 1 = 8.43731 loss)
I0523 02:14:33.228649 34819 sgd_solver.cpp:112] Iteration 31530, lr = 0.01
I0523 02:14:38.217000 34819 solver.cpp:239] Iteration 31540 (1.97197 iter/s, 5.07107s/10 iters), loss = 8.88275
I0523 02:14:38.217051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88275 (* 1 = 8.88275 loss)
I0523 02:14:38.279762 34819 sgd_solver.cpp:112] Iteration 31540, lr = 0.01
I0523 02:14:43.825827 34819 solver.cpp:239] Iteration 31550 (1.78299 iter/s, 5.60855s/10 iters), loss = 8.52561
I0523 02:14:43.825871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52561 (* 1 = 8.52561 loss)
I0523 02:14:44.666859 34819 sgd_solver.cpp:112] Iteration 31550, lr = 0.01
I0523 02:14:49.713237 34819 solver.cpp:239] Iteration 31560 (1.69863 iter/s, 5.88711s/10 iters), loss = 9.42228
I0523 02:14:49.713279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42228 (* 1 = 9.42228 loss)
I0523 02:14:49.777483 34819 sgd_solver.cpp:112] Iteration 31560, lr = 0.01
I0523 02:14:56.171140 34819 solver.cpp:239] Iteration 31570 (1.54856 iter/s, 6.45759s/10 iters), loss = 8.51108
I0523 02:14:56.171275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51108 (* 1 = 8.51108 loss)
I0523 02:14:56.777983 34819 sgd_solver.cpp:112] Iteration 31570, lr = 0.01
I0523 02:15:01.612488 34819 solver.cpp:239] Iteration 31580 (1.8379 iter/s, 5.44098s/10 iters), loss = 8.63416
I0523 02:15:01.612532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63416 (* 1 = 8.63416 loss)
I0523 02:15:01.698177 34819 sgd_solver.cpp:112] Iteration 31580, lr = 0.01
I0523 02:15:07.355440 34819 solver.cpp:239] Iteration 31590 (1.74135 iter/s, 5.74266s/10 iters), loss = 9.36913
I0523 02:15:07.355485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36913 (* 1 = 9.36913 loss)
I0523 02:15:07.429149 34819 sgd_solver.cpp:112] Iteration 31590, lr = 0.01
I0523 02:15:10.638639 34819 solver.cpp:239] Iteration 31600 (3.04598 iter/s, 3.28301s/10 iters), loss = 9.29632
I0523 02:15:10.638684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29632 (* 1 = 9.29632 loss)
I0523 02:15:10.706307 34819 sgd_solver.cpp:112] Iteration 31600, lr = 0.01
I0523 02:15:15.031065 34819 solver.cpp:239] Iteration 31610 (2.27677 iter/s, 4.39219s/10 iters), loss = 8.70897
I0523 02:15:15.031107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70897 (* 1 = 8.70897 loss)
I0523 02:15:15.105846 34819 sgd_solver.cpp:112] Iteration 31610, lr = 0.01
I0523 02:15:19.974249 34819 solver.cpp:239] Iteration 31620 (2.02311 iter/s, 4.94289s/10 iters), loss = 9.07151
I0523 02:15:19.974300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07151 (* 1 = 9.07151 loss)
I0523 02:15:20.812984 34819 sgd_solver.cpp:112] Iteration 31620, lr = 0.01
I0523 02:15:25.560019 34819 solver.cpp:239] Iteration 31630 (1.79035 iter/s, 5.58549s/10 iters), loss = 9.70834
I0523 02:15:25.560061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70834 (* 1 = 9.70834 loss)
I0523 02:15:26.304024 34819 sgd_solver.cpp:112] Iteration 31630, lr = 0.01
I0523 02:15:31.792992 34819 solver.cpp:239] Iteration 31640 (1.60445 iter/s, 6.23267s/10 iters), loss = 8.81599
I0523 02:15:31.793036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81599 (* 1 = 8.81599 loss)
I0523 02:15:31.867580 34819 sgd_solver.cpp:112] Iteration 31640, lr = 0.01
I0523 02:15:35.165294 34819 solver.cpp:239] Iteration 31650 (2.96551 iter/s, 3.3721s/10 iters), loss = 8.60508
I0523 02:15:35.165334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60508 (* 1 = 8.60508 loss)
I0523 02:15:35.967139 34819 sgd_solver.cpp:112] Iteration 31650, lr = 0.01
I0523 02:15:40.664377 34819 solver.cpp:239] Iteration 31660 (1.81858 iter/s, 5.49881s/10 iters), loss = 9.01399
I0523 02:15:40.664419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01399 (* 1 = 9.01399 loss)
I0523 02:15:41.453415 34819 sgd_solver.cpp:112] Iteration 31660, lr = 0.01
I0523 02:15:46.797699 34819 solver.cpp:239] Iteration 31670 (1.63051 iter/s, 6.13303s/10 iters), loss = 8.98931
I0523 02:15:46.797741 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98931 (* 1 = 8.98931 loss)
I0523 02:15:46.865339 34819 sgd_solver.cpp:112] Iteration 31670, lr = 0.01
I0523 02:15:50.347048 34819 solver.cpp:239] Iteration 31680 (2.81758 iter/s, 3.54914s/10 iters), loss = 9.96737
I0523 02:15:50.347090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.96737 (* 1 = 9.96737 loss)
I0523 02:15:51.135507 34819 sgd_solver.cpp:112] Iteration 31680, lr = 0.01
I0523 02:15:54.578033 34819 solver.cpp:239] Iteration 31690 (2.36364 iter/s, 4.23076s/10 iters), loss = 8.69134
I0523 02:15:54.578075 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69134 (* 1 = 8.69134 loss)
I0523 02:15:55.406612 34819 sgd_solver.cpp:112] Iteration 31690, lr = 0.01
I0523 02:15:59.165858 34819 solver.cpp:239] Iteration 31700 (2.17979 iter/s, 4.58759s/10 iters), loss = 8.71825
I0523 02:15:59.165997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71825 (* 1 = 8.71825 loss)
I0523 02:15:59.224328 34819 sgd_solver.cpp:112] Iteration 31700, lr = 0.01
I0523 02:16:04.138765 34819 solver.cpp:239] Iteration 31710 (2.01103 iter/s, 4.97257s/10 iters), loss = 9.50658
I0523 02:16:04.138809 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50658 (* 1 = 9.50658 loss)
I0523 02:16:04.907335 34819 sgd_solver.cpp:112] Iteration 31710, lr = 0.01
I0523 02:16:09.137208 34819 solver.cpp:239] Iteration 31720 (2.00073 iter/s, 4.99818s/10 iters), loss = 8.44798
I0523 02:16:09.137264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44798 (* 1 = 8.44798 loss)
I0523 02:16:09.721280 34819 sgd_solver.cpp:112] Iteration 31720, lr = 0.01
I0523 02:16:15.206382 34819 solver.cpp:239] Iteration 31730 (1.64776 iter/s, 6.06885s/10 iters), loss = 9.35131
I0523 02:16:15.206427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35131 (* 1 = 9.35131 loss)
I0523 02:16:15.282881 34819 sgd_solver.cpp:112] Iteration 31730, lr = 0.01
I0523 02:16:19.881497 34819 solver.cpp:239] Iteration 31740 (2.1391 iter/s, 4.67486s/10 iters), loss = 8.74839
I0523 02:16:19.881558 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74839 (* 1 = 8.74839 loss)
I0523 02:16:20.737207 34819 sgd_solver.cpp:112] Iteration 31740, lr = 0.01
I0523 02:16:24.049706 34819 solver.cpp:239] Iteration 31750 (2.39925 iter/s, 4.16797s/10 iters), loss = 8.42578
I0523 02:16:24.049751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42578 (* 1 = 8.42578 loss)
I0523 02:16:24.126091 34819 sgd_solver.cpp:112] Iteration 31750, lr = 0.01
I0523 02:16:28.721910 34819 solver.cpp:239] Iteration 31760 (2.14043 iter/s, 4.67195s/10 iters), loss = 7.91225
I0523 02:16:28.721962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91225 (* 1 = 7.91225 loss)
I0523 02:16:28.794286 34819 sgd_solver.cpp:112] Iteration 31760, lr = 0.01
I0523 02:16:34.014494 34819 solver.cpp:239] Iteration 31770 (1.88953 iter/s, 5.29231s/10 iters), loss = 9.19176
I0523 02:16:34.014575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19176 (* 1 = 9.19176 loss)
I0523 02:16:34.527369 34819 sgd_solver.cpp:112] Iteration 31770, lr = 0.01
I0523 02:16:39.295608 34819 solver.cpp:239] Iteration 31780 (1.89365 iter/s, 5.28081s/10 iters), loss = 8.45515
I0523 02:16:39.295658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45515 (* 1 = 8.45515 loss)
I0523 02:16:39.882531 34819 sgd_solver.cpp:112] Iteration 31780, lr = 0.01
I0523 02:16:45.530807 34819 solver.cpp:239] Iteration 31790 (1.60388 iter/s, 6.23488s/10 iters), loss = 8.2775
I0523 02:16:45.530864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2775 (* 1 = 8.2775 loss)
I0523 02:16:45.592877 34819 sgd_solver.cpp:112] Iteration 31790, lr = 0.01
I0523 02:16:50.282307 34819 solver.cpp:239] Iteration 31800 (2.10472 iter/s, 4.75123s/10 iters), loss = 10.1531
I0523 02:16:50.282372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1531 (* 1 = 10.1531 loss)
I0523 02:16:50.993443 34819 sgd_solver.cpp:112] Iteration 31800, lr = 0.01
I0523 02:16:55.929546 34819 solver.cpp:239] Iteration 31810 (1.77087 iter/s, 5.64695s/10 iters), loss = 8.54963
I0523 02:16:55.929591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54963 (* 1 = 8.54963 loss)
I0523 02:16:55.993365 34819 sgd_solver.cpp:112] Iteration 31810, lr = 0.01
I0523 02:17:01.357014 34819 solver.cpp:239] Iteration 31820 (1.84257 iter/s, 5.4272s/10 iters), loss = 9.52188
I0523 02:17:01.357080 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52188 (* 1 = 9.52188 loss)
I0523 02:17:02.167686 34819 sgd_solver.cpp:112] Iteration 31820, lr = 0.01
I0523 02:17:06.889832 34819 solver.cpp:239] Iteration 31830 (1.8075 iter/s, 5.53252s/10 iters), loss = 8.16939
I0523 02:17:06.890071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16939 (* 1 = 8.16939 loss)
I0523 02:17:06.965340 34819 sgd_solver.cpp:112] Iteration 31830, lr = 0.01
I0523 02:17:11.073968 34819 solver.cpp:239] Iteration 31840 (2.39019 iter/s, 4.18376s/10 iters), loss = 8.59554
I0523 02:17:11.074012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59554 (* 1 = 8.59554 loss)
I0523 02:17:11.863013 34819 sgd_solver.cpp:112] Iteration 31840, lr = 0.01
I0523 02:17:16.325011 34819 solver.cpp:239] Iteration 31850 (1.90448 iter/s, 5.25078s/10 iters), loss = 9.51235
I0523 02:17:16.325063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51235 (* 1 = 9.51235 loss)
I0523 02:17:17.174160 34819 sgd_solver.cpp:112] Iteration 31850, lr = 0.01
I0523 02:17:22.006512 34819 solver.cpp:239] Iteration 31860 (1.7602 iter/s, 5.68117s/10 iters), loss = 8.44658
I0523 02:17:22.006573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44658 (* 1 = 8.44658 loss)
I0523 02:17:22.826820 34819 sgd_solver.cpp:112] Iteration 31860, lr = 0.01
I0523 02:17:25.777678 34819 solver.cpp:239] Iteration 31870 (2.65185 iter/s, 3.77095s/10 iters), loss = 8.80957
I0523 02:17:25.777724 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80957 (* 1 = 8.80957 loss)
I0523 02:17:26.524416 34819 sgd_solver.cpp:112] Iteration 31870, lr = 0.01
I0523 02:17:30.940354 34819 solver.cpp:239] Iteration 31880 (1.93708 iter/s, 5.1624s/10 iters), loss = 9.20777
I0523 02:17:30.940408 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20777 (* 1 = 9.20777 loss)
I0523 02:17:31.655354 34819 sgd_solver.cpp:112] Iteration 31880, lr = 0.01
I0523 02:17:37.286259 34819 solver.cpp:239] Iteration 31890 (1.5759 iter/s, 6.34558s/10 iters), loss = 8.91204
I0523 02:17:37.286453 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91204 (* 1 = 8.91204 loss)
I0523 02:17:37.355211 34819 sgd_solver.cpp:112] Iteration 31890, lr = 0.01
I0523 02:17:43.076544 34819 solver.cpp:239] Iteration 31900 (1.72715 iter/s, 5.78987s/10 iters), loss = 8.66465
I0523 02:17:43.076596 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66465 (* 1 = 8.66465 loss)
I0523 02:17:43.136242 34819 sgd_solver.cpp:112] Iteration 31900, lr = 0.01
I0523 02:17:46.459406 34819 solver.cpp:239] Iteration 31910 (2.95625 iter/s, 3.38266s/10 iters), loss = 9.36908
I0523 02:17:46.459458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36908 (* 1 = 9.36908 loss)
I0523 02:17:47.090531 34819 sgd_solver.cpp:112] Iteration 31910, lr = 0.01
I0523 02:17:51.429219 34819 solver.cpp:239] Iteration 31920 (2.01225 iter/s, 4.96955s/10 iters), loss = 8.60769
I0523 02:17:51.429275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60769 (* 1 = 8.60769 loss)
I0523 02:17:51.494606 34819 sgd_solver.cpp:112] Iteration 31920, lr = 0.01
I0523 02:17:55.508635 34819 solver.cpp:239] Iteration 31930 (2.45147 iter/s, 4.07918s/10 iters), loss = 9.36888
I0523 02:17:55.508677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36888 (* 1 = 9.36888 loss)
I0523 02:17:55.575495 34819 sgd_solver.cpp:112] Iteration 31930, lr = 0.01
I0523 02:18:00.460806 34819 solver.cpp:239] Iteration 31940 (2.01942 iter/s, 4.95192s/10 iters), loss = 8.12585
I0523 02:18:00.460860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12585 (* 1 = 8.12585 loss)
I0523 02:18:00.522521 34819 sgd_solver.cpp:112] Iteration 31940, lr = 0.01
I0523 02:18:04.205446 34819 solver.cpp:239] Iteration 31950 (2.67064 iter/s, 3.74443s/10 iters), loss = 9.7544
I0523 02:18:04.205494 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.7544 (* 1 = 9.7544 loss)
I0523 02:18:04.264477 34819 sgd_solver.cpp:112] Iteration 31950, lr = 0.01
I0523 02:18:08.487439 34819 solver.cpp:239] Iteration 31960 (2.33548 iter/s, 4.28177s/10 iters), loss = 9.01847
I0523 02:18:08.487566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01847 (* 1 = 9.01847 loss)
I0523 02:18:08.555948 34819 sgd_solver.cpp:112] Iteration 31960, lr = 0.01
I0523 02:18:13.132268 34819 solver.cpp:239] Iteration 31970 (2.15308 iter/s, 4.64451s/10 iters), loss = 7.73156
I0523 02:18:13.132309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73156 (* 1 = 7.73156 loss)
I0523 02:18:13.211813 34819 sgd_solver.cpp:112] Iteration 31970, lr = 0.01
I0523 02:18:17.407863 34819 solver.cpp:239] Iteration 31980 (2.33899 iter/s, 4.27535s/10 iters), loss = 9.73108
I0523 02:18:17.407919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.73108 (* 1 = 9.73108 loss)
I0523 02:18:18.263170 34819 sgd_solver.cpp:112] Iteration 31980, lr = 0.01
I0523 02:18:20.792420 34819 solver.cpp:239] Iteration 31990 (2.95477 iter/s, 3.38435s/10 iters), loss = 9.18833
I0523 02:18:20.792472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18833 (* 1 = 9.18833 loss)
I0523 02:18:20.872129 34819 sgd_solver.cpp:112] Iteration 31990, lr = 0.01
I0523 02:18:26.630103 34819 solver.cpp:239] Iteration 32000 (1.71309 iter/s, 5.83739s/10 iters), loss = 9.18437
I0523 02:18:26.630158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18437 (* 1 = 9.18437 loss)
I0523 02:18:26.711205 34819 sgd_solver.cpp:112] Iteration 32000, lr = 0.01
I0523 02:18:30.156195 34819 solver.cpp:239] Iteration 32010 (2.83616 iter/s, 3.52589s/10 iters), loss = 8.01715
I0523 02:18:30.156237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01715 (* 1 = 8.01715 loss)
I0523 02:18:30.946918 34819 sgd_solver.cpp:112] Iteration 32010, lr = 0.01
I0523 02:18:35.702934 34819 solver.cpp:239] Iteration 32020 (1.80296 iter/s, 5.54645s/10 iters), loss = 8.29345
I0523 02:18:35.702998 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29345 (* 1 = 8.29345 loss)
I0523 02:18:35.776207 34819 sgd_solver.cpp:112] Iteration 32020, lr = 0.01
I0523 02:18:39.988690 34819 solver.cpp:239] Iteration 32030 (2.33345 iter/s, 4.28551s/10 iters), loss = 8.76796
I0523 02:18:39.988824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76796 (* 1 = 8.76796 loss)
I0523 02:18:40.815686 34819 sgd_solver.cpp:112] Iteration 32030, lr = 0.01
I0523 02:18:45.717589 34819 solver.cpp:239] Iteration 32040 (1.74565 iter/s, 5.72853s/10 iters), loss = 9.06393
I0523 02:18:45.717634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06393 (* 1 = 9.06393 loss)
I0523 02:18:45.790081 34819 sgd_solver.cpp:112] Iteration 32040, lr = 0.01
I0523 02:18:49.921939 34819 solver.cpp:239] Iteration 32050 (2.37862 iter/s, 4.20412s/10 iters), loss = 8.81549
I0523 02:18:49.921988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81549 (* 1 = 8.81549 loss)
I0523 02:18:49.981791 34819 sgd_solver.cpp:112] Iteration 32050, lr = 0.01
I0523 02:18:56.029083 34819 solver.cpp:239] Iteration 32060 (1.63751 iter/s, 6.10683s/10 iters), loss = 8.0565
I0523 02:18:56.029125 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0565 (* 1 = 8.0565 loss)
I0523 02:18:56.089664 34819 sgd_solver.cpp:112] Iteration 32060, lr = 0.01
I0523 02:19:01.283568 34819 solver.cpp:239] Iteration 32070 (1.90323 iter/s, 5.25422s/10 iters), loss = 9.85179
I0523 02:19:01.283614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.85179 (* 1 = 9.85179 loss)
I0523 02:19:01.335196 34819 sgd_solver.cpp:112] Iteration 32070, lr = 0.01
I0523 02:19:03.809459 34819 solver.cpp:239] Iteration 32080 (3.95925 iter/s, 2.52573s/10 iters), loss = 9.52225
I0523 02:19:03.809507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52225 (* 1 = 9.52225 loss)
I0523 02:19:04.615835 34819 sgd_solver.cpp:112] Iteration 32080, lr = 0.01
I0523 02:19:10.803804 34819 solver.cpp:239] Iteration 32090 (1.42979 iter/s, 6.99401s/10 iters), loss = 8.98255
I0523 02:19:10.804070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98255 (* 1 = 8.98255 loss)
I0523 02:19:10.859242 34819 sgd_solver.cpp:112] Iteration 32090, lr = 0.01
I0523 02:19:15.299471 34819 solver.cpp:239] Iteration 32100 (2.22457 iter/s, 4.49524s/10 iters), loss = 10.2761
I0523 02:19:15.299515 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2761 (* 1 = 10.2761 loss)
I0523 02:19:16.123790 34819 sgd_solver.cpp:112] Iteration 32100, lr = 0.01
I0523 02:19:22.276000 34819 solver.cpp:239] Iteration 32110 (1.43344 iter/s, 6.9762s/10 iters), loss = 8.84711
I0523 02:19:22.276046 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84711 (* 1 = 8.84711 loss)
I0523 02:19:22.329177 34819 sgd_solver.cpp:112] Iteration 32110, lr = 0.01
I0523 02:19:25.257138 34819 solver.cpp:239] Iteration 32120 (3.35462 iter/s, 2.98096s/10 iters), loss = 8.61593
I0523 02:19:25.257179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61593 (* 1 = 8.61593 loss)
I0523 02:19:25.334779 34819 sgd_solver.cpp:112] Iteration 32120, lr = 0.01
I0523 02:19:29.847589 34819 solver.cpp:239] Iteration 32130 (2.17855 iter/s, 4.59021s/10 iters), loss = 9.24351
I0523 02:19:29.847630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24351 (* 1 = 9.24351 loss)
I0523 02:19:30.620959 34819 sgd_solver.cpp:112] Iteration 32130, lr = 0.01
I0523 02:19:35.436188 34819 solver.cpp:239] Iteration 32140 (1.78945 iter/s, 5.58832s/10 iters), loss = 8.69532
I0523 02:19:35.436240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69532 (* 1 = 8.69532 loss)
I0523 02:19:35.500669 34819 sgd_solver.cpp:112] Iteration 32140, lr = 0.01
I0523 02:19:39.300518 34819 solver.cpp:239] Iteration 32150 (2.58791 iter/s, 3.86412s/10 iters), loss = 9.12901
I0523 02:19:39.300562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12901 (* 1 = 9.12901 loss)
I0523 02:19:40.137702 34819 sgd_solver.cpp:112] Iteration 32150, lr = 0.01
I0523 02:19:45.597694 34819 solver.cpp:239] Iteration 32160 (1.58809 iter/s, 6.29687s/10 iters), loss = 9.04527
I0523 02:19:45.597923 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04527 (* 1 = 9.04527 loss)
I0523 02:19:45.667999 34819 sgd_solver.cpp:112] Iteration 32160, lr = 0.01
I0523 02:19:51.037874 34819 solver.cpp:239] Iteration 32170 (1.83832 iter/s, 5.43975s/10 iters), loss = 8.3231
I0523 02:19:51.037920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3231 (* 1 = 8.3231 loss)
I0523 02:19:51.087741 34819 sgd_solver.cpp:112] Iteration 32170, lr = 0.01
I0523 02:19:55.198614 34819 solver.cpp:239] Iteration 32180 (2.40355 iter/s, 4.16052s/10 iters), loss = 8.56295
I0523 02:19:55.198660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56295 (* 1 = 8.56295 loss)
I0523 02:19:55.256721 34819 sgd_solver.cpp:112] Iteration 32180, lr = 0.01
I0523 02:20:00.026407 34819 solver.cpp:239] Iteration 32190 (2.07145 iter/s, 4.82755s/10 iters), loss = 8.88678
I0523 02:20:00.026451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88678 (* 1 = 8.88678 loss)
I0523 02:20:00.102452 34819 sgd_solver.cpp:112] Iteration 32190, lr = 0.01
I0523 02:20:05.056658 34819 solver.cpp:239] Iteration 32200 (1.98807 iter/s, 5.03s/10 iters), loss = 8.88354
I0523 02:20:05.056699 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88354 (* 1 = 8.88354 loss)
I0523 02:20:05.129631 34819 sgd_solver.cpp:112] Iteration 32200, lr = 0.01
I0523 02:20:09.062095 34819 solver.cpp:239] Iteration 32210 (2.49675 iter/s, 4.0052s/10 iters), loss = 8.12225
I0523 02:20:09.062142 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12225 (* 1 = 8.12225 loss)
I0523 02:20:09.121523 34819 sgd_solver.cpp:112] Iteration 32210, lr = 0.01
I0523 02:20:13.178637 34819 solver.cpp:239] Iteration 32220 (2.42936 iter/s, 4.11632s/10 iters), loss = 8.54278
I0523 02:20:13.178714 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54278 (* 1 = 8.54278 loss)
I0523 02:20:13.257993 34819 sgd_solver.cpp:112] Iteration 32220, lr = 0.01
I0523 02:20:19.421051 34819 solver.cpp:239] Iteration 32230 (1.60203 iter/s, 6.24209s/10 iters), loss = 8.93262
I0523 02:20:19.421243 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93262 (* 1 = 8.93262 loss)
I0523 02:20:19.480024 34819 sgd_solver.cpp:112] Iteration 32230, lr = 0.01
I0523 02:20:24.517638 34819 solver.cpp:239] Iteration 32240 (1.96226 iter/s, 5.09617s/10 iters), loss = 9.04239
I0523 02:20:24.517688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04239 (* 1 = 9.04239 loss)
I0523 02:20:25.349257 34819 sgd_solver.cpp:112] Iteration 32240, lr = 0.01
I0523 02:20:28.096386 34819 solver.cpp:239] Iteration 32250 (2.79445 iter/s, 3.57853s/10 iters), loss = 8.9213
I0523 02:20:28.096433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9213 (* 1 = 8.9213 loss)
I0523 02:20:28.807719 34819 sgd_solver.cpp:112] Iteration 32250, lr = 0.01
I0523 02:20:33.450656 34819 solver.cpp:239] Iteration 32260 (1.86777 iter/s, 5.35399s/10 iters), loss = 8.51826
I0523 02:20:33.450726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51826 (* 1 = 8.51826 loss)
I0523 02:20:33.519143 34819 sgd_solver.cpp:112] Iteration 32260, lr = 0.01
I0523 02:20:38.613401 34819 solver.cpp:239] Iteration 32270 (1.93706 iter/s, 5.16245s/10 iters), loss = 8.78382
I0523 02:20:38.613452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78382 (* 1 = 8.78382 loss)
I0523 02:20:38.662261 34819 sgd_solver.cpp:112] Iteration 32270, lr = 0.01
I0523 02:20:44.178014 34819 solver.cpp:239] Iteration 32280 (1.79716 iter/s, 5.56433s/10 iters), loss = 7.9041
I0523 02:20:44.178053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9041 (* 1 = 7.9041 loss)
I0523 02:20:45.006574 34819 sgd_solver.cpp:112] Iteration 32280, lr = 0.01
I0523 02:20:49.110049 34819 solver.cpp:239] Iteration 32290 (2.02766 iter/s, 4.93179s/10 iters), loss = 8.99702
I0523 02:20:49.110090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99702 (* 1 = 8.99702 loss)
I0523 02:20:49.979385 34819 sgd_solver.cpp:112] Iteration 32290, lr = 0.01
I0523 02:20:54.056094 34819 solver.cpp:239] Iteration 32300 (2.02192 iter/s, 4.9458s/10 iters), loss = 8.92691
I0523 02:20:54.056138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92691 (* 1 = 8.92691 loss)
I0523 02:20:54.886072 34819 sgd_solver.cpp:112] Iteration 32300, lr = 0.01
I0523 02:21:00.624621 34819 solver.cpp:239] Iteration 32310 (1.52248 iter/s, 6.56822s/10 iters), loss = 9.55892
I0523 02:21:00.624667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55892 (* 1 = 9.55892 loss)
I0523 02:21:01.400743 34819 sgd_solver.cpp:112] Iteration 32310, lr = 0.01
I0523 02:21:06.565783 34819 solver.cpp:239] Iteration 32320 (1.68326 iter/s, 5.94085s/10 iters), loss = 8.94885
I0523 02:21:06.565843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94885 (* 1 = 8.94885 loss)
I0523 02:21:07.299003 34819 sgd_solver.cpp:112] Iteration 32320, lr = 0.01
I0523 02:21:10.063697 34819 solver.cpp:239] Iteration 32330 (2.85902 iter/s, 3.4977s/10 iters), loss = 8.97104
I0523 02:21:10.063748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97104 (* 1 = 8.97104 loss)
I0523 02:21:10.900050 34819 sgd_solver.cpp:112] Iteration 32330, lr = 0.01
I0523 02:21:14.252010 34819 solver.cpp:239] Iteration 32340 (2.38774 iter/s, 4.18806s/10 iters), loss = 8.99828
I0523 02:21:14.252060 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99828 (* 1 = 8.99828 loss)
I0523 02:21:14.997526 34819 sgd_solver.cpp:112] Iteration 32340, lr = 0.01
I0523 02:21:18.288753 34819 solver.cpp:239] Iteration 32350 (2.47738 iter/s, 4.03653s/10 iters), loss = 8.7017
I0523 02:21:18.288794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7017 (* 1 = 8.7017 loss)
I0523 02:21:18.366925 34819 sgd_solver.cpp:112] Iteration 32350, lr = 0.01
I0523 02:21:23.797302 34819 solver.cpp:239] Iteration 32360 (1.81545 iter/s, 5.50828s/10 iters), loss = 9.84084
I0523 02:21:23.797454 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84084 (* 1 = 9.84084 loss)
I0523 02:21:23.860782 34819 sgd_solver.cpp:112] Iteration 32360, lr = 0.01
I0523 02:21:26.764683 34819 solver.cpp:239] Iteration 32370 (3.37031 iter/s, 2.96709s/10 iters), loss = 9.23981
I0523 02:21:26.764734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23981 (* 1 = 9.23981 loss)
I0523 02:21:26.830737 34819 sgd_solver.cpp:112] Iteration 32370, lr = 0.01
I0523 02:21:31.856178 34819 solver.cpp:239] Iteration 32380 (1.96416 iter/s, 5.09123s/10 iters), loss = 9.64275
I0523 02:21:31.856220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64275 (* 1 = 9.64275 loss)
I0523 02:21:32.678477 34819 sgd_solver.cpp:112] Iteration 32380, lr = 0.01
I0523 02:21:37.680743 34819 solver.cpp:239] Iteration 32390 (1.71695 iter/s, 5.82428s/10 iters), loss = 8.49262
I0523 02:21:37.680789 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49262 (* 1 = 8.49262 loss)
I0523 02:21:38.402287 34819 sgd_solver.cpp:112] Iteration 32390, lr = 0.01
I0523 02:21:42.370985 34819 solver.cpp:239] Iteration 32400 (2.1322 iter/s, 4.68999s/10 iters), loss = 9.04265
I0523 02:21:42.371028 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04265 (* 1 = 9.04265 loss)
I0523 02:21:42.443501 34819 sgd_solver.cpp:112] Iteration 32400, lr = 0.01
I0523 02:21:45.958297 34819 solver.cpp:239] Iteration 32410 (2.78776 iter/s, 3.58711s/10 iters), loss = 9.40879
I0523 02:21:45.958346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40879 (* 1 = 9.40879 loss)
I0523 02:21:46.038909 34819 sgd_solver.cpp:112] Iteration 32410, lr = 0.01
I0523 02:21:50.218890 34819 solver.cpp:239] Iteration 32420 (2.34721 iter/s, 4.26037s/10 iters), loss = 9.07546
I0523 02:21:50.218932 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07546 (* 1 = 9.07546 loss)
I0523 02:21:50.277151 34819 sgd_solver.cpp:112] Iteration 32420, lr = 0.01
I0523 02:21:51.060436 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 02:21:53.444726 34819 solver.cpp:239] Iteration 32430 (3.10014 iter/s, 3.22566s/10 iters), loss = 9.35005
I0523 02:21:53.444769 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35005 (* 1 = 9.35005 loss)
I0523 02:21:53.503999 34819 sgd_solver.cpp:112] Iteration 32430, lr = 0.01
I0523 02:21:56.730280 34819 solver.cpp:239] Iteration 32440 (3.0438 iter/s, 3.28536s/10 iters), loss = 8.70807
I0523 02:21:56.730422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70807 (* 1 = 8.70807 loss)
I0523 02:21:56.797623 34819 sgd_solver.cpp:112] Iteration 32440, lr = 0.01
I0523 02:22:02.469174 34819 solver.cpp:239] Iteration 32450 (1.74261 iter/s, 5.73851s/10 iters), loss = 9.08415
I0523 02:22:02.469218 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08415 (* 1 = 9.08415 loss)
I0523 02:22:02.539393 34819 sgd_solver.cpp:112] Iteration 32450, lr = 0.01
I0523 02:22:07.349011 34819 solver.cpp:239] Iteration 32460 (2.04935 iter/s, 4.87958s/10 iters), loss = 8.22893
I0523 02:22:07.349053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22893 (* 1 = 8.22893 loss)
I0523 02:22:07.413404 34819 sgd_solver.cpp:112] Iteration 32460, lr = 0.01
I0523 02:22:11.891474 34819 solver.cpp:239] Iteration 32470 (2.20157 iter/s, 4.54222s/10 iters), loss = 9.2986
I0523 02:22:11.891516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2986 (* 1 = 9.2986 loss)
I0523 02:22:11.964190 34819 sgd_solver.cpp:112] Iteration 32470, lr = 0.01
I0523 02:22:16.002331 34819 solver.cpp:239] Iteration 32480 (2.43271 iter/s, 4.11064s/10 iters), loss = 8.49404
I0523 02:22:16.002372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49404 (* 1 = 8.49404 loss)
I0523 02:22:16.610523 34819 sgd_solver.cpp:112] Iteration 32480, lr = 0.01
I0523 02:22:23.198212 34819 solver.cpp:239] Iteration 32490 (1.38975 iter/s, 7.19554s/10 iters), loss = 8.44675
I0523 02:22:23.198252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44675 (* 1 = 8.44675 loss)
I0523 02:22:23.272671 34819 sgd_solver.cpp:112] Iteration 32490, lr = 0.01
I0523 02:22:27.934929 34819 solver.cpp:239] Iteration 32500 (2.11128 iter/s, 4.73647s/10 iters), loss = 8.41643
I0523 02:22:27.935089 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41643 (* 1 = 8.41643 loss)
I0523 02:22:28.007280 34819 sgd_solver.cpp:112] Iteration 32500, lr = 0.01
I0523 02:22:31.820309 34819 solver.cpp:239] Iteration 32510 (2.57396 iter/s, 3.88506s/10 iters), loss = 8.61537
I0523 02:22:31.820350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61537 (* 1 = 8.61537 loss)
I0523 02:22:32.647858 34819 sgd_solver.cpp:112] Iteration 32510, lr = 0.01
I0523 02:22:37.437440 34819 solver.cpp:239] Iteration 32520 (1.78036 iter/s, 5.61684s/10 iters), loss = 9.10718
I0523 02:22:37.437503 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10718 (* 1 = 9.10718 loss)
I0523 02:22:38.091377 34819 sgd_solver.cpp:112] Iteration 32520, lr = 0.01
I0523 02:22:42.504942 34819 solver.cpp:239] Iteration 32530 (1.97347 iter/s, 5.06723s/10 iters), loss = 8.5333
I0523 02:22:42.504990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5333 (* 1 = 8.5333 loss)
I0523 02:22:42.568145 34819 sgd_solver.cpp:112] Iteration 32530, lr = 0.01
I0523 02:22:46.744557 34819 solver.cpp:239] Iteration 32540 (2.35883 iter/s, 4.23939s/10 iters), loss = 8.55712
I0523 02:22:46.744599 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55712 (* 1 = 8.55712 loss)
I0523 02:22:46.808984 34819 sgd_solver.cpp:112] Iteration 32540, lr = 0.01
I0523 02:22:51.268456 34819 solver.cpp:239] Iteration 32550 (2.2106 iter/s, 4.52366s/10 iters), loss = 9.37082
I0523 02:22:51.268507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37082 (* 1 = 9.37082 loss)
I0523 02:22:51.943061 34819 sgd_solver.cpp:112] Iteration 32550, lr = 0.01
I0523 02:22:56.710330 34819 solver.cpp:239] Iteration 32560 (1.83769 iter/s, 5.4416s/10 iters), loss = 8.89775
I0523 02:22:56.710373 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89775 (* 1 = 8.89775 loss)
I0523 02:22:56.781214 34819 sgd_solver.cpp:112] Iteration 32560, lr = 0.01
I0523 02:23:01.138952 34819 solver.cpp:239] Iteration 32570 (2.25816 iter/s, 4.42838s/10 iters), loss = 8.27878
I0523 02:23:01.139138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27878 (* 1 = 8.27878 loss)
I0523 02:23:01.931299 34819 sgd_solver.cpp:112] Iteration 32570, lr = 0.01
I0523 02:23:08.334120 34819 solver.cpp:239] Iteration 32580 (1.38991 iter/s, 7.1947s/10 iters), loss = 8.58899
I0523 02:23:08.334159 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58899 (* 1 = 8.58899 loss)
I0523 02:23:08.409168 34819 sgd_solver.cpp:112] Iteration 32580, lr = 0.01
I0523 02:23:13.173796 34819 solver.cpp:239] Iteration 32590 (2.06636 iter/s, 4.83944s/10 iters), loss = 8.62635
I0523 02:23:13.173838 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62635 (* 1 = 8.62635 loss)
I0523 02:23:13.232772 34819 sgd_solver.cpp:112] Iteration 32590, lr = 0.01
I0523 02:23:16.612195 34819 solver.cpp:239] Iteration 32600 (2.90849 iter/s, 3.43821s/10 iters), loss = 8.40706
I0523 02:23:16.612234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40706 (* 1 = 8.40706 loss)
I0523 02:23:16.678139 34819 sgd_solver.cpp:112] Iteration 32600, lr = 0.01
I0523 02:23:20.345922 34819 solver.cpp:239] Iteration 32610 (2.67843 iter/s, 3.73353s/10 iters), loss = 8.64302
I0523 02:23:20.345963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64302 (* 1 = 8.64302 loss)
I0523 02:23:20.418773 34819 sgd_solver.cpp:112] Iteration 32610, lr = 0.01
I0523 02:23:24.615948 34819 solver.cpp:239] Iteration 32620 (2.34203 iter/s, 4.2698s/10 iters), loss = 9.03805
I0523 02:23:24.616016 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03805 (* 1 = 9.03805 loss)
I0523 02:23:25.411212 34819 sgd_solver.cpp:112] Iteration 32620, lr = 0.01
I0523 02:23:29.382241 34819 solver.cpp:239] Iteration 32630 (2.09819 iter/s, 4.76601s/10 iters), loss = 8.11362
I0523 02:23:29.382295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11362 (* 1 = 8.11362 loss)
I0523 02:23:29.453533 34819 sgd_solver.cpp:112] Iteration 32630, lr = 0.01
I0523 02:23:33.425343 34819 solver.cpp:239] Iteration 32640 (2.47349 iter/s, 4.04287s/10 iters), loss = 8.26919
I0523 02:23:33.425520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26919 (* 1 = 8.26919 loss)
I0523 02:23:33.485630 34819 sgd_solver.cpp:112] Iteration 32640, lr = 0.01
I0523 02:23:37.568073 34819 solver.cpp:239] Iteration 32650 (2.41408 iter/s, 4.14237s/10 iters), loss = 8.92098
I0523 02:23:37.568135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92098 (* 1 = 8.92098 loss)
I0523 02:23:38.330947 34819 sgd_solver.cpp:112] Iteration 32650, lr = 0.01
I0523 02:23:44.141458 34819 solver.cpp:239] Iteration 32660 (1.52136 iter/s, 6.57304s/10 iters), loss = 9.21269
I0523 02:23:44.141512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21269 (* 1 = 9.21269 loss)
I0523 02:23:44.218243 34819 sgd_solver.cpp:112] Iteration 32660, lr = 0.01
I0523 02:23:48.050308 34819 solver.cpp:239] Iteration 32670 (2.55844 iter/s, 3.90863s/10 iters), loss = 7.19739
I0523 02:23:48.050359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.19739 (* 1 = 7.19739 loss)
I0523 02:23:48.121933 34819 sgd_solver.cpp:112] Iteration 32670, lr = 0.01
I0523 02:23:51.741590 34819 solver.cpp:239] Iteration 32680 (2.70924 iter/s, 3.69107s/10 iters), loss = 9.43952
I0523 02:23:51.741634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43952 (* 1 = 9.43952 loss)
I0523 02:23:52.531788 34819 sgd_solver.cpp:112] Iteration 32680, lr = 0.01
I0523 02:23:57.186177 34819 solver.cpp:239] Iteration 32690 (1.83678 iter/s, 5.44431s/10 iters), loss = 8.74444
I0523 02:23:57.186231 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74444 (* 1 = 8.74444 loss)
I0523 02:23:57.260566 34819 sgd_solver.cpp:112] Iteration 32690, lr = 0.01
I0523 02:24:01.235736 34819 solver.cpp:239] Iteration 32700 (2.46954 iter/s, 4.04934s/10 iters), loss = 8.96503
I0523 02:24:01.235780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96503 (* 1 = 8.96503 loss)
I0523 02:24:01.298575 34819 sgd_solver.cpp:112] Iteration 32700, lr = 0.01
I0523 02:24:06.558934 34819 solver.cpp:239] Iteration 32710 (1.87866 iter/s, 5.32293s/10 iters), loss = 9.24835
I0523 02:24:06.559154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24835 (* 1 = 9.24835 loss)
I0523 02:24:06.626340 34819 sgd_solver.cpp:112] Iteration 32710, lr = 0.01
I0523 02:24:10.395298 34819 solver.cpp:239] Iteration 32720 (2.60688 iter/s, 3.836s/10 iters), loss = 8.62837
I0523 02:24:10.395340 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62837 (* 1 = 8.62837 loss)
I0523 02:24:11.072566 34819 sgd_solver.cpp:112] Iteration 32720, lr = 0.01
I0523 02:24:16.511907 34819 solver.cpp:239] Iteration 32730 (1.63498 iter/s, 6.1163s/10 iters), loss = 9.78662
I0523 02:24:16.511967 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.78662 (* 1 = 9.78662 loss)
I0523 02:24:17.358803 34819 sgd_solver.cpp:112] Iteration 32730, lr = 0.01
I0523 02:24:21.420331 34819 solver.cpp:239] Iteration 32740 (2.03743 iter/s, 4.90815s/10 iters), loss = 8.79251
I0523 02:24:21.420382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79251 (* 1 = 8.79251 loss)
I0523 02:24:22.228715 34819 sgd_solver.cpp:112] Iteration 32740, lr = 0.01
I0523 02:24:25.537176 34819 solver.cpp:239] Iteration 32750 (2.42918 iter/s, 4.11662s/10 iters), loss = 9.02926
I0523 02:24:25.537226 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02926 (* 1 = 9.02926 loss)
I0523 02:24:25.605222 34819 sgd_solver.cpp:112] Iteration 32750, lr = 0.01
I0523 02:24:29.834826 34819 solver.cpp:239] Iteration 32760 (2.32698 iter/s, 4.29741s/10 iters), loss = 9.60577
I0523 02:24:29.834877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60577 (* 1 = 9.60577 loss)
I0523 02:24:29.902384 34819 sgd_solver.cpp:112] Iteration 32760, lr = 0.01
I0523 02:24:34.481676 34819 solver.cpp:239] Iteration 32770 (2.15211 iter/s, 4.6466s/10 iters), loss = 8.44434
I0523 02:24:34.481731 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44434 (* 1 = 8.44434 loss)
I0523 02:24:34.844532 34819 sgd_solver.cpp:112] Iteration 32770, lr = 0.01
I0523 02:24:39.005301 34819 solver.cpp:239] Iteration 32780 (2.21074 iter/s, 4.52337s/10 iters), loss = 9.33378
I0523 02:24:39.005468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33378 (* 1 = 9.33378 loss)
I0523 02:24:39.645311 34819 sgd_solver.cpp:112] Iteration 32780, lr = 0.01
I0523 02:24:45.706555 34819 solver.cpp:239] Iteration 32790 (1.49236 iter/s, 6.70081s/10 iters), loss = 9.12498
I0523 02:24:45.706609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12498 (* 1 = 9.12498 loss)
I0523 02:24:45.772300 34819 sgd_solver.cpp:112] Iteration 32790, lr = 0.01
I0523 02:24:50.981065 34819 solver.cpp:239] Iteration 32800 (1.89601 iter/s, 5.27422s/10 iters), loss = 8.90731
I0523 02:24:50.981117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90731 (* 1 = 8.90731 loss)
I0523 02:24:51.042551 34819 sgd_solver.cpp:112] Iteration 32800, lr = 0.01
I0523 02:24:55.307456 34819 solver.cpp:239] Iteration 32810 (2.31152 iter/s, 4.32615s/10 iters), loss = 7.46829
I0523 02:24:55.307505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46829 (* 1 = 7.46829 loss)
I0523 02:24:55.373775 34819 sgd_solver.cpp:112] Iteration 32810, lr = 0.01
I0523 02:25:00.300202 34819 solver.cpp:239] Iteration 32820 (2.00301 iter/s, 4.99249s/10 iters), loss = 8.28508
I0523 02:25:00.300245 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28508 (* 1 = 8.28508 loss)
I0523 02:25:00.372812 34819 sgd_solver.cpp:112] Iteration 32820, lr = 0.01
I0523 02:25:05.378976 34819 solver.cpp:239] Iteration 32830 (1.96908 iter/s, 5.0785s/10 iters), loss = 9.26746
I0523 02:25:05.379034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26746 (* 1 = 9.26746 loss)
I0523 02:25:05.461784 34819 sgd_solver.cpp:112] Iteration 32830, lr = 0.01
I0523 02:25:11.492280 34819 solver.cpp:239] Iteration 32840 (1.63586 iter/s, 6.11298s/10 iters), loss = 9.28893
I0523 02:25:11.492426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28893 (* 1 = 9.28893 loss)
I0523 02:25:11.564445 34819 sgd_solver.cpp:112] Iteration 32840, lr = 0.01
I0523 02:25:16.825079 34819 solver.cpp:239] Iteration 32850 (1.87532 iter/s, 5.33243s/10 iters), loss = 7.77533
I0523 02:25:16.825125 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77533 (* 1 = 7.77533 loss)
I0523 02:25:17.531311 34819 sgd_solver.cpp:112] Iteration 32850, lr = 0.01
I0523 02:25:22.217468 34819 solver.cpp:239] Iteration 32860 (1.85456 iter/s, 5.39212s/10 iters), loss = 9.27796
I0523 02:25:22.217514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27796 (* 1 = 9.27796 loss)
I0523 02:25:22.267078 34819 sgd_solver.cpp:112] Iteration 32860, lr = 0.01
I0523 02:25:26.072044 34819 solver.cpp:239] Iteration 32870 (2.59446 iter/s, 3.85437s/10 iters), loss = 9.65573
I0523 02:25:26.072091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65573 (* 1 = 9.65573 loss)
I0523 02:25:26.886732 34819 sgd_solver.cpp:112] Iteration 32870, lr = 0.01
I0523 02:25:31.191408 34819 solver.cpp:239] Iteration 32880 (1.95347 iter/s, 5.1191s/10 iters), loss = 8.66796
I0523 02:25:31.191459 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66796 (* 1 = 8.66796 loss)
I0523 02:25:31.893461 34819 sgd_solver.cpp:112] Iteration 32880, lr = 0.01
I0523 02:25:35.782232 34819 solver.cpp:239] Iteration 32890 (2.17837 iter/s, 4.59058s/10 iters), loss = 8.76343
I0523 02:25:35.782279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76343 (* 1 = 8.76343 loss)
I0523 02:25:35.840626 34819 sgd_solver.cpp:112] Iteration 32890, lr = 0.01
I0523 02:25:39.942355 34819 solver.cpp:239] Iteration 32900 (2.4039 iter/s, 4.1599s/10 iters), loss = 8.68209
I0523 02:25:39.942405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68209 (* 1 = 8.68209 loss)
I0523 02:25:40.018373 34819 sgd_solver.cpp:112] Iteration 32900, lr = 0.01
I0523 02:25:44.635087 34819 solver.cpp:239] Iteration 32910 (2.13107 iter/s, 4.69247s/10 iters), loss = 8.39357
I0523 02:25:44.635253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39357 (* 1 = 8.39357 loss)
I0523 02:25:44.690739 34819 sgd_solver.cpp:112] Iteration 32910, lr = 0.01
I0523 02:25:50.082391 34819 solver.cpp:239] Iteration 32920 (1.8359 iter/s, 5.44691s/10 iters), loss = 9.18366
I0523 02:25:50.082432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18366 (* 1 = 9.18366 loss)
I0523 02:25:50.143827 34819 sgd_solver.cpp:112] Iteration 32920, lr = 0.01
I0523 02:25:55.947726 34819 solver.cpp:239] Iteration 32930 (1.70502 iter/s, 5.86504s/10 iters), loss = 7.47392
I0523 02:25:55.947777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47392 (* 1 = 7.47392 loss)
I0523 02:25:56.761283 34819 sgd_solver.cpp:112] Iteration 32930, lr = 0.01
I0523 02:26:01.175776 34819 solver.cpp:239] Iteration 32940 (1.91286 iter/s, 5.22778s/10 iters), loss = 8.99514
I0523 02:26:01.175817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99514 (* 1 = 8.99514 loss)
I0523 02:26:02.013093 34819 sgd_solver.cpp:112] Iteration 32940, lr = 0.01
I0523 02:26:06.952177 34819 solver.cpp:239] Iteration 32950 (1.73127 iter/s, 5.7761s/10 iters), loss = 8.63038
I0523 02:26:06.952237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63038 (* 1 = 8.63038 loss)
I0523 02:26:07.750458 34819 sgd_solver.cpp:112] Iteration 32950, lr = 0.01
I0523 02:26:14.537392 34819 solver.cpp:239] Iteration 32960 (1.31842 iter/s, 7.58485s/10 iters), loss = 8.15701
I0523 02:26:14.537433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15701 (* 1 = 8.15701 loss)
I0523 02:26:14.616827 34819 sgd_solver.cpp:112] Iteration 32960, lr = 0.01
I0523 02:26:17.730813 34819 solver.cpp:239] Iteration 32970 (3.13163 iter/s, 3.19322s/10 iters), loss = 7.65351
I0523 02:26:17.730938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65351 (* 1 = 7.65351 loss)
I0523 02:26:17.793573 34819 sgd_solver.cpp:112] Iteration 32970, lr = 0.01
I0523 02:26:21.938321 34819 solver.cpp:239] Iteration 32980 (2.37687 iter/s, 4.20721s/10 iters), loss = 9.49338
I0523 02:26:21.938381 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49338 (* 1 = 9.49338 loss)
I0523 02:26:22.005575 34819 sgd_solver.cpp:112] Iteration 32980, lr = 0.01
I0523 02:26:26.859957 34819 solver.cpp:239] Iteration 32990 (2.03196 iter/s, 4.92136s/10 iters), loss = 9.12379
I0523 02:26:26.860008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12379 (* 1 = 9.12379 loss)
I0523 02:26:27.732966 34819 sgd_solver.cpp:112] Iteration 32990, lr = 0.01
I0523 02:26:31.031503 34819 solver.cpp:239] Iteration 33000 (2.39732 iter/s, 4.17132s/10 iters), loss = 9.35717
I0523 02:26:31.031548 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35717 (* 1 = 9.35717 loss)
I0523 02:26:31.081574 34819 sgd_solver.cpp:112] Iteration 33000, lr = 0.01
I0523 02:26:35.523317 34819 solver.cpp:239] Iteration 33010 (2.2264 iter/s, 4.49156s/10 iters), loss = 7.73957
I0523 02:26:35.523370 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73957 (* 1 = 7.73957 loss)
I0523 02:26:36.278311 34819 sgd_solver.cpp:112] Iteration 33010, lr = 0.01
I0523 02:26:39.223832 34819 solver.cpp:239] Iteration 33020 (2.70248 iter/s, 3.70031s/10 iters), loss = 8.46162
I0523 02:26:39.223886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46162 (* 1 = 8.46162 loss)
I0523 02:26:39.299991 34819 sgd_solver.cpp:112] Iteration 33020, lr = 0.01
I0523 02:26:44.066726 34819 solver.cpp:239] Iteration 33030 (2.06499 iter/s, 4.84263s/10 iters), loss = 8.84659
I0523 02:26:44.066781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84659 (* 1 = 8.84659 loss)
I0523 02:26:44.125655 34819 sgd_solver.cpp:112] Iteration 33030, lr = 0.01
I0523 02:26:47.639153 34819 solver.cpp:239] Iteration 33040 (2.79938 iter/s, 3.57222s/10 iters), loss = 8.3127
I0523 02:26:47.639204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3127 (* 1 = 8.3127 loss)
I0523 02:26:48.309731 34819 sgd_solver.cpp:112] Iteration 33040, lr = 0.01
I0523 02:26:52.942975 34819 solver.cpp:239] Iteration 33050 (1.88553 iter/s, 5.30355s/10 iters), loss = 8.73464
I0523 02:26:52.943023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73464 (* 1 = 8.73464 loss)
I0523 02:26:53.164829 34819 sgd_solver.cpp:112] Iteration 33050, lr = 0.01
I0523 02:26:56.956166 34819 solver.cpp:239] Iteration 33060 (2.49192 iter/s, 4.01297s/10 iters), loss = 8.13736
I0523 02:26:56.956219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13736 (* 1 = 8.13736 loss)
I0523 02:26:57.037770 34819 sgd_solver.cpp:112] Iteration 33060, lr = 0.01
I0523 02:27:01.975644 34819 solver.cpp:239] Iteration 33070 (1.99234 iter/s, 5.01922s/10 iters), loss = 7.7687
I0523 02:27:01.975694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7687 (* 1 = 7.7687 loss)
I0523 02:27:02.037928 34819 sgd_solver.cpp:112] Iteration 33070, lr = 0.01
I0523 02:27:06.440155 34819 solver.cpp:239] Iteration 33080 (2.24001 iter/s, 4.46427s/10 iters), loss = 8.44741
I0523 02:27:06.440208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44741 (* 1 = 8.44741 loss)
I0523 02:27:06.524240 34819 sgd_solver.cpp:112] Iteration 33080, lr = 0.01
I0523 02:27:10.462049 34819 solver.cpp:239] Iteration 33090 (2.48653 iter/s, 4.02166s/10 iters), loss = 8.99511
I0523 02:27:10.462096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99511 (* 1 = 8.99511 loss)
I0523 02:27:10.525817 34819 sgd_solver.cpp:112] Iteration 33090, lr = 0.01
I0523 02:27:14.274875 34819 solver.cpp:239] Iteration 33100 (2.62289 iter/s, 3.81259s/10 iters), loss = 9.63367
I0523 02:27:14.274937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63367 (* 1 = 9.63367 loss)
I0523 02:27:15.023957 34819 sgd_solver.cpp:112] Iteration 33100, lr = 0.01
I0523 02:27:19.051570 34819 solver.cpp:239] Iteration 33110 (2.09362 iter/s, 4.77642s/10 iters), loss = 8.79323
I0523 02:27:19.051704 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79323 (* 1 = 8.79323 loss)
I0523 02:27:19.491324 34819 sgd_solver.cpp:112] Iteration 33110, lr = 0.01
I0523 02:27:24.738075 34819 solver.cpp:239] Iteration 33120 (1.75867 iter/s, 5.68612s/10 iters), loss = 8.44552
I0523 02:27:24.738128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44552 (* 1 = 8.44552 loss)
I0523 02:27:24.802114 34819 sgd_solver.cpp:112] Iteration 33120, lr = 0.01
I0523 02:27:32.769712 34819 solver.cpp:239] Iteration 33130 (1.24514 iter/s, 8.03126s/10 iters), loss = 10.2372
I0523 02:27:32.769753 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2372 (* 1 = 10.2372 loss)
I0523 02:27:32.840893 34819 sgd_solver.cpp:112] Iteration 33130, lr = 0.01
I0523 02:27:37.811162 34819 solver.cpp:239] Iteration 33140 (1.98365 iter/s, 5.0412s/10 iters), loss = 9.04837
I0523 02:27:37.811204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04837 (* 1 = 9.04837 loss)
I0523 02:27:37.873311 34819 sgd_solver.cpp:112] Iteration 33140, lr = 0.01
I0523 02:27:43.185175 34819 solver.cpp:239] Iteration 33150 (1.8609 iter/s, 5.37374s/10 iters), loss = 8.35385
I0523 02:27:43.185220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35385 (* 1 = 8.35385 loss)
I0523 02:27:43.253237 34819 sgd_solver.cpp:112] Iteration 33150, lr = 0.01
I0523 02:27:48.159833 34819 solver.cpp:239] Iteration 33160 (2.0103 iter/s, 4.97439s/10 iters), loss = 9.07898
I0523 02:27:48.159884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07898 (* 1 = 9.07898 loss)
I0523 02:27:48.224341 34819 sgd_solver.cpp:112] Iteration 33160, lr = 0.01
I0523 02:27:52.944555 34819 solver.cpp:239] Iteration 33170 (2.0901 iter/s, 4.78447s/10 iters), loss = 9.34759
I0523 02:27:52.944802 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34759 (* 1 = 9.34759 loss)
I0523 02:27:53.019532 34819 sgd_solver.cpp:112] Iteration 33170, lr = 0.01
I0523 02:27:57.707655 34819 solver.cpp:239] Iteration 33180 (2.09966 iter/s, 4.76268s/10 iters), loss = 9.44639
I0523 02:27:57.707696 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44639 (* 1 = 9.44639 loss)
I0523 02:27:57.782218 34819 sgd_solver.cpp:112] Iteration 33180, lr = 0.01
I0523 02:28:01.005903 34819 solver.cpp:239] Iteration 33190 (3.03208 iter/s, 3.29806s/10 iters), loss = 8.56684
I0523 02:28:01.005944 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56684 (* 1 = 8.56684 loss)
I0523 02:28:01.865594 34819 sgd_solver.cpp:112] Iteration 33190, lr = 0.01
I0523 02:28:05.290377 34819 solver.cpp:239] Iteration 33200 (2.33413 iter/s, 4.28425s/10 iters), loss = 8.73045
I0523 02:28:05.290417 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73045 (* 1 = 8.73045 loss)
I0523 02:28:06.150887 34819 sgd_solver.cpp:112] Iteration 33200, lr = 0.01
I0523 02:28:12.679234 34819 solver.cpp:239] Iteration 33210 (1.35345 iter/s, 7.38851s/10 iters), loss = 10.0832
I0523 02:28:12.679275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0832 (* 1 = 10.0832 loss)
I0523 02:28:13.127393 34819 sgd_solver.cpp:112] Iteration 33210, lr = 0.01
I0523 02:28:17.135639 34819 solver.cpp:239] Iteration 33220 (2.24409 iter/s, 4.45616s/10 iters), loss = 9.33241
I0523 02:28:17.135689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33241 (* 1 = 9.33241 loss)
I0523 02:28:17.765413 34819 sgd_solver.cpp:112] Iteration 33220, lr = 0.01
I0523 02:28:22.383314 34819 solver.cpp:239] Iteration 33230 (1.9057 iter/s, 5.24741s/10 iters), loss = 8.73331
I0523 02:28:22.383358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73331 (* 1 = 8.73331 loss)
I0523 02:28:22.442188 34819 sgd_solver.cpp:112] Iteration 33230, lr = 0.01
I0523 02:28:26.046046 34819 solver.cpp:239] Iteration 33240 (2.73036 iter/s, 3.66252s/10 iters), loss = 8.49993
I0523 02:28:26.046175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49993 (* 1 = 8.49993 loss)
I0523 02:28:26.837493 34819 sgd_solver.cpp:112] Iteration 33240, lr = 0.01
I0523 02:28:31.768748 34819 solver.cpp:239] Iteration 33250 (1.74754 iter/s, 5.72232s/10 iters), loss = 8.36652
I0523 02:28:31.768802 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36652 (* 1 = 8.36652 loss)
I0523 02:28:31.842618 34819 sgd_solver.cpp:112] Iteration 33250, lr = 0.01
I0523 02:28:36.979946 34819 solver.cpp:239] Iteration 33260 (1.91904 iter/s, 5.21093s/10 iters), loss = 9.89311
I0523 02:28:36.980002 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.89311 (* 1 = 9.89311 loss)
I0523 02:28:37.049578 34819 sgd_solver.cpp:112] Iteration 33260, lr = 0.01
I0523 02:28:41.982568 34819 solver.cpp:239] Iteration 33270 (1.99906 iter/s, 5.00235s/10 iters), loss = 9.49212
I0523 02:28:41.982609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49212 (* 1 = 9.49212 loss)
I0523 02:28:42.753906 34819 sgd_solver.cpp:112] Iteration 33270, lr = 0.01
I0523 02:28:46.801132 34819 solver.cpp:239] Iteration 33280 (2.07542 iter/s, 4.8183s/10 iters), loss = 9.00461
I0523 02:28:46.801177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00461 (* 1 = 9.00461 loss)
I0523 02:28:47.669458 34819 sgd_solver.cpp:112] Iteration 33280, lr = 0.01
I0523 02:28:52.572531 34819 solver.cpp:239] Iteration 33290 (1.73277 iter/s, 5.77111s/10 iters), loss = 9.54656
I0523 02:28:52.572572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.54656 (* 1 = 9.54656 loss)
I0523 02:28:52.631556 34819 sgd_solver.cpp:112] Iteration 33290, lr = 0.01
I0523 02:28:57.718894 34819 solver.cpp:239] Iteration 33300 (1.94322 iter/s, 5.14611s/10 iters), loss = 8.82653
I0523 02:28:57.719175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82653 (* 1 = 8.82653 loss)
I0523 02:28:58.576231 34819 sgd_solver.cpp:112] Iteration 33300, lr = 0.01
I0523 02:29:02.630753 34819 solver.cpp:239] Iteration 33310 (2.03608 iter/s, 4.9114s/10 iters), loss = 8.74301
I0523 02:29:02.630805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74301 (* 1 = 8.74301 loss)
I0523 02:29:03.487442 34819 sgd_solver.cpp:112] Iteration 33310, lr = 0.01
I0523 02:29:07.058971 34819 solver.cpp:239] Iteration 33320 (2.25837 iter/s, 4.42797s/10 iters), loss = 9.00658
I0523 02:29:07.059033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00658 (* 1 = 9.00658 loss)
I0523 02:29:07.928576 34819 sgd_solver.cpp:112] Iteration 33320, lr = 0.01
I0523 02:29:11.202554 34819 solver.cpp:239] Iteration 33330 (2.41351 iter/s, 4.14334s/10 iters), loss = 8.62217
I0523 02:29:11.202595 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62217 (* 1 = 8.62217 loss)
I0523 02:29:11.257447 34819 sgd_solver.cpp:112] Iteration 33330, lr = 0.01
I0523 02:29:16.108851 34819 solver.cpp:239] Iteration 33340 (2.0383 iter/s, 4.90604s/10 iters), loss = 8.50978
I0523 02:29:16.108916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50978 (* 1 = 8.50978 loss)
I0523 02:29:16.920630 34819 sgd_solver.cpp:112] Iteration 33340, lr = 0.01
I0523 02:29:20.163491 34819 solver.cpp:239] Iteration 33350 (2.46646 iter/s, 4.0544s/10 iters), loss = 9.38559
I0523 02:29:20.163539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38559 (* 1 = 9.38559 loss)
I0523 02:29:20.715570 34819 sgd_solver.cpp:112] Iteration 33350, lr = 0.01
I0523 02:29:25.065862 34819 solver.cpp:239] Iteration 33360 (2.03993 iter/s, 4.90212s/10 iters), loss = 8.07238
I0523 02:29:25.065904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07238 (* 1 = 8.07238 loss)
I0523 02:29:25.777855 34819 sgd_solver.cpp:112] Iteration 33360, lr = 0.01
I0523 02:29:30.771142 34819 solver.cpp:239] Iteration 33370 (1.75285 iter/s, 5.70499s/10 iters), loss = 8.91203
I0523 02:29:30.771337 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91203 (* 1 = 8.91203 loss)
I0523 02:29:31.561846 34819 sgd_solver.cpp:112] Iteration 33370, lr = 0.01
I0523 02:29:35.834357 34819 solver.cpp:239] Iteration 33380 (1.97518 iter/s, 5.06282s/10 iters), loss = 9.00804
I0523 02:29:35.834412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00804 (* 1 = 9.00804 loss)
I0523 02:29:36.648056 34819 sgd_solver.cpp:112] Iteration 33380, lr = 0.01
I0523 02:29:42.139526 34819 solver.cpp:239] Iteration 33390 (1.58608 iter/s, 6.30485s/10 iters), loss = 8.15756
I0523 02:29:42.139578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15756 (* 1 = 8.15756 loss)
I0523 02:29:42.908766 34819 sgd_solver.cpp:112] Iteration 33390, lr = 0.01
I0523 02:29:49.038342 34819 solver.cpp:239] Iteration 33400 (1.4496 iter/s, 6.89845s/10 iters), loss = 9.32424
I0523 02:29:49.038383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32424 (* 1 = 9.32424 loss)
I0523 02:29:49.109275 34819 sgd_solver.cpp:112] Iteration 33400, lr = 0.01
I0523 02:29:52.912818 34819 solver.cpp:239] Iteration 33410 (2.58114 iter/s, 3.87426s/10 iters), loss = 8.9764
I0523 02:29:52.912868 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9764 (* 1 = 8.9764 loss)
I0523 02:29:53.701145 34819 sgd_solver.cpp:112] Iteration 33410, lr = 0.01
I0523 02:29:58.229547 34819 solver.cpp:239] Iteration 33420 (1.88095 iter/s, 5.31645s/10 iters), loss = 8.87165
I0523 02:29:58.229591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87165 (* 1 = 8.87165 loss)
I0523 02:29:59.098450 34819 sgd_solver.cpp:112] Iteration 33420, lr = 0.01
I0523 02:30:04.381170 34819 solver.cpp:239] Iteration 33430 (1.62567 iter/s, 6.15132s/10 iters), loss = 8.98075
I0523 02:30:04.381433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98075 (* 1 = 8.98075 loss)
I0523 02:30:04.448139 34819 sgd_solver.cpp:112] Iteration 33430, lr = 0.01
I0523 02:30:08.582837 34819 solver.cpp:239] Iteration 33440 (2.38025 iter/s, 4.20123s/10 iters), loss = 8.82824
I0523 02:30:08.582901 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82824 (* 1 = 8.82824 loss)
I0523 02:30:08.651263 34819 sgd_solver.cpp:112] Iteration 33440, lr = 0.01
I0523 02:30:12.622164 34819 solver.cpp:239] Iteration 33450 (2.47581 iter/s, 4.03909s/10 iters), loss = 9.56335
I0523 02:30:12.622208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56335 (* 1 = 9.56335 loss)
I0523 02:30:12.686822 34819 sgd_solver.cpp:112] Iteration 33450, lr = 0.01
I0523 02:30:18.033367 34819 solver.cpp:239] Iteration 33460 (1.84812 iter/s, 5.41091s/10 iters), loss = 8.68418
I0523 02:30:18.033437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68418 (* 1 = 8.68418 loss)
I0523 02:30:18.767894 34819 sgd_solver.cpp:112] Iteration 33460, lr = 0.01
I0523 02:30:23.057045 34819 solver.cpp:239] Iteration 33470 (1.99068 iter/s, 5.02341s/10 iters), loss = 9.32582
I0523 02:30:23.057097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32582 (* 1 = 9.32582 loss)
I0523 02:30:23.134882 34819 sgd_solver.cpp:112] Iteration 33470, lr = 0.01
I0523 02:30:27.412796 34819 solver.cpp:239] Iteration 33480 (2.29595 iter/s, 4.3555s/10 iters), loss = 8.44769
I0523 02:30:27.412848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44769 (* 1 = 8.44769 loss)
I0523 02:30:27.481521 34819 sgd_solver.cpp:112] Iteration 33480, lr = 0.01
I0523 02:30:31.076031 34819 solver.cpp:239] Iteration 33490 (2.72999 iter/s, 3.66302s/10 iters), loss = 7.87393
I0523 02:30:31.076072 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87393 (* 1 = 7.87393 loss)
I0523 02:30:31.917227 34819 sgd_solver.cpp:112] Iteration 33490, lr = 0.01
I0523 02:30:35.976157 34819 solver.cpp:239] Iteration 33500 (2.04087 iter/s, 4.89988s/10 iters), loss = 7.97961
I0523 02:30:35.976306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97961 (* 1 = 7.97961 loss)
I0523 02:30:36.036007 34819 sgd_solver.cpp:112] Iteration 33500, lr = 0.01
I0523 02:30:37.825093 34819 solver.cpp:239] Iteration 33510 (5.40919 iter/s, 1.8487s/10 iters), loss = 8.82361
I0523 02:30:37.825143 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82361 (* 1 = 8.82361 loss)
I0523 02:30:38.607831 34819 sgd_solver.cpp:112] Iteration 33510, lr = 0.01
I0523 02:30:41.834959 34819 solver.cpp:239] Iteration 33520 (2.49398 iter/s, 4.00965s/10 iters), loss = 8.56347
I0523 02:30:41.835000 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56347 (* 1 = 8.56347 loss)
I0523 02:30:41.890646 34819 sgd_solver.cpp:112] Iteration 33520, lr = 0.01
I0523 02:30:46.249202 34819 solver.cpp:239] Iteration 33530 (2.26551 iter/s, 4.41402s/10 iters), loss = 8.41246
I0523 02:30:46.249244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41246 (* 1 = 8.41246 loss)
I0523 02:30:47.036389 34819 sgd_solver.cpp:112] Iteration 33530, lr = 0.01
I0523 02:30:52.712640 34819 solver.cpp:239] Iteration 33540 (1.54724 iter/s, 6.46312s/10 iters), loss = 8.97449
I0523 02:30:52.712700 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97449 (* 1 = 8.97449 loss)
I0523 02:30:53.567806 34819 sgd_solver.cpp:112] Iteration 33540, lr = 0.01
I0523 02:30:57.799063 34819 solver.cpp:239] Iteration 33550 (1.96613 iter/s, 5.08614s/10 iters), loss = 9.13424
I0523 02:30:57.799116 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13424 (* 1 = 9.13424 loss)
I0523 02:30:58.620903 34819 sgd_solver.cpp:112] Iteration 33550, lr = 0.01
I0523 02:31:02.698973 34819 solver.cpp:239] Iteration 33560 (2.04096 iter/s, 4.89965s/10 iters), loss = 8.28168
I0523 02:31:02.699030 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28168 (* 1 = 8.28168 loss)
I0523 02:31:02.759069 34819 sgd_solver.cpp:112] Iteration 33560, lr = 0.01
I0523 02:31:06.194842 34819 solver.cpp:239] Iteration 33570 (2.86069 iter/s, 3.49566s/10 iters), loss = 8.7521
I0523 02:31:06.194983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7521 (* 1 = 8.7521 loss)
I0523 02:31:06.263536 34819 sgd_solver.cpp:112] Iteration 33570, lr = 0.01
I0523 02:31:09.968964 34819 solver.cpp:239] Iteration 33580 (2.64983 iter/s, 3.77382s/10 iters), loss = 8.95019
I0523 02:31:09.969007 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95019 (* 1 = 8.95019 loss)
I0523 02:31:10.025846 34819 sgd_solver.cpp:112] Iteration 33580, lr = 0.01
I0523 02:31:12.687005 34819 solver.cpp:239] Iteration 33590 (3.67934 iter/s, 2.71788s/10 iters), loss = 9.31836
I0523 02:31:12.687050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31836 (* 1 = 9.31836 loss)
I0523 02:31:13.334878 34819 sgd_solver.cpp:112] Iteration 33590, lr = 0.01
I0523 02:31:18.274247 34819 solver.cpp:239] Iteration 33600 (1.78988 iter/s, 5.58697s/10 iters), loss = 8.99648
I0523 02:31:18.274288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99648 (* 1 = 8.99648 loss)
I0523 02:31:19.108099 34819 sgd_solver.cpp:112] Iteration 33600, lr = 0.01
I0523 02:31:24.179477 34819 solver.cpp:239] Iteration 33610 (1.69349 iter/s, 5.90495s/10 iters), loss = 8.23764
I0523 02:31:24.179519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23764 (* 1 = 8.23764 loss)
I0523 02:31:24.983204 34819 sgd_solver.cpp:112] Iteration 33610, lr = 0.01
I0523 02:31:30.219514 34819 solver.cpp:239] Iteration 33620 (1.6557 iter/s, 6.03975s/10 iters), loss = 8.01157
I0523 02:31:30.219558 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01157 (* 1 = 8.01157 loss)
I0523 02:31:30.292075 34819 sgd_solver.cpp:112] Iteration 33620, lr = 0.01
I0523 02:31:34.317873 34819 solver.cpp:239] Iteration 33630 (2.44013 iter/s, 4.09814s/10 iters), loss = 8.44994
I0523 02:31:34.317914 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44994 (* 1 = 8.44994 loss)
I0523 02:31:34.378319 34819 sgd_solver.cpp:112] Iteration 33630, lr = 0.01
I0523 02:31:39.716953 34819 solver.cpp:239] Iteration 33640 (1.85226 iter/s, 5.39881s/10 iters), loss = 8.11745
I0523 02:31:39.717066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11745 (* 1 = 8.11745 loss)
I0523 02:31:39.767853 34819 sgd_solver.cpp:112] Iteration 33640, lr = 0.01
I0523 02:31:46.186404 34819 solver.cpp:239] Iteration 33650 (1.54582 iter/s, 6.46907s/10 iters), loss = 9.08501
I0523 02:31:46.186460 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08501 (* 1 = 9.08501 loss)
I0523 02:31:46.259450 34819 sgd_solver.cpp:112] Iteration 33650, lr = 0.01
I0523 02:31:51.826555 34819 solver.cpp:239] Iteration 33660 (1.7731 iter/s, 5.63985s/10 iters), loss = 8.60249
I0523 02:31:51.826614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60249 (* 1 = 8.60249 loss)
I0523 02:31:52.692458 34819 sgd_solver.cpp:112] Iteration 33660, lr = 0.01
I0523 02:31:57.529953 34819 solver.cpp:239] Iteration 33670 (1.75343 iter/s, 5.70311s/10 iters), loss = 8.92456
I0523 02:31:57.530000 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92456 (* 1 = 8.92456 loss)
I0523 02:31:57.588220 34819 sgd_solver.cpp:112] Iteration 33670, lr = 0.01
I0523 02:32:02.180742 34819 solver.cpp:239] Iteration 33680 (2.15029 iter/s, 4.65054s/10 iters), loss = 8.88947
I0523 02:32:02.180781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88947 (* 1 = 8.88947 loss)
I0523 02:32:02.241619 34819 sgd_solver.cpp:112] Iteration 33680, lr = 0.01
I0523 02:32:07.000921 34819 solver.cpp:239] Iteration 33690 (2.07472 iter/s, 4.81993s/10 iters), loss = 9.04149
I0523 02:32:07.000975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04149 (* 1 = 9.04149 loss)
I0523 02:32:07.064673 34819 sgd_solver.cpp:112] Iteration 33690, lr = 0.01
I0523 02:32:09.668815 34819 solver.cpp:239] Iteration 33700 (3.74852 iter/s, 2.66772s/10 iters), loss = 7.7394
I0523 02:32:09.668866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7394 (* 1 = 7.7394 loss)
I0523 02:32:10.329454 34819 sgd_solver.cpp:112] Iteration 33700, lr = 0.01
I0523 02:32:14.460671 34819 solver.cpp:239] Iteration 33710 (2.087 iter/s, 4.79157s/10 iters), loss = 9.37895
I0523 02:32:14.460721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37895 (* 1 = 9.37895 loss)
I0523 02:32:14.517320 34819 sgd_solver.cpp:112] Iteration 33710, lr = 0.01
I0523 02:32:19.322774 34819 solver.cpp:239] Iteration 33720 (2.05683 iter/s, 4.86184s/10 iters), loss = 8.85561
I0523 02:32:19.322826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85561 (* 1 = 8.85561 loss)
I0523 02:32:20.073091 34819 sgd_solver.cpp:112] Iteration 33720, lr = 0.01
I0523 02:32:23.954627 34819 solver.cpp:239] Iteration 33730 (2.15908 iter/s, 4.6316s/10 iters), loss = 8.6929
I0523 02:32:23.954670 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6929 (* 1 = 8.6929 loss)
I0523 02:32:24.026219 34819 sgd_solver.cpp:112] Iteration 33730, lr = 0.01
I0523 02:32:28.959146 34819 solver.cpp:239] Iteration 33740 (1.99829 iter/s, 5.00427s/10 iters), loss = 8.61206
I0523 02:32:28.959193 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61206 (* 1 = 8.61206 loss)
I0523 02:32:29.027711 34819 sgd_solver.cpp:112] Iteration 33740, lr = 0.01
I0523 02:32:32.365847 34819 solver.cpp:239] Iteration 33750 (2.93556 iter/s, 3.4065s/10 iters), loss = 8.59499
I0523 02:32:32.365887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59499 (* 1 = 8.59499 loss)
I0523 02:32:33.116771 34819 sgd_solver.cpp:112] Iteration 33750, lr = 0.01
I0523 02:32:37.894651 34819 solver.cpp:239] Iteration 33760 (1.8088 iter/s, 5.52853s/10 iters), loss = 8.49477
I0523 02:32:37.894722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49477 (* 1 = 8.49477 loss)
I0523 02:32:37.970226 34819 sgd_solver.cpp:112] Iteration 33760, lr = 0.01
I0523 02:32:42.334581 34819 solver.cpp:239] Iteration 33770 (2.25241 iter/s, 4.4397s/10 iters), loss = 9.01696
I0523 02:32:42.334725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01696 (* 1 = 9.01696 loss)
I0523 02:32:43.159993 34819 sgd_solver.cpp:112] Iteration 33770, lr = 0.01
I0523 02:32:48.860927 34819 solver.cpp:239] Iteration 33780 (1.53235 iter/s, 6.52593s/10 iters), loss = 8.82292
I0523 02:32:48.860977 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82292 (* 1 = 8.82292 loss)
I0523 02:32:48.940390 34819 sgd_solver.cpp:112] Iteration 33780, lr = 0.01
I0523 02:32:55.652727 34819 solver.cpp:239] Iteration 33790 (1.47243 iter/s, 6.79148s/10 iters), loss = 8.96913
I0523 02:32:55.652781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96913 (* 1 = 8.96913 loss)
I0523 02:32:56.090713 34819 sgd_solver.cpp:112] Iteration 33790, lr = 0.01
I0523 02:33:01.573220 34819 solver.cpp:239] Iteration 33800 (1.68914 iter/s, 5.92018s/10 iters), loss = 8.82264
I0523 02:33:01.573272 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82264 (* 1 = 8.82264 loss)
I0523 02:33:02.333247 34819 sgd_solver.cpp:112] Iteration 33800, lr = 0.01
I0523 02:33:07.239472 34819 solver.cpp:239] Iteration 33810 (1.76493 iter/s, 5.66596s/10 iters), loss = 10.0873
I0523 02:33:07.239521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0873 (* 1 = 10.0873 loss)
I0523 02:33:07.861943 34819 sgd_solver.cpp:112] Iteration 33810, lr = 0.01
I0523 02:33:11.808368 34819 solver.cpp:239] Iteration 33820 (2.18883 iter/s, 4.56865s/10 iters), loss = 9.50363
I0523 02:33:11.808411 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50363 (* 1 = 9.50363 loss)
I0523 02:33:11.864717 34819 sgd_solver.cpp:112] Iteration 33820, lr = 0.01
I0523 02:33:16.546676 34819 solver.cpp:239] Iteration 33830 (2.11057 iter/s, 4.73806s/10 iters), loss = 7.97584
I0523 02:33:16.546810 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97584 (* 1 = 7.97584 loss)
I0523 02:33:16.610450 34819 sgd_solver.cpp:112] Iteration 33830, lr = 0.01
I0523 02:33:20.710326 34819 solver.cpp:239] Iteration 33840 (2.40194 iter/s, 4.1633s/10 iters), loss = 9.71718
I0523 02:33:20.710376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71718 (* 1 = 9.71718 loss)
I0523 02:33:21.355145 34819 sgd_solver.cpp:112] Iteration 33840, lr = 0.01
I0523 02:33:26.786329 34819 solver.cpp:239] Iteration 33850 (1.64591 iter/s, 6.07568s/10 iters), loss = 8.96622
I0523 02:33:26.786391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96622 (* 1 = 8.96622 loss)
I0523 02:33:27.659185 34819 sgd_solver.cpp:112] Iteration 33850, lr = 0.01
I0523 02:33:33.399958 34819 solver.cpp:239] Iteration 33860 (1.51211 iter/s, 6.61328s/10 iters), loss = 9.48037
I0523 02:33:33.400017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48037 (* 1 = 9.48037 loss)
I0523 02:33:33.470345 34819 sgd_solver.cpp:112] Iteration 33860, lr = 0.01
I0523 02:33:38.245719 34819 solver.cpp:239] Iteration 33870 (2.06377 iter/s, 4.84551s/10 iters), loss = 8.2052
I0523 02:33:38.245769 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2052 (* 1 = 8.2052 loss)
I0523 02:33:38.307412 34819 sgd_solver.cpp:112] Iteration 33870, lr = 0.01
I0523 02:33:43.429716 34819 solver.cpp:239] Iteration 33880 (1.92912 iter/s, 5.18372s/10 iters), loss = 8.75028
I0523 02:33:43.429764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75028 (* 1 = 8.75028 loss)
I0523 02:33:44.152840 34819 sgd_solver.cpp:112] Iteration 33880, lr = 0.01
I0523 02:33:48.421185 34819 solver.cpp:239] Iteration 33890 (2.00353 iter/s, 4.99119s/10 iters), loss = 8.24299
I0523 02:33:48.421382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24299 (* 1 = 8.24299 loss)
I0523 02:33:49.195003 34819 sgd_solver.cpp:112] Iteration 33890, lr = 0.01
I0523 02:33:52.629081 34819 solver.cpp:239] Iteration 33900 (2.37668 iter/s, 4.20755s/10 iters), loss = 8.28029
I0523 02:33:52.629123 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28029 (* 1 = 8.28029 loss)
I0523 02:33:53.319164 34819 sgd_solver.cpp:112] Iteration 33900, lr = 0.01
I0523 02:33:58.510372 34819 solver.cpp:239] Iteration 33910 (1.70039 iter/s, 5.88101s/10 iters), loss = 9.23952
I0523 02:33:58.510413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23952 (* 1 = 9.23952 loss)
I0523 02:33:58.583777 34819 sgd_solver.cpp:112] Iteration 33910, lr = 0.01
I0523 02:34:02.615820 34819 solver.cpp:239] Iteration 33920 (2.43592 iter/s, 4.10523s/10 iters), loss = 8.58089
I0523 02:34:02.615865 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58089 (* 1 = 8.58089 loss)
I0523 02:34:03.438037 34819 sgd_solver.cpp:112] Iteration 33920, lr = 0.01
I0523 02:34:10.116542 34819 solver.cpp:239] Iteration 33930 (1.33327 iter/s, 7.50038s/10 iters), loss = 8.87253
I0523 02:34:10.116583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87253 (* 1 = 8.87253 loss)
I0523 02:34:10.939069 34819 sgd_solver.cpp:112] Iteration 33930, lr = 0.01
I0523 02:34:16.215229 34819 solver.cpp:239] Iteration 33940 (1.63978 iter/s, 6.09838s/10 iters), loss = 9.18694
I0523 02:34:16.215289 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18694 (* 1 = 9.18694 loss)
I0523 02:34:16.251760 34819 sgd_solver.cpp:112] Iteration 33940, lr = 0.01
I0523 02:34:17.542810 34819 solver.cpp:239] Iteration 33950 (7.53323 iter/s, 1.32745s/10 iters), loss = 9.03112
I0523 02:34:17.542861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03112 (* 1 = 9.03112 loss)
I0523 02:34:18.242967 34819 sgd_solver.cpp:112] Iteration 33950, lr = 0.01
I0523 02:34:21.816504 34819 solver.cpp:239] Iteration 33960 (2.34003 iter/s, 4.27345s/10 iters), loss = 8.2973
I0523 02:34:21.816728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2973 (* 1 = 8.2973 loss)
I0523 02:34:22.112720 34819 sgd_solver.cpp:112] Iteration 33960, lr = 0.01
I0523 02:34:25.535691 34819 solver.cpp:239] Iteration 33970 (2.68902 iter/s, 3.71882s/10 iters), loss = 9.70318
I0523 02:34:25.535732 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70318 (* 1 = 9.70318 loss)
I0523 02:34:26.397928 34819 sgd_solver.cpp:112] Iteration 33970, lr = 0.01
I0523 02:34:32.030331 34819 solver.cpp:239] Iteration 33980 (1.53981 iter/s, 6.49432s/10 iters), loss = 9.58564
I0523 02:34:32.030382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58564 (* 1 = 9.58564 loss)
I0523 02:34:32.099229 34819 sgd_solver.cpp:112] Iteration 33980, lr = 0.01
I0523 02:34:35.464665 34819 solver.cpp:239] Iteration 33990 (2.91194 iter/s, 3.43414s/10 iters), loss = 8.26119
I0523 02:34:35.464715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26119 (* 1 = 8.26119 loss)
I0523 02:34:35.533135 34819 sgd_solver.cpp:112] Iteration 33990, lr = 0.01
I0523 02:34:39.006201 34819 solver.cpp:239] Iteration 34000 (2.8238 iter/s, 3.54133s/10 iters), loss = 9.27085
I0523 02:34:39.006242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27085 (* 1 = 9.27085 loss)
I0523 02:34:39.067319 34819 sgd_solver.cpp:112] Iteration 34000, lr = 0.01
I0523 02:34:44.036139 34819 solver.cpp:239] Iteration 34010 (1.9882 iter/s, 5.02968s/10 iters), loss = 7.68243
I0523 02:34:44.036192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68243 (* 1 = 7.68243 loss)
I0523 02:34:44.107282 34819 sgd_solver.cpp:112] Iteration 34010, lr = 0.01
I0523 02:34:51.331171 34819 solver.cpp:239] Iteration 34020 (1.37086 iter/s, 7.29468s/10 iters), loss = 8.92069
I0523 02:34:51.331214 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92069 (* 1 = 8.92069 loss)
I0523 02:34:51.388157 34819 sgd_solver.cpp:112] Iteration 34020, lr = 0.01
I0523 02:34:55.512055 34819 solver.cpp:239] Iteration 34030 (2.39196 iter/s, 4.18067s/10 iters), loss = 8.99947
I0523 02:34:55.512320 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99947 (* 1 = 8.99947 loss)
I0523 02:34:55.577430 34819 sgd_solver.cpp:112] Iteration 34030, lr = 0.01
I0523 02:35:01.820520 34819 solver.cpp:239] Iteration 34040 (1.5853 iter/s, 6.30797s/10 iters), loss = 8.97136
I0523 02:35:01.820562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97136 (* 1 = 8.97136 loss)
I0523 02:35:02.589952 34819 sgd_solver.cpp:112] Iteration 34040, lr = 0.01
I0523 02:35:06.207707 34819 solver.cpp:239] Iteration 34050 (2.27949 iter/s, 4.38695s/10 iters), loss = 8.59135
I0523 02:35:06.207759 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59135 (* 1 = 8.59135 loss)
I0523 02:35:06.993394 34819 sgd_solver.cpp:112] Iteration 34050, lr = 0.01
I0523 02:35:10.452520 34819 solver.cpp:239] Iteration 34060 (2.35594 iter/s, 4.24459s/10 iters), loss = 8.65365
I0523 02:35:10.452563 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65365 (* 1 = 8.65365 loss)
I0523 02:35:11.059628 34819 sgd_solver.cpp:112] Iteration 34060, lr = 0.01
I0523 02:35:16.488452 34819 solver.cpp:239] Iteration 34070 (1.65682 iter/s, 6.03564s/10 iters), loss = 8.68468
I0523 02:35:16.488502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68468 (* 1 = 8.68468 loss)
I0523 02:35:16.563947 34819 sgd_solver.cpp:112] Iteration 34070, lr = 0.01
I0523 02:35:19.750421 34819 solver.cpp:239] Iteration 34080 (3.06581 iter/s, 3.26178s/10 iters), loss = 8.69378
I0523 02:35:19.750463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69378 (* 1 = 8.69378 loss)
I0523 02:35:20.565598 34819 sgd_solver.cpp:112] Iteration 34080, lr = 0.01
I0523 02:35:25.000768 34819 solver.cpp:239] Iteration 34090 (1.90473 iter/s, 5.25008s/10 iters), loss = 8.70171
I0523 02:35:25.000815 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70171 (* 1 = 8.70171 loss)
I0523 02:35:25.835002 34819 sgd_solver.cpp:112] Iteration 34090, lr = 0.01
I0523 02:35:28.199338 34819 solver.cpp:239] Iteration 34100 (3.12659 iter/s, 3.19837s/10 iters), loss = 8.89096
I0523 02:35:28.199390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89096 (* 1 = 8.89096 loss)
I0523 02:35:28.292661 34819 sgd_solver.cpp:112] Iteration 34100, lr = 0.01
I0523 02:35:30.975577 34819 solver.cpp:239] Iteration 34110 (3.60222 iter/s, 2.77607s/10 iters), loss = 9.03189
I0523 02:35:30.975620 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03189 (* 1 = 9.03189 loss)
I0523 02:35:31.050817 34819 sgd_solver.cpp:112] Iteration 34110, lr = 0.01
I0523 02:35:34.133476 34819 solver.cpp:239] Iteration 34120 (3.16684 iter/s, 3.15772s/10 iters), loss = 8.36085
I0523 02:35:34.133523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36085 (* 1 = 8.36085 loss)
I0523 02:35:34.189024 34819 sgd_solver.cpp:112] Iteration 34120, lr = 0.01
I0523 02:35:40.010605 34819 solver.cpp:239] Iteration 34130 (1.70159 iter/s, 5.87684s/10 iters), loss = 8.98024
I0523 02:35:40.010654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98024 (* 1 = 8.98024 loss)
I0523 02:35:40.064898 34819 sgd_solver.cpp:112] Iteration 34130, lr = 0.01
I0523 02:35:46.798445 34819 solver.cpp:239] Iteration 34140 (1.4733 iter/s, 6.7875s/10 iters), loss = 8.81391
I0523 02:35:46.798501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81391 (* 1 = 8.81391 loss)
I0523 02:35:46.869987 34819 sgd_solver.cpp:112] Iteration 34140, lr = 0.01
I0523 02:35:50.932081 34819 solver.cpp:239] Iteration 34150 (2.41932 iter/s, 4.13339s/10 iters), loss = 9.01976
I0523 02:35:50.932137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01976 (* 1 = 9.01976 loss)
I0523 02:35:50.995378 34819 sgd_solver.cpp:112] Iteration 34150, lr = 0.01
I0523 02:35:56.659628 34819 solver.cpp:239] Iteration 34160 (1.74604 iter/s, 5.72724s/10 iters), loss = 8.73632
I0523 02:35:56.659926 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73632 (* 1 = 8.73632 loss)
I0523 02:35:56.730329 34819 sgd_solver.cpp:112] Iteration 34160, lr = 0.01
I0523 02:35:59.168144 34819 solver.cpp:239] Iteration 34170 (3.98707 iter/s, 2.50811s/10 iters), loss = 8.75078
I0523 02:35:59.168198 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75078 (* 1 = 8.75078 loss)
I0523 02:35:59.694408 34819 sgd_solver.cpp:112] Iteration 34170, lr = 0.01
I0523 02:36:02.376926 34819 solver.cpp:239] Iteration 34180 (3.11663 iter/s, 3.20859s/10 iters), loss = 8.81578
I0523 02:36:02.376986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81578 (* 1 = 8.81578 loss)
I0523 02:36:02.439389 34819 sgd_solver.cpp:112] Iteration 34180, lr = 0.01
I0523 02:36:07.721532 34819 solver.cpp:239] Iteration 34190 (1.87114 iter/s, 5.34432s/10 iters), loss = 9.07639
I0523 02:36:07.721583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07639 (* 1 = 9.07639 loss)
I0523 02:36:08.471312 34819 sgd_solver.cpp:112] Iteration 34190, lr = 0.01
I0523 02:36:13.110368 34819 solver.cpp:239] Iteration 34200 (1.85578 iter/s, 5.38856s/10 iters), loss = 8.32652
I0523 02:36:13.110411 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32652 (* 1 = 8.32652 loss)
I0523 02:36:13.175477 34819 sgd_solver.cpp:112] Iteration 34200, lr = 0.01
I0523 02:36:17.315862 34819 solver.cpp:239] Iteration 34210 (2.37797 iter/s, 4.20527s/10 iters), loss = 8.59273
I0523 02:36:17.315914 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59273 (* 1 = 8.59273 loss)
I0523 02:36:18.121098 34819 sgd_solver.cpp:112] Iteration 34210, lr = 0.01
I0523 02:36:23.270190 34819 solver.cpp:239] Iteration 34220 (1.67953 iter/s, 5.95404s/10 iters), loss = 8.63564
I0523 02:36:23.270229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63564 (* 1 = 8.63564 loss)
I0523 02:36:23.326014 34819 sgd_solver.cpp:112] Iteration 34220, lr = 0.01
I0523 02:36:27.588687 34819 solver.cpp:239] Iteration 34230 (2.31574 iter/s, 4.31827s/10 iters), loss = 8.18223
I0523 02:36:27.588907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18223 (* 1 = 8.18223 loss)
I0523 02:36:28.417106 34819 sgd_solver.cpp:112] Iteration 34230, lr = 0.01
I0523 02:36:32.333576 34819 solver.cpp:239] Iteration 34240 (2.10771 iter/s, 4.74449s/10 iters), loss = 8.23019
I0523 02:36:32.333628 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23019 (* 1 = 8.23019 loss)
I0523 02:36:32.412854 34819 sgd_solver.cpp:112] Iteration 34240, lr = 0.01
I0523 02:36:36.015453 34819 solver.cpp:239] Iteration 34250 (2.71616 iter/s, 3.68167s/10 iters), loss = 8.25658
I0523 02:36:36.015506 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25658 (* 1 = 8.25658 loss)
I0523 02:36:36.083393 34819 sgd_solver.cpp:112] Iteration 34250, lr = 0.01
I0523 02:36:40.964992 34819 solver.cpp:239] Iteration 34260 (2.02049 iter/s, 4.94928s/10 iters), loss = 8.9028
I0523 02:36:40.965036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9028 (* 1 = 8.9028 loss)
I0523 02:36:41.418212 34819 sgd_solver.cpp:112] Iteration 34260, lr = 0.01
I0523 02:36:45.499570 34819 solver.cpp:239] Iteration 34270 (2.20539 iter/s, 4.53434s/10 iters), loss = 9.85841
I0523 02:36:45.499617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.85841 (* 1 = 9.85841 loss)
I0523 02:36:46.083351 34819 sgd_solver.cpp:112] Iteration 34270, lr = 0.01
I0523 02:36:51.130553 34819 solver.cpp:239] Iteration 34280 (1.77598 iter/s, 5.63069s/10 iters), loss = 9.19845
I0523 02:36:51.130609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19845 (* 1 = 9.19845 loss)
I0523 02:36:51.188833 34819 sgd_solver.cpp:112] Iteration 34280, lr = 0.01
I0523 02:36:54.587083 34819 solver.cpp:239] Iteration 34290 (2.89324 iter/s, 3.45633s/10 iters), loss = 8.96379
I0523 02:36:54.587141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96379 (* 1 = 8.96379 loss)
I0523 02:36:54.658597 34819 sgd_solver.cpp:112] Iteration 34290, lr = 0.01
I0523 02:36:59.375727 34819 solver.cpp:239] Iteration 34300 (2.08838 iter/s, 4.78839s/10 iters), loss = 8.85479
I0523 02:36:59.375871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85479 (* 1 = 8.85479 loss)
I0523 02:36:59.926524 34819 sgd_solver.cpp:112] Iteration 34300, lr = 0.01
I0523 02:37:03.700770 34819 solver.cpp:239] Iteration 34310 (2.3123 iter/s, 4.32471s/10 iters), loss = 9.25079
I0523 02:37:03.700824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25079 (* 1 = 9.25079 loss)
I0523 02:37:03.773494 34819 sgd_solver.cpp:112] Iteration 34310, lr = 0.01
I0523 02:37:09.837617 34819 solver.cpp:239] Iteration 34320 (1.62958 iter/s, 6.13654s/10 iters), loss = 8.36158
I0523 02:37:09.837661 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36158 (* 1 = 8.36158 loss)
I0523 02:37:09.911134 34819 sgd_solver.cpp:112] Iteration 34320, lr = 0.01
I0523 02:37:15.030488 34819 solver.cpp:239] Iteration 34330 (1.92582 iter/s, 5.1926s/10 iters), loss = 8.99091
I0523 02:37:15.030527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99091 (* 1 = 8.99091 loss)
I0523 02:37:15.107815 34819 sgd_solver.cpp:112] Iteration 34330, lr = 0.01
I0523 02:37:20.789562 34819 solver.cpp:239] Iteration 34340 (1.73647 iter/s, 5.7588s/10 iters), loss = 9.0401
I0523 02:37:20.789602 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0401 (* 1 = 9.0401 loss)
I0523 02:37:21.367631 34819 sgd_solver.cpp:112] Iteration 34340, lr = 0.01
I0523 02:37:28.350159 34819 solver.cpp:239] Iteration 34350 (1.32271 iter/s, 7.56024s/10 iters), loss = 9.02193
I0523 02:37:28.350214 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02193 (* 1 = 9.02193 loss)
I0523 02:37:28.419306 34819 sgd_solver.cpp:112] Iteration 34350, lr = 0.01
I0523 02:37:33.328276 34819 solver.cpp:239] Iteration 34360 (2.0089 iter/s, 4.97785s/10 iters), loss = 9.68606
I0523 02:37:33.328390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68606 (* 1 = 9.68606 loss)
I0523 02:37:33.602227 34819 sgd_solver.cpp:112] Iteration 34360, lr = 0.01
I0523 02:37:39.101320 34819 solver.cpp:239] Iteration 34370 (1.73229 iter/s, 5.7727s/10 iters), loss = 9.91209
I0523 02:37:39.101361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.91209 (* 1 = 9.91209 loss)
I0523 02:37:39.948417 34819 sgd_solver.cpp:112] Iteration 34370, lr = 0.01
I0523 02:37:45.029410 34819 solver.cpp:239] Iteration 34380 (1.68697 iter/s, 5.9278s/10 iters), loss = 9.77134
I0523 02:37:45.029458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.77134 (* 1 = 9.77134 loss)
I0523 02:37:45.847647 34819 sgd_solver.cpp:112] Iteration 34380, lr = 0.01
I0523 02:37:50.345772 34819 solver.cpp:239] Iteration 34390 (1.88109 iter/s, 5.31608s/10 iters), loss = 8.76764
I0523 02:37:50.345813 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76764 (* 1 = 8.76764 loss)
I0523 02:37:50.988862 34819 sgd_solver.cpp:112] Iteration 34390, lr = 0.01
I0523 02:37:53.584360 34819 solver.cpp:239] Iteration 34400 (3.08794 iter/s, 3.23841s/10 iters), loss = 10.034
I0523 02:37:53.584409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.034 (* 1 = 10.034 loss)
I0523 02:37:53.648383 34819 sgd_solver.cpp:112] Iteration 34400, lr = 0.01
I0523 02:37:58.034111 34819 solver.cpp:239] Iteration 34410 (2.24744 iter/s, 4.44951s/10 iters), loss = 9.1457
I0523 02:37:58.034157 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1457 (* 1 = 9.1457 loss)
I0523 02:37:58.591269 34819 sgd_solver.cpp:112] Iteration 34410, lr = 0.01
I0523 02:38:02.708989 34819 solver.cpp:239] Iteration 34420 (2.1392 iter/s, 4.67463s/10 iters), loss = 8.88675
I0523 02:38:02.709050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88675 (* 1 = 8.88675 loss)
I0523 02:38:03.564491 34819 sgd_solver.cpp:112] Iteration 34420, lr = 0.01
I0523 02:38:08.965447 34819 solver.cpp:239] Iteration 34430 (1.59843 iter/s, 6.25615s/10 iters), loss = 9.14902
I0523 02:38:08.965489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14902 (* 1 = 9.14902 loss)
I0523 02:38:09.029304 34819 sgd_solver.cpp:112] Iteration 34430, lr = 0.01
I0523 02:38:12.905398 34819 solver.cpp:239] Iteration 34440 (2.53824 iter/s, 3.93974s/10 iters), loss = 9.18009
I0523 02:38:12.905452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18009 (* 1 = 9.18009 loss)
I0523 02:38:13.623533 34819 sgd_solver.cpp:112] Iteration 34440, lr = 0.01
I0523 02:38:17.541113 34819 solver.cpp:239] Iteration 34450 (2.15729 iter/s, 4.63544s/10 iters), loss = 9.644
I0523 02:38:17.541162 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.644 (* 1 = 9.644 loss)
I0523 02:38:17.593431 34819 sgd_solver.cpp:112] Iteration 34450, lr = 0.01
I0523 02:38:21.482250 34819 solver.cpp:239] Iteration 34460 (2.53748 iter/s, 3.94092s/10 iters), loss = 9.15665
I0523 02:38:21.482292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15665 (* 1 = 9.15665 loss)
I0523 02:38:22.090515 34819 sgd_solver.cpp:112] Iteration 34460, lr = 0.01
I0523 02:38:25.440918 34819 solver.cpp:239] Iteration 34470 (2.52624 iter/s, 3.95845s/10 iters), loss = 8.64391
I0523 02:38:25.440971 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64391 (* 1 = 8.64391 loss)
I0523 02:38:25.518172 34819 sgd_solver.cpp:112] Iteration 34470, lr = 0.01
I0523 02:38:31.228385 34819 solver.cpp:239] Iteration 34480 (1.72796 iter/s, 5.78717s/10 iters), loss = 9.07015
I0523 02:38:31.228430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07015 (* 1 = 9.07015 loss)
I0523 02:38:31.916573 34819 sgd_solver.cpp:112] Iteration 34480, lr = 0.01
I0523 02:38:36.110298 34819 solver.cpp:239] Iteration 34490 (2.04849 iter/s, 4.88165s/10 iters), loss = 7.64678
I0523 02:38:36.110419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64678 (* 1 = 7.64678 loss)
I0523 02:38:36.172372 34819 sgd_solver.cpp:112] Iteration 34490, lr = 0.01
I0523 02:38:40.530864 34819 solver.cpp:239] Iteration 34500 (2.26231 iter/s, 4.42025s/10 iters), loss = 8.57306
I0523 02:38:40.530921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57306 (* 1 = 8.57306 loss)
I0523 02:38:40.591821 34819 sgd_solver.cpp:112] Iteration 34500, lr = 0.01
I0523 02:38:46.807170 34819 solver.cpp:239] Iteration 34510 (1.59337 iter/s, 6.27599s/10 iters), loss = 9.91549
I0523 02:38:46.807221 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.91549 (* 1 = 9.91549 loss)
I0523 02:38:46.868499 34819 sgd_solver.cpp:112] Iteration 34510, lr = 0.01
I0523 02:38:51.432422 34819 solver.cpp:239] Iteration 34520 (2.16216 iter/s, 4.62501s/10 iters), loss = 8.73909
I0523 02:38:51.432467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73909 (* 1 = 8.73909 loss)
I0523 02:38:52.260102 34819 sgd_solver.cpp:112] Iteration 34520, lr = 0.01
I0523 02:38:57.587673 34819 solver.cpp:239] Iteration 34530 (1.62471 iter/s, 6.15495s/10 iters), loss = 8.67373
I0523 02:38:57.587728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67373 (* 1 = 8.67373 loss)
I0523 02:38:58.416842 34819 sgd_solver.cpp:112] Iteration 34530, lr = 0.01
I0523 02:39:04.090999 34819 solver.cpp:239] Iteration 34540 (1.53775 iter/s, 6.50301s/10 iters), loss = 8.9882
I0523 02:39:04.091045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9882 (* 1 = 8.9882 loss)
I0523 02:39:04.786909 34819 sgd_solver.cpp:112] Iteration 34540, lr = 0.01
I0523 02:39:09.216204 34819 solver.cpp:239] Iteration 34550 (1.95124 iter/s, 5.12494s/10 iters), loss = 8.90678
I0523 02:39:09.216410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90678 (* 1 = 8.90678 loss)
I0523 02:39:10.046802 34819 sgd_solver.cpp:112] Iteration 34550, lr = 0.01
I0523 02:39:14.767393 34819 solver.cpp:239] Iteration 34560 (1.80155 iter/s, 5.55077s/10 iters), loss = 9.41656
I0523 02:39:14.767432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41656 (* 1 = 9.41656 loss)
I0523 02:39:15.129945 34819 sgd_solver.cpp:112] Iteration 34560, lr = 0.01
I0523 02:39:20.531085 34819 solver.cpp:239] Iteration 34570 (1.73509 iter/s, 5.76339s/10 iters), loss = 8.84456
I0523 02:39:20.531153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84456 (* 1 = 8.84456 loss)
I0523 02:39:20.591194 34819 sgd_solver.cpp:112] Iteration 34570, lr = 0.01
I0523 02:39:23.220762 34819 solver.cpp:239] Iteration 34580 (3.7182 iter/s, 2.68947s/10 iters), loss = 8.50779
I0523 02:39:23.220823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50779 (* 1 = 8.50779 loss)
I0523 02:39:24.097136 34819 sgd_solver.cpp:112] Iteration 34580, lr = 0.01
I0523 02:39:30.590065 34819 solver.cpp:239] Iteration 34590 (1.35705 iter/s, 7.36893s/10 iters), loss = 8.58508
I0523 02:39:30.590119 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58508 (* 1 = 8.58508 loss)
I0523 02:39:30.661598 34819 sgd_solver.cpp:112] Iteration 34590, lr = 0.01
I0523 02:39:35.031440 34819 solver.cpp:239] Iteration 34600 (2.25169 iter/s, 4.44111s/10 iters), loss = 8.80117
I0523 02:39:35.031491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80117 (* 1 = 8.80117 loss)
I0523 02:39:35.099721 34819 sgd_solver.cpp:112] Iteration 34600, lr = 0.01
I0523 02:39:39.383954 34819 solver.cpp:239] Iteration 34610 (2.29765 iter/s, 4.35226s/10 iters), loss = 10.0884
I0523 02:39:39.384145 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0884 (* 1 = 10.0884 loss)
I0523 02:39:40.206209 34819 sgd_solver.cpp:112] Iteration 34610, lr = 0.01
I0523 02:39:44.151003 34819 solver.cpp:239] Iteration 34620 (2.09789 iter/s, 4.76669s/10 iters), loss = 9.02572
I0523 02:39:44.151049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02572 (* 1 = 9.02572 loss)
I0523 02:39:44.205193 34819 sgd_solver.cpp:112] Iteration 34620, lr = 0.01
I0523 02:39:48.574342 34819 solver.cpp:239] Iteration 34630 (2.26086 iter/s, 4.42309s/10 iters), loss = 9.11399
I0523 02:39:48.574401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11399 (* 1 = 9.11399 loss)
I0523 02:39:48.625383 34819 sgd_solver.cpp:112] Iteration 34630, lr = 0.01
I0523 02:39:52.174942 34819 solver.cpp:239] Iteration 34640 (2.77748 iter/s, 3.60039s/10 iters), loss = 8.45137
I0523 02:39:52.174994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45137 (* 1 = 8.45137 loss)
I0523 02:39:52.916720 34819 sgd_solver.cpp:112] Iteration 34640, lr = 0.01
I0523 02:39:55.907536 34819 solver.cpp:239] Iteration 34650 (2.67926 iter/s, 3.73237s/10 iters), loss = 8.57864
I0523 02:39:55.907588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57864 (* 1 = 8.57864 loss)
I0523 02:39:55.975071 34819 sgd_solver.cpp:112] Iteration 34650, lr = 0.01
I0523 02:40:00.065989 34819 solver.cpp:239] Iteration 34660 (2.40488 iter/s, 4.15821s/10 iters), loss = 9.42733
I0523 02:40:00.066056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42733 (* 1 = 9.42733 loss)
I0523 02:40:00.843430 34819 sgd_solver.cpp:112] Iteration 34660, lr = 0.01
I0523 02:40:02.910882 34819 solver.cpp:239] Iteration 34670 (3.5153 iter/s, 2.8447s/10 iters), loss = 9.03279
I0523 02:40:02.910928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03279 (* 1 = 9.03279 loss)
I0523 02:40:03.755758 34819 sgd_solver.cpp:112] Iteration 34670, lr = 0.01
I0523 02:40:08.611969 34819 solver.cpp:239] Iteration 34680 (1.75414 iter/s, 5.70081s/10 iters), loss = 9.03237
I0523 02:40:08.612025 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03237 (* 1 = 9.03237 loss)
I0523 02:40:08.676184 34819 sgd_solver.cpp:112] Iteration 34680, lr = 0.01
I0523 02:40:12.709554 34819 solver.cpp:239] Iteration 34690 (2.4406 iter/s, 4.09736s/10 iters), loss = 9.70891
I0523 02:40:12.709700 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70891 (* 1 = 9.70891 loss)
I0523 02:40:13.400530 34819 sgd_solver.cpp:112] Iteration 34690, lr = 0.01
I0523 02:40:18.386728 34819 solver.cpp:239] Iteration 34700 (1.76157 iter/s, 5.67675s/10 iters), loss = 9.80091
I0523 02:40:18.386786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.80091 (* 1 = 9.80091 loss)
I0523 02:40:19.159621 34819 sgd_solver.cpp:112] Iteration 34700, lr = 0.01
I0523 02:40:22.441326 34819 solver.cpp:239] Iteration 34710 (2.46647 iter/s, 4.05437s/10 iters), loss = 8.7158
I0523 02:40:22.441380 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7158 (* 1 = 8.7158 loss)
I0523 02:40:22.507581 34819 sgd_solver.cpp:112] Iteration 34710, lr = 0.01
I0523 02:40:26.709242 34819 solver.cpp:239] Iteration 34720 (2.3432 iter/s, 4.26767s/10 iters), loss = 9.07058
I0523 02:40:26.709291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07058 (* 1 = 9.07058 loss)
I0523 02:40:27.540480 34819 sgd_solver.cpp:112] Iteration 34720, lr = 0.01
I0523 02:40:31.696507 34819 solver.cpp:239] Iteration 34730 (2.00521 iter/s, 4.987s/10 iters), loss = 9.23361
I0523 02:40:31.696548 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23361 (* 1 = 9.23361 loss)
I0523 02:40:31.765658 34819 sgd_solver.cpp:112] Iteration 34730, lr = 0.01
I0523 02:40:35.875428 34819 solver.cpp:239] Iteration 34740 (2.39309 iter/s, 4.1787s/10 iters), loss = 9.93837
I0523 02:40:35.875483 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93837 (* 1 = 9.93837 loss)
I0523 02:40:35.954253 34819 sgd_solver.cpp:112] Iteration 34740, lr = 0.01
I0523 02:40:40.604588 34819 solver.cpp:239] Iteration 34750 (2.11465 iter/s, 4.72891s/10 iters), loss = 9.87376
I0523 02:40:40.604641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.87376 (* 1 = 9.87376 loss)
I0523 02:40:40.675249 34819 sgd_solver.cpp:112] Iteration 34750, lr = 0.01
I0523 02:40:45.952885 34819 solver.cpp:239] Iteration 34760 (1.86985 iter/s, 5.34802s/10 iters), loss = 8.37133
I0523 02:40:45.953037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37133 (* 1 = 8.37133 loss)
I0523 02:40:46.020792 34819 sgd_solver.cpp:112] Iteration 34760, lr = 0.01
I0523 02:40:53.540817 34819 solver.cpp:239] Iteration 34770 (1.31796 iter/s, 7.58747s/10 iters), loss = 7.76853
I0523 02:40:53.540874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76853 (* 1 = 7.76853 loss)
I0523 02:40:54.435955 34819 sgd_solver.cpp:112] Iteration 34770, lr = 0.01
I0523 02:40:59.760506 34819 solver.cpp:239] Iteration 34780 (1.60788 iter/s, 6.21937s/10 iters), loss = 8.79731
I0523 02:40:59.760547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79731 (* 1 = 8.79731 loss)
I0523 02:40:59.826370 34819 sgd_solver.cpp:112] Iteration 34780, lr = 0.01
I0523 02:41:03.875134 34819 solver.cpp:239] Iteration 34790 (2.43048 iter/s, 4.11441s/10 iters), loss = 8.70294
I0523 02:41:03.875177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70294 (* 1 = 8.70294 loss)
I0523 02:41:04.411420 34819 sgd_solver.cpp:112] Iteration 34790, lr = 0.01
I0523 02:41:07.792958 34819 solver.cpp:239] Iteration 34800 (2.55257 iter/s, 3.91761s/10 iters), loss = 8.21034
I0523 02:41:07.793009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21034 (* 1 = 8.21034 loss)
I0523 02:41:07.861268 34819 sgd_solver.cpp:112] Iteration 34800, lr = 0.01
I0523 02:41:11.796303 34819 solver.cpp:239] Iteration 34810 (2.50083 iter/s, 3.99867s/10 iters), loss = 9.90543
I0523 02:41:11.796368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.90543 (* 1 = 9.90543 loss)
I0523 02:41:12.598187 34819 sgd_solver.cpp:112] Iteration 34810, lr = 0.01
I0523 02:41:18.277704 34819 solver.cpp:239] Iteration 34820 (1.54296 iter/s, 6.48106s/10 iters), loss = 7.98026
I0523 02:41:18.277885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98026 (* 1 = 7.98026 loss)
I0523 02:41:18.358074 34819 sgd_solver.cpp:112] Iteration 34820, lr = 0.01
I0523 02:41:21.681126 34819 solver.cpp:239] Iteration 34830 (2.9385 iter/s, 3.4031s/10 iters), loss = 10.0381
I0523 02:41:21.681182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0381 (* 1 = 10.0381 loss)
I0523 02:41:21.744663 34819 sgd_solver.cpp:112] Iteration 34830, lr = 0.01
I0523 02:41:25.638496 34819 solver.cpp:239] Iteration 34840 (2.52707 iter/s, 3.95715s/10 iters), loss = 8.90217
I0523 02:41:25.638541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90217 (* 1 = 8.90217 loss)
I0523 02:41:26.448573 34819 sgd_solver.cpp:112] Iteration 34840, lr = 0.01
I0523 02:41:30.415038 34819 solver.cpp:239] Iteration 34850 (2.09368 iter/s, 4.77628s/10 iters), loss = 8.31381
I0523 02:41:30.415102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31381 (* 1 = 8.31381 loss)
I0523 02:41:31.187283 34819 sgd_solver.cpp:112] Iteration 34850, lr = 0.01
I0523 02:41:35.965195 34819 solver.cpp:239] Iteration 34860 (1.80186 iter/s, 5.54982s/10 iters), loss = 9.26689
I0523 02:41:35.965255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26689 (* 1 = 9.26689 loss)
I0523 02:41:36.823932 34819 sgd_solver.cpp:112] Iteration 34860, lr = 0.01
I0523 02:41:41.664611 34819 solver.cpp:239] Iteration 34870 (1.75466 iter/s, 5.69911s/10 iters), loss = 7.71127
I0523 02:41:41.664662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71127 (* 1 = 7.71127 loss)
I0523 02:41:41.736968 34819 sgd_solver.cpp:112] Iteration 34870, lr = 0.01
I0523 02:41:45.070842 34819 solver.cpp:239] Iteration 34880 (2.93598 iter/s, 3.40602s/10 iters), loss = 9.15925
I0523 02:41:45.070904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15925 (* 1 = 9.15925 loss)
I0523 02:41:45.375192 34819 sgd_solver.cpp:112] Iteration 34880, lr = 0.01
I0523 02:41:48.392643 34819 solver.cpp:239] Iteration 34890 (3.01063 iter/s, 3.32156s/10 iters), loss = 8.81273
I0523 02:41:48.392858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81273 (* 1 = 8.81273 loss)
I0523 02:41:49.253080 34819 sgd_solver.cpp:112] Iteration 34890, lr = 0.01
I0523 02:41:51.711740 34819 solver.cpp:239] Iteration 34900 (3.01317 iter/s, 3.31876s/10 iters), loss = 8.9429
I0523 02:41:51.711786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9429 (* 1 = 8.9429 loss)
I0523 02:41:52.551918 34819 sgd_solver.cpp:112] Iteration 34900, lr = 0.01
I0523 02:41:58.105391 34819 solver.cpp:239] Iteration 34910 (1.56413 iter/s, 6.39332s/10 iters), loss = 9.52372
I0523 02:41:58.105446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52372 (* 1 = 9.52372 loss)
I0523 02:41:58.164059 34819 sgd_solver.cpp:112] Iteration 34910, lr = 0.01
I0523 02:42:02.147620 34819 solver.cpp:239] Iteration 34920 (2.47403 iter/s, 4.04199s/10 iters), loss = 8.86763
I0523 02:42:02.147675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86763 (* 1 = 8.86763 loss)
I0523 02:42:02.210597 34819 sgd_solver.cpp:112] Iteration 34920, lr = 0.01
I0523 02:42:06.155712 34819 solver.cpp:239] Iteration 34930 (2.49509 iter/s, 4.00787s/10 iters), loss = 9.23406
I0523 02:42:06.155763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23406 (* 1 = 9.23406 loss)
I0523 02:42:06.228771 34819 sgd_solver.cpp:112] Iteration 34930, lr = 0.01
I0523 02:42:11.078130 34819 solver.cpp:239] Iteration 34940 (2.03164 iter/s, 4.92214s/10 iters), loss = 8.45819
I0523 02:42:11.078176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45819 (* 1 = 8.45819 loss)
I0523 02:42:11.133663 34819 sgd_solver.cpp:112] Iteration 34940, lr = 0.01
I0523 02:42:16.081511 34819 solver.cpp:239] Iteration 34950 (1.99875 iter/s, 5.00313s/10 iters), loss = 9.23695
I0523 02:42:16.081560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23695 (* 1 = 9.23695 loss)
I0523 02:42:16.144949 34819 sgd_solver.cpp:112] Iteration 34950, lr = 0.01
I0523 02:42:21.636256 34819 solver.cpp:239] Iteration 34960 (1.80035 iter/s, 5.55447s/10 iters), loss = 8.74062
I0523 02:42:21.636462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74062 (* 1 = 8.74062 loss)
I0523 02:42:21.709923 34819 sgd_solver.cpp:112] Iteration 34960, lr = 0.01
I0523 02:42:26.146246 34819 solver.cpp:239] Iteration 34970 (2.21748 iter/s, 4.50962s/10 iters), loss = 8.20596
I0523 02:42:26.146287 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20596 (* 1 = 8.20596 loss)
I0523 02:42:26.420161 34819 sgd_solver.cpp:112] Iteration 34970, lr = 0.01
I0523 02:42:29.753825 34819 solver.cpp:239] Iteration 34980 (2.7721 iter/s, 3.60737s/10 iters), loss = 8.80316
I0523 02:42:29.753875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80316 (* 1 = 8.80316 loss)
I0523 02:42:29.835713 34819 sgd_solver.cpp:112] Iteration 34980, lr = 0.01
I0523 02:42:35.065524 34819 solver.cpp:239] Iteration 34990 (1.88273 iter/s, 5.31142s/10 iters), loss = 8.41965
I0523 02:42:35.065565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41965 (* 1 = 8.41965 loss)
I0523 02:42:35.137693 34819 sgd_solver.cpp:112] Iteration 34990, lr = 0.01
I0523 02:42:41.180678 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_35000.caffemodel
I0523 02:42:43.223811 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_35000.solverstate
I0523 02:42:43.439036 34819 solver.cpp:239] Iteration 35000 (1.19429 iter/s, 8.37314s/10 iters), loss = 8.77291
I0523 02:42:43.439074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77291 (* 1 = 8.77291 loss)
I0523 02:42:44.187925 34819 sgd_solver.cpp:112] Iteration 35000, lr = 0.01
I0523 02:42:51.531500 34819 solver.cpp:239] Iteration 35010 (1.23577 iter/s, 8.0921s/10 iters), loss = 7.75595
I0523 02:42:51.531546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75595 (* 1 = 7.75595 loss)
I0523 02:42:51.589396 34819 sgd_solver.cpp:112] Iteration 35010, lr = 0.01
I0523 02:42:57.093260 34819 solver.cpp:239] Iteration 35020 (1.79808 iter/s, 5.56147s/10 iters), loss = 8.47324
I0523 02:42:57.093406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47324 (* 1 = 8.47324 loss)
I0523 02:42:57.163713 34819 sgd_solver.cpp:112] Iteration 35020, lr = 0.01
I0523 02:43:01.906522 34819 solver.cpp:239] Iteration 35030 (2.07775 iter/s, 4.81291s/10 iters), loss = 8.9244
I0523 02:43:01.906572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9244 (* 1 = 8.9244 loss)
I0523 02:43:01.973345 34819 sgd_solver.cpp:112] Iteration 35030, lr = 0.01
I0523 02:43:07.861990 34819 solver.cpp:239] Iteration 35040 (1.67921 iter/s, 5.95517s/10 iters), loss = 8.70779
I0523 02:43:07.862035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70779 (* 1 = 8.70779 loss)
I0523 02:43:08.714866 34819 sgd_solver.cpp:112] Iteration 35040, lr = 0.01
I0523 02:43:13.659687 34819 solver.cpp:239] Iteration 35050 (1.72491 iter/s, 5.79742s/10 iters), loss = 8.15513
I0523 02:43:13.659729 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15513 (* 1 = 8.15513 loss)
I0523 02:43:13.732075 34819 sgd_solver.cpp:112] Iteration 35050, lr = 0.01
I0523 02:43:18.957089 34819 solver.cpp:239] Iteration 35060 (1.88781 iter/s, 5.29715s/10 iters), loss = 8.86689
I0523 02:43:18.957131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86689 (* 1 = 8.86689 loss)
I0523 02:43:19.025400 34819 sgd_solver.cpp:112] Iteration 35060, lr = 0.01
I0523 02:43:23.880563 34819 solver.cpp:239] Iteration 35070 (2.03119 iter/s, 4.92323s/10 iters), loss = 8.56358
I0523 02:43:23.880604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56358 (* 1 = 8.56358 loss)
I0523 02:43:24.719463 34819 sgd_solver.cpp:112] Iteration 35070, lr = 0.01
I0523 02:43:27.722460 34819 solver.cpp:239] Iteration 35080 (2.60302 iter/s, 3.84169s/10 iters), loss = 8.35628
I0523 02:43:27.722638 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35628 (* 1 = 8.35628 loss)
I0523 02:43:27.779518 34819 sgd_solver.cpp:112] Iteration 35080, lr = 0.01
I0523 02:43:32.605957 34819 solver.cpp:239] Iteration 35090 (2.04788 iter/s, 4.8831s/10 iters), loss = 8.58021
I0523 02:43:32.606009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58021 (* 1 = 8.58021 loss)
I0523 02:43:33.466156 34819 sgd_solver.cpp:112] Iteration 35090, lr = 0.01
I0523 02:43:38.960250 34819 solver.cpp:239] Iteration 35100 (1.57382 iter/s, 6.35398s/10 iters), loss = 8.77753
I0523 02:43:38.960294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77753 (* 1 = 8.77753 loss)
I0523 02:43:39.027746 34819 sgd_solver.cpp:112] Iteration 35100, lr = 0.01
I0523 02:43:42.375442 34819 solver.cpp:239] Iteration 35110 (2.92827 iter/s, 3.41499s/10 iters), loss = 9.15233
I0523 02:43:42.375483 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15233 (* 1 = 9.15233 loss)
I0523 02:43:42.443960 34819 sgd_solver.cpp:112] Iteration 35110, lr = 0.01
I0523 02:43:47.218948 34819 solver.cpp:239] Iteration 35120 (2.06473 iter/s, 4.84326s/10 iters), loss = 7.56222
I0523 02:43:47.219005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56222 (* 1 = 7.56222 loss)
I0523 02:43:47.289232 34819 sgd_solver.cpp:112] Iteration 35120, lr = 0.01
I0523 02:43:51.953662 34819 solver.cpp:239] Iteration 35130 (2.11218 iter/s, 4.73446s/10 iters), loss = 8.91711
I0523 02:43:51.953703 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91711 (* 1 = 8.91711 loss)
I0523 02:43:52.683914 34819 sgd_solver.cpp:112] Iteration 35130, lr = 0.01
I0523 02:43:57.042866 34819 solver.cpp:239] Iteration 35140 (1.96504 iter/s, 5.08895s/10 iters), loss = 8.72454
I0523 02:43:57.042908 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72454 (* 1 = 8.72454 loss)
I0523 02:43:57.889250 34819 sgd_solver.cpp:112] Iteration 35140, lr = 0.01
I0523 02:44:01.184505 34819 solver.cpp:239] Iteration 35150 (2.41463 iter/s, 4.14141s/10 iters), loss = 9.14678
I0523 02:44:01.184551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14678 (* 1 = 9.14678 loss)
I0523 02:44:02.009050 34819 sgd_solver.cpp:112] Iteration 35150, lr = 0.01
I0523 02:44:07.984375 34819 solver.cpp:239] Iteration 35160 (1.47069 iter/s, 6.79955s/10 iters), loss = 8.98588
I0523 02:44:07.984413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98588 (* 1 = 8.98588 loss)
I0523 02:44:08.059931 34819 sgd_solver.cpp:112] Iteration 35160, lr = 0.01
I0523 02:44:13.297097 34819 solver.cpp:239] Iteration 35170 (1.88238 iter/s, 5.31244s/10 iters), loss = 9.29205
I0523 02:44:13.297147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29205 (* 1 = 9.29205 loss)
I0523 02:44:14.095794 34819 sgd_solver.cpp:112] Iteration 35170, lr = 0.01
I0523 02:44:18.912533 34819 solver.cpp:239] Iteration 35180 (1.78089 iter/s, 5.61516s/10 iters), loss = 8.9244
I0523 02:44:18.912575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9244 (* 1 = 8.9244 loss)
I0523 02:44:18.972110 34819 sgd_solver.cpp:112] Iteration 35180, lr = 0.01
I0523 02:44:22.826040 34819 solver.cpp:239] Iteration 35190 (2.55539 iter/s, 3.9133s/10 iters), loss = 9.20005
I0523 02:44:22.826086 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20005 (* 1 = 9.20005 loss)
I0523 02:44:22.908650 34819 sgd_solver.cpp:112] Iteration 35190, lr = 0.01
I0523 02:44:28.059438 34819 solver.cpp:239] Iteration 35200 (1.91091 iter/s, 5.23312s/10 iters), loss = 8.36326
I0523 02:44:28.059607 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36326 (* 1 = 8.36326 loss)
I0523 02:44:28.138468 34819 sgd_solver.cpp:112] Iteration 35200, lr = 0.01
I0523 02:44:31.896127 34819 solver.cpp:239] Iteration 35210 (2.60663 iter/s, 3.83636s/10 iters), loss = 8.82906
I0523 02:44:31.896173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82906 (* 1 = 8.82906 loss)
I0523 02:44:32.622669 34819 sgd_solver.cpp:112] Iteration 35210, lr = 0.01
I0523 02:44:36.956084 34819 solver.cpp:239] Iteration 35220 (1.9764 iter/s, 5.0597s/10 iters), loss = 9.22313
I0523 02:44:36.956133 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22313 (* 1 = 9.22313 loss)
I0523 02:44:37.744616 34819 sgd_solver.cpp:112] Iteration 35220, lr = 0.01
I0523 02:44:42.516124 34819 solver.cpp:239] Iteration 35230 (1.79864 iter/s, 5.55975s/10 iters), loss = 8.81564
I0523 02:44:42.516173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81564 (* 1 = 8.81564 loss)
I0523 02:44:42.592017 34819 sgd_solver.cpp:112] Iteration 35230, lr = 0.01
I0523 02:44:48.563947 34819 solver.cpp:239] Iteration 35240 (1.65357 iter/s, 6.04752s/10 iters), loss = 9.17865
I0523 02:44:48.563992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17865 (* 1 = 9.17865 loss)
I0523 02:44:48.631976 34819 sgd_solver.cpp:112] Iteration 35240, lr = 0.01
I0523 02:44:51.994105 34819 solver.cpp:239] Iteration 35250 (2.91553 iter/s, 3.42991s/10 iters), loss = 9.41838
I0523 02:44:51.994151 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41838 (* 1 = 9.41838 loss)
I0523 02:44:52.052559 34819 sgd_solver.cpp:112] Iteration 35250, lr = 0.01
I0523 02:44:56.668689 34819 solver.cpp:239] Iteration 35260 (2.13934 iter/s, 4.67434s/10 iters), loss = 9.57683
I0523 02:44:56.668742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57683 (* 1 = 9.57683 loss)
I0523 02:44:56.758528 34819 sgd_solver.cpp:112] Iteration 35260, lr = 0.01
I0523 02:45:01.235111 34819 solver.cpp:239] Iteration 35270 (2.19002 iter/s, 4.56617s/10 iters), loss = 8.5778
I0523 02:45:01.235246 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5778 (* 1 = 8.5778 loss)
I0523 02:45:01.308790 34819 sgd_solver.cpp:112] Iteration 35270, lr = 0.01
I0523 02:45:06.867970 34819 solver.cpp:239] Iteration 35280 (1.77542 iter/s, 5.63248s/10 iters), loss = 9.47648
I0523 02:45:06.868016 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47648 (* 1 = 9.47648 loss)
I0523 02:45:07.683883 34819 sgd_solver.cpp:112] Iteration 35280, lr = 0.01
I0523 02:45:11.717416 34819 solver.cpp:239] Iteration 35290 (2.06219 iter/s, 4.8492s/10 iters), loss = 8.82611
I0523 02:45:11.717456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82611 (* 1 = 8.82611 loss)
I0523 02:45:11.785375 34819 sgd_solver.cpp:112] Iteration 35290, lr = 0.01
I0523 02:45:15.726907 34819 solver.cpp:239] Iteration 35300 (2.49421 iter/s, 4.00928s/10 iters), loss = 7.90852
I0523 02:45:15.726950 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90852 (* 1 = 7.90852 loss)
I0523 02:45:16.535256 34819 sgd_solver.cpp:112] Iteration 35300, lr = 0.01
I0523 02:45:22.462535 34819 solver.cpp:239] Iteration 35310 (1.48471 iter/s, 6.73531s/10 iters), loss = 8.30446
I0523 02:45:22.462579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30446 (* 1 = 8.30446 loss)
I0523 02:45:22.542317 34819 sgd_solver.cpp:112] Iteration 35310, lr = 0.01
I0523 02:45:27.585451 34819 solver.cpp:239] Iteration 35320 (1.95211 iter/s, 5.12266s/10 iters), loss = 9.21735
I0523 02:45:27.585494 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21735 (* 1 = 9.21735 loss)
I0523 02:45:27.661635 34819 sgd_solver.cpp:112] Iteration 35320, lr = 0.01
I0523 02:45:33.081183 34819 solver.cpp:239] Iteration 35330 (1.81968 iter/s, 5.49547s/10 iters), loss = 8.83506
I0523 02:45:33.081323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83506 (* 1 = 8.83506 loss)
I0523 02:45:33.155766 34819 sgd_solver.cpp:112] Iteration 35330, lr = 0.01
I0523 02:45:36.343257 34819 solver.cpp:239] Iteration 35340 (3.0658 iter/s, 3.26179s/10 iters), loss = 9.40515
I0523 02:45:36.343298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40515 (* 1 = 9.40515 loss)
I0523 02:45:37.183403 34819 sgd_solver.cpp:112] Iteration 35340, lr = 0.01
I0523 02:45:42.011371 34819 solver.cpp:239] Iteration 35350 (1.76434 iter/s, 5.66784s/10 iters), loss = 9.38961
I0523 02:45:42.011410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38961 (* 1 = 9.38961 loss)
I0523 02:45:42.088915 34819 sgd_solver.cpp:112] Iteration 35350, lr = 0.01
I0523 02:45:45.924916 34819 solver.cpp:239] Iteration 35360 (2.55536 iter/s, 3.91334s/10 iters), loss = 8.84175
I0523 02:45:45.924958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84175 (* 1 = 8.84175 loss)
I0523 02:45:46.630990 34819 sgd_solver.cpp:112] Iteration 35360, lr = 0.01
I0523 02:45:50.613123 34819 solver.cpp:239] Iteration 35370 (2.13312 iter/s, 4.68796s/10 iters), loss = 9.76369
I0523 02:45:50.613164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.76369 (* 1 = 9.76369 loss)
I0523 02:45:51.449674 34819 sgd_solver.cpp:112] Iteration 35370, lr = 0.01
I0523 02:45:55.697916 34819 solver.cpp:239] Iteration 35380 (1.96675 iter/s, 5.08453s/10 iters), loss = 8.11377
I0523 02:45:55.697965 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11377 (* 1 = 8.11377 loss)
I0523 02:45:56.574985 34819 sgd_solver.cpp:112] Iteration 35380, lr = 0.01
I0523 02:46:01.332758 34819 solver.cpp:239] Iteration 35390 (1.77476 iter/s, 5.63456s/10 iters), loss = 9.11766
I0523 02:46:01.332799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11766 (* 1 = 9.11766 loss)
I0523 02:46:02.121771 34819 sgd_solver.cpp:112] Iteration 35390, lr = 0.01
I0523 02:46:09.296301 34819 solver.cpp:239] Iteration 35400 (1.25578 iter/s, 7.96317s/10 iters), loss = 9.05284
I0523 02:46:09.296509 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05284 (* 1 = 9.05284 loss)
I0523 02:46:09.384573 34819 sgd_solver.cpp:112] Iteration 35400, lr = 0.01
I0523 02:46:15.110321 34819 solver.cpp:239] Iteration 35410 (1.72011 iter/s, 5.81357s/10 iters), loss = 8.38581
I0523 02:46:15.110378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38581 (* 1 = 8.38581 loss)
I0523 02:46:15.949609 34819 sgd_solver.cpp:112] Iteration 35410, lr = 0.01
I0523 02:46:18.580142 34819 solver.cpp:239] Iteration 35420 (2.88217 iter/s, 3.46961s/10 iters), loss = 9.0072
I0523 02:46:18.580199 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0072 (* 1 = 9.0072 loss)
I0523 02:46:18.636183 34819 sgd_solver.cpp:112] Iteration 35420, lr = 0.01
I0523 02:46:24.869663 34819 solver.cpp:239] Iteration 35430 (1.59003 iter/s, 6.28919s/10 iters), loss = 9.75452
I0523 02:46:24.869710 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75452 (* 1 = 9.75452 loss)
I0523 02:46:25.686504 34819 sgd_solver.cpp:112] Iteration 35430, lr = 0.01
I0523 02:46:32.007287 34819 solver.cpp:239] Iteration 35440 (1.40109 iter/s, 7.13729s/10 iters), loss = 9.71634
I0523 02:46:32.007333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71634 (* 1 = 9.71634 loss)
I0523 02:46:32.079263 34819 sgd_solver.cpp:112] Iteration 35440, lr = 0.01
I0523 02:46:34.697705 34819 solver.cpp:239] Iteration 35450 (3.71712 iter/s, 2.69026s/10 iters), loss = 8.56941
I0523 02:46:34.697746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56941 (* 1 = 8.56941 loss)
I0523 02:46:35.234634 34819 sgd_solver.cpp:112] Iteration 35450, lr = 0.01
I0523 02:46:39.763767 34819 solver.cpp:239] Iteration 35460 (1.97402 iter/s, 5.0658s/10 iters), loss = 7.99245
I0523 02:46:39.763931 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99245 (* 1 = 7.99245 loss)
I0523 02:46:39.824332 34819 sgd_solver.cpp:112] Iteration 35460, lr = 0.01
I0523 02:46:44.034176 34819 solver.cpp:239] Iteration 35470 (2.34189 iter/s, 4.27006s/10 iters), loss = 9.51898
I0523 02:46:44.034214 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51898 (* 1 = 9.51898 loss)
I0523 02:46:44.881285 34819 sgd_solver.cpp:112] Iteration 35470, lr = 0.01
I0523 02:46:48.956446 34819 solver.cpp:239] Iteration 35480 (2.03168 iter/s, 4.92202s/10 iters), loss = 9.25911
I0523 02:46:48.956496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25911 (* 1 = 9.25911 loss)
I0523 02:46:49.028491 34819 sgd_solver.cpp:112] Iteration 35480, lr = 0.01
I0523 02:46:53.282025 34819 solver.cpp:239] Iteration 35490 (2.31196 iter/s, 4.32533s/10 iters), loss = 8.78292
I0523 02:46:53.282074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78292 (* 1 = 8.78292 loss)
I0523 02:46:54.113857 34819 sgd_solver.cpp:112] Iteration 35490, lr = 0.01
I0523 02:46:58.392840 34819 solver.cpp:239] Iteration 35500 (1.95673 iter/s, 5.11056s/10 iters), loss = 8.69508
I0523 02:46:58.392881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69508 (* 1 = 8.69508 loss)
I0523 02:46:59.043592 34819 sgd_solver.cpp:112] Iteration 35500, lr = 0.01
I0523 02:47:04.833890 34819 solver.cpp:239] Iteration 35510 (1.55262 iter/s, 6.44074s/10 iters), loss = 8.89079
I0523 02:47:04.833930 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89079 (* 1 = 8.89079 loss)
I0523 02:47:05.708586 34819 sgd_solver.cpp:112] Iteration 35510, lr = 0.01
I0523 02:47:09.732424 34819 solver.cpp:239] Iteration 35520 (2.04154 iter/s, 4.89827s/10 iters), loss = 8.94433
I0523 02:47:09.732475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94433 (* 1 = 8.94433 loss)
I0523 02:47:10.579102 34819 sgd_solver.cpp:112] Iteration 35520, lr = 0.01
I0523 02:47:13.888074 34819 solver.cpp:239] Iteration 35530 (2.4065 iter/s, 4.15542s/10 iters), loss = 8.91465
I0523 02:47:13.888114 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91465 (* 1 = 8.91465 loss)
I0523 02:47:13.955364 34819 sgd_solver.cpp:112] Iteration 35530, lr = 0.01
I0523 02:47:20.231180 34819 solver.cpp:239] Iteration 35540 (1.57659 iter/s, 6.34281s/10 iters), loss = 9.1993
I0523 02:47:20.231220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1993 (* 1 = 9.1993 loss)
I0523 02:47:20.305867 34819 sgd_solver.cpp:112] Iteration 35540, lr = 0.01
I0523 02:47:23.843641 34819 solver.cpp:239] Iteration 35550 (2.76834 iter/s, 3.61227s/10 iters), loss = 8.94596
I0523 02:47:23.843681 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94596 (* 1 = 8.94596 loss)
I0523 02:47:23.904376 34819 sgd_solver.cpp:112] Iteration 35550, lr = 0.01
I0523 02:47:30.293366 34819 solver.cpp:239] Iteration 35560 (1.55158 iter/s, 6.44503s/10 iters), loss = 8.29748
I0523 02:47:30.293407 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29748 (* 1 = 8.29748 loss)
I0523 02:47:31.108945 34819 sgd_solver.cpp:112] Iteration 35560, lr = 0.01
I0523 02:47:34.862115 34819 solver.cpp:239] Iteration 35570 (2.1889 iter/s, 4.5685s/10 iters), loss = 8.60612
I0523 02:47:34.862157 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60612 (* 1 = 8.60612 loss)
I0523 02:47:34.936952 34819 sgd_solver.cpp:112] Iteration 35570, lr = 0.01
I0523 02:47:40.129770 34819 solver.cpp:239] Iteration 35580 (1.89848 iter/s, 5.26737s/10 iters), loss = 8.64291
I0523 02:47:40.129818 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64291 (* 1 = 8.64291 loss)
I0523 02:47:40.882293 34819 sgd_solver.cpp:112] Iteration 35580, lr = 0.01
I0523 02:47:46.693212 34819 solver.cpp:239] Iteration 35590 (1.52366 iter/s, 6.56313s/10 iters), loss = 10.4695
I0523 02:47:46.693253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.4695 (* 1 = 10.4695 loss)
I0523 02:47:46.762326 34819 sgd_solver.cpp:112] Iteration 35590, lr = 0.01
I0523 02:47:50.150111 34819 solver.cpp:239] Iteration 35600 (2.89294 iter/s, 3.45669s/10 iters), loss = 8.92865
I0523 02:47:50.150166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92865 (* 1 = 8.92865 loss)
I0523 02:47:50.220540 34819 sgd_solver.cpp:112] Iteration 35600, lr = 0.01
I0523 02:47:55.403302 34819 solver.cpp:239] Iteration 35610 (1.9037 iter/s, 5.25292s/10 iters), loss = 8.43432
I0523 02:47:55.403355 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43432 (* 1 = 8.43432 loss)
I0523 02:47:55.481346 34819 sgd_solver.cpp:112] Iteration 35610, lr = 0.01
I0523 02:47:59.653785 34819 solver.cpp:239] Iteration 35620 (2.35281 iter/s, 4.25024s/10 iters), loss = 8.51176
I0523 02:47:59.653836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51176 (* 1 = 8.51176 loss)
I0523 02:47:59.723538 34819 sgd_solver.cpp:112] Iteration 35620, lr = 0.01
I0523 02:48:02.994421 34819 solver.cpp:239] Iteration 35630 (2.99362 iter/s, 3.34044s/10 iters), loss = 8.15954
I0523 02:48:02.994473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15954 (* 1 = 8.15954 loss)
I0523 02:48:03.033067 34819 sgd_solver.cpp:112] Iteration 35630, lr = 0.01
I0523 02:48:06.275600 34819 solver.cpp:239] Iteration 35640 (3.04787 iter/s, 3.28098s/10 iters), loss = 8.07974
I0523 02:48:06.275653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07974 (* 1 = 8.07974 loss)
I0523 02:48:07.100425 34819 sgd_solver.cpp:112] Iteration 35640, lr = 0.01
I0523 02:48:10.297845 34819 solver.cpp:239] Iteration 35650 (2.48631 iter/s, 4.02202s/10 iters), loss = 8.27262
I0523 02:48:10.297899 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27262 (* 1 = 8.27262 loss)
I0523 02:48:10.357683 34819 sgd_solver.cpp:112] Iteration 35650, lr = 0.01
I0523 02:48:15.065595 34819 solver.cpp:239] Iteration 35660 (2.09754 iter/s, 4.76749s/10 iters), loss = 8.11784
I0523 02:48:15.065755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11784 (* 1 = 8.11784 loss)
I0523 02:48:15.138650 34819 sgd_solver.cpp:112] Iteration 35660, lr = 0.01
I0523 02:48:19.189456 34819 solver.cpp:239] Iteration 35670 (2.42511 iter/s, 4.12352s/10 iters), loss = 8.62789
I0523 02:48:19.189497 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62789 (* 1 = 8.62789 loss)
I0523 02:48:19.267416 34819 sgd_solver.cpp:112] Iteration 35670, lr = 0.01
I0523 02:48:22.506273 34819 solver.cpp:239] Iteration 35680 (3.01511 iter/s, 3.31663s/10 iters), loss = 9.04941
I0523 02:48:22.506314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04941 (* 1 = 9.04941 loss)
I0523 02:48:22.587309 34819 sgd_solver.cpp:112] Iteration 35680, lr = 0.01
I0523 02:48:28.114739 34819 solver.cpp:239] Iteration 35690 (1.78311 iter/s, 5.60819s/10 iters), loss = 9.25114
I0523 02:48:28.114781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25114 (* 1 = 9.25114 loss)
I0523 02:48:28.181876 34819 sgd_solver.cpp:112] Iteration 35690, lr = 0.01
I0523 02:48:32.594727 34819 solver.cpp:239] Iteration 35700 (2.23226 iter/s, 4.47976s/10 iters), loss = 8.7469
I0523 02:48:32.594769 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7469 (* 1 = 8.7469 loss)
I0523 02:48:32.649176 34819 sgd_solver.cpp:112] Iteration 35700, lr = 0.01
I0523 02:48:36.272380 34819 solver.cpp:239] Iteration 35710 (2.71927 iter/s, 3.67745s/10 iters), loss = 9.14041
I0523 02:48:36.272423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14041 (* 1 = 9.14041 loss)
I0523 02:48:36.338326 34819 sgd_solver.cpp:112] Iteration 35710, lr = 0.01
I0523 02:48:39.773301 34819 solver.cpp:239] Iteration 35720 (2.85656 iter/s, 3.50071s/10 iters), loss = 8.65836
I0523 02:48:39.773350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65836 (* 1 = 8.65836 loss)
I0523 02:48:40.604912 34819 sgd_solver.cpp:112] Iteration 35720, lr = 0.01
I0523 02:48:44.149785 34819 solver.cpp:239] Iteration 35730 (2.28506 iter/s, 4.37626s/10 iters), loss = 8.75999
I0523 02:48:44.149824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75999 (* 1 = 8.75999 loss)
I0523 02:48:44.824321 34819 sgd_solver.cpp:112] Iteration 35730, lr = 0.01
I0523 02:48:50.930991 34819 solver.cpp:239] Iteration 35740 (1.47474 iter/s, 6.78087s/10 iters), loss = 8.57119
I0523 02:48:50.931169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57119 (* 1 = 8.57119 loss)
I0523 02:48:50.991055 34819 sgd_solver.cpp:112] Iteration 35740, lr = 0.01
I0523 02:48:55.310520 34819 solver.cpp:239] Iteration 35750 (2.28355 iter/s, 4.37916s/10 iters), loss = 8.32195
I0523 02:48:55.310571 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32195 (* 1 = 8.32195 loss)
I0523 02:48:55.379225 34819 sgd_solver.cpp:112] Iteration 35750, lr = 0.01
I0523 02:49:00.176440 34819 solver.cpp:239] Iteration 35760 (2.05522 iter/s, 4.86566s/10 iters), loss = 8.39303
I0523 02:49:00.176481 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39303 (* 1 = 8.39303 loss)
I0523 02:49:01.030331 34819 sgd_solver.cpp:112] Iteration 35760, lr = 0.01
I0523 02:49:05.922261 34819 solver.cpp:239] Iteration 35770 (1.74048 iter/s, 5.74554s/10 iters), loss = 8.87587
I0523 02:49:05.922304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87587 (* 1 = 8.87587 loss)
I0523 02:49:06.691972 34819 sgd_solver.cpp:112] Iteration 35770, lr = 0.01
I0523 02:49:12.408694 34819 solver.cpp:239] Iteration 35780 (1.54176 iter/s, 6.48611s/10 iters), loss = 9.17884
I0523 02:49:12.408740 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17884 (* 1 = 9.17884 loss)
I0523 02:49:13.087249 34819 sgd_solver.cpp:112] Iteration 35780, lr = 0.01
I0523 02:49:18.777709 34819 solver.cpp:239] Iteration 35790 (1.57018 iter/s, 6.36871s/10 iters), loss = 8.77182
I0523 02:49:18.777747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77182 (* 1 = 8.77182 loss)
I0523 02:49:19.512027 34819 sgd_solver.cpp:112] Iteration 35790, lr = 0.01
I0523 02:49:24.398871 34819 solver.cpp:239] Iteration 35800 (1.77908 iter/s, 5.62089s/10 iters), loss = 9.40661
I0523 02:49:24.399015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40661 (* 1 = 9.40661 loss)
I0523 02:49:24.472515 34819 sgd_solver.cpp:112] Iteration 35800, lr = 0.01
I0523 02:49:29.984634 34819 solver.cpp:239] Iteration 35810 (1.79039 iter/s, 5.58537s/10 iters), loss = 8.91518
I0523 02:49:29.984683 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91518 (* 1 = 8.91518 loss)
I0523 02:49:30.756815 34819 sgd_solver.cpp:112] Iteration 35810, lr = 0.01
I0523 02:49:36.208210 34819 solver.cpp:239] Iteration 35820 (1.60687 iter/s, 6.22327s/10 iters), loss = 8.27933
I0523 02:49:36.208252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27933 (* 1 = 8.27933 loss)
I0523 02:49:37.048184 34819 sgd_solver.cpp:112] Iteration 35820, lr = 0.01
I0523 02:49:41.962143 34819 solver.cpp:239] Iteration 35830 (1.73803 iter/s, 5.75364s/10 iters), loss = 8.51923
I0523 02:49:41.962183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51923 (* 1 = 8.51923 loss)
I0523 02:49:42.021437 34819 sgd_solver.cpp:112] Iteration 35830, lr = 0.01
I0523 02:49:47.669271 34819 solver.cpp:239] Iteration 35840 (1.75228 iter/s, 5.70684s/10 iters), loss = 9.46301
I0523 02:49:47.669318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.46301 (* 1 = 9.46301 loss)
I0523 02:49:47.736356 34819 sgd_solver.cpp:112] Iteration 35840, lr = 0.01
I0523 02:49:53.517938 34819 solver.cpp:239] Iteration 35850 (1.70988 iter/s, 5.84836s/10 iters), loss = 8.98315
I0523 02:49:53.517987 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98315 (* 1 = 8.98315 loss)
I0523 02:49:53.722190 34819 sgd_solver.cpp:112] Iteration 35850, lr = 0.01
I0523 02:49:57.080902 34819 solver.cpp:239] Iteration 35860 (2.80682 iter/s, 3.56275s/10 iters), loss = 8.90093
I0523 02:49:57.081041 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90093 (* 1 = 8.90093 loss)
I0523 02:49:57.159893 34819 sgd_solver.cpp:112] Iteration 35860, lr = 0.01
I0523 02:50:02.602393 34819 solver.cpp:239] Iteration 35870 (1.81122 iter/s, 5.52113s/10 iters), loss = 9.67527
I0523 02:50:02.602442 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67527 (* 1 = 9.67527 loss)
I0523 02:50:03.287010 34819 sgd_solver.cpp:112] Iteration 35870, lr = 0.01
I0523 02:50:06.761443 34819 solver.cpp:239] Iteration 35880 (2.40453 iter/s, 4.15882s/10 iters), loss = 9.67622
I0523 02:50:06.761492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67622 (* 1 = 9.67622 loss)
I0523 02:50:07.595847 34819 sgd_solver.cpp:112] Iteration 35880, lr = 0.01
I0523 02:50:11.809365 34819 solver.cpp:239] Iteration 35890 (1.98112 iter/s, 5.04766s/10 iters), loss = 8.83272
I0523 02:50:11.809406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83272 (* 1 = 8.83272 loss)
I0523 02:50:11.867344 34819 sgd_solver.cpp:112] Iteration 35890, lr = 0.01
I0523 02:50:16.506352 34819 solver.cpp:239] Iteration 35900 (2.12915 iter/s, 4.69672s/10 iters), loss = 8.91412
I0523 02:50:16.506415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91412 (* 1 = 8.91412 loss)
I0523 02:50:17.395782 34819 sgd_solver.cpp:112] Iteration 35900, lr = 0.01
I0523 02:50:22.103662 34819 solver.cpp:239] Iteration 35910 (1.78667 iter/s, 5.59701s/10 iters), loss = 7.78684
I0523 02:50:22.103704 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78684 (* 1 = 7.78684 loss)
I0523 02:50:22.179051 34819 sgd_solver.cpp:112] Iteration 35910, lr = 0.01
I0523 02:50:27.207840 34819 solver.cpp:239] Iteration 35920 (1.95928 iter/s, 5.10392s/10 iters), loss = 8.96084
I0523 02:50:27.208050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96084 (* 1 = 8.96084 loss)
I0523 02:50:28.010790 34819 sgd_solver.cpp:112] Iteration 35920, lr = 0.01
I0523 02:50:31.407840 34819 solver.cpp:239] Iteration 35930 (2.38117 iter/s, 4.19962s/10 iters), loss = 8.49228
I0523 02:50:31.407891 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49228 (* 1 = 8.49228 loss)
I0523 02:50:31.478019 34819 sgd_solver.cpp:112] Iteration 35930, lr = 0.01
I0523 02:50:36.786510 34819 solver.cpp:239] Iteration 35940 (1.85929 iter/s, 5.37839s/10 iters), loss = 8.38247
I0523 02:50:36.786566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38247 (* 1 = 8.38247 loss)
I0523 02:50:37.652722 34819 sgd_solver.cpp:112] Iteration 35940, lr = 0.01
I0523 02:50:44.018240 34819 solver.cpp:239] Iteration 35950 (1.38286 iter/s, 7.23138s/10 iters), loss = 7.69709
I0523 02:50:44.018280 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69709 (* 1 = 7.69709 loss)
I0523 02:50:44.081079 34819 sgd_solver.cpp:112] Iteration 35950, lr = 0.01
I0523 02:50:48.112157 34819 solver.cpp:239] Iteration 35960 (2.44278 iter/s, 4.0937s/10 iters), loss = 8.14847
I0523 02:50:48.112201 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14847 (* 1 = 8.14847 loss)
I0523 02:50:48.181465 34819 sgd_solver.cpp:112] Iteration 35960, lr = 0.01
I0523 02:50:53.673389 34819 solver.cpp:239] Iteration 35970 (1.79825 iter/s, 5.56096s/10 iters), loss = 7.8045
I0523 02:50:53.673439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8045 (* 1 = 7.8045 loss)
I0523 02:50:54.450001 34819 sgd_solver.cpp:112] Iteration 35970, lr = 0.01
I0523 02:50:59.486873 34819 solver.cpp:239] Iteration 35980 (1.72022 iter/s, 5.8132s/10 iters), loss = 8.12335
I0523 02:50:59.486989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12335 (* 1 = 8.12335 loss)
I0523 02:50:59.567564 34819 sgd_solver.cpp:112] Iteration 35980, lr = 0.01
I0523 02:51:03.258321 34819 solver.cpp:239] Iteration 35990 (2.6517 iter/s, 3.77117s/10 iters), loss = 9.86667
I0523 02:51:03.258361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.86667 (* 1 = 9.86667 loss)
I0523 02:51:03.328169 34819 sgd_solver.cpp:112] Iteration 35990, lr = 0.01
I0523 02:51:09.016566 34819 solver.cpp:239] Iteration 36000 (1.73673 iter/s, 5.75796s/10 iters), loss = 7.92018
I0523 02:51:09.016605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92018 (* 1 = 7.92018 loss)
I0523 02:51:09.068377 34819 sgd_solver.cpp:112] Iteration 36000, lr = 0.01
I0523 02:51:15.064556 34819 solver.cpp:239] Iteration 36010 (1.65352 iter/s, 6.0477s/10 iters), loss = 7.7545
I0523 02:51:15.064596 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7545 (* 1 = 7.7545 loss)
I0523 02:51:15.891445 34819 sgd_solver.cpp:112] Iteration 36010, lr = 0.01
I0523 02:51:20.282722 34819 solver.cpp:239] Iteration 36020 (1.91648 iter/s, 5.2179s/10 iters), loss = 8.79684
I0523 02:51:20.282766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79684 (* 1 = 8.79684 loss)
I0523 02:51:20.340739 34819 sgd_solver.cpp:112] Iteration 36020, lr = 0.01
I0523 02:51:25.341823 34819 solver.cpp:239] Iteration 36030 (1.97674 iter/s, 5.05882s/10 iters), loss = 8.96003
I0523 02:51:25.341881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96003 (* 1 = 8.96003 loss)
I0523 02:51:26.192572 34819 sgd_solver.cpp:112] Iteration 36030, lr = 0.01
I0523 02:51:30.573264 34819 solver.cpp:239] Iteration 36040 (1.91162 iter/s, 5.23116s/10 iters), loss = 8.91848
I0523 02:51:30.573427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91848 (* 1 = 8.91848 loss)
I0523 02:51:30.647059 34819 sgd_solver.cpp:112] Iteration 36040, lr = 0.01
I0523 02:51:36.310760 34819 solver.cpp:239] Iteration 36050 (1.74304 iter/s, 5.7371s/10 iters), loss = 9.70271
I0523 02:51:36.310801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70271 (* 1 = 9.70271 loss)
I0523 02:51:36.389433 34819 sgd_solver.cpp:112] Iteration 36050, lr = 0.01
I0523 02:51:41.891284 34819 solver.cpp:239] Iteration 36060 (1.79204 iter/s, 5.58024s/10 iters), loss = 8.96526
I0523 02:51:41.891337 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96526 (* 1 = 8.96526 loss)
I0523 02:51:41.963538 34819 sgd_solver.cpp:112] Iteration 36060, lr = 0.01
I0523 02:51:47.359211 34819 solver.cpp:239] Iteration 36070 (1.82894 iter/s, 5.46765s/10 iters), loss = 8.08332
I0523 02:51:47.359253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08332 (* 1 = 8.08332 loss)
I0523 02:51:47.414937 34819 sgd_solver.cpp:112] Iteration 36070, lr = 0.01
I0523 02:51:52.951838 34819 solver.cpp:239] Iteration 36080 (1.78816 iter/s, 5.59234s/10 iters), loss = 9.18226
I0523 02:51:52.951887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18226 (* 1 = 9.18226 loss)
I0523 02:51:53.012065 34819 sgd_solver.cpp:112] Iteration 36080, lr = 0.01
I0523 02:51:58.571725 34819 solver.cpp:239] Iteration 36090 (1.77948 iter/s, 5.61961s/10 iters), loss = 9.02315
I0523 02:51:58.571768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02315 (* 1 = 9.02315 loss)
I0523 02:51:59.289933 34819 sgd_solver.cpp:112] Iteration 36090, lr = 0.01
I0523 02:52:04.038643 34819 solver.cpp:239] Iteration 36100 (1.82927 iter/s, 5.46665s/10 iters), loss = 8.60271
I0523 02:52:04.038807 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60271 (* 1 = 8.60271 loss)
I0523 02:52:04.102214 34819 sgd_solver.cpp:112] Iteration 36100, lr = 0.01
I0523 02:52:08.459519 34819 solver.cpp:239] Iteration 36110 (2.26217 iter/s, 4.42053s/10 iters), loss = 8.7696
I0523 02:52:08.459558 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7696 (* 1 = 8.7696 loss)
I0523 02:52:09.314110 34819 sgd_solver.cpp:112] Iteration 36110, lr = 0.01
I0523 02:52:16.015044 34819 solver.cpp:239] Iteration 36120 (1.3236 iter/s, 7.55517s/10 iters), loss = 9.23771
I0523 02:52:16.015087 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23771 (* 1 = 9.23771 loss)
I0523 02:52:16.864115 34819 sgd_solver.cpp:112] Iteration 36120, lr = 0.01
I0523 02:52:23.181855 34819 solver.cpp:239] Iteration 36130 (1.39539 iter/s, 7.16648s/10 iters), loss = 8.37509
I0523 02:52:23.181896 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37509 (* 1 = 8.37509 loss)
I0523 02:52:23.253319 34819 sgd_solver.cpp:112] Iteration 36130, lr = 0.01
I0523 02:52:27.633409 34819 solver.cpp:239] Iteration 36140 (2.24653 iter/s, 4.45132s/10 iters), loss = 9.24478
I0523 02:52:27.633447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24478 (* 1 = 9.24478 loss)
I0523 02:52:28.448832 34819 sgd_solver.cpp:112] Iteration 36140, lr = 0.01
I0523 02:52:34.165902 34819 solver.cpp:239] Iteration 36150 (1.53088 iter/s, 6.53219s/10 iters), loss = 7.91903
I0523 02:52:34.166057 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91903 (* 1 = 7.91903 loss)
I0523 02:52:34.246273 34819 sgd_solver.cpp:112] Iteration 36150, lr = 0.01
I0523 02:52:39.882439 34819 solver.cpp:239] Iteration 36160 (1.74943 iter/s, 5.71615s/10 iters), loss = 9.42249
I0523 02:52:39.882483 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42249 (* 1 = 9.42249 loss)
I0523 02:52:39.952528 34819 sgd_solver.cpp:112] Iteration 36160, lr = 0.01
I0523 02:52:46.250211 34819 solver.cpp:239] Iteration 36170 (1.57048 iter/s, 6.36747s/10 iters), loss = 8.41432
I0523 02:52:46.250262 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41432 (* 1 = 8.41432 loss)
I0523 02:52:46.325286 34819 sgd_solver.cpp:112] Iteration 36170, lr = 0.01
I0523 02:52:49.855314 34819 solver.cpp:239] Iteration 36180 (2.774 iter/s, 3.6049s/10 iters), loss = 8.66173
I0523 02:52:49.855355 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66173 (* 1 = 8.66173 loss)
I0523 02:52:49.924309 34819 sgd_solver.cpp:112] Iteration 36180, lr = 0.01
I0523 02:52:53.656249 34819 solver.cpp:239] Iteration 36190 (2.63108 iter/s, 3.80072s/10 iters), loss = 7.92597
I0523 02:52:53.656287 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92597 (* 1 = 7.92597 loss)
I0523 02:52:53.711494 34819 sgd_solver.cpp:112] Iteration 36190, lr = 0.01
I0523 02:53:00.661046 34819 solver.cpp:239] Iteration 36200 (1.42766 iter/s, 7.00448s/10 iters), loss = 9.50954
I0523 02:53:00.661101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50954 (* 1 = 9.50954 loss)
I0523 02:53:00.737689 34819 sgd_solver.cpp:112] Iteration 36200, lr = 0.01
I0523 02:53:04.818822 34819 solver.cpp:239] Iteration 36210 (2.40527 iter/s, 4.15754s/10 iters), loss = 8.5842
I0523 02:53:04.818953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5842 (* 1 = 8.5842 loss)
I0523 02:53:05.585741 34819 sgd_solver.cpp:112] Iteration 36210, lr = 0.01
I0523 02:53:08.642891 34819 solver.cpp:239] Iteration 36220 (2.61522 iter/s, 3.82377s/10 iters), loss = 8.59777
I0523 02:53:08.642946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59777 (* 1 = 8.59777 loss)
I0523 02:53:08.714840 34819 sgd_solver.cpp:112] Iteration 36220, lr = 0.01
I0523 02:53:14.397172 34819 solver.cpp:239] Iteration 36230 (1.73792 iter/s, 5.75399s/10 iters), loss = 8.17923
I0523 02:53:14.397225 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17923 (* 1 = 8.17923 loss)
I0523 02:53:15.222749 34819 sgd_solver.cpp:112] Iteration 36230, lr = 0.01
I0523 02:53:19.853514 34819 solver.cpp:239] Iteration 36240 (1.83282 iter/s, 5.45606s/10 iters), loss = 8.78316
I0523 02:53:19.853567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78316 (* 1 = 8.78316 loss)
I0523 02:53:20.691110 34819 sgd_solver.cpp:112] Iteration 36240, lr = 0.01
I0523 02:53:24.724277 34819 solver.cpp:239] Iteration 36250 (2.05318 iter/s, 4.8705s/10 iters), loss = 9.44798
I0523 02:53:24.724336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44798 (* 1 = 9.44798 loss)
I0523 02:53:25.548753 34819 sgd_solver.cpp:112] Iteration 36250, lr = 0.01
I0523 02:53:30.244391 34819 solver.cpp:239] Iteration 36260 (1.81165 iter/s, 5.51982s/10 iters), loss = 9.29729
I0523 02:53:30.244436 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29729 (* 1 = 9.29729 loss)
I0523 02:53:30.317400 34819 sgd_solver.cpp:112] Iteration 36260, lr = 0.01
I0523 02:53:35.984602 34819 solver.cpp:239] Iteration 36270 (1.74219 iter/s, 5.73991s/10 iters), loss = 8.29529
I0523 02:53:35.984858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29529 (* 1 = 8.29529 loss)
I0523 02:53:36.053722 34819 sgd_solver.cpp:112] Iteration 36270, lr = 0.01
I0523 02:53:38.953205 34819 solver.cpp:239] Iteration 36280 (3.36901 iter/s, 2.96823s/10 iters), loss = 8.22202
I0523 02:53:38.953250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22202 (* 1 = 8.22202 loss)
I0523 02:53:39.014822 34819 sgd_solver.cpp:112] Iteration 36280, lr = 0.01
I0523 02:53:43.540125 34819 solver.cpp:239] Iteration 36290 (2.18023 iter/s, 4.58667s/10 iters), loss = 8.3851
I0523 02:53:43.540176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3851 (* 1 = 8.3851 loss)
I0523 02:53:43.619397 34819 sgd_solver.cpp:112] Iteration 36290, lr = 0.01
I0523 02:53:49.520999 34819 solver.cpp:239] Iteration 36300 (1.67208 iter/s, 5.98058s/10 iters), loss = 9.43803
I0523 02:53:49.521054 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43803 (* 1 = 9.43803 loss)
I0523 02:53:49.590121 34819 sgd_solver.cpp:112] Iteration 36300, lr = 0.01
I0523 02:53:52.987466 34819 solver.cpp:239] Iteration 36310 (2.88497 iter/s, 3.46625s/10 iters), loss = 8.49897
I0523 02:53:52.987514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49897 (* 1 = 8.49897 loss)
I0523 02:53:53.053066 34819 sgd_solver.cpp:112] Iteration 36310, lr = 0.01
I0523 02:53:58.014546 34819 solver.cpp:239] Iteration 36320 (1.98933 iter/s, 5.02681s/10 iters), loss = 9.10913
I0523 02:53:58.014590 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10913 (* 1 = 9.10913 loss)
I0523 02:53:58.072846 34819 sgd_solver.cpp:112] Iteration 36320, lr = 0.01
I0523 02:54:02.942070 34819 solver.cpp:239] Iteration 36330 (2.02952 iter/s, 4.92727s/10 iters), loss = 9.06869
I0523 02:54:02.942131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06869 (* 1 = 9.06869 loss)
I0523 02:54:03.478199 34819 sgd_solver.cpp:112] Iteration 36330, lr = 0.01
I0523 02:54:07.354849 34819 solver.cpp:239] Iteration 36340 (2.26628 iter/s, 4.41252s/10 iters), loss = 8.90668
I0523 02:54:07.354985 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90668 (* 1 = 8.90668 loss)
I0523 02:54:07.411181 34819 sgd_solver.cpp:112] Iteration 36340, lr = 0.01
I0523 02:54:12.468142 34819 solver.cpp:239] Iteration 36350 (1.95582 iter/s, 5.11295s/10 iters), loss = 8.97467
I0523 02:54:12.468183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97467 (* 1 = 8.97467 loss)
I0523 02:54:13.287803 34819 sgd_solver.cpp:112] Iteration 36350, lr = 0.01
I0523 02:54:16.751500 34819 solver.cpp:239] Iteration 36360 (2.33474 iter/s, 4.28314s/10 iters), loss = 8.01384
I0523 02:54:16.751545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01384 (* 1 = 8.01384 loss)
I0523 02:54:16.827461 34819 sgd_solver.cpp:112] Iteration 36360, lr = 0.01
I0523 02:54:22.311199 34819 solver.cpp:239] Iteration 36370 (1.79875 iter/s, 5.55942s/10 iters), loss = 9.39807
I0523 02:54:22.311241 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39807 (* 1 = 9.39807 loss)
I0523 02:54:22.375109 34819 sgd_solver.cpp:112] Iteration 36370, lr = 0.01
I0523 02:54:24.952360 34819 solver.cpp:239] Iteration 36380 (3.78645 iter/s, 2.641s/10 iters), loss = 8.94026
I0523 02:54:24.952406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94026 (* 1 = 8.94026 loss)
I0523 02:54:25.022008 34819 sgd_solver.cpp:112] Iteration 36380, lr = 0.01
I0523 02:54:28.402405 34819 solver.cpp:239] Iteration 36390 (2.89868 iter/s, 3.44984s/10 iters), loss = 8.98895
I0523 02:54:28.402444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98895 (* 1 = 8.98895 loss)
I0523 02:54:28.463007 34819 sgd_solver.cpp:112] Iteration 36390, lr = 0.01
I0523 02:54:33.059219 34819 solver.cpp:239] Iteration 36400 (2.1475 iter/s, 4.65658s/10 iters), loss = 9.43789
I0523 02:54:33.059257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43789 (* 1 = 9.43789 loss)
I0523 02:54:33.133620 34819 sgd_solver.cpp:112] Iteration 36400, lr = 0.01
I0523 02:54:37.887204 34819 solver.cpp:239] Iteration 36410 (2.07136 iter/s, 4.82774s/10 iters), loss = 9.7384
I0523 02:54:37.887341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.7384 (* 1 = 9.7384 loss)
I0523 02:54:38.618518 34819 sgd_solver.cpp:112] Iteration 36410, lr = 0.01
I0523 02:54:43.337007 34819 solver.cpp:239] Iteration 36420 (1.83505 iter/s, 5.44943s/10 iters), loss = 8.15704
I0523 02:54:43.337055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15704 (* 1 = 8.15704 loss)
I0523 02:54:43.404911 34819 sgd_solver.cpp:112] Iteration 36420, lr = 0.01
I0523 02:54:47.617069 34819 solver.cpp:239] Iteration 36430 (2.33654 iter/s, 4.27984s/10 iters), loss = 9.60236
I0523 02:54:47.617110 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60236 (* 1 = 9.60236 loss)
I0523 02:54:47.684300 34819 sgd_solver.cpp:112] Iteration 36430, lr = 0.01
I0523 02:54:52.468641 34819 solver.cpp:239] Iteration 36440 (2.06129 iter/s, 4.85132s/10 iters), loss = 8.5366
I0523 02:54:52.468690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5366 (* 1 = 8.5366 loss)
I0523 02:54:53.270607 34819 sgd_solver.cpp:112] Iteration 36440, lr = 0.01
I0523 02:54:59.154076 34819 solver.cpp:239] Iteration 36450 (1.49587 iter/s, 6.68507s/10 iters), loss = 8.40088
I0523 02:54:59.154124 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40088 (* 1 = 8.40088 loss)
I0523 02:54:59.790704 34819 sgd_solver.cpp:112] Iteration 36450, lr = 0.01
I0523 02:55:04.025099 34819 solver.cpp:239] Iteration 36460 (2.05307 iter/s, 4.87076s/10 iters), loss = 8.56843
I0523 02:55:04.025151 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56843 (* 1 = 8.56843 loss)
I0523 02:55:04.861307 34819 sgd_solver.cpp:112] Iteration 36460, lr = 0.01
I0523 02:55:10.107890 34819 solver.cpp:239] Iteration 36470 (1.64406 iter/s, 6.08249s/10 iters), loss = 9.18268
I0523 02:55:10.108034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18268 (* 1 = 9.18268 loss)
I0523 02:55:10.940286 34819 sgd_solver.cpp:112] Iteration 36470, lr = 0.01
I0523 02:55:16.539901 34819 solver.cpp:239] Iteration 36480 (1.55483 iter/s, 6.43157s/10 iters), loss = 9.00755
I0523 02:55:16.539958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00755 (* 1 = 9.00755 loss)
I0523 02:55:17.381480 34819 sgd_solver.cpp:112] Iteration 36480, lr = 0.01
I0523 02:55:23.637960 34819 solver.cpp:239] Iteration 36490 (1.4089 iter/s, 7.09771s/10 iters), loss = 10.0835
I0523 02:55:23.638001 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0835 (* 1 = 10.0835 loss)
I0523 02:55:23.700541 34819 sgd_solver.cpp:112] Iteration 36490, lr = 0.01
I0523 02:55:30.209089 34819 solver.cpp:239] Iteration 36500 (1.52188 iter/s, 6.57081s/10 iters), loss = 9.06269
I0523 02:55:30.209136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06269 (* 1 = 9.06269 loss)
I0523 02:55:30.279983 34819 sgd_solver.cpp:112] Iteration 36500, lr = 0.01
I0523 02:55:35.148880 34819 solver.cpp:239] Iteration 36510 (2.02449 iter/s, 4.93952s/10 iters), loss = 9.47751
I0523 02:55:35.148918 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47751 (* 1 = 9.47751 loss)
I0523 02:55:35.207998 34819 sgd_solver.cpp:112] Iteration 36510, lr = 0.01
I0523 02:55:40.681684 34819 solver.cpp:239] Iteration 36520 (1.80749 iter/s, 5.53253s/10 iters), loss = 8.76134
I0523 02:55:40.681820 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76134 (* 1 = 8.76134 loss)
I0523 02:55:41.354557 34819 sgd_solver.cpp:112] Iteration 36520, lr = 0.01
I0523 02:55:44.116941 34819 solver.cpp:239] Iteration 36530 (2.91123 iter/s, 3.43497s/10 iters), loss = 8.23049
I0523 02:55:44.116994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23049 (* 1 = 8.23049 loss)
I0523 02:55:44.200733 34819 sgd_solver.cpp:112] Iteration 36530, lr = 0.01
I0523 02:55:49.012013 34819 solver.cpp:239] Iteration 36540 (2.04298 iter/s, 4.8948s/10 iters), loss = 8.53533
I0523 02:55:49.012069 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53533 (* 1 = 8.53533 loss)
I0523 02:55:49.075872 34819 sgd_solver.cpp:112] Iteration 36540, lr = 0.01
I0523 02:55:54.700134 34819 solver.cpp:239] Iteration 36550 (1.75814 iter/s, 5.68783s/10 iters), loss = 8.21708
I0523 02:55:54.700186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21708 (* 1 = 8.21708 loss)
I0523 02:55:55.540077 34819 sgd_solver.cpp:112] Iteration 36550, lr = 0.01
I0523 02:56:00.359483 34819 solver.cpp:239] Iteration 36560 (1.76708 iter/s, 5.65907s/10 iters), loss = 9.26654
I0523 02:56:00.359535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26654 (* 1 = 9.26654 loss)
I0523 02:56:00.450031 34819 sgd_solver.cpp:112] Iteration 36560, lr = 0.01
I0523 02:56:04.395867 34819 solver.cpp:239] Iteration 36570 (2.47761 iter/s, 4.03615s/10 iters), loss = 9.02418
I0523 02:56:04.395928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02418 (* 1 = 9.02418 loss)
I0523 02:56:05.176301 34819 sgd_solver.cpp:112] Iteration 36570, lr = 0.01
I0523 02:56:08.532374 34819 solver.cpp:239] Iteration 36580 (2.41764 iter/s, 4.13627s/10 iters), loss = 8.903
I0523 02:56:08.532424 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.903 (* 1 = 8.903 loss)
I0523 02:56:09.377732 34819 sgd_solver.cpp:112] Iteration 36580, lr = 0.01
I0523 02:56:13.506069 34819 solver.cpp:239] Iteration 36590 (2.01243 iter/s, 4.96911s/10 iters), loss = 8.90404
I0523 02:56:13.506309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90404 (* 1 = 8.90404 loss)
I0523 02:56:13.580437 34819 sgd_solver.cpp:112] Iteration 36590, lr = 0.01
I0523 02:56:18.579757 34819 solver.cpp:239] Iteration 36600 (1.97112 iter/s, 5.07326s/10 iters), loss = 8.65181
I0523 02:56:18.579808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65181 (* 1 = 8.65181 loss)
I0523 02:56:18.660933 34819 sgd_solver.cpp:112] Iteration 36600, lr = 0.01
I0523 02:56:22.075084 34819 solver.cpp:239] Iteration 36610 (2.86114 iter/s, 3.49511s/10 iters), loss = 8.85719
I0523 02:56:22.075129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85719 (* 1 = 8.85719 loss)
I0523 02:56:22.869014 34819 sgd_solver.cpp:112] Iteration 36610, lr = 0.01
I0523 02:56:27.304786 34819 solver.cpp:239] Iteration 36620 (1.91225 iter/s, 5.22944s/10 iters), loss = 8.37565
I0523 02:56:27.304836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37565 (* 1 = 8.37565 loss)
I0523 02:56:27.361510 34819 sgd_solver.cpp:112] Iteration 36620, lr = 0.01
I0523 02:56:31.465620 34819 solver.cpp:239] Iteration 36630 (2.4035 iter/s, 4.1606s/10 iters), loss = 9.77118
I0523 02:56:31.465662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.77118 (* 1 = 9.77118 loss)
I0523 02:56:31.516247 34819 sgd_solver.cpp:112] Iteration 36630, lr = 0.01
I0523 02:56:36.432895 34819 solver.cpp:239] Iteration 36640 (2.01328 iter/s, 4.96701s/10 iters), loss = 8.82157
I0523 02:56:36.432952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82157 (* 1 = 8.82157 loss)
I0523 02:56:36.500188 34819 sgd_solver.cpp:112] Iteration 36640, lr = 0.01
I0523 02:56:41.334035 34819 solver.cpp:239] Iteration 36650 (2.04045 iter/s, 4.90088s/10 iters), loss = 9.48965
I0523 02:56:41.334086 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48965 (* 1 = 9.48965 loss)
I0523 02:56:41.395988 34819 sgd_solver.cpp:112] Iteration 36650, lr = 0.01
I0523 02:56:45.426093 34819 solver.cpp:239] Iteration 36660 (2.44389 iter/s, 4.09183s/10 iters), loss = 9.04595
I0523 02:56:45.426239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04595 (* 1 = 9.04595 loss)
I0523 02:56:45.489639 34819 sgd_solver.cpp:112] Iteration 36660, lr = 0.01
I0523 02:56:49.563098 34819 solver.cpp:239] Iteration 36670 (2.4174 iter/s, 4.13668s/10 iters), loss = 8.55224
I0523 02:56:49.563141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55224 (* 1 = 8.55224 loss)
I0523 02:56:49.619714 34819 sgd_solver.cpp:112] Iteration 36670, lr = 0.01
I0523 02:56:52.989681 34819 solver.cpp:239] Iteration 36680 (2.91852 iter/s, 3.42639s/10 iters), loss = 8.05541
I0523 02:56:52.989732 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05541 (* 1 = 8.05541 loss)
I0523 02:56:53.058699 34819 sgd_solver.cpp:112] Iteration 36680, lr = 0.01
I0523 02:56:56.966135 34819 solver.cpp:239] Iteration 36690 (2.51494 iter/s, 3.97624s/10 iters), loss = 8.45082
I0523 02:56:56.966189 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45082 (* 1 = 8.45082 loss)
I0523 02:56:57.042171 34819 sgd_solver.cpp:112] Iteration 36690, lr = 0.01
I0523 02:57:03.175050 34819 solver.cpp:239] Iteration 36700 (1.61067 iter/s, 6.20861s/10 iters), loss = 8.3607
I0523 02:57:03.175102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3607 (* 1 = 8.3607 loss)
I0523 02:57:03.947391 34819 sgd_solver.cpp:112] Iteration 36700, lr = 0.01
I0523 02:57:08.000138 34819 solver.cpp:239] Iteration 36710 (2.07262 iter/s, 4.82482s/10 iters), loss = 8.90399
I0523 02:57:08.000190 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90399 (* 1 = 8.90399 loss)
I0523 02:57:08.078510 34819 sgd_solver.cpp:112] Iteration 36710, lr = 0.01
I0523 02:57:13.520752 34819 solver.cpp:239] Iteration 36720 (1.81148 iter/s, 5.52033s/10 iters), loss = 9.02745
I0523 02:57:13.520809 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02745 (* 1 = 9.02745 loss)
I0523 02:57:14.369366 34819 sgd_solver.cpp:112] Iteration 36720, lr = 0.01
I0523 02:57:19.185456 34819 solver.cpp:239] Iteration 36730 (1.76542 iter/s, 5.66439s/10 iters), loss = 8.3821
I0523 02:57:19.185640 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3821 (* 1 = 8.3821 loss)
I0523 02:57:19.977509 34819 sgd_solver.cpp:112] Iteration 36730, lr = 0.01
I0523 02:57:24.757611 34819 solver.cpp:239] Iteration 36740 (1.79477 iter/s, 5.57174s/10 iters), loss = 9.55102
I0523 02:57:24.757653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55102 (* 1 = 9.55102 loss)
I0523 02:57:24.811277 34819 sgd_solver.cpp:112] Iteration 36740, lr = 0.01
I0523 02:57:28.772877 34819 solver.cpp:239] Iteration 36750 (2.49063 iter/s, 4.01505s/10 iters), loss = 9.62183
I0523 02:57:28.772919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.62183 (* 1 = 9.62183 loss)
I0523 02:57:28.841794 34819 sgd_solver.cpp:112] Iteration 36750, lr = 0.01
I0523 02:57:32.710479 34819 solver.cpp:239] Iteration 36760 (2.53976 iter/s, 3.93738s/10 iters), loss = 8.7299
I0523 02:57:32.710518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7299 (* 1 = 8.7299 loss)
I0523 02:57:33.363340 34819 sgd_solver.cpp:112] Iteration 36760, lr = 0.01
I0523 02:57:37.410598 34819 solver.cpp:239] Iteration 36770 (2.12772 iter/s, 4.69987s/10 iters), loss = 8.93694
I0523 02:57:37.410646 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93694 (* 1 = 8.93694 loss)
I0523 02:57:38.174980 34819 sgd_solver.cpp:112] Iteration 36770, lr = 0.01
I0523 02:57:44.282171 34819 solver.cpp:239] Iteration 36780 (1.45534 iter/s, 6.87124s/10 iters), loss = 9.68936
I0523 02:57:44.282213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68936 (* 1 = 9.68936 loss)
I0523 02:57:45.088294 34819 sgd_solver.cpp:112] Iteration 36780, lr = 0.01
I0523 02:57:49.844612 34819 solver.cpp:239] Iteration 36790 (1.79786 iter/s, 5.56216s/10 iters), loss = 8.52881
I0523 02:57:49.844745 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52881 (* 1 = 8.52881 loss)
I0523 02:57:50.338999 34819 sgd_solver.cpp:112] Iteration 36790, lr = 0.01
I0523 02:57:55.741863 34819 solver.cpp:239] Iteration 36800 (1.69582 iter/s, 5.89685s/10 iters), loss = 9.93791
I0523 02:57:55.741914 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93791 (* 1 = 9.93791 loss)
I0523 02:57:56.520562 34819 sgd_solver.cpp:112] Iteration 36800, lr = 0.01
I0523 02:57:59.402897 34819 solver.cpp:239] Iteration 36810 (2.73163 iter/s, 3.66081s/10 iters), loss = 9.16747
I0523 02:57:59.402954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16747 (* 1 = 9.16747 loss)
I0523 02:57:59.465135 34819 sgd_solver.cpp:112] Iteration 36810, lr = 0.01
I0523 02:58:03.676271 34819 solver.cpp:239] Iteration 36820 (2.3402 iter/s, 4.27314s/10 iters), loss = 9.42477
I0523 02:58:03.676311 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42477 (* 1 = 9.42477 loss)
I0523 02:58:03.744267 34819 sgd_solver.cpp:112] Iteration 36820, lr = 0.01
I0523 02:58:09.648847 34819 solver.cpp:239] Iteration 36830 (1.6744 iter/s, 5.97228s/10 iters), loss = 8.57707
I0523 02:58:09.648888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57707 (* 1 = 8.57707 loss)
I0523 02:58:10.346588 34819 sgd_solver.cpp:112] Iteration 36830, lr = 0.01
I0523 02:58:14.413229 34819 solver.cpp:239] Iteration 36840 (2.09902 iter/s, 4.76413s/10 iters), loss = 8.53048
I0523 02:58:14.413271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53048 (* 1 = 8.53048 loss)
I0523 02:58:15.278741 34819 sgd_solver.cpp:112] Iteration 36840, lr = 0.01
I0523 02:58:20.490687 34819 solver.cpp:239] Iteration 36850 (1.6455 iter/s, 6.07716s/10 iters), loss = 10.2297
I0523 02:58:20.490839 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.2297 (* 1 = 10.2297 loss)
I0523 02:58:20.555253 34819 sgd_solver.cpp:112] Iteration 36850, lr = 0.01
I0523 02:58:25.466540 34819 solver.cpp:239] Iteration 36860 (2.00985 iter/s, 4.97549s/10 iters), loss = 9.0547
I0523 02:58:25.466579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0547 (* 1 = 9.0547 loss)
I0523 02:58:25.541849 34819 sgd_solver.cpp:112] Iteration 36860, lr = 0.01
I0523 02:58:30.419675 34819 solver.cpp:239] Iteration 36870 (2.01903 iter/s, 4.95288s/10 iters), loss = 8.94422
I0523 02:58:30.419716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94422 (* 1 = 8.94422 loss)
I0523 02:58:30.500527 34819 sgd_solver.cpp:112] Iteration 36870, lr = 0.01
I0523 02:58:35.252681 34819 solver.cpp:239] Iteration 36880 (2.06921 iter/s, 4.83276s/10 iters), loss = 7.99476
I0523 02:58:35.252722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99476 (* 1 = 7.99476 loss)
I0523 02:58:35.313783 34819 sgd_solver.cpp:112] Iteration 36880, lr = 0.01
I0523 02:58:40.997092 34819 solver.cpp:239] Iteration 36890 (1.74091 iter/s, 5.74413s/10 iters), loss = 9.43207
I0523 02:58:40.997135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43207 (* 1 = 9.43207 loss)
I0523 02:58:41.067308 34819 sgd_solver.cpp:112] Iteration 36890, lr = 0.01
I0523 02:58:44.424113 34819 solver.cpp:239] Iteration 36900 (2.91819 iter/s, 3.42678s/10 iters), loss = 9.29709
I0523 02:58:44.424170 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29709 (* 1 = 9.29709 loss)
I0523 02:58:45.129953 34819 sgd_solver.cpp:112] Iteration 36900, lr = 0.01
I0523 02:58:51.023285 34819 solver.cpp:239] Iteration 36910 (1.51542 iter/s, 6.59884s/10 iters), loss = 8.7009
I0523 02:58:51.023406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7009 (* 1 = 8.7009 loss)
I0523 02:58:51.162487 34819 sgd_solver.cpp:112] Iteration 36910, lr = 0.01
I0523 02:58:57.457018 34819 solver.cpp:239] Iteration 36920 (1.5544 iter/s, 6.43336s/10 iters), loss = 9.03988
I0523 02:58:57.457060 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03988 (* 1 = 9.03988 loss)
I0523 02:58:58.317896 34819 sgd_solver.cpp:112] Iteration 36920, lr = 0.01
I0523 02:59:00.969254 34819 solver.cpp:239] Iteration 36930 (2.84735 iter/s, 3.51204s/10 iters), loss = 8.54333
I0523 02:59:00.969290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54333 (* 1 = 8.54333 loss)
I0523 02:59:01.665279 34819 sgd_solver.cpp:112] Iteration 36930, lr = 0.01
I0523 02:59:05.679531 34819 solver.cpp:239] Iteration 36940 (2.12313 iter/s, 4.71004s/10 iters), loss = 9.60839
I0523 02:59:05.679572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60839 (* 1 = 9.60839 loss)
I0523 02:59:06.229395 34819 sgd_solver.cpp:112] Iteration 36940, lr = 0.01
I0523 02:59:12.220906 34819 solver.cpp:239] Iteration 36950 (1.5288 iter/s, 6.54106s/10 iters), loss = 8.49022
I0523 02:59:12.220944 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49022 (* 1 = 8.49022 loss)
I0523 02:59:12.296036 34819 sgd_solver.cpp:112] Iteration 36950, lr = 0.01
I0523 02:59:14.850646 34819 solver.cpp:239] Iteration 36960 (3.80289 iter/s, 2.62958s/10 iters), loss = 9.48139
I0523 02:59:14.850687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48139 (* 1 = 9.48139 loss)
I0523 02:59:15.660145 34819 sgd_solver.cpp:112] Iteration 36960, lr = 0.01
I0523 02:59:21.124992 34819 solver.cpp:239] Iteration 36970 (1.59387 iter/s, 6.27402s/10 iters), loss = 9.51262
I0523 02:59:21.125154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51262 (* 1 = 9.51262 loss)
I0523 02:59:21.986732 34819 sgd_solver.cpp:112] Iteration 36970, lr = 0.01
I0523 02:59:26.274049 34819 solver.cpp:239] Iteration 36980 (1.94225 iter/s, 5.14867s/10 iters), loss = 9.56286
I0523 02:59:26.274091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56286 (* 1 = 9.56286 loss)
I0523 02:59:26.344499 34819 sgd_solver.cpp:112] Iteration 36980, lr = 0.01
I0523 02:59:31.199973 34819 solver.cpp:239] Iteration 36990 (2.03018 iter/s, 4.92567s/10 iters), loss = 8.90085
I0523 02:59:31.200013 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90085 (* 1 = 8.90085 loss)
I0523 02:59:31.261878 34819 sgd_solver.cpp:112] Iteration 36990, lr = 0.01
I0523 02:59:35.320359 34819 solver.cpp:239] Iteration 37000 (2.42709 iter/s, 4.12016s/10 iters), loss = 9.15629
I0523 02:59:35.320402 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15629 (* 1 = 9.15629 loss)
I0523 02:59:35.384941 34819 sgd_solver.cpp:112] Iteration 37000, lr = 0.01
I0523 02:59:40.138857 34819 solver.cpp:239] Iteration 37010 (2.07544 iter/s, 4.81825s/10 iters), loss = 8.29532
I0523 02:59:40.138900 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29532 (* 1 = 8.29532 loss)
I0523 02:59:40.222707 34819 sgd_solver.cpp:112] Iteration 37010, lr = 0.01
I0523 02:59:45.212210 34819 solver.cpp:239] Iteration 37020 (1.97119 iter/s, 5.07308s/10 iters), loss = 8.53885
I0523 02:59:45.212262 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53885 (* 1 = 8.53885 loss)
I0523 02:59:45.272505 34819 sgd_solver.cpp:112] Iteration 37020, lr = 0.01
I0523 02:59:50.928846 34819 solver.cpp:239] Iteration 37030 (1.74937 iter/s, 5.71633s/10 iters), loss = 9.22346
I0523 02:59:50.928897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22346 (* 1 = 9.22346 loss)
I0523 02:59:51.454390 34819 sgd_solver.cpp:112] Iteration 37030, lr = 0.01
I0523 02:59:57.791836 34819 solver.cpp:239] Iteration 37040 (1.45716 iter/s, 6.86265s/10 iters), loss = 9.12514
I0523 02:59:57.791898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12514 (* 1 = 9.12514 loss)
I0523 02:59:58.132949 34819 sgd_solver.cpp:112] Iteration 37040, lr = 0.01
I0523 03:00:00.688385 34819 solver.cpp:239] Iteration 37050 (3.45263 iter/s, 2.89634s/10 iters), loss = 9.07919
I0523 03:00:00.688438 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07919 (* 1 = 9.07919 loss)
I0523 03:00:01.475080 34819 sgd_solver.cpp:112] Iteration 37050, lr = 0.01
I0523 03:00:07.195417 34819 solver.cpp:239] Iteration 37060 (1.53687 iter/s, 6.50672s/10 iters), loss = 8.69597
I0523 03:00:07.195461 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69597 (* 1 = 8.69597 loss)
I0523 03:00:07.267040 34819 sgd_solver.cpp:112] Iteration 37060, lr = 0.01
I0523 03:00:12.225723 34819 solver.cpp:239] Iteration 37070 (1.98805 iter/s, 5.03005s/10 iters), loss = 9.50167
I0523 03:00:12.225771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50167 (* 1 = 9.50167 loss)
I0523 03:00:13.046790 34819 sgd_solver.cpp:112] Iteration 37070, lr = 0.01
I0523 03:00:16.052459 34819 solver.cpp:239] Iteration 37080 (2.61334 iter/s, 3.82652s/10 iters), loss = 9.12693
I0523 03:00:16.052526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12693 (* 1 = 9.12693 loss)
I0523 03:00:16.931277 34819 sgd_solver.cpp:112] Iteration 37080, lr = 0.01
I0523 03:00:22.473760 34819 solver.cpp:239] Iteration 37090 (1.55739 iter/s, 6.42098s/10 iters), loss = 8.83979
I0523 03:00:22.473876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83979 (* 1 = 8.83979 loss)
I0523 03:00:22.532758 34819 sgd_solver.cpp:112] Iteration 37090, lr = 0.01
I0523 03:00:25.419790 34819 solver.cpp:239] Iteration 37100 (3.39468 iter/s, 2.94579s/10 iters), loss = 8.28114
I0523 03:00:25.419836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28114 (* 1 = 8.28114 loss)
I0523 03:00:25.499752 34819 sgd_solver.cpp:112] Iteration 37100, lr = 0.01
I0523 03:00:30.336978 34819 solver.cpp:239] Iteration 37110 (2.03379 iter/s, 4.91692s/10 iters), loss = 9.01296
I0523 03:00:30.337031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01296 (* 1 = 9.01296 loss)
I0523 03:00:30.416106 34819 sgd_solver.cpp:112] Iteration 37110, lr = 0.01
I0523 03:00:35.963464 34819 solver.cpp:239] Iteration 37120 (1.7774 iter/s, 5.6262s/10 iters), loss = 7.70086
I0523 03:00:35.963520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70086 (* 1 = 7.70086 loss)
I0523 03:00:36.624755 34819 sgd_solver.cpp:112] Iteration 37120, lr = 0.01
I0523 03:00:41.471895 34819 solver.cpp:239] Iteration 37130 (1.8155 iter/s, 5.50813s/10 iters), loss = 8.42119
I0523 03:00:41.471943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42119 (* 1 = 8.42119 loss)
I0523 03:00:41.527262 34819 sgd_solver.cpp:112] Iteration 37130, lr = 0.01
I0523 03:00:45.103279 34819 solver.cpp:239] Iteration 37140 (2.75394 iter/s, 3.63116s/10 iters), loss = 9.37647
I0523 03:00:45.103329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37647 (* 1 = 9.37647 loss)
I0523 03:00:45.698982 34819 sgd_solver.cpp:112] Iteration 37140, lr = 0.01
I0523 03:00:49.368377 34819 solver.cpp:239] Iteration 37150 (2.34474 iter/s, 4.26486s/10 iters), loss = 8.77973
I0523 03:00:49.368430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77973 (* 1 = 8.77973 loss)
I0523 03:00:50.234465 34819 sgd_solver.cpp:112] Iteration 37150, lr = 0.01
I0523 03:00:55.713289 34819 solver.cpp:239] Iteration 37160 (1.57615 iter/s, 6.34458s/10 iters), loss = 8.94413
I0523 03:00:55.713559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94413 (* 1 = 8.94413 loss)
I0523 03:00:55.794561 34819 sgd_solver.cpp:112] Iteration 37160, lr = 0.01
I0523 03:01:01.773402 34819 solver.cpp:239] Iteration 37170 (1.65027 iter/s, 6.05962s/10 iters), loss = 7.64233
I0523 03:01:01.773444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64233 (* 1 = 7.64233 loss)
I0523 03:01:02.650319 34819 sgd_solver.cpp:112] Iteration 37170, lr = 0.01
I0523 03:01:08.399514 34819 solver.cpp:239] Iteration 37180 (1.50925 iter/s, 6.6258s/10 iters), loss = 7.8907
I0523 03:01:08.399555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8907 (* 1 = 7.8907 loss)
I0523 03:01:08.467475 34819 sgd_solver.cpp:112] Iteration 37180, lr = 0.01
I0523 03:01:12.068917 34819 solver.cpp:239] Iteration 37190 (2.7254 iter/s, 3.66919s/10 iters), loss = 9.25528
I0523 03:01:12.068969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25528 (* 1 = 9.25528 loss)
I0523 03:01:12.138813 34819 sgd_solver.cpp:112] Iteration 37190, lr = 0.01
I0523 03:01:16.316339 34819 solver.cpp:239] Iteration 37200 (2.3545 iter/s, 4.24719s/10 iters), loss = 8.17653
I0523 03:01:16.316395 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17653 (* 1 = 8.17653 loss)
I0523 03:01:17.153257 34819 sgd_solver.cpp:112] Iteration 37200, lr = 0.01
I0523 03:01:20.848372 34819 solver.cpp:239] Iteration 37210 (2.20664 iter/s, 4.53178s/10 iters), loss = 8.90177
I0523 03:01:20.848426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90177 (* 1 = 8.90177 loss)
I0523 03:01:20.931640 34819 sgd_solver.cpp:112] Iteration 37210, lr = 0.01
I0523 03:01:24.192034 34819 solver.cpp:239] Iteration 37220 (2.99092 iter/s, 3.34346s/10 iters), loss = 8.32602
I0523 03:01:24.192091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32602 (* 1 = 8.32602 loss)
I0523 03:01:25.006963 34819 sgd_solver.cpp:112] Iteration 37220, lr = 0.01
I0523 03:01:29.070905 34819 solver.cpp:239] Iteration 37230 (2.04977 iter/s, 4.87861s/10 iters), loss = 8.37653
I0523 03:01:29.071089 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37653 (* 1 = 8.37653 loss)
I0523 03:01:29.128626 34819 sgd_solver.cpp:112] Iteration 37230, lr = 0.01
I0523 03:01:34.618561 34819 solver.cpp:239] Iteration 37240 (1.80269 iter/s, 5.54725s/10 iters), loss = 8.76835
I0523 03:01:34.618613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76835 (* 1 = 8.76835 loss)
I0523 03:01:35.386662 34819 sgd_solver.cpp:112] Iteration 37240, lr = 0.01
I0523 03:01:40.196041 34819 solver.cpp:239] Iteration 37250 (1.79302 iter/s, 5.57719s/10 iters), loss = 8.73771
I0523 03:01:40.196099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73771 (* 1 = 8.73771 loss)
I0523 03:01:40.252202 34819 sgd_solver.cpp:112] Iteration 37250, lr = 0.01
I0523 03:01:44.509780 34819 solver.cpp:239] Iteration 37260 (2.3183 iter/s, 4.3135s/10 iters), loss = 8.7668
I0523 03:01:44.509830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7668 (* 1 = 8.7668 loss)
I0523 03:01:44.782177 34819 sgd_solver.cpp:112] Iteration 37260, lr = 0.01
I0523 03:01:49.700433 34819 solver.cpp:239] Iteration 37270 (1.92664 iter/s, 5.19038s/10 iters), loss = 8.70052
I0523 03:01:49.700486 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70052 (* 1 = 8.70052 loss)
I0523 03:01:49.763468 34819 sgd_solver.cpp:112] Iteration 37270, lr = 0.01
I0523 03:01:54.800647 34819 solver.cpp:239] Iteration 37280 (1.96081 iter/s, 5.09995s/10 iters), loss = 9.2354
I0523 03:01:54.800703 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2354 (* 1 = 9.2354 loss)
I0523 03:01:55.668179 34819 sgd_solver.cpp:112] Iteration 37280, lr = 0.01
I0523 03:01:58.704658 34819 solver.cpp:239] Iteration 37290 (2.56161 iter/s, 3.90379s/10 iters), loss = 8.02337
I0523 03:01:58.704713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02337 (* 1 = 8.02337 loss)
I0523 03:01:59.555547 34819 sgd_solver.cpp:112] Iteration 37290, lr = 0.01
I0523 03:02:02.959089 34819 solver.cpp:239] Iteration 37300 (2.35063 iter/s, 4.25418s/10 iters), loss = 9.07304
I0523 03:02:02.959131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07304 (* 1 = 9.07304 loss)
I0523 03:02:03.014812 34819 sgd_solver.cpp:112] Iteration 37300, lr = 0.01
I0523 03:02:08.567214 34819 solver.cpp:239] Iteration 37310 (1.78322 iter/s, 5.60785s/10 iters), loss = 8.33294
I0523 03:02:08.567265 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33294 (* 1 = 8.33294 loss)
I0523 03:02:08.640105 34819 sgd_solver.cpp:112] Iteration 37310, lr = 0.01
I0523 03:02:12.566401 34819 solver.cpp:239] Iteration 37320 (2.50065 iter/s, 3.99896s/10 iters), loss = 8.90665
I0523 03:02:12.566457 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90665 (* 1 = 8.90665 loss)
I0523 03:02:12.641636 34819 sgd_solver.cpp:112] Iteration 37320, lr = 0.01
I0523 03:02:16.151911 34819 solver.cpp:239] Iteration 37330 (2.78916 iter/s, 3.5853s/10 iters), loss = 8.3708
I0523 03:02:16.151960 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3708 (* 1 = 8.3708 loss)
I0523 03:02:16.885816 34819 sgd_solver.cpp:112] Iteration 37330, lr = 0.01
I0523 03:02:21.151360 34819 solver.cpp:239] Iteration 37340 (2.00033 iter/s, 4.99918s/10 iters), loss = 9.40944
I0523 03:02:21.151414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40944 (* 1 = 9.40944 loss)
I0523 03:02:21.232318 34819 sgd_solver.cpp:112] Iteration 37340, lr = 0.01
I0523 03:02:25.336230 34819 solver.cpp:239] Iteration 37350 (2.3897 iter/s, 4.18463s/10 iters), loss = 9.59849
I0523 03:02:25.336282 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.59849 (* 1 = 9.59849 loss)
I0523 03:02:26.115615 34819 sgd_solver.cpp:112] Iteration 37350, lr = 0.01
I0523 03:02:30.778537 34819 solver.cpp:239] Iteration 37360 (1.83755 iter/s, 5.44202s/10 iters), loss = 8.10217
I0523 03:02:30.778683 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10217 (* 1 = 8.10217 loss)
I0523 03:02:30.850721 34819 sgd_solver.cpp:112] Iteration 37360, lr = 0.01
I0523 03:02:36.022533 34819 solver.cpp:239] Iteration 37370 (1.90708 iter/s, 5.24361s/10 iters), loss = 8.84659
I0523 03:02:36.022593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84659 (* 1 = 8.84659 loss)
I0523 03:02:36.091990 34819 sgd_solver.cpp:112] Iteration 37370, lr = 0.01
I0523 03:02:42.368407 34819 solver.cpp:239] Iteration 37380 (1.57591 iter/s, 6.34554s/10 iters), loss = 8.1407
I0523 03:02:42.368460 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1407 (* 1 = 8.1407 loss)
I0523 03:02:43.187069 34819 sgd_solver.cpp:112] Iteration 37380, lr = 0.01
I0523 03:02:47.973841 34819 solver.cpp:239] Iteration 37390 (1.78407 iter/s, 5.60515s/10 iters), loss = 8.9924
I0523 03:02:47.973882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9924 (* 1 = 8.9924 loss)
I0523 03:02:48.595175 34819 sgd_solver.cpp:112] Iteration 37390, lr = 0.01
I0523 03:02:53.682423 34819 solver.cpp:239] Iteration 37400 (1.75184 iter/s, 5.70829s/10 iters), loss = 9.16802
I0523 03:02:53.682478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16802 (* 1 = 9.16802 loss)
I0523 03:02:53.820926 34819 sgd_solver.cpp:112] Iteration 37400, lr = 0.01
I0523 03:02:59.341246 34819 solver.cpp:239] Iteration 37410 (1.76725 iter/s, 5.65852s/10 iters), loss = 9.35346
I0523 03:02:59.341300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35346 (* 1 = 9.35346 loss)
I0523 03:03:00.119601 34819 sgd_solver.cpp:112] Iteration 37410, lr = 0.01
I0523 03:03:05.927743 34819 solver.cpp:239] Iteration 37420 (1.51833 iter/s, 6.58618s/10 iters), loss = 8.94538
I0523 03:03:05.927886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94538 (* 1 = 8.94538 loss)
I0523 03:03:06.006633 34819 sgd_solver.cpp:112] Iteration 37420, lr = 0.01
I0523 03:03:11.594720 34819 solver.cpp:239] Iteration 37430 (1.76473 iter/s, 5.66659s/10 iters), loss = 8.86413
I0523 03:03:11.594765 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86413 (* 1 = 8.86413 loss)
I0523 03:03:11.661523 34819 sgd_solver.cpp:112] Iteration 37430, lr = 0.01
I0523 03:03:16.479724 34819 solver.cpp:239] Iteration 37440 (2.04719 iter/s, 4.88475s/10 iters), loss = 9.23917
I0523 03:03:16.479765 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23917 (* 1 = 9.23917 loss)
I0523 03:03:16.780640 34819 sgd_solver.cpp:112] Iteration 37440, lr = 0.01
I0523 03:03:22.032438 34819 solver.cpp:239] Iteration 37450 (1.80101 iter/s, 5.55243s/10 iters), loss = 8.76518
I0523 03:03:22.032485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76518 (* 1 = 8.76518 loss)
I0523 03:03:22.090850 34819 sgd_solver.cpp:112] Iteration 37450, lr = 0.01
I0523 03:03:28.695477 34819 solver.cpp:239] Iteration 37460 (1.50089 iter/s, 6.66272s/10 iters), loss = 8.75136
I0523 03:03:28.695528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75136 (* 1 = 8.75136 loss)
I0523 03:03:29.516669 34819 sgd_solver.cpp:112] Iteration 37460, lr = 0.01
I0523 03:03:33.518134 34819 solver.cpp:239] Iteration 37470 (2.07366 iter/s, 4.8224s/10 iters), loss = 8.58981
I0523 03:03:33.518175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58981 (* 1 = 8.58981 loss)
I0523 03:03:33.612320 34819 sgd_solver.cpp:112] Iteration 37470, lr = 0.01
I0523 03:03:39.118415 34819 solver.cpp:239] Iteration 37480 (1.78571 iter/s, 5.60001s/10 iters), loss = 9.27313
I0523 03:03:39.118659 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27313 (* 1 = 9.27313 loss)
I0523 03:03:39.926031 34819 sgd_solver.cpp:112] Iteration 37480, lr = 0.01
I0523 03:03:44.291236 34819 solver.cpp:239] Iteration 37490 (1.93334 iter/s, 5.17239s/10 iters), loss = 8.53184
I0523 03:03:44.291306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53184 (* 1 = 8.53184 loss)
I0523 03:03:45.133955 34819 sgd_solver.cpp:112] Iteration 37490, lr = 0.01
I0523 03:03:49.523269 34819 solver.cpp:239] Iteration 37500 (1.91141 iter/s, 5.23174s/10 iters), loss = 9.17437
I0523 03:03:49.523317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17437 (* 1 = 9.17437 loss)
I0523 03:03:49.585875 34819 sgd_solver.cpp:112] Iteration 37500, lr = 0.01
I0523 03:03:54.383987 34819 solver.cpp:239] Iteration 37510 (2.05742 iter/s, 4.86045s/10 iters), loss = 8.54739
I0523 03:03:54.384040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54739 (* 1 = 8.54739 loss)
I0523 03:03:54.577868 34819 sgd_solver.cpp:112] Iteration 37510, lr = 0.01
I0523 03:03:59.156226 34819 solver.cpp:239] Iteration 37520 (2.09556 iter/s, 4.77199s/10 iters), loss = 9.56299
I0523 03:03:59.156268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56299 (* 1 = 9.56299 loss)
I0523 03:03:59.991161 34819 sgd_solver.cpp:112] Iteration 37520, lr = 0.01
I0523 03:04:06.167048 34819 solver.cpp:239] Iteration 37530 (1.42643 iter/s, 7.0105s/10 iters), loss = 8.43128
I0523 03:04:06.167093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43128 (* 1 = 8.43128 loss)
I0523 03:04:06.946907 34819 sgd_solver.cpp:112] Iteration 37530, lr = 0.01
I0523 03:04:11.970499 34819 solver.cpp:239] Iteration 37540 (1.7232 iter/s, 5.80317s/10 iters), loss = 8.49086
I0523 03:04:11.970645 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49086 (* 1 = 8.49086 loss)
I0523 03:04:12.047242 34819 sgd_solver.cpp:112] Iteration 37540, lr = 0.01
I0523 03:04:15.426535 34819 solver.cpp:239] Iteration 37550 (2.89373 iter/s, 3.45575s/10 iters), loss = 9.08563
I0523 03:04:15.426576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08563 (* 1 = 9.08563 loss)
I0523 03:04:15.492175 34819 sgd_solver.cpp:112] Iteration 37550, lr = 0.01
I0523 03:04:18.698660 34819 solver.cpp:239] Iteration 37560 (3.05629 iter/s, 3.27194s/10 iters), loss = 8.79358
I0523 03:04:18.698731 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79358 (* 1 = 8.79358 loss)
I0523 03:04:18.768921 34819 sgd_solver.cpp:112] Iteration 37560, lr = 0.01
I0523 03:04:24.839224 34819 solver.cpp:239] Iteration 37570 (1.6286 iter/s, 6.14024s/10 iters), loss = 9.16351
I0523 03:04:24.839278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16351 (* 1 = 9.16351 loss)
I0523 03:04:25.650758 34819 sgd_solver.cpp:112] Iteration 37570, lr = 0.01
I0523 03:04:30.260730 34819 solver.cpp:239] Iteration 37580 (1.8446 iter/s, 5.42123s/10 iters), loss = 8.3472
I0523 03:04:30.260771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3472 (* 1 = 8.3472 loss)
I0523 03:04:30.319382 34819 sgd_solver.cpp:112] Iteration 37580, lr = 0.01
I0523 03:04:33.348035 34819 solver.cpp:239] Iteration 37590 (3.23926 iter/s, 3.08713s/10 iters), loss = 9.82532
I0523 03:04:33.348084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.82532 (* 1 = 9.82532 loss)
I0523 03:04:33.422464 34819 sgd_solver.cpp:112] Iteration 37590, lr = 0.01
I0523 03:04:39.680855 34819 solver.cpp:239] Iteration 37600 (1.57915 iter/s, 6.33251s/10 iters), loss = 8.87609
I0523 03:04:39.680897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87609 (* 1 = 8.87609 loss)
I0523 03:04:39.742550 34819 sgd_solver.cpp:112] Iteration 37600, lr = 0.01
I0523 03:04:45.226187 34819 solver.cpp:239] Iteration 37610 (1.80341 iter/s, 5.54506s/10 iters), loss = 8.35415
I0523 03:04:45.226291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35415 (* 1 = 8.35415 loss)
I0523 03:04:45.301954 34819 sgd_solver.cpp:112] Iteration 37610, lr = 0.01
I0523 03:04:48.945004 34819 solver.cpp:239] Iteration 37620 (2.68922 iter/s, 3.71856s/10 iters), loss = 7.58985
I0523 03:04:48.945055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58985 (* 1 = 7.58985 loss)
I0523 03:04:49.029907 34819 sgd_solver.cpp:112] Iteration 37620, lr = 0.01
I0523 03:04:53.089970 34819 solver.cpp:239] Iteration 37630 (2.41271 iter/s, 4.14471s/10 iters), loss = 8.59079
I0523 03:04:53.090035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59079 (* 1 = 8.59079 loss)
I0523 03:04:53.875804 34819 sgd_solver.cpp:112] Iteration 37630, lr = 0.01
I0523 03:04:59.464334 34819 solver.cpp:239] Iteration 37640 (1.56887 iter/s, 6.37403s/10 iters), loss = 8.72117
I0523 03:04:59.464385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72117 (* 1 = 8.72117 loss)
I0523 03:04:59.537657 34819 sgd_solver.cpp:112] Iteration 37640, lr = 0.01
I0523 03:05:03.552199 34819 solver.cpp:239] Iteration 37650 (2.4464 iter/s, 4.08764s/10 iters), loss = 8.99315
I0523 03:05:03.552242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99315 (* 1 = 8.99315 loss)
I0523 03:05:03.626309 34819 sgd_solver.cpp:112] Iteration 37650, lr = 0.01
I0523 03:05:08.418848 34819 solver.cpp:239] Iteration 37660 (2.05491 iter/s, 4.86639s/10 iters), loss = 8.47981
I0523 03:05:08.418905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47981 (* 1 = 8.47981 loss)
I0523 03:05:08.493336 34819 sgd_solver.cpp:112] Iteration 37660, lr = 0.01
I0523 03:05:12.806083 34819 solver.cpp:239] Iteration 37670 (2.27946 iter/s, 4.387s/10 iters), loss = 8.67958
I0523 03:05:12.806130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67958 (* 1 = 8.67958 loss)
I0523 03:05:13.607892 34819 sgd_solver.cpp:112] Iteration 37670, lr = 0.01
I0523 03:05:18.687101 34819 solver.cpp:239] Iteration 37680 (1.70047 iter/s, 5.88071s/10 iters), loss = 8.41055
I0523 03:05:18.687366 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41055 (* 1 = 8.41055 loss)
I0523 03:05:19.509899 34819 sgd_solver.cpp:112] Iteration 37680, lr = 0.01
I0523 03:05:22.225455 34819 solver.cpp:239] Iteration 37690 (2.82648 iter/s, 3.53797s/10 iters), loss = 8.86699
I0523 03:05:22.225510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86699 (* 1 = 8.86699 loss)
I0523 03:05:22.313087 34819 sgd_solver.cpp:112] Iteration 37690, lr = 0.01
I0523 03:05:26.455920 34819 solver.cpp:239] Iteration 37700 (2.36394 iter/s, 4.23022s/10 iters), loss = 8.34965
I0523 03:05:26.455986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34965 (* 1 = 8.34965 loss)
I0523 03:05:26.675585 34819 sgd_solver.cpp:112] Iteration 37700, lr = 0.01
I0523 03:05:31.621951 34819 solver.cpp:239] Iteration 37710 (1.93583 iter/s, 5.16574s/10 iters), loss = 8.52057
I0523 03:05:31.622005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52057 (* 1 = 8.52057 loss)
I0523 03:05:31.700500 34819 sgd_solver.cpp:112] Iteration 37710, lr = 0.01
I0523 03:05:35.970350 34819 solver.cpp:239] Iteration 37720 (2.29982 iter/s, 4.34817s/10 iters), loss = 7.62396
I0523 03:05:35.970392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62396 (* 1 = 7.62396 loss)
I0523 03:05:36.035153 34819 sgd_solver.cpp:112] Iteration 37720, lr = 0.01
I0523 03:05:40.114650 34819 solver.cpp:239] Iteration 37730 (2.41308 iter/s, 4.14408s/10 iters), loss = 9.6598
I0523 03:05:40.114720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6598 (* 1 = 9.6598 loss)
I0523 03:05:40.179006 34819 sgd_solver.cpp:112] Iteration 37730, lr = 0.01
I0523 03:05:46.400607 34819 solver.cpp:239] Iteration 37740 (1.59092 iter/s, 6.28565s/10 iters), loss = 9.68497
I0523 03:05:46.400648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68497 (* 1 = 9.68497 loss)
I0523 03:05:47.182258 34819 sgd_solver.cpp:112] Iteration 37740, lr = 0.01
I0523 03:05:53.248569 34819 solver.cpp:239] Iteration 37750 (1.46036 iter/s, 6.84763s/10 iters), loss = 8.64952
I0523 03:05:53.248773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64952 (* 1 = 8.64952 loss)
I0523 03:05:53.309720 34819 sgd_solver.cpp:112] Iteration 37750, lr = 0.01
I0523 03:05:57.876430 34819 solver.cpp:239] Iteration 37760 (2.161 iter/s, 4.62748s/10 iters), loss = 9.0703
I0523 03:05:57.876480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0703 (* 1 = 9.0703 loss)
I0523 03:05:58.649128 34819 sgd_solver.cpp:112] Iteration 37760, lr = 0.01
I0523 03:06:04.973671 34819 solver.cpp:239] Iteration 37770 (1.40907 iter/s, 7.09688s/10 iters), loss = 8.39323
I0523 03:06:04.973737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39323 (* 1 = 8.39323 loss)
I0523 03:06:05.756206 34819 sgd_solver.cpp:112] Iteration 37770, lr = 0.01
I0523 03:06:10.677157 34819 solver.cpp:239] Iteration 37780 (1.75341 iter/s, 5.70319s/10 iters), loss = 9.91705
I0523 03:06:10.677198 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.91705 (* 1 = 9.91705 loss)
I0523 03:06:10.740073 34819 sgd_solver.cpp:112] Iteration 37780, lr = 0.01
I0523 03:06:16.740041 34819 solver.cpp:239] Iteration 37790 (1.64946 iter/s, 6.06258s/10 iters), loss = 8.67515
I0523 03:06:16.740090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67515 (* 1 = 8.67515 loss)
I0523 03:06:16.812094 34819 sgd_solver.cpp:112] Iteration 37790, lr = 0.01
I0523 03:06:21.013231 34819 solver.cpp:239] Iteration 37800 (2.3403 iter/s, 4.27296s/10 iters), loss = 9.0062
I0523 03:06:21.013274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0062 (* 1 = 9.0062 loss)
I0523 03:06:21.879472 34819 sgd_solver.cpp:112] Iteration 37800, lr = 0.01
I0523 03:06:25.429522 34819 solver.cpp:239] Iteration 37810 (2.26446 iter/s, 4.41605s/10 iters), loss = 8.8753
I0523 03:06:25.429666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8753 (* 1 = 8.8753 loss)
I0523 03:06:25.507234 34819 sgd_solver.cpp:112] Iteration 37810, lr = 0.01
I0523 03:06:28.950736 34819 solver.cpp:239] Iteration 37820 (2.84017 iter/s, 3.52092s/10 iters), loss = 9.20601
I0523 03:06:28.950778 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20601 (* 1 = 9.20601 loss)
I0523 03:06:29.771989 34819 sgd_solver.cpp:112] Iteration 37820, lr = 0.01
I0523 03:06:32.432920 34819 solver.cpp:239] Iteration 37830 (2.87193 iter/s, 3.48198s/10 iters), loss = 8.1973
I0523 03:06:32.432987 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1973 (* 1 = 8.1973 loss)
I0523 03:06:33.241150 34819 sgd_solver.cpp:112] Iteration 37830, lr = 0.01
I0523 03:06:37.896647 34819 solver.cpp:239] Iteration 37840 (1.83035 iter/s, 5.46344s/10 iters), loss = 8.66666
I0523 03:06:37.896689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66666 (* 1 = 8.66666 loss)
I0523 03:06:37.968600 34819 sgd_solver.cpp:112] Iteration 37840, lr = 0.01
I0523 03:06:42.598798 34819 solver.cpp:239] Iteration 37850 (2.12681 iter/s, 4.70189s/10 iters), loss = 7.95974
I0523 03:06:42.598855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95974 (* 1 = 7.95974 loss)
I0523 03:06:43.427289 34819 sgd_solver.cpp:112] Iteration 37850, lr = 0.01
I0523 03:06:49.173128 34819 solver.cpp:239] Iteration 37860 (1.52114 iter/s, 6.574s/10 iters), loss = 8.73922
I0523 03:06:49.173169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73922 (* 1 = 8.73922 loss)
I0523 03:06:49.242892 34819 sgd_solver.cpp:112] Iteration 37860, lr = 0.01
I0523 03:06:52.952204 34819 solver.cpp:239] Iteration 37870 (2.6463 iter/s, 3.77887s/10 iters), loss = 9.35534
I0523 03:06:52.952258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35534 (* 1 = 9.35534 loss)
I0523 03:06:53.628849 34819 sgd_solver.cpp:112] Iteration 37870, lr = 0.01
I0523 03:06:57.138018 34819 solver.cpp:239] Iteration 37880 (2.38915 iter/s, 4.18558s/10 iters), loss = 8.29146
I0523 03:06:57.138167 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29146 (* 1 = 8.29146 loss)
I0523 03:06:57.796283 34819 sgd_solver.cpp:112] Iteration 37880, lr = 0.01
I0523 03:07:02.995218 34819 solver.cpp:239] Iteration 37890 (1.70741 iter/s, 5.85681s/10 iters), loss = 8.84441
I0523 03:07:02.995268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84441 (* 1 = 8.84441 loss)
I0523 03:07:03.052392 34819 sgd_solver.cpp:112] Iteration 37890, lr = 0.01
I0523 03:07:09.428730 34819 solver.cpp:239] Iteration 37900 (1.55444 iter/s, 6.43319s/10 iters), loss = 8.78032
I0523 03:07:09.428781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78032 (* 1 = 8.78032 loss)
I0523 03:07:10.289157 34819 sgd_solver.cpp:112] Iteration 37900, lr = 0.01
I0523 03:07:15.554340 34819 solver.cpp:239] Iteration 37910 (1.63258 iter/s, 6.12529s/10 iters), loss = 9.0878
I0523 03:07:15.554396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0878 (* 1 = 9.0878 loss)
I0523 03:07:15.622634 34819 sgd_solver.cpp:112] Iteration 37910, lr = 0.01
I0523 03:07:19.674085 34819 solver.cpp:239] Iteration 37920 (2.42748 iter/s, 4.11949s/10 iters), loss = 9.18083
I0523 03:07:19.674157 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18083 (* 1 = 9.18083 loss)
I0523 03:07:19.745249 34819 sgd_solver.cpp:112] Iteration 37920, lr = 0.01
I0523 03:07:23.930918 34819 solver.cpp:239] Iteration 37930 (2.3493 iter/s, 4.25658s/10 iters), loss = 9.47654
I0523 03:07:23.930960 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47654 (* 1 = 9.47654 loss)
I0523 03:07:24.756537 34819 sgd_solver.cpp:112] Iteration 37930, lr = 0.01
I0523 03:07:28.961585 34819 solver.cpp:239] Iteration 37940 (1.98791 iter/s, 5.03041s/10 iters), loss = 9.81283
I0523 03:07:28.961745 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.81283 (* 1 = 9.81283 loss)
I0523 03:07:29.030153 34819 sgd_solver.cpp:112] Iteration 37940, lr = 0.01
I0523 03:07:33.246292 34819 solver.cpp:239] Iteration 37950 (2.33406 iter/s, 4.28437s/10 iters), loss = 8.33915
I0523 03:07:33.246335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33915 (* 1 = 8.33915 loss)
I0523 03:07:34.067400 34819 sgd_solver.cpp:112] Iteration 37950, lr = 0.01
I0523 03:07:37.427379 34819 solver.cpp:239] Iteration 37960 (2.39185 iter/s, 4.18087s/10 iters), loss = 9.42137
I0523 03:07:37.427420 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42137 (* 1 = 9.42137 loss)
I0523 03:07:37.500895 34819 sgd_solver.cpp:112] Iteration 37960, lr = 0.01
I0523 03:07:42.147498 34819 solver.cpp:239] Iteration 37970 (2.1187 iter/s, 4.71988s/10 iters), loss = 8.3766
I0523 03:07:42.147541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3766 (* 1 = 8.3766 loss)
I0523 03:07:42.231068 34819 sgd_solver.cpp:112] Iteration 37970, lr = 0.01
I0523 03:07:47.487748 34819 solver.cpp:239] Iteration 37980 (1.87267 iter/s, 5.33998s/10 iters), loss = 8.79423
I0523 03:07:47.487799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79423 (* 1 = 8.79423 loss)
I0523 03:07:47.552284 34819 sgd_solver.cpp:112] Iteration 37980, lr = 0.01
I0523 03:07:51.475602 34819 solver.cpp:239] Iteration 37990 (2.50776 iter/s, 3.98762s/10 iters), loss = 9.53576
I0523 03:07:51.475652 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.53576 (* 1 = 9.53576 loss)
I0523 03:07:51.542434 34819 sgd_solver.cpp:112] Iteration 37990, lr = 0.01
I0523 03:07:54.919836 34819 solver.cpp:239] Iteration 38000 (2.90357 iter/s, 3.44403s/10 iters), loss = 8.48733
I0523 03:07:54.919880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48733 (* 1 = 8.48733 loss)
I0523 03:07:55.729153 34819 sgd_solver.cpp:112] Iteration 38000, lr = 0.01
I0523 03:08:00.022326 34819 solver.cpp:239] Iteration 38010 (1.95992 iter/s, 5.10224s/10 iters), loss = 8.298
I0523 03:08:00.022452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.298 (* 1 = 8.298 loss)
I0523 03:08:00.073693 34819 sgd_solver.cpp:112] Iteration 38010, lr = 0.01
I0523 03:08:07.410078 34819 solver.cpp:239] Iteration 38020 (1.35367 iter/s, 7.38731s/10 iters), loss = 9.69282
I0523 03:08:07.410128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.69282 (* 1 = 9.69282 loss)
I0523 03:08:07.484743 34819 sgd_solver.cpp:112] Iteration 38020, lr = 0.01
I0523 03:08:12.497627 34819 solver.cpp:239] Iteration 38030 (1.96569 iter/s, 5.08728s/10 iters), loss = 9.71419
I0523 03:08:12.497683 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71419 (* 1 = 9.71419 loss)
I0523 03:08:12.568168 34819 sgd_solver.cpp:112] Iteration 38030, lr = 0.01
I0523 03:08:19.091801 34819 solver.cpp:239] Iteration 38040 (1.51657 iter/s, 6.59385s/10 iters), loss = 8.34124
I0523 03:08:19.091868 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34124 (* 1 = 8.34124 loss)
I0523 03:08:19.149183 34819 sgd_solver.cpp:112] Iteration 38040, lr = 0.01
I0523 03:08:24.113663 34819 solver.cpp:239] Iteration 38050 (1.9914 iter/s, 5.02159s/10 iters), loss = 9.29817
I0523 03:08:24.113721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29817 (* 1 = 9.29817 loss)
I0523 03:08:24.974131 34819 sgd_solver.cpp:112] Iteration 38050, lr = 0.01
I0523 03:08:29.980126 34819 solver.cpp:239] Iteration 38060 (1.7047 iter/s, 5.86614s/10 iters), loss = 8.61437
I0523 03:08:29.980201 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61437 (* 1 = 8.61437 loss)
I0523 03:08:30.825580 34819 sgd_solver.cpp:112] Iteration 38060, lr = 0.01
I0523 03:08:37.217830 34819 solver.cpp:239] Iteration 38070 (1.38172 iter/s, 7.23733s/10 iters), loss = 8.90625
I0523 03:08:37.217880 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90625 (* 1 = 8.90625 loss)
I0523 03:08:37.302788 34819 sgd_solver.cpp:112] Iteration 38070, lr = 0.01
I0523 03:08:40.608042 34819 solver.cpp:239] Iteration 38080 (2.94984 iter/s, 3.39001s/10 iters), loss = 8.51424
I0523 03:08:40.608098 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51424 (* 1 = 8.51424 loss)
I0523 03:08:40.682426 34819 sgd_solver.cpp:112] Iteration 38080, lr = 0.01
I0523 03:08:44.132120 34819 solver.cpp:239] Iteration 38090 (2.83779 iter/s, 3.52387s/10 iters), loss = 9.2113
I0523 03:08:44.132179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2113 (* 1 = 9.2113 loss)
I0523 03:08:44.977929 34819 sgd_solver.cpp:112] Iteration 38090, lr = 0.01
I0523 03:08:47.676492 34819 solver.cpp:239] Iteration 38100 (2.82154 iter/s, 3.54416s/10 iters), loss = 9.16963
I0523 03:08:47.676545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16963 (* 1 = 9.16963 loss)
I0523 03:08:47.751457 34819 sgd_solver.cpp:112] Iteration 38100, lr = 0.01
I0523 03:08:53.115303 34819 solver.cpp:239] Iteration 38110 (1.83873 iter/s, 5.43853s/10 iters), loss = 9.04476
I0523 03:08:53.115351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04476 (* 1 = 9.04476 loss)
I0523 03:08:54.016028 34819 sgd_solver.cpp:112] Iteration 38110, lr = 0.01
I0523 03:08:57.403532 34819 solver.cpp:239] Iteration 38120 (2.33209 iter/s, 4.28799s/10 iters), loss = 8.23646
I0523 03:08:57.403584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23646 (* 1 = 8.23646 loss)
I0523 03:08:58.265388 34819 sgd_solver.cpp:112] Iteration 38120, lr = 0.01
I0523 03:09:03.305601 34819 solver.cpp:239] Iteration 38130 (1.69441 iter/s, 5.90175s/10 iters), loss = 8.24059
I0523 03:09:03.305791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24059 (* 1 = 8.24059 loss)
I0523 03:09:03.384274 34819 sgd_solver.cpp:112] Iteration 38130, lr = 0.01
I0523 03:09:08.017572 34819 solver.cpp:239] Iteration 38140 (2.12242 iter/s, 4.7116s/10 iters), loss = 8.20023
I0523 03:09:08.017626 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20023 (* 1 = 8.20023 loss)
I0523 03:09:08.851316 34819 sgd_solver.cpp:112] Iteration 38140, lr = 0.01
I0523 03:09:14.555034 34819 solver.cpp:239] Iteration 38150 (1.52972 iter/s, 6.53715s/10 iters), loss = 7.88453
I0523 03:09:14.555073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88453 (* 1 = 7.88453 loss)
I0523 03:09:15.015607 34819 sgd_solver.cpp:112] Iteration 38150, lr = 0.01
I0523 03:09:17.527706 34819 solver.cpp:239] Iteration 38160 (3.36417 iter/s, 2.9725s/10 iters), loss = 8.93596
I0523 03:09:17.527751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93596 (* 1 = 8.93596 loss)
I0523 03:09:18.356226 34819 sgd_solver.cpp:112] Iteration 38160, lr = 0.01
I0523 03:09:23.461652 34819 solver.cpp:239] Iteration 38170 (1.6853 iter/s, 5.93366s/10 iters), loss = 9.26906
I0523 03:09:23.461705 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26906 (* 1 = 9.26906 loss)
I0523 03:09:24.186110 34819 sgd_solver.cpp:112] Iteration 38170, lr = 0.01
I0523 03:09:27.322227 34819 solver.cpp:239] Iteration 38180 (2.59044 iter/s, 3.86035s/10 iters), loss = 9.06642
I0523 03:09:27.322278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06642 (* 1 = 9.06642 loss)
I0523 03:09:27.390138 34819 sgd_solver.cpp:112] Iteration 38180, lr = 0.01
I0523 03:09:30.719883 34819 solver.cpp:239] Iteration 38190 (2.94338 iter/s, 3.39746s/10 iters), loss = 8.80595
I0523 03:09:30.719938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80595 (* 1 = 8.80595 loss)
I0523 03:09:30.792150 34819 sgd_solver.cpp:112] Iteration 38190, lr = 0.01
I0523 03:09:36.863948 34819 solver.cpp:239] Iteration 38200 (1.62767 iter/s, 6.14374s/10 iters), loss = 8.24814
I0523 03:09:36.864138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24814 (* 1 = 8.24814 loss)
I0523 03:09:36.933820 34819 sgd_solver.cpp:112] Iteration 38200, lr = 0.01
I0523 03:09:41.348793 34819 solver.cpp:239] Iteration 38210 (2.23116 iter/s, 4.48198s/10 iters), loss = 8.4465
I0523 03:09:41.348845 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4465 (* 1 = 8.4465 loss)
I0523 03:09:41.418998 34819 sgd_solver.cpp:112] Iteration 38210, lr = 0.01
I0523 03:09:46.711170 34819 solver.cpp:239] Iteration 38220 (1.86494 iter/s, 5.36209s/10 iters), loss = 8.86837
I0523 03:09:46.711220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86837 (* 1 = 8.86837 loss)
I0523 03:09:46.777570 34819 sgd_solver.cpp:112] Iteration 38220, lr = 0.01
I0523 03:09:52.286720 34819 solver.cpp:239] Iteration 38230 (1.79365 iter/s, 5.57524s/10 iters), loss = 9.29242
I0523 03:09:52.286774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29242 (* 1 = 9.29242 loss)
I0523 03:09:52.370391 34819 sgd_solver.cpp:112] Iteration 38230, lr = 0.01
I0523 03:09:55.713079 34819 solver.cpp:239] Iteration 38240 (2.91873 iter/s, 3.42615s/10 iters), loss = 9.27781
I0523 03:09:55.713137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27781 (* 1 = 9.27781 loss)
I0523 03:09:56.392702 34819 sgd_solver.cpp:112] Iteration 38240, lr = 0.01
I0523 03:10:02.069533 34819 solver.cpp:239] Iteration 38250 (1.57328 iter/s, 6.35613s/10 iters), loss = 9.06621
I0523 03:10:02.069581 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06621 (* 1 = 9.06621 loss)
I0523 03:10:02.808411 34819 sgd_solver.cpp:112] Iteration 38250, lr = 0.01
I0523 03:10:06.996922 34819 solver.cpp:239] Iteration 38260 (2.02958 iter/s, 4.92713s/10 iters), loss = 9.40728
I0523 03:10:06.997042 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40728 (* 1 = 9.40728 loss)
I0523 03:10:07.052520 34819 sgd_solver.cpp:112] Iteration 38260, lr = 0.01
I0523 03:10:09.738870 34819 solver.cpp:239] Iteration 38270 (3.64736 iter/s, 2.74171s/10 iters), loss = 8.87766
I0523 03:10:09.738919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87766 (* 1 = 8.87766 loss)
I0523 03:10:10.359529 34819 sgd_solver.cpp:112] Iteration 38270, lr = 0.01
I0523 03:10:14.564600 34819 solver.cpp:239] Iteration 38280 (2.07233 iter/s, 4.82548s/10 iters), loss = 8.66101
I0523 03:10:14.564642 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66101 (* 1 = 8.66101 loss)
I0523 03:10:14.629498 34819 sgd_solver.cpp:112] Iteration 38280, lr = 0.01
I0523 03:10:22.042146 34819 solver.cpp:239] Iteration 38290 (1.3374 iter/s, 7.47719s/10 iters), loss = 8.94385
I0523 03:10:22.042197 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94385 (* 1 = 8.94385 loss)
I0523 03:10:22.149650 34819 sgd_solver.cpp:112] Iteration 38290, lr = 0.01
I0523 03:10:26.277804 34819 solver.cpp:239] Iteration 38300 (2.36103 iter/s, 4.23543s/10 iters), loss = 8.96357
I0523 03:10:26.277846 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96357 (* 1 = 8.96357 loss)
I0523 03:10:26.345257 34819 sgd_solver.cpp:112] Iteration 38300, lr = 0.01
I0523 03:10:31.722803 34819 solver.cpp:239] Iteration 38310 (1.83664 iter/s, 5.44471s/10 iters), loss = 8.78475
I0523 03:10:31.722852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78475 (* 1 = 8.78475 loss)
I0523 03:10:31.940095 34819 sgd_solver.cpp:112] Iteration 38310, lr = 0.01
I0523 03:10:38.250445 34819 solver.cpp:239] Iteration 38320 (1.53202 iter/s, 6.52733s/10 iters), loss = 8.17507
I0523 03:10:38.250556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17507 (* 1 = 8.17507 loss)
I0523 03:10:38.309474 34819 sgd_solver.cpp:112] Iteration 38320, lr = 0.01
I0523 03:10:42.408051 34819 solver.cpp:239] Iteration 38330 (2.4054 iter/s, 4.15732s/10 iters), loss = 8.96784
I0523 03:10:42.408093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96784 (* 1 = 8.96784 loss)
I0523 03:10:42.473191 34819 sgd_solver.cpp:112] Iteration 38330, lr = 0.01
I0523 03:10:46.446396 34819 solver.cpp:239] Iteration 38340 (2.47639 iter/s, 4.03813s/10 iters), loss = 8.25499
I0523 03:10:46.446437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25499 (* 1 = 8.25499 loss)
I0523 03:10:46.514051 34819 sgd_solver.cpp:112] Iteration 38340, lr = 0.01
I0523 03:10:51.399642 34819 solver.cpp:239] Iteration 38350 (2.01898 iter/s, 4.953s/10 iters), loss = 9.25086
I0523 03:10:51.399679 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25086 (* 1 = 9.25086 loss)
I0523 03:10:51.466858 34819 sgd_solver.cpp:112] Iteration 38350, lr = 0.01
I0523 03:10:55.615718 34819 solver.cpp:239] Iteration 38360 (2.372 iter/s, 4.21585s/10 iters), loss = 9.28704
I0523 03:10:55.615767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28704 (* 1 = 9.28704 loss)
I0523 03:10:56.369472 34819 sgd_solver.cpp:112] Iteration 38360, lr = 0.01
I0523 03:11:00.396920 34819 solver.cpp:239] Iteration 38370 (2.09164 iter/s, 4.78093s/10 iters), loss = 8.97874
I0523 03:11:00.396961 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97874 (* 1 = 8.97874 loss)
I0523 03:11:00.464030 34819 sgd_solver.cpp:112] Iteration 38370, lr = 0.01
I0523 03:11:04.375515 34819 solver.cpp:239] Iteration 38380 (2.51358 iter/s, 3.97839s/10 iters), loss = 9.30076
I0523 03:11:04.375555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30076 (* 1 = 9.30076 loss)
I0523 03:11:04.445791 34819 sgd_solver.cpp:112] Iteration 38380, lr = 0.01
I0523 03:11:10.208840 34819 solver.cpp:239] Iteration 38390 (1.71437 iter/s, 5.83305s/10 iters), loss = 8.63274
I0523 03:11:10.209087 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63274 (* 1 = 8.63274 loss)
I0523 03:11:10.880128 34819 sgd_solver.cpp:112] Iteration 38390, lr = 0.01
I0523 03:11:16.474766 34819 solver.cpp:239] Iteration 38400 (1.59606 iter/s, 6.26544s/10 iters), loss = 8.33191
I0523 03:11:16.474807 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33191 (* 1 = 8.33191 loss)
I0523 03:11:17.365247 34819 sgd_solver.cpp:112] Iteration 38400, lr = 0.01
I0523 03:11:21.586853 34819 solver.cpp:239] Iteration 38410 (1.95625 iter/s, 5.11182s/10 iters), loss = 9.06134
I0523 03:11:21.586905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06134 (* 1 = 9.06134 loss)
I0523 03:11:22.355720 34819 sgd_solver.cpp:112] Iteration 38410, lr = 0.01
I0523 03:11:27.315105 34819 solver.cpp:239] Iteration 38420 (1.74583 iter/s, 5.72793s/10 iters), loss = 9.0366
I0523 03:11:27.315148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0366 (* 1 = 9.0366 loss)
I0523 03:11:27.385510 34819 sgd_solver.cpp:112] Iteration 38420, lr = 0.01
I0523 03:11:33.448592 34819 solver.cpp:239] Iteration 38430 (1.63048 iter/s, 6.13318s/10 iters), loss = 9.38533
I0523 03:11:33.448638 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38533 (* 1 = 9.38533 loss)
I0523 03:11:34.178622 34819 sgd_solver.cpp:112] Iteration 38430, lr = 0.01
I0523 03:11:40.189051 34819 solver.cpp:239] Iteration 38440 (1.48365 iter/s, 6.74013s/10 iters), loss = 9.36806
I0523 03:11:40.189095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36806 (* 1 = 9.36806 loss)
I0523 03:11:40.987567 34819 sgd_solver.cpp:112] Iteration 38440, lr = 0.01
I0523 03:11:46.606488 34819 solver.cpp:239] Iteration 38450 (1.55833 iter/s, 6.41712s/10 iters), loss = 8.78178
I0523 03:11:46.606544 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78178 (* 1 = 8.78178 loss)
I0523 03:11:46.667280 34819 sgd_solver.cpp:112] Iteration 38450, lr = 0.01
I0523 03:11:50.946940 34819 solver.cpp:239] Iteration 38460 (2.30403 iter/s, 4.34022s/10 iters), loss = 8.76805
I0523 03:11:50.946987 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76805 (* 1 = 8.76805 loss)
I0523 03:11:51.007083 34819 sgd_solver.cpp:112] Iteration 38460, lr = 0.01
I0523 03:11:55.610733 34819 solver.cpp:239] Iteration 38470 (2.1443 iter/s, 4.66353s/10 iters), loss = 9.04948
I0523 03:11:55.610780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04948 (* 1 = 9.04948 loss)
I0523 03:11:55.681493 34819 sgd_solver.cpp:112] Iteration 38470, lr = 0.01
I0523 03:12:00.630205 34819 solver.cpp:239] Iteration 38480 (1.99235 iter/s, 5.01919s/10 iters), loss = 9.08628
I0523 03:12:00.630280 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08628 (* 1 = 9.08628 loss)
I0523 03:12:00.685501 34819 sgd_solver.cpp:112] Iteration 38480, lr = 0.01
I0523 03:12:05.077524 34819 solver.cpp:239] Iteration 38490 (2.24868 iter/s, 4.44706s/10 iters), loss = 9.41164
I0523 03:12:05.077566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41164 (* 1 = 9.41164 loss)
I0523 03:12:05.145908 34819 sgd_solver.cpp:112] Iteration 38490, lr = 0.01
I0523 03:12:08.458551 34819 solver.cpp:239] Iteration 38500 (2.95786 iter/s, 3.38083s/10 iters), loss = 8.72399
I0523 03:12:08.458616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72399 (* 1 = 8.72399 loss)
I0523 03:12:08.528260 34819 sgd_solver.cpp:112] Iteration 38500, lr = 0.01
I0523 03:12:12.969954 34819 solver.cpp:239] Iteration 38510 (2.21673 iter/s, 4.51115s/10 iters), loss = 8.51816
I0523 03:12:12.970147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51816 (* 1 = 8.51816 loss)
I0523 03:12:13.769793 34819 sgd_solver.cpp:112] Iteration 38510, lr = 0.01
I0523 03:12:19.523264 34819 solver.cpp:239] Iteration 38520 (1.52605 iter/s, 6.55286s/10 iters), loss = 9.37667
I0523 03:12:19.523305 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37667 (* 1 = 9.37667 loss)
I0523 03:12:20.346395 34819 sgd_solver.cpp:112] Iteration 38520, lr = 0.01
I0523 03:12:23.180529 34819 solver.cpp:239] Iteration 38530 (2.73444 iter/s, 3.65706s/10 iters), loss = 9.48647
I0523 03:12:23.180598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.48647 (* 1 = 9.48647 loss)
I0523 03:12:23.239796 34819 sgd_solver.cpp:112] Iteration 38530, lr = 0.01
I0523 03:12:26.839839 34819 solver.cpp:239] Iteration 38540 (2.73292 iter/s, 3.65909s/10 iters), loss = 9.75825
I0523 03:12:26.839885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75825 (* 1 = 9.75825 loss)
I0523 03:12:27.662992 34819 sgd_solver.cpp:112] Iteration 38540, lr = 0.01
I0523 03:12:31.193717 34819 solver.cpp:239] Iteration 38550 (2.29693 iter/s, 4.35364s/10 iters), loss = 8.58529
I0523 03:12:31.193775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58529 (* 1 = 8.58529 loss)
I0523 03:12:31.972743 34819 sgd_solver.cpp:112] Iteration 38550, lr = 0.01
I0523 03:12:35.990068 34819 solver.cpp:239] Iteration 38560 (2.08503 iter/s, 4.79609s/10 iters), loss = 8.90602
I0523 03:12:35.990120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90602 (* 1 = 8.90602 loss)
I0523 03:12:36.047904 34819 sgd_solver.cpp:112] Iteration 38560, lr = 0.01
I0523 03:12:38.870751 34819 solver.cpp:239] Iteration 38570 (3.47161 iter/s, 2.88051s/10 iters), loss = 9.31964
I0523 03:12:38.870796 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31964 (* 1 = 9.31964 loss)
I0523 03:12:39.726318 34819 sgd_solver.cpp:112] Iteration 38570, lr = 0.01
I0523 03:12:44.949868 34819 solver.cpp:239] Iteration 38580 (1.64506 iter/s, 6.07881s/10 iters), loss = 8.2472
I0523 03:12:44.950026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2472 (* 1 = 8.2472 loss)
I0523 03:12:45.021545 34819 sgd_solver.cpp:112] Iteration 38580, lr = 0.01
I0523 03:12:48.080807 34819 solver.cpp:239] Iteration 38590 (3.19424 iter/s, 3.13064s/10 iters), loss = 8.32195
I0523 03:12:48.080853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32195 (* 1 = 8.32195 loss)
I0523 03:12:48.850157 34819 sgd_solver.cpp:112] Iteration 38590, lr = 0.01
I0523 03:12:53.859812 34819 solver.cpp:239] Iteration 38600 (1.73049 iter/s, 5.77871s/10 iters), loss = 9.6831
I0523 03:12:53.859854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.6831 (* 1 = 9.6831 loss)
I0523 03:12:53.915822 34819 sgd_solver.cpp:112] Iteration 38600, lr = 0.01
I0523 03:12:59.684201 34819 solver.cpp:239] Iteration 38610 (1.717 iter/s, 5.82411s/10 iters), loss = 9.45176
I0523 03:12:59.684258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45176 (* 1 = 9.45176 loss)
I0523 03:13:00.005560 34819 sgd_solver.cpp:112] Iteration 38610, lr = 0.01
I0523 03:13:05.694245 34819 solver.cpp:239] Iteration 38620 (1.66396 iter/s, 6.00974s/10 iters), loss = 9.33257
I0523 03:13:05.694298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33257 (* 1 = 9.33257 loss)
I0523 03:13:05.757622 34819 sgd_solver.cpp:112] Iteration 38620, lr = 0.01
I0523 03:13:10.561802 34819 solver.cpp:239] Iteration 38630 (2.05454 iter/s, 4.86728s/10 iters), loss = 8.83837
I0523 03:13:10.561863 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83837 (* 1 = 8.83837 loss)
I0523 03:13:11.428259 34819 sgd_solver.cpp:112] Iteration 38630, lr = 0.01
I0523 03:13:14.014616 34819 solver.cpp:239] Iteration 38640 (2.89637 iter/s, 3.4526s/10 iters), loss = 8.94417
I0523 03:13:14.014691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94417 (* 1 = 8.94417 loss)
I0523 03:13:14.528053 34819 sgd_solver.cpp:112] Iteration 38640, lr = 0.01
I0523 03:13:20.851994 34819 solver.cpp:239] Iteration 38650 (1.46262 iter/s, 6.83703s/10 iters), loss = 8.91852
I0523 03:13:20.852255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91852 (* 1 = 8.91852 loss)
I0523 03:13:20.913054 34819 sgd_solver.cpp:112] Iteration 38650, lr = 0.01
I0523 03:13:26.504065 34819 solver.cpp:239] Iteration 38660 (1.76941 iter/s, 5.6516s/10 iters), loss = 9.78936
I0523 03:13:26.504117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.78936 (* 1 = 9.78936 loss)
I0523 03:13:26.577996 34819 sgd_solver.cpp:112] Iteration 38660, lr = 0.01
I0523 03:13:32.114776 34819 solver.cpp:239] Iteration 38670 (1.7824 iter/s, 5.61043s/10 iters), loss = 7.75953
I0523 03:13:32.114819 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75953 (* 1 = 7.75953 loss)
I0523 03:13:32.588340 34819 sgd_solver.cpp:112] Iteration 38670, lr = 0.01
I0523 03:13:37.011276 34819 solver.cpp:239] Iteration 38680 (2.04238 iter/s, 4.89624s/10 iters), loss = 8.65669
I0523 03:13:37.011328 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65669 (* 1 = 8.65669 loss)
I0523 03:13:37.085918 34819 sgd_solver.cpp:112] Iteration 38680, lr = 0.01
I0523 03:13:40.413445 34819 solver.cpp:239] Iteration 38690 (2.93947 iter/s, 3.40197s/10 iters), loss = 8.82182
I0523 03:13:40.413503 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82182 (* 1 = 8.82182 loss)
I0523 03:13:40.490305 34819 sgd_solver.cpp:112] Iteration 38690, lr = 0.01
I0523 03:13:45.478873 34819 solver.cpp:239] Iteration 38700 (1.97599 iter/s, 5.06076s/10 iters), loss = 9.17896
I0523 03:13:45.478924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17896 (* 1 = 9.17896 loss)
I0523 03:13:46.307801 34819 sgd_solver.cpp:112] Iteration 38700, lr = 0.01
I0523 03:13:51.801760 34819 solver.cpp:239] Iteration 38710 (1.58163 iter/s, 6.32258s/10 iters), loss = 8.52733
I0523 03:13:51.801890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52733 (* 1 = 8.52733 loss)
I0523 03:13:52.474911 34819 sgd_solver.cpp:112] Iteration 38710, lr = 0.01
I0523 03:13:57.345474 34819 solver.cpp:239] Iteration 38720 (1.80396 iter/s, 5.54335s/10 iters), loss = 7.89484
I0523 03:13:57.345516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89484 (* 1 = 7.89484 loss)
I0523 03:13:58.179893 34819 sgd_solver.cpp:112] Iteration 38720, lr = 0.01
I0523 03:14:03.868955 34819 solver.cpp:239] Iteration 38730 (1.533 iter/s, 6.52317s/10 iters), loss = 9.51578
I0523 03:14:03.868999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51578 (* 1 = 9.51578 loss)
I0523 03:14:03.925606 34819 sgd_solver.cpp:112] Iteration 38730, lr = 0.01
I0523 03:14:08.080206 34819 solver.cpp:239] Iteration 38740 (2.37471 iter/s, 4.21103s/10 iters), loss = 9.16443
I0523 03:14:08.080246 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16443 (* 1 = 9.16443 loss)
I0523 03:14:08.137933 34819 sgd_solver.cpp:112] Iteration 38740, lr = 0.01
I0523 03:14:14.607722 34819 solver.cpp:239] Iteration 38750 (1.53205 iter/s, 6.5272s/10 iters), loss = 9.28179
I0523 03:14:14.607762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28179 (* 1 = 9.28179 loss)
I0523 03:14:14.672315 34819 sgd_solver.cpp:112] Iteration 38750, lr = 0.01
I0523 03:14:18.887197 34819 solver.cpp:239] Iteration 38760 (2.33687 iter/s, 4.27923s/10 iters), loss = 8.9164
I0523 03:14:18.887256 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9164 (* 1 = 8.9164 loss)
I0523 03:14:18.980885 34819 sgd_solver.cpp:112] Iteration 38760, lr = 0.01
I0523 03:14:22.819844 34819 solver.cpp:239] Iteration 38770 (2.54296 iter/s, 3.93243s/10 iters), loss = 9.13054
I0523 03:14:22.820091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13054 (* 1 = 9.13054 loss)
I0523 03:14:22.879526 34819 sgd_solver.cpp:112] Iteration 38770, lr = 0.01
I0523 03:14:29.920388 34819 solver.cpp:239] Iteration 38780 (1.40845 iter/s, 7.10002s/10 iters), loss = 8.96991
I0523 03:14:29.920439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96991 (* 1 = 8.96991 loss)
I0523 03:14:29.987778 34819 sgd_solver.cpp:112] Iteration 38780, lr = 0.01
I0523 03:14:35.186684 34819 solver.cpp:239] Iteration 38790 (1.89897 iter/s, 5.26601s/10 iters), loss = 8.61334
I0523 03:14:35.186754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61334 (* 1 = 8.61334 loss)
I0523 03:14:35.263561 34819 sgd_solver.cpp:112] Iteration 38790, lr = 0.01
I0523 03:14:39.838027 34819 solver.cpp:239] Iteration 38800 (2.15004 iter/s, 4.65108s/10 iters), loss = 9.84558
I0523 03:14:39.838081 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84558 (* 1 = 9.84558 loss)
I0523 03:14:39.908856 34819 sgd_solver.cpp:112] Iteration 38800, lr = 0.01
I0523 03:14:43.864485 34819 solver.cpp:239] Iteration 38810 (2.48371 iter/s, 4.02624s/10 iters), loss = 8.65934
I0523 03:14:43.864526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65934 (* 1 = 8.65934 loss)
I0523 03:14:43.942651 34819 sgd_solver.cpp:112] Iteration 38810, lr = 0.01
I0523 03:14:48.722321 34819 solver.cpp:239] Iteration 38820 (2.05863 iter/s, 4.85759s/10 iters), loss = 9.12304
I0523 03:14:48.722374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12304 (* 1 = 9.12304 loss)
I0523 03:14:48.799135 34819 sgd_solver.cpp:112] Iteration 38820, lr = 0.01
I0523 03:14:52.755151 34819 solver.cpp:239] Iteration 38830 (2.47979 iter/s, 4.0326s/10 iters), loss = 8.79326
I0523 03:14:52.755203 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79326 (* 1 = 8.79326 loss)
I0523 03:14:53.573544 34819 sgd_solver.cpp:112] Iteration 38830, lr = 0.01
I0523 03:14:57.472240 34819 solver.cpp:239] Iteration 38840 (2.12007 iter/s, 4.71683s/10 iters), loss = 8.83643
I0523 03:14:57.472296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83643 (* 1 = 8.83643 loss)
I0523 03:14:58.277743 34819 sgd_solver.cpp:112] Iteration 38840, lr = 0.01
I0523 03:15:02.684223 34819 solver.cpp:239] Iteration 38850 (1.91875 iter/s, 5.21171s/10 iters), loss = 9.24811
I0523 03:15:02.684269 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24811 (* 1 = 9.24811 loss)
I0523 03:15:02.764253 34819 sgd_solver.cpp:112] Iteration 38850, lr = 0.01
I0523 03:15:06.854753 34819 solver.cpp:239] Iteration 38860 (2.39791 iter/s, 4.1703s/10 iters), loss = 8.59163
I0523 03:15:06.854797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59163 (* 1 = 8.59163 loss)
I0523 03:15:06.920913 34819 sgd_solver.cpp:112] Iteration 38860, lr = 0.01
I0523 03:15:10.140878 34819 solver.cpp:239] Iteration 38870 (3.04329 iter/s, 3.28592s/10 iters), loss = 8.80472
I0523 03:15:10.140934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80472 (* 1 = 8.80472 loss)
I0523 03:15:10.225400 34819 sgd_solver.cpp:112] Iteration 38870, lr = 0.01
I0523 03:15:14.822598 34819 solver.cpp:239] Iteration 38880 (2.13609 iter/s, 4.68146s/10 iters), loss = 8.70258
I0523 03:15:14.822667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70258 (* 1 = 8.70258 loss)
I0523 03:15:15.623118 34819 sgd_solver.cpp:112] Iteration 38880, lr = 0.01
I0523 03:15:20.491770 34819 solver.cpp:239] Iteration 38890 (1.76402 iter/s, 5.66886s/10 iters), loss = 9.38767
I0523 03:15:20.491830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38767 (* 1 = 9.38767 loss)
I0523 03:15:21.350478 34819 sgd_solver.cpp:112] Iteration 38890, lr = 0.01
I0523 03:15:25.111192 34819 solver.cpp:239] Iteration 38900 (2.1649 iter/s, 4.61914s/10 iters), loss = 8.67993
I0523 03:15:25.111472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67993 (* 1 = 8.67993 loss)
I0523 03:15:25.890064 34819 sgd_solver.cpp:112] Iteration 38900, lr = 0.01
I0523 03:15:29.860234 34819 solver.cpp:239] Iteration 38910 (2.1059 iter/s, 4.74857s/10 iters), loss = 9.01544
I0523 03:15:29.860289 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01544 (* 1 = 9.01544 loss)
I0523 03:15:30.310809 34819 sgd_solver.cpp:112] Iteration 38910, lr = 0.01
I0523 03:15:35.448518 34819 solver.cpp:239] Iteration 38920 (1.78955 iter/s, 5.588s/10 iters), loss = 9.12864
I0523 03:15:35.448575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12864 (* 1 = 9.12864 loss)
I0523 03:15:35.518579 34819 sgd_solver.cpp:112] Iteration 38920, lr = 0.01
I0523 03:15:41.283368 34819 solver.cpp:239] Iteration 38930 (1.71393 iter/s, 5.83455s/10 iters), loss = 8.62694
I0523 03:15:41.283426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62694 (* 1 = 8.62694 loss)
I0523 03:15:42.146411 34819 sgd_solver.cpp:112] Iteration 38930, lr = 0.01
I0523 03:15:43.384732 34819 solver.cpp:239] Iteration 38940 (4.7592 iter/s, 2.10119s/10 iters), loss = 9.55447
I0523 03:15:43.384784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.55447 (* 1 = 9.55447 loss)
I0523 03:15:43.422893 34819 sgd_solver.cpp:112] Iteration 38940, lr = 0.01
I0523 03:15:47.510296 34819 solver.cpp:239] Iteration 38950 (2.42405 iter/s, 4.12533s/10 iters), loss = 9.03662
I0523 03:15:47.510339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03662 (* 1 = 9.03662 loss)
I0523 03:15:47.587990 34819 sgd_solver.cpp:112] Iteration 38950, lr = 0.01
I0523 03:15:51.850145 34819 solver.cpp:239] Iteration 38960 (2.30435 iter/s, 4.33962s/10 iters), loss = 8.35192
I0523 03:15:51.850186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35192 (* 1 = 8.35192 loss)
I0523 03:15:52.490770 34819 sgd_solver.cpp:112] Iteration 38960, lr = 0.01
I0523 03:15:58.721585 34819 solver.cpp:239] Iteration 38970 (1.45537 iter/s, 6.8711s/10 iters), loss = 8.53597
I0523 03:15:58.721732 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53597 (* 1 = 8.53597 loss)
I0523 03:15:59.567754 34819 sgd_solver.cpp:112] Iteration 38970, lr = 0.01
I0523 03:16:04.595566 34819 solver.cpp:239] Iteration 38980 (1.70253 iter/s, 5.8736s/10 iters), loss = 8.48138
I0523 03:16:04.595608 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48138 (* 1 = 8.48138 loss)
I0523 03:16:04.651358 34819 sgd_solver.cpp:112] Iteration 38980, lr = 0.01
I0523 03:16:08.672685 34819 solver.cpp:239] Iteration 38990 (2.45285 iter/s, 4.0769s/10 iters), loss = 8.3455
I0523 03:16:08.672727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3455 (* 1 = 8.3455 loss)
I0523 03:16:08.742187 34819 sgd_solver.cpp:112] Iteration 38990, lr = 0.01
I0523 03:16:15.626169 34819 solver.cpp:239] Iteration 39000 (1.4382 iter/s, 6.95315s/10 iters), loss = 8.53326
I0523 03:16:15.626209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53326 (* 1 = 8.53326 loss)
I0523 03:16:16.357689 34819 sgd_solver.cpp:112] Iteration 39000, lr = 0.01
I0523 03:16:21.809094 34819 solver.cpp:239] Iteration 39010 (1.61743 iter/s, 6.18264s/10 iters), loss = 8.9963
I0523 03:16:21.809137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9963 (* 1 = 8.9963 loss)
I0523 03:16:22.644740 34819 sgd_solver.cpp:112] Iteration 39010, lr = 0.01
I0523 03:16:28.578400 34819 solver.cpp:239] Iteration 39020 (1.47733 iter/s, 6.76898s/10 iters), loss = 8.84027
I0523 03:16:28.578444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84027 (* 1 = 8.84027 loss)
I0523 03:16:29.100330 34819 sgd_solver.cpp:112] Iteration 39020, lr = 0.01
I0523 03:16:36.659802 34819 solver.cpp:239] Iteration 39030 (1.23747 iter/s, 8.08103s/10 iters), loss = 8.90634
I0523 03:16:36.659842 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90634 (* 1 = 8.90634 loss)
I0523 03:16:36.714676 34819 sgd_solver.cpp:112] Iteration 39030, lr = 0.01
I0523 03:16:41.426043 34819 solver.cpp:239] Iteration 39040 (2.09819 iter/s, 4.766s/10 iters), loss = 9.67536
I0523 03:16:41.426084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67536 (* 1 = 9.67536 loss)
I0523 03:16:41.481221 34819 sgd_solver.cpp:112] Iteration 39040, lr = 0.01
I0523 03:16:47.689869 34819 solver.cpp:239] Iteration 39050 (1.59654 iter/s, 6.26353s/10 iters), loss = 9.45403
I0523 03:16:47.689910 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45403 (* 1 = 9.45403 loss)
I0523 03:16:47.764917 34819 sgd_solver.cpp:112] Iteration 39050, lr = 0.01
I0523 03:16:51.182680 34819 solver.cpp:239] Iteration 39060 (2.86318 iter/s, 3.49261s/10 iters), loss = 8.36851
I0523 03:16:51.182739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36851 (* 1 = 8.36851 loss)
I0523 03:16:51.310891 34819 sgd_solver.cpp:112] Iteration 39060, lr = 0.01
I0523 03:16:55.452663 34819 solver.cpp:239] Iteration 39070 (2.34208 iter/s, 4.26972s/10 iters), loss = 8.07661
I0523 03:16:55.452739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07661 (* 1 = 8.07661 loss)
I0523 03:16:56.121481 34819 sgd_solver.cpp:112] Iteration 39070, lr = 0.01
I0523 03:16:59.382903 34819 solver.cpp:239] Iteration 39080 (2.54453 iter/s, 3.93s/10 iters), loss = 8.86658
I0523 03:16:59.383117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86658 (* 1 = 8.86658 loss)
I0523 03:17:00.213922 34819 sgd_solver.cpp:112] Iteration 39080, lr = 0.01
I0523 03:17:04.605433 34819 solver.cpp:239] Iteration 39090 (1.91493 iter/s, 5.22213s/10 iters), loss = 9.00388
I0523 03:17:04.605474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00388 (* 1 = 9.00388 loss)
I0523 03:17:05.476999 34819 sgd_solver.cpp:112] Iteration 39090, lr = 0.01
I0523 03:17:09.830729 34819 solver.cpp:239] Iteration 39100 (1.91387 iter/s, 5.22502s/10 iters), loss = 8.68279
I0523 03:17:09.830771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68279 (* 1 = 8.68279 loss)
I0523 03:17:09.904135 34819 sgd_solver.cpp:112] Iteration 39100, lr = 0.01
I0523 03:17:16.096246 34819 solver.cpp:239] Iteration 39110 (1.59611 iter/s, 6.26522s/10 iters), loss = 8.28095
I0523 03:17:16.096298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28095 (* 1 = 8.28095 loss)
I0523 03:17:16.160667 34819 sgd_solver.cpp:112] Iteration 39110, lr = 0.01
I0523 03:17:21.858999 34819 solver.cpp:239] Iteration 39120 (1.73537 iter/s, 5.76246s/10 iters), loss = 8.68357
I0523 03:17:21.859057 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68357 (* 1 = 8.68357 loss)
I0523 03:17:22.635654 34819 sgd_solver.cpp:112] Iteration 39120, lr = 0.01
I0523 03:17:25.571223 34819 solver.cpp:239] Iteration 39130 (2.69397 iter/s, 3.71199s/10 iters), loss = 8.35262
I0523 03:17:25.571271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35262 (* 1 = 8.35262 loss)
I0523 03:17:25.629676 34819 sgd_solver.cpp:112] Iteration 39130, lr = 0.01
I0523 03:17:31.247654 34819 solver.cpp:239] Iteration 39140 (1.76176 iter/s, 5.67614s/10 iters), loss = 9.66096
I0523 03:17:31.247859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.66096 (* 1 = 9.66096 loss)
I0523 03:17:31.315817 34819 sgd_solver.cpp:112] Iteration 39140, lr = 0.01
I0523 03:17:36.790436 34819 solver.cpp:239] Iteration 39150 (1.80509 iter/s, 5.53989s/10 iters), loss = 8.91874
I0523 03:17:36.790482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91874 (* 1 = 8.91874 loss)
I0523 03:17:36.865670 34819 sgd_solver.cpp:112] Iteration 39150, lr = 0.01
I0523 03:17:42.070397 34819 solver.cpp:239] Iteration 39160 (1.89405 iter/s, 5.27968s/10 iters), loss = 9.0457
I0523 03:17:42.070446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0457 (* 1 = 9.0457 loss)
I0523 03:17:42.128947 34819 sgd_solver.cpp:112] Iteration 39160, lr = 0.01
I0523 03:17:45.448778 34819 solver.cpp:239] Iteration 39170 (2.96016 iter/s, 3.37819s/10 iters), loss = 9.17806
I0523 03:17:45.448822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17806 (* 1 = 9.17806 loss)
I0523 03:17:45.514786 34819 sgd_solver.cpp:112] Iteration 39170, lr = 0.01
I0523 03:17:48.731524 34819 solver.cpp:239] Iteration 39180 (3.04643 iter/s, 3.28253s/10 iters), loss = 9.72077
I0523 03:17:48.731590 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72077 (* 1 = 9.72077 loss)
I0523 03:17:49.594182 34819 sgd_solver.cpp:112] Iteration 39180, lr = 0.01
I0523 03:17:52.675869 34819 solver.cpp:239] Iteration 39190 (2.53543 iter/s, 3.9441s/10 iters), loss = 8.35034
I0523 03:17:52.675920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35034 (* 1 = 8.35034 loss)
I0523 03:17:53.464562 34819 sgd_solver.cpp:112] Iteration 39190, lr = 0.01
I0523 03:17:59.029896 34819 solver.cpp:239] Iteration 39200 (1.57388 iter/s, 6.35372s/10 iters), loss = 8.04179
I0523 03:17:59.029940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04179 (* 1 = 8.04179 loss)
I0523 03:17:59.891935 34819 sgd_solver.cpp:112] Iteration 39200, lr = 0.01
I0523 03:18:04.825220 34819 solver.cpp:239] Iteration 39210 (1.72561 iter/s, 5.79505s/10 iters), loss = 8.77135
I0523 03:18:04.825357 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77135 (* 1 = 8.77135 loss)
I0523 03:18:04.888787 34819 sgd_solver.cpp:112] Iteration 39210, lr = 0.01
I0523 03:18:10.848836 34819 solver.cpp:239] Iteration 39220 (1.66024 iter/s, 6.02324s/10 iters), loss = 8.17698
I0523 03:18:10.848877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17698 (* 1 = 8.17698 loss)
I0523 03:18:10.905351 34819 sgd_solver.cpp:112] Iteration 39220, lr = 0.01
I0523 03:18:14.085237 34819 solver.cpp:239] Iteration 39230 (3.09004 iter/s, 3.23621s/10 iters), loss = 8.18431
I0523 03:18:14.085278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18431 (* 1 = 8.18431 loss)
I0523 03:18:14.878144 34819 sgd_solver.cpp:112] Iteration 39230, lr = 0.01
I0523 03:18:18.381960 34819 solver.cpp:239] Iteration 39240 (2.32748 iter/s, 4.2965s/10 iters), loss = 8.36424
I0523 03:18:18.382011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36424 (* 1 = 8.36424 loss)
I0523 03:18:18.445850 34819 sgd_solver.cpp:112] Iteration 39240, lr = 0.01
I0523 03:18:24.970296 34819 solver.cpp:239] Iteration 39250 (1.51791 iter/s, 6.58802s/10 iters), loss = 8.404
I0523 03:18:24.970367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.404 (* 1 = 8.404 loss)
I0523 03:18:25.778357 34819 sgd_solver.cpp:112] Iteration 39250, lr = 0.01
I0523 03:18:31.271747 34819 solver.cpp:239] Iteration 39260 (1.58702 iter/s, 6.30114s/10 iters), loss = 8.88079
I0523 03:18:31.271790 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88079 (* 1 = 8.88079 loss)
I0523 03:18:31.341712 34819 sgd_solver.cpp:112] Iteration 39260, lr = 0.01
I0523 03:18:36.002197 34819 solver.cpp:239] Iteration 39270 (2.11408 iter/s, 4.73019s/10 iters), loss = 9.03783
I0523 03:18:36.002465 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03783 (* 1 = 9.03783 loss)
I0523 03:18:36.813825 34819 sgd_solver.cpp:112] Iteration 39270, lr = 0.01
I0523 03:18:39.180162 34819 solver.cpp:239] Iteration 39280 (3.14703 iter/s, 3.1776s/10 iters), loss = 8.89397
I0523 03:18:39.180207 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89397 (* 1 = 8.89397 loss)
I0523 03:18:39.238191 34819 sgd_solver.cpp:112] Iteration 39280, lr = 0.01
I0523 03:18:43.494958 34819 solver.cpp:239] Iteration 39290 (2.31773 iter/s, 4.31457s/10 iters), loss = 8.7248
I0523 03:18:43.495014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7248 (* 1 = 8.7248 loss)
I0523 03:18:43.561980 34819 sgd_solver.cpp:112] Iteration 39290, lr = 0.01
I0523 03:18:48.436725 34819 solver.cpp:239] Iteration 39300 (2.02367 iter/s, 4.94151s/10 iters), loss = 8.68176
I0523 03:18:48.436769 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68176 (* 1 = 8.68176 loss)
I0523 03:18:48.498370 34819 sgd_solver.cpp:112] Iteration 39300, lr = 0.01
I0523 03:18:52.314877 34819 solver.cpp:239] Iteration 39310 (2.57869 iter/s, 3.87794s/10 iters), loss = 9.06373
I0523 03:18:52.314929 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06373 (* 1 = 9.06373 loss)
I0523 03:18:52.386972 34819 sgd_solver.cpp:112] Iteration 39310, lr = 0.01
I0523 03:18:57.018575 34819 solver.cpp:239] Iteration 39320 (2.1261 iter/s, 4.70344s/10 iters), loss = 7.71505
I0523 03:18:57.018623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71505 (* 1 = 7.71505 loss)
I0523 03:18:57.075721 34819 sgd_solver.cpp:112] Iteration 39320, lr = 0.01
I0523 03:19:02.695507 34819 solver.cpp:239] Iteration 39330 (1.76161 iter/s, 5.67663s/10 iters), loss = 9.97631
I0523 03:19:02.695562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.97631 (* 1 = 9.97631 loss)
I0523 03:19:03.560762 34819 sgd_solver.cpp:112] Iteration 39330, lr = 0.01
I0523 03:19:07.510442 34819 solver.cpp:239] Iteration 39340 (2.07699 iter/s, 4.81466s/10 iters), loss = 8.8168
I0523 03:19:07.510612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8168 (* 1 = 8.8168 loss)
I0523 03:19:07.567294 34819 sgd_solver.cpp:112] Iteration 39340, lr = 0.01
I0523 03:19:13.199977 34819 solver.cpp:239] Iteration 39350 (1.75775 iter/s, 5.68911s/10 iters), loss = 8.97244
I0523 03:19:13.200037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97244 (* 1 = 8.97244 loss)
I0523 03:19:13.991240 34819 sgd_solver.cpp:112] Iteration 39350, lr = 0.01
I0523 03:19:19.809697 34819 solver.cpp:239] Iteration 39360 (1.513 iter/s, 6.6094s/10 iters), loss = 9.05563
I0523 03:19:19.809751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05563 (* 1 = 9.05563 loss)
I0523 03:19:19.881721 34819 sgd_solver.cpp:112] Iteration 39360, lr = 0.01
I0523 03:19:23.518970 34819 solver.cpp:239] Iteration 39370 (2.6961 iter/s, 3.70906s/10 iters), loss = 8.37016
I0523 03:19:23.519014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37016 (* 1 = 8.37016 loss)
I0523 03:19:23.575523 34819 sgd_solver.cpp:112] Iteration 39370, lr = 0.01
I0523 03:19:26.053262 34819 solver.cpp:239] Iteration 39380 (3.94613 iter/s, 2.53413s/10 iters), loss = 9.57481
I0523 03:19:26.053314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57481 (* 1 = 9.57481 loss)
I0523 03:19:26.876863 34819 sgd_solver.cpp:112] Iteration 39380, lr = 0.01
I0523 03:19:32.371553 34819 solver.cpp:239] Iteration 39390 (1.58279 iter/s, 6.31796s/10 iters), loss = 8.7424
I0523 03:19:32.371605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7424 (* 1 = 8.7424 loss)
I0523 03:19:33.136837 34819 sgd_solver.cpp:112] Iteration 39390, lr = 0.01
I0523 03:19:38.426070 34819 solver.cpp:239] Iteration 39400 (1.65174 iter/s, 6.0542s/10 iters), loss = 9.60269
I0523 03:19:38.426255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60269 (* 1 = 9.60269 loss)
I0523 03:19:38.494093 34819 sgd_solver.cpp:112] Iteration 39400, lr = 0.01
I0523 03:19:42.464066 34819 solver.cpp:239] Iteration 39410 (2.47669 iter/s, 4.03765s/10 iters), loss = 9.7198
I0523 03:19:42.464108 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.7198 (* 1 = 9.7198 loss)
I0523 03:19:42.524123 34819 sgd_solver.cpp:112] Iteration 39410, lr = 0.01
I0523 03:19:47.211992 34819 solver.cpp:239] Iteration 39420 (2.10629 iter/s, 4.74768s/10 iters), loss = 9.94918
I0523 03:19:47.212038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.94918 (* 1 = 9.94918 loss)
I0523 03:19:48.063288 34819 sgd_solver.cpp:112] Iteration 39420, lr = 0.01
I0523 03:19:50.700392 34819 solver.cpp:239] Iteration 39430 (2.86682 iter/s, 3.48818s/10 iters), loss = 8.57204
I0523 03:19:50.700443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57204 (* 1 = 8.57204 loss)
I0523 03:19:51.477540 34819 sgd_solver.cpp:112] Iteration 39430, lr = 0.01
I0523 03:19:55.925622 34819 solver.cpp:239] Iteration 39440 (1.9139 iter/s, 5.22495s/10 iters), loss = 8.52259
I0523 03:19:55.925678 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52259 (* 1 = 8.52259 loss)
I0523 03:19:56.715819 34819 sgd_solver.cpp:112] Iteration 39440, lr = 0.01
I0523 03:20:01.419915 34819 solver.cpp:239] Iteration 39450 (1.82016 iter/s, 5.49401s/10 iters), loss = 9.30913
I0523 03:20:01.419962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30913 (* 1 = 9.30913 loss)
I0523 03:20:02.274457 34819 sgd_solver.cpp:112] Iteration 39450, lr = 0.01
I0523 03:20:07.429369 34819 solver.cpp:239] Iteration 39460 (1.66413 iter/s, 6.00916s/10 iters), loss = 9.16148
I0523 03:20:07.429422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16148 (* 1 = 9.16148 loss)
I0523 03:20:07.497900 34819 sgd_solver.cpp:112] Iteration 39460, lr = 0.01
I0523 03:20:13.416200 34819 solver.cpp:239] Iteration 39470 (1.67042 iter/s, 5.98651s/10 iters), loss = 8.69152
I0523 03:20:13.416358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69152 (* 1 = 8.69152 loss)
I0523 03:20:13.497870 34819 sgd_solver.cpp:112] Iteration 39470, lr = 0.01
I0523 03:20:18.118901 34819 solver.cpp:239] Iteration 39480 (2.1266 iter/s, 4.70235s/10 iters), loss = 9.11484
I0523 03:20:18.118942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11484 (* 1 = 9.11484 loss)
I0523 03:20:18.180949 34819 sgd_solver.cpp:112] Iteration 39480, lr = 0.01
I0523 03:20:20.754477 34819 solver.cpp:239] Iteration 39490 (3.79447 iter/s, 2.63542s/10 iters), loss = 9.06251
I0523 03:20:20.754520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06251 (* 1 = 9.06251 loss)
I0523 03:20:21.523967 34819 sgd_solver.cpp:112] Iteration 39490, lr = 0.01
I0523 03:20:26.471288 34819 solver.cpp:239] Iteration 39500 (1.74931 iter/s, 5.71654s/10 iters), loss = 8.29932
I0523 03:20:26.471330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29932 (* 1 = 8.29932 loss)
I0523 03:20:26.537291 34819 sgd_solver.cpp:112] Iteration 39500, lr = 0.01
I0523 03:20:30.326202 34819 solver.cpp:239] Iteration 39510 (2.59423 iter/s, 3.8547s/10 iters), loss = 7.77955
I0523 03:20:30.326242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77955 (* 1 = 7.77955 loss)
I0523 03:20:30.394557 34819 sgd_solver.cpp:112] Iteration 39510, lr = 0.01
I0523 03:20:33.611279 34819 solver.cpp:239] Iteration 39520 (3.04424 iter/s, 3.28489s/10 iters), loss = 9.21025
I0523 03:20:33.611325 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21025 (* 1 = 9.21025 loss)
I0523 03:20:33.674892 34819 sgd_solver.cpp:112] Iteration 39520, lr = 0.01
I0523 03:20:38.596674 34819 solver.cpp:239] Iteration 39530 (2.00618 iter/s, 4.9846s/10 iters), loss = 9.33474
I0523 03:20:38.596725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33474 (* 1 = 9.33474 loss)
I0523 03:20:39.310036 34819 sgd_solver.cpp:112] Iteration 39530, lr = 0.01
I0523 03:20:42.738818 34819 solver.cpp:239] Iteration 39540 (2.41434 iter/s, 4.14192s/10 iters), loss = 8.93512
I0523 03:20:42.738859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93512 (* 1 = 8.93512 loss)
I0523 03:20:42.815685 34819 sgd_solver.cpp:112] Iteration 39540, lr = 0.01
I0523 03:20:46.230067 34819 solver.cpp:239] Iteration 39550 (2.86446 iter/s, 3.49106s/10 iters), loss = 9.06432
I0523 03:20:46.230132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06432 (* 1 = 9.06432 loss)
I0523 03:20:46.988131 34819 sgd_solver.cpp:112] Iteration 39550, lr = 0.01
I0523 03:20:52.801479 34819 solver.cpp:239] Iteration 39560 (1.52182 iter/s, 6.57108s/10 iters), loss = 9.65807
I0523 03:20:52.801523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65807 (* 1 = 9.65807 loss)
I0523 03:20:52.871129 34819 sgd_solver.cpp:112] Iteration 39560, lr = 0.01
I0523 03:20:56.338485 34819 solver.cpp:239] Iteration 39570 (2.82742 iter/s, 3.5368s/10 iters), loss = 9.2978
I0523 03:20:56.338534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2978 (* 1 = 9.2978 loss)
I0523 03:20:56.416092 34819 sgd_solver.cpp:112] Iteration 39570, lr = 0.01
I0523 03:21:00.429633 34819 solver.cpp:239] Iteration 39580 (2.44444 iter/s, 4.09092s/10 iters), loss = 9.56785
I0523 03:21:00.429675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56785 (* 1 = 9.56785 loss)
I0523 03:21:01.181968 34819 sgd_solver.cpp:112] Iteration 39580, lr = 0.01
I0523 03:21:06.677429 34819 solver.cpp:239] Iteration 39590 (1.60064 iter/s, 6.24749s/10 iters), loss = 8.93303
I0523 03:21:06.677469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93303 (* 1 = 8.93303 loss)
I0523 03:21:06.735172 34819 sgd_solver.cpp:112] Iteration 39590, lr = 0.01
I0523 03:21:11.251767 34819 solver.cpp:239] Iteration 39600 (2.18622 iter/s, 4.57411s/10 iters), loss = 8.58563
I0523 03:21:11.251809 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58563 (* 1 = 8.58563 loss)
I0523 03:21:11.313156 34819 sgd_solver.cpp:112] Iteration 39600, lr = 0.01
I0523 03:21:15.310389 34819 solver.cpp:239] Iteration 39610 (2.46403 iter/s, 4.0584s/10 iters), loss = 8.70708
I0523 03:21:15.310430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70708 (* 1 = 8.70708 loss)
I0523 03:21:15.379762 34819 sgd_solver.cpp:112] Iteration 39610, lr = 0.01
I0523 03:21:19.484469 34819 solver.cpp:239] Iteration 39620 (2.39586 iter/s, 4.17386s/10 iters), loss = 8.42071
I0523 03:21:19.484560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42071 (* 1 = 8.42071 loss)
I0523 03:21:20.336230 34819 sgd_solver.cpp:112] Iteration 39620, lr = 0.01
I0523 03:21:23.922327 34819 solver.cpp:239] Iteration 39630 (2.25348 iter/s, 4.43758s/10 iters), loss = 9.41214
I0523 03:21:23.922368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41214 (* 1 = 9.41214 loss)
I0523 03:21:23.993641 34819 sgd_solver.cpp:112] Iteration 39630, lr = 0.01
I0523 03:21:27.873142 34819 solver.cpp:239] Iteration 39640 (2.53127 iter/s, 3.95059s/10 iters), loss = 8.60752
I0523 03:21:27.873188 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60752 (* 1 = 8.60752 loss)
I0523 03:21:28.549995 34819 sgd_solver.cpp:112] Iteration 39640, lr = 0.01
I0523 03:21:34.131765 34819 solver.cpp:239] Iteration 39650 (1.59787 iter/s, 6.25832s/10 iters), loss = 7.98558
I0523 03:21:34.131817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98558 (* 1 = 7.98558 loss)
I0523 03:21:34.978426 34819 sgd_solver.cpp:112] Iteration 39650, lr = 0.01
I0523 03:21:40.473359 34819 solver.cpp:239] Iteration 39660 (1.57697 iter/s, 6.34128s/10 iters), loss = 8.97298
I0523 03:21:40.473409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97298 (* 1 = 8.97298 loss)
I0523 03:21:41.276935 34819 sgd_solver.cpp:112] Iteration 39660, lr = 0.01
I0523 03:21:46.699245 34819 solver.cpp:239] Iteration 39670 (1.60628 iter/s, 6.22558s/10 iters), loss = 8.71331
I0523 03:21:46.699286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71331 (* 1 = 8.71331 loss)
I0523 03:21:46.753911 34819 sgd_solver.cpp:112] Iteration 39670, lr = 0.01
I0523 03:21:51.480130 34819 solver.cpp:239] Iteration 39680 (2.09177 iter/s, 4.78064s/10 iters), loss = 8.68782
I0523 03:21:51.480326 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68782 (* 1 = 8.68782 loss)
I0523 03:21:52.187916 34819 sgd_solver.cpp:112] Iteration 39680, lr = 0.01
I0523 03:21:55.076081 34819 solver.cpp:239] Iteration 39690 (2.78116 iter/s, 3.59562s/10 iters), loss = 8.88839
I0523 03:21:55.076138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88839 (* 1 = 8.88839 loss)
I0523 03:21:55.141520 34819 sgd_solver.cpp:112] Iteration 39690, lr = 0.01
I0523 03:21:59.444998 34819 solver.cpp:239] Iteration 39700 (2.28902 iter/s, 4.36868s/10 iters), loss = 9.19437
I0523 03:21:59.445040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19437 (* 1 = 9.19437 loss)
I0523 03:21:59.503032 34819 sgd_solver.cpp:112] Iteration 39700, lr = 0.01
I0523 03:22:03.735471 34819 solver.cpp:239] Iteration 39710 (2.33087 iter/s, 4.29025s/10 iters), loss = 8.51914
I0523 03:22:03.735522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51914 (* 1 = 8.51914 loss)
I0523 03:22:03.797864 34819 sgd_solver.cpp:112] Iteration 39710, lr = 0.01
I0523 03:22:07.695307 34819 solver.cpp:239] Iteration 39720 (2.5255 iter/s, 3.95961s/10 iters), loss = 8.73706
I0523 03:22:07.695358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73706 (* 1 = 8.73706 loss)
I0523 03:22:07.766438 34819 sgd_solver.cpp:112] Iteration 39720, lr = 0.01
I0523 03:22:14.676167 34819 solver.cpp:239] Iteration 39730 (1.43256 iter/s, 6.98052s/10 iters), loss = 9.28254
I0523 03:22:14.676229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28254 (* 1 = 9.28254 loss)
I0523 03:22:15.518373 34819 sgd_solver.cpp:112] Iteration 39730, lr = 0.01
I0523 03:22:18.779431 34819 solver.cpp:239] Iteration 39740 (2.43722 iter/s, 4.10304s/10 iters), loss = 9.56152
I0523 03:22:18.779474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56152 (* 1 = 9.56152 loss)
I0523 03:22:18.851349 34819 sgd_solver.cpp:112] Iteration 39740, lr = 0.01
I0523 03:22:22.567679 34819 solver.cpp:239] Iteration 39750 (2.63989 iter/s, 3.78804s/10 iters), loss = 8.76852
I0523 03:22:22.567826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76852 (* 1 = 8.76852 loss)
I0523 03:22:22.618155 34819 sgd_solver.cpp:112] Iteration 39750, lr = 0.01
I0523 03:22:26.617766 34819 solver.cpp:239] Iteration 39760 (2.46928 iter/s, 4.04976s/10 iters), loss = 8.49681
I0523 03:22:26.617828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49681 (* 1 = 8.49681 loss)
I0523 03:22:26.677436 34819 sgd_solver.cpp:112] Iteration 39760, lr = 0.01
I0523 03:22:31.434820 34819 solver.cpp:239] Iteration 39770 (2.07608 iter/s, 4.81678s/10 iters), loss = 9.07266
I0523 03:22:31.434875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07266 (* 1 = 9.07266 loss)
I0523 03:22:31.505425 34819 sgd_solver.cpp:112] Iteration 39770, lr = 0.01
I0523 03:22:34.159710 34819 solver.cpp:239] Iteration 39780 (3.67011 iter/s, 2.72471s/10 iters), loss = 8.7342
I0523 03:22:34.159770 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7342 (* 1 = 8.7342 loss)
I0523 03:22:34.232816 34819 sgd_solver.cpp:112] Iteration 39780, lr = 0.01
I0523 03:22:38.073756 34819 solver.cpp:239] Iteration 39790 (2.55505 iter/s, 3.91382s/10 iters), loss = 8.43319
I0523 03:22:38.073796 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43319 (* 1 = 8.43319 loss)
I0523 03:22:38.935426 34819 sgd_solver.cpp:112] Iteration 39790, lr = 0.01
I0523 03:22:43.897825 34819 solver.cpp:239] Iteration 39800 (1.7171 iter/s, 5.82379s/10 iters), loss = 7.92249
I0523 03:22:43.897876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92249 (* 1 = 7.92249 loss)
I0523 03:22:43.961397 34819 sgd_solver.cpp:112] Iteration 39800, lr = 0.01
I0523 03:22:50.558871 34819 solver.cpp:239] Iteration 39810 (1.50134 iter/s, 6.66073s/10 iters), loss = 8.67569
I0523 03:22:50.558924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67569 (* 1 = 8.67569 loss)
I0523 03:22:50.630780 34819 sgd_solver.cpp:112] Iteration 39810, lr = 0.01
I0523 03:22:55.326858 34819 solver.cpp:239] Iteration 39820 (2.09744 iter/s, 4.76773s/10 iters), loss = 8.7859
I0523 03:22:55.326983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7859 (* 1 = 8.7859 loss)
I0523 03:22:56.067314 34819 sgd_solver.cpp:112] Iteration 39820, lr = 0.01
I0523 03:23:00.261888 34819 solver.cpp:239] Iteration 39830 (2.02648 iter/s, 4.93467s/10 iters), loss = 8.73765
I0523 03:23:00.261977 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73765 (* 1 = 8.73765 loss)
I0523 03:23:01.030690 34819 sgd_solver.cpp:112] Iteration 39830, lr = 0.01
I0523 03:23:04.552393 34819 solver.cpp:239] Iteration 39840 (2.33087 iter/s, 4.29024s/10 iters), loss = 9.72067
I0523 03:23:04.552446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72067 (* 1 = 9.72067 loss)
I0523 03:23:05.390277 34819 sgd_solver.cpp:112] Iteration 39840, lr = 0.01
I0523 03:23:09.003465 34819 solver.cpp:239] Iteration 39850 (2.24677 iter/s, 4.45083s/10 iters), loss = 9.36161
I0523 03:23:09.003527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36161 (* 1 = 9.36161 loss)
I0523 03:23:09.072434 34819 sgd_solver.cpp:112] Iteration 39850, lr = 0.01
I0523 03:23:13.835434 34819 solver.cpp:239] Iteration 39860 (2.06966 iter/s, 4.8317s/10 iters), loss = 9.53174
I0523 03:23:13.835510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.53174 (* 1 = 9.53174 loss)
I0523 03:23:13.902541 34819 sgd_solver.cpp:112] Iteration 39860, lr = 0.01
I0523 03:23:17.187088 34819 solver.cpp:239] Iteration 39870 (2.98379 iter/s, 3.35144s/10 iters), loss = 9.15111
I0523 03:23:17.187134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15111 (* 1 = 9.15111 loss)
I0523 03:23:17.243984 34819 sgd_solver.cpp:112] Iteration 39870, lr = 0.01
I0523 03:23:21.402714 34819 solver.cpp:239] Iteration 39880 (2.37226 iter/s, 4.21539s/10 iters), loss = 8.50424
I0523 03:23:21.402768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50424 (* 1 = 8.50424 loss)
I0523 03:23:21.477962 34819 sgd_solver.cpp:112] Iteration 39880, lr = 0.01
I0523 03:23:26.864610 34819 solver.cpp:239] Iteration 39890 (1.83096 iter/s, 5.46162s/10 iters), loss = 8.8219
I0523 03:23:26.864816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8219 (* 1 = 8.8219 loss)
I0523 03:23:27.639153 34819 sgd_solver.cpp:112] Iteration 39890, lr = 0.01
I0523 03:23:33.204313 34819 solver.cpp:239] Iteration 39900 (1.57747 iter/s, 6.33926s/10 iters), loss = 8.99869
I0523 03:23:33.204378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99869 (* 1 = 8.99869 loss)
I0523 03:23:33.567042 34819 sgd_solver.cpp:112] Iteration 39900, lr = 0.01
I0523 03:23:39.131177 34819 solver.cpp:239] Iteration 39910 (1.68732 iter/s, 5.92656s/10 iters), loss = 8.5652
I0523 03:23:39.131219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5652 (* 1 = 8.5652 loss)
I0523 03:23:39.209955 34819 sgd_solver.cpp:112] Iteration 39910, lr = 0.01
I0523 03:23:42.879892 34819 solver.cpp:239] Iteration 39920 (2.66773 iter/s, 3.7485s/10 iters), loss = 9.51579
I0523 03:23:42.879945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51579 (* 1 = 9.51579 loss)
I0523 03:23:43.687585 34819 sgd_solver.cpp:112] Iteration 39920, lr = 0.01
I0523 03:23:47.794350 34819 solver.cpp:239] Iteration 39930 (2.03492 iter/s, 4.9142s/10 iters), loss = 7.19843
I0523 03:23:47.794391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.19843 (* 1 = 7.19843 loss)
I0523 03:23:47.858716 34819 sgd_solver.cpp:112] Iteration 39930, lr = 0.01
I0523 03:23:52.907573 34819 solver.cpp:239] Iteration 39940 (1.95693 iter/s, 5.11005s/10 iters), loss = 8.32051
I0523 03:23:52.907620 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32051 (* 1 = 8.32051 loss)
I0523 03:23:53.430522 34819 sgd_solver.cpp:112] Iteration 39940, lr = 0.01
I0523 03:23:56.910401 34819 solver.cpp:239] Iteration 39950 (2.49837 iter/s, 4.00261s/10 iters), loss = 9.10415
I0523 03:23:56.910576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10415 (* 1 = 9.10415 loss)
I0523 03:23:56.971154 34819 sgd_solver.cpp:112] Iteration 39950, lr = 0.01
I0523 03:23:59.667978 34819 solver.cpp:239] Iteration 39960 (3.62674 iter/s, 2.7573s/10 iters), loss = 8.72832
I0523 03:23:59.668026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72832 (* 1 = 8.72832 loss)
I0523 03:23:59.751683 34819 sgd_solver.cpp:112] Iteration 39960, lr = 0.01
I0523 03:24:04.886092 34819 solver.cpp:239] Iteration 39970 (1.9165 iter/s, 5.21785s/10 iters), loss = 9.81509
I0523 03:24:04.886138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.81509 (* 1 = 9.81509 loss)
I0523 03:24:04.954659 34819 sgd_solver.cpp:112] Iteration 39970, lr = 0.01
I0523 03:24:08.415645 34819 solver.cpp:239] Iteration 39980 (2.8334 iter/s, 3.52933s/10 iters), loss = 8.36819
I0523 03:24:08.415694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36819 (* 1 = 8.36819 loss)
I0523 03:24:08.475247 34819 sgd_solver.cpp:112] Iteration 39980, lr = 0.01
I0523 03:24:11.790932 34819 solver.cpp:239] Iteration 39990 (2.96288 iter/s, 3.37509s/10 iters), loss = 8.68709
I0523 03:24:11.790973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68709 (* 1 = 8.68709 loss)
I0523 03:24:12.458070 34819 sgd_solver.cpp:112] Iteration 39990, lr = 0.01
I0523 03:24:15.891602 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_40000.caffemodel
I0523 03:25:02.850020 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_40000.solverstate
I0523 03:25:03.080075 34819 solver.cpp:239] Iteration 40000 (0.194981 iter/s, 51.2872s/10 iters), loss = 8.46208
I0523 03:25:03.080113 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46208 (* 1 = 8.46208 loss)
I0523 03:25:03.880692 34819 sgd_solver.cpp:112] Iteration 40000, lr = 0.01
I0523 03:25:09.460835 34819 solver.cpp:239] Iteration 40010 (1.56729 iter/s, 6.38044s/10 iters), loss = 9.28536
I0523 03:25:09.460886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28536 (* 1 = 9.28536 loss)
I0523 03:25:10.229717 34819 sgd_solver.cpp:112] Iteration 40010, lr = 0.01
I0523 03:25:14.633893 34819 solver.cpp:239] Iteration 40020 (1.93319 iter/s, 5.17278s/10 iters), loss = 8.04801
I0523 03:25:14.633934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04801 (* 1 = 8.04801 loss)
I0523 03:25:14.698917 34819 sgd_solver.cpp:112] Iteration 40020, lr = 0.01
I0523 03:25:18.935956 34819 solver.cpp:239] Iteration 40030 (2.32459 iter/s, 4.30184s/10 iters), loss = 8.30307
I0523 03:25:18.936002 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30307 (* 1 = 8.30307 loss)
I0523 03:25:19.834839 34819 sgd_solver.cpp:112] Iteration 40030, lr = 0.01
I0523 03:25:25.554080 34819 solver.cpp:239] Iteration 40040 (1.51108 iter/s, 6.6178s/10 iters), loss = 9.65805
I0523 03:25:25.554121 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65805 (* 1 = 9.65805 loss)
I0523 03:25:25.626590 34819 sgd_solver.cpp:112] Iteration 40040, lr = 0.01
I0523 03:25:29.445628 34819 solver.cpp:239] Iteration 40050 (2.56981 iter/s, 3.89133s/10 iters), loss = 8.74112
I0523 03:25:29.445672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74112 (* 1 = 8.74112 loss)
I0523 03:25:29.522063 34819 sgd_solver.cpp:112] Iteration 40050, lr = 0.01
I0523 03:25:33.019446 34819 solver.cpp:239] Iteration 40060 (2.79829 iter/s, 3.57361s/10 iters), loss = 9.2132
I0523 03:25:33.019570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2132 (* 1 = 9.2132 loss)
I0523 03:25:33.672927 34819 sgd_solver.cpp:112] Iteration 40060, lr = 0.01
I0523 03:25:37.603926 34819 solver.cpp:239] Iteration 40070 (2.18142 iter/s, 4.58417s/10 iters), loss = 9.23711
I0523 03:25:37.603966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23711 (* 1 = 9.23711 loss)
I0523 03:25:38.231832 34819 sgd_solver.cpp:112] Iteration 40070, lr = 0.01
I0523 03:25:42.972800 34819 solver.cpp:239] Iteration 40080 (1.86268 iter/s, 5.3686s/10 iters), loss = 8.07011
I0523 03:25:42.972856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07011 (* 1 = 8.07011 loss)
I0523 03:25:43.317728 34819 sgd_solver.cpp:112] Iteration 40080, lr = 0.01
I0523 03:25:47.396917 34819 solver.cpp:239] Iteration 40090 (2.26046 iter/s, 4.42387s/10 iters), loss = 8.55504
I0523 03:25:47.396960 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55504 (* 1 = 8.55504 loss)
I0523 03:25:47.469806 34819 sgd_solver.cpp:112] Iteration 40090, lr = 0.01
I0523 03:25:50.762081 34819 solver.cpp:239] Iteration 40100 (2.9718 iter/s, 3.36497s/10 iters), loss = 8.26664
I0523 03:25:50.762122 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26664 (* 1 = 8.26664 loss)
I0523 03:25:50.820734 34819 sgd_solver.cpp:112] Iteration 40100, lr = 0.01
I0523 03:25:55.800112 34819 solver.cpp:239] Iteration 40110 (1.985 iter/s, 5.03778s/10 iters), loss = 8.51834
I0523 03:25:55.800153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51834 (* 1 = 8.51834 loss)
I0523 03:25:55.872984 34819 sgd_solver.cpp:112] Iteration 40110, lr = 0.01
I0523 03:25:59.872584 34819 solver.cpp:239] Iteration 40120 (2.45565 iter/s, 4.07225s/10 iters), loss = 9.47511
I0523 03:25:59.872635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47511 (* 1 = 9.47511 loss)
I0523 03:25:59.938416 34819 sgd_solver.cpp:112] Iteration 40120, lr = 0.01
I0523 03:26:04.153151 34819 solver.cpp:239] Iteration 40130 (2.33627 iter/s, 4.28033s/10 iters), loss = 8.21511
I0523 03:26:04.153285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21511 (* 1 = 8.21511 loss)
I0523 03:26:04.228216 34819 sgd_solver.cpp:112] Iteration 40130, lr = 0.01
I0523 03:26:08.525679 34819 solver.cpp:239] Iteration 40140 (2.28717 iter/s, 4.37221s/10 iters), loss = 8.52442
I0523 03:26:08.525722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52442 (* 1 = 8.52442 loss)
I0523 03:26:08.589000 34819 sgd_solver.cpp:112] Iteration 40140, lr = 0.01
I0523 03:26:14.214979 34819 solver.cpp:239] Iteration 40150 (1.75777 iter/s, 5.68901s/10 iters), loss = 8.74401
I0523 03:26:14.215021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74401 (* 1 = 8.74401 loss)
I0523 03:26:15.099494 34819 sgd_solver.cpp:112] Iteration 40150, lr = 0.01
I0523 03:26:19.100507 34819 solver.cpp:239] Iteration 40160 (2.04697 iter/s, 4.88528s/10 iters), loss = 9.07572
I0523 03:26:19.100549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07572 (* 1 = 9.07572 loss)
I0523 03:26:19.152539 34819 sgd_solver.cpp:112] Iteration 40160, lr = 0.01
I0523 03:26:23.843468 34819 solver.cpp:239] Iteration 40170 (2.10849 iter/s, 4.74272s/10 iters), loss = 8.95387
I0523 03:26:23.843513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95387 (* 1 = 8.95387 loss)
I0523 03:26:23.911121 34819 sgd_solver.cpp:112] Iteration 40170, lr = 0.01
I0523 03:26:30.596897 34819 solver.cpp:239] Iteration 40180 (1.4808 iter/s, 6.75311s/10 iters), loss = 8.31586
I0523 03:26:30.596938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31586 (* 1 = 8.31586 loss)
I0523 03:26:30.671953 34819 sgd_solver.cpp:112] Iteration 40180, lr = 0.01
I0523 03:26:35.215698 34819 solver.cpp:239] Iteration 40190 (2.16517 iter/s, 4.61856s/10 iters), loss = 8.57076
I0523 03:26:35.215804 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57076 (* 1 = 8.57076 loss)
I0523 03:26:35.278424 34819 sgd_solver.cpp:112] Iteration 40190, lr = 0.01
I0523 03:26:40.025254 34819 solver.cpp:239] Iteration 40200 (2.07933 iter/s, 4.80923s/10 iters), loss = 8.6287
I0523 03:26:40.025308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6287 (* 1 = 8.6287 loss)
I0523 03:26:40.741345 34819 sgd_solver.cpp:112] Iteration 40200, lr = 0.01
I0523 03:26:45.459576 34819 solver.cpp:239] Iteration 40210 (1.84025 iter/s, 5.43404s/10 iters), loss = 8.34745
I0523 03:26:45.459623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34745 (* 1 = 8.34745 loss)
I0523 03:26:46.013093 34819 sgd_solver.cpp:112] Iteration 40210, lr = 0.01
I0523 03:26:50.865602 34819 solver.cpp:239] Iteration 40220 (1.84988 iter/s, 5.40576s/10 iters), loss = 9.10889
I0523 03:26:50.865641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10889 (* 1 = 9.10889 loss)
I0523 03:26:51.734741 34819 sgd_solver.cpp:112] Iteration 40220, lr = 0.01
I0523 03:26:55.115046 34819 solver.cpp:239] Iteration 40230 (2.35337 iter/s, 4.24922s/10 iters), loss = 9.28696
I0523 03:26:55.115090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28696 (* 1 = 9.28696 loss)
I0523 03:26:55.178316 34819 sgd_solver.cpp:112] Iteration 40230, lr = 0.01
I0523 03:27:00.089670 34819 solver.cpp:239] Iteration 40240 (2.0103 iter/s, 4.97438s/10 iters), loss = 9.53299
I0523 03:27:00.089715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.53299 (* 1 = 9.53299 loss)
I0523 03:27:00.148049 34819 sgd_solver.cpp:112] Iteration 40240, lr = 0.01
I0523 03:27:05.308162 34819 solver.cpp:239] Iteration 40250 (1.91636 iter/s, 5.21823s/10 iters), loss = 9.58865
I0523 03:27:05.308312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58865 (* 1 = 9.58865 loss)
I0523 03:27:05.387553 34819 sgd_solver.cpp:112] Iteration 40250, lr = 0.01
I0523 03:27:11.037500 34819 solver.cpp:239] Iteration 40260 (1.74552 iter/s, 5.72894s/10 iters), loss = 7.74549
I0523 03:27:11.037555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74549 (* 1 = 7.74549 loss)
I0523 03:27:11.113636 34819 sgd_solver.cpp:112] Iteration 40260, lr = 0.01
I0523 03:27:15.326820 34819 solver.cpp:239] Iteration 40270 (2.3315 iter/s, 4.28909s/10 iters), loss = 8.65711
I0523 03:27:15.326864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65711 (* 1 = 8.65711 loss)
I0523 03:27:16.085999 34819 sgd_solver.cpp:112] Iteration 40270, lr = 0.01
I0523 03:27:19.650507 34819 solver.cpp:239] Iteration 40280 (2.31297 iter/s, 4.32345s/10 iters), loss = 9.3209
I0523 03:27:19.650564 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3209 (* 1 = 9.3209 loss)
I0523 03:27:20.396029 34819 sgd_solver.cpp:112] Iteration 40280, lr = 0.01
I0523 03:27:24.628928 34819 solver.cpp:239] Iteration 40290 (2.00879 iter/s, 4.97813s/10 iters), loss = 9.11989
I0523 03:27:24.628971 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11989 (* 1 = 9.11989 loss)
I0523 03:27:25.412154 34819 sgd_solver.cpp:112] Iteration 40290, lr = 0.01
I0523 03:27:28.830296 34819 solver.cpp:239] Iteration 40300 (2.38031 iter/s, 4.20113s/10 iters), loss = 9.31991
I0523 03:27:28.830343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31991 (* 1 = 9.31991 loss)
I0523 03:27:29.526978 34819 sgd_solver.cpp:112] Iteration 40300, lr = 0.01
I0523 03:27:34.340289 34819 solver.cpp:239] Iteration 40310 (1.81498 iter/s, 5.5097s/10 iters), loss = 9.0593
I0523 03:27:34.340345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0593 (* 1 = 9.0593 loss)
I0523 03:27:34.409219 34819 sgd_solver.cpp:112] Iteration 40310, lr = 0.01
I0523 03:27:39.202997 34819 solver.cpp:239] Iteration 40320 (2.05658 iter/s, 4.86244s/10 iters), loss = 8.73926
I0523 03:27:39.203115 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73926 (* 1 = 8.73926 loss)
I0523 03:27:40.090214 34819 sgd_solver.cpp:112] Iteration 40320, lr = 0.01
I0523 03:27:44.554745 34819 solver.cpp:239] Iteration 40330 (1.86867 iter/s, 5.35141s/10 iters), loss = 8.73827
I0523 03:27:44.554792 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73827 (* 1 = 8.73827 loss)
I0523 03:27:44.633785 34819 sgd_solver.cpp:112] Iteration 40330, lr = 0.01
I0523 03:27:47.990018 34819 solver.cpp:239] Iteration 40340 (2.91114 iter/s, 3.43508s/10 iters), loss = 8.23575
I0523 03:27:47.990065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23575 (* 1 = 8.23575 loss)
I0523 03:27:48.726047 34819 sgd_solver.cpp:112] Iteration 40340, lr = 0.01
I0523 03:27:52.024500 34819 solver.cpp:239] Iteration 40350 (2.4788 iter/s, 4.03421s/10 iters), loss = 8.55564
I0523 03:27:52.024554 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55564 (* 1 = 8.55564 loss)
I0523 03:27:52.144210 34819 sgd_solver.cpp:112] Iteration 40350, lr = 0.01
I0523 03:27:57.929956 34819 solver.cpp:239] Iteration 40360 (1.69343 iter/s, 5.90516s/10 iters), loss = 9.30781
I0523 03:27:57.930006 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30781 (* 1 = 9.30781 loss)
I0523 03:27:58.626340 34819 sgd_solver.cpp:112] Iteration 40360, lr = 0.01
I0523 03:28:02.835436 34819 solver.cpp:239] Iteration 40370 (2.03865 iter/s, 4.90521s/10 iters), loss = 8.95765
I0523 03:28:02.835491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95765 (* 1 = 8.95765 loss)
I0523 03:28:03.546911 34819 sgd_solver.cpp:112] Iteration 40370, lr = 0.01
I0523 03:28:09.161785 34819 solver.cpp:239] Iteration 40380 (1.58077 iter/s, 6.32603s/10 iters), loss = 8.4833
I0523 03:28:09.161837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4833 (* 1 = 8.4833 loss)
I0523 03:28:09.870575 34819 sgd_solver.cpp:112] Iteration 40380, lr = 0.01
I0523 03:28:16.122356 34819 solver.cpp:239] Iteration 40390 (1.43673 iter/s, 6.96024s/10 iters), loss = 8.49475
I0523 03:28:16.122400 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49475 (* 1 = 8.49475 loss)
I0523 03:28:16.187522 34819 sgd_solver.cpp:112] Iteration 40390, lr = 0.01
I0523 03:28:21.080862 34819 solver.cpp:239] Iteration 40400 (2.01684 iter/s, 4.95824s/10 iters), loss = 9.21623
I0523 03:28:21.080911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21623 (* 1 = 9.21623 loss)
I0523 03:28:21.133533 34819 sgd_solver.cpp:112] Iteration 40400, lr = 0.01
I0523 03:28:25.101006 34819 solver.cpp:239] Iteration 40410 (2.48761 iter/s, 4.01992s/10 iters), loss = 9.11583
I0523 03:28:25.101063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11583 (* 1 = 9.11583 loss)
I0523 03:28:25.161847 34819 sgd_solver.cpp:112] Iteration 40410, lr = 0.01
I0523 03:28:30.285231 34819 solver.cpp:239] Iteration 40420 (1.92903 iter/s, 5.18395s/10 iters), loss = 9.37138
I0523 03:28:30.285274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37138 (* 1 = 9.37138 loss)
I0523 03:28:30.347040 34819 sgd_solver.cpp:112] Iteration 40420, lr = 0.01
I0523 03:28:35.058686 34819 solver.cpp:239] Iteration 40430 (2.09503 iter/s, 4.77321s/10 iters), loss = 9.88452
I0523 03:28:35.058745 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.88452 (* 1 = 9.88452 loss)
I0523 03:28:35.140933 34819 sgd_solver.cpp:112] Iteration 40430, lr = 0.01
I0523 03:28:38.675235 34819 solver.cpp:239] Iteration 40440 (2.76523 iter/s, 3.61634s/10 iters), loss = 9.10678
I0523 03:28:38.675277 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10678 (* 1 = 9.10678 loss)
I0523 03:28:39.416980 34819 sgd_solver.cpp:112] Iteration 40440, lr = 0.01
I0523 03:28:44.017324 34819 solver.cpp:239] Iteration 40450 (1.87202 iter/s, 5.34181s/10 iters), loss = 9.50422
I0523 03:28:44.017580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50422 (* 1 = 9.50422 loss)
I0523 03:28:44.774456 34819 sgd_solver.cpp:112] Iteration 40450, lr = 0.01
I0523 03:28:50.152861 34819 solver.cpp:239] Iteration 40460 (1.62998 iter/s, 6.13506s/10 iters), loss = 9.72752
I0523 03:28:50.152902 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72752 (* 1 = 9.72752 loss)
I0523 03:28:50.221465 34819 sgd_solver.cpp:112] Iteration 40460, lr = 0.01
I0523 03:28:54.320760 34819 solver.cpp:239] Iteration 40470 (2.39943 iter/s, 4.16766s/10 iters), loss = 8.61277
I0523 03:28:54.320816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61277 (* 1 = 8.61277 loss)
I0523 03:28:54.987887 34819 sgd_solver.cpp:112] Iteration 40470, lr = 0.01
I0523 03:28:58.160027 34819 solver.cpp:239] Iteration 40480 (2.60482 iter/s, 3.83904s/10 iters), loss = 9.42679
I0523 03:28:58.160079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42679 (* 1 = 9.42679 loss)
I0523 03:28:58.233368 34819 sgd_solver.cpp:112] Iteration 40480, lr = 0.01
I0523 03:29:03.698825 34819 solver.cpp:239] Iteration 40490 (1.80696 iter/s, 5.53415s/10 iters), loss = 8.474
I0523 03:29:03.698879 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.474 (* 1 = 8.474 loss)
I0523 03:29:03.763269 34819 sgd_solver.cpp:112] Iteration 40490, lr = 0.01
I0523 03:29:09.525424 34819 solver.cpp:239] Iteration 40500 (1.71635 iter/s, 5.82631s/10 iters), loss = 9.20797
I0523 03:29:09.525465 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20797 (* 1 = 9.20797 loss)
I0523 03:29:09.886080 34819 sgd_solver.cpp:112] Iteration 40500, lr = 0.01
I0523 03:29:13.283411 34819 solver.cpp:239] Iteration 40510 (2.66116 iter/s, 3.75776s/10 iters), loss = 8.19332
I0523 03:29:13.283465 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19332 (* 1 = 8.19332 loss)
I0523 03:29:14.094357 34819 sgd_solver.cpp:112] Iteration 40510, lr = 0.01
I0523 03:29:17.437225 34819 solver.cpp:239] Iteration 40520 (2.40756 iter/s, 4.15359s/10 iters), loss = 8.45677
I0523 03:29:17.437274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45677 (* 1 = 8.45677 loss)
I0523 03:29:17.511137 34819 sgd_solver.cpp:112] Iteration 40520, lr = 0.01
I0523 03:29:24.125511 34819 solver.cpp:239] Iteration 40530 (1.49523 iter/s, 6.68795s/10 iters), loss = 8.30649
I0523 03:29:24.125551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30649 (* 1 = 8.30649 loss)
I0523 03:29:24.925696 34819 sgd_solver.cpp:112] Iteration 40530, lr = 0.01
I0523 03:29:25.839136 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 03:29:29.742255 34819 solver.cpp:239] Iteration 40540 (1.78048 iter/s, 5.61647s/10 iters), loss = 9.43506
I0523 03:29:29.742314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43506 (* 1 = 9.43506 loss)
I0523 03:29:30.610857 34819 sgd_solver.cpp:112] Iteration 40540, lr = 0.01
I0523 03:29:37.627360 34819 solver.cpp:239] Iteration 40550 (1.26828 iter/s, 7.88471s/10 iters), loss = 8.52358
I0523 03:29:37.627410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52358 (* 1 = 8.52358 loss)
I0523 03:29:38.298766 34819 sgd_solver.cpp:112] Iteration 40550, lr = 0.01
I0523 03:29:44.127851 34819 solver.cpp:239] Iteration 40560 (1.53843 iter/s, 6.50015s/10 iters), loss = 9.20869
I0523 03:29:44.128057 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20869 (* 1 = 9.20869 loss)
I0523 03:29:44.959295 34819 sgd_solver.cpp:112] Iteration 40560, lr = 0.01
I0523 03:29:48.799437 34819 solver.cpp:239] Iteration 40570 (2.14078 iter/s, 4.6712s/10 iters), loss = 7.98746
I0523 03:29:48.799477 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98746 (* 1 = 7.98746 loss)
I0523 03:29:49.017777 34819 sgd_solver.cpp:112] Iteration 40570, lr = 0.01
I0523 03:29:54.515965 34819 solver.cpp:239] Iteration 40580 (1.7494 iter/s, 5.71624s/10 iters), loss = 8.45885
I0523 03:29:54.516021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45885 (* 1 = 8.45885 loss)
I0523 03:29:54.595055 34819 sgd_solver.cpp:112] Iteration 40580, lr = 0.01
I0523 03:29:58.141983 34819 solver.cpp:239] Iteration 40590 (2.75802 iter/s, 3.62579s/10 iters), loss = 9.74383
I0523 03:29:58.142045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74383 (* 1 = 9.74383 loss)
I0523 03:29:58.573436 34819 sgd_solver.cpp:112] Iteration 40590, lr = 0.01
I0523 03:30:03.532524 34819 solver.cpp:239] Iteration 40600 (1.8552 iter/s, 5.39024s/10 iters), loss = 10.0719
I0523 03:30:03.532584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0719 (* 1 = 10.0719 loss)
I0523 03:30:04.354882 34819 sgd_solver.cpp:112] Iteration 40600, lr = 0.01
I0523 03:30:07.594246 34819 solver.cpp:239] Iteration 40610 (2.46216 iter/s, 4.06148s/10 iters), loss = 8.86353
I0523 03:30:07.594300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86353 (* 1 = 8.86353 loss)
I0523 03:30:07.658360 34819 sgd_solver.cpp:112] Iteration 40610, lr = 0.01
I0523 03:30:13.601649 34819 solver.cpp:239] Iteration 40620 (1.6647 iter/s, 6.00709s/10 iters), loss = 9.07939
I0523 03:30:13.601691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07939 (* 1 = 9.07939 loss)
I0523 03:30:14.309073 34819 sgd_solver.cpp:112] Iteration 40620, lr = 0.01
I0523 03:30:17.658426 34819 solver.cpp:239] Iteration 40630 (2.46514 iter/s, 4.05656s/10 iters), loss = 8.97084
I0523 03:30:17.658466 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97084 (* 1 = 8.97084 loss)
I0523 03:30:17.736394 34819 sgd_solver.cpp:112] Iteration 40630, lr = 0.01
I0523 03:30:23.877722 34819 solver.cpp:239] Iteration 40640 (1.60798 iter/s, 6.21899s/10 iters), loss = 8.69788
I0523 03:30:23.877771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69788 (* 1 = 8.69788 loss)
I0523 03:30:24.713747 34819 sgd_solver.cpp:112] Iteration 40640, lr = 0.01
I0523 03:30:28.932945 34819 solver.cpp:239] Iteration 40650 (1.97825 iter/s, 5.05497s/10 iters), loss = 8.9011
I0523 03:30:28.932986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9011 (* 1 = 8.9011 loss)
I0523 03:30:28.996232 34819 sgd_solver.cpp:112] Iteration 40650, lr = 0.01
I0523 03:30:34.079996 34819 solver.cpp:239] Iteration 40660 (1.94296 iter/s, 5.1468s/10 iters), loss = 8.78531
I0523 03:30:34.080036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78531 (* 1 = 8.78531 loss)
I0523 03:30:34.140030 34819 sgd_solver.cpp:112] Iteration 40660, lr = 0.01
I0523 03:30:37.697197 34819 solver.cpp:239] Iteration 40670 (2.76474 iter/s, 3.61698s/10 iters), loss = 8.89245
I0523 03:30:37.697257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89245 (* 1 = 8.89245 loss)
I0523 03:30:38.447257 34819 sgd_solver.cpp:112] Iteration 40670, lr = 0.01
I0523 03:30:43.925689 34819 solver.cpp:239] Iteration 40680 (1.60561 iter/s, 6.22817s/10 iters), loss = 9.217
I0523 03:30:43.925750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.217 (* 1 = 9.217 loss)
I0523 03:30:44.710469 34819 sgd_solver.cpp:112] Iteration 40680, lr = 0.01
I0523 03:30:49.301631 34819 solver.cpp:239] Iteration 40690 (1.86024 iter/s, 5.37565s/10 iters), loss = 8.68055
I0523 03:30:49.301684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68055 (* 1 = 8.68055 loss)
I0523 03:30:49.362109 34819 sgd_solver.cpp:112] Iteration 40690, lr = 0.01
I0523 03:30:54.535517 34819 solver.cpp:239] Iteration 40700 (1.91073 iter/s, 5.2336s/10 iters), loss = 8.87699
I0523 03:30:54.535575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87699 (* 1 = 8.87699 loss)
I0523 03:30:55.281323 34819 sgd_solver.cpp:112] Iteration 40700, lr = 0.01
I0523 03:30:59.802371 34819 solver.cpp:239] Iteration 40710 (1.89877 iter/s, 5.26657s/10 iters), loss = 9.05312
I0523 03:30:59.802412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05312 (* 1 = 9.05312 loss)
I0523 03:31:00.617463 34819 sgd_solver.cpp:112] Iteration 40710, lr = 0.01
I0523 03:31:03.026758 34819 solver.cpp:239] Iteration 40720 (3.10155 iter/s, 3.22419s/10 iters), loss = 8.96266
I0523 03:31:03.026820 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96266 (* 1 = 8.96266 loss)
I0523 03:31:03.093122 34819 sgd_solver.cpp:112] Iteration 40720, lr = 0.01
I0523 03:31:09.308970 34819 solver.cpp:239] Iteration 40730 (1.59188 iter/s, 6.2819s/10 iters), loss = 8.95212
I0523 03:31:09.309012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95212 (* 1 = 8.95212 loss)
I0523 03:31:09.377003 34819 sgd_solver.cpp:112] Iteration 40730, lr = 0.01
I0523 03:31:13.053951 34819 solver.cpp:239] Iteration 40740 (2.67038 iter/s, 3.74478s/10 iters), loss = 9.83881
I0523 03:31:13.053992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.83881 (* 1 = 9.83881 loss)
I0523 03:31:13.872700 34819 sgd_solver.cpp:112] Iteration 40740, lr = 0.01
I0523 03:31:19.871852 34819 solver.cpp:239] Iteration 40750 (1.4668 iter/s, 6.81758s/10 iters), loss = 9.27856
I0523 03:31:19.872036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27856 (* 1 = 9.27856 loss)
I0523 03:31:19.933511 34819 sgd_solver.cpp:112] Iteration 40750, lr = 0.01
I0523 03:31:24.747658 34819 solver.cpp:239] Iteration 40760 (2.0511 iter/s, 4.87543s/10 iters), loss = 8.76246
I0523 03:31:24.747709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76246 (* 1 = 8.76246 loss)
I0523 03:31:24.807621 34819 sgd_solver.cpp:112] Iteration 40760, lr = 0.01
I0523 03:31:31.256089 34819 solver.cpp:239] Iteration 40770 (1.53654 iter/s, 6.50811s/10 iters), loss = 9.3699
I0523 03:31:31.256150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3699 (* 1 = 9.3699 loss)
I0523 03:31:31.320119 34819 sgd_solver.cpp:112] Iteration 40770, lr = 0.01
I0523 03:31:33.664366 34819 solver.cpp:239] Iteration 40780 (4.15264 iter/s, 2.40811s/10 iters), loss = 8.66823
I0523 03:31:33.664412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66823 (* 1 = 8.66823 loss)
I0523 03:31:33.760393 34819 sgd_solver.cpp:112] Iteration 40780, lr = 0.01
I0523 03:31:39.951089 34819 solver.cpp:239] Iteration 40790 (1.59073 iter/s, 6.28642s/10 iters), loss = 8.8473
I0523 03:31:39.951146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8473 (* 1 = 8.8473 loss)
I0523 03:31:40.783052 34819 sgd_solver.cpp:112] Iteration 40790, lr = 0.01
I0523 03:31:45.617991 34819 solver.cpp:239] Iteration 40800 (1.76473 iter/s, 5.6666s/10 iters), loss = 8.61248
I0523 03:31:45.618044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61248 (* 1 = 8.61248 loss)
I0523 03:31:46.355760 34819 sgd_solver.cpp:112] Iteration 40800, lr = 0.01
I0523 03:31:51.999555 34819 solver.cpp:239] Iteration 40810 (1.56709 iter/s, 6.38125s/10 iters), loss = 8.65387
I0523 03:31:51.999709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65387 (* 1 = 8.65387 loss)
I0523 03:31:52.071938 34819 sgd_solver.cpp:112] Iteration 40810, lr = 0.01
I0523 03:31:56.026667 34819 solver.cpp:239] Iteration 40820 (2.48337 iter/s, 4.02678s/10 iters), loss = 8.86385
I0523 03:31:56.026743 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86385 (* 1 = 8.86385 loss)
I0523 03:31:56.098544 34819 sgd_solver.cpp:112] Iteration 40820, lr = 0.01
I0523 03:32:01.784586 34819 solver.cpp:239] Iteration 40830 (1.73816 iter/s, 5.75321s/10 iters), loss = 8.46846
I0523 03:32:01.784641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46846 (* 1 = 8.46846 loss)
I0523 03:32:01.850524 34819 sgd_solver.cpp:112] Iteration 40830, lr = 0.01
I0523 03:32:05.307572 34819 solver.cpp:239] Iteration 40840 (2.83867 iter/s, 3.52278s/10 iters), loss = 8.67424
I0523 03:32:05.307618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67424 (* 1 = 8.67424 loss)
I0523 03:32:05.378432 34819 sgd_solver.cpp:112] Iteration 40840, lr = 0.01
I0523 03:32:10.776453 34819 solver.cpp:239] Iteration 40850 (1.82862 iter/s, 5.46859s/10 iters), loss = 8.9321
I0523 03:32:10.776502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9321 (* 1 = 8.9321 loss)
I0523 03:32:11.480304 34819 sgd_solver.cpp:112] Iteration 40850, lr = 0.01
I0523 03:32:16.690011 34819 solver.cpp:239] Iteration 40860 (1.69111 iter/s, 5.91326s/10 iters), loss = 8.46353
I0523 03:32:16.690063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46353 (* 1 = 8.46353 loss)
I0523 03:32:16.753708 34819 sgd_solver.cpp:112] Iteration 40860, lr = 0.01
I0523 03:32:21.652498 34819 solver.cpp:239] Iteration 40870 (2.01523 iter/s, 4.96222s/10 iters), loss = 8.9604
I0523 03:32:21.652570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9604 (* 1 = 8.9604 loss)
I0523 03:32:21.721858 34819 sgd_solver.cpp:112] Iteration 40870, lr = 0.01
I0523 03:32:26.657989 34819 solver.cpp:239] Iteration 40880 (1.99791 iter/s, 5.00522s/10 iters), loss = 9.05715
I0523 03:32:26.658129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05715 (* 1 = 9.05715 loss)
I0523 03:32:26.736639 34819 sgd_solver.cpp:112] Iteration 40880, lr = 0.01
I0523 03:32:32.326108 34819 solver.cpp:239] Iteration 40890 (1.76437 iter/s, 5.66774s/10 iters), loss = 8.61051
I0523 03:32:32.326154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61051 (* 1 = 8.61051 loss)
I0523 03:32:33.070513 34819 sgd_solver.cpp:112] Iteration 40890, lr = 0.01
I0523 03:32:37.367802 34819 solver.cpp:239] Iteration 40900 (1.98356 iter/s, 5.04144s/10 iters), loss = 8.84637
I0523 03:32:37.367847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84637 (* 1 = 8.84637 loss)
I0523 03:32:37.428618 34819 sgd_solver.cpp:112] Iteration 40900, lr = 0.01
I0523 03:32:42.898568 34819 solver.cpp:239] Iteration 40910 (1.80816 iter/s, 5.53048s/10 iters), loss = 8.27364
I0523 03:32:42.898623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27364 (* 1 = 8.27364 loss)
I0523 03:32:42.974476 34819 sgd_solver.cpp:112] Iteration 40910, lr = 0.01
I0523 03:32:47.009382 34819 solver.cpp:239] Iteration 40920 (2.43274 iter/s, 4.11058s/10 iters), loss = 9.19818
I0523 03:32:47.009441 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19818 (* 1 = 9.19818 loss)
I0523 03:32:47.737671 34819 sgd_solver.cpp:112] Iteration 40920, lr = 0.01
I0523 03:32:53.330214 34819 solver.cpp:239] Iteration 40930 (1.58216 iter/s, 6.32047s/10 iters), loss = 8.70621
I0523 03:32:53.330262 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70621 (* 1 = 8.70621 loss)
I0523 03:32:54.126010 34819 sgd_solver.cpp:112] Iteration 40930, lr = 0.01
I0523 03:32:59.890094 34819 solver.cpp:239] Iteration 40940 (1.52449 iter/s, 6.55955s/10 iters), loss = 9.93398
I0523 03:32:59.890241 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93398 (* 1 = 9.93398 loss)
I0523 03:32:59.953085 34819 sgd_solver.cpp:112] Iteration 40940, lr = 0.01
I0523 03:33:04.801957 34819 solver.cpp:239] Iteration 40950 (2.03603 iter/s, 4.91152s/10 iters), loss = 8.49541
I0523 03:33:04.802008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49541 (* 1 = 8.49541 loss)
I0523 03:33:05.650473 34819 sgd_solver.cpp:112] Iteration 40950, lr = 0.01
I0523 03:33:08.557445 34819 solver.cpp:239] Iteration 40960 (2.66292 iter/s, 3.75528s/10 iters), loss = 8.62078
I0523 03:33:08.557487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62078 (* 1 = 8.62078 loss)
I0523 03:33:08.612994 34819 sgd_solver.cpp:112] Iteration 40960, lr = 0.01
I0523 03:33:12.403084 34819 solver.cpp:239] Iteration 40970 (2.60049 iter/s, 3.84543s/10 iters), loss = 9.11438
I0523 03:33:12.403141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11438 (* 1 = 9.11438 loss)
I0523 03:33:12.469871 34819 sgd_solver.cpp:112] Iteration 40970, lr = 0.01
I0523 03:33:16.953423 34819 solver.cpp:239] Iteration 40980 (2.19776 iter/s, 4.55009s/10 iters), loss = 7.88057
I0523 03:33:16.953474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88057 (* 1 = 7.88057 loss)
I0523 03:33:17.006649 34819 sgd_solver.cpp:112] Iteration 40980, lr = 0.01
I0523 03:33:21.147423 34819 solver.cpp:239] Iteration 40990 (2.3845 iter/s, 4.19375s/10 iters), loss = 8.45118
I0523 03:33:21.147480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45118 (* 1 = 8.45118 loss)
I0523 03:33:21.936301 34819 sgd_solver.cpp:112] Iteration 40990, lr = 0.01
I0523 03:33:24.223232 34819 solver.cpp:239] Iteration 41000 (3.25139 iter/s, 3.07561s/10 iters), loss = 8.64773
I0523 03:33:24.223285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64773 (* 1 = 8.64773 loss)
I0523 03:33:25.026219 34819 sgd_solver.cpp:112] Iteration 41000, lr = 0.01
I0523 03:33:29.722048 34819 solver.cpp:239] Iteration 41010 (1.81867 iter/s, 5.49854s/10 iters), loss = 8.91918
I0523 03:33:29.722100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91918 (* 1 = 8.91918 loss)
I0523 03:33:29.798456 34819 sgd_solver.cpp:112] Iteration 41010, lr = 0.01
I0523 03:33:34.775504 34819 solver.cpp:239] Iteration 41020 (1.97895 iter/s, 5.05317s/10 iters), loss = 9.13334
I0523 03:33:34.775604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13334 (* 1 = 9.13334 loss)
I0523 03:33:35.637552 34819 sgd_solver.cpp:112] Iteration 41020, lr = 0.01
I0523 03:33:38.638592 34819 solver.cpp:239] Iteration 41030 (2.58878 iter/s, 3.86282s/10 iters), loss = 8.41672
I0523 03:33:38.638648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41672 (* 1 = 8.41672 loss)
I0523 03:33:39.202996 34819 sgd_solver.cpp:112] Iteration 41030, lr = 0.01
I0523 03:33:43.549729 34819 solver.cpp:239] Iteration 41040 (2.0363 iter/s, 4.91087s/10 iters), loss = 9.2725
I0523 03:33:43.549778 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2725 (* 1 = 9.2725 loss)
I0523 03:33:43.628361 34819 sgd_solver.cpp:112] Iteration 41040, lr = 0.01
I0523 03:33:50.134510 34819 solver.cpp:239] Iteration 41050 (1.51873 iter/s, 6.58446s/10 iters), loss = 8.14288
I0523 03:33:50.134562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14288 (* 1 = 8.14288 loss)
I0523 03:33:50.210358 34819 sgd_solver.cpp:112] Iteration 41050, lr = 0.01
I0523 03:33:55.171875 34819 solver.cpp:239] Iteration 41060 (1.98527 iter/s, 5.03709s/10 iters), loss = 9.11583
I0523 03:33:55.171917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11583 (* 1 = 9.11583 loss)
I0523 03:33:55.243741 34819 sgd_solver.cpp:112] Iteration 41060, lr = 0.01
I0523 03:34:00.597029 34819 solver.cpp:239] Iteration 41070 (1.84336 iter/s, 5.42488s/10 iters), loss = 8.67214
I0523 03:34:00.597072 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67214 (* 1 = 8.67214 loss)
I0523 03:34:01.362032 34819 sgd_solver.cpp:112] Iteration 41070, lr = 0.01
I0523 03:34:06.116912 34819 solver.cpp:239] Iteration 41080 (1.81172 iter/s, 5.51961s/10 iters), loss = 8.70588
I0523 03:34:06.117069 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70588 (* 1 = 8.70588 loss)
I0523 03:34:06.196568 34819 sgd_solver.cpp:112] Iteration 41080, lr = 0.01
I0523 03:34:09.561194 34819 solver.cpp:239] Iteration 41090 (2.90362 iter/s, 3.44398s/10 iters), loss = 8.2569
I0523 03:34:09.561235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2569 (* 1 = 8.2569 loss)
I0523 03:34:10.021112 34819 sgd_solver.cpp:112] Iteration 41090, lr = 0.01
I0523 03:34:13.495951 34819 solver.cpp:239] Iteration 41100 (2.54159 iter/s, 3.93454s/10 iters), loss = 9.01328
I0523 03:34:13.496003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01328 (* 1 = 9.01328 loss)
I0523 03:34:14.364303 34819 sgd_solver.cpp:112] Iteration 41100, lr = 0.01
I0523 03:34:22.308077 34819 solver.cpp:239] Iteration 41110 (1.13486 iter/s, 8.81169s/10 iters), loss = 8.9203
I0523 03:34:22.308135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9203 (* 1 = 8.9203 loss)
I0523 03:34:23.150985 34819 sgd_solver.cpp:112] Iteration 41110, lr = 0.01
I0523 03:34:29.343701 34819 solver.cpp:239] Iteration 41120 (1.42141 iter/s, 7.03526s/10 iters), loss = 8.72055
I0523 03:34:29.343757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72055 (* 1 = 8.72055 loss)
I0523 03:34:29.417410 34819 sgd_solver.cpp:112] Iteration 41120, lr = 0.01
I0523 03:34:32.714464 34819 solver.cpp:239] Iteration 41130 (2.96689 iter/s, 3.37053s/10 iters), loss = 9.41543
I0523 03:34:32.714527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41543 (* 1 = 9.41543 loss)
I0523 03:34:32.772078 34819 sgd_solver.cpp:112] Iteration 41130, lr = 0.01
I0523 03:34:38.226271 34819 solver.cpp:239] Iteration 41140 (1.81438 iter/s, 5.51152s/10 iters), loss = 8.75074
I0523 03:34:38.226511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75074 (* 1 = 8.75074 loss)
I0523 03:34:38.308506 34819 sgd_solver.cpp:112] Iteration 41140, lr = 0.01
I0523 03:34:44.466506 34819 solver.cpp:239] Iteration 41150 (1.60375 iter/s, 6.2354s/10 iters), loss = 8.88134
I0523 03:34:44.466557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88134 (* 1 = 8.88134 loss)
I0523 03:34:44.537163 34819 sgd_solver.cpp:112] Iteration 41150, lr = 0.01
I0523 03:34:49.440369 34819 solver.cpp:239] Iteration 41160 (2.01061 iter/s, 4.97361s/10 iters), loss = 8.94773
I0523 03:34:49.440412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94773 (* 1 = 8.94773 loss)
I0523 03:34:49.507100 34819 sgd_solver.cpp:112] Iteration 41160, lr = 0.01
I0523 03:34:53.632123 34819 solver.cpp:239] Iteration 41170 (2.38576 iter/s, 4.19153s/10 iters), loss = 8.53148
I0523 03:34:53.632165 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53148 (* 1 = 8.53148 loss)
I0523 03:34:54.488768 34819 sgd_solver.cpp:112] Iteration 41170, lr = 0.01
I0523 03:34:57.129300 34819 solver.cpp:239] Iteration 41180 (2.85961 iter/s, 3.49698s/10 iters), loss = 8.67157
I0523 03:34:57.129343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67157 (* 1 = 8.67157 loss)
I0523 03:34:57.970026 34819 sgd_solver.cpp:112] Iteration 41180, lr = 0.01
I0523 03:35:01.322264 34819 solver.cpp:239] Iteration 41190 (2.38508 iter/s, 4.19274s/10 iters), loss = 8.67353
I0523 03:35:01.322319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67353 (* 1 = 8.67353 loss)
I0523 03:35:02.147384 34819 sgd_solver.cpp:112] Iteration 41190, lr = 0.01
I0523 03:35:06.640250 34819 solver.cpp:239] Iteration 41200 (1.88051 iter/s, 5.3177s/10 iters), loss = 8.40264
I0523 03:35:06.640300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40264 (* 1 = 8.40264 loss)
I0523 03:35:07.533126 34819 sgd_solver.cpp:112] Iteration 41200, lr = 0.01
I0523 03:35:13.231544 34819 solver.cpp:239] Iteration 41210 (1.51723 iter/s, 6.59098s/10 iters), loss = 8.56314
I0523 03:35:13.231768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56314 (* 1 = 8.56314 loss)
I0523 03:35:14.084066 34819 sgd_solver.cpp:112] Iteration 41210, lr = 0.01
I0523 03:35:18.471971 34819 solver.cpp:239] Iteration 41220 (1.9084 iter/s, 5.23999s/10 iters), loss = 8.58088
I0523 03:35:18.472024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58088 (* 1 = 8.58088 loss)
I0523 03:35:19.293254 34819 sgd_solver.cpp:112] Iteration 41220, lr = 0.01
I0523 03:35:22.568339 34819 solver.cpp:239] Iteration 41230 (2.44133 iter/s, 4.09613s/10 iters), loss = 8.55719
I0523 03:35:22.568392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55719 (* 1 = 8.55719 loss)
I0523 03:35:23.430622 34819 sgd_solver.cpp:112] Iteration 41230, lr = 0.01
I0523 03:35:27.515941 34819 solver.cpp:239] Iteration 41240 (2.02129 iter/s, 4.94734s/10 iters), loss = 9.24514
I0523 03:35:27.515993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24514 (* 1 = 9.24514 loss)
I0523 03:35:28.280449 34819 sgd_solver.cpp:112] Iteration 41240, lr = 0.01
I0523 03:35:32.755420 34819 solver.cpp:239] Iteration 41250 (1.90869 iter/s, 5.23921s/10 iters), loss = 7.73362
I0523 03:35:32.755472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73362 (* 1 = 7.73362 loss)
I0523 03:35:33.576195 34819 sgd_solver.cpp:112] Iteration 41250, lr = 0.01
I0523 03:35:39.129384 34819 solver.cpp:239] Iteration 41260 (1.56896 iter/s, 6.37364s/10 iters), loss = 8.05268
I0523 03:35:39.129434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05268 (* 1 = 8.05268 loss)
I0523 03:35:39.206218 34819 sgd_solver.cpp:112] Iteration 41260, lr = 0.01
I0523 03:35:44.579854 34819 solver.cpp:239] Iteration 41270 (1.8348 iter/s, 5.4502s/10 iters), loss = 8.42596
I0523 03:35:44.581279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42596 (* 1 = 8.42596 loss)
I0523 03:35:45.436913 34819 sgd_solver.cpp:112] Iteration 41270, lr = 0.01
I0523 03:35:50.176967 34819 solver.cpp:239] Iteration 41280 (1.78849 iter/s, 5.59131s/10 iters), loss = 9.17708
I0523 03:35:50.177019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17708 (* 1 = 9.17708 loss)
I0523 03:35:50.230177 34819 sgd_solver.cpp:112] Iteration 41280, lr = 0.01
I0523 03:35:55.040995 34819 solver.cpp:239] Iteration 41290 (2.05602 iter/s, 4.86377s/10 iters), loss = 9.09581
I0523 03:35:55.041038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09581 (* 1 = 9.09581 loss)
I0523 03:35:55.845120 34819 sgd_solver.cpp:112] Iteration 41290, lr = 0.01
I0523 03:36:00.134188 34819 solver.cpp:239] Iteration 41300 (1.9635 iter/s, 5.09294s/10 iters), loss = 8.54364
I0523 03:36:00.134238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54364 (* 1 = 8.54364 loss)
I0523 03:36:00.196177 34819 sgd_solver.cpp:112] Iteration 41300, lr = 0.01
I0523 03:36:03.636438 34819 solver.cpp:239] Iteration 41310 (2.8555 iter/s, 3.50202s/10 iters), loss = 8.41982
I0523 03:36:03.636497 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41982 (* 1 = 8.41982 loss)
I0523 03:36:04.332875 34819 sgd_solver.cpp:112] Iteration 41310, lr = 0.01
I0523 03:36:08.036877 34819 solver.cpp:239] Iteration 41320 (2.27262 iter/s, 4.4002s/10 iters), loss = 9.1102
I0523 03:36:08.036936 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1102 (* 1 = 9.1102 loss)
I0523 03:36:08.117725 34819 sgd_solver.cpp:112] Iteration 41320, lr = 0.01
I0523 03:36:12.462473 34819 solver.cpp:239] Iteration 41330 (2.25971 iter/s, 4.42535s/10 iters), loss = 9.29106
I0523 03:36:12.462514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29106 (* 1 = 9.29106 loss)
I0523 03:36:13.041764 34819 sgd_solver.cpp:112] Iteration 41330, lr = 0.01
I0523 03:36:17.008180 34819 solver.cpp:239] Iteration 41340 (2.19999 iter/s, 4.54547s/10 iters), loss = 8.65385
I0523 03:36:17.008323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65385 (* 1 = 8.65385 loss)
I0523 03:36:17.069084 34819 sgd_solver.cpp:112] Iteration 41340, lr = 0.01
I0523 03:36:21.214610 34819 solver.cpp:239] Iteration 41350 (2.3775 iter/s, 4.2061s/10 iters), loss = 7.70897
I0523 03:36:21.214664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70897 (* 1 = 7.70897 loss)
I0523 03:36:21.288794 34819 sgd_solver.cpp:112] Iteration 41350, lr = 0.01
I0523 03:36:25.082358 34819 solver.cpp:239] Iteration 41360 (2.58563 iter/s, 3.86753s/10 iters), loss = 8.90552
I0523 03:36:25.082399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90552 (* 1 = 8.90552 loss)
I0523 03:36:25.151026 34819 sgd_solver.cpp:112] Iteration 41360, lr = 0.01
I0523 03:36:30.949862 34819 solver.cpp:239] Iteration 41370 (1.70439 iter/s, 5.86722s/10 iters), loss = 9.63888
I0523 03:36:30.949913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63888 (* 1 = 9.63888 loss)
I0523 03:36:31.004417 34819 sgd_solver.cpp:112] Iteration 41370, lr = 0.01
I0523 03:36:35.840816 34819 solver.cpp:239] Iteration 41380 (2.0447 iter/s, 4.89069s/10 iters), loss = 8.29622
I0523 03:36:35.840857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29622 (* 1 = 8.29622 loss)
I0523 03:36:35.994272 34819 sgd_solver.cpp:112] Iteration 41380, lr = 0.01
I0523 03:36:39.861498 34819 solver.cpp:239] Iteration 41390 (2.48728 iter/s, 4.02046s/10 iters), loss = 8.89985
I0523 03:36:39.861567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89985 (* 1 = 8.89985 loss)
I0523 03:36:40.682912 34819 sgd_solver.cpp:112] Iteration 41390, lr = 0.01
I0523 03:36:47.268941 34819 solver.cpp:239] Iteration 41400 (1.35006 iter/s, 7.40708s/10 iters), loss = 8.25923
I0523 03:36:47.269050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25923 (* 1 = 8.25923 loss)
I0523 03:36:47.784528 34819 sgd_solver.cpp:112] Iteration 41400, lr = 0.01
I0523 03:36:53.783897 34819 solver.cpp:239] Iteration 41410 (1.53502 iter/s, 6.51456s/10 iters), loss = 9.13036
I0523 03:36:53.783949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13036 (* 1 = 9.13036 loss)
I0523 03:36:53.858717 34819 sgd_solver.cpp:112] Iteration 41410, lr = 0.01
I0523 03:36:59.491276 34819 solver.cpp:239] Iteration 41420 (1.75221 iter/s, 5.70709s/10 iters), loss = 8.86567
I0523 03:36:59.491331 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86567 (* 1 = 8.86567 loss)
I0523 03:36:59.556452 34819 sgd_solver.cpp:112] Iteration 41420, lr = 0.01
I0523 03:37:05.062348 34819 solver.cpp:239] Iteration 41430 (1.79508 iter/s, 5.57078s/10 iters), loss = 9.40133
I0523 03:37:05.062399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40133 (* 1 = 9.40133 loss)
I0523 03:37:05.932787 34819 sgd_solver.cpp:112] Iteration 41430, lr = 0.01
I0523 03:37:10.640956 34819 solver.cpp:239] Iteration 41440 (1.79266 iter/s, 5.57831s/10 iters), loss = 9.70966
I0523 03:37:10.640997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.70966 (* 1 = 9.70966 loss)
I0523 03:37:10.703335 34819 sgd_solver.cpp:112] Iteration 41440, lr = 0.01
I0523 03:37:15.087357 34819 solver.cpp:239] Iteration 41450 (2.24913 iter/s, 4.44617s/10 iters), loss = 8.35827
I0523 03:37:15.087399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35827 (* 1 = 8.35827 loss)
I0523 03:37:15.883545 34819 sgd_solver.cpp:112] Iteration 41450, lr = 0.01
I0523 03:37:21.398991 34819 solver.cpp:239] Iteration 41460 (1.58445 iter/s, 6.31133s/10 iters), loss = 8.77563
I0523 03:37:21.399253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77563 (* 1 = 8.77563 loss)
I0523 03:37:21.454008 34819 sgd_solver.cpp:112] Iteration 41460, lr = 0.01
I0523 03:37:26.508014 34819 solver.cpp:239] Iteration 41470 (1.9575 iter/s, 5.10857s/10 iters), loss = 9.35421
I0523 03:37:26.508072 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35421 (* 1 = 9.35421 loss)
I0523 03:37:26.558451 34819 sgd_solver.cpp:112] Iteration 41470, lr = 0.01
I0523 03:37:29.774020 34819 solver.cpp:239] Iteration 41480 (3.06204 iter/s, 3.2658s/10 iters), loss = 8.27514
I0523 03:37:29.774085 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27514 (* 1 = 8.27514 loss)
I0523 03:37:30.549767 34819 sgd_solver.cpp:112] Iteration 41480, lr = 0.01
I0523 03:37:33.837508 34819 solver.cpp:239] Iteration 41490 (2.46109 iter/s, 4.06324s/10 iters), loss = 9.26408
I0523 03:37:33.837563 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26408 (* 1 = 9.26408 loss)
I0523 03:37:33.914638 34819 sgd_solver.cpp:112] Iteration 41490, lr = 0.01
I0523 03:37:38.636582 34819 solver.cpp:239] Iteration 41500 (2.08385 iter/s, 4.79881s/10 iters), loss = 9.18099
I0523 03:37:38.636631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18099 (* 1 = 9.18099 loss)
I0523 03:37:39.500416 34819 sgd_solver.cpp:112] Iteration 41500, lr = 0.01
I0523 03:37:43.664894 34819 solver.cpp:239] Iteration 41510 (1.98885 iter/s, 5.02804s/10 iters), loss = 8.97654
I0523 03:37:43.664952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97654 (* 1 = 8.97654 loss)
I0523 03:37:43.731431 34819 sgd_solver.cpp:112] Iteration 41510, lr = 0.01
I0523 03:37:49.295857 34819 solver.cpp:239] Iteration 41520 (1.77599 iter/s, 5.63066s/10 iters), loss = 8.76744
I0523 03:37:49.295912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76744 (* 1 = 8.76744 loss)
I0523 03:37:49.354964 34819 sgd_solver.cpp:112] Iteration 41520, lr = 0.01
I0523 03:37:52.730278 34819 solver.cpp:239] Iteration 41530 (2.91187 iter/s, 3.43422s/10 iters), loss = 9.24113
I0523 03:37:52.730406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24113 (* 1 = 9.24113 loss)
I0523 03:37:52.789803 34819 sgd_solver.cpp:112] Iteration 41530, lr = 0.01
I0523 03:37:56.604714 34819 solver.cpp:239] Iteration 41540 (2.58122 iter/s, 3.87414s/10 iters), loss = 8.78459
I0523 03:37:56.604759 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78459 (* 1 = 8.78459 loss)
I0523 03:37:57.237370 34819 sgd_solver.cpp:112] Iteration 41540, lr = 0.01
I0523 03:38:02.998211 34819 solver.cpp:239] Iteration 41550 (1.56417 iter/s, 6.39317s/10 iters), loss = 8.17305
I0523 03:38:02.998267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17305 (* 1 = 8.17305 loss)
I0523 03:38:03.052350 34819 sgd_solver.cpp:112] Iteration 41550, lr = 0.01
I0523 03:38:07.134654 34819 solver.cpp:239] Iteration 41560 (2.41768 iter/s, 4.1362s/10 iters), loss = 8.94667
I0523 03:38:07.134721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94667 (* 1 = 8.94667 loss)
I0523 03:38:07.762411 34819 sgd_solver.cpp:112] Iteration 41560, lr = 0.01
I0523 03:38:11.782713 34819 solver.cpp:239] Iteration 41570 (2.15156 iter/s, 4.64779s/10 iters), loss = 9.9271
I0523 03:38:11.782757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.9271 (* 1 = 9.9271 loss)
I0523 03:38:11.848870 34819 sgd_solver.cpp:112] Iteration 41570, lr = 0.01
I0523 03:38:16.784335 34819 solver.cpp:239] Iteration 41580 (1.99946 iter/s, 5.00136s/10 iters), loss = 8.26692
I0523 03:38:16.784377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26692 (* 1 = 8.26692 loss)
I0523 03:38:17.572376 34819 sgd_solver.cpp:112] Iteration 41580, lr = 0.01
I0523 03:38:21.726352 34819 solver.cpp:239] Iteration 41590 (2.02357 iter/s, 4.94175s/10 iters), loss = 9.34581
I0523 03:38:21.726415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34581 (* 1 = 9.34581 loss)
I0523 03:38:22.578480 34819 sgd_solver.cpp:112] Iteration 41590, lr = 0.01
I0523 03:38:29.149773 34819 solver.cpp:239] Iteration 41600 (1.34715 iter/s, 7.42306s/10 iters), loss = 9.39933
I0523 03:38:29.150034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39933 (* 1 = 9.39933 loss)
I0523 03:38:29.673943 34819 sgd_solver.cpp:112] Iteration 41600, lr = 0.01
I0523 03:38:34.572542 34819 solver.cpp:239] Iteration 41610 (1.84423 iter/s, 5.42232s/10 iters), loss = 8.02583
I0523 03:38:34.572585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02583 (* 1 = 8.02583 loss)
I0523 03:38:35.433039 34819 sgd_solver.cpp:112] Iteration 41610, lr = 0.01
I0523 03:38:40.049772 34819 solver.cpp:239] Iteration 41620 (1.82583 iter/s, 5.47695s/10 iters), loss = 8.86407
I0523 03:38:40.049814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86407 (* 1 = 8.86407 loss)
I0523 03:38:40.835629 34819 sgd_solver.cpp:112] Iteration 41620, lr = 0.01
I0523 03:38:45.251698 34819 solver.cpp:239] Iteration 41630 (1.92247 iter/s, 5.20165s/10 iters), loss = 8.57481
I0523 03:38:45.251754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57481 (* 1 = 8.57481 loss)
I0523 03:38:45.322996 34819 sgd_solver.cpp:112] Iteration 41630, lr = 0.01
I0523 03:38:50.172953 34819 solver.cpp:239] Iteration 41640 (2.03211 iter/s, 4.921s/10 iters), loss = 9.39072
I0523 03:38:50.172996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39072 (* 1 = 9.39072 loss)
I0523 03:38:50.239346 34819 sgd_solver.cpp:112] Iteration 41640, lr = 0.01
I0523 03:38:55.645270 34819 solver.cpp:239] Iteration 41650 (1.82747 iter/s, 5.47204s/10 iters), loss = 9.2547
I0523 03:38:55.645313 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2547 (* 1 = 9.2547 loss)
I0523 03:38:55.710423 34819 sgd_solver.cpp:112] Iteration 41650, lr = 0.01
I0523 03:38:57.990883 34819 solver.cpp:239] Iteration 41660 (4.26358 iter/s, 2.34545s/10 iters), loss = 8.80536
I0523 03:38:57.990938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80536 (* 1 = 8.80536 loss)
I0523 03:38:58.061844 34819 sgd_solver.cpp:112] Iteration 41660, lr = 0.01
I0523 03:39:02.483062 34819 solver.cpp:239] Iteration 41670 (2.22621 iter/s, 4.49193s/10 iters), loss = 8.96507
I0523 03:39:02.483199 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96507 (* 1 = 8.96507 loss)
I0523 03:39:02.539908 34819 sgd_solver.cpp:112] Iteration 41670, lr = 0.01
I0523 03:39:08.373273 34819 solver.cpp:239] Iteration 41680 (1.69784 iter/s, 5.88984s/10 iters), loss = 9.14412
I0523 03:39:08.373313 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14412 (* 1 = 9.14412 loss)
I0523 03:39:08.429728 34819 sgd_solver.cpp:112] Iteration 41680, lr = 0.01
I0523 03:39:13.111203 34819 solver.cpp:239] Iteration 41690 (2.11074 iter/s, 4.73768s/10 iters), loss = 8.89844
I0523 03:39:13.111254 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89844 (* 1 = 8.89844 loss)
I0523 03:39:13.914719 34819 sgd_solver.cpp:112] Iteration 41690, lr = 0.01
I0523 03:39:17.383633 34819 solver.cpp:239] Iteration 41700 (2.34072 iter/s, 4.27219s/10 iters), loss = 8.68664
I0523 03:39:17.383684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68664 (* 1 = 8.68664 loss)
I0523 03:39:18.226002 34819 sgd_solver.cpp:112] Iteration 41700, lr = 0.01
I0523 03:39:22.684696 34819 solver.cpp:239] Iteration 41710 (1.88651 iter/s, 5.3008s/10 iters), loss = 9.30719
I0523 03:39:22.684742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30719 (* 1 = 9.30719 loss)
I0523 03:39:23.557919 34819 sgd_solver.cpp:112] Iteration 41710, lr = 0.01
I0523 03:39:28.454735 34819 solver.cpp:239] Iteration 41720 (1.73319 iter/s, 5.76971s/10 iters), loss = 8.53741
I0523 03:39:28.454818 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53741 (* 1 = 8.53741 loss)
I0523 03:39:29.314224 34819 sgd_solver.cpp:112] Iteration 41720, lr = 0.01
I0523 03:39:34.917021 34819 solver.cpp:239] Iteration 41730 (1.54753 iter/s, 6.46193s/10 iters), loss = 9.44833
I0523 03:39:34.917184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44833 (* 1 = 9.44833 loss)
I0523 03:39:34.984422 34819 sgd_solver.cpp:112] Iteration 41730, lr = 0.01
I0523 03:39:39.070580 34819 solver.cpp:239] Iteration 41740 (2.40777 iter/s, 4.15322s/10 iters), loss = 9.11928
I0523 03:39:39.070622 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11928 (* 1 = 9.11928 loss)
I0523 03:39:39.142138 34819 sgd_solver.cpp:112] Iteration 41740, lr = 0.01
I0523 03:39:44.036087 34819 solver.cpp:239] Iteration 41750 (2.01399 iter/s, 4.96526s/10 iters), loss = 8.98306
I0523 03:39:44.036128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98306 (* 1 = 8.98306 loss)
I0523 03:39:44.105948 34819 sgd_solver.cpp:112] Iteration 41750, lr = 0.01
I0523 03:39:51.789482 34819 solver.cpp:239] Iteration 41760 (1.28982 iter/s, 7.75304s/10 iters), loss = 8.59657
I0523 03:39:51.789527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59657 (* 1 = 8.59657 loss)
I0523 03:39:52.519727 34819 sgd_solver.cpp:112] Iteration 41760, lr = 0.01
I0523 03:39:57.878361 34819 solver.cpp:239] Iteration 41770 (1.64242 iter/s, 6.08858s/10 iters), loss = 8.46337
I0523 03:39:57.878413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46337 (* 1 = 8.46337 loss)
I0523 03:39:57.936209 34819 sgd_solver.cpp:112] Iteration 41770, lr = 0.01
I0523 03:40:02.050132 34819 solver.cpp:239] Iteration 41780 (2.3972 iter/s, 4.17154s/10 iters), loss = 8.34814
I0523 03:40:02.050200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34814 (* 1 = 8.34814 loss)
I0523 03:40:02.900231 34819 sgd_solver.cpp:112] Iteration 41780, lr = 0.01
I0523 03:40:07.726487 34819 solver.cpp:239] Iteration 41790 (1.76179 iter/s, 5.67603s/10 iters), loss = 8.76939
I0523 03:40:07.726789 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76939 (* 1 = 8.76939 loss)
I0523 03:40:08.518863 34819 sgd_solver.cpp:112] Iteration 41790, lr = 0.01
I0523 03:40:10.698169 34819 solver.cpp:239] Iteration 41800 (3.36557 iter/s, 2.97127s/10 iters), loss = 8.45881
I0523 03:40:10.698215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45881 (* 1 = 8.45881 loss)
I0523 03:40:11.335223 34819 sgd_solver.cpp:112] Iteration 41800, lr = 0.01
I0523 03:40:14.440506 34819 solver.cpp:239] Iteration 41810 (2.67229 iter/s, 3.74211s/10 iters), loss = 8.76967
I0523 03:40:14.440562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76967 (* 1 = 8.76967 loss)
I0523 03:40:14.509227 34819 sgd_solver.cpp:112] Iteration 41810, lr = 0.01
I0523 03:40:19.606045 34819 solver.cpp:239] Iteration 41820 (1.93601 iter/s, 5.16527s/10 iters), loss = 8.46295
I0523 03:40:19.606087 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46295 (* 1 = 8.46295 loss)
I0523 03:40:19.670984 34819 sgd_solver.cpp:112] Iteration 41820, lr = 0.01
I0523 03:40:22.842824 34819 solver.cpp:239] Iteration 41830 (3.08967 iter/s, 3.23659s/10 iters), loss = 8.74835
I0523 03:40:22.842876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74835 (* 1 = 8.74835 loss)
I0523 03:40:22.916821 34819 sgd_solver.cpp:112] Iteration 41830, lr = 0.01
I0523 03:40:27.600615 34819 solver.cpp:239] Iteration 41840 (2.10193 iter/s, 4.75754s/10 iters), loss = 9.21982
I0523 03:40:27.600658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21982 (* 1 = 9.21982 loss)
I0523 03:40:27.667716 34819 sgd_solver.cpp:112] Iteration 41840, lr = 0.01
I0523 03:40:34.265640 34819 solver.cpp:239] Iteration 41850 (1.50044 iter/s, 6.66469s/10 iters), loss = 8.78918
I0523 03:40:34.265698 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78918 (* 1 = 8.78918 loss)
I0523 03:40:35.066479 34819 sgd_solver.cpp:112] Iteration 41850, lr = 0.01
I0523 03:40:40.388217 34819 solver.cpp:239] Iteration 41860 (1.63339 iter/s, 6.12223s/10 iters), loss = 8.90726
I0523 03:40:40.388473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90726 (* 1 = 8.90726 loss)
I0523 03:40:41.163189 34819 sgd_solver.cpp:112] Iteration 41860, lr = 0.01
I0523 03:40:46.919940 34819 solver.cpp:239] Iteration 41870 (1.53111 iter/s, 6.53122s/10 iters), loss = 8.41407
I0523 03:40:46.919996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41407 (* 1 = 8.41407 loss)
I0523 03:40:47.713063 34819 sgd_solver.cpp:112] Iteration 41870, lr = 0.01
I0523 03:40:51.850219 34819 solver.cpp:239] Iteration 41880 (2.02839 iter/s, 4.93002s/10 iters), loss = 9.37121
I0523 03:40:51.850265 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37121 (* 1 = 9.37121 loss)
I0523 03:40:51.911656 34819 sgd_solver.cpp:112] Iteration 41880, lr = 0.01
I0523 03:40:56.214465 34819 solver.cpp:239] Iteration 41890 (2.29147 iter/s, 4.36402s/10 iters), loss = 8.46254
I0523 03:40:56.214505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46254 (* 1 = 8.46254 loss)
I0523 03:40:56.815158 34819 sgd_solver.cpp:112] Iteration 41890, lr = 0.01
I0523 03:41:03.870147 34819 solver.cpp:239] Iteration 41900 (1.30628 iter/s, 7.65532s/10 iters), loss = 8.76146
I0523 03:41:03.870198 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76146 (* 1 = 8.76146 loss)
I0523 03:41:03.930320 34819 sgd_solver.cpp:112] Iteration 41900, lr = 0.01
I0523 03:41:08.355665 34819 solver.cpp:239] Iteration 41910 (2.22952 iter/s, 4.48528s/10 iters), loss = 8.30803
I0523 03:41:08.355723 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30803 (* 1 = 8.30803 loss)
I0523 03:41:08.415387 34819 sgd_solver.cpp:112] Iteration 41910, lr = 0.01
I0523 03:41:12.618746 34819 solver.cpp:239] Iteration 41920 (2.34587 iter/s, 4.26281s/10 iters), loss = 9.37993
I0523 03:41:12.618943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37993 (* 1 = 9.37993 loss)
I0523 03:41:13.332597 34819 sgd_solver.cpp:112] Iteration 41920, lr = 0.01
I0523 03:41:16.554368 34819 solver.cpp:239] Iteration 41930 (2.54113 iter/s, 3.93526s/10 iters), loss = 9.19934
I0523 03:41:16.554420 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19934 (* 1 = 9.19934 loss)
I0523 03:41:16.631309 34819 sgd_solver.cpp:112] Iteration 41930, lr = 0.01
I0523 03:41:19.469797 34819 solver.cpp:239] Iteration 41940 (3.43025 iter/s, 2.91524s/10 iters), loss = 8.27571
I0523 03:41:19.469857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27571 (* 1 = 8.27571 loss)
I0523 03:41:20.306411 34819 sgd_solver.cpp:112] Iteration 41940, lr = 0.01
I0523 03:41:24.347749 34819 solver.cpp:239] Iteration 41950 (2.05015 iter/s, 4.87769s/10 iters), loss = 8.8713
I0523 03:41:24.347805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8713 (* 1 = 8.8713 loss)
I0523 03:41:24.419281 34819 sgd_solver.cpp:112] Iteration 41950, lr = 0.01
I0523 03:41:29.091017 34819 solver.cpp:239] Iteration 41960 (2.11031 iter/s, 4.73864s/10 iters), loss = 8.26714
I0523 03:41:29.091070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26714 (* 1 = 8.26714 loss)
I0523 03:41:29.926255 34819 sgd_solver.cpp:112] Iteration 41960, lr = 0.01
I0523 03:41:34.788661 34819 solver.cpp:239] Iteration 41970 (1.7552 iter/s, 5.69736s/10 iters), loss = 8.8192
I0523 03:41:34.788702 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8192 (* 1 = 8.8192 loss)
I0523 03:41:35.332504 34819 sgd_solver.cpp:112] Iteration 41970, lr = 0.01
I0523 03:41:38.941721 34819 solver.cpp:239] Iteration 41980 (2.40799 iter/s, 4.15284s/10 iters), loss = 8.83734
I0523 03:41:38.941764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83734 (* 1 = 8.83734 loss)
I0523 03:41:39.759286 34819 sgd_solver.cpp:112] Iteration 41980, lr = 0.01
I0523 03:41:42.297665 34819 solver.cpp:239] Iteration 41990 (2.97995 iter/s, 3.35576s/10 iters), loss = 8.7816
I0523 03:41:42.297716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7816 (* 1 = 8.7816 loss)
I0523 03:41:42.378844 34819 sgd_solver.cpp:112] Iteration 41990, lr = 0.01
I0523 03:41:48.406805 34819 solver.cpp:239] Iteration 42000 (1.63697 iter/s, 6.10884s/10 iters), loss = 10.5251
I0523 03:41:48.406988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.5251 (* 1 = 10.5251 loss)
I0523 03:41:48.467931 34819 sgd_solver.cpp:112] Iteration 42000, lr = 0.01
I0523 03:41:51.108809 34819 solver.cpp:239] Iteration 42010 (3.70137 iter/s, 2.7017s/10 iters), loss = 8.91952
I0523 03:41:51.108858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91952 (* 1 = 8.91952 loss)
I0523 03:41:51.795132 34819 sgd_solver.cpp:112] Iteration 42010, lr = 0.01
I0523 03:41:55.442273 34819 solver.cpp:239] Iteration 42020 (2.30775 iter/s, 4.33323s/10 iters), loss = 9.25353
I0523 03:41:55.442327 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25353 (* 1 = 9.25353 loss)
I0523 03:41:55.519676 34819 sgd_solver.cpp:112] Iteration 42020, lr = 0.01
I0523 03:41:59.619693 34819 solver.cpp:239] Iteration 42030 (2.39397 iter/s, 4.17717s/10 iters), loss = 7.80642
I0523 03:41:59.619751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80642 (* 1 = 7.80642 loss)
I0523 03:41:59.683495 34819 sgd_solver.cpp:112] Iteration 42030, lr = 0.01
I0523 03:42:02.257540 34819 solver.cpp:239] Iteration 42040 (3.79122 iter/s, 2.63768s/10 iters), loss = 9.84791
I0523 03:42:02.257586 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84791 (* 1 = 9.84791 loss)
I0523 03:42:03.053459 34819 sgd_solver.cpp:112] Iteration 42040, lr = 0.01
I0523 03:42:08.168576 34819 solver.cpp:239] Iteration 42050 (1.69183 iter/s, 5.91075s/10 iters), loss = 8.4112
I0523 03:42:08.168632 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4112 (* 1 = 8.4112 loss)
I0523 03:42:08.891958 34819 sgd_solver.cpp:112] Iteration 42050, lr = 0.01
I0523 03:42:14.650193 34819 solver.cpp:239] Iteration 42060 (1.5429 iter/s, 6.48129s/10 iters), loss = 8.29921
I0523 03:42:14.650234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29921 (* 1 = 8.29921 loss)
I0523 03:42:14.722597 34819 sgd_solver.cpp:112] Iteration 42060, lr = 0.01
I0523 03:42:18.450959 34819 solver.cpp:239] Iteration 42070 (2.63119 iter/s, 3.80056s/10 iters), loss = 8.3357
I0523 03:42:18.451056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3357 (* 1 = 8.3357 loss)
I0523 03:42:18.526088 34819 sgd_solver.cpp:112] Iteration 42070, lr = 0.01
I0523 03:42:22.580919 34819 solver.cpp:239] Iteration 42080 (2.42149 iter/s, 4.12969s/10 iters), loss = 8.27697
I0523 03:42:22.580970 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27697 (* 1 = 8.27697 loss)
I0523 03:42:22.662021 34819 sgd_solver.cpp:112] Iteration 42080, lr = 0.01
I0523 03:42:27.622226 34819 solver.cpp:239] Iteration 42090 (1.98372 iter/s, 5.04105s/10 iters), loss = 8.05495
I0523 03:42:27.622275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05495 (* 1 = 8.05495 loss)
I0523 03:42:27.678102 34819 sgd_solver.cpp:112] Iteration 42090, lr = 0.01
I0523 03:42:31.515633 34819 solver.cpp:239] Iteration 42100 (2.56859 iter/s, 3.89318s/10 iters), loss = 8.47338
I0523 03:42:31.515686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47338 (* 1 = 8.47338 loss)
I0523 03:42:32.275418 34819 sgd_solver.cpp:112] Iteration 42100, lr = 0.01
I0523 03:42:36.455827 34819 solver.cpp:239] Iteration 42110 (2.02432 iter/s, 4.93993s/10 iters), loss = 9.32834
I0523 03:42:36.455871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32834 (* 1 = 9.32834 loss)
I0523 03:42:36.518252 34819 sgd_solver.cpp:112] Iteration 42110, lr = 0.01
I0523 03:42:41.524636 34819 solver.cpp:239] Iteration 42120 (1.97296 iter/s, 5.06854s/10 iters), loss = 9.19132
I0523 03:42:41.524688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19132 (* 1 = 9.19132 loss)
I0523 03:42:41.602433 34819 sgd_solver.cpp:112] Iteration 42120, lr = 0.01
I0523 03:42:45.505914 34819 solver.cpp:239] Iteration 42130 (2.51189 iter/s, 3.98106s/10 iters), loss = 7.44543
I0523 03:42:45.505959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44543 (* 1 = 7.44543 loss)
I0523 03:42:46.355224 34819 sgd_solver.cpp:112] Iteration 42130, lr = 0.01
I0523 03:42:49.668932 34819 solver.cpp:239] Iteration 42140 (2.40224 iter/s, 4.16278s/10 iters), loss = 9.1321
I0523 03:42:49.669178 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1321 (* 1 = 9.1321 loss)
I0523 03:42:49.742039 34819 sgd_solver.cpp:112] Iteration 42140, lr = 0.01
I0523 03:42:53.818997 34819 solver.cpp:239] Iteration 42150 (2.40985 iter/s, 4.14963s/10 iters), loss = 8.39387
I0523 03:42:53.819056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39387 (* 1 = 8.39387 loss)
I0523 03:42:54.476655 34819 sgd_solver.cpp:112] Iteration 42150, lr = 0.01
I0523 03:42:59.042091 34819 solver.cpp:239] Iteration 42160 (1.91467 iter/s, 5.22283s/10 iters), loss = 9.133
I0523 03:42:59.042136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.133 (* 1 = 9.133 loss)
I0523 03:42:59.102968 34819 sgd_solver.cpp:112] Iteration 42160, lr = 0.01
I0523 03:43:03.625341 34819 solver.cpp:239] Iteration 42170 (2.18198 iter/s, 4.58299s/10 iters), loss = 8.07737
I0523 03:43:03.625411 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07737 (* 1 = 8.07737 loss)
I0523 03:43:04.482350 34819 sgd_solver.cpp:112] Iteration 42170, lr = 0.01
I0523 03:43:08.987922 34819 solver.cpp:239] Iteration 42180 (1.86488 iter/s, 5.36228s/10 iters), loss = 9.1981
I0523 03:43:08.987973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1981 (* 1 = 9.1981 loss)
I0523 03:43:09.050990 34819 sgd_solver.cpp:112] Iteration 42180, lr = 0.01
I0523 03:43:12.420020 34819 solver.cpp:239] Iteration 42190 (2.91384 iter/s, 3.4319s/10 iters), loss = 8.71846
I0523 03:43:12.420083 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71846 (* 1 = 8.71846 loss)
I0523 03:43:13.178701 34819 sgd_solver.cpp:112] Iteration 42190, lr = 0.01
I0523 03:43:17.290637 34819 solver.cpp:239] Iteration 42200 (2.05324 iter/s, 4.87035s/10 iters), loss = 7.63674
I0523 03:43:17.290727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63674 (* 1 = 7.63674 loss)
I0523 03:43:17.360442 34819 sgd_solver.cpp:112] Iteration 42200, lr = 0.01
I0523 03:43:21.887542 34819 solver.cpp:239] Iteration 42210 (2.1755 iter/s, 4.59665s/10 iters), loss = 8.26401
I0523 03:43:21.887761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26401 (* 1 = 8.26401 loss)
I0523 03:43:21.970247 34819 sgd_solver.cpp:112] Iteration 42210, lr = 0.01
I0523 03:43:25.126447 34819 solver.cpp:239] Iteration 42220 (3.08778 iter/s, 3.23857s/10 iters), loss = 9.26972
I0523 03:43:25.126502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26972 (* 1 = 9.26972 loss)
I0523 03:43:25.192739 34819 sgd_solver.cpp:112] Iteration 42220, lr = 0.01
I0523 03:43:28.622243 34819 solver.cpp:239] Iteration 42230 (2.86075 iter/s, 3.49559s/10 iters), loss = 9.42747
I0523 03:43:28.622295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42747 (* 1 = 9.42747 loss)
I0523 03:43:28.685618 34819 sgd_solver.cpp:112] Iteration 42230, lr = 0.01
I0523 03:43:31.905704 34819 solver.cpp:239] Iteration 42240 (3.04576 iter/s, 3.28325s/10 iters), loss = 8.36292
I0523 03:43:31.905764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36292 (* 1 = 8.36292 loss)
I0523 03:43:32.774869 34819 sgd_solver.cpp:112] Iteration 42240, lr = 0.01
I0523 03:43:36.327795 34819 solver.cpp:239] Iteration 42250 (2.2615 iter/s, 4.42183s/10 iters), loss = 8.16899
I0523 03:43:36.327852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16899 (* 1 = 8.16899 loss)
I0523 03:43:37.060736 34819 sgd_solver.cpp:112] Iteration 42250, lr = 0.01
I0523 03:43:40.375452 34819 solver.cpp:239] Iteration 42260 (2.4707 iter/s, 4.04743s/10 iters), loss = 8.95488
I0523 03:43:40.375504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95488 (* 1 = 8.95488 loss)
I0523 03:43:40.448179 34819 sgd_solver.cpp:112] Iteration 42260, lr = 0.01
I0523 03:43:46.742918 34819 solver.cpp:239] Iteration 42270 (1.57056 iter/s, 6.36715s/10 iters), loss = 8.92203
I0523 03:43:46.742985 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92203 (* 1 = 8.92203 loss)
I0523 03:43:47.518946 34819 sgd_solver.cpp:112] Iteration 42270, lr = 0.01
I0523 03:43:53.557165 34819 solver.cpp:239] Iteration 42280 (1.46759 iter/s, 6.8139s/10 iters), loss = 8.57879
I0523 03:43:53.557353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57879 (* 1 = 8.57879 loss)
I0523 03:43:53.629158 34819 sgd_solver.cpp:112] Iteration 42280, lr = 0.01
I0523 03:43:56.731247 34819 solver.cpp:239] Iteration 42290 (3.15083 iter/s, 3.17377s/10 iters), loss = 8.49641
I0523 03:43:56.731288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49641 (* 1 = 8.49641 loss)
I0523 03:43:56.808651 34819 sgd_solver.cpp:112] Iteration 42290, lr = 0.01
I0523 03:44:02.465979 34819 solver.cpp:239] Iteration 42300 (1.74385 iter/s, 5.73445s/10 iters), loss = 9.14542
I0523 03:44:02.466020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14542 (* 1 = 9.14542 loss)
I0523 03:44:02.534716 34819 sgd_solver.cpp:112] Iteration 42300, lr = 0.01
I0523 03:44:06.582177 34819 solver.cpp:239] Iteration 42310 (2.42956 iter/s, 4.11597s/10 iters), loss = 8.75693
I0523 03:44:06.582218 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75693 (* 1 = 8.75693 loss)
I0523 03:44:06.867041 34819 sgd_solver.cpp:112] Iteration 42310, lr = 0.01
I0523 03:44:11.474001 34819 solver.cpp:239] Iteration 42320 (2.04433 iter/s, 4.89157s/10 iters), loss = 8.47518
I0523 03:44:11.474043 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47518 (* 1 = 8.47518 loss)
I0523 03:44:11.545109 34819 sgd_solver.cpp:112] Iteration 42320, lr = 0.01
I0523 03:44:17.759341 34819 solver.cpp:239] Iteration 42330 (1.59108 iter/s, 6.28504s/10 iters), loss = 9.57319
I0523 03:44:17.759382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57319 (* 1 = 9.57319 loss)
I0523 03:44:17.832264 34819 sgd_solver.cpp:112] Iteration 42330, lr = 0.01
I0523 03:44:23.166707 34819 solver.cpp:239] Iteration 42340 (1.84943 iter/s, 5.40708s/10 iters), loss = 8.78562
I0523 03:44:23.166749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78562 (* 1 = 8.78562 loss)
I0523 03:44:23.234120 34819 sgd_solver.cpp:112] Iteration 42340, lr = 0.01
I0523 03:44:27.346278 34819 solver.cpp:239] Iteration 42350 (2.39272 iter/s, 4.17935s/10 iters), loss = 7.96798
I0523 03:44:27.346464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96798 (* 1 = 7.96798 loss)
I0523 03:44:28.018360 34819 sgd_solver.cpp:112] Iteration 42350, lr = 0.01
I0523 03:44:31.361462 34819 solver.cpp:239] Iteration 42360 (2.49075 iter/s, 4.01486s/10 iters), loss = 8.20509
I0523 03:44:31.361513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20509 (* 1 = 8.20509 loss)
I0523 03:44:31.430203 34819 sgd_solver.cpp:112] Iteration 42360, lr = 0.01
I0523 03:44:36.078999 34819 solver.cpp:239] Iteration 42370 (2.11987 iter/s, 4.71727s/10 iters), loss = 10.1304
I0523 03:44:36.079051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1304 (* 1 = 10.1304 loss)
I0523 03:44:36.142001 34819 sgd_solver.cpp:112] Iteration 42370, lr = 0.01
I0523 03:44:41.890192 34819 solver.cpp:239] Iteration 42380 (1.7209 iter/s, 5.8109s/10 iters), loss = 9.58221
I0523 03:44:41.890249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58221 (* 1 = 9.58221 loss)
I0523 03:44:42.630877 34819 sgd_solver.cpp:112] Iteration 42380, lr = 0.01
I0523 03:44:46.550765 34819 solver.cpp:239] Iteration 42390 (2.14579 iter/s, 4.6603s/10 iters), loss = 8.52303
I0523 03:44:46.550818 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52303 (* 1 = 8.52303 loss)
I0523 03:44:47.388190 34819 sgd_solver.cpp:112] Iteration 42390, lr = 0.01
I0523 03:44:50.768584 34819 solver.cpp:239] Iteration 42400 (2.37102 iter/s, 4.21759s/10 iters), loss = 10.1542
I0523 03:44:50.768640 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1542 (* 1 = 10.1542 loss)
I0523 03:44:50.826301 34819 sgd_solver.cpp:112] Iteration 42400, lr = 0.01
I0523 03:44:54.542060 34819 solver.cpp:239] Iteration 42410 (2.65023 iter/s, 3.77326s/10 iters), loss = 7.97281
I0523 03:44:54.542104 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97281 (* 1 = 7.97281 loss)
I0523 03:44:54.593197 34819 sgd_solver.cpp:112] Iteration 42410, lr = 0.01
I0523 03:44:55.900882 34819 solver.cpp:239] Iteration 42420 (7.36005 iter/s, 1.35869s/10 iters), loss = 8.78527
I0523 03:44:55.900956 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78527 (* 1 = 8.78527 loss)
I0523 03:44:56.025784 34819 sgd_solver.cpp:112] Iteration 42420, lr = 0.01
I0523 03:44:59.201239 34819 solver.cpp:239] Iteration 42430 (3.03017 iter/s, 3.30014s/10 iters), loss = 9.32071
I0523 03:44:59.201385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32071 (* 1 = 9.32071 loss)
I0523 03:44:59.955950 34819 sgd_solver.cpp:112] Iteration 42430, lr = 0.01
I0523 03:45:04.686488 34819 solver.cpp:239] Iteration 42440 (1.8232 iter/s, 5.48486s/10 iters), loss = 8.58556
I0523 03:45:04.686547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58556 (* 1 = 8.58556 loss)
I0523 03:45:05.528581 34819 sgd_solver.cpp:112] Iteration 42440, lr = 0.01
I0523 03:45:10.255023 34819 solver.cpp:239] Iteration 42450 (1.7959 iter/s, 5.56823s/10 iters), loss = 9.39601
I0523 03:45:10.255075 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39601 (* 1 = 9.39601 loss)
I0523 03:45:11.071164 34819 sgd_solver.cpp:112] Iteration 42450, lr = 0.01
I0523 03:45:15.040678 34819 solver.cpp:239] Iteration 42460 (2.08969 iter/s, 4.7854s/10 iters), loss = 8.61603
I0523 03:45:15.040720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61603 (* 1 = 8.61603 loss)
I0523 03:45:15.117703 34819 sgd_solver.cpp:112] Iteration 42460, lr = 0.01
I0523 03:45:19.594712 34819 solver.cpp:239] Iteration 42470 (2.19598 iter/s, 4.55378s/10 iters), loss = 8.97015
I0523 03:45:19.594760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97015 (* 1 = 8.97015 loss)
I0523 03:45:19.662509 34819 sgd_solver.cpp:112] Iteration 42470, lr = 0.01
I0523 03:45:24.617213 34819 solver.cpp:239] Iteration 42480 (1.99115 iter/s, 5.02223s/10 iters), loss = 8.94439
I0523 03:45:24.617259 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94439 (* 1 = 8.94439 loss)
I0523 03:45:25.438673 34819 sgd_solver.cpp:112] Iteration 42480, lr = 0.01
I0523 03:45:29.866839 34819 solver.cpp:239] Iteration 42490 (1.905 iter/s, 5.24936s/10 iters), loss = 8.48144
I0523 03:45:29.866963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48144 (* 1 = 8.48144 loss)
I0523 03:45:29.927850 34819 sgd_solver.cpp:112] Iteration 42490, lr = 0.01
I0523 03:45:34.725524 34819 solver.cpp:239] Iteration 42500 (2.05832 iter/s, 4.85834s/10 iters), loss = 9.09048
I0523 03:45:34.725577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09048 (* 1 = 9.09048 loss)
I0523 03:45:34.788255 34819 sgd_solver.cpp:112] Iteration 42500, lr = 0.01
I0523 03:45:40.324362 34819 solver.cpp:239] Iteration 42510 (1.78618 iter/s, 5.59855s/10 iters), loss = 9.42633
I0523 03:45:40.324434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42633 (* 1 = 9.42633 loss)
I0523 03:45:40.391687 34819 sgd_solver.cpp:112] Iteration 42510, lr = 0.01
I0523 03:45:44.725842 34819 solver.cpp:239] Iteration 42520 (2.2721 iter/s, 4.40122s/10 iters), loss = 7.96377
I0523 03:45:44.725886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96377 (* 1 = 7.96377 loss)
I0523 03:45:44.788910 34819 sgd_solver.cpp:112] Iteration 42520, lr = 0.01
I0523 03:45:48.929174 34819 solver.cpp:239] Iteration 42530 (2.37919 iter/s, 4.2031s/10 iters), loss = 8.42456
I0523 03:45:48.929215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42456 (* 1 = 8.42456 loss)
I0523 03:45:48.989841 34819 sgd_solver.cpp:112] Iteration 42530, lr = 0.01
I0523 03:45:54.043738 34819 solver.cpp:239] Iteration 42540 (1.9553 iter/s, 5.11431s/10 iters), loss = 8.27596
I0523 03:45:54.043783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27596 (* 1 = 8.27596 loss)
I0523 03:45:54.669574 34819 sgd_solver.cpp:112] Iteration 42540, lr = 0.01
I0523 03:45:59.487769 34819 solver.cpp:239] Iteration 42550 (1.83697 iter/s, 5.44376s/10 iters), loss = 9.02227
I0523 03:45:59.487823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02227 (* 1 = 9.02227 loss)
I0523 03:45:59.552253 34819 sgd_solver.cpp:112] Iteration 42550, lr = 0.01
I0523 03:46:04.471714 34819 solver.cpp:239] Iteration 42560 (2.00655 iter/s, 4.98367s/10 iters), loss = 8.41729
I0523 03:46:04.471889 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41729 (* 1 = 8.41729 loss)
I0523 03:46:04.545471 34819 sgd_solver.cpp:112] Iteration 42560, lr = 0.01
I0523 03:46:09.727326 34819 solver.cpp:239] Iteration 42570 (1.90287 iter/s, 5.25523s/10 iters), loss = 8.74093
I0523 03:46:09.727368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74093 (* 1 = 8.74093 loss)
I0523 03:46:10.496798 34819 sgd_solver.cpp:112] Iteration 42570, lr = 0.01
I0523 03:46:16.267887 34819 solver.cpp:239] Iteration 42580 (1.52899 iter/s, 6.54025s/10 iters), loss = 8.69352
I0523 03:46:16.267928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69352 (* 1 = 8.69352 loss)
I0523 03:46:16.343607 34819 sgd_solver.cpp:112] Iteration 42580, lr = 0.01
I0523 03:46:19.416244 34819 solver.cpp:239] Iteration 42590 (3.17645 iter/s, 3.14817s/10 iters), loss = 8.58307
I0523 03:46:19.416296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58307 (* 1 = 8.58307 loss)
I0523 03:46:19.499131 34819 sgd_solver.cpp:112] Iteration 42590, lr = 0.01
I0523 03:46:24.070688 34819 solver.cpp:239] Iteration 42600 (2.1486 iter/s, 4.65419s/10 iters), loss = 9.41829
I0523 03:46:24.070749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41829 (* 1 = 9.41829 loss)
I0523 03:46:24.135591 34819 sgd_solver.cpp:112] Iteration 42600, lr = 0.01
I0523 03:46:27.455853 34819 solver.cpp:239] Iteration 42610 (2.95425 iter/s, 3.38496s/10 iters), loss = 9.28774
I0523 03:46:27.455895 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28774 (* 1 = 9.28774 loss)
I0523 03:46:27.537081 34819 sgd_solver.cpp:112] Iteration 42610, lr = 0.01
I0523 03:46:31.588321 34819 solver.cpp:239] Iteration 42620 (2.41999 iter/s, 4.13225s/10 iters), loss = 9.16193
I0523 03:46:31.588363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16193 (* 1 = 9.16193 loss)
I0523 03:46:31.646162 34819 sgd_solver.cpp:112] Iteration 42620, lr = 0.01
I0523 03:46:36.272444 34819 solver.cpp:239] Iteration 42630 (2.13666 iter/s, 4.68021s/10 iters), loss = 8.27
I0523 03:46:36.272680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27 (* 1 = 8.27 loss)
I0523 03:46:37.145059 34819 sgd_solver.cpp:112] Iteration 42630, lr = 0.01
I0523 03:46:42.241912 34819 solver.cpp:239] Iteration 42640 (1.67533 iter/s, 5.96899s/10 iters), loss = 9.21714
I0523 03:46:42.241964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21714 (* 1 = 9.21714 loss)
I0523 03:46:43.060649 34819 sgd_solver.cpp:112] Iteration 42640, lr = 0.01
I0523 03:46:47.117219 34819 solver.cpp:239] Iteration 42650 (2.05126 iter/s, 4.87505s/10 iters), loss = 8.97384
I0523 03:46:47.117270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97384 (* 1 = 8.97384 loss)
I0523 03:46:47.896651 34819 sgd_solver.cpp:112] Iteration 42650, lr = 0.01
I0523 03:46:51.511623 34819 solver.cpp:239] Iteration 42660 (2.27574 iter/s, 4.39417s/10 iters), loss = 8.93558
I0523 03:46:51.511673 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93558 (* 1 = 8.93558 loss)
I0523 03:46:51.572090 34819 sgd_solver.cpp:112] Iteration 42660, lr = 0.01
I0523 03:46:56.303764 34819 solver.cpp:239] Iteration 42670 (2.08686 iter/s, 4.79188s/10 iters), loss = 8.31382
I0523 03:46:56.303812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31382 (* 1 = 8.31382 loss)
I0523 03:46:56.368698 34819 sgd_solver.cpp:112] Iteration 42670, lr = 0.01
I0523 03:47:01.199637 34819 solver.cpp:239] Iteration 42680 (2.04264 iter/s, 4.89563s/10 iters), loss = 9.09953
I0523 03:47:01.199679 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09953 (* 1 = 9.09953 loss)
I0523 03:47:02.013005 34819 sgd_solver.cpp:112] Iteration 42680, lr = 0.01
I0523 03:47:06.221767 34819 solver.cpp:239] Iteration 42690 (1.99129 iter/s, 5.02187s/10 iters), loss = 7.8322
I0523 03:47:06.221808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8322 (* 1 = 7.8322 loss)
I0523 03:47:06.287189 34819 sgd_solver.cpp:112] Iteration 42690, lr = 0.01
I0523 03:47:11.624044 34819 solver.cpp:239] Iteration 42700 (1.85117 iter/s, 5.402s/10 iters), loss = 7.75035
I0523 03:47:11.624094 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75035 (* 1 = 7.75035 loss)
I0523 03:47:11.700630 34819 sgd_solver.cpp:112] Iteration 42700, lr = 0.01
I0523 03:47:17.287382 34819 solver.cpp:239] Iteration 42710 (1.76583 iter/s, 5.66306s/10 iters), loss = 8.85894
I0523 03:47:17.287425 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85894 (* 1 = 8.85894 loss)
I0523 03:47:17.352486 34819 sgd_solver.cpp:112] Iteration 42710, lr = 0.01
I0523 03:47:21.420853 34819 solver.cpp:239] Iteration 42720 (2.41941 iter/s, 4.13324s/10 iters), loss = 8.53802
I0523 03:47:21.420915 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53802 (* 1 = 8.53802 loss)
I0523 03:47:22.219643 34819 sgd_solver.cpp:112] Iteration 42720, lr = 0.01
I0523 03:47:26.339126 34819 solver.cpp:239] Iteration 42730 (2.03335 iter/s, 4.91799s/10 iters), loss = 7.83163
I0523 03:47:26.339174 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83163 (* 1 = 7.83163 loss)
I0523 03:47:26.410589 34819 sgd_solver.cpp:112] Iteration 42730, lr = 0.01
I0523 03:47:29.025233 34819 solver.cpp:239] Iteration 42740 (3.72309 iter/s, 2.68594s/10 iters), loss = 9.0715
I0523 03:47:29.025275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0715 (* 1 = 9.0715 loss)
I0523 03:47:29.084906 34819 sgd_solver.cpp:112] Iteration 42740, lr = 0.01
I0523 03:47:34.207541 34819 solver.cpp:239] Iteration 42750 (1.92974 iter/s, 5.18205s/10 iters), loss = 8.38686
I0523 03:47:34.207592 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38686 (* 1 = 8.38686 loss)
I0523 03:47:34.276217 34819 sgd_solver.cpp:112] Iteration 42750, lr = 0.01
I0523 03:47:38.269078 34819 solver.cpp:239] Iteration 42760 (2.46226 iter/s, 4.06131s/10 iters), loss = 10.1177
I0523 03:47:38.269229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.1177 (* 1 = 10.1177 loss)
I0523 03:47:39.146054 34819 sgd_solver.cpp:112] Iteration 42760, lr = 0.01
I0523 03:47:44.889849 34819 solver.cpp:239] Iteration 42770 (1.5105 iter/s, 6.62034s/10 iters), loss = 8.2694
I0523 03:47:44.889895 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2694 (* 1 = 8.2694 loss)
I0523 03:47:45.657814 34819 sgd_solver.cpp:112] Iteration 42770, lr = 0.01
I0523 03:47:48.231237 34819 solver.cpp:239] Iteration 42780 (2.99294 iter/s, 3.34119s/10 iters), loss = 9.778
I0523 03:47:48.231288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.778 (* 1 = 9.778 loss)
I0523 03:47:48.312012 34819 sgd_solver.cpp:112] Iteration 42780, lr = 0.01
I0523 03:47:51.831138 34819 solver.cpp:239] Iteration 42790 (2.77802 iter/s, 3.59969s/10 iters), loss = 9.30638
I0523 03:47:51.831193 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30638 (* 1 = 9.30638 loss)
I0523 03:47:52.564668 34819 sgd_solver.cpp:112] Iteration 42790, lr = 0.01
I0523 03:47:57.552695 34819 solver.cpp:239] Iteration 42800 (1.74787 iter/s, 5.72127s/10 iters), loss = 8.43327
I0523 03:47:57.552736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43327 (* 1 = 8.43327 loss)
I0523 03:47:57.611435 34819 sgd_solver.cpp:112] Iteration 42800, lr = 0.01
I0523 03:48:03.272635 34819 solver.cpp:239] Iteration 42810 (1.74835 iter/s, 5.71967s/10 iters), loss = 9.14759
I0523 03:48:03.272677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14759 (* 1 = 9.14759 loss)
I0523 03:48:03.332954 34819 sgd_solver.cpp:112] Iteration 42810, lr = 0.01
I0523 03:48:08.169670 34819 solver.cpp:239] Iteration 42820 (2.04216 iter/s, 4.89678s/10 iters), loss = 9.00818
I0523 03:48:08.169713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00818 (* 1 = 9.00818 loss)
I0523 03:48:09.019767 34819 sgd_solver.cpp:112] Iteration 42820, lr = 0.01
I0523 03:48:13.864887 34819 solver.cpp:239] Iteration 42830 (1.75595 iter/s, 5.69493s/10 iters), loss = 9.27655
I0523 03:48:13.864938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27655 (* 1 = 9.27655 loss)
I0523 03:48:13.925329 34819 sgd_solver.cpp:112] Iteration 42830, lr = 0.01
I0523 03:48:20.421355 34819 solver.cpp:239] Iteration 42840 (1.52529 iter/s, 6.55613s/10 iters), loss = 8.86516
I0523 03:48:20.421422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86516 (* 1 = 8.86516 loss)
I0523 03:48:20.480705 34819 sgd_solver.cpp:112] Iteration 42840, lr = 0.01
I0523 03:48:23.994004 34819 solver.cpp:239] Iteration 42850 (2.79922 iter/s, 3.57242s/10 iters), loss = 9.13292
I0523 03:48:23.994055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13292 (* 1 = 9.13292 loss)
I0523 03:48:24.069038 34819 sgd_solver.cpp:112] Iteration 42850, lr = 0.01
I0523 03:48:27.319973 34819 solver.cpp:239] Iteration 42860 (3.00683 iter/s, 3.32577s/10 iters), loss = 8.30023
I0523 03:48:27.320014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30023 (* 1 = 8.30023 loss)
I0523 03:48:27.393239 34819 sgd_solver.cpp:112] Iteration 42860, lr = 0.01
I0523 03:48:31.269053 34819 solver.cpp:239] Iteration 42870 (2.53238 iter/s, 3.94886s/10 iters), loss = 8.6827
I0523 03:48:31.269094 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6827 (* 1 = 8.6827 loss)
I0523 03:48:31.957598 34819 sgd_solver.cpp:112] Iteration 42870, lr = 0.01
I0523 03:48:36.978199 34819 solver.cpp:239] Iteration 42880 (1.75166 iter/s, 5.70887s/10 iters), loss = 8.58398
I0523 03:48:36.978250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58398 (* 1 = 8.58398 loss)
I0523 03:48:37.803153 34819 sgd_solver.cpp:112] Iteration 42880, lr = 0.01
I0523 03:48:40.312721 34819 solver.cpp:239] Iteration 42890 (2.99911 iter/s, 3.33433s/10 iters), loss = 9.3181
I0523 03:48:40.312899 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3181 (* 1 = 9.3181 loss)
I0523 03:48:40.371804 34819 sgd_solver.cpp:112] Iteration 42890, lr = 0.01
I0523 03:48:42.993340 34819 solver.cpp:239] Iteration 42900 (3.73087 iter/s, 2.68034s/10 iters), loss = 8.43238
I0523 03:48:42.993387 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43238 (* 1 = 8.43238 loss)
I0523 03:48:43.835983 34819 sgd_solver.cpp:112] Iteration 42900, lr = 0.01
I0523 03:48:47.168929 34819 solver.cpp:239] Iteration 42910 (2.39501 iter/s, 4.17535s/10 iters), loss = 9.01232
I0523 03:48:47.168985 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01232 (* 1 = 9.01232 loss)
I0523 03:48:47.251381 34819 sgd_solver.cpp:112] Iteration 42910, lr = 0.01
I0523 03:48:51.686563 34819 solver.cpp:239] Iteration 42920 (2.21368 iter/s, 4.51737s/10 iters), loss = 8.87285
I0523 03:48:51.686630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87285 (* 1 = 8.87285 loss)
I0523 03:48:52.202888 34819 sgd_solver.cpp:112] Iteration 42920, lr = 0.01
I0523 03:48:57.868738 34819 solver.cpp:239] Iteration 42930 (1.61764 iter/s, 6.18185s/10 iters), loss = 9.45986
I0523 03:48:57.868805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45986 (* 1 = 9.45986 loss)
I0523 03:48:58.611889 34819 sgd_solver.cpp:112] Iteration 42930, lr = 0.01
I0523 03:49:02.839202 34819 solver.cpp:239] Iteration 42940 (2.012 iter/s, 4.97019s/10 iters), loss = 8.50433
I0523 03:49:02.839253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50433 (* 1 = 8.50433 loss)
I0523 03:49:02.896076 34819 sgd_solver.cpp:112] Iteration 42940, lr = 0.01
I0523 03:49:06.940786 34819 solver.cpp:239] Iteration 42950 (2.43821 iter/s, 4.10136s/10 iters), loss = 7.7509
I0523 03:49:06.940829 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7509 (* 1 = 7.7509 loss)
I0523 03:49:06.987056 34819 sgd_solver.cpp:112] Iteration 42950, lr = 0.01
I0523 03:49:11.335165 34819 solver.cpp:239] Iteration 42960 (2.27575 iter/s, 4.39415s/10 iters), loss = 8.59463
I0523 03:49:11.335310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59463 (* 1 = 8.59463 loss)
I0523 03:49:11.397459 34819 sgd_solver.cpp:112] Iteration 42960, lr = 0.01
I0523 03:49:15.676431 34819 solver.cpp:239] Iteration 42970 (2.30365 iter/s, 4.34093s/10 iters), loss = 9.49931
I0523 03:49:15.676476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49931 (* 1 = 9.49931 loss)
I0523 03:49:15.977175 34819 sgd_solver.cpp:112] Iteration 42970, lr = 0.01
I0523 03:49:20.295325 34819 solver.cpp:239] Iteration 42980 (2.16514 iter/s, 4.61865s/10 iters), loss = 8.88988
I0523 03:49:20.295374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88988 (* 1 = 8.88988 loss)
I0523 03:49:20.366302 34819 sgd_solver.cpp:112] Iteration 42980, lr = 0.01
I0523 03:49:23.916589 34819 solver.cpp:239] Iteration 42990 (2.76163 iter/s, 3.62105s/10 iters), loss = 7.83159
I0523 03:49:23.916632 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83159 (* 1 = 7.83159 loss)
I0523 03:49:23.969122 34819 sgd_solver.cpp:112] Iteration 42990, lr = 0.01
I0523 03:49:29.665987 34819 solver.cpp:239] Iteration 43000 (1.7394 iter/s, 5.7491s/10 iters), loss = 8.70424
I0523 03:49:29.666043 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70424 (* 1 = 8.70424 loss)
I0523 03:49:29.733212 34819 sgd_solver.cpp:112] Iteration 43000, lr = 0.01
I0523 03:49:34.674190 34819 solver.cpp:239] Iteration 43010 (1.99684 iter/s, 5.00792s/10 iters), loss = 7.61829
I0523 03:49:34.674242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61829 (* 1 = 7.61829 loss)
I0523 03:49:34.733080 34819 sgd_solver.cpp:112] Iteration 43010, lr = 0.01
I0523 03:49:37.351272 34819 solver.cpp:239] Iteration 43020 (3.73566 iter/s, 2.67691s/10 iters), loss = 9.4943
I0523 03:49:37.351317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4943 (* 1 = 9.4943 loss)
I0523 03:49:37.412160 34819 sgd_solver.cpp:112] Iteration 43020, lr = 0.01
I0523 03:49:42.529963 34819 solver.cpp:239] Iteration 43030 (1.93109 iter/s, 5.17842s/10 iters), loss = 8.07771
I0523 03:49:42.530094 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07771 (* 1 = 8.07771 loss)
I0523 03:49:43.409212 34819 sgd_solver.cpp:112] Iteration 43030, lr = 0.01
I0523 03:49:48.001118 34819 solver.cpp:239] Iteration 43040 (1.82789 iter/s, 5.47079s/10 iters), loss = 8.18843
I0523 03:49:48.001169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18843 (* 1 = 8.18843 loss)
I0523 03:49:48.843247 34819 sgd_solver.cpp:112] Iteration 43040, lr = 0.01
I0523 03:49:52.908419 34819 solver.cpp:239] Iteration 43050 (2.03789 iter/s, 4.90704s/10 iters), loss = 9.25346
I0523 03:49:52.908485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25346 (* 1 = 9.25346 loss)
I0523 03:49:52.970784 34819 sgd_solver.cpp:112] Iteration 43050, lr = 0.01
I0523 03:49:57.673390 34819 solver.cpp:239] Iteration 43060 (2.09877 iter/s, 4.76469s/10 iters), loss = 9.36582
I0523 03:49:57.673444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36582 (* 1 = 9.36582 loss)
I0523 03:49:58.348387 34819 sgd_solver.cpp:112] Iteration 43060, lr = 0.01
I0523 03:50:03.632369 34819 solver.cpp:239] Iteration 43070 (1.67822 iter/s, 5.95868s/10 iters), loss = 8.90449
I0523 03:50:03.632422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90449 (* 1 = 8.90449 loss)
I0523 03:50:03.702673 34819 sgd_solver.cpp:112] Iteration 43070, lr = 0.01
I0523 03:50:08.231922 34819 solver.cpp:239] Iteration 43080 (2.17424 iter/s, 4.5993s/10 iters), loss = 9.12474
I0523 03:50:08.231962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12474 (* 1 = 9.12474 loss)
I0523 03:50:09.070428 34819 sgd_solver.cpp:112] Iteration 43080, lr = 0.01
I0523 03:50:13.340651 34819 solver.cpp:239] Iteration 43090 (1.95753 iter/s, 5.10847s/10 iters), loss = 9.16509
I0523 03:50:13.340766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16509 (* 1 = 9.16509 loss)
I0523 03:50:13.398500 34819 sgd_solver.cpp:112] Iteration 43090, lr = 0.01
I0523 03:50:19.021952 34819 solver.cpp:239] Iteration 43100 (1.76027 iter/s, 5.68093s/10 iters), loss = 8.39717
I0523 03:50:19.022002 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39717 (* 1 = 8.39717 loss)
I0523 03:50:19.872079 34819 sgd_solver.cpp:112] Iteration 43100, lr = 0.01
I0523 03:50:24.149382 34819 solver.cpp:239] Iteration 43110 (1.9504 iter/s, 5.12715s/10 iters), loss = 8.63259
I0523 03:50:24.149433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63259 (* 1 = 8.63259 loss)
I0523 03:50:24.870645 34819 sgd_solver.cpp:112] Iteration 43110, lr = 0.01
I0523 03:50:28.984959 34819 solver.cpp:239] Iteration 43120 (2.06812 iter/s, 4.83531s/10 iters), loss = 8.75648
I0523 03:50:28.985009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75648 (* 1 = 8.75648 loss)
I0523 03:50:29.058781 34819 sgd_solver.cpp:112] Iteration 43120, lr = 0.01
I0523 03:50:31.586788 34819 solver.cpp:239] Iteration 43130 (3.84371 iter/s, 2.60165s/10 iters), loss = 8.5135
I0523 03:50:31.586840 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5135 (* 1 = 8.5135 loss)
I0523 03:50:31.660856 34819 sgd_solver.cpp:112] Iteration 43130, lr = 0.01
I0523 03:50:36.019615 34819 solver.cpp:239] Iteration 43140 (2.25602 iter/s, 4.43258s/10 iters), loss = 8.74409
I0523 03:50:36.019670 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74409 (* 1 = 8.74409 loss)
I0523 03:50:36.093005 34819 sgd_solver.cpp:112] Iteration 43140, lr = 0.01
I0523 03:50:40.457608 34819 solver.cpp:239] Iteration 43150 (2.2534 iter/s, 4.43775s/10 iters), loss = 8.76381
I0523 03:50:40.457650 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76381 (* 1 = 8.76381 loss)
I0523 03:50:40.516346 34819 sgd_solver.cpp:112] Iteration 43150, lr = 0.01
I0523 03:50:46.115741 34819 solver.cpp:239] Iteration 43160 (1.76746 iter/s, 5.65785s/10 iters), loss = 8.85906
I0523 03:50:46.115957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85906 (* 1 = 8.85906 loss)
I0523 03:50:46.624728 34819 sgd_solver.cpp:112] Iteration 43160, lr = 0.01
I0523 03:50:50.091709 34819 solver.cpp:239] Iteration 43170 (2.51535 iter/s, 3.97559s/10 iters), loss = 8.88987
I0523 03:50:50.091758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88987 (* 1 = 8.88987 loss)
I0523 03:50:50.157694 34819 sgd_solver.cpp:112] Iteration 43170, lr = 0.01
I0523 03:50:55.725361 34819 solver.cpp:239] Iteration 43180 (1.77514 iter/s, 5.63337s/10 iters), loss = 8.64203
I0523 03:50:55.725401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64203 (* 1 = 8.64203 loss)
I0523 03:50:55.782330 34819 sgd_solver.cpp:112] Iteration 43180, lr = 0.01
I0523 03:51:00.771175 34819 solver.cpp:239] Iteration 43190 (1.98194 iter/s, 5.04555s/10 iters), loss = 8.51683
I0523 03:51:00.771221 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51683 (* 1 = 8.51683 loss)
I0523 03:51:01.639894 34819 sgd_solver.cpp:112] Iteration 43190, lr = 0.01
I0523 03:51:06.599211 34819 solver.cpp:239] Iteration 43200 (1.71593 iter/s, 5.82775s/10 iters), loss = 8.44168
I0523 03:51:06.599263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44168 (* 1 = 8.44168 loss)
I0523 03:51:07.464293 34819 sgd_solver.cpp:112] Iteration 43200, lr = 0.01
I0523 03:51:11.120481 34819 solver.cpp:239] Iteration 43210 (2.21189 iter/s, 4.52102s/10 iters), loss = 8.11765
I0523 03:51:11.120520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11765 (* 1 = 8.11765 loss)
I0523 03:51:11.183890 34819 sgd_solver.cpp:112] Iteration 43210, lr = 0.01
I0523 03:51:13.790916 34819 solver.cpp:239] Iteration 43220 (3.74495 iter/s, 2.67027s/10 iters), loss = 7.90213
I0523 03:51:13.790973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90213 (* 1 = 7.90213 loss)
I0523 03:51:13.880174 34819 sgd_solver.cpp:112] Iteration 43220, lr = 0.01
I0523 03:51:18.889109 34819 solver.cpp:239] Iteration 43230 (1.96158 iter/s, 5.09792s/10 iters), loss = 8.9681
I0523 03:51:18.889334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9681 (* 1 = 8.9681 loss)
I0523 03:51:19.709888 34819 sgd_solver.cpp:112] Iteration 43230, lr = 0.01
I0523 03:51:23.758433 34819 solver.cpp:239] Iteration 43240 (2.05384 iter/s, 4.86893s/10 iters), loss = 8.96199
I0523 03:51:23.758474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96199 (* 1 = 8.96199 loss)
I0523 03:51:23.817301 34819 sgd_solver.cpp:112] Iteration 43240, lr = 0.01
I0523 03:51:28.867302 34819 solver.cpp:239] Iteration 43250 (1.95748 iter/s, 5.10861s/10 iters), loss = 9.43795
I0523 03:51:28.867352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43795 (* 1 = 9.43795 loss)
I0523 03:51:28.938583 34819 sgd_solver.cpp:112] Iteration 43250, lr = 0.01
I0523 03:51:31.479478 34819 solver.cpp:239] Iteration 43260 (3.82847 iter/s, 2.61201s/10 iters), loss = 8.89157
I0523 03:51:31.479521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89157 (* 1 = 8.89157 loss)
I0523 03:51:31.553063 34819 sgd_solver.cpp:112] Iteration 43260, lr = 0.01
I0523 03:51:36.609350 34819 solver.cpp:239] Iteration 43270 (1.94946 iter/s, 5.12962s/10 iters), loss = 7.9653
I0523 03:51:36.609396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9653 (* 1 = 7.9653 loss)
I0523 03:51:36.664597 34819 sgd_solver.cpp:112] Iteration 43270, lr = 0.01
I0523 03:51:40.820940 34819 solver.cpp:239] Iteration 43280 (2.37453 iter/s, 4.21136s/10 iters), loss = 8.6547
I0523 03:51:40.820991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6547 (* 1 = 8.6547 loss)
I0523 03:51:41.555012 34819 sgd_solver.cpp:112] Iteration 43280, lr = 0.01
I0523 03:51:45.535374 34819 solver.cpp:239] Iteration 43290 (2.12126 iter/s, 4.71417s/10 iters), loss = 8.19975
I0523 03:51:45.535423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19975 (* 1 = 8.19975 loss)
I0523 03:51:46.373137 34819 sgd_solver.cpp:112] Iteration 43290, lr = 0.01
I0523 03:51:49.648748 34819 solver.cpp:239] Iteration 43300 (2.43123 iter/s, 4.11315s/10 iters), loss = 9.59924
I0523 03:51:49.648983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.59924 (* 1 = 9.59924 loss)
I0523 03:51:49.707453 34819 sgd_solver.cpp:112] Iteration 43300, lr = 0.01
I0523 03:51:53.029808 34819 solver.cpp:239] Iteration 43310 (2.95796 iter/s, 3.38071s/10 iters), loss = 7.83342
I0523 03:51:53.029848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83342 (* 1 = 7.83342 loss)
I0523 03:51:53.126044 34819 sgd_solver.cpp:112] Iteration 43310, lr = 0.01
I0523 03:51:58.109688 34819 solver.cpp:239] Iteration 43320 (1.96865 iter/s, 5.07962s/10 iters), loss = 8.60662
I0523 03:51:58.109730 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60662 (* 1 = 8.60662 loss)
I0523 03:51:58.185700 34819 sgd_solver.cpp:112] Iteration 43320, lr = 0.01
I0523 03:52:02.058643 34819 solver.cpp:239] Iteration 43330 (2.53245 iter/s, 3.94874s/10 iters), loss = 9.04757
I0523 03:52:02.058692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04757 (* 1 = 9.04757 loss)
I0523 03:52:02.874756 34819 sgd_solver.cpp:112] Iteration 43330, lr = 0.01
I0523 03:52:07.960932 34819 solver.cpp:239] Iteration 43340 (1.69434 iter/s, 5.902s/10 iters), loss = 7.97582
I0523 03:52:07.960978 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97582 (* 1 = 7.97582 loss)
I0523 03:52:08.037101 34819 sgd_solver.cpp:112] Iteration 43340, lr = 0.01
I0523 03:52:11.391466 34819 solver.cpp:239] Iteration 43350 (2.91516 iter/s, 3.43034s/10 iters), loss = 9.33854
I0523 03:52:11.391511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33854 (* 1 = 9.33854 loss)
I0523 03:52:11.472616 34819 sgd_solver.cpp:112] Iteration 43350, lr = 0.01
I0523 03:52:14.805387 34819 solver.cpp:239] Iteration 43360 (2.92935 iter/s, 3.41372s/10 iters), loss = 8.04527
I0523 03:52:14.805433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04527 (* 1 = 8.04527 loss)
I0523 03:52:14.877457 34819 sgd_solver.cpp:112] Iteration 43360, lr = 0.01
I0523 03:52:20.580593 34819 solver.cpp:239] Iteration 43370 (1.73162 iter/s, 5.77493s/10 iters), loss = 9.26018
I0523 03:52:20.580734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26018 (* 1 = 9.26018 loss)
I0523 03:52:20.641826 34819 sgd_solver.cpp:112] Iteration 43370, lr = 0.01
I0523 03:52:25.135592 34819 solver.cpp:239] Iteration 43380 (2.19555 iter/s, 4.55466s/10 iters), loss = 8.83266
I0523 03:52:25.135638 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83266 (* 1 = 8.83266 loss)
I0523 03:52:25.905371 34819 sgd_solver.cpp:112] Iteration 43380, lr = 0.01
I0523 03:52:30.635843 34819 solver.cpp:239] Iteration 43390 (1.81819 iter/s, 5.49997s/10 iters), loss = 9.2642
I0523 03:52:30.635887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2642 (* 1 = 9.2642 loss)
I0523 03:52:30.705080 34819 sgd_solver.cpp:112] Iteration 43390, lr = 0.01
I0523 03:52:34.652204 34819 solver.cpp:239] Iteration 43400 (2.49263 iter/s, 4.01182s/10 iters), loss = 9.0536
I0523 03:52:34.652247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0536 (* 1 = 9.0536 loss)
I0523 03:52:34.718425 34819 sgd_solver.cpp:112] Iteration 43400, lr = 0.01
I0523 03:52:39.772011 34819 solver.cpp:239] Iteration 43410 (1.9533 iter/s, 5.11955s/10 iters), loss = 8.39097
I0523 03:52:39.772053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39097 (* 1 = 8.39097 loss)
I0523 03:52:39.839058 34819 sgd_solver.cpp:112] Iteration 43410, lr = 0.01
I0523 03:52:44.109091 34819 solver.cpp:239] Iteration 43420 (2.30582 iter/s, 4.33685s/10 iters), loss = 8.56565
I0523 03:52:44.109145 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56565 (* 1 = 8.56565 loss)
I0523 03:52:44.955536 34819 sgd_solver.cpp:112] Iteration 43420, lr = 0.01
I0523 03:52:49.522543 34819 solver.cpp:239] Iteration 43430 (1.84734 iter/s, 5.41318s/10 iters), loss = 8.97474
I0523 03:52:49.522588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97474 (* 1 = 8.97474 loss)
I0523 03:52:49.578374 34819 sgd_solver.cpp:112] Iteration 43430, lr = 0.01
I0523 03:52:54.331394 34819 solver.cpp:239] Iteration 43440 (2.0796 iter/s, 4.80861s/10 iters), loss = 8.04592
I0523 03:52:54.331606 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04592 (* 1 = 8.04592 loss)
I0523 03:52:54.954294 34819 sgd_solver.cpp:112] Iteration 43440, lr = 0.01
I0523 03:52:59.705893 34819 solver.cpp:239] Iteration 43450 (1.86078 iter/s, 5.37409s/10 iters), loss = 9.44412
I0523 03:52:59.705945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44412 (* 1 = 9.44412 loss)
I0523 03:52:59.801214 34819 sgd_solver.cpp:112] Iteration 43450, lr = 0.01
I0523 03:53:05.072067 34819 solver.cpp:239] Iteration 43460 (1.86362 iter/s, 5.3659s/10 iters), loss = 8.99617
I0523 03:53:05.072108 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99617 (* 1 = 8.99617 loss)
I0523 03:53:05.133652 34819 sgd_solver.cpp:112] Iteration 43460, lr = 0.01
I0523 03:53:09.475317 34819 solver.cpp:239] Iteration 43470 (2.27118 iter/s, 4.40301s/10 iters), loss = 8.76385
I0523 03:53:09.475371 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76385 (* 1 = 8.76385 loss)
I0523 03:53:10.278162 34819 sgd_solver.cpp:112] Iteration 43470, lr = 0.01
I0523 03:53:16.800876 34819 solver.cpp:239] Iteration 43480 (1.36515 iter/s, 7.32519s/10 iters), loss = 8.79551
I0523 03:53:16.800935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79551 (* 1 = 8.79551 loss)
I0523 03:53:17.515884 34819 sgd_solver.cpp:112] Iteration 43480, lr = 0.01
I0523 03:53:22.059367 34819 solver.cpp:239] Iteration 43490 (1.90179 iter/s, 5.25821s/10 iters), loss = 8.76094
I0523 03:53:22.059409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76094 (* 1 = 8.76094 loss)
I0523 03:53:22.119150 34819 sgd_solver.cpp:112] Iteration 43490, lr = 0.01
I0523 03:53:26.892966 34819 solver.cpp:239] Iteration 43500 (2.06896 iter/s, 4.83334s/10 iters), loss = 8.51464
I0523 03:53:26.893213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51464 (* 1 = 8.51464 loss)
I0523 03:53:27.441826 34819 sgd_solver.cpp:112] Iteration 43500, lr = 0.01
I0523 03:53:33.015034 34819 solver.cpp:239] Iteration 43510 (1.63356 iter/s, 6.1216s/10 iters), loss = 8.80826
I0523 03:53:33.015079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80826 (* 1 = 8.80826 loss)
I0523 03:53:33.076836 34819 sgd_solver.cpp:112] Iteration 43510, lr = 0.01
I0523 03:53:38.984145 34819 solver.cpp:239] Iteration 43520 (1.67537 iter/s, 5.96882s/10 iters), loss = 10.0904
I0523 03:53:38.984200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0904 (* 1 = 10.0904 loss)
I0523 03:53:39.053664 34819 sgd_solver.cpp:112] Iteration 43520, lr = 0.01
I0523 03:53:42.420559 34819 solver.cpp:239] Iteration 43530 (2.91018 iter/s, 3.43621s/10 iters), loss = 9.35625
I0523 03:53:42.420605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35625 (* 1 = 9.35625 loss)
I0523 03:53:42.485071 34819 sgd_solver.cpp:112] Iteration 43530, lr = 0.01
I0523 03:53:46.702433 34819 solver.cpp:239] Iteration 43540 (2.33555 iter/s, 4.28165s/10 iters), loss = 8.86084
I0523 03:53:46.702477 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86084 (* 1 = 8.86084 loss)
I0523 03:53:46.760257 34819 sgd_solver.cpp:112] Iteration 43540, lr = 0.01
I0523 03:53:51.382589 34819 solver.cpp:239] Iteration 43550 (2.13679 iter/s, 4.67991s/10 iters), loss = 9.27821
I0523 03:53:51.382634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27821 (* 1 = 9.27821 loss)
I0523 03:53:51.444958 34819 sgd_solver.cpp:112] Iteration 43550, lr = 0.01
I0523 03:53:56.346467 34819 solver.cpp:239] Iteration 43560 (2.01466 iter/s, 4.96362s/10 iters), loss = 8.90547
I0523 03:53:56.346520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90547 (* 1 = 8.90547 loss)
I0523 03:53:56.424621 34819 sgd_solver.cpp:112] Iteration 43560, lr = 0.01
I0523 03:54:02.218252 34819 solver.cpp:239] Iteration 43570 (1.70314 iter/s, 5.87149s/10 iters), loss = 8.38328
I0523 03:54:02.218385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38328 (* 1 = 8.38328 loss)
I0523 03:54:02.287447 34819 sgd_solver.cpp:112] Iteration 43570, lr = 0.01
I0523 03:54:07.243422 34819 solver.cpp:239] Iteration 43580 (1.99012 iter/s, 5.02482s/10 iters), loss = 8.13006
I0523 03:54:07.243484 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13006 (* 1 = 8.13006 loss)
I0523 03:54:08.086616 34819 sgd_solver.cpp:112] Iteration 43580, lr = 0.01
I0523 03:54:11.686681 34819 solver.cpp:239] Iteration 43590 (2.25072 iter/s, 4.44301s/10 iters), loss = 9.0769
I0523 03:54:11.686753 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0769 (* 1 = 9.0769 loss)
I0523 03:54:11.749227 34819 sgd_solver.cpp:112] Iteration 43590, lr = 0.01
I0523 03:54:16.595350 34819 solver.cpp:239] Iteration 43600 (2.03733 iter/s, 4.90839s/10 iters), loss = 8.0272
I0523 03:54:16.595413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0272 (* 1 = 8.0272 loss)
I0523 03:54:16.657043 34819 sgd_solver.cpp:112] Iteration 43600, lr = 0.01
I0523 03:54:20.785028 34819 solver.cpp:239] Iteration 43610 (2.38695 iter/s, 4.18945s/10 iters), loss = 7.84923
I0523 03:54:20.785071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84923 (* 1 = 7.84923 loss)
I0523 03:54:20.830813 34819 sgd_solver.cpp:112] Iteration 43610, lr = 0.01
I0523 03:54:23.033514 34819 solver.cpp:239] Iteration 43620 (4.44777 iter/s, 2.24832s/10 iters), loss = 8.62344
I0523 03:54:23.033568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62344 (* 1 = 8.62344 loss)
I0523 03:54:23.756319 34819 sgd_solver.cpp:112] Iteration 43620, lr = 0.01
I0523 03:54:28.425129 34819 solver.cpp:239] Iteration 43630 (1.85483 iter/s, 5.39134s/10 iters), loss = 8.70073
I0523 03:54:28.425182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70073 (* 1 = 8.70073 loss)
I0523 03:54:28.491042 34819 sgd_solver.cpp:112] Iteration 43630, lr = 0.01
I0523 03:54:33.435876 34819 solver.cpp:239] Iteration 43640 (1.99582 iter/s, 5.01048s/10 iters), loss = 8.27405
I0523 03:54:33.436008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27405 (* 1 = 8.27405 loss)
I0523 03:54:33.499088 34819 sgd_solver.cpp:112] Iteration 43640, lr = 0.01
I0523 03:54:38.047755 34819 solver.cpp:239] Iteration 43650 (2.16847 iter/s, 4.61155s/10 iters), loss = 9.16635
I0523 03:54:38.047812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16635 (* 1 = 9.16635 loss)
I0523 03:54:38.895999 34819 sgd_solver.cpp:112] Iteration 43650, lr = 0.01
I0523 03:54:43.758399 34819 solver.cpp:239] Iteration 43660 (1.75121 iter/s, 5.71035s/10 iters), loss = 8.40081
I0523 03:54:43.758445 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40081 (* 1 = 8.40081 loss)
I0523 03:54:43.827445 34819 sgd_solver.cpp:112] Iteration 43660, lr = 0.01
I0523 03:54:48.841612 34819 solver.cpp:239] Iteration 43670 (1.96736 iter/s, 5.08295s/10 iters), loss = 8.77553
I0523 03:54:48.841657 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77553 (* 1 = 8.77553 loss)
I0523 03:54:49.521512 34819 sgd_solver.cpp:112] Iteration 43670, lr = 0.01
I0523 03:54:54.433164 34819 solver.cpp:239] Iteration 43680 (1.7885 iter/s, 5.59127s/10 iters), loss = 8.91415
I0523 03:54:54.433209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91415 (* 1 = 8.91415 loss)
I0523 03:54:54.512348 34819 sgd_solver.cpp:112] Iteration 43680, lr = 0.01
I0523 03:55:00.337306 34819 solver.cpp:239] Iteration 43690 (1.69381 iter/s, 5.90383s/10 iters), loss = 8.29208
I0523 03:55:00.337366 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29208 (* 1 = 8.29208 loss)
I0523 03:55:01.139390 34819 sgd_solver.cpp:112] Iteration 43690, lr = 0.01
I0523 03:55:06.123781 34819 solver.cpp:239] Iteration 43700 (1.72826 iter/s, 5.78617s/10 iters), loss = 9.08924
I0523 03:55:06.123927 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08924 (* 1 = 9.08924 loss)
I0523 03:55:06.972745 34819 sgd_solver.cpp:112] Iteration 43700, lr = 0.01
I0523 03:55:10.215494 34819 solver.cpp:239] Iteration 43710 (2.44415 iter/s, 4.0914s/10 iters), loss = 8.79414
I0523 03:55:10.215543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79414 (* 1 = 8.79414 loss)
I0523 03:55:10.273733 34819 sgd_solver.cpp:112] Iteration 43710, lr = 0.01
I0523 03:55:16.247495 34819 solver.cpp:239] Iteration 43720 (1.65791 iter/s, 6.0317s/10 iters), loss = 9.16931
I0523 03:55:16.247548 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16931 (* 1 = 9.16931 loss)
I0523 03:55:16.320147 34819 sgd_solver.cpp:112] Iteration 43720, lr = 0.01
I0523 03:55:22.198864 34819 solver.cpp:239] Iteration 43730 (1.68037 iter/s, 5.95106s/10 iters), loss = 8.84723
I0523 03:55:22.198920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84723 (* 1 = 8.84723 loss)
I0523 03:55:22.257092 34819 sgd_solver.cpp:112] Iteration 43730, lr = 0.01
I0523 03:55:27.008047 34819 solver.cpp:239] Iteration 43740 (2.07947 iter/s, 4.80893s/10 iters), loss = 9.26844
I0523 03:55:27.008097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26844 (* 1 = 9.26844 loss)
I0523 03:55:27.780290 34819 sgd_solver.cpp:112] Iteration 43740, lr = 0.01
I0523 03:55:32.213296 34819 solver.cpp:239] Iteration 43750 (1.92124 iter/s, 5.20498s/10 iters), loss = 8.72858
I0523 03:55:32.213336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72858 (* 1 = 8.72858 loss)
I0523 03:55:32.712231 34819 sgd_solver.cpp:112] Iteration 43750, lr = 0.01
I0523 03:55:36.497925 34819 solver.cpp:239] Iteration 43760 (2.33405 iter/s, 4.2844s/10 iters), loss = 8.6215
I0523 03:55:36.498116 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6215 (* 1 = 8.6215 loss)
I0523 03:55:36.553274 34819 sgd_solver.cpp:112] Iteration 43760, lr = 0.01
I0523 03:55:41.556424 34819 solver.cpp:239] Iteration 43770 (1.97702 iter/s, 5.05813s/10 iters), loss = 8.78536
I0523 03:55:41.556468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78536 (* 1 = 8.78536 loss)
I0523 03:55:42.320080 34819 sgd_solver.cpp:112] Iteration 43770, lr = 0.01
I0523 03:55:46.355906 34819 solver.cpp:239] Iteration 43780 (2.08367 iter/s, 4.79923s/10 iters), loss = 8.77516
I0523 03:55:46.355970 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77516 (* 1 = 8.77516 loss)
I0523 03:55:46.411474 34819 sgd_solver.cpp:112] Iteration 43780, lr = 0.01
I0523 03:55:51.967486 34819 solver.cpp:239] Iteration 43790 (1.78212 iter/s, 5.61129s/10 iters), loss = 9.29825
I0523 03:55:51.967531 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29825 (* 1 = 9.29825 loss)
I0523 03:55:52.776664 34819 sgd_solver.cpp:112] Iteration 43790, lr = 0.01
I0523 03:55:55.668296 34819 solver.cpp:239] Iteration 43800 (2.70227 iter/s, 3.7006s/10 iters), loss = 8.9677
I0523 03:55:55.668347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9677 (* 1 = 8.9677 loss)
I0523 03:55:55.727613 34819 sgd_solver.cpp:112] Iteration 43800, lr = 0.01
I0523 03:56:01.741660 34819 solver.cpp:239] Iteration 43810 (1.64662 iter/s, 6.07305s/10 iters), loss = 7.92543
I0523 03:56:01.741714 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92543 (* 1 = 7.92543 loss)
I0523 03:56:02.531476 34819 sgd_solver.cpp:112] Iteration 43810, lr = 0.01
I0523 03:56:07.517006 34819 solver.cpp:239] Iteration 43820 (1.73159 iter/s, 5.77504s/10 iters), loss = 8.60903
I0523 03:56:07.517222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60903 (* 1 = 8.60903 loss)
I0523 03:56:07.576882 34819 sgd_solver.cpp:112] Iteration 43820, lr = 0.01
I0523 03:56:11.346004 34819 solver.cpp:239] Iteration 43830 (2.61191 iter/s, 3.82861s/10 iters), loss = 9.04739
I0523 03:56:11.346058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04739 (* 1 = 9.04739 loss)
I0523 03:56:11.404768 34819 sgd_solver.cpp:112] Iteration 43830, lr = 0.01
I0523 03:56:16.696041 34819 solver.cpp:239] Iteration 43840 (1.86924 iter/s, 5.34976s/10 iters), loss = 8.07296
I0523 03:56:16.696092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07296 (* 1 = 8.07296 loss)
I0523 03:56:16.766880 34819 sgd_solver.cpp:112] Iteration 43840, lr = 0.01
I0523 03:56:20.279736 34819 solver.cpp:239] Iteration 43850 (2.79058 iter/s, 3.58349s/10 iters), loss = 7.88631
I0523 03:56:20.279793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88631 (* 1 = 7.88631 loss)
I0523 03:56:20.344265 34819 sgd_solver.cpp:112] Iteration 43850, lr = 0.01
I0523 03:56:24.328420 34819 solver.cpp:239] Iteration 43860 (2.47009 iter/s, 4.04844s/10 iters), loss = 8.50483
I0523 03:56:24.328467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50483 (* 1 = 8.50483 loss)
I0523 03:56:24.403321 34819 sgd_solver.cpp:112] Iteration 43860, lr = 0.01
I0523 03:56:31.685034 34819 solver.cpp:239] Iteration 43870 (1.35938 iter/s, 7.35627s/10 iters), loss = 9.42149
I0523 03:56:31.685089 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42149 (* 1 = 9.42149 loss)
I0523 03:56:31.753644 34819 sgd_solver.cpp:112] Iteration 43870, lr = 0.01
I0523 03:56:36.938431 34819 solver.cpp:239] Iteration 43880 (1.90363 iter/s, 5.25312s/10 iters), loss = 8.54021
I0523 03:56:36.938478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54021 (* 1 = 8.54021 loss)
I0523 03:56:37.616488 34819 sgd_solver.cpp:112] Iteration 43880, lr = 0.01
I0523 03:56:40.245092 34819 solver.cpp:239] Iteration 43890 (3.0244 iter/s, 3.30645s/10 iters), loss = 9.1663
I0523 03:56:40.245152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1663 (* 1 = 9.1663 loss)
I0523 03:56:41.091421 34819 sgd_solver.cpp:112] Iteration 43890, lr = 0.01
I0523 03:56:45.348517 34819 solver.cpp:239] Iteration 43900 (1.95958 iter/s, 5.10314s/10 iters), loss = 9.24831
I0523 03:56:45.348559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24831 (* 1 = 9.24831 loss)
I0523 03:56:45.418251 34819 sgd_solver.cpp:112] Iteration 43900, lr = 0.01
I0523 03:56:50.051631 34819 solver.cpp:239] Iteration 43910 (2.12636 iter/s, 4.70287s/10 iters), loss = 9.12
I0523 03:56:50.051692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12 (* 1 = 9.12 loss)
I0523 03:56:50.111701 34819 sgd_solver.cpp:112] Iteration 43910, lr = 0.01
I0523 03:56:53.359264 34819 solver.cpp:239] Iteration 43920 (3.0235 iter/s, 3.30743s/10 iters), loss = 8.16695
I0523 03:56:53.359305 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16695 (* 1 = 8.16695 loss)
I0523 03:56:53.416215 34819 sgd_solver.cpp:112] Iteration 43920, lr = 0.01
I0523 03:56:58.377470 34819 solver.cpp:239] Iteration 43930 (1.99431 iter/s, 5.01425s/10 iters), loss = 8.75325
I0523 03:56:58.377518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75325 (* 1 = 8.75325 loss)
I0523 03:56:58.444650 34819 sgd_solver.cpp:112] Iteration 43930, lr = 0.01
I0523 03:57:02.376317 34819 solver.cpp:239] Iteration 43940 (2.50086 iter/s, 3.99862s/10 iters), loss = 9.30224
I0523 03:57:02.376361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30224 (* 1 = 9.30224 loss)
I0523 03:57:03.071532 34819 sgd_solver.cpp:112] Iteration 43940, lr = 0.01
I0523 03:57:08.012737 34819 solver.cpp:239] Iteration 43950 (1.77426 iter/s, 5.63614s/10 iters), loss = 8.88755
I0523 03:57:08.012883 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88755 (* 1 = 8.88755 loss)
I0523 03:57:08.089720 34819 sgd_solver.cpp:112] Iteration 43950, lr = 0.01
I0523 03:57:13.203802 34819 solver.cpp:239] Iteration 43960 (1.92653 iter/s, 5.19069s/10 iters), loss = 8.54011
I0523 03:57:13.203856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54011 (* 1 = 8.54011 loss)
I0523 03:57:13.694478 34819 sgd_solver.cpp:112] Iteration 43960, lr = 0.01
I0523 03:57:19.500656 34819 solver.cpp:239] Iteration 43970 (1.58818 iter/s, 6.29653s/10 iters), loss = 8.46749
I0523 03:57:19.500713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46749 (* 1 = 8.46749 loss)
I0523 03:57:20.203536 34819 sgd_solver.cpp:112] Iteration 43970, lr = 0.01
I0523 03:57:24.856470 34819 solver.cpp:239] Iteration 43980 (1.86723 iter/s, 5.35554s/10 iters), loss = 9.72805
I0523 03:57:24.856523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72805 (* 1 = 9.72805 loss)
I0523 03:57:24.915786 34819 sgd_solver.cpp:112] Iteration 43980, lr = 0.01
I0523 03:57:29.193687 34819 solver.cpp:239] Iteration 43990 (2.30576 iter/s, 4.33697s/10 iters), loss = 8.48932
I0523 03:57:29.193747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48932 (* 1 = 8.48932 loss)
I0523 03:57:29.271425 34819 sgd_solver.cpp:112] Iteration 43990, lr = 0.01
I0523 03:57:34.202426 34819 solver.cpp:239] Iteration 44000 (1.99663 iter/s, 5.00843s/10 iters), loss = 9.32163
I0523 03:57:34.202473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32163 (* 1 = 9.32163 loss)
I0523 03:57:34.991226 34819 sgd_solver.cpp:112] Iteration 44000, lr = 0.01
I0523 03:57:40.236572 34819 solver.cpp:239] Iteration 44010 (1.65732 iter/s, 6.03385s/10 iters), loss = 8.84637
I0523 03:57:40.236737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84637 (* 1 = 8.84637 loss)
I0523 03:57:41.090390 34819 sgd_solver.cpp:112] Iteration 44010, lr = 0.01
I0523 03:57:47.132135 34819 solver.cpp:239] Iteration 44020 (1.4503 iter/s, 6.89512s/10 iters), loss = 8.77774
I0523 03:57:47.132176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77774 (* 1 = 8.77774 loss)
I0523 03:57:47.201503 34819 sgd_solver.cpp:112] Iteration 44020, lr = 0.01
I0523 03:57:52.083971 34819 solver.cpp:239] Iteration 44030 (2.01956 iter/s, 4.95157s/10 iters), loss = 8.77576
I0523 03:57:52.084019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77576 (* 1 = 8.77576 loss)
I0523 03:57:52.803957 34819 sgd_solver.cpp:112] Iteration 44030, lr = 0.01
I0523 03:57:56.661490 34819 solver.cpp:239] Iteration 44040 (2.18471 iter/s, 4.57727s/10 iters), loss = 9.1733
I0523 03:57:56.661530 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1733 (* 1 = 9.1733 loss)
I0523 03:57:57.546711 34819 sgd_solver.cpp:112] Iteration 44040, lr = 0.01
I0523 03:58:01.605682 34819 solver.cpp:239] Iteration 44050 (2.02268 iter/s, 4.94394s/10 iters), loss = 7.50127
I0523 03:58:01.605722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50127 (* 1 = 7.50127 loss)
I0523 03:58:01.663311 34819 sgd_solver.cpp:112] Iteration 44050, lr = 0.01
I0523 03:58:07.365854 34819 solver.cpp:239] Iteration 44060 (1.73615 iter/s, 5.75987s/10 iters), loss = 8.66266
I0523 03:58:07.365903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66266 (* 1 = 8.66266 loss)
I0523 03:58:08.228698 34819 sgd_solver.cpp:112] Iteration 44060, lr = 0.01
I0523 03:58:12.398485 34819 solver.cpp:239] Iteration 44070 (1.98713 iter/s, 5.03238s/10 iters), loss = 8.88935
I0523 03:58:12.398634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88935 (* 1 = 8.88935 loss)
I0523 03:58:13.236224 34819 sgd_solver.cpp:112] Iteration 44070, lr = 0.01
I0523 03:58:17.991583 34819 solver.cpp:239] Iteration 44080 (1.78804 iter/s, 5.59272s/10 iters), loss = 9.63945
I0523 03:58:17.991626 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63945 (* 1 = 9.63945 loss)
I0523 03:58:18.061825 34819 sgd_solver.cpp:112] Iteration 44080, lr = 0.01
I0523 03:58:20.518225 34819 solver.cpp:239] Iteration 44090 (3.95808 iter/s, 2.52648s/10 iters), loss = 9.07812
I0523 03:58:20.518267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07812 (* 1 = 9.07812 loss)
I0523 03:58:20.593932 34819 sgd_solver.cpp:112] Iteration 44090, lr = 0.01
I0523 03:58:25.453104 34819 solver.cpp:239] Iteration 44100 (2.02649 iter/s, 4.93463s/10 iters), loss = 9.07305
I0523 03:58:25.453145 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07305 (* 1 = 9.07305 loss)
I0523 03:58:25.515524 34819 sgd_solver.cpp:112] Iteration 44100, lr = 0.01
I0523 03:58:30.361753 34819 solver.cpp:239] Iteration 44110 (2.03732 iter/s, 4.9084s/10 iters), loss = 8.07004
I0523 03:58:30.361793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07004 (* 1 = 8.07004 loss)
I0523 03:58:30.430321 34819 sgd_solver.cpp:112] Iteration 44110, lr = 0.01
I0523 03:58:34.611884 34819 solver.cpp:239] Iteration 44120 (2.35299 iter/s, 4.24991s/10 iters), loss = 8.16645
I0523 03:58:34.611924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16645 (* 1 = 8.16645 loss)
I0523 03:58:35.347115 34819 sgd_solver.cpp:112] Iteration 44120, lr = 0.01
I0523 03:58:41.864758 34819 solver.cpp:239] Iteration 44130 (1.37883 iter/s, 7.25254s/10 iters), loss = 8.84092
I0523 03:58:41.864799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84092 (* 1 = 8.84092 loss)
I0523 03:58:41.918781 34819 sgd_solver.cpp:112] Iteration 44130, lr = 0.01
I0523 03:58:46.027225 34819 solver.cpp:239] Iteration 44140 (2.40256 iter/s, 4.16222s/10 iters), loss = 10.0849
I0523 03:58:46.027367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.0849 (* 1 = 10.0849 loss)
I0523 03:58:46.096833 34819 sgd_solver.cpp:112] Iteration 44140, lr = 0.01
I0523 03:58:51.318145 34819 solver.cpp:239] Iteration 44150 (1.89016 iter/s, 5.29055s/10 iters), loss = 8.86576
I0523 03:58:51.318198 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86576 (* 1 = 8.86576 loss)
I0523 03:58:51.389269 34819 sgd_solver.cpp:112] Iteration 44150, lr = 0.01
I0523 03:58:54.695967 34819 solver.cpp:239] Iteration 44160 (2.96067 iter/s, 3.37762s/10 iters), loss = 8.5519
I0523 03:58:54.696018 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5519 (* 1 = 8.5519 loss)
I0523 03:58:54.755242 34819 sgd_solver.cpp:112] Iteration 44160, lr = 0.01
I0523 03:58:59.614821 34819 solver.cpp:239] Iteration 44170 (2.03311 iter/s, 4.91858s/10 iters), loss = 8.10404
I0523 03:58:59.614883 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10404 (* 1 = 8.10404 loss)
I0523 03:59:00.462029 34819 sgd_solver.cpp:112] Iteration 44170, lr = 0.01
I0523 03:59:04.761598 34819 solver.cpp:239] Iteration 44180 (1.94307 iter/s, 5.1465s/10 iters), loss = 9.40537
I0523 03:59:04.761653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40537 (* 1 = 9.40537 loss)
I0523 03:59:04.976573 34819 sgd_solver.cpp:112] Iteration 44180, lr = 0.01
I0523 03:59:09.154268 34819 solver.cpp:239] Iteration 44190 (2.27664 iter/s, 4.39243s/10 iters), loss = 8.78275
I0523 03:59:09.154316 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78275 (* 1 = 8.78275 loss)
I0523 03:59:09.220810 34819 sgd_solver.cpp:112] Iteration 44190, lr = 0.01
I0523 03:59:15.002614 34819 solver.cpp:239] Iteration 44200 (1.70997 iter/s, 5.84805s/10 iters), loss = 9.03532
I0523 03:59:15.002656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03532 (* 1 = 9.03532 loss)
I0523 03:59:15.771487 34819 sgd_solver.cpp:112] Iteration 44200, lr = 0.01
I0523 03:59:20.471900 34819 solver.cpp:239] Iteration 44210 (1.82849 iter/s, 5.46901s/10 iters), loss = 8.97802
I0523 03:59:20.472084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97802 (* 1 = 8.97802 loss)
I0523 03:59:21.286571 34819 sgd_solver.cpp:112] Iteration 44210, lr = 0.01
I0523 03:59:26.100183 34819 solver.cpp:239] Iteration 44220 (1.77687 iter/s, 5.62786s/10 iters), loss = 8.79619
I0523 03:59:26.100236 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79619 (* 1 = 8.79619 loss)
I0523 03:59:26.175339 34819 sgd_solver.cpp:112] Iteration 44220, lr = 0.01
I0523 03:59:30.599539 34819 solver.cpp:239] Iteration 44230 (2.22266 iter/s, 4.49911s/10 iters), loss = 8.93098
I0523 03:59:30.599601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93098 (* 1 = 8.93098 loss)
I0523 03:59:31.396220 34819 sgd_solver.cpp:112] Iteration 44230, lr = 0.01
I0523 03:59:35.841049 34819 solver.cpp:239] Iteration 44240 (1.90795 iter/s, 5.24122s/10 iters), loss = 8.43443
I0523 03:59:35.841104 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43443 (* 1 = 8.43443 loss)
I0523 03:59:35.913460 34819 sgd_solver.cpp:112] Iteration 44240, lr = 0.01
I0523 03:59:41.319118 34819 solver.cpp:239] Iteration 44250 (1.82556 iter/s, 5.47778s/10 iters), loss = 9.38881
I0523 03:59:41.319169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38881 (* 1 = 9.38881 loss)
I0523 03:59:41.385143 34819 sgd_solver.cpp:112] Iteration 44250, lr = 0.01
I0523 03:59:45.791173 34819 solver.cpp:239] Iteration 44260 (2.23624 iter/s, 4.4718s/10 iters), loss = 7.85808
I0523 03:59:45.791226 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85808 (* 1 = 7.85808 loss)
I0523 03:59:46.485499 34819 sgd_solver.cpp:112] Iteration 44260, lr = 0.01
I0523 03:59:51.194988 34819 solver.cpp:239] Iteration 44270 (1.85064 iter/s, 5.40353s/10 iters), loss = 8.27134
I0523 03:59:51.195103 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27134 (* 1 = 8.27134 loss)
I0523 03:59:51.253149 34819 sgd_solver.cpp:112] Iteration 44270, lr = 0.01
I0523 03:59:57.085762 34819 solver.cpp:239] Iteration 44280 (1.69836 iter/s, 5.88802s/10 iters), loss = 8.34793
I0523 03:59:57.085813 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34793 (* 1 = 8.34793 loss)
I0523 03:59:57.915740 34819 sgd_solver.cpp:112] Iteration 44280, lr = 0.01
I0523 04:00:00.362673 34819 solver.cpp:239] Iteration 44290 (3.05183 iter/s, 3.27672s/10 iters), loss = 8.50764
I0523 04:00:00.362749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50764 (* 1 = 8.50764 loss)
I0523 04:00:01.214637 34819 sgd_solver.cpp:112] Iteration 44290, lr = 0.01
I0523 04:00:06.178504 34819 solver.cpp:239] Iteration 44300 (1.71954 iter/s, 5.81551s/10 iters), loss = 8.40562
I0523 04:00:06.178560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40562 (* 1 = 8.40562 loss)
I0523 04:00:06.251585 34819 sgd_solver.cpp:112] Iteration 44300, lr = 0.01
I0523 04:00:09.758215 34819 solver.cpp:239] Iteration 44310 (2.7937 iter/s, 3.57949s/10 iters), loss = 9.01944
I0523 04:00:09.758275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01944 (* 1 = 9.01944 loss)
I0523 04:00:10.586524 34819 sgd_solver.cpp:112] Iteration 44310, lr = 0.01
I0523 04:00:15.479365 34819 solver.cpp:239] Iteration 44320 (1.74799 iter/s, 5.72085s/10 iters), loss = 9.49291
I0523 04:00:15.479426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49291 (* 1 = 9.49291 loss)
I0523 04:00:16.220155 34819 sgd_solver.cpp:112] Iteration 44320, lr = 0.01
I0523 04:00:22.478281 34819 solver.cpp:239] Iteration 44330 (1.42886 iter/s, 6.99857s/10 iters), loss = 8.22458
I0523 04:00:22.478472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22458 (* 1 = 8.22458 loss)
I0523 04:00:23.205288 34819 sgd_solver.cpp:112] Iteration 44330, lr = 0.01
I0523 04:00:27.439821 34819 solver.cpp:239] Iteration 44340 (2.01566 iter/s, 4.96115s/10 iters), loss = 8.33323
I0523 04:00:27.439874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33323 (* 1 = 8.33323 loss)
I0523 04:00:27.520041 34819 sgd_solver.cpp:112] Iteration 44340, lr = 0.01
I0523 04:00:30.084973 34819 solver.cpp:239] Iteration 44350 (3.78075 iter/s, 2.64498s/10 iters), loss = 8.85917
I0523 04:00:30.085021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85917 (* 1 = 8.85917 loss)
I0523 04:00:30.624047 34819 sgd_solver.cpp:112] Iteration 44350, lr = 0.01
I0523 04:00:34.845078 34819 solver.cpp:239] Iteration 44360 (2.1009 iter/s, 4.75986s/10 iters), loss = 9.21746
I0523 04:00:34.845139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21746 (* 1 = 9.21746 loss)
I0523 04:00:35.549676 34819 sgd_solver.cpp:112] Iteration 44360, lr = 0.01
I0523 04:00:39.565747 34819 solver.cpp:239] Iteration 44370 (2.11846 iter/s, 4.72041s/10 iters), loss = 9.28587
I0523 04:00:39.565811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28587 (* 1 = 9.28587 loss)
I0523 04:00:39.634188 34819 sgd_solver.cpp:112] Iteration 44370, lr = 0.01
I0523 04:00:44.248248 34819 solver.cpp:239] Iteration 44380 (2.13573 iter/s, 4.68225s/10 iters), loss = 9.43157
I0523 04:00:44.248291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43157 (* 1 = 9.43157 loss)
I0523 04:00:44.330166 34819 sgd_solver.cpp:112] Iteration 44380, lr = 0.01
I0523 04:00:48.566434 34819 solver.cpp:239] Iteration 44390 (2.31592 iter/s, 4.31795s/10 iters), loss = 8.71948
I0523 04:00:48.566488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71948 (* 1 = 8.71948 loss)
I0523 04:00:48.813016 34819 sgd_solver.cpp:112] Iteration 44390, lr = 0.01
I0523 04:00:55.051169 34819 solver.cpp:239] Iteration 44400 (1.54216 iter/s, 6.48441s/10 iters), loss = 8.45322
I0523 04:00:55.051393 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45322 (* 1 = 8.45322 loss)
I0523 04:00:55.109716 34819 sgd_solver.cpp:112] Iteration 44400, lr = 0.01
I0523 04:01:00.305685 34819 solver.cpp:239] Iteration 44410 (1.90328 iter/s, 5.25409s/10 iters), loss = 8.94644
I0523 04:01:00.305737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94644 (* 1 = 8.94644 loss)
I0523 04:01:01.049862 34819 sgd_solver.cpp:112] Iteration 44410, lr = 0.01
I0523 04:01:05.335809 34819 solver.cpp:239] Iteration 44420 (1.98813 iter/s, 5.02986s/10 iters), loss = 9.13394
I0523 04:01:05.335861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13394 (* 1 = 9.13394 loss)
I0523 04:01:05.418947 34819 sgd_solver.cpp:112] Iteration 44420, lr = 0.01
I0523 04:01:08.830845 34819 solver.cpp:239] Iteration 44430 (2.86136 iter/s, 3.49484s/10 iters), loss = 8.28548
I0523 04:01:08.830891 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28548 (* 1 = 8.28548 loss)
I0523 04:01:08.894569 34819 sgd_solver.cpp:112] Iteration 44430, lr = 0.01
I0523 04:01:15.072432 34819 solver.cpp:239] Iteration 44440 (1.60225 iter/s, 6.24123s/10 iters), loss = 9.31528
I0523 04:01:15.072480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31528 (* 1 = 9.31528 loss)
I0523 04:01:15.768208 34819 sgd_solver.cpp:112] Iteration 44440, lr = 0.01
I0523 04:01:20.120635 34819 solver.cpp:239] Iteration 44450 (1.98101 iter/s, 5.04793s/10 iters), loss = 8.40794
I0523 04:01:20.120692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40794 (* 1 = 8.40794 loss)
I0523 04:01:20.937703 34819 sgd_solver.cpp:112] Iteration 44450, lr = 0.01
I0523 04:01:25.747469 34819 solver.cpp:239] Iteration 44460 (1.77729 iter/s, 5.62655s/10 iters), loss = 9.76328
I0523 04:01:25.747645 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.76328 (* 1 = 9.76328 loss)
I0523 04:01:25.810936 34819 sgd_solver.cpp:112] Iteration 44460, lr = 0.01
I0523 04:01:31.019042 34819 solver.cpp:239] Iteration 44470 (1.8971 iter/s, 5.2712s/10 iters), loss = 9.25791
I0523 04:01:31.019095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25791 (* 1 = 9.25791 loss)
I0523 04:01:31.085593 34819 sgd_solver.cpp:112] Iteration 44470, lr = 0.01
I0523 04:01:35.901850 34819 solver.cpp:239] Iteration 44480 (2.04811 iter/s, 4.88255s/10 iters), loss = 9.40953
I0523 04:01:35.901901 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40953 (* 1 = 9.40953 loss)
I0523 04:01:36.742697 34819 sgd_solver.cpp:112] Iteration 44480, lr = 0.01
I0523 04:01:40.877179 34819 solver.cpp:239] Iteration 44490 (2.01002 iter/s, 4.97507s/10 iters), loss = 8.94654
I0523 04:01:40.877218 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94654 (* 1 = 8.94654 loss)
I0523 04:01:41.639570 34819 sgd_solver.cpp:112] Iteration 44490, lr = 0.01
I0523 04:01:46.367619 34819 solver.cpp:239] Iteration 44500 (1.82144 iter/s, 5.49017s/10 iters), loss = 8.43408
I0523 04:01:46.367676 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43408 (* 1 = 8.43408 loss)
I0523 04:01:47.196195 34819 sgd_solver.cpp:112] Iteration 44500, lr = 0.01
I0523 04:01:52.245915 34819 solver.cpp:239] Iteration 44510 (1.70126 iter/s, 5.87799s/10 iters), loss = 8.5269
I0523 04:01:52.245985 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5269 (* 1 = 8.5269 loss)
I0523 04:01:53.023228 34819 sgd_solver.cpp:112] Iteration 44510, lr = 0.01
I0523 04:01:58.068967 34819 solver.cpp:239] Iteration 44520 (1.7174 iter/s, 5.82275s/10 iters), loss = 8.32984
I0523 04:01:58.069133 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32984 (* 1 = 8.32984 loss)
I0523 04:01:58.748332 34819 sgd_solver.cpp:112] Iteration 44520, lr = 0.01
I0523 04:02:04.794246 34819 solver.cpp:239] Iteration 44530 (1.48702 iter/s, 6.72484s/10 iters), loss = 8.83078
I0523 04:02:04.794296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83078 (* 1 = 8.83078 loss)
I0523 04:02:04.861240 34819 sgd_solver.cpp:112] Iteration 44530, lr = 0.01
I0523 04:02:11.934274 34819 solver.cpp:239] Iteration 44540 (1.40062 iter/s, 7.13968s/10 iters), loss = 8.54939
I0523 04:02:11.934329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54939 (* 1 = 8.54939 loss)
I0523 04:02:11.990633 34819 sgd_solver.cpp:112] Iteration 44540, lr = 0.01
I0523 04:02:18.142550 34819 solver.cpp:239] Iteration 44550 (1.61083 iter/s, 6.20797s/10 iters), loss = 9.36286
I0523 04:02:18.142596 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36286 (* 1 = 9.36286 loss)
I0523 04:02:18.201750 34819 sgd_solver.cpp:112] Iteration 44550, lr = 0.01
I0523 04:02:23.704777 34819 solver.cpp:239] Iteration 44560 (1.79793 iter/s, 5.56194s/10 iters), loss = 9.67753
I0523 04:02:23.704833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67753 (* 1 = 9.67753 loss)
I0523 04:02:23.770740 34819 sgd_solver.cpp:112] Iteration 44560, lr = 0.01
I0523 04:02:28.091727 34819 solver.cpp:239] Iteration 44570 (2.27962 iter/s, 4.3867s/10 iters), loss = 8.90539
I0523 04:02:28.091907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90539 (* 1 = 8.90539 loss)
I0523 04:02:28.160557 34819 sgd_solver.cpp:112] Iteration 44570, lr = 0.01
I0523 04:02:30.989596 34819 solver.cpp:239] Iteration 44580 (3.45117 iter/s, 2.89757s/10 iters), loss = 9.00647
I0523 04:02:30.989641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00647 (* 1 = 9.00647 loss)
I0523 04:02:31.053283 34819 sgd_solver.cpp:112] Iteration 44580, lr = 0.01
I0523 04:02:34.945643 34819 solver.cpp:239] Iteration 44590 (2.52791 iter/s, 3.95583s/10 iters), loss = 8.24153
I0523 04:02:34.945695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24153 (* 1 = 8.24153 loss)
I0523 04:02:35.018170 34819 sgd_solver.cpp:112] Iteration 44590, lr = 0.01
I0523 04:02:40.640007 34819 solver.cpp:239] Iteration 44600 (1.75621 iter/s, 5.69408s/10 iters), loss = 7.29776
I0523 04:02:40.640053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29776 (* 1 = 7.29776 loss)
I0523 04:02:40.696748 34819 sgd_solver.cpp:112] Iteration 44600, lr = 0.01
I0523 04:02:44.839612 34819 solver.cpp:239] Iteration 44610 (2.3813 iter/s, 4.19938s/10 iters), loss = 9.11623
I0523 04:02:44.839653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11623 (* 1 = 9.11623 loss)
I0523 04:02:44.940346 34819 sgd_solver.cpp:112] Iteration 44610, lr = 0.01
I0523 04:02:50.326683 34819 solver.cpp:239] Iteration 44620 (1.82256 iter/s, 5.4868s/10 iters), loss = 8.79554
I0523 04:02:50.326761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79554 (* 1 = 8.79554 loss)
I0523 04:02:50.402092 34819 sgd_solver.cpp:112] Iteration 44620, lr = 0.01
I0523 04:02:54.909422 34819 solver.cpp:239] Iteration 44630 (2.18223 iter/s, 4.58247s/10 iters), loss = 8.69926
I0523 04:02:54.909463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69926 (* 1 = 8.69926 loss)
I0523 04:02:54.981541 34819 sgd_solver.cpp:112] Iteration 44630, lr = 0.01
I0523 04:02:57.604336 34819 solver.cpp:239] Iteration 44640 (3.71093 iter/s, 2.69474s/10 iters), loss = 8.22315
I0523 04:02:57.604382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22315 (* 1 = 8.22315 loss)
I0523 04:02:58.421141 34819 sgd_solver.cpp:112] Iteration 44640, lr = 0.01
I0523 04:03:03.940165 34819 solver.cpp:239] Iteration 44650 (1.5784 iter/s, 6.33551s/10 iters), loss = 8.47065
I0523 04:03:03.940209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47065 (* 1 = 8.47065 loss)
I0523 04:03:04.778746 34819 sgd_solver.cpp:112] Iteration 44650, lr = 0.01
I0523 04:03:07.474475 34819 solver.cpp:239] Iteration 44660 (2.82956 iter/s, 3.53411s/10 iters), loss = 8.53071
I0523 04:03:07.474517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53071 (* 1 = 8.53071 loss)
I0523 04:03:08.323024 34819 sgd_solver.cpp:112] Iteration 44660, lr = 0.01
I0523 04:03:14.427561 34819 solver.cpp:239] Iteration 44670 (1.43828 iter/s, 6.95276s/10 iters), loss = 9.41296
I0523 04:03:14.427613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41296 (* 1 = 9.41296 loss)
I0523 04:03:14.507093 34819 sgd_solver.cpp:112] Iteration 44670, lr = 0.01
I0523 04:03:18.460042 34819 solver.cpp:239] Iteration 44680 (2.48 iter/s, 4.03226s/10 iters), loss = 8.99728
I0523 04:03:18.460088 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99728 (* 1 = 8.99728 loss)
I0523 04:03:18.529423 34819 sgd_solver.cpp:112] Iteration 44680, lr = 0.01
I0523 04:03:21.498414 34819 solver.cpp:239] Iteration 44690 (3.29143 iter/s, 3.0382s/10 iters), loss = 8.69666
I0523 04:03:21.498461 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69666 (* 1 = 8.69666 loss)
I0523 04:03:21.558006 34819 sgd_solver.cpp:112] Iteration 44690, lr = 0.01
I0523 04:03:25.827769 34819 solver.cpp:239] Iteration 44700 (2.30994 iter/s, 4.32912s/10 iters), loss = 8.42065
I0523 04:03:25.827808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42065 (* 1 = 8.42065 loss)
I0523 04:03:25.976195 34819 sgd_solver.cpp:112] Iteration 44700, lr = 0.01
I0523 04:03:28.994333 34819 solver.cpp:239] Iteration 44710 (3.15818 iter/s, 3.16639s/10 iters), loss = 8.72358
I0523 04:03:28.994462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72358 (* 1 = 8.72358 loss)
I0523 04:03:29.059340 34819 sgd_solver.cpp:112] Iteration 44710, lr = 0.01
I0523 04:03:34.781512 34819 solver.cpp:239] Iteration 44720 (1.72806 iter/s, 5.78682s/10 iters), loss = 8.83759
I0523 04:03:34.781554 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83759 (* 1 = 8.83759 loss)
I0523 04:03:34.846288 34819 sgd_solver.cpp:112] Iteration 44720, lr = 0.01
I0523 04:03:39.037884 34819 solver.cpp:239] Iteration 44730 (2.34954 iter/s, 4.25615s/10 iters), loss = 8.19167
I0523 04:03:39.037928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19167 (* 1 = 8.19167 loss)
I0523 04:03:39.113608 34819 sgd_solver.cpp:112] Iteration 44730, lr = 0.01
I0523 04:03:43.177873 34819 solver.cpp:239] Iteration 44740 (2.4156 iter/s, 4.13976s/10 iters), loss = 8.47239
I0523 04:03:43.177917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47239 (* 1 = 8.47239 loss)
I0523 04:03:43.638918 34819 sgd_solver.cpp:112] Iteration 44740, lr = 0.01
I0523 04:03:49.076689 34819 solver.cpp:239] Iteration 44750 (1.69534 iter/s, 5.89852s/10 iters), loss = 8.85149
I0523 04:03:49.076738 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85149 (* 1 = 8.85149 loss)
I0523 04:03:49.149636 34819 sgd_solver.cpp:112] Iteration 44750, lr = 0.01
I0523 04:03:53.455070 34819 solver.cpp:239] Iteration 44760 (2.28407 iter/s, 4.37815s/10 iters), loss = 8.88254
I0523 04:03:53.455121 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88254 (* 1 = 8.88254 loss)
I0523 04:03:53.523876 34819 sgd_solver.cpp:112] Iteration 44760, lr = 0.01
I0523 04:03:59.038329 34819 solver.cpp:239] Iteration 44770 (1.79116 iter/s, 5.58297s/10 iters), loss = 8.68657
I0523 04:03:59.038488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68657 (* 1 = 8.68657 loss)
I0523 04:03:59.099633 34819 sgd_solver.cpp:112] Iteration 44770, lr = 0.01
I0523 04:04:04.842290 34819 solver.cpp:239] Iteration 44780 (1.72308 iter/s, 5.80356s/10 iters), loss = 7.64555
I0523 04:04:04.842331 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64555 (* 1 = 7.64555 loss)
I0523 04:04:05.631933 34819 sgd_solver.cpp:112] Iteration 44780, lr = 0.01
I0523 04:04:08.976721 34819 solver.cpp:239] Iteration 44790 (2.41884 iter/s, 4.13422s/10 iters), loss = 7.84538
I0523 04:04:08.976763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84538 (* 1 = 7.84538 loss)
I0523 04:04:09.784546 34819 sgd_solver.cpp:112] Iteration 44790, lr = 0.01
I0523 04:04:14.657691 34819 solver.cpp:239] Iteration 44800 (1.76035 iter/s, 5.68069s/10 iters), loss = 8.94262
I0523 04:04:14.657737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94262 (* 1 = 8.94262 loss)
I0523 04:04:15.473377 34819 sgd_solver.cpp:112] Iteration 44800, lr = 0.01
I0523 04:04:18.479336 34819 solver.cpp:239] Iteration 44810 (2.61682 iter/s, 3.82143s/10 iters), loss = 8.123
I0523 04:04:18.479378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.123 (* 1 = 8.123 loss)
I0523 04:04:18.542500 34819 sgd_solver.cpp:112] Iteration 44810, lr = 0.01
I0523 04:04:22.701359 34819 solver.cpp:239] Iteration 44820 (2.36866 iter/s, 4.2218s/10 iters), loss = 9.60036
I0523 04:04:22.701407 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60036 (* 1 = 9.60036 loss)
I0523 04:04:22.771708 34819 sgd_solver.cpp:112] Iteration 44820, lr = 0.01
I0523 04:04:27.598172 34819 solver.cpp:239] Iteration 44830 (2.04226 iter/s, 4.89655s/10 iters), loss = 8.90722
I0523 04:04:27.598232 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90722 (* 1 = 8.90722 loss)
I0523 04:04:27.665684 34819 sgd_solver.cpp:112] Iteration 44830, lr = 0.01
I0523 04:04:32.671555 34819 solver.cpp:239] Iteration 44840 (1.97118 iter/s, 5.07311s/10 iters), loss = 8.88067
I0523 04:04:32.672507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88067 (* 1 = 8.88067 loss)
I0523 04:04:32.738667 34819 sgd_solver.cpp:112] Iteration 44840, lr = 0.01
I0523 04:04:35.401947 34819 solver.cpp:239] Iteration 44850 (3.66915 iter/s, 2.72543s/10 iters), loss = 8.39315
I0523 04:04:35.401988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39315 (* 1 = 8.39315 loss)
I0523 04:04:35.478122 34819 sgd_solver.cpp:112] Iteration 44850, lr = 0.01
I0523 04:04:41.792466 34819 solver.cpp:239] Iteration 44860 (1.5649 iter/s, 6.3902s/10 iters), loss = 9.397
I0523 04:04:41.792521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.397 (* 1 = 9.397 loss)
I0523 04:04:42.667891 34819 sgd_solver.cpp:112] Iteration 44860, lr = 0.01
I0523 04:04:47.102023 34819 solver.cpp:239] Iteration 44870 (1.88349 iter/s, 5.30928s/10 iters), loss = 8.89258
I0523 04:04:47.102066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89258 (* 1 = 8.89258 loss)
I0523 04:04:47.159467 34819 sgd_solver.cpp:112] Iteration 44870, lr = 0.01
I0523 04:04:50.806789 34819 solver.cpp:239] Iteration 44880 (2.69937 iter/s, 3.70456s/10 iters), loss = 8.60339
I0523 04:04:50.806830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60339 (* 1 = 8.60339 loss)
I0523 04:04:50.889601 34819 sgd_solver.cpp:112] Iteration 44880, lr = 0.01
I0523 04:04:54.845983 34819 solver.cpp:239] Iteration 44890 (2.47587 iter/s, 4.03898s/10 iters), loss = 8.97905
I0523 04:04:54.846024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97905 (* 1 = 8.97905 loss)
I0523 04:04:55.547709 34819 sgd_solver.cpp:112] Iteration 44890, lr = 0.01
I0523 04:04:59.519582 34819 solver.cpp:239] Iteration 44900 (2.13979 iter/s, 4.67336s/10 iters), loss = 8.62845
I0523 04:04:59.519628 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62845 (* 1 = 8.62845 loss)
I0523 04:05:00.258857 34819 sgd_solver.cpp:112] Iteration 44900, lr = 0.01
I0523 04:05:03.509029 34819 solver.cpp:239] Iteration 44910 (2.50675 iter/s, 3.98922s/10 iters), loss = 9.05586
I0523 04:05:03.509212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05586 (* 1 = 9.05586 loss)
I0523 04:05:03.573716 34819 sgd_solver.cpp:112] Iteration 44910, lr = 0.01
I0523 04:05:09.095697 34819 solver.cpp:239] Iteration 44920 (1.79011 iter/s, 5.58624s/10 iters), loss = 9.35608
I0523 04:05:09.095754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35608 (* 1 = 9.35608 loss)
I0523 04:05:09.901746 34819 sgd_solver.cpp:112] Iteration 44920, lr = 0.01
I0523 04:05:14.115270 34819 solver.cpp:239] Iteration 44930 (1.99231 iter/s, 5.01931s/10 iters), loss = 7.97718
I0523 04:05:14.115320 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97718 (* 1 = 7.97718 loss)
I0523 04:05:14.178985 34819 sgd_solver.cpp:112] Iteration 44930, lr = 0.01
I0523 04:05:18.359047 34819 solver.cpp:239] Iteration 44940 (2.35652 iter/s, 4.24354s/10 iters), loss = 9.08403
I0523 04:05:18.359087 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08403 (* 1 = 9.08403 loss)
I0523 04:05:18.558523 34819 sgd_solver.cpp:112] Iteration 44940, lr = 0.01
I0523 04:05:23.188546 34819 solver.cpp:239] Iteration 44950 (2.07071 iter/s, 4.82926s/10 iters), loss = 8.07644
I0523 04:05:23.188588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07644 (* 1 = 8.07644 loss)
I0523 04:05:23.261142 34819 sgd_solver.cpp:112] Iteration 44950, lr = 0.01
I0523 04:05:27.236264 34819 solver.cpp:239] Iteration 44960 (2.47066 iter/s, 4.0475s/10 iters), loss = 9.33459
I0523 04:05:27.236311 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33459 (* 1 = 9.33459 loss)
I0523 04:05:27.292948 34819 sgd_solver.cpp:112] Iteration 44960, lr = 0.01
I0523 04:05:32.202312 34819 solver.cpp:239] Iteration 44970 (2.01378 iter/s, 4.96578s/10 iters), loss = 8.66456
I0523 04:05:32.202384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66456 (* 1 = 8.66456 loss)
I0523 04:05:33.073599 34819 sgd_solver.cpp:112] Iteration 44970, lr = 0.01
I0523 04:05:35.593971 34819 solver.cpp:239] Iteration 44980 (2.9486 iter/s, 3.39144s/10 iters), loss = 8.58319
I0523 04:05:35.594126 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58319 (* 1 = 8.58319 loss)
I0523 04:05:35.671073 34819 sgd_solver.cpp:112] Iteration 44980, lr = 0.01
I0523 04:05:40.479164 34819 solver.cpp:239] Iteration 44990 (2.04715 iter/s, 4.88483s/10 iters), loss = 8.3433
I0523 04:05:40.479205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3433 (* 1 = 8.3433 loss)
I0523 04:05:40.537798 34819 sgd_solver.cpp:112] Iteration 44990, lr = 0.01
I0523 04:05:44.866027 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_45000.caffemodel
I0523 04:05:50.179071 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_45000.solverstate
I0523 04:05:50.413712 34819 solver.cpp:239] Iteration 45000 (1.00663 iter/s, 9.93412s/10 iters), loss = 9.81235
I0523 04:05:50.413756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.81235 (* 1 = 9.81235 loss)
I0523 04:05:50.468242 34819 sgd_solver.cpp:112] Iteration 45000, lr = 0.01
I0523 04:05:54.870568 34819 solver.cpp:239] Iteration 45010 (2.24385 iter/s, 4.45662s/10 iters), loss = 7.91458
I0523 04:05:54.870632 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91458 (* 1 = 7.91458 loss)
I0523 04:05:54.941949 34819 sgd_solver.cpp:112] Iteration 45010, lr = 0.01
I0523 04:05:58.309098 34819 solver.cpp:239] Iteration 45020 (2.90839 iter/s, 3.43832s/10 iters), loss = 8.50954
I0523 04:05:58.309140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50954 (* 1 = 8.50954 loss)
I0523 04:05:59.107048 34819 sgd_solver.cpp:112] Iteration 45020, lr = 0.01
I0523 04:06:06.792124 34819 solver.cpp:239] Iteration 45030 (1.17888 iter/s, 8.48264s/10 iters), loss = 9.3076
I0523 04:06:06.792294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3076 (* 1 = 9.3076 loss)
I0523 04:06:06.867139 34819 sgd_solver.cpp:112] Iteration 45030, lr = 0.01
I0523 04:06:12.286674 34819 solver.cpp:239] Iteration 45040 (1.82011 iter/s, 5.49416s/10 iters), loss = 9.18855
I0523 04:06:12.286738 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18855 (* 1 = 9.18855 loss)
I0523 04:06:13.110682 34819 sgd_solver.cpp:112] Iteration 45040, lr = 0.01
I0523 04:06:19.345654 34819 solver.cpp:239] Iteration 45050 (1.41671 iter/s, 7.05863s/10 iters), loss = 8.97488
I0523 04:06:19.345696 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97488 (* 1 = 8.97488 loss)
I0523 04:06:20.201413 34819 sgd_solver.cpp:112] Iteration 45050, lr = 0.01
I0523 04:06:22.435308 34819 solver.cpp:239] Iteration 45060 (3.23679 iter/s, 3.08948s/10 iters), loss = 9.31097
I0523 04:06:22.435353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31097 (* 1 = 9.31097 loss)
I0523 04:06:22.848373 34819 sgd_solver.cpp:112] Iteration 45060, lr = 0.01
I0523 04:06:26.839463 34819 solver.cpp:239] Iteration 45070 (2.2707 iter/s, 4.40392s/10 iters), loss = 9.42316
I0523 04:06:26.839511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42316 (* 1 = 9.42316 loss)
I0523 04:06:26.909111 34819 sgd_solver.cpp:112] Iteration 45070, lr = 0.01
I0523 04:06:29.903159 34819 solver.cpp:239] Iteration 45080 (3.26422 iter/s, 3.06352s/10 iters), loss = 9.93638
I0523 04:06:29.903203 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.93638 (* 1 = 9.93638 loss)
I0523 04:06:29.974411 34819 sgd_solver.cpp:112] Iteration 45080, lr = 0.01
I0523 04:06:33.554199 34819 solver.cpp:239] Iteration 45090 (2.73909 iter/s, 3.65084s/10 iters), loss = 8.69486
I0523 04:06:33.554240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69486 (* 1 = 8.69486 loss)
I0523 04:06:33.615046 34819 sgd_solver.cpp:112] Iteration 45090, lr = 0.01
I0523 04:06:37.721065 34819 solver.cpp:239] Iteration 45100 (2.40001 iter/s, 4.16664s/10 iters), loss = 8.4448
I0523 04:06:37.721290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4448 (* 1 = 8.4448 loss)
I0523 04:06:38.363553 34819 sgd_solver.cpp:112] Iteration 45100, lr = 0.01
I0523 04:06:43.138291 34819 solver.cpp:239] Iteration 45110 (1.84611 iter/s, 5.4168s/10 iters), loss = 8.50667
I0523 04:06:43.138348 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50667 (* 1 = 8.50667 loss)
I0523 04:06:43.199506 34819 sgd_solver.cpp:112] Iteration 45110, lr = 0.01
I0523 04:06:47.470710 34819 solver.cpp:239] Iteration 45120 (2.30831 iter/s, 4.33217s/10 iters), loss = 8.71005
I0523 04:06:47.470762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71005 (* 1 = 8.71005 loss)
I0523 04:06:47.529973 34819 sgd_solver.cpp:112] Iteration 45120, lr = 0.01
I0523 04:06:52.152444 34819 solver.cpp:239] Iteration 45130 (2.13608 iter/s, 4.68147s/10 iters), loss = 8.27903
I0523 04:06:52.152499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27903 (* 1 = 8.27903 loss)
I0523 04:06:52.218165 34819 sgd_solver.cpp:112] Iteration 45130, lr = 0.01
I0523 04:06:58.231982 34819 solver.cpp:239] Iteration 45140 (1.64494 iter/s, 6.07923s/10 iters), loss = 8.20574
I0523 04:06:58.232038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20574 (* 1 = 8.20574 loss)
I0523 04:06:58.305341 34819 sgd_solver.cpp:112] Iteration 45140, lr = 0.01
I0523 04:07:02.359645 34819 solver.cpp:239] Iteration 45150 (2.42281 iter/s, 4.12744s/10 iters), loss = 9.57145
I0523 04:07:02.359690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57145 (* 1 = 9.57145 loss)
I0523 04:07:02.432940 34819 sgd_solver.cpp:112] Iteration 45150, lr = 0.01
I0523 04:07:06.449460 34819 solver.cpp:239] Iteration 45160 (2.44523 iter/s, 4.08959s/10 iters), loss = 9.09324
I0523 04:07:06.449513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09324 (* 1 = 9.09324 loss)
I0523 04:07:07.024320 34819 sgd_solver.cpp:112] Iteration 45160, lr = 0.01
I0523 04:07:09.562655 34819 solver.cpp:239] Iteration 45170 (3.21233 iter/s, 3.113s/10 iters), loss = 8.18578
I0523 04:07:09.562858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18578 (* 1 = 8.18578 loss)
I0523 04:07:09.644783 34819 sgd_solver.cpp:112] Iteration 45170, lr = 0.01
I0523 04:07:16.024631 34819 solver.cpp:239] Iteration 45180 (1.54762 iter/s, 6.46151s/10 iters), loss = 8.98269
I0523 04:07:16.024672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98269 (* 1 = 8.98269 loss)
I0523 04:07:16.854069 34819 sgd_solver.cpp:112] Iteration 45180, lr = 0.01
I0523 04:07:20.074873 34819 solver.cpp:239] Iteration 45190 (2.46912 iter/s, 4.05003s/10 iters), loss = 9.53794
I0523 04:07:20.074918 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.53794 (* 1 = 9.53794 loss)
I0523 04:07:20.944690 34819 sgd_solver.cpp:112] Iteration 45190, lr = 0.01
I0523 04:07:25.927125 34819 solver.cpp:239] Iteration 45200 (1.70883 iter/s, 5.85195s/10 iters), loss = 8.45228
I0523 04:07:25.927173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45228 (* 1 = 8.45228 loss)
I0523 04:07:26.153887 34819 sgd_solver.cpp:112] Iteration 45200, lr = 0.01
I0523 04:07:30.239454 34819 solver.cpp:239] Iteration 45210 (2.31907 iter/s, 4.31208s/10 iters), loss = 9.08504
I0523 04:07:30.239508 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08504 (* 1 = 9.08504 loss)
I0523 04:07:30.308310 34819 sgd_solver.cpp:112] Iteration 45210, lr = 0.01
I0523 04:07:35.666342 34819 solver.cpp:239] Iteration 45220 (1.84278 iter/s, 5.42659s/10 iters), loss = 8.84649
I0523 04:07:35.666396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84649 (* 1 = 8.84649 loss)
I0523 04:07:35.741685 34819 sgd_solver.cpp:112] Iteration 45220, lr = 0.01
I0523 04:07:39.931545 34819 solver.cpp:239] Iteration 45230 (2.34469 iter/s, 4.26496s/10 iters), loss = 8.47038
I0523 04:07:39.931689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47038 (* 1 = 8.47038 loss)
I0523 04:07:40.005852 34819 sgd_solver.cpp:112] Iteration 45230, lr = 0.01
I0523 04:07:44.680173 34819 solver.cpp:239] Iteration 45240 (2.10602 iter/s, 4.74829s/10 iters), loss = 8.54016
I0523 04:07:44.680223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54016 (* 1 = 8.54016 loss)
I0523 04:07:45.419668 34819 sgd_solver.cpp:112] Iteration 45240, lr = 0.01
I0523 04:07:51.304380 34819 solver.cpp:239] Iteration 45250 (1.50969 iter/s, 6.62387s/10 iters), loss = 8.08716
I0523 04:07:51.304436 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08716 (* 1 = 8.08716 loss)
I0523 04:07:52.063341 34819 sgd_solver.cpp:112] Iteration 45250, lr = 0.01
I0523 04:07:56.921977 34819 solver.cpp:239] Iteration 45260 (1.78021 iter/s, 5.61731s/10 iters), loss = 8.89997
I0523 04:07:56.922019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89997 (* 1 = 8.89997 loss)
I0523 04:07:56.990732 34819 sgd_solver.cpp:112] Iteration 45260, lr = 0.01
I0523 04:08:01.863761 34819 solver.cpp:239] Iteration 45270 (2.02367 iter/s, 4.94153s/10 iters), loss = 9.11642
I0523 04:08:01.863824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11642 (* 1 = 9.11642 loss)
I0523 04:08:02.738500 34819 sgd_solver.cpp:112] Iteration 45270, lr = 0.01
I0523 04:08:08.935999 34819 solver.cpp:239] Iteration 45280 (1.41405 iter/s, 7.07188s/10 iters), loss = 9.30047
I0523 04:08:08.936053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.30047 (* 1 = 9.30047 loss)
I0523 04:08:09.004407 34819 sgd_solver.cpp:112] Iteration 45280, lr = 0.01
I0523 04:08:12.958551 34819 solver.cpp:239] Iteration 45290 (2.48612 iter/s, 4.02233s/10 iters), loss = 9.24825
I0523 04:08:12.958734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24825 (* 1 = 9.24825 loss)
I0523 04:08:13.033262 34819 sgd_solver.cpp:112] Iteration 45290, lr = 0.01
I0523 04:08:18.762879 34819 solver.cpp:239] Iteration 45300 (1.72298 iter/s, 5.8039s/10 iters), loss = 9.84371
I0523 04:08:18.762943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84371 (* 1 = 9.84371 loss)
I0523 04:08:19.402801 34819 sgd_solver.cpp:112] Iteration 45300, lr = 0.01
I0523 04:08:23.319267 34819 solver.cpp:239] Iteration 45310 (2.19484 iter/s, 4.55614s/10 iters), loss = 9.01542
I0523 04:08:23.319311 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01542 (* 1 = 9.01542 loss)
I0523 04:08:23.379153 34819 sgd_solver.cpp:112] Iteration 45310, lr = 0.01
I0523 04:08:28.840461 34819 solver.cpp:239] Iteration 45320 (1.8113 iter/s, 5.52091s/10 iters), loss = 8.75018
I0523 04:08:28.840512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75018 (* 1 = 8.75018 loss)
I0523 04:08:28.919200 34819 sgd_solver.cpp:112] Iteration 45320, lr = 0.01
I0523 04:08:32.217291 34819 solver.cpp:239] Iteration 45330 (2.96153 iter/s, 3.37663s/10 iters), loss = 8.67325
I0523 04:08:32.217345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67325 (* 1 = 8.67325 loss)
I0523 04:08:32.286557 34819 sgd_solver.cpp:112] Iteration 45330, lr = 0.01
I0523 04:08:36.508388 34819 solver.cpp:239] Iteration 45340 (2.33054 iter/s, 4.29085s/10 iters), loss = 8.14978
I0523 04:08:36.508435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14978 (* 1 = 8.14978 loss)
I0523 04:08:36.580198 34819 sgd_solver.cpp:112] Iteration 45340, lr = 0.01
I0523 04:08:42.504078 34819 solver.cpp:239] Iteration 45350 (1.66795 iter/s, 5.99538s/10 iters), loss = 9.34557
I0523 04:08:42.504128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34557 (* 1 = 9.34557 loss)
I0523 04:08:42.575531 34819 sgd_solver.cpp:112] Iteration 45350, lr = 0.01
I0523 04:08:45.905302 34819 solver.cpp:239] Iteration 45360 (2.9403 iter/s, 3.40101s/10 iters), loss = 8.81093
I0523 04:08:45.905434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81093 (* 1 = 8.81093 loss)
I0523 04:08:45.986073 34819 sgd_solver.cpp:112] Iteration 45360, lr = 0.01
I0523 04:08:49.476392 34819 solver.cpp:239] Iteration 45370 (2.80052 iter/s, 3.57076s/10 iters), loss = 9.1238
I0523 04:08:49.476452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1238 (* 1 = 9.1238 loss)
I0523 04:08:50.305558 34819 sgd_solver.cpp:112] Iteration 45370, lr = 0.01
I0523 04:08:53.903494 34819 solver.cpp:239] Iteration 45380 (2.25894 iter/s, 4.42685s/10 iters), loss = 7.74063
I0523 04:08:53.903544 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74063 (* 1 = 7.74063 loss)
I0523 04:08:53.966917 34819 sgd_solver.cpp:112] Iteration 45380, lr = 0.01
I0523 04:08:57.814422 34819 solver.cpp:239] Iteration 45390 (2.55708 iter/s, 3.91071s/10 iters), loss = 9.0346
I0523 04:08:57.814471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0346 (* 1 = 9.0346 loss)
I0523 04:08:58.626505 34819 sgd_solver.cpp:112] Iteration 45390, lr = 0.01
I0523 04:09:04.345232 34819 solver.cpp:239] Iteration 45400 (1.53128 iter/s, 6.53049s/10 iters), loss = 8.12854
I0523 04:09:04.345283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12854 (* 1 = 8.12854 loss)
I0523 04:09:05.139122 34819 sgd_solver.cpp:112] Iteration 45400, lr = 0.01
I0523 04:09:09.654906 34819 solver.cpp:239] Iteration 45410 (1.88345 iter/s, 5.3094s/10 iters), loss = 8.76782
I0523 04:09:09.654948 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76782 (* 1 = 8.76782 loss)
I0523 04:09:10.423985 34819 sgd_solver.cpp:112] Iteration 45410, lr = 0.01
I0523 04:09:17.603525 34819 solver.cpp:239] Iteration 45420 (1.25814 iter/s, 7.94824s/10 iters), loss = 8.83664
I0523 04:09:17.603704 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83664 (* 1 = 8.83664 loss)
I0523 04:09:17.670887 34819 sgd_solver.cpp:112] Iteration 45420, lr = 0.01
I0523 04:09:19.516911 34819 solver.cpp:239] Iteration 45430 (5.2271 iter/s, 1.91311s/10 iters), loss = 8.40481
I0523 04:09:19.516968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40481 (* 1 = 8.40481 loss)
I0523 04:09:20.342609 34819 sgd_solver.cpp:112] Iteration 45430, lr = 0.01
I0523 04:09:25.018405 34819 solver.cpp:239] Iteration 45440 (1.81778 iter/s, 5.50121s/10 iters), loss = 8.53883
I0523 04:09:25.018450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53883 (* 1 = 8.53883 loss)
I0523 04:09:25.084141 34819 sgd_solver.cpp:112] Iteration 45440, lr = 0.01
I0523 04:09:28.637221 34819 solver.cpp:239] Iteration 45450 (2.76349 iter/s, 3.61861s/10 iters), loss = 9.01182
I0523 04:09:28.637271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01182 (* 1 = 9.01182 loss)
I0523 04:09:29.473276 34819 sgd_solver.cpp:112] Iteration 45450, lr = 0.01
I0523 04:09:34.679549 34819 solver.cpp:239] Iteration 45460 (1.65508 iter/s, 6.04201s/10 iters), loss = 8.92186
I0523 04:09:34.679610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92186 (* 1 = 8.92186 loss)
I0523 04:09:35.394652 34819 sgd_solver.cpp:112] Iteration 45460, lr = 0.01
I0523 04:09:40.290987 34819 solver.cpp:239] Iteration 45470 (1.78217 iter/s, 5.61113s/10 iters), loss = 8.41053
I0523 04:09:40.291043 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41053 (* 1 = 8.41053 loss)
I0523 04:09:40.356572 34819 sgd_solver.cpp:112] Iteration 45470, lr = 0.01
I0523 04:09:47.074985 34819 solver.cpp:239] Iteration 45480 (1.47413 iter/s, 6.78367s/10 iters), loss = 8.21939
I0523 04:09:47.075047 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21939 (* 1 = 8.21939 loss)
I0523 04:09:47.904609 34819 sgd_solver.cpp:112] Iteration 45480, lr = 0.01
I0523 04:09:52.805222 34819 solver.cpp:239] Iteration 45490 (1.74522 iter/s, 5.72993s/10 iters), loss = 8.50016
I0523 04:09:52.805266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50016 (* 1 = 8.50016 loss)
I0523 04:09:53.577862 34819 sgd_solver.cpp:112] Iteration 45490, lr = 0.01
I0523 04:09:58.495941 34819 solver.cpp:239] Iteration 45500 (1.75733 iter/s, 5.69044s/10 iters), loss = 8.91321
I0523 04:09:58.495993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91321 (* 1 = 8.91321 loss)
I0523 04:09:59.323101 34819 sgd_solver.cpp:112] Iteration 45500, lr = 0.01
I0523 04:10:02.629070 34819 solver.cpp:239] Iteration 45510 (2.41961 iter/s, 4.1329s/10 iters), loss = 8.67855
I0523 04:10:02.629120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67855 (* 1 = 8.67855 loss)
I0523 04:10:03.203711 34819 sgd_solver.cpp:112] Iteration 45510, lr = 0.01
I0523 04:10:06.410964 34819 solver.cpp:239] Iteration 45520 (2.64433 iter/s, 3.78168s/10 iters), loss = 9.27925
I0523 04:10:06.411010 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27925 (* 1 = 9.27925 loss)
I0523 04:10:07.216069 34819 sgd_solver.cpp:112] Iteration 45520, lr = 0.01
I0523 04:10:10.575461 34819 solver.cpp:239] Iteration 45530 (2.40138 iter/s, 4.16428s/10 iters), loss = 8.64034
I0523 04:10:10.575505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64034 (* 1 = 8.64034 loss)
I0523 04:10:10.641835 34819 sgd_solver.cpp:112] Iteration 45530, lr = 0.01
I0523 04:10:16.107777 34819 solver.cpp:239] Iteration 45540 (1.80765 iter/s, 5.53205s/10 iters), loss = 8.00395
I0523 04:10:16.107830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00395 (* 1 = 8.00395 loss)
I0523 04:10:16.183672 34819 sgd_solver.cpp:112] Iteration 45540, lr = 0.01
I0523 04:10:21.103514 34819 solver.cpp:239] Iteration 45550 (2.00181 iter/s, 4.99548s/10 iters), loss = 9.04248
I0523 04:10:21.103695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04248 (* 1 = 9.04248 loss)
I0523 04:10:21.812870 34819 sgd_solver.cpp:112] Iteration 45550, lr = 0.01
I0523 04:10:25.083315 34819 solver.cpp:239] Iteration 45560 (2.51291 iter/s, 3.97945s/10 iters), loss = 8.64814
I0523 04:10:25.083356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64814 (* 1 = 8.64814 loss)
I0523 04:10:25.142385 34819 sgd_solver.cpp:112] Iteration 45560, lr = 0.01
I0523 04:10:28.611335 34819 solver.cpp:239] Iteration 45570 (2.83462 iter/s, 3.52782s/10 iters), loss = 8.59518
I0523 04:10:28.611409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59518 (* 1 = 8.59518 loss)
I0523 04:10:29.407599 34819 sgd_solver.cpp:112] Iteration 45570, lr = 0.01
I0523 04:10:33.614812 34819 solver.cpp:239] Iteration 45580 (1.99873 iter/s, 5.00318s/10 iters), loss = 9.19211
I0523 04:10:33.614876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19211 (* 1 = 9.19211 loss)
I0523 04:10:33.677317 34819 sgd_solver.cpp:112] Iteration 45580, lr = 0.01
I0523 04:10:37.766489 34819 solver.cpp:239] Iteration 45590 (2.40881 iter/s, 4.15143s/10 iters), loss = 9.00699
I0523 04:10:37.766542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00699 (* 1 = 9.00699 loss)
I0523 04:10:37.841241 34819 sgd_solver.cpp:112] Iteration 45590, lr = 0.01
I0523 04:10:43.599169 34819 solver.cpp:239] Iteration 45600 (1.71457 iter/s, 5.83238s/10 iters), loss = 8.59796
I0523 04:10:43.599236 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59796 (* 1 = 8.59796 loss)
I0523 04:10:44.366381 34819 sgd_solver.cpp:112] Iteration 45600, lr = 0.01
I0523 04:10:51.146431 34819 solver.cpp:239] Iteration 45610 (1.32505 iter/s, 7.54689s/10 iters), loss = 9.13337
I0523 04:10:51.146564 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13337 (* 1 = 9.13337 loss)
I0523 04:10:51.207077 34819 sgd_solver.cpp:112] Iteration 45610, lr = 0.01
I0523 04:10:56.209216 34819 solver.cpp:239] Iteration 45620 (1.97533 iter/s, 5.06245s/10 iters), loss = 9.20529
I0523 04:10:56.209257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20529 (* 1 = 9.20529 loss)
I0523 04:10:57.024148 34819 sgd_solver.cpp:112] Iteration 45620, lr = 0.01
I0523 04:11:00.901531 34819 solver.cpp:239] Iteration 45630 (2.13126 iter/s, 4.69207s/10 iters), loss = 9.44048
I0523 04:11:00.901579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44048 (* 1 = 9.44048 loss)
I0523 04:11:00.960999 34819 sgd_solver.cpp:112] Iteration 45630, lr = 0.01
I0523 04:11:04.871044 34819 solver.cpp:239] Iteration 45640 (2.51935 iter/s, 3.96928s/10 iters), loss = 9.32206
I0523 04:11:04.871098 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32206 (* 1 = 9.32206 loss)
I0523 04:11:04.933972 34819 sgd_solver.cpp:112] Iteration 45640, lr = 0.01
I0523 04:11:10.110792 34819 solver.cpp:239] Iteration 45650 (1.90859 iter/s, 5.23946s/10 iters), loss = 9.10887
I0523 04:11:10.110837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10887 (* 1 = 9.10887 loss)
I0523 04:11:10.715020 34819 sgd_solver.cpp:112] Iteration 45650, lr = 0.01
I0523 04:11:15.913074 34819 solver.cpp:239] Iteration 45660 (1.72355 iter/s, 5.80198s/10 iters), loss = 9.20461
I0523 04:11:15.913130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20461 (* 1 = 9.20461 loss)
I0523 04:11:15.986774 34819 sgd_solver.cpp:112] Iteration 45660, lr = 0.01
I0523 04:11:21.208875 34819 solver.cpp:239] Iteration 45670 (1.88839 iter/s, 5.29552s/10 iters), loss = 8.4659
I0523 04:11:21.209043 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4659 (* 1 = 8.4659 loss)
I0523 04:11:22.060183 34819 sgd_solver.cpp:112] Iteration 45670, lr = 0.01
I0523 04:11:25.985154 34819 solver.cpp:239] Iteration 45680 (2.09384 iter/s, 4.77591s/10 iters), loss = 8.87815
I0523 04:11:25.985200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87815 (* 1 = 8.87815 loss)
I0523 04:11:26.060314 34819 sgd_solver.cpp:112] Iteration 45680, lr = 0.01
I0523 04:11:28.625857 34819 solver.cpp:239] Iteration 45690 (3.78711 iter/s, 2.64053s/10 iters), loss = 8.43379
I0523 04:11:28.625910 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43379 (* 1 = 8.43379 loss)
I0523 04:11:29.426726 34819 sgd_solver.cpp:112] Iteration 45690, lr = 0.01
I0523 04:11:34.381142 34819 solver.cpp:239] Iteration 45700 (1.73762 iter/s, 5.75499s/10 iters), loss = 7.86246
I0523 04:11:34.381201 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86246 (* 1 = 7.86246 loss)
I0523 04:11:34.896857 34819 sgd_solver.cpp:112] Iteration 45700, lr = 0.01
I0523 04:11:38.986038 34819 solver.cpp:239] Iteration 45710 (2.17173 iter/s, 4.60463s/10 iters), loss = 8.87252
I0523 04:11:38.986088 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87252 (* 1 = 8.87252 loss)
I0523 04:11:39.840009 34819 sgd_solver.cpp:112] Iteration 45710, lr = 0.01
I0523 04:11:43.032994 34819 solver.cpp:239] Iteration 45720 (2.47113 iter/s, 4.04674s/10 iters), loss = 8.79124
I0523 04:11:43.033040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79124 (* 1 = 8.79124 loss)
I0523 04:11:43.095042 34819 sgd_solver.cpp:112] Iteration 45720, lr = 0.01
I0523 04:11:48.482867 34819 solver.cpp:239] Iteration 45730 (1.835 iter/s, 5.4496s/10 iters), loss = 8.59824
I0523 04:11:48.482909 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59824 (* 1 = 8.59824 loss)
I0523 04:11:48.550864 34819 sgd_solver.cpp:112] Iteration 45730, lr = 0.01
I0523 04:11:53.116657 34819 solver.cpp:239] Iteration 45740 (2.15817 iter/s, 4.63355s/10 iters), loss = 8.52548
I0523 04:11:53.116811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52548 (* 1 = 8.52548 loss)
I0523 04:11:53.916831 34819 sgd_solver.cpp:112] Iteration 45740, lr = 0.01
I0523 04:11:59.434520 34819 solver.cpp:239] Iteration 45750 (1.58292 iter/s, 6.31745s/10 iters), loss = 8.22278
I0523 04:11:59.434576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22278 (* 1 = 8.22278 loss)
I0523 04:12:00.219895 34819 sgd_solver.cpp:112] Iteration 45750, lr = 0.01
I0523 04:12:05.635764 34819 solver.cpp:239] Iteration 45760 (1.61266 iter/s, 6.20092s/10 iters), loss = 9.28167
I0523 04:12:05.635828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28167 (* 1 = 9.28167 loss)
I0523 04:12:06.346900 34819 sgd_solver.cpp:112] Iteration 45760, lr = 0.01
I0523 04:12:11.455303 34819 solver.cpp:239] Iteration 45770 (1.71844 iter/s, 5.81924s/10 iters), loss = 7.97303
I0523 04:12:11.455360 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97303 (* 1 = 7.97303 loss)
I0523 04:12:11.538079 34819 sgd_solver.cpp:112] Iteration 45770, lr = 0.01
I0523 04:12:17.180275 34819 solver.cpp:239] Iteration 45780 (1.74682 iter/s, 5.72468s/10 iters), loss = 8.9009
I0523 04:12:17.180330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9009 (* 1 = 8.9009 loss)
I0523 04:12:17.256002 34819 sgd_solver.cpp:112] Iteration 45780, lr = 0.01
I0523 04:12:20.270404 34819 solver.cpp:239] Iteration 45790 (3.2363 iter/s, 3.08994s/10 iters), loss = 8.80162
I0523 04:12:20.270447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80162 (* 1 = 8.80162 loss)
I0523 04:12:20.326591 34819 sgd_solver.cpp:112] Iteration 45790, lr = 0.01
I0523 04:12:25.207653 34819 solver.cpp:239] Iteration 45800 (2.02554 iter/s, 4.93697s/10 iters), loss = 8.7619
I0523 04:12:25.207847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7619 (* 1 = 8.7619 loss)
I0523 04:12:25.453407 34819 sgd_solver.cpp:112] Iteration 45800, lr = 0.01
I0523 04:12:30.311190 34819 solver.cpp:239] Iteration 45810 (1.95958 iter/s, 5.10313s/10 iters), loss = 8.50277
I0523 04:12:30.311239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50277 (* 1 = 8.50277 loss)
I0523 04:12:31.174942 34819 sgd_solver.cpp:112] Iteration 45810, lr = 0.01
I0523 04:12:35.787775 34819 solver.cpp:239] Iteration 45820 (1.82605 iter/s, 5.47631s/10 iters), loss = 9.01284
I0523 04:12:35.787817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01284 (* 1 = 9.01284 loss)
I0523 04:12:35.846274 34819 sgd_solver.cpp:112] Iteration 45820, lr = 0.01
I0523 04:12:39.174616 34819 solver.cpp:239] Iteration 45830 (2.95277 iter/s, 3.38666s/10 iters), loss = 9.20386
I0523 04:12:39.174660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20386 (* 1 = 9.20386 loss)
I0523 04:12:39.246495 34819 sgd_solver.cpp:112] Iteration 45830, lr = 0.01
I0523 04:12:42.342638 34819 solver.cpp:239] Iteration 45840 (3.15673 iter/s, 3.16784s/10 iters), loss = 8.79989
I0523 04:12:42.342708 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79989 (* 1 = 8.79989 loss)
I0523 04:12:43.159379 34819 sgd_solver.cpp:112] Iteration 45840, lr = 0.01
I0523 04:12:48.048836 34819 solver.cpp:239] Iteration 45850 (1.75257 iter/s, 5.7059s/10 iters), loss = 8.9872
I0523 04:12:48.048892 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9872 (* 1 = 8.9872 loss)
I0523 04:12:48.115842 34819 sgd_solver.cpp:112] Iteration 45850, lr = 0.01
I0523 04:12:54.248878 34819 solver.cpp:239] Iteration 45860 (1.61297 iter/s, 6.19973s/10 iters), loss = 8.84693
I0523 04:12:54.248946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84693 (* 1 = 8.84693 loss)
I0523 04:12:54.304651 34819 sgd_solver.cpp:112] Iteration 45860, lr = 0.01
I0523 04:12:57.892416 34819 solver.cpp:239] Iteration 45870 (2.74476 iter/s, 3.64331s/10 iters), loss = 9.09711
I0523 04:12:57.892552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09711 (* 1 = 9.09711 loss)
I0523 04:12:57.961251 34819 sgd_solver.cpp:112] Iteration 45870, lr = 0.01
I0523 04:13:01.882220 34819 solver.cpp:239] Iteration 45880 (2.50659 iter/s, 3.98949s/10 iters), loss = 8.73337
I0523 04:13:01.882273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73337 (* 1 = 8.73337 loss)
I0523 04:13:02.672108 34819 sgd_solver.cpp:112] Iteration 45880, lr = 0.01
I0523 04:13:06.037875 34819 solver.cpp:239] Iteration 45890 (2.40649 iter/s, 4.15543s/10 iters), loss = 9.5225
I0523 04:13:06.037916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.5225 (* 1 = 9.5225 loss)
I0523 04:13:06.831817 34819 sgd_solver.cpp:112] Iteration 45890, lr = 0.01
I0523 04:13:12.311483 34819 solver.cpp:239] Iteration 45900 (1.59406 iter/s, 6.2733s/10 iters), loss = 8.85949
I0523 04:13:12.311525 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85949 (* 1 = 8.85949 loss)
I0523 04:13:12.383909 34819 sgd_solver.cpp:112] Iteration 45900, lr = 0.01
I0523 04:13:18.504840 34819 solver.cpp:239] Iteration 45910 (1.61471 iter/s, 6.19305s/10 iters), loss = 8.23264
I0523 04:13:18.504884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23264 (* 1 = 8.23264 loss)
I0523 04:13:18.945562 34819 sgd_solver.cpp:112] Iteration 45910, lr = 0.01
I0523 04:13:23.731813 34819 solver.cpp:239] Iteration 45920 (1.91325 iter/s, 5.22671s/10 iters), loss = 8.90319
I0523 04:13:23.731855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90319 (* 1 = 8.90319 loss)
I0523 04:13:23.795956 34819 sgd_solver.cpp:112] Iteration 45920, lr = 0.01
I0523 04:13:27.085439 34819 solver.cpp:239] Iteration 45930 (2.98202 iter/s, 3.35343s/10 iters), loss = 9.22983
I0523 04:13:27.085480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22983 (* 1 = 9.22983 loss)
I0523 04:13:27.919178 34819 sgd_solver.cpp:112] Iteration 45930, lr = 0.01
I0523 04:13:31.495829 34819 solver.cpp:239] Iteration 45940 (2.26749 iter/s, 4.41016s/10 iters), loss = 8.71827
I0523 04:13:31.495884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71827 (* 1 = 8.71827 loss)
I0523 04:13:31.545384 34819 sgd_solver.cpp:112] Iteration 45940, lr = 0.01
I0523 04:13:35.850208 34819 solver.cpp:239] Iteration 45950 (2.29666 iter/s, 4.35415s/10 iters), loss = 9.25349
I0523 04:13:35.850250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25349 (* 1 = 9.25349 loss)
I0523 04:13:35.923606 34819 sgd_solver.cpp:112] Iteration 45950, lr = 0.01
I0523 04:13:41.058342 34819 solver.cpp:239] Iteration 45960 (1.92017 iter/s, 5.20787s/10 iters), loss = 10.3614
I0523 04:13:41.058394 34819 solver.cpp:258]     Train net output #0: softmax_loss = 10.3614 (* 1 = 10.3614 loss)
I0523 04:13:41.121398 34819 sgd_solver.cpp:112] Iteration 45960, lr = 0.01
I0523 04:13:46.098529 34819 solver.cpp:239] Iteration 45970 (1.98416 iter/s, 5.03992s/10 iters), loss = 8.79498
I0523 04:13:46.098583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79498 (* 1 = 8.79498 loss)
I0523 04:13:46.167822 34819 sgd_solver.cpp:112] Iteration 45970, lr = 0.01
I0523 04:13:49.550457 34819 solver.cpp:239] Iteration 45980 (2.8971 iter/s, 3.45172s/10 iters), loss = 7.97545
I0523 04:13:49.550505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97545 (* 1 = 7.97545 loss)
I0523 04:13:49.608119 34819 sgd_solver.cpp:112] Iteration 45980, lr = 0.01
I0523 04:13:53.811285 34819 solver.cpp:239] Iteration 45990 (2.34709 iter/s, 4.26059s/10 iters), loss = 8.88601
I0523 04:13:53.811326 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88601 (* 1 = 8.88601 loss)
I0523 04:13:53.873288 34819 sgd_solver.cpp:112] Iteration 45990, lr = 0.01
I0523 04:13:58.625039 34819 solver.cpp:239] Iteration 46000 (2.07748 iter/s, 4.81351s/10 iters), loss = 9.31401
I0523 04:13:58.625150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31401 (* 1 = 9.31401 loss)
I0523 04:13:58.707633 34819 sgd_solver.cpp:112] Iteration 46000, lr = 0.01
I0523 04:14:03.195098 34819 solver.cpp:239] Iteration 46010 (2.1883 iter/s, 4.56976s/10 iters), loss = 8.14635
I0523 04:14:03.195139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14635 (* 1 = 8.14635 loss)
I0523 04:14:03.274258 34819 sgd_solver.cpp:112] Iteration 46010, lr = 0.01
I0523 04:14:09.735865 34819 solver.cpp:239] Iteration 46020 (1.52895 iter/s, 6.54045s/10 iters), loss = 7.70469
I0523 04:14:09.735911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70469 (* 1 = 7.70469 loss)
I0523 04:14:09.804361 34819 sgd_solver.cpp:112] Iteration 46020, lr = 0.01
I0523 04:14:14.885816 34819 solver.cpp:239] Iteration 46030 (1.94187 iter/s, 5.14969s/10 iters), loss = 9.14546
I0523 04:14:14.885866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14546 (* 1 = 9.14546 loss)
I0523 04:14:15.748991 34819 sgd_solver.cpp:112] Iteration 46030, lr = 0.01
I0523 04:14:20.143999 34819 solver.cpp:239] Iteration 46040 (1.9019 iter/s, 5.25791s/10 iters), loss = 9.32647
I0523 04:14:20.144048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32647 (* 1 = 9.32647 loss)
I0523 04:14:20.208474 34819 sgd_solver.cpp:112] Iteration 46040, lr = 0.01
I0523 04:14:24.517820 34819 solver.cpp:239] Iteration 46050 (2.28645 iter/s, 4.37359s/10 iters), loss = 8.16652
I0523 04:14:24.517861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16652 (* 1 = 8.16652 loss)
I0523 04:14:24.587105 34819 sgd_solver.cpp:112] Iteration 46050, lr = 0.01
I0523 04:14:30.886250 34819 solver.cpp:239] Iteration 46060 (1.57032 iter/s, 6.36813s/10 iters), loss = 8.58897
I0523 04:14:30.886374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58897 (* 1 = 8.58897 loss)
I0523 04:14:31.505564 34819 sgd_solver.cpp:112] Iteration 46060, lr = 0.01
I0523 04:14:35.118180 34819 solver.cpp:239] Iteration 46070 (2.36315 iter/s, 4.23163s/10 iters), loss = 9.07245
I0523 04:14:35.118222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07245 (* 1 = 9.07245 loss)
I0523 04:14:35.773284 34819 sgd_solver.cpp:112] Iteration 46070, lr = 0.01
I0523 04:14:40.003252 34819 solver.cpp:239] Iteration 46080 (2.04716 iter/s, 4.88482s/10 iters), loss = 9.24117
I0523 04:14:40.003299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24117 (* 1 = 9.24117 loss)
I0523 04:14:40.060058 34819 sgd_solver.cpp:112] Iteration 46080, lr = 0.01
I0523 04:14:45.769284 34819 solver.cpp:239] Iteration 46090 (1.73438 iter/s, 5.76574s/10 iters), loss = 8.67598
I0523 04:14:45.769325 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67598 (* 1 = 8.67598 loss)
I0523 04:14:46.502214 34819 sgd_solver.cpp:112] Iteration 46090, lr = 0.01
I0523 04:14:49.917369 34819 solver.cpp:239] Iteration 46100 (2.41088 iter/s, 4.14787s/10 iters), loss = 7.74582
I0523 04:14:49.917409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74582 (* 1 = 7.74582 loss)
I0523 04:14:50.714726 34819 sgd_solver.cpp:112] Iteration 46100, lr = 0.01
I0523 04:14:55.724267 34819 solver.cpp:239] Iteration 46110 (1.72217 iter/s, 5.80662s/10 iters), loss = 9.80928
I0523 04:14:55.724308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.80928 (* 1 = 9.80928 loss)
I0523 04:14:55.782446 34819 sgd_solver.cpp:112] Iteration 46110, lr = 0.01
I0523 04:15:00.134307 34819 solver.cpp:239] Iteration 46120 (2.26767 iter/s, 4.40982s/10 iters), loss = 9.08379
I0523 04:15:00.134348 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08379 (* 1 = 9.08379 loss)
I0523 04:15:00.202494 34819 sgd_solver.cpp:112] Iteration 46120, lr = 0.01
I0523 04:15:07.006192 34819 solver.cpp:239] Iteration 46130 (1.45527 iter/s, 6.87155s/10 iters), loss = 8.7438
I0523 04:15:07.006464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7438 (* 1 = 8.7438 loss)
I0523 04:15:07.071076 34819 sgd_solver.cpp:112] Iteration 46130, lr = 0.01
I0523 04:15:10.822876 34819 solver.cpp:239] Iteration 46140 (2.62035 iter/s, 3.81628s/10 iters), loss = 8.69389
I0523 04:15:10.822921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69389 (* 1 = 8.69389 loss)
I0523 04:15:10.879521 34819 sgd_solver.cpp:112] Iteration 46140, lr = 0.01
I0523 04:15:15.601892 34819 solver.cpp:239] Iteration 46150 (2.09259 iter/s, 4.77877s/10 iters), loss = 9.66724
I0523 04:15:15.601943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.66724 (* 1 = 9.66724 loss)
I0523 04:15:16.323434 34819 sgd_solver.cpp:112] Iteration 46150, lr = 0.01
I0523 04:15:21.850196 34819 solver.cpp:239] Iteration 46160 (1.60051 iter/s, 6.24799s/10 iters), loss = 8.02359
I0523 04:15:21.850246 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02359 (* 1 = 8.02359 loss)
I0523 04:15:21.906711 34819 sgd_solver.cpp:112] Iteration 46160, lr = 0.01
I0523 04:15:25.367847 34819 solver.cpp:239] Iteration 46170 (2.84298 iter/s, 3.51744s/10 iters), loss = 8.87061
I0523 04:15:25.367904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87061 (* 1 = 8.87061 loss)
I0523 04:15:26.177906 34819 sgd_solver.cpp:112] Iteration 46170, lr = 0.01
I0523 04:15:29.608263 34819 solver.cpp:239] Iteration 46180 (2.35839 iter/s, 4.24018s/10 iters), loss = 8.28562
I0523 04:15:29.608316 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28562 (* 1 = 8.28562 loss)
I0523 04:15:30.477377 34819 sgd_solver.cpp:112] Iteration 46180, lr = 0.01
I0523 04:15:36.517514 34819 solver.cpp:239] Iteration 46190 (1.44741 iter/s, 6.90891s/10 iters), loss = 8.10589
I0523 04:15:36.517556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10589 (* 1 = 8.10589 loss)
I0523 04:15:37.112620 34819 sgd_solver.cpp:112] Iteration 46190, lr = 0.01
I0523 04:15:40.498843 34819 solver.cpp:239] Iteration 46200 (2.51186 iter/s, 3.98112s/10 iters), loss = 9.04099
I0523 04:15:40.498883 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04099 (* 1 = 9.04099 loss)
I0523 04:15:41.312707 34819 sgd_solver.cpp:112] Iteration 46200, lr = 0.01
I0523 04:15:43.612035 34819 solver.cpp:239] Iteration 46210 (3.21232 iter/s, 3.11302s/10 iters), loss = 8.54523
I0523 04:15:43.612073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54523 (* 1 = 8.54523 loss)
I0523 04:15:44.213716 34819 sgd_solver.cpp:112] Iteration 46210, lr = 0.01
I0523 04:15:49.457821 34819 solver.cpp:239] Iteration 46220 (1.71072 iter/s, 5.84551s/10 iters), loss = 8.53147
I0523 04:15:49.457864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53147 (* 1 = 8.53147 loss)
I0523 04:15:49.534704 34819 sgd_solver.cpp:112] Iteration 46220, lr = 0.01
I0523 04:15:53.875726 34819 solver.cpp:239] Iteration 46230 (2.26364 iter/s, 4.41767s/10 iters), loss = 8.92202
I0523 04:15:53.875773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92202 (* 1 = 8.92202 loss)
I0523 04:15:54.262888 34819 sgd_solver.cpp:112] Iteration 46230, lr = 0.01
I0523 04:15:56.916021 34819 solver.cpp:239] Iteration 46240 (3.28936 iter/s, 3.0401s/10 iters), loss = 9.16191
I0523 04:15:56.916070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16191 (* 1 = 9.16191 loss)
I0523 04:15:57.369554 34819 sgd_solver.cpp:112] Iteration 46240, lr = 0.01
I0523 04:16:02.042908 34819 solver.cpp:239] Iteration 46250 (1.9506 iter/s, 5.12662s/10 iters), loss = 9.12653
I0523 04:16:02.042968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12653 (* 1 = 9.12653 loss)
I0523 04:16:02.883771 34819 sgd_solver.cpp:112] Iteration 46250, lr = 0.01
I0523 04:16:08.749474 34819 solver.cpp:239] Iteration 46260 (1.49115 iter/s, 6.70623s/10 iters), loss = 8.2711
I0523 04:16:08.749653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2711 (* 1 = 8.2711 loss)
I0523 04:16:09.573140 34819 sgd_solver.cpp:112] Iteration 46260, lr = 0.01
I0523 04:16:14.332068 34819 solver.cpp:239] Iteration 46270 (1.79141 iter/s, 5.58218s/10 iters), loss = 8.64021
I0523 04:16:14.332110 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64021 (* 1 = 8.64021 loss)
I0523 04:16:15.013938 34819 sgd_solver.cpp:112] Iteration 46270, lr = 0.01
I0523 04:16:19.830265 34819 solver.cpp:239] Iteration 46280 (1.81887 iter/s, 5.49792s/10 iters), loss = 9.44345
I0523 04:16:19.830307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44345 (* 1 = 9.44345 loss)
I0523 04:16:20.518728 34819 sgd_solver.cpp:112] Iteration 46280, lr = 0.01
I0523 04:16:25.438097 34819 solver.cpp:239] Iteration 46290 (1.78331 iter/s, 5.60755s/10 iters), loss = 8.46706
I0523 04:16:25.438144 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46706 (* 1 = 8.46706 loss)
I0523 04:16:26.194571 34819 sgd_solver.cpp:112] Iteration 46290, lr = 0.01
I0523 04:16:30.982897 34819 solver.cpp:239] Iteration 46300 (1.80359 iter/s, 5.54451s/10 iters), loss = 9.18021
I0523 04:16:30.982945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18021 (* 1 = 9.18021 loss)
I0523 04:16:31.051311 34819 sgd_solver.cpp:112] Iteration 46300, lr = 0.01
I0523 04:16:35.760167 34819 solver.cpp:239] Iteration 46310 (2.09336 iter/s, 4.77701s/10 iters), loss = 8.69629
I0523 04:16:35.760217 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69629 (* 1 = 8.69629 loss)
I0523 04:16:36.463832 34819 sgd_solver.cpp:112] Iteration 46310, lr = 0.01
I0523 04:16:41.333986 34819 solver.cpp:239] Iteration 46320 (1.79419 iter/s, 5.57354s/10 iters), loss = 9.68463
I0523 04:16:41.334116 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68463 (* 1 = 9.68463 loss)
I0523 04:16:41.504386 34819 sgd_solver.cpp:112] Iteration 46320, lr = 0.01
I0523 04:16:47.942787 34819 solver.cpp:239] Iteration 46330 (1.51323 iter/s, 6.6084s/10 iters), loss = 8.94524
I0523 04:16:47.942837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94524 (* 1 = 8.94524 loss)
I0523 04:16:48.760084 34819 sgd_solver.cpp:112] Iteration 46330, lr = 0.01
I0523 04:16:52.249091 34819 solver.cpp:239] Iteration 46340 (2.3223 iter/s, 4.30608s/10 iters), loss = 9.65317
I0523 04:16:52.249132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.65317 (* 1 = 9.65317 loss)
I0523 04:16:52.324314 34819 sgd_solver.cpp:112] Iteration 46340, lr = 0.01
I0523 04:16:56.446374 34819 solver.cpp:239] Iteration 46350 (2.38262 iter/s, 4.19706s/10 iters), loss = 8.80333
I0523 04:16:56.446435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80333 (* 1 = 8.80333 loss)
I0523 04:16:56.520728 34819 sgd_solver.cpp:112] Iteration 46350, lr = 0.01
I0523 04:17:01.543581 34819 solver.cpp:239] Iteration 46360 (1.96196 iter/s, 5.09693s/10 iters), loss = 8.25368
I0523 04:17:01.543629 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25368 (* 1 = 8.25368 loss)
I0523 04:17:01.599083 34819 sgd_solver.cpp:112] Iteration 46360, lr = 0.01
I0523 04:17:05.843185 34819 solver.cpp:239] Iteration 46370 (2.32593 iter/s, 4.29936s/10 iters), loss = 8.84503
I0523 04:17:05.843271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84503 (* 1 = 8.84503 loss)
I0523 04:17:06.658671 34819 sgd_solver.cpp:112] Iteration 46370, lr = 0.01
I0523 04:17:12.465621 34819 solver.cpp:239] Iteration 46380 (1.51011 iter/s, 6.62205s/10 iters), loss = 9.56473
I0523 04:17:12.465796 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56473 (* 1 = 9.56473 loss)
I0523 04:17:12.531730 34819 sgd_solver.cpp:112] Iteration 46380, lr = 0.01
I0523 04:17:17.603484 34819 solver.cpp:239] Iteration 46390 (1.94648 iter/s, 5.13748s/10 iters), loss = 8.62776
I0523 04:17:17.603526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62776 (* 1 = 8.62776 loss)
I0523 04:17:18.441224 34819 sgd_solver.cpp:112] Iteration 46390, lr = 0.01
I0523 04:17:23.179399 34819 solver.cpp:239] Iteration 46400 (1.79351 iter/s, 5.57564s/10 iters), loss = 8.73522
I0523 04:17:23.179440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73522 (* 1 = 8.73522 loss)
I0523 04:17:23.239017 34819 sgd_solver.cpp:112] Iteration 46400, lr = 0.01
I0523 04:17:28.172492 34819 solver.cpp:239] Iteration 46410 (2.00287 iter/s, 4.99282s/10 iters), loss = 8.80412
I0523 04:17:28.172539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80412 (* 1 = 8.80412 loss)
I0523 04:17:28.702189 34819 sgd_solver.cpp:112] Iteration 46410, lr = 0.01
I0523 04:17:33.413378 34819 solver.cpp:239] Iteration 46420 (1.90817 iter/s, 5.24061s/10 iters), loss = 8.74857
I0523 04:17:33.413429 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74857 (* 1 = 8.74857 loss)
I0523 04:17:33.474381 34819 sgd_solver.cpp:112] Iteration 46420, lr = 0.01
I0523 04:17:37.654276 34819 solver.cpp:239] Iteration 46430 (2.35812 iter/s, 4.24066s/10 iters), loss = 9.16919
I0523 04:17:37.654345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16919 (* 1 = 9.16919 loss)
I0523 04:17:38.454398 34819 sgd_solver.cpp:112] Iteration 46430, lr = 0.01
I0523 04:17:43.533699 34819 solver.cpp:239] Iteration 46440 (1.70094 iter/s, 5.87911s/10 iters), loss = 8.98606
I0523 04:17:43.533871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98606 (* 1 = 8.98606 loss)
I0523 04:17:43.603437 34819 sgd_solver.cpp:112] Iteration 46440, lr = 0.01
I0523 04:17:47.366328 34819 solver.cpp:239] Iteration 46450 (2.60939 iter/s, 3.83231s/10 iters), loss = 7.98965
I0523 04:17:47.366372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98965 (* 1 = 7.98965 loss)
I0523 04:17:47.902772 34819 sgd_solver.cpp:112] Iteration 46450, lr = 0.01
I0523 04:17:52.891927 34819 solver.cpp:239] Iteration 46460 (1.80985 iter/s, 5.52531s/10 iters), loss = 8.41732
I0523 04:17:52.891983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41732 (* 1 = 8.41732 loss)
I0523 04:17:52.949422 34819 sgd_solver.cpp:112] Iteration 46460, lr = 0.01
I0523 04:17:59.017218 34819 solver.cpp:239] Iteration 46470 (1.63266 iter/s, 6.12498s/10 iters), loss = 8.78509
I0523 04:17:59.017259 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78509 (* 1 = 8.78509 loss)
I0523 04:17:59.836733 34819 sgd_solver.cpp:112] Iteration 46470, lr = 0.01
I0523 04:18:04.616432 34819 solver.cpp:239] Iteration 46480 (1.78605 iter/s, 5.59894s/10 iters), loss = 8.09578
I0523 04:18:04.616503 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09578 (* 1 = 8.09578 loss)
I0523 04:18:04.682709 34819 sgd_solver.cpp:112] Iteration 46480, lr = 0.01
I0523 04:18:09.614732 34819 solver.cpp:239] Iteration 46490 (2.00079 iter/s, 4.99802s/10 iters), loss = 8.51821
I0523 04:18:09.614778 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51821 (* 1 = 8.51821 loss)
I0523 04:18:09.673213 34819 sgd_solver.cpp:112] Iteration 46490, lr = 0.01
I0523 04:18:15.373126 34819 solver.cpp:239] Iteration 46500 (1.73669 iter/s, 5.75808s/10 iters), loss = 7.46778
I0523 04:18:15.373286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46778 (* 1 = 7.46778 loss)
I0523 04:18:15.897912 34819 sgd_solver.cpp:112] Iteration 46500, lr = 0.01
I0523 04:18:19.898594 34819 solver.cpp:239] Iteration 46510 (2.20988 iter/s, 4.52512s/10 iters), loss = 9.10919
I0523 04:18:19.898646 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10919 (* 1 = 9.10919 loss)
I0523 04:18:20.727808 34819 sgd_solver.cpp:112] Iteration 46510, lr = 0.01
I0523 04:18:25.762651 34819 solver.cpp:239] Iteration 46520 (1.70539 iter/s, 5.86376s/10 iters), loss = 8.13262
I0523 04:18:25.762723 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13262 (* 1 = 8.13262 loss)
I0523 04:18:25.832451 34819 sgd_solver.cpp:112] Iteration 46520, lr = 0.01
I0523 04:18:29.916865 34819 solver.cpp:239] Iteration 46530 (2.40733 iter/s, 4.15399s/10 iters), loss = 8.85502
I0523 04:18:29.916920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85502 (* 1 = 8.85502 loss)
I0523 04:18:29.987169 34819 sgd_solver.cpp:112] Iteration 46530, lr = 0.01
I0523 04:18:36.301028 34819 solver.cpp:239] Iteration 46540 (1.56646 iter/s, 6.38383s/10 iters), loss = 8.25684
I0523 04:18:36.301079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25684 (* 1 = 8.25684 loss)
I0523 04:18:36.850749 34819 sgd_solver.cpp:112] Iteration 46540, lr = 0.01
I0523 04:18:42.729449 34819 solver.cpp:239] Iteration 46550 (1.55567 iter/s, 6.4281s/10 iters), loss = 8.82857
I0523 04:18:42.729487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82857 (* 1 = 8.82857 loss)
I0523 04:18:42.996892 34819 sgd_solver.cpp:112] Iteration 46550, lr = 0.01
I0523 04:18:47.132032 34819 solver.cpp:239] Iteration 46560 (2.27151 iter/s, 4.40235s/10 iters), loss = 8.76841
I0523 04:18:47.132179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76841 (* 1 = 8.76841 loss)
I0523 04:18:47.915117 34819 sgd_solver.cpp:112] Iteration 46560, lr = 0.01
I0523 04:18:51.220425 34819 solver.cpp:239] Iteration 46570 (2.44614 iter/s, 4.08807s/10 iters), loss = 9.4181
I0523 04:18:51.220468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4181 (* 1 = 9.4181 loss)
I0523 04:18:51.274047 34819 sgd_solver.cpp:112] Iteration 46570, lr = 0.01
I0523 04:18:57.508687 34819 solver.cpp:239] Iteration 46580 (1.59034 iter/s, 6.28794s/10 iters), loss = 8.39644
I0523 04:18:57.508731 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39644 (* 1 = 8.39644 loss)
I0523 04:18:58.336809 34819 sgd_solver.cpp:112] Iteration 46580, lr = 0.01
I0523 04:19:04.657672 34819 solver.cpp:239] Iteration 46590 (1.39887 iter/s, 7.14865s/10 iters), loss = 8.38344
I0523 04:19:04.657712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38344 (* 1 = 8.38344 loss)
I0523 04:19:04.729145 34819 sgd_solver.cpp:112] Iteration 46590, lr = 0.01
I0523 04:19:09.472005 34819 solver.cpp:239] Iteration 46600 (2.07724 iter/s, 4.81409s/10 iters), loss = 9.00021
I0523 04:19:09.472045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00021 (* 1 = 9.00021 loss)
I0523 04:19:09.539489 34819 sgd_solver.cpp:112] Iteration 46600, lr = 0.01
I0523 04:19:15.004571 34819 solver.cpp:239] Iteration 46610 (1.80757 iter/s, 5.53229s/10 iters), loss = 8.52274
I0523 04:19:15.004609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52274 (* 1 = 8.52274 loss)
I0523 04:19:15.872874 34819 sgd_solver.cpp:112] Iteration 46610, lr = 0.01
I0523 04:19:23.720613 34819 solver.cpp:239] Iteration 46620 (1.14736 iter/s, 8.71564s/10 iters), loss = 8.89021
I0523 04:19:23.720723 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89021 (* 1 = 8.89021 loss)
I0523 04:19:23.780052 34819 sgd_solver.cpp:112] Iteration 46620, lr = 0.01
I0523 04:19:28.791451 34819 solver.cpp:239] Iteration 46630 (1.97219 iter/s, 5.07051s/10 iters), loss = 8.51025
I0523 04:19:28.791489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51025 (* 1 = 8.51025 loss)
I0523 04:19:28.849056 34819 sgd_solver.cpp:112] Iteration 46630, lr = 0.01
I0523 04:19:34.685499 34819 solver.cpp:239] Iteration 46640 (1.69671 iter/s, 5.89376s/10 iters), loss = 9.10242
I0523 04:19:34.685547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10242 (* 1 = 9.10242 loss)
I0523 04:19:35.456107 34819 sgd_solver.cpp:112] Iteration 46640, lr = 0.01
I0523 04:19:39.242363 34819 solver.cpp:239] Iteration 46650 (2.19461 iter/s, 4.55662s/10 iters), loss = 8.59642
I0523 04:19:39.242404 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59642 (* 1 = 8.59642 loss)
I0523 04:19:39.297488 34819 sgd_solver.cpp:112] Iteration 46650, lr = 0.01
I0523 04:19:43.418560 34819 solver.cpp:239] Iteration 46660 (2.39466 iter/s, 4.17596s/10 iters), loss = 8.54784
I0523 04:19:43.418612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54784 (* 1 = 8.54784 loss)
I0523 04:19:44.219055 34819 sgd_solver.cpp:112] Iteration 46660, lr = 0.01
I0523 04:19:48.791546 34819 solver.cpp:239] Iteration 46670 (1.86126 iter/s, 5.37271s/10 iters), loss = 7.92269
I0523 04:19:48.791586 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92269 (* 1 = 7.92269 loss)
I0523 04:19:49.561377 34819 sgd_solver.cpp:112] Iteration 46670, lr = 0.01
I0523 04:19:54.539620 34819 solver.cpp:239] Iteration 46680 (1.7398 iter/s, 5.74779s/10 iters), loss = 7.77146
I0523 04:19:54.539763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77146 (* 1 = 7.77146 loss)
I0523 04:19:54.614975 34819 sgd_solver.cpp:112] Iteration 46680, lr = 0.01
I0523 04:19:58.907661 34819 solver.cpp:239] Iteration 46690 (2.28953 iter/s, 4.3677s/10 iters), loss = 9.36316
I0523 04:19:58.907716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36316 (* 1 = 9.36316 loss)
I0523 04:19:58.979568 34819 sgd_solver.cpp:112] Iteration 46690, lr = 0.01
I0523 04:20:04.459869 34819 solver.cpp:239] Iteration 46700 (1.80118 iter/s, 5.55193s/10 iters), loss = 8.93733
I0523 04:20:04.459911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93733 (* 1 = 8.93733 loss)
I0523 04:20:04.656639 34819 sgd_solver.cpp:112] Iteration 46700, lr = 0.01
I0523 04:20:11.047057 34819 solver.cpp:239] Iteration 46710 (1.51817 iter/s, 6.58687s/10 iters), loss = 9.12316
I0523 04:20:11.047101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12316 (* 1 = 9.12316 loss)
I0523 04:20:11.120105 34819 sgd_solver.cpp:112] Iteration 46710, lr = 0.01
I0523 04:20:16.075327 34819 solver.cpp:239] Iteration 46720 (1.98885 iter/s, 5.02802s/10 iters), loss = 9.15099
I0523 04:20:16.075368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15099 (* 1 = 9.15099 loss)
I0523 04:20:16.141249 34819 sgd_solver.cpp:112] Iteration 46720, lr = 0.01
I0523 04:20:20.929505 34819 solver.cpp:239] Iteration 46730 (2.06019 iter/s, 4.85392s/10 iters), loss = 9.77059
I0523 04:20:20.929550 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.77059 (* 1 = 9.77059 loss)
I0523 04:20:21.726105 34819 sgd_solver.cpp:112] Iteration 46730, lr = 0.01
I0523 04:20:27.349416 34819 solver.cpp:239] Iteration 46740 (1.55773 iter/s, 6.41961s/10 iters), loss = 8.08774
I0523 04:20:27.349537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08774 (* 1 = 8.08774 loss)
I0523 04:20:27.400348 34819 sgd_solver.cpp:112] Iteration 46740, lr = 0.01
I0523 04:20:30.556078 34819 solver.cpp:239] Iteration 46750 (3.11877 iter/s, 3.20639s/10 iters), loss = 8.81001
I0523 04:20:30.556139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81001 (* 1 = 8.81001 loss)
I0523 04:20:31.251790 34819 sgd_solver.cpp:112] Iteration 46750, lr = 0.01
I0523 04:20:37.637500 34819 solver.cpp:239] Iteration 46760 (1.41221 iter/s, 7.08107s/10 iters), loss = 8.52738
I0523 04:20:37.637550 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52738 (* 1 = 8.52738 loss)
I0523 04:20:37.709532 34819 sgd_solver.cpp:112] Iteration 46760, lr = 0.01
I0523 04:20:43.367453 34819 solver.cpp:239] Iteration 46770 (1.7453 iter/s, 5.72967s/10 iters), loss = 8.58777
I0523 04:20:43.367494 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58777 (* 1 = 8.58777 loss)
I0523 04:20:44.178334 34819 sgd_solver.cpp:112] Iteration 46770, lr = 0.01
I0523 04:20:47.787463 34819 solver.cpp:239] Iteration 46780 (2.26256 iter/s, 4.41978s/10 iters), loss = 8.44288
I0523 04:20:47.787504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44288 (* 1 = 8.44288 loss)
I0523 04:20:47.861035 34819 sgd_solver.cpp:112] Iteration 46780, lr = 0.01
I0523 04:20:50.462949 34819 solver.cpp:239] Iteration 46790 (3.73786 iter/s, 2.67533s/10 iters), loss = 8.44151
I0523 04:20:50.462991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44151 (* 1 = 8.44151 loss)
I0523 04:20:50.514690 34819 sgd_solver.cpp:112] Iteration 46790, lr = 0.01
I0523 04:20:57.486968 34819 solver.cpp:239] Iteration 46800 (1.42376 iter/s, 7.02368s/10 iters), loss = 8.83041
I0523 04:20:57.487195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83041 (* 1 = 8.83041 loss)
I0523 04:20:58.266139 34819 sgd_solver.cpp:112] Iteration 46800, lr = 0.01
I0523 04:21:01.878119 34819 solver.cpp:239] Iteration 46810 (2.27751 iter/s, 4.39077s/10 iters), loss = 9.23486
I0523 04:21:01.878178 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23486 (* 1 = 9.23486 loss)
I0523 04:21:02.748971 34819 sgd_solver.cpp:112] Iteration 46810, lr = 0.01
I0523 04:21:06.981433 34819 solver.cpp:239] Iteration 46820 (1.95961 iter/s, 5.10305s/10 iters), loss = 8.37173
I0523 04:21:06.981480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37173 (* 1 = 8.37173 loss)
I0523 04:21:07.036119 34819 sgd_solver.cpp:112] Iteration 46820, lr = 0.01
I0523 04:21:11.550482 34819 solver.cpp:239] Iteration 46830 (2.18876 iter/s, 4.56881s/10 iters), loss = 8.08165
I0523 04:21:11.550534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08165 (* 1 = 8.08165 loss)
I0523 04:21:11.625553 34819 sgd_solver.cpp:112] Iteration 46830, lr = 0.01
I0523 04:21:16.245163 34819 solver.cpp:239] Iteration 46840 (2.13018 iter/s, 4.69444s/10 iters), loss = 7.50093
I0523 04:21:16.245204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50093 (* 1 = 7.50093 loss)
I0523 04:21:16.315210 34819 sgd_solver.cpp:112] Iteration 46840, lr = 0.01
I0523 04:21:19.234380 34819 solver.cpp:239] Iteration 46850 (3.34555 iter/s, 2.98904s/10 iters), loss = 7.24162
I0523 04:21:19.234424 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.24162 (* 1 = 7.24162 loss)
I0523 04:21:19.309945 34819 sgd_solver.cpp:112] Iteration 46850, lr = 0.01
I0523 04:21:21.880364 34819 solver.cpp:239] Iteration 46860 (3.77955 iter/s, 2.64582s/10 iters), loss = 9.03874
I0523 04:21:21.880421 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03874 (* 1 = 9.03874 loss)
I0523 04:21:21.938724 34819 sgd_solver.cpp:112] Iteration 46860, lr = 0.01
I0523 04:21:27.379215 34819 solver.cpp:239] Iteration 46870 (1.81866 iter/s, 5.49855s/10 iters), loss = 9.17186
I0523 04:21:27.379272 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17186 (* 1 = 9.17186 loss)
I0523 04:21:27.446846 34819 sgd_solver.cpp:112] Iteration 46870, lr = 0.01
I0523 04:21:31.429510 34819 solver.cpp:239] Iteration 46880 (2.4691 iter/s, 4.05007s/10 iters), loss = 8.35066
I0523 04:21:31.429709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35066 (* 1 = 8.35066 loss)
I0523 04:21:31.620798 34819 sgd_solver.cpp:112] Iteration 46880, lr = 0.01
I0523 04:21:37.052561 34819 solver.cpp:239] Iteration 46890 (1.77852 iter/s, 5.62265s/10 iters), loss = 7.94298
I0523 04:21:37.052603 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94298 (* 1 = 7.94298 loss)
I0523 04:21:37.115422 34819 sgd_solver.cpp:112] Iteration 46890, lr = 0.01
I0523 04:21:41.222414 34819 solver.cpp:239] Iteration 46900 (2.39832 iter/s, 4.16959s/10 iters), loss = 8.94548
I0523 04:21:41.222465 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94548 (* 1 = 8.94548 loss)
I0523 04:21:41.695085 34819 sgd_solver.cpp:112] Iteration 46900, lr = 0.01
I0523 04:21:45.033414 34819 solver.cpp:239] Iteration 46910 (2.62413 iter/s, 3.81079s/10 iters), loss = 7.95453
I0523 04:21:45.033457 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95453 (* 1 = 7.95453 loss)
I0523 04:21:45.096640 34819 sgd_solver.cpp:112] Iteration 46910, lr = 0.01
I0523 04:21:48.526821 34819 solver.cpp:239] Iteration 46920 (2.8627 iter/s, 3.4932s/10 iters), loss = 9.25054
I0523 04:21:48.526863 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25054 (* 1 = 9.25054 loss)
I0523 04:21:49.269552 34819 sgd_solver.cpp:112] Iteration 46920, lr = 0.01
I0523 04:21:54.681910 34819 solver.cpp:239] Iteration 46930 (1.62475 iter/s, 6.15478s/10 iters), loss = 8.54756
I0523 04:21:54.681959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54756 (* 1 = 8.54756 loss)
I0523 04:21:54.742033 34819 sgd_solver.cpp:112] Iteration 46930, lr = 0.01
I0523 04:21:58.707919 34819 solver.cpp:239] Iteration 46940 (2.48399 iter/s, 4.02579s/10 iters), loss = 8.99651
I0523 04:21:58.707967 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99651 (* 1 = 8.99651 loss)
I0523 04:21:58.769737 34819 sgd_solver.cpp:112] Iteration 46940, lr = 0.01
I0523 04:22:03.617480 34819 solver.cpp:239] Iteration 46950 (2.03695 iter/s, 4.90931s/10 iters), loss = 8.648
I0523 04:22:03.617604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.648 (* 1 = 8.648 loss)
I0523 04:22:03.686262 34819 sgd_solver.cpp:112] Iteration 46950, lr = 0.01
I0523 04:22:09.241436 34819 solver.cpp:239] Iteration 46960 (1.77822 iter/s, 5.62359s/10 iters), loss = 8.24442
I0523 04:22:09.241489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24442 (* 1 = 8.24442 loss)
I0523 04:22:09.309478 34819 sgd_solver.cpp:112] Iteration 46960, lr = 0.01
I0523 04:22:16.334586 34819 solver.cpp:239] Iteration 46970 (1.40988 iter/s, 7.0928s/10 iters), loss = 8.67623
I0523 04:22:16.334636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67623 (* 1 = 8.67623 loss)
I0523 04:22:16.397267 34819 sgd_solver.cpp:112] Iteration 46970, lr = 0.01
I0523 04:22:23.258814 34819 solver.cpp:239] Iteration 46980 (1.44427 iter/s, 6.92389s/10 iters), loss = 9.15271
I0523 04:22:23.258864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15271 (* 1 = 9.15271 loss)
I0523 04:22:23.920306 34819 sgd_solver.cpp:112] Iteration 46980, lr = 0.01
I0523 04:22:27.195072 34819 solver.cpp:239] Iteration 46990 (2.54063 iter/s, 3.93603s/10 iters), loss = 7.64852
I0523 04:22:27.195143 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64852 (* 1 = 7.64852 loss)
I0523 04:22:28.025074 34819 sgd_solver.cpp:112] Iteration 46990, lr = 0.01
I0523 04:22:32.156708 34819 solver.cpp:239] Iteration 47000 (2.01558 iter/s, 4.96136s/10 iters), loss = 9.78886
I0523 04:22:32.156764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.78886 (* 1 = 9.78886 loss)
I0523 04:22:32.239425 34819 sgd_solver.cpp:112] Iteration 47000, lr = 0.01
I0523 04:22:36.416844 34819 solver.cpp:239] Iteration 47010 (2.34747 iter/s, 4.2599s/10 iters), loss = 9.09896
I0523 04:22:36.417083 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09896 (* 1 = 9.09896 loss)
I0523 04:22:37.185438 34819 sgd_solver.cpp:112] Iteration 47010, lr = 0.01
I0523 04:22:39.996289 34819 solver.cpp:239] Iteration 47020 (2.79402 iter/s, 3.57908s/10 iters), loss = 8.75956
I0523 04:22:39.996342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75956 (* 1 = 8.75956 loss)
I0523 04:22:40.053326 34819 sgd_solver.cpp:112] Iteration 47020, lr = 0.01
I0523 04:22:45.952474 34819 solver.cpp:239] Iteration 47030 (1.67901 iter/s, 5.95589s/10 iters), loss = 9.22402
I0523 04:22:45.952523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22402 (* 1 = 9.22402 loss)
I0523 04:22:46.043495 34819 sgd_solver.cpp:112] Iteration 47030, lr = 0.01
I0523 04:22:50.254384 34819 solver.cpp:239] Iteration 47040 (2.32468 iter/s, 4.30167s/10 iters), loss = 8.85058
I0523 04:22:50.254444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85058 (* 1 = 8.85058 loss)
I0523 04:22:51.099158 34819 sgd_solver.cpp:112] Iteration 47040, lr = 0.01
I0523 04:22:54.449528 34819 solver.cpp:239] Iteration 47050 (2.38385 iter/s, 4.1949s/10 iters), loss = 8.39273
I0523 04:22:54.449582 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39273 (* 1 = 8.39273 loss)
I0523 04:22:54.518568 34819 sgd_solver.cpp:112] Iteration 47050, lr = 0.01
I0523 04:22:59.354080 34819 solver.cpp:239] Iteration 47060 (2.03903 iter/s, 4.9043s/10 iters), loss = 9.24804
I0523 04:22:59.354127 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24804 (* 1 = 9.24804 loss)
I0523 04:22:59.428196 34819 sgd_solver.cpp:112] Iteration 47060, lr = 0.01
I0523 04:23:04.479609 34819 solver.cpp:239] Iteration 47070 (1.95112 iter/s, 5.12525s/10 iters), loss = 8.34022
I0523 04:23:04.479666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34022 (* 1 = 8.34022 loss)
I0523 04:23:05.167290 34819 sgd_solver.cpp:112] Iteration 47070, lr = 0.01
I0523 04:23:08.432775 34819 solver.cpp:239] Iteration 47080 (2.52977 iter/s, 3.95293s/10 iters), loss = 8.49482
I0523 04:23:08.432902 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49482 (* 1 = 8.49482 loss)
I0523 04:23:09.219894 34819 sgd_solver.cpp:112] Iteration 47080, lr = 0.01
I0523 04:23:14.574337 34819 solver.cpp:239] Iteration 47090 (1.62835 iter/s, 6.14119s/10 iters), loss = 9.11504
I0523 04:23:14.574394 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11504 (* 1 = 9.11504 loss)
I0523 04:23:14.643102 34819 sgd_solver.cpp:112] Iteration 47090, lr = 0.01
I0523 04:23:19.260695 34819 solver.cpp:239] Iteration 47100 (2.13399 iter/s, 4.68606s/10 iters), loss = 9.16634
I0523 04:23:19.260756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16634 (* 1 = 9.16634 loss)
I0523 04:23:19.388835 34819 sgd_solver.cpp:112] Iteration 47100, lr = 0.01
I0523 04:23:24.872790 34819 solver.cpp:239] Iteration 47110 (1.78196 iter/s, 5.61181s/10 iters), loss = 8.29193
I0523 04:23:24.872843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29193 (* 1 = 8.29193 loss)
I0523 04:23:24.944138 34819 sgd_solver.cpp:112] Iteration 47110, lr = 0.01
I0523 04:23:29.125543 34819 solver.cpp:239] Iteration 47120 (2.35155 iter/s, 4.25252s/10 iters), loss = 9.29091
I0523 04:23:29.125586 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29091 (* 1 = 9.29091 loss)
I0523 04:23:29.179111 34819 sgd_solver.cpp:112] Iteration 47120, lr = 0.01
I0523 04:23:33.804386 34819 solver.cpp:239] Iteration 47130 (2.13739 iter/s, 4.67861s/10 iters), loss = 8.56762
I0523 04:23:33.804430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56762 (* 1 = 8.56762 loss)
I0523 04:23:33.880031 34819 sgd_solver.cpp:112] Iteration 47130, lr = 0.01
I0523 04:23:37.357209 34819 solver.cpp:239] Iteration 47140 (2.81483 iter/s, 3.55261s/10 iters), loss = 8.0582
I0523 04:23:37.357262 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0582 (* 1 = 8.0582 loss)
I0523 04:23:37.426473 34819 sgd_solver.cpp:112] Iteration 47140, lr = 0.01
I0523 04:23:40.681118 34819 solver.cpp:239] Iteration 47150 (3.00868 iter/s, 3.32372s/10 iters), loss = 8.832
I0523 04:23:40.681216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.832 (* 1 = 8.832 loss)
I0523 04:23:40.744390 34819 sgd_solver.cpp:112] Iteration 47150, lr = 0.01
I0523 04:23:45.539892 34819 solver.cpp:239] Iteration 47160 (2.05826 iter/s, 4.85847s/10 iters), loss = 8.15827
I0523 04:23:45.539947 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15827 (* 1 = 8.15827 loss)
I0523 04:23:46.371975 34819 sgd_solver.cpp:112] Iteration 47160, lr = 0.01
I0523 04:23:49.794373 34819 solver.cpp:239] Iteration 47170 (2.35059 iter/s, 4.25424s/10 iters), loss = 9.27273
I0523 04:23:49.794426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27273 (* 1 = 9.27273 loss)
I0523 04:23:49.861889 34819 sgd_solver.cpp:112] Iteration 47170, lr = 0.01
I0523 04:23:54.597322 34819 solver.cpp:239] Iteration 47180 (2.08216 iter/s, 4.8027s/10 iters), loss = 8.84999
I0523 04:23:54.597376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84999 (* 1 = 8.84999 loss)
I0523 04:23:55.426308 34819 sgd_solver.cpp:112] Iteration 47180, lr = 0.01
I0523 04:23:59.633842 34819 solver.cpp:239] Iteration 47190 (1.9856 iter/s, 5.03625s/10 iters), loss = 8.10591
I0523 04:23:59.633885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10591 (* 1 = 8.10591 loss)
I0523 04:23:59.691728 34819 sgd_solver.cpp:112] Iteration 47190, lr = 0.01
I0523 04:24:04.684866 34819 solver.cpp:239] Iteration 47200 (1.9799 iter/s, 5.05076s/10 iters), loss = 9.25328
I0523 04:24:04.684908 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25328 (* 1 = 9.25328 loss)
I0523 04:24:04.739126 34819 sgd_solver.cpp:112] Iteration 47200, lr = 0.01
I0523 04:24:09.625433 34819 solver.cpp:239] Iteration 47210 (2.02416 iter/s, 4.94031s/10 iters), loss = 8.63714
I0523 04:24:09.625488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63714 (* 1 = 8.63714 loss)
I0523 04:24:10.416523 34819 sgd_solver.cpp:112] Iteration 47210, lr = 0.01
I0523 04:24:14.552284 34819 solver.cpp:239] Iteration 47220 (2.02982 iter/s, 4.92654s/10 iters), loss = 8.37261
I0523 04:24:14.552532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37261 (* 1 = 8.37261 loss)
I0523 04:24:15.377024 34819 sgd_solver.cpp:112] Iteration 47220, lr = 0.01
I0523 04:24:21.637004 34819 solver.cpp:239] Iteration 47230 (1.41159 iter/s, 7.0842s/10 iters), loss = 8.65958
I0523 04:24:21.637071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65958 (* 1 = 8.65958 loss)
I0523 04:24:22.317711 34819 sgd_solver.cpp:112] Iteration 47230, lr = 0.01
I0523 04:24:28.294308 34819 solver.cpp:239] Iteration 47240 (1.50219 iter/s, 6.65697s/10 iters), loss = 8.901
I0523 04:24:28.294349 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.901 (* 1 = 8.901 loss)
I0523 04:24:29.136229 34819 sgd_solver.cpp:112] Iteration 47240, lr = 0.01
I0523 04:24:32.489851 34819 solver.cpp:239] Iteration 47250 (2.38361 iter/s, 4.19532s/10 iters), loss = 8.97364
I0523 04:24:32.489904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97364 (* 1 = 8.97364 loss)
I0523 04:24:32.547493 34819 sgd_solver.cpp:112] Iteration 47250, lr = 0.01
I0523 04:24:37.361694 34819 solver.cpp:239] Iteration 47260 (2.05272 iter/s, 4.87158s/10 iters), loss = 7.85475
I0523 04:24:37.361737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85475 (* 1 = 7.85475 loss)
I0523 04:24:38.189664 34819 sgd_solver.cpp:112] Iteration 47260, lr = 0.01
I0523 04:24:40.841388 34819 solver.cpp:239] Iteration 47270 (2.87398 iter/s, 3.47949s/10 iters), loss = 8.63295
I0523 04:24:40.841431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63295 (* 1 = 8.63295 loss)
I0523 04:24:41.595615 34819 sgd_solver.cpp:112] Iteration 47270, lr = 0.01
I0523 04:24:45.362548 34819 solver.cpp:239] Iteration 47280 (2.21194 iter/s, 4.52092s/10 iters), loss = 8.72439
I0523 04:24:45.362685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72439 (* 1 = 8.72439 loss)
I0523 04:24:46.241478 34819 sgd_solver.cpp:112] Iteration 47280, lr = 0.01
I0523 04:24:51.159790 34819 solver.cpp:239] Iteration 47290 (1.72507 iter/s, 5.79686s/10 iters), loss = 8.36264
I0523 04:24:51.159832 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36264 (* 1 = 8.36264 loss)
I0523 04:24:51.987201 34819 sgd_solver.cpp:112] Iteration 47290, lr = 0.01
I0523 04:24:56.995901 34819 solver.cpp:239] Iteration 47300 (1.71355 iter/s, 5.83582s/10 iters), loss = 8.67445
I0523 04:24:56.995942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67445 (* 1 = 8.67445 loss)
I0523 04:24:57.058619 34819 sgd_solver.cpp:112] Iteration 47300, lr = 0.01
I0523 04:25:02.475812 34819 solver.cpp:239] Iteration 47310 (1.82494 iter/s, 5.47963s/10 iters), loss = 9.35313
I0523 04:25:02.475853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35313 (* 1 = 9.35313 loss)
I0523 04:25:02.546962 34819 sgd_solver.cpp:112] Iteration 47310, lr = 0.01
I0523 04:25:06.883165 34819 solver.cpp:239] Iteration 47320 (2.26905 iter/s, 4.40712s/10 iters), loss = 7.6855
I0523 04:25:06.883213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6855 (* 1 = 7.6855 loss)
I0523 04:25:07.033931 34819 sgd_solver.cpp:112] Iteration 47320, lr = 0.01
I0523 04:25:14.152705 34819 solver.cpp:239] Iteration 47330 (1.37567 iter/s, 7.26918s/10 iters), loss = 9.72836
I0523 04:25:14.152756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.72836 (* 1 = 9.72836 loss)
I0523 04:25:14.863842 34819 sgd_solver.cpp:112] Iteration 47330, lr = 0.01
I0523 04:25:19.542773 34819 solver.cpp:239] Iteration 47340 (1.85536 iter/s, 5.38978s/10 iters), loss = 8.43887
I0523 04:25:19.542922 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43887 (* 1 = 8.43887 loss)
I0523 04:25:20.375397 34819 sgd_solver.cpp:112] Iteration 47340, lr = 0.01
I0523 04:25:24.361186 34819 solver.cpp:239] Iteration 47350 (2.07552 iter/s, 4.81806s/10 iters), loss = 8.20297
I0523 04:25:24.361235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20297 (* 1 = 8.20297 loss)
I0523 04:25:24.433902 34819 sgd_solver.cpp:112] Iteration 47350, lr = 0.01
I0523 04:25:29.960110 34819 solver.cpp:239] Iteration 47360 (1.78615 iter/s, 5.59864s/10 iters), loss = 9.60519
I0523 04:25:29.960152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60519 (* 1 = 9.60519 loss)
I0523 04:25:30.025815 34819 sgd_solver.cpp:112] Iteration 47360, lr = 0.01
I0523 04:25:35.819643 34819 solver.cpp:239] Iteration 47370 (1.70671 iter/s, 5.85924s/10 iters), loss = 9.06148
I0523 04:25:35.819684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06148 (* 1 = 9.06148 loss)
I0523 04:25:36.149251 34819 sgd_solver.cpp:112] Iteration 47370, lr = 0.01
I0523 04:25:41.252786 34819 solver.cpp:239] Iteration 47380 (1.84065 iter/s, 5.43288s/10 iters), loss = 9.01746
I0523 04:25:41.252836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01746 (* 1 = 9.01746 loss)
I0523 04:25:41.946467 34819 sgd_solver.cpp:112] Iteration 47380, lr = 0.01
I0523 04:25:45.319049 34819 solver.cpp:239] Iteration 47390 (2.4594 iter/s, 4.06604s/10 iters), loss = 9.25697
I0523 04:25:45.319094 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25697 (* 1 = 9.25697 loss)
I0523 04:25:46.149538 34819 sgd_solver.cpp:112] Iteration 47390, lr = 0.01
I0523 04:25:50.805817 34819 solver.cpp:239] Iteration 47400 (1.82266 iter/s, 5.4865s/10 iters), loss = 8.8126
I0523 04:25:50.805958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8126 (* 1 = 8.8126 loss)
I0523 04:25:50.874961 34819 sgd_solver.cpp:112] Iteration 47400, lr = 0.01
I0523 04:25:56.323685 34819 solver.cpp:239] Iteration 47410 (1.81242 iter/s, 5.5175s/10 iters), loss = 8.2567
I0523 04:25:56.323727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2567 (* 1 = 8.2567 loss)
I0523 04:25:57.171200 34819 sgd_solver.cpp:112] Iteration 47410, lr = 0.01
I0523 04:26:00.755220 34819 solver.cpp:239] Iteration 47420 (2.25667 iter/s, 4.4313s/10 iters), loss = 8.68058
I0523 04:26:00.755271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68058 (* 1 = 8.68058 loss)
I0523 04:26:01.309543 34819 sgd_solver.cpp:112] Iteration 47420, lr = 0.01
I0523 04:26:05.533215 34819 solver.cpp:239] Iteration 47430 (2.09304 iter/s, 4.77774s/10 iters), loss = 8.60876
I0523 04:26:05.533258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60876 (* 1 = 8.60876 loss)
I0523 04:26:06.044397 34819 sgd_solver.cpp:112] Iteration 47430, lr = 0.01
I0523 04:26:10.913111 34819 solver.cpp:239] Iteration 47440 (1.85887 iter/s, 5.3796s/10 iters), loss = 8.87586
I0523 04:26:10.913164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87586 (* 1 = 8.87586 loss)
I0523 04:26:10.968070 34819 sgd_solver.cpp:112] Iteration 47440, lr = 0.01
I0523 04:26:15.797689 34819 solver.cpp:239] Iteration 47450 (2.04737 iter/s, 4.88431s/10 iters), loss = 9.19612
I0523 04:26:15.797732 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19612 (* 1 = 9.19612 loss)
I0523 04:26:15.867846 34819 sgd_solver.cpp:112] Iteration 47450, lr = 0.01
I0523 04:26:20.980191 34819 solver.cpp:239] Iteration 47460 (1.92967 iter/s, 5.18224s/10 iters), loss = 9.0009
I0523 04:26:20.980346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0009 (* 1 = 9.0009 loss)
I0523 04:26:21.048516 34819 sgd_solver.cpp:112] Iteration 47460, lr = 0.01
I0523 04:26:25.682106 34819 solver.cpp:239] Iteration 47470 (2.12695 iter/s, 4.70156s/10 iters), loss = 8.76533
I0523 04:26:25.682148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76533 (* 1 = 8.76533 loss)
I0523 04:26:25.860093 34819 sgd_solver.cpp:112] Iteration 47470, lr = 0.01
I0523 04:26:30.835741 34819 solver.cpp:239] Iteration 47480 (1.94048 iter/s, 5.15336s/10 iters), loss = 9.39095
I0523 04:26:30.835788 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39095 (* 1 = 9.39095 loss)
I0523 04:26:31.483557 34819 sgd_solver.cpp:112] Iteration 47480, lr = 0.01
I0523 04:26:35.935127 34819 solver.cpp:239] Iteration 47490 (1.96112 iter/s, 5.09912s/10 iters), loss = 9.32155
I0523 04:26:35.935183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32155 (* 1 = 9.32155 loss)
I0523 04:26:35.995682 34819 sgd_solver.cpp:112] Iteration 47490, lr = 0.01
I0523 04:26:41.811336 34819 solver.cpp:239] Iteration 47500 (1.70186 iter/s, 5.87591s/10 iters), loss = 8.73509
I0523 04:26:41.811378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73509 (* 1 = 8.73509 loss)
I0523 04:26:41.868108 34819 sgd_solver.cpp:112] Iteration 47500, lr = 0.01
I0523 04:26:46.331710 34819 solver.cpp:239] Iteration 47510 (2.21232 iter/s, 4.52014s/10 iters), loss = 8.4003
I0523 04:26:46.331753 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4003 (* 1 = 8.4003 loss)
I0523 04:26:46.399747 34819 sgd_solver.cpp:112] Iteration 47510, lr = 0.01
I0523 04:26:51.426836 34819 solver.cpp:239] Iteration 47520 (1.96276 iter/s, 5.09486s/10 iters), loss = 9.40903
I0523 04:26:51.427042 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40903 (* 1 = 9.40903 loss)
I0523 04:26:51.502712 34819 sgd_solver.cpp:112] Iteration 47520, lr = 0.01
I0523 04:26:53.307732 34819 solver.cpp:239] Iteration 47530 (5.31738 iter/s, 1.88062s/10 iters), loss = 9.24034
I0523 04:26:53.307783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24034 (* 1 = 9.24034 loss)
I0523 04:26:54.084544 34819 sgd_solver.cpp:112] Iteration 47530, lr = 0.01
I0523 04:26:58.191238 34819 solver.cpp:239] Iteration 47540 (2.04782 iter/s, 4.88325s/10 iters), loss = 9.31892
I0523 04:26:58.191287 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31892 (* 1 = 9.31892 loss)
I0523 04:26:58.902456 34819 sgd_solver.cpp:112] Iteration 47540, lr = 0.01
I0523 04:27:02.340806 34819 solver.cpp:239] Iteration 47550 (2.41002 iter/s, 4.14934s/10 iters), loss = 8.86303
I0523 04:27:02.340849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86303 (* 1 = 8.86303 loss)
I0523 04:27:03.217473 34819 sgd_solver.cpp:112] Iteration 47550, lr = 0.01
I0523 04:27:08.812252 34819 solver.cpp:239] Iteration 47560 (1.54533 iter/s, 6.47112s/10 iters), loss = 8.69319
I0523 04:27:08.812297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69319 (* 1 = 8.69319 loss)
I0523 04:27:08.878201 34819 sgd_solver.cpp:112] Iteration 47560, lr = 0.01
I0523 04:27:14.586330 34819 solver.cpp:239] Iteration 47570 (1.73197 iter/s, 5.77379s/10 iters), loss = 9.60544
I0523 04:27:14.586370 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.60544 (* 1 = 9.60544 loss)
I0523 04:27:14.657760 34819 sgd_solver.cpp:112] Iteration 47570, lr = 0.01
I0523 04:27:18.566969 34819 solver.cpp:239] Iteration 47580 (2.51229 iter/s, 3.98043s/10 iters), loss = 7.83996
I0523 04:27:18.567025 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83996 (* 1 = 7.83996 loss)
I0523 04:27:18.635999 34819 sgd_solver.cpp:112] Iteration 47580, lr = 0.01
I0523 04:27:24.909520 34819 solver.cpp:239] Iteration 47590 (1.57673 iter/s, 6.34223s/10 iters), loss = 8.65574
I0523 04:27:24.909685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65574 (* 1 = 8.65574 loss)
I0523 04:27:25.188592 34819 sgd_solver.cpp:112] Iteration 47590, lr = 0.01
I0523 04:27:30.744717 34819 solver.cpp:239] Iteration 47600 (1.71387 iter/s, 5.83474s/10 iters), loss = 8.3417
I0523 04:27:30.744767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3417 (* 1 = 8.3417 loss)
I0523 04:27:30.797852 34819 sgd_solver.cpp:112] Iteration 47600, lr = 0.01
I0523 04:27:34.534936 34819 solver.cpp:239] Iteration 47610 (2.63852 iter/s, 3.79001s/10 iters), loss = 8.58476
I0523 04:27:34.534987 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58476 (* 1 = 8.58476 loss)
I0523 04:27:34.607492 34819 sgd_solver.cpp:112] Iteration 47610, lr = 0.01
I0523 04:27:39.677114 34819 solver.cpp:239] Iteration 47620 (1.9448 iter/s, 5.14191s/10 iters), loss = 8.81746
I0523 04:27:39.677165 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81746 (* 1 = 8.81746 loss)
I0523 04:27:39.750325 34819 sgd_solver.cpp:112] Iteration 47620, lr = 0.01
I0523 04:27:43.914096 34819 solver.cpp:239] Iteration 47630 (2.3603 iter/s, 4.23675s/10 iters), loss = 8.95566
I0523 04:27:43.914146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95566 (* 1 = 8.95566 loss)
I0523 04:27:44.725138 34819 sgd_solver.cpp:112] Iteration 47630, lr = 0.01
I0523 04:27:50.642537 34819 solver.cpp:239] Iteration 47640 (1.4863 iter/s, 6.72811s/10 iters), loss = 8.66112
I0523 04:27:50.642580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66112 (* 1 = 8.66112 loss)
I0523 04:27:50.718691 34819 sgd_solver.cpp:112] Iteration 47640, lr = 0.01
I0523 04:27:53.886764 34819 solver.cpp:239] Iteration 47650 (3.08258 iter/s, 3.24404s/10 iters), loss = 9.32734
I0523 04:27:53.886822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32734 (* 1 = 9.32734 loss)
I0523 04:27:53.954219 34819 sgd_solver.cpp:112] Iteration 47650, lr = 0.01
I0523 04:27:58.553642 34819 solver.cpp:239] Iteration 47660 (2.14288 iter/s, 4.66661s/10 iters), loss = 8.36268
I0523 04:27:58.553805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36268 (* 1 = 8.36268 loss)
I0523 04:27:58.628554 34819 sgd_solver.cpp:112] Iteration 47660, lr = 0.01
I0523 04:28:02.385162 34819 solver.cpp:239] Iteration 47670 (2.61015 iter/s, 3.8312s/10 iters), loss = 9.04669
I0523 04:28:02.385211 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04669 (* 1 = 9.04669 loss)
I0523 04:28:03.057004 34819 sgd_solver.cpp:112] Iteration 47670, lr = 0.01
I0523 04:28:06.970207 34819 solver.cpp:239] Iteration 47680 (2.18112 iter/s, 4.5848s/10 iters), loss = 8.92754
I0523 04:28:06.970248 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92754 (* 1 = 8.92754 loss)
I0523 04:28:07.047706 34819 sgd_solver.cpp:112] Iteration 47680, lr = 0.01
I0523 04:28:10.728943 34819 solver.cpp:239] Iteration 47690 (2.66062 iter/s, 3.75852s/10 iters), loss = 7.86816
I0523 04:28:10.728986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86816 (* 1 = 7.86816 loss)
I0523 04:28:11.491659 34819 sgd_solver.cpp:112] Iteration 47690, lr = 0.01
I0523 04:28:14.682116 34819 solver.cpp:239] Iteration 47700 (2.52976 iter/s, 3.95295s/10 iters), loss = 8.99424
I0523 04:28:14.682157 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99424 (* 1 = 8.99424 loss)
I0523 04:28:14.743818 34819 sgd_solver.cpp:112] Iteration 47700, lr = 0.01
I0523 04:28:18.153095 34819 solver.cpp:239] Iteration 47710 (2.8812 iter/s, 3.47078s/10 iters), loss = 8.30096
I0523 04:28:18.153136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30096 (* 1 = 8.30096 loss)
I0523 04:28:18.909080 34819 sgd_solver.cpp:112] Iteration 47710, lr = 0.01
I0523 04:28:21.695108 34819 solver.cpp:239] Iteration 47720 (2.82342 iter/s, 3.54181s/10 iters), loss = 9.40479
I0523 04:28:21.695150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40479 (* 1 = 9.40479 loss)
I0523 04:28:21.758545 34819 sgd_solver.cpp:112] Iteration 47720, lr = 0.01
I0523 04:28:26.060724 34819 solver.cpp:239] Iteration 47730 (2.29075 iter/s, 4.36538s/10 iters), loss = 9.20941
I0523 04:28:26.060765 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20941 (* 1 = 9.20941 loss)
I0523 04:28:26.718616 34819 sgd_solver.cpp:112] Iteration 47730, lr = 0.01
I0523 04:28:29.267570 34819 solver.cpp:239] Iteration 47740 (3.11851 iter/s, 3.20666s/10 iters), loss = 8.87313
I0523 04:28:29.267822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87313 (* 1 = 8.87313 loss)
I0523 04:28:30.099490 34819 sgd_solver.cpp:112] Iteration 47740, lr = 0.01
I0523 04:28:34.540294 34819 solver.cpp:239] Iteration 47750 (1.89672 iter/s, 5.27227s/10 iters), loss = 8.20651
I0523 04:28:34.540338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20651 (* 1 = 8.20651 loss)
I0523 04:28:34.993577 34819 sgd_solver.cpp:112] Iteration 47750, lr = 0.01
I0523 04:28:38.825868 34819 solver.cpp:239] Iteration 47760 (2.33353 iter/s, 4.28535s/10 iters), loss = 7.68729
I0523 04:28:38.825911 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68729 (* 1 = 7.68729 loss)
I0523 04:28:38.905169 34819 sgd_solver.cpp:112] Iteration 47760, lr = 0.01
I0523 04:28:43.288002 34819 solver.cpp:239] Iteration 47770 (2.2412 iter/s, 4.46189s/10 iters), loss = 8.06967
I0523 04:28:43.288061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06967 (* 1 = 8.06967 loss)
I0523 04:28:44.113620 34819 sgd_solver.cpp:112] Iteration 47770, lr = 0.01
I0523 04:28:49.629487 34819 solver.cpp:239] Iteration 47780 (1.577 iter/s, 6.34116s/10 iters), loss = 9.10255
I0523 04:28:49.629528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10255 (* 1 = 9.10255 loss)
I0523 04:28:49.706614 34819 sgd_solver.cpp:112] Iteration 47780, lr = 0.01
I0523 04:28:55.993273 34819 solver.cpp:239] Iteration 47790 (1.57147 iter/s, 6.36349s/10 iters), loss = 8.12208
I0523 04:28:55.993314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12208 (* 1 = 8.12208 loss)
I0523 04:28:56.055907 34819 sgd_solver.cpp:112] Iteration 47790, lr = 0.01
I0523 04:29:01.703244 34819 solver.cpp:239] Iteration 47800 (1.75141 iter/s, 5.70969s/10 iters), loss = 8.33861
I0523 04:29:01.703466 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33861 (* 1 = 8.33861 loss)
I0523 04:29:01.777868 34819 sgd_solver.cpp:112] Iteration 47800, lr = 0.01
I0523 04:29:05.573385 34819 solver.cpp:239] Iteration 47810 (2.58414 iter/s, 3.86976s/10 iters), loss = 8.02887
I0523 04:29:05.573439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02887 (* 1 = 8.02887 loss)
I0523 04:29:05.644791 34819 sgd_solver.cpp:112] Iteration 47810, lr = 0.01
I0523 04:29:10.697495 34819 solver.cpp:239] Iteration 47820 (1.95166 iter/s, 5.12385s/10 iters), loss = 9.29622
I0523 04:29:10.697536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29622 (* 1 = 9.29622 loss)
I0523 04:29:10.757277 34819 sgd_solver.cpp:112] Iteration 47820, lr = 0.01
I0523 04:29:14.089716 34819 solver.cpp:239] Iteration 47830 (2.94808 iter/s, 3.39203s/10 iters), loss = 8.55048
I0523 04:29:14.089761 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55048 (* 1 = 8.55048 loss)
I0523 04:29:14.150735 34819 sgd_solver.cpp:112] Iteration 47830, lr = 0.01
I0523 04:29:18.586518 34819 solver.cpp:239] Iteration 47840 (2.22394 iter/s, 4.49653s/10 iters), loss = 8.95154
I0523 04:29:18.586582 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95154 (* 1 = 8.95154 loss)
I0523 04:29:19.371275 34819 sgd_solver.cpp:112] Iteration 47840, lr = 0.01
I0523 04:29:22.957341 34819 solver.cpp:239] Iteration 47850 (2.28803 iter/s, 4.37057s/10 iters), loss = 9.24282
I0523 04:29:22.957391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24282 (* 1 = 9.24282 loss)
I0523 04:29:23.015578 34819 sgd_solver.cpp:112] Iteration 47850, lr = 0.01
I0523 04:29:28.777011 34819 solver.cpp:239] Iteration 47860 (1.7184 iter/s, 5.81938s/10 iters), loss = 8.55812
I0523 04:29:28.777055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55812 (* 1 = 8.55812 loss)
I0523 04:29:29.596364 34819 sgd_solver.cpp:112] Iteration 47860, lr = 0.01
I0523 04:29:34.528175 34819 solver.cpp:239] Iteration 47870 (1.73887 iter/s, 5.75087s/10 iters), loss = 9.02148
I0523 04:29:34.528439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02148 (* 1 = 9.02148 loss)
I0523 04:29:35.302707 34819 sgd_solver.cpp:112] Iteration 47870, lr = 0.01
I0523 04:29:38.707279 34819 solver.cpp:239] Iteration 47880 (2.3931 iter/s, 4.17869s/10 iters), loss = 8.8196
I0523 04:29:38.707320 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8196 (* 1 = 8.8196 loss)
I0523 04:29:38.768834 34819 sgd_solver.cpp:112] Iteration 47880, lr = 0.01
I0523 04:29:43.568943 34819 solver.cpp:239] Iteration 47890 (2.05702 iter/s, 4.86141s/10 iters), loss = 8.45746
I0523 04:29:43.568990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45746 (* 1 = 8.45746 loss)
I0523 04:29:43.636312 34819 sgd_solver.cpp:112] Iteration 47890, lr = 0.01
I0523 04:29:47.231529 34819 solver.cpp:239] Iteration 47900 (2.73046 iter/s, 3.66238s/10 iters), loss = 8.98132
I0523 04:29:47.231575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98132 (* 1 = 8.98132 loss)
I0523 04:29:47.301645 34819 sgd_solver.cpp:112] Iteration 47900, lr = 0.01
I0523 04:29:51.275526 34819 solver.cpp:239] Iteration 47910 (2.47293 iter/s, 4.04378s/10 iters), loss = 8.56789
I0523 04:29:51.275566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56789 (* 1 = 8.56789 loss)
I0523 04:29:51.333451 34819 sgd_solver.cpp:112] Iteration 47910, lr = 0.01
I0523 04:29:54.633005 34819 solver.cpp:239] Iteration 47920 (2.97861 iter/s, 3.35728s/10 iters), loss = 8.84644
I0523 04:29:54.633054 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84644 (* 1 = 8.84644 loss)
I0523 04:29:55.475745 34819 sgd_solver.cpp:112] Iteration 47920, lr = 0.01
I0523 04:29:58.626371 34819 solver.cpp:239] Iteration 47930 (2.5043 iter/s, 3.99314s/10 iters), loss = 9.00819
I0523 04:29:58.626421 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00819 (* 1 = 9.00819 loss)
I0523 04:29:58.712486 34819 sgd_solver.cpp:112] Iteration 47930, lr = 0.01
I0523 04:30:02.762485 34819 solver.cpp:239] Iteration 47940 (2.41786 iter/s, 4.13588s/10 iters), loss = 7.88232
I0523 04:30:02.762537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88232 (* 1 = 7.88232 loss)
I0523 04:30:02.817301 34819 sgd_solver.cpp:112] Iteration 47940, lr = 0.01
I0523 04:30:06.980198 34819 solver.cpp:239] Iteration 47950 (2.37109 iter/s, 4.21747s/10 iters), loss = 9.29109
I0523 04:30:06.980337 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29109 (* 1 = 9.29109 loss)
I0523 04:30:07.787525 34819 sgd_solver.cpp:112] Iteration 47950, lr = 0.01
I0523 04:30:12.466904 34819 solver.cpp:239] Iteration 47960 (1.82271 iter/s, 5.48634s/10 iters), loss = 8.65045
I0523 04:30:12.466959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65045 (* 1 = 8.65045 loss)
I0523 04:30:12.541193 34819 sgd_solver.cpp:112] Iteration 47960, lr = 0.01
I0523 04:30:17.802582 34819 solver.cpp:239] Iteration 47970 (1.87428 iter/s, 5.3354s/10 iters), loss = 9.09224
I0523 04:30:17.802631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09224 (* 1 = 9.09224 loss)
I0523 04:30:18.577270 34819 sgd_solver.cpp:112] Iteration 47970, lr = 0.01
I0523 04:30:23.391930 34819 solver.cpp:239] Iteration 47980 (1.78921 iter/s, 5.58906s/10 iters), loss = 8.38251
I0523 04:30:23.391980 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38251 (* 1 = 8.38251 loss)
I0523 04:30:23.470971 34819 sgd_solver.cpp:112] Iteration 47980, lr = 0.01
I0523 04:30:27.716171 34819 solver.cpp:239] Iteration 47990 (2.31268 iter/s, 4.324s/10 iters), loss = 8.31162
I0523 04:30:27.716223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31162 (* 1 = 8.31162 loss)
I0523 04:30:28.169081 34819 sgd_solver.cpp:112] Iteration 47990, lr = 0.01
I0523 04:30:32.232892 34819 solver.cpp:239] Iteration 48000 (2.21412 iter/s, 4.51646s/10 iters), loss = 9.42556
I0523 04:30:32.232952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42556 (* 1 = 9.42556 loss)
I0523 04:30:33.095896 34819 sgd_solver.cpp:112] Iteration 48000, lr = 0.01
I0523 04:30:38.791815 34819 solver.cpp:239] Iteration 48010 (1.52472 iter/s, 6.55859s/10 iters), loss = 8.86259
I0523 04:30:38.792117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86259 (* 1 = 8.86259 loss)
I0523 04:30:39.598572 34819 sgd_solver.cpp:112] Iteration 48010, lr = 0.01
I0523 04:30:42.924242 34819 solver.cpp:239] Iteration 48020 (2.42015 iter/s, 4.13198s/10 iters), loss = 8.94951
I0523 04:30:42.924284 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94951 (* 1 = 8.94951 loss)
I0523 04:30:42.990643 34819 sgd_solver.cpp:112] Iteration 48020, lr = 0.01
I0523 04:30:48.310597 34819 solver.cpp:239] Iteration 48030 (1.85664 iter/s, 5.38608s/10 iters), loss = 9.16192
I0523 04:30:48.310648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16192 (* 1 = 9.16192 loss)
I0523 04:30:48.361685 34819 sgd_solver.cpp:112] Iteration 48030, lr = 0.01
I0523 04:30:53.745743 34819 solver.cpp:239] Iteration 48040 (1.83997 iter/s, 5.43486s/10 iters), loss = 9.57691
I0523 04:30:53.745800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.57691 (* 1 = 9.57691 loss)
I0523 04:30:54.514961 34819 sgd_solver.cpp:112] Iteration 48040, lr = 0.01
I0523 04:30:58.707365 34819 solver.cpp:239] Iteration 48050 (2.01558 iter/s, 4.96136s/10 iters), loss = 9.67865
I0523 04:30:58.707407 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67865 (* 1 = 9.67865 loss)
I0523 04:30:58.779009 34819 sgd_solver.cpp:112] Iteration 48050, lr = 0.01
I0523 04:31:03.612673 34819 solver.cpp:239] Iteration 48060 (2.03871 iter/s, 4.90506s/10 iters), loss = 8.95897
I0523 04:31:03.612728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95897 (* 1 = 8.95897 loss)
I0523 04:31:03.678704 34819 sgd_solver.cpp:112] Iteration 48060, lr = 0.01
I0523 04:31:09.337949 34819 solver.cpp:239] Iteration 48070 (1.74673 iter/s, 5.72498s/10 iters), loss = 8.05274
I0523 04:31:09.338119 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05274 (* 1 = 8.05274 loss)
I0523 04:31:10.205713 34819 sgd_solver.cpp:112] Iteration 48070, lr = 0.01
I0523 04:31:14.894176 34819 solver.cpp:239] Iteration 48080 (1.79991 iter/s, 5.55583s/10 iters), loss = 8.61426
I0523 04:31:14.894215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61426 (* 1 = 8.61426 loss)
I0523 04:31:14.966326 34819 sgd_solver.cpp:112] Iteration 48080, lr = 0.01
I0523 04:31:19.540642 34819 solver.cpp:239] Iteration 48090 (2.15229 iter/s, 4.64622s/10 iters), loss = 9.31485
I0523 04:31:19.540693 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31485 (* 1 = 9.31485 loss)
I0523 04:31:19.616083 34819 sgd_solver.cpp:112] Iteration 48090, lr = 0.01
I0523 04:31:21.971765 34819 solver.cpp:239] Iteration 48100 (4.1136 iter/s, 2.43096s/10 iters), loss = 9.16628
I0523 04:31:21.971812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16628 (* 1 = 9.16628 loss)
I0523 04:31:22.031891 34819 sgd_solver.cpp:112] Iteration 48100, lr = 0.01
I0523 04:31:25.378924 34819 solver.cpp:239] Iteration 48110 (2.93516 iter/s, 3.40697s/10 iters), loss = 8.83093
I0523 04:31:25.378967 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83093 (* 1 = 8.83093 loss)
I0523 04:31:25.458021 34819 sgd_solver.cpp:112] Iteration 48110, lr = 0.01
I0523 04:31:32.444002 34819 solver.cpp:239] Iteration 48120 (1.41548 iter/s, 7.06475s/10 iters), loss = 8.60043
I0523 04:31:32.444044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60043 (* 1 = 8.60043 loss)
I0523 04:31:32.512753 34819 sgd_solver.cpp:112] Iteration 48120, lr = 0.01
I0523 04:31:36.439921 34819 solver.cpp:239] Iteration 48130 (2.50269 iter/s, 3.99571s/10 iters), loss = 8.79104
I0523 04:31:36.439965 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79104 (* 1 = 8.79104 loss)
I0523 04:31:36.521314 34819 sgd_solver.cpp:112] Iteration 48130, lr = 0.01
I0523 04:31:40.555683 34819 solver.cpp:239] Iteration 48140 (2.42982 iter/s, 4.11553s/10 iters), loss = 8.9533
I0523 04:31:40.555871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9533 (* 1 = 8.9533 loss)
I0523 04:31:40.626993 34819 sgd_solver.cpp:112] Iteration 48140, lr = 0.01
I0523 04:31:44.102885 34819 solver.cpp:239] Iteration 48150 (2.82287 iter/s, 3.54249s/10 iters), loss = 8.29226
I0523 04:31:44.102926 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29226 (* 1 = 8.29226 loss)
I0523 04:31:44.176323 34819 sgd_solver.cpp:112] Iteration 48150, lr = 0.01
I0523 04:31:47.523036 34819 solver.cpp:239] Iteration 48160 (2.92402 iter/s, 3.41995s/10 iters), loss = 8.73635
I0523 04:31:47.523079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73635 (* 1 = 8.73635 loss)
I0523 04:31:48.093780 34819 sgd_solver.cpp:112] Iteration 48160, lr = 0.01
I0523 04:31:51.530293 34819 solver.cpp:239] Iteration 48170 (2.49562 iter/s, 4.00702s/10 iters), loss = 8.97522
I0523 04:31:51.530349 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97522 (* 1 = 8.97522 loss)
I0523 04:31:51.592381 34819 sgd_solver.cpp:112] Iteration 48170, lr = 0.01
I0523 04:31:56.501427 34819 solver.cpp:239] Iteration 48180 (2.01172 iter/s, 4.97087s/10 iters), loss = 8.5072
I0523 04:31:56.501469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5072 (* 1 = 8.5072 loss)
I0523 04:31:56.565924 34819 sgd_solver.cpp:112] Iteration 48180, lr = 0.01
I0523 04:31:59.515384 34819 solver.cpp:239] Iteration 48190 (3.31809 iter/s, 3.01378s/10 iters), loss = 8.72261
I0523 04:31:59.515444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72261 (* 1 = 8.72261 loss)
I0523 04:32:00.116143 34819 sgd_solver.cpp:112] Iteration 48190, lr = 0.01
I0523 04:32:04.441582 34819 solver.cpp:239] Iteration 48200 (2.03007 iter/s, 4.92594s/10 iters), loss = 8.25221
I0523 04:32:04.441623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25221 (* 1 = 8.25221 loss)
I0523 04:32:04.519284 34819 sgd_solver.cpp:112] Iteration 48200, lr = 0.01
I0523 04:32:09.923955 34819 solver.cpp:239] Iteration 48210 (1.82412 iter/s, 5.4821s/10 iters), loss = 9.02414
I0523 04:32:09.924000 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02414 (* 1 = 9.02414 loss)
I0523 04:32:10.008585 34819 sgd_solver.cpp:112] Iteration 48210, lr = 0.01
I0523 04:32:15.702034 34819 solver.cpp:239] Iteration 48220 (1.73076 iter/s, 5.77779s/10 iters), loss = 8.8449
I0523 04:32:15.702224 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8449 (* 1 = 8.8449 loss)
I0523 04:32:15.782510 34819 sgd_solver.cpp:112] Iteration 48220, lr = 0.01
I0523 04:32:18.435732 34819 solver.cpp:239] Iteration 48230 (3.65843 iter/s, 2.73341s/10 iters), loss = 8.98363
I0523 04:32:18.435777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98363 (* 1 = 8.98363 loss)
I0523 04:32:18.494340 34819 sgd_solver.cpp:112] Iteration 48230, lr = 0.01
I0523 04:32:22.639650 34819 solver.cpp:239] Iteration 48240 (2.37886 iter/s, 4.20369s/10 iters), loss = 8.18403
I0523 04:32:22.639688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18403 (* 1 = 8.18403 loss)
I0523 04:32:22.700623 34819 sgd_solver.cpp:112] Iteration 48240, lr = 0.01
I0523 04:32:29.024158 34819 solver.cpp:239] Iteration 48250 (1.56637 iter/s, 6.3842s/10 iters), loss = 8.93994
I0523 04:32:29.024199 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93994 (* 1 = 8.93994 loss)
I0523 04:32:29.896554 34819 sgd_solver.cpp:112] Iteration 48250, lr = 0.01
I0523 04:32:35.202991 34819 solver.cpp:239] Iteration 48260 (1.61851 iter/s, 6.17851s/10 iters), loss = 8.95109
I0523 04:32:35.203040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95109 (* 1 = 8.95109 loss)
I0523 04:32:36.068929 34819 sgd_solver.cpp:112] Iteration 48260, lr = 0.01
I0523 04:32:40.069839 34819 solver.cpp:239] Iteration 48270 (2.05483 iter/s, 4.86659s/10 iters), loss = 8.74323
I0523 04:32:40.069882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74323 (* 1 = 8.74323 loss)
I0523 04:32:40.141366 34819 sgd_solver.cpp:112] Iteration 48270, lr = 0.01
I0523 04:32:43.538061 34819 solver.cpp:239] Iteration 48280 (2.8835 iter/s, 3.46801s/10 iters), loss = 8.75872
I0523 04:32:43.538113 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75872 (* 1 = 8.75872 loss)
I0523 04:32:44.394793 34819 sgd_solver.cpp:112] Iteration 48280, lr = 0.01
I0523 04:32:50.686347 34819 solver.cpp:239] Iteration 48290 (1.39901 iter/s, 7.14794s/10 iters), loss = 8.3239
I0523 04:32:50.686594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3239 (* 1 = 8.3239 loss)
I0523 04:32:50.750957 34819 sgd_solver.cpp:112] Iteration 48290, lr = 0.01
I0523 04:32:56.298732 34819 solver.cpp:239] Iteration 48300 (1.78192 iter/s, 5.61192s/10 iters), loss = 9.25112
I0523 04:32:56.298784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25112 (* 1 = 9.25112 loss)
I0523 04:32:56.367599 34819 sgd_solver.cpp:112] Iteration 48300, lr = 0.01
I0523 04:33:00.486330 34819 solver.cpp:239] Iteration 48310 (2.38813 iter/s, 4.18737s/10 iters), loss = 9.07978
I0523 04:33:00.486380 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07978 (* 1 = 9.07978 loss)
I0523 04:33:00.556758 34819 sgd_solver.cpp:112] Iteration 48310, lr = 0.01
I0523 04:33:05.407348 34819 solver.cpp:239] Iteration 48320 (2.03221 iter/s, 4.92076s/10 iters), loss = 9.25486
I0523 04:33:05.407389 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25486 (* 1 = 9.25486 loss)
I0523 04:33:06.229240 34819 sgd_solver.cpp:112] Iteration 48320, lr = 0.01
I0523 04:33:11.092756 34819 solver.cpp:239] Iteration 48330 (1.75897 iter/s, 5.68513s/10 iters), loss = 8.39512
I0523 04:33:11.092799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39512 (* 1 = 8.39512 loss)
I0523 04:33:11.872925 34819 sgd_solver.cpp:112] Iteration 48330, lr = 0.01
I0523 04:33:15.928799 34819 solver.cpp:239] Iteration 48340 (2.06792 iter/s, 4.83578s/10 iters), loss = 8.98268
I0523 04:33:15.928853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98268 (* 1 = 8.98268 loss)
I0523 04:33:16.685812 34819 sgd_solver.cpp:112] Iteration 48340, lr = 0.01
I0523 04:33:20.102583 34819 solver.cpp:239] Iteration 48350 (2.39604 iter/s, 4.17355s/10 iters), loss = 8.68684
I0523 04:33:20.102653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68684 (* 1 = 8.68684 loss)
I0523 04:33:20.166352 34819 sgd_solver.cpp:112] Iteration 48350, lr = 0.01
I0523 04:33:25.295218 34819 solver.cpp:239] Iteration 48360 (1.92591 iter/s, 5.19235s/10 iters), loss = 8.83207
I0523 04:33:25.295439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83207 (* 1 = 8.83207 loss)
I0523 04:33:25.360100 34819 sgd_solver.cpp:112] Iteration 48360, lr = 0.01
I0523 04:33:28.850880 34819 solver.cpp:239] Iteration 48370 (2.81269 iter/s, 3.55532s/10 iters), loss = 9.34965
I0523 04:33:28.850924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34965 (* 1 = 9.34965 loss)
I0523 04:33:28.915007 34819 sgd_solver.cpp:112] Iteration 48370, lr = 0.01
I0523 04:33:33.868692 34819 solver.cpp:239] Iteration 48380 (1.99387 iter/s, 5.01538s/10 iters), loss = 9.15678
I0523 04:33:33.868733 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15678 (* 1 = 9.15678 loss)
I0523 04:33:34.737462 34819 sgd_solver.cpp:112] Iteration 48380, lr = 0.01
I0523 04:33:41.704255 34819 solver.cpp:239] Iteration 48390 (1.27629 iter/s, 7.83519s/10 iters), loss = 8.88634
I0523 04:33:41.704301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88634 (* 1 = 8.88634 loss)
I0523 04:33:42.504179 34819 sgd_solver.cpp:112] Iteration 48390, lr = 0.01
I0523 04:33:44.957552 34819 solver.cpp:239] Iteration 48400 (3.07399 iter/s, 3.25311s/10 iters), loss = 9.18803
I0523 04:33:44.957604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18803 (* 1 = 9.18803 loss)
I0523 04:33:45.018016 34819 sgd_solver.cpp:112] Iteration 48400, lr = 0.01
I0523 04:33:49.334765 34819 solver.cpp:239] Iteration 48410 (2.28468 iter/s, 4.37697s/10 iters), loss = 7.55682
I0523 04:33:49.334815 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55682 (* 1 = 7.55682 loss)
I0523 04:33:50.106971 34819 sgd_solver.cpp:112] Iteration 48410, lr = 0.01
I0523 04:33:53.322150 34819 solver.cpp:239] Iteration 48420 (2.50804 iter/s, 3.98717s/10 iters), loss = 8.49222
I0523 04:33:53.322190 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49222 (* 1 = 8.49222 loss)
I0523 04:33:53.386626 34819 sgd_solver.cpp:112] Iteration 48420, lr = 0.01
I0523 04:33:55.948452 34819 solver.cpp:239] Iteration 48430 (3.80787 iter/s, 2.62614s/10 iters), loss = 9.15977
I0523 04:33:55.948635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15977 (* 1 = 9.15977 loss)
I0523 04:33:56.018124 34819 sgd_solver.cpp:112] Iteration 48430, lr = 0.01
I0523 04:34:00.963198 34819 solver.cpp:239] Iteration 48440 (1.99427 iter/s, 5.01436s/10 iters), loss = 8.36492
I0523 04:34:00.963243 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36492 (* 1 = 8.36492 loss)
I0523 04:34:01.759060 34819 sgd_solver.cpp:112] Iteration 48440, lr = 0.01
I0523 04:34:07.523268 34819 solver.cpp:239] Iteration 48450 (1.52445 iter/s, 6.55974s/10 iters), loss = 8.87421
I0523 04:34:07.523319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87421 (* 1 = 8.87421 loss)
I0523 04:34:07.599380 34819 sgd_solver.cpp:112] Iteration 48450, lr = 0.01
I0523 04:34:11.113059 34819 solver.cpp:239] Iteration 48460 (2.78928 iter/s, 3.58515s/10 iters), loss = 8.05742
I0523 04:34:11.113099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05742 (* 1 = 8.05742 loss)
I0523 04:34:11.188935 34819 sgd_solver.cpp:112] Iteration 48460, lr = 0.01
I0523 04:34:15.201725 34819 solver.cpp:239] Iteration 48470 (2.44592 iter/s, 4.08844s/10 iters), loss = 8.93087
I0523 04:34:15.201776 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93087 (* 1 = 8.93087 loss)
I0523 04:34:15.275084 34819 sgd_solver.cpp:112] Iteration 48470, lr = 0.01
I0523 04:34:19.434366 34819 solver.cpp:239] Iteration 48480 (2.36272 iter/s, 4.23242s/10 iters), loss = 9.12424
I0523 04:34:19.434406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12424 (* 1 = 9.12424 loss)
I0523 04:34:19.492755 34819 sgd_solver.cpp:112] Iteration 48480, lr = 0.01
I0523 04:34:24.281409 34819 solver.cpp:239] Iteration 48490 (2.06322 iter/s, 4.84678s/10 iters), loss = 8.13596
I0523 04:34:24.281464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13596 (* 1 = 8.13596 loss)
I0523 04:34:24.358204 34819 sgd_solver.cpp:112] Iteration 48490, lr = 0.01
I0523 04:34:29.749629 34819 solver.cpp:239] Iteration 48500 (1.82884 iter/s, 5.46793s/10 iters), loss = 7.705
I0523 04:34:29.749847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.705 (* 1 = 7.705 loss)
I0523 04:34:30.364665 34819 sgd_solver.cpp:112] Iteration 48500, lr = 0.01
I0523 04:34:34.512871 34819 solver.cpp:239] Iteration 48510 (2.09958 iter/s, 4.76285s/10 iters), loss = 8.69433
I0523 04:34:34.512928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69433 (* 1 = 8.69433 loss)
I0523 04:34:34.567898 34819 sgd_solver.cpp:112] Iteration 48510, lr = 0.01
I0523 04:34:39.938417 34819 solver.cpp:239] Iteration 48520 (1.84323 iter/s, 5.42526s/10 iters), loss = 8.94436
I0523 04:34:39.938470 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94436 (* 1 = 8.94436 loss)
I0523 04:34:40.013466 34819 sgd_solver.cpp:112] Iteration 48520, lr = 0.01
I0523 04:34:42.853086 34819 solver.cpp:239] Iteration 48530 (3.43114 iter/s, 2.91449s/10 iters), loss = 8.79803
I0523 04:34:42.853140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79803 (* 1 = 8.79803 loss)
I0523 04:34:42.933334 34819 sgd_solver.cpp:112] Iteration 48530, lr = 0.01
I0523 04:34:48.026337 34819 solver.cpp:239] Iteration 48540 (1.93312 iter/s, 5.17298s/10 iters), loss = 8.08297
I0523 04:34:48.026378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08297 (* 1 = 8.08297 loss)
I0523 04:34:48.092514 34819 sgd_solver.cpp:112] Iteration 48540, lr = 0.01
I0523 04:34:52.116726 34819 solver.cpp:239] Iteration 48550 (2.44489 iter/s, 4.09017s/10 iters), loss = 9.28236
I0523 04:34:52.116767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28236 (* 1 = 9.28236 loss)
I0523 04:34:52.179363 34819 sgd_solver.cpp:112] Iteration 48550, lr = 0.01
I0523 04:34:56.095293 34819 solver.cpp:239] Iteration 48560 (2.5136 iter/s, 3.97836s/10 iters), loss = 8.32856
I0523 04:34:56.095333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32856 (* 1 = 8.32856 loss)
I0523 04:34:56.943581 34819 sgd_solver.cpp:112] Iteration 48560, lr = 0.01
I0523 04:35:01.060585 34819 solver.cpp:239] Iteration 48570 (2.01409 iter/s, 4.96502s/10 iters), loss = 8.95713
I0523 04:35:01.060833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95713 (* 1 = 8.95713 loss)
I0523 04:35:01.918720 34819 sgd_solver.cpp:112] Iteration 48570, lr = 0.01
I0523 04:35:06.289079 34819 solver.cpp:239] Iteration 48580 (1.91276 iter/s, 5.22806s/10 iters), loss = 8.68437
I0523 04:35:06.289121 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68437 (* 1 = 8.68437 loss)
I0523 04:35:06.328783 34819 sgd_solver.cpp:112] Iteration 48580, lr = 0.01
I0523 04:35:09.225386 34819 solver.cpp:239] Iteration 48590 (3.40585 iter/s, 2.93612s/10 iters), loss = 8.52403
I0523 04:35:09.225440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52403 (* 1 = 8.52403 loss)
I0523 04:35:10.014621 34819 sgd_solver.cpp:112] Iteration 48590, lr = 0.01
I0523 04:35:16.395155 34819 solver.cpp:239] Iteration 48600 (1.39481 iter/s, 7.16942s/10 iters), loss = 8.21377
I0523 04:35:16.395195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21377 (* 1 = 8.21377 loss)
I0523 04:35:16.476254 34819 sgd_solver.cpp:112] Iteration 48600, lr = 0.01
I0523 04:35:22.193964 34819 solver.cpp:239] Iteration 48610 (1.72458 iter/s, 5.79853s/10 iters), loss = 9.00691
I0523 04:35:22.194005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00691 (* 1 = 9.00691 loss)
I0523 04:35:22.882910 34819 sgd_solver.cpp:112] Iteration 48610, lr = 0.01
I0523 04:35:27.274307 34819 solver.cpp:239] Iteration 48620 (1.96847 iter/s, 5.08009s/10 iters), loss = 8.74916
I0523 04:35:27.274348 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74916 (* 1 = 8.74916 loss)
I0523 04:35:27.349643 34819 sgd_solver.cpp:112] Iteration 48620, lr = 0.01
I0523 04:35:32.687479 34819 solver.cpp:239] Iteration 48630 (1.84744 iter/s, 5.41291s/10 iters), loss = 8.30045
I0523 04:35:32.687685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30045 (* 1 = 8.30045 loss)
I0523 04:35:33.275262 34819 sgd_solver.cpp:112] Iteration 48630, lr = 0.01
I0523 04:35:37.197207 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 04:35:37.292683 34819 solver.cpp:239] Iteration 48640 (2.17163 iter/s, 4.60484s/10 iters), loss = 8.83817
I0523 04:35:37.292718 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83817 (* 1 = 8.83817 loss)
I0523 04:35:37.351445 34819 sgd_solver.cpp:112] Iteration 48640, lr = 0.01
I0523 04:35:41.527889 34819 solver.cpp:239] Iteration 48650 (2.36129 iter/s, 4.23498s/10 iters), loss = 8.85475
I0523 04:35:41.527945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85475 (* 1 = 8.85475 loss)
I0523 04:35:42.316999 34819 sgd_solver.cpp:112] Iteration 48650, lr = 0.01
I0523 04:35:45.374461 34819 solver.cpp:239] Iteration 48660 (2.59987 iter/s, 3.84634s/10 iters), loss = 9.15621
I0523 04:35:45.374514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15621 (* 1 = 9.15621 loss)
I0523 04:35:45.447803 34819 sgd_solver.cpp:112] Iteration 48660, lr = 0.01
I0523 04:35:50.019495 34819 solver.cpp:239] Iteration 48670 (2.15295 iter/s, 4.64479s/10 iters), loss = 8.3197
I0523 04:35:50.019552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3197 (* 1 = 8.3197 loss)
I0523 04:35:50.093236 34819 sgd_solver.cpp:112] Iteration 48670, lr = 0.01
I0523 04:35:53.888846 34819 solver.cpp:239] Iteration 48680 (2.58457 iter/s, 3.86912s/10 iters), loss = 9.15943
I0523 04:35:53.888893 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15943 (* 1 = 9.15943 loss)
I0523 04:35:53.952625 34819 sgd_solver.cpp:112] Iteration 48680, lr = 0.01
I0523 04:35:59.021648 34819 solver.cpp:239] Iteration 48690 (1.94836 iter/s, 5.13253s/10 iters), loss = 8.37175
I0523 04:35:59.021705 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37175 (* 1 = 8.37175 loss)
I0523 04:35:59.101537 34819 sgd_solver.cpp:112] Iteration 48690, lr = 0.01
I0523 04:36:02.339215 34819 solver.cpp:239] Iteration 48700 (3.01446 iter/s, 3.31734s/10 iters), loss = 8.09636
I0523 04:36:02.339267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09636 (* 1 = 8.09636 loss)
I0523 04:36:02.414782 34819 sgd_solver.cpp:112] Iteration 48700, lr = 0.01
I0523 04:36:07.717363 34819 solver.cpp:239] Iteration 48710 (1.86098 iter/s, 5.37351s/10 iters), loss = 8.98459
I0523 04:36:07.717546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98459 (* 1 = 8.98459 loss)
I0523 04:36:07.779420 34819 sgd_solver.cpp:112] Iteration 48710, lr = 0.01
I0523 04:36:11.981057 34819 solver.cpp:239] Iteration 48720 (2.34559 iter/s, 4.26332s/10 iters), loss = 8.16636
I0523 04:36:11.981114 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16636 (* 1 = 8.16636 loss)
I0523 04:36:12.046119 34819 sgd_solver.cpp:112] Iteration 48720, lr = 0.01
I0523 04:36:16.272387 34819 solver.cpp:239] Iteration 48730 (2.33041 iter/s, 4.29109s/10 iters), loss = 8.02227
I0523 04:36:16.272439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02227 (* 1 = 8.02227 loss)
I0523 04:36:17.142858 34819 sgd_solver.cpp:112] Iteration 48730, lr = 0.01
I0523 04:36:22.248009 34819 solver.cpp:239] Iteration 48740 (1.67355 iter/s, 5.97532s/10 iters), loss = 8.96785
I0523 04:36:22.248070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96785 (* 1 = 8.96785 loss)
I0523 04:36:22.943533 34819 sgd_solver.cpp:112] Iteration 48740, lr = 0.01
I0523 04:36:27.130806 34819 solver.cpp:239] Iteration 48750 (2.04813 iter/s, 4.88251s/10 iters), loss = 8.80466
I0523 04:36:27.130869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80466 (* 1 = 8.80466 loss)
I0523 04:36:27.998538 34819 sgd_solver.cpp:112] Iteration 48750, lr = 0.01
I0523 04:36:33.611953 34819 solver.cpp:239] Iteration 48760 (1.54302 iter/s, 6.48081s/10 iters), loss = 8.89231
I0523 04:36:33.612010 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89231 (* 1 = 8.89231 loss)
I0523 04:36:34.332813 34819 sgd_solver.cpp:112] Iteration 48760, lr = 0.01
I0523 04:36:40.268146 34819 solver.cpp:239] Iteration 48770 (1.50244 iter/s, 6.65585s/10 iters), loss = 8.39651
I0523 04:36:40.268357 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39651 (* 1 = 8.39651 loss)
I0523 04:36:41.042789 34819 sgd_solver.cpp:112] Iteration 48770, lr = 0.01
I0523 04:36:46.612473 34819 solver.cpp:239] Iteration 48780 (1.57632 iter/s, 6.34388s/10 iters), loss = 8.69178
I0523 04:36:46.612519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69178 (* 1 = 8.69178 loss)
I0523 04:36:46.692678 34819 sgd_solver.cpp:112] Iteration 48780, lr = 0.01
I0523 04:36:51.937914 34819 solver.cpp:239] Iteration 48790 (1.87787 iter/s, 5.32517s/10 iters), loss = 8.48558
I0523 04:36:51.937958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48558 (* 1 = 8.48558 loss)
I0523 04:36:52.599191 34819 sgd_solver.cpp:112] Iteration 48790, lr = 0.01
I0523 04:36:57.808172 34819 solver.cpp:239] Iteration 48800 (1.70359 iter/s, 5.86997s/10 iters), loss = 9.18713
I0523 04:36:57.808213 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18713 (* 1 = 9.18713 loss)
I0523 04:36:57.878600 34819 sgd_solver.cpp:112] Iteration 48800, lr = 0.01
I0523 04:37:01.790364 34819 solver.cpp:239] Iteration 48810 (2.51132 iter/s, 3.98197s/10 iters), loss = 9.04628
I0523 04:37:01.790410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04628 (* 1 = 9.04628 loss)
I0523 04:37:02.679074 34819 sgd_solver.cpp:112] Iteration 48810, lr = 0.01
I0523 04:37:06.797317 34819 solver.cpp:239] Iteration 48820 (1.99732 iter/s, 5.0067s/10 iters), loss = 8.36773
I0523 04:37:06.797370 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36773 (* 1 = 8.36773 loss)
I0523 04:37:06.866358 34819 sgd_solver.cpp:112] Iteration 48820, lr = 0.01
I0523 04:37:11.203202 34819 solver.cpp:239] Iteration 48830 (2.26982 iter/s, 4.40564s/10 iters), loss = 8.91918
I0523 04:37:11.203461 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91918 (* 1 = 8.91918 loss)
I0523 04:37:12.038553 34819 sgd_solver.cpp:112] Iteration 48830, lr = 0.01
I0523 04:37:16.592540 34819 solver.cpp:239] Iteration 48840 (1.85567 iter/s, 5.38888s/10 iters), loss = 9.04963
I0523 04:37:16.592581 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04963 (* 1 = 9.04963 loss)
I0523 04:37:16.664571 34819 sgd_solver.cpp:112] Iteration 48840, lr = 0.01
I0523 04:37:21.506803 34819 solver.cpp:239] Iteration 48850 (2.035 iter/s, 4.91401s/10 iters), loss = 8.20941
I0523 04:37:21.506844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20941 (* 1 = 8.20941 loss)
I0523 04:37:21.571429 34819 sgd_solver.cpp:112] Iteration 48850, lr = 0.01
I0523 04:37:24.627444 34819 solver.cpp:239] Iteration 48860 (3.20466 iter/s, 3.12045s/10 iters), loss = 7.47029
I0523 04:37:24.627496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47029 (* 1 = 7.47029 loss)
I0523 04:37:24.682932 34819 sgd_solver.cpp:112] Iteration 48860, lr = 0.01
I0523 04:37:29.587188 34819 solver.cpp:239] Iteration 48870 (2.01634 iter/s, 4.95948s/10 iters), loss = 8.78602
I0523 04:37:29.587240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78602 (* 1 = 8.78602 loss)
I0523 04:37:29.702003 34819 sgd_solver.cpp:112] Iteration 48870, lr = 0.01
I0523 04:37:35.164854 34819 solver.cpp:239] Iteration 48880 (1.79296 iter/s, 5.57738s/10 iters), loss = 8.75607
I0523 04:37:35.164896 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75607 (* 1 = 8.75607 loss)
I0523 04:37:35.229696 34819 sgd_solver.cpp:112] Iteration 48880, lr = 0.01
I0523 04:37:41.885872 34819 solver.cpp:239] Iteration 48890 (1.48794 iter/s, 6.72071s/10 iters), loss = 8.22001
I0523 04:37:41.885990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22001 (* 1 = 8.22001 loss)
I0523 04:37:42.662398 34819 sgd_solver.cpp:112] Iteration 48890, lr = 0.01
I0523 04:37:46.689327 34819 solver.cpp:239] Iteration 48900 (2.08197 iter/s, 4.80314s/10 iters), loss = 8.85996
I0523 04:37:46.689373 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85996 (* 1 = 8.85996 loss)
I0523 04:37:47.569315 34819 sgd_solver.cpp:112] Iteration 48900, lr = 0.01
I0523 04:37:50.656534 34819 solver.cpp:239] Iteration 48910 (2.5208 iter/s, 3.967s/10 iters), loss = 9.14156
I0523 04:37:50.656577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14156 (* 1 = 9.14156 loss)
I0523 04:37:51.422215 34819 sgd_solver.cpp:112] Iteration 48910, lr = 0.01
I0523 04:37:55.008074 34819 solver.cpp:239] Iteration 48920 (2.29816 iter/s, 4.35132s/10 iters), loss = 8.66181
I0523 04:37:55.008112 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66181 (* 1 = 8.66181 loss)
I0523 04:37:55.065882 34819 sgd_solver.cpp:112] Iteration 48920, lr = 0.01
I0523 04:37:59.023847 34819 solver.cpp:239] Iteration 48930 (2.49031 iter/s, 4.01556s/10 iters), loss = 8.00978
I0523 04:37:59.023890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00978 (* 1 = 8.00978 loss)
I0523 04:37:59.095238 34819 sgd_solver.cpp:112] Iteration 48930, lr = 0.01
I0523 04:38:01.761500 34819 solver.cpp:239] Iteration 48940 (3.65299 iter/s, 2.73749s/10 iters), loss = 8.53989
I0523 04:38:01.761546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53989 (* 1 = 8.53989 loss)
I0523 04:38:02.595713 34819 sgd_solver.cpp:112] Iteration 48940, lr = 0.01
I0523 04:38:08.706727 34819 solver.cpp:239] Iteration 48950 (1.43991 iter/s, 6.94488s/10 iters), loss = 9.28982
I0523 04:38:08.706778 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28982 (* 1 = 9.28982 loss)
I0523 04:38:08.769672 34819 sgd_solver.cpp:112] Iteration 48950, lr = 0.01
I0523 04:38:13.649478 34819 solver.cpp:239] Iteration 48960 (2.02327 iter/s, 4.94249s/10 iters), loss = 8.48326
I0523 04:38:13.649646 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48326 (* 1 = 8.48326 loss)
I0523 04:38:13.718446 34819 sgd_solver.cpp:112] Iteration 48960, lr = 0.01
I0523 04:38:17.107431 34819 solver.cpp:239] Iteration 48970 (2.89215 iter/s, 3.45763s/10 iters), loss = 8.66237
I0523 04:38:17.107475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66237 (* 1 = 8.66237 loss)
I0523 04:38:17.173091 34819 sgd_solver.cpp:112] Iteration 48970, lr = 0.01
I0523 04:38:22.153997 34819 solver.cpp:239] Iteration 48980 (1.98165 iter/s, 5.04629s/10 iters), loss = 9.23491
I0523 04:38:22.154057 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23491 (* 1 = 9.23491 loss)
I0523 04:38:22.223179 34819 sgd_solver.cpp:112] Iteration 48980, lr = 0.01
I0523 04:38:28.609510 34819 solver.cpp:239] Iteration 48990 (1.54914 iter/s, 6.4552s/10 iters), loss = 8.88828
I0523 04:38:28.609551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88828 (* 1 = 8.88828 loss)
I0523 04:38:28.681553 34819 sgd_solver.cpp:112] Iteration 48990, lr = 0.01
I0523 04:38:32.110849 34819 solver.cpp:239] Iteration 49000 (2.85622 iter/s, 3.50114s/10 iters), loss = 8.03579
I0523 04:38:32.110890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03579 (* 1 = 8.03579 loss)
I0523 04:38:32.163111 34819 sgd_solver.cpp:112] Iteration 49000, lr = 0.01
I0523 04:38:34.355669 34819 solver.cpp:239] Iteration 49010 (4.45499 iter/s, 2.24467s/10 iters), loss = 8.45584
I0523 04:38:34.355711 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45584 (* 1 = 8.45584 loss)
I0523 04:38:34.986610 34819 sgd_solver.cpp:112] Iteration 49010, lr = 0.01
I0523 04:38:40.583142 34819 solver.cpp:239] Iteration 49020 (1.60586 iter/s, 6.22717s/10 iters), loss = 9.41262
I0523 04:38:40.583182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41262 (* 1 = 9.41262 loss)
I0523 04:38:41.358963 34819 sgd_solver.cpp:112] Iteration 49020, lr = 0.01
I0523 04:38:46.899688 34819 solver.cpp:239] Iteration 49030 (1.58322 iter/s, 6.31625s/10 iters), loss = 8.83644
I0523 04:38:46.899919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83644 (* 1 = 8.83644 loss)
I0523 04:38:47.747041 34819 sgd_solver.cpp:112] Iteration 49030, lr = 0.01
I0523 04:38:50.234589 34819 solver.cpp:239] Iteration 49040 (2.9989 iter/s, 3.33456s/10 iters), loss = 8.55549
I0523 04:38:50.234643 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55549 (* 1 = 8.55549 loss)
I0523 04:38:50.300551 34819 sgd_solver.cpp:112] Iteration 49040, lr = 0.01
I0523 04:38:55.546016 34819 solver.cpp:239] Iteration 49050 (1.88283 iter/s, 5.31115s/10 iters), loss = 9.42401
I0523 04:38:55.546066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42401 (* 1 = 9.42401 loss)
I0523 04:38:56.341212 34819 sgd_solver.cpp:112] Iteration 49050, lr = 0.01
I0523 04:38:59.443472 34819 solver.cpp:239] Iteration 49060 (2.56592 iter/s, 3.89724s/10 iters), loss = 8.94678
I0523 04:38:59.443522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94678 (* 1 = 8.94678 loss)
I0523 04:39:00.027184 34819 sgd_solver.cpp:112] Iteration 49060, lr = 0.01
I0523 04:39:04.657438 34819 solver.cpp:239] Iteration 49070 (1.91803 iter/s, 5.2137s/10 iters), loss = 9.53572
I0523 04:39:04.657512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.53572 (* 1 = 9.53572 loss)
I0523 04:39:04.720230 34819 sgd_solver.cpp:112] Iteration 49070, lr = 0.01
I0523 04:39:09.288661 34819 solver.cpp:239] Iteration 49080 (2.15938 iter/s, 4.63096s/10 iters), loss = 9.67584
I0523 04:39:09.288712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67584 (* 1 = 9.67584 loss)
I0523 04:39:09.353658 34819 sgd_solver.cpp:112] Iteration 49080, lr = 0.01
I0523 04:39:12.017729 34819 solver.cpp:239] Iteration 49090 (3.66449 iter/s, 2.72889s/10 iters), loss = 8.96502
I0523 04:39:12.017786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96502 (* 1 = 8.96502 loss)
I0523 04:39:12.080963 34819 sgd_solver.cpp:112] Iteration 49090, lr = 0.01
I0523 04:39:16.835147 34819 solver.cpp:239] Iteration 49100 (2.07591 iter/s, 4.81716s/10 iters), loss = 8.23442
I0523 04:39:16.835196 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23442 (* 1 = 8.23442 loss)
I0523 04:39:17.499583 34819 sgd_solver.cpp:112] Iteration 49100, lr = 0.01
I0523 04:39:20.049083 34819 solver.cpp:239] Iteration 49110 (3.11164 iter/s, 3.21374s/10 iters), loss = 8.74127
I0523 04:39:20.049130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74127 (* 1 = 8.74127 loss)
I0523 04:39:20.132107 34819 sgd_solver.cpp:112] Iteration 49110, lr = 0.01
I0523 04:39:25.054728 34819 solver.cpp:239] Iteration 49120 (1.99786 iter/s, 5.00535s/10 iters), loss = 8.48439
I0523 04:39:25.054791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48439 (* 1 = 8.48439 loss)
I0523 04:39:25.124840 34819 sgd_solver.cpp:112] Iteration 49120, lr = 0.01
I0523 04:39:30.814034 34819 solver.cpp:239] Iteration 49130 (1.73641 iter/s, 5.759s/10 iters), loss = 9.11456
I0523 04:39:30.814092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11456 (* 1 = 9.11456 loss)
I0523 04:39:31.647853 34819 sgd_solver.cpp:112] Iteration 49130, lr = 0.01
I0523 04:39:36.312621 34819 solver.cpp:239] Iteration 49140 (1.81874 iter/s, 5.49831s/10 iters), loss = 8.7582
I0523 04:39:36.312662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7582 (* 1 = 8.7582 loss)
I0523 04:39:36.368327 34819 sgd_solver.cpp:112] Iteration 49140, lr = 0.01
I0523 04:39:39.477181 34819 solver.cpp:239] Iteration 49150 (3.16018 iter/s, 3.16438s/10 iters), loss = 8.06553
I0523 04:39:39.477237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06553 (* 1 = 8.06553 loss)
I0523 04:39:39.557332 34819 sgd_solver.cpp:112] Iteration 49150, lr = 0.01
I0523 04:39:42.868683 34819 solver.cpp:239] Iteration 49160 (2.94872 iter/s, 3.3913s/10 iters), loss = 8.27276
I0523 04:39:42.868722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27276 (* 1 = 8.27276 loss)
I0523 04:39:43.588709 34819 sgd_solver.cpp:112] Iteration 49160, lr = 0.01
I0523 04:39:47.572172 34819 solver.cpp:239] Iteration 49170 (2.12619 iter/s, 4.70325s/10 iters), loss = 8.80883
I0523 04:39:47.572290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80883 (* 1 = 8.80883 loss)
I0523 04:39:47.637326 34819 sgd_solver.cpp:112] Iteration 49170, lr = 0.01
I0523 04:39:51.826658 34819 solver.cpp:239] Iteration 49180 (2.35062 iter/s, 4.25419s/10 iters), loss = 8.9983
I0523 04:39:51.826712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9983 (* 1 = 8.9983 loss)
I0523 04:39:52.673441 34819 sgd_solver.cpp:112] Iteration 49180, lr = 0.01
I0523 04:39:57.157409 34819 solver.cpp:239] Iteration 49190 (1.87601 iter/s, 5.33046s/10 iters), loss = 8.09681
I0523 04:39:57.157466 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09681 (* 1 = 8.09681 loss)
I0523 04:39:57.230651 34819 sgd_solver.cpp:112] Iteration 49190, lr = 0.01
I0523 04:40:00.553854 34819 solver.cpp:239] Iteration 49200 (2.94443 iter/s, 3.39624s/10 iters), loss = 8.90572
I0523 04:40:00.553897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90572 (* 1 = 8.90572 loss)
I0523 04:40:01.428053 34819 sgd_solver.cpp:112] Iteration 49200, lr = 0.01
I0523 04:40:06.260337 34819 solver.cpp:239] Iteration 49210 (1.75248 iter/s, 5.7062s/10 iters), loss = 8.00298
I0523 04:40:06.260391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00298 (* 1 = 8.00298 loss)
I0523 04:40:06.343508 34819 sgd_solver.cpp:112] Iteration 49210, lr = 0.01
I0523 04:40:10.364053 34819 solver.cpp:239] Iteration 49220 (2.43695 iter/s, 4.10348s/10 iters), loss = 7.98443
I0523 04:40:10.364095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98443 (* 1 = 7.98443 loss)
I0523 04:40:10.434756 34819 sgd_solver.cpp:112] Iteration 49220, lr = 0.01
I0523 04:40:13.833760 34819 solver.cpp:239] Iteration 49230 (2.88225 iter/s, 3.46952s/10 iters), loss = 8.37713
I0523 04:40:13.833804 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37713 (* 1 = 8.37713 loss)
I0523 04:40:13.895114 34819 sgd_solver.cpp:112] Iteration 49230, lr = 0.01
I0523 04:40:18.131533 34819 solver.cpp:239] Iteration 49240 (2.32692 iter/s, 4.29752s/10 iters), loss = 8.9984
I0523 04:40:18.131805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9984 (* 1 = 8.9984 loss)
I0523 04:40:18.878140 34819 sgd_solver.cpp:112] Iteration 49240, lr = 0.01
I0523 04:40:22.231657 34819 solver.cpp:239] Iteration 49250 (2.43921 iter/s, 4.09969s/10 iters), loss = 9.02196
I0523 04:40:22.231709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02196 (* 1 = 9.02196 loss)
I0523 04:40:22.309751 34819 sgd_solver.cpp:112] Iteration 49250, lr = 0.01
I0523 04:40:27.104502 34819 solver.cpp:239] Iteration 49260 (2.0523 iter/s, 4.87259s/10 iters), loss = 7.87053
I0523 04:40:27.104544 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87053 (* 1 = 7.87053 loss)
I0523 04:40:27.902441 34819 sgd_solver.cpp:112] Iteration 49260, lr = 0.01
I0523 04:40:32.026149 34819 solver.cpp:239] Iteration 49270 (2.03195 iter/s, 4.92139s/10 iters), loss = 8.39983
I0523 04:40:32.026193 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39983 (* 1 = 8.39983 loss)
I0523 04:40:32.565219 34819 sgd_solver.cpp:112] Iteration 49270, lr = 0.01
I0523 04:40:37.395836 34819 solver.cpp:239] Iteration 49280 (1.8624 iter/s, 5.36942s/10 iters), loss = 8.92466
I0523 04:40:37.395881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92466 (* 1 = 8.92466 loss)
I0523 04:40:37.586180 34819 sgd_solver.cpp:112] Iteration 49280, lr = 0.01
I0523 04:40:40.217010 34819 solver.cpp:239] Iteration 49290 (3.54488 iter/s, 2.82097s/10 iters), loss = 9.29114
I0523 04:40:40.217061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29114 (* 1 = 9.29114 loss)
I0523 04:40:40.268332 34819 sgd_solver.cpp:112] Iteration 49290, lr = 0.01
I0523 04:40:44.115617 34819 solver.cpp:239] Iteration 49300 (2.56517 iter/s, 3.89838s/10 iters), loss = 8.81385
I0523 04:40:44.115664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81385 (* 1 = 8.81385 loss)
I0523 04:40:44.716640 34819 sgd_solver.cpp:112] Iteration 49300, lr = 0.01
I0523 04:40:48.198683 34819 solver.cpp:239] Iteration 49310 (2.44927 iter/s, 4.08284s/10 iters), loss = 7.52177
I0523 04:40:48.198896 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52177 (* 1 = 7.52177 loss)
I0523 04:40:48.266605 34819 sgd_solver.cpp:112] Iteration 49310, lr = 0.01
I0523 04:40:53.455248 34819 solver.cpp:239] Iteration 49320 (1.90254 iter/s, 5.25612s/10 iters), loss = 8.81564
I0523 04:40:53.455304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81564 (* 1 = 8.81564 loss)
I0523 04:40:54.266422 34819 sgd_solver.cpp:112] Iteration 49320, lr = 0.01
I0523 04:40:58.205289 34819 solver.cpp:239] Iteration 49330 (2.10536 iter/s, 4.74979s/10 iters), loss = 8.7765
I0523 04:40:58.205343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7765 (* 1 = 8.7765 loss)
I0523 04:40:58.278028 34819 sgd_solver.cpp:112] Iteration 49330, lr = 0.01
I0523 04:41:03.403273 34819 solver.cpp:239] Iteration 49340 (1.92392 iter/s, 5.19771s/10 iters), loss = 8.53924
I0523 04:41:03.403314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53924 (* 1 = 8.53924 loss)
I0523 04:41:03.464779 34819 sgd_solver.cpp:112] Iteration 49340, lr = 0.01
I0523 04:41:07.991574 34819 solver.cpp:239] Iteration 49350 (2.17957 iter/s, 4.58806s/10 iters), loss = 9.1588
I0523 04:41:07.991634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1588 (* 1 = 9.1588 loss)
I0523 04:41:08.055891 34819 sgd_solver.cpp:112] Iteration 49350, lr = 0.01
I0523 04:41:14.156011 34819 solver.cpp:239] Iteration 49360 (1.62229 iter/s, 6.16412s/10 iters), loss = 8.6271
I0523 04:41:14.156056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6271 (* 1 = 8.6271 loss)
I0523 04:41:14.225289 34819 sgd_solver.cpp:112] Iteration 49360, lr = 0.01
I0523 04:41:18.866061 34819 solver.cpp:239] Iteration 49370 (2.12323 iter/s, 4.70981s/10 iters), loss = 8.5847
I0523 04:41:18.866227 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5847 (* 1 = 8.5847 loss)
I0523 04:41:18.928221 34819 sgd_solver.cpp:112] Iteration 49370, lr = 0.01
I0523 04:41:22.990773 34819 solver.cpp:239] Iteration 49380 (2.42461 iter/s, 4.12438s/10 iters), loss = 8.38421
I0523 04:41:22.990823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38421 (* 1 = 8.38421 loss)
I0523 04:41:23.071836 34819 sgd_solver.cpp:112] Iteration 49380, lr = 0.01
I0523 04:41:27.459616 34819 solver.cpp:239] Iteration 49390 (2.23783 iter/s, 4.46861s/10 iters), loss = 8.31455
I0523 04:41:27.459666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31455 (* 1 = 8.31455 loss)
I0523 04:41:27.534215 34819 sgd_solver.cpp:112] Iteration 49390, lr = 0.01
I0523 04:41:34.093626 34819 solver.cpp:239] Iteration 49400 (1.50746 iter/s, 6.63369s/10 iters), loss = 9.34154
I0523 04:41:34.093667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34154 (* 1 = 9.34154 loss)
I0523 04:41:34.923429 34819 sgd_solver.cpp:112] Iteration 49400, lr = 0.01
I0523 04:41:38.838177 34819 solver.cpp:239] Iteration 49410 (2.1078 iter/s, 4.74429s/10 iters), loss = 8.47819
I0523 04:41:38.838238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47819 (* 1 = 8.47819 loss)
I0523 04:41:39.667870 34819 sgd_solver.cpp:112] Iteration 49410, lr = 0.01
I0523 04:41:42.911453 34819 solver.cpp:239] Iteration 49420 (2.45517 iter/s, 4.07304s/10 iters), loss = 8.19405
I0523 04:41:42.911509 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19405 (* 1 = 8.19405 loss)
I0523 04:41:43.780529 34819 sgd_solver.cpp:112] Iteration 49420, lr = 0.01
I0523 04:41:49.719985 34819 solver.cpp:239] Iteration 49430 (1.46882 iter/s, 6.80819s/10 iters), loss = 8.6561
I0523 04:41:49.720206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6561 (* 1 = 8.6561 loss)
I0523 04:41:50.489516 34819 sgd_solver.cpp:112] Iteration 49430, lr = 0.01
I0523 04:41:54.654498 34819 solver.cpp:239] Iteration 49440 (2.02671 iter/s, 4.9341s/10 iters), loss = 9.56345
I0523 04:41:54.654551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56345 (* 1 = 9.56345 loss)
I0523 04:41:54.710983 34819 sgd_solver.cpp:112] Iteration 49440, lr = 0.01
I0523 04:41:59.458509 34819 solver.cpp:239] Iteration 49450 (2.08171 iter/s, 4.80375s/10 iters), loss = 8.97544
I0523 04:41:59.458552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97544 (* 1 = 8.97544 loss)
I0523 04:42:00.185236 34819 sgd_solver.cpp:112] Iteration 49450, lr = 0.01
I0523 04:42:05.330286 34819 solver.cpp:239] Iteration 49460 (1.70315 iter/s, 5.87147s/10 iters), loss = 8.57122
I0523 04:42:05.330339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57122 (* 1 = 8.57122 loss)
I0523 04:42:05.389233 34819 sgd_solver.cpp:112] Iteration 49460, lr = 0.01
I0523 04:42:09.468411 34819 solver.cpp:239] Iteration 49470 (2.41668 iter/s, 4.1379s/10 iters), loss = 8.36456
I0523 04:42:09.468462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36456 (* 1 = 8.36456 loss)
I0523 04:42:09.545400 34819 sgd_solver.cpp:112] Iteration 49470, lr = 0.01
I0523 04:42:14.544334 34819 solver.cpp:239] Iteration 49480 (1.97019 iter/s, 5.07565s/10 iters), loss = 9.41176
I0523 04:42:14.544383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41176 (* 1 = 9.41176 loss)
I0523 04:42:14.620824 34819 sgd_solver.cpp:112] Iteration 49480, lr = 0.01
I0523 04:42:20.050225 34819 solver.cpp:239] Iteration 49490 (1.81633 iter/s, 5.50561s/10 iters), loss = 8.37805
I0523 04:42:20.050362 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37805 (* 1 = 8.37805 loss)
I0523 04:42:20.886163 34819 sgd_solver.cpp:112] Iteration 49490, lr = 0.01
I0523 04:42:25.398212 34819 solver.cpp:239] Iteration 49500 (1.86999 iter/s, 5.34763s/10 iters), loss = 8.64547
I0523 04:42:25.398254 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64547 (* 1 = 8.64547 loss)
I0523 04:42:25.474503 34819 sgd_solver.cpp:112] Iteration 49500, lr = 0.01
I0523 04:42:29.748706 34819 solver.cpp:239] Iteration 49510 (2.29871 iter/s, 4.35026s/10 iters), loss = 7.98377
I0523 04:42:29.748750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98377 (* 1 = 7.98377 loss)
I0523 04:42:29.817107 34819 sgd_solver.cpp:112] Iteration 49510, lr = 0.01
I0523 04:42:35.163298 34819 solver.cpp:239] Iteration 49520 (1.84696 iter/s, 5.4143s/10 iters), loss = 9.64271
I0523 04:42:35.163347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64271 (* 1 = 9.64271 loss)
I0523 04:42:35.903185 34819 sgd_solver.cpp:112] Iteration 49520, lr = 0.01
I0523 04:42:40.149313 34819 solver.cpp:239] Iteration 49530 (2.00572 iter/s, 4.98575s/10 iters), loss = 8.27221
I0523 04:42:40.149354 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27221 (* 1 = 8.27221 loss)
I0523 04:42:40.212420 34819 sgd_solver.cpp:112] Iteration 49530, lr = 0.01
I0523 04:42:45.667173 34819 solver.cpp:239] Iteration 49540 (1.81239 iter/s, 5.51759s/10 iters), loss = 9.22186
I0523 04:42:45.667215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22186 (* 1 = 9.22186 loss)
I0523 04:42:46.442881 34819 sgd_solver.cpp:112] Iteration 49540, lr = 0.01
I0523 04:42:51.404604 34819 solver.cpp:239] Iteration 49550 (1.74302 iter/s, 5.73716s/10 iters), loss = 8.20372
I0523 04:42:51.404822 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20372 (* 1 = 8.20372 loss)
I0523 04:42:51.469930 34819 sgd_solver.cpp:112] Iteration 49550, lr = 0.01
I0523 04:42:55.889494 34819 solver.cpp:239] Iteration 49560 (2.2299 iter/s, 4.4845s/10 iters), loss = 7.83295
I0523 04:42:55.889546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83295 (* 1 = 7.83295 loss)
I0523 04:42:55.970382 34819 sgd_solver.cpp:112] Iteration 49560, lr = 0.01
I0523 04:43:00.661056 34819 solver.cpp:239] Iteration 49570 (2.09586 iter/s, 4.77131s/10 iters), loss = 8.7055
I0523 04:43:00.661098 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7055 (* 1 = 8.7055 loss)
I0523 04:43:00.732542 34819 sgd_solver.cpp:112] Iteration 49570, lr = 0.01
I0523 04:43:03.374083 34819 solver.cpp:239] Iteration 49580 (3.68615 iter/s, 2.71286s/10 iters), loss = 8.3773
I0523 04:43:03.374136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3773 (* 1 = 8.3773 loss)
I0523 04:43:04.202013 34819 sgd_solver.cpp:112] Iteration 49580, lr = 0.01
I0523 04:43:07.476792 34819 solver.cpp:239] Iteration 49590 (2.43755 iter/s, 4.10249s/10 iters), loss = 8.71776
I0523 04:43:07.476835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71776 (* 1 = 8.71776 loss)
I0523 04:43:07.560490 34819 sgd_solver.cpp:112] Iteration 49590, lr = 0.01
I0523 04:43:12.154633 34819 solver.cpp:239] Iteration 49600 (2.13786 iter/s, 4.67758s/10 iters), loss = 8.38867
I0523 04:43:12.154685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38867 (* 1 = 8.38867 loss)
I0523 04:43:12.972122 34819 sgd_solver.cpp:112] Iteration 49600, lr = 0.01
I0523 04:43:19.503294 34819 solver.cpp:239] Iteration 49610 (1.36086 iter/s, 7.34831s/10 iters), loss = 8.37718
I0523 04:43:19.503345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37718 (* 1 = 8.37718 loss)
I0523 04:43:19.559478 34819 sgd_solver.cpp:112] Iteration 49610, lr = 0.01
I0523 04:43:23.643532 34819 solver.cpp:239] Iteration 49620 (2.41546 iter/s, 4.14001s/10 iters), loss = 8.42141
I0523 04:43:23.643733 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42141 (* 1 = 8.42141 loss)
I0523 04:43:23.725811 34819 sgd_solver.cpp:112] Iteration 49620, lr = 0.01
I0523 04:43:26.593847 34819 solver.cpp:239] Iteration 49630 (3.38983 iter/s, 2.95s/10 iters), loss = 9.41596
I0523 04:43:26.593889 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41596 (* 1 = 9.41596 loss)
I0523 04:43:26.661964 34819 sgd_solver.cpp:112] Iteration 49630, lr = 0.01
I0523 04:43:31.881001 34819 solver.cpp:239] Iteration 49640 (1.89147 iter/s, 5.28688s/10 iters), loss = 8.56975
I0523 04:43:31.881047 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56975 (* 1 = 8.56975 loss)
I0523 04:43:31.976586 34819 sgd_solver.cpp:112] Iteration 49640, lr = 0.01
I0523 04:43:37.451743 34819 solver.cpp:239] Iteration 49650 (1.79519 iter/s, 5.57045s/10 iters), loss = 8.83572
I0523 04:43:37.451802 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83572 (* 1 = 8.83572 loss)
I0523 04:43:37.522742 34819 sgd_solver.cpp:112] Iteration 49650, lr = 0.01
I0523 04:43:42.299458 34819 solver.cpp:239] Iteration 49660 (2.06294 iter/s, 4.84744s/10 iters), loss = 8.73529
I0523 04:43:42.299511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73529 (* 1 = 8.73529 loss)
I0523 04:43:42.368146 34819 sgd_solver.cpp:112] Iteration 49660, lr = 0.01
I0523 04:43:48.503007 34819 solver.cpp:239] Iteration 49670 (1.61206 iter/s, 6.20325s/10 iters), loss = 8.21758
I0523 04:43:48.503049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21758 (* 1 = 8.21758 loss)
I0523 04:43:48.577976 34819 sgd_solver.cpp:112] Iteration 49670, lr = 0.01
I0523 04:43:53.321981 34819 solver.cpp:239] Iteration 49680 (2.07525 iter/s, 4.8187s/10 iters), loss = 8.69669
I0523 04:43:53.322044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69669 (* 1 = 8.69669 loss)
I0523 04:43:54.140075 34819 sgd_solver.cpp:112] Iteration 49680, lr = 0.01
I0523 04:43:59.040472 34819 solver.cpp:239] Iteration 49690 (1.7488 iter/s, 5.71819s/10 iters), loss = 8.78012
I0523 04:43:59.040524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78012 (* 1 = 8.78012 loss)
I0523 04:43:59.100035 34819 sgd_solver.cpp:112] Iteration 49690, lr = 0.01
I0523 04:44:03.950337 34819 solver.cpp:239] Iteration 49700 (2.03683 iter/s, 4.9096s/10 iters), loss = 9.40589
I0523 04:44:03.950392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40589 (* 1 = 9.40589 loss)
I0523 04:44:04.030179 34819 sgd_solver.cpp:112] Iteration 49700, lr = 0.01
I0523 04:44:07.639534 34819 solver.cpp:239] Iteration 49710 (2.71079 iter/s, 3.68896s/10 iters), loss = 8.7511
I0523 04:44:07.639598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7511 (* 1 = 8.7511 loss)
I0523 04:44:08.441275 34819 sgd_solver.cpp:112] Iteration 49710, lr = 0.01
I0523 04:44:13.298650 34819 solver.cpp:239] Iteration 49720 (1.76716 iter/s, 5.65879s/10 iters), loss = 7.69375
I0523 04:44:13.298715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69375 (* 1 = 7.69375 loss)
I0523 04:44:14.074436 34819 sgd_solver.cpp:112] Iteration 49720, lr = 0.01
I0523 04:44:20.006289 34819 solver.cpp:239] Iteration 49730 (1.49091 iter/s, 6.70732s/10 iters), loss = 8.64235
I0523 04:44:20.006331 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64235 (* 1 = 8.64235 loss)
I0523 04:44:20.799324 34819 sgd_solver.cpp:112] Iteration 49730, lr = 0.01
I0523 04:44:24.571292 34819 solver.cpp:239] Iteration 49740 (2.19069 iter/s, 4.56477s/10 iters), loss = 8.52755
I0523 04:44:24.571419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52755 (* 1 = 8.52755 loss)
I0523 04:44:24.639539 34819 sgd_solver.cpp:112] Iteration 49740, lr = 0.01
I0523 04:44:30.331197 34819 solver.cpp:239] Iteration 49750 (1.73699 iter/s, 5.7571s/10 iters), loss = 8.74744
I0523 04:44:30.331249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74744 (* 1 = 8.74744 loss)
I0523 04:44:31.027623 34819 sgd_solver.cpp:112] Iteration 49750, lr = 0.01
I0523 04:44:36.991325 34819 solver.cpp:239] Iteration 49760 (1.50155 iter/s, 6.65978s/10 iters), loss = 8.56508
I0523 04:44:36.991379 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56508 (* 1 = 8.56508 loss)
I0523 04:44:37.774174 34819 sgd_solver.cpp:112] Iteration 49760, lr = 0.01
I0523 04:44:41.549690 34819 solver.cpp:239] Iteration 49770 (2.19389 iter/s, 4.55811s/10 iters), loss = 8.98345
I0523 04:44:41.549741 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98345 (* 1 = 8.98345 loss)
I0523 04:44:42.398211 34819 sgd_solver.cpp:112] Iteration 49770, lr = 0.01
I0523 04:44:46.927531 34819 solver.cpp:239] Iteration 49780 (1.85958 iter/s, 5.37756s/10 iters), loss = 8.04701
I0523 04:44:46.927595 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04701 (* 1 = 8.04701 loss)
I0523 04:44:47.744854 34819 sgd_solver.cpp:112] Iteration 49780, lr = 0.01
I0523 04:44:52.505211 34819 solver.cpp:239] Iteration 49790 (1.79296 iter/s, 5.57738s/10 iters), loss = 8.54285
I0523 04:44:52.505266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54285 (* 1 = 8.54285 loss)
I0523 04:44:52.574185 34819 sgd_solver.cpp:112] Iteration 49790, lr = 0.01
I0523 04:44:57.127157 34819 solver.cpp:239] Iteration 49800 (2.16371 iter/s, 4.6217s/10 iters), loss = 8.52501
I0523 04:44:57.127398 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52501 (* 1 = 8.52501 loss)
I0523 04:44:57.204959 34819 sgd_solver.cpp:112] Iteration 49800, lr = 0.01
I0523 04:44:59.918179 34819 solver.cpp:239] Iteration 49810 (3.58336 iter/s, 2.79068s/10 iters), loss = 8.70143
I0523 04:44:59.918234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70143 (* 1 = 8.70143 loss)
I0523 04:44:59.992678 34819 sgd_solver.cpp:112] Iteration 49810, lr = 0.01
I0523 04:45:06.018779 34819 solver.cpp:239] Iteration 49820 (1.63926 iter/s, 6.1003s/10 iters), loss = 9.05558
I0523 04:45:06.018821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05558 (* 1 = 9.05558 loss)
I0523 04:45:06.095650 34819 sgd_solver.cpp:112] Iteration 49820, lr = 0.01
I0523 04:45:10.003480 34819 solver.cpp:239] Iteration 49830 (2.50974 iter/s, 3.98448s/10 iters), loss = 8.02487
I0523 04:45:10.003522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02487 (* 1 = 8.02487 loss)
I0523 04:45:10.826417 34819 sgd_solver.cpp:112] Iteration 49830, lr = 0.01
I0523 04:45:15.064136 34819 solver.cpp:239] Iteration 49840 (1.97613 iter/s, 5.0604s/10 iters), loss = 8.79055
I0523 04:45:15.064177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79055 (* 1 = 8.79055 loss)
I0523 04:45:15.136927 34819 sgd_solver.cpp:112] Iteration 49840, lr = 0.01
I0523 04:45:18.533444 34819 solver.cpp:239] Iteration 49850 (2.88258 iter/s, 3.46912s/10 iters), loss = 8.56967
I0523 04:45:18.533486 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56967 (* 1 = 8.56967 loss)
I0523 04:45:18.679991 34819 sgd_solver.cpp:112] Iteration 49850, lr = 0.01
I0523 04:45:23.663100 34819 solver.cpp:239] Iteration 49860 (1.94955 iter/s, 5.12939s/10 iters), loss = 8.423
I0523 04:45:23.663161 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.423 (* 1 = 8.423 loss)
I0523 04:45:24.538044 34819 sgd_solver.cpp:112] Iteration 49860, lr = 0.01
I0523 04:45:28.767642 34819 solver.cpp:239] Iteration 49870 (1.95914 iter/s, 5.10427s/10 iters), loss = 9.36173
I0523 04:45:28.767858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.36173 (* 1 = 9.36173 loss)
I0523 04:45:29.569728 34819 sgd_solver.cpp:112] Iteration 49870, lr = 0.01
I0523 04:45:33.380408 34819 solver.cpp:239] Iteration 49880 (2.16808 iter/s, 4.61238s/10 iters), loss = 7.81816
I0523 04:45:33.380450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81816 (* 1 = 7.81816 loss)
I0523 04:45:34.242511 34819 sgd_solver.cpp:112] Iteration 49880, lr = 0.01
I0523 04:45:37.423631 34819 solver.cpp:239] Iteration 49890 (2.47341 iter/s, 4.043s/10 iters), loss = 9.07752
I0523 04:45:37.423676 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07752 (* 1 = 9.07752 loss)
I0523 04:45:38.128782 34819 sgd_solver.cpp:112] Iteration 49890, lr = 0.01
I0523 04:45:44.174726 34819 solver.cpp:239] Iteration 49900 (1.48132 iter/s, 6.75076s/10 iters), loss = 7.8315
I0523 04:45:44.174774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8315 (* 1 = 7.8315 loss)
I0523 04:45:44.957878 34819 sgd_solver.cpp:112] Iteration 49900, lr = 0.01
I0523 04:45:49.907122 34819 solver.cpp:239] Iteration 49910 (1.74456 iter/s, 5.73211s/10 iters), loss = 8.41347
I0523 04:45:49.907168 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41347 (* 1 = 8.41347 loss)
I0523 04:45:50.543949 34819 sgd_solver.cpp:112] Iteration 49910, lr = 0.01
I0523 04:45:53.998070 34819 solver.cpp:239] Iteration 49920 (2.44456 iter/s, 4.09072s/10 iters), loss = 8.58344
I0523 04:45:53.998119 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58344 (* 1 = 8.58344 loss)
I0523 04:45:54.056978 34819 sgd_solver.cpp:112] Iteration 49920, lr = 0.01
I0523 04:45:59.464834 34819 solver.cpp:239] Iteration 49930 (1.82933 iter/s, 5.46649s/10 iters), loss = 8.24568
I0523 04:45:59.465090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24568 (* 1 = 8.24568 loss)
I0523 04:45:59.540822 34819 sgd_solver.cpp:112] Iteration 49930, lr = 0.01
I0523 04:46:06.458894 34819 solver.cpp:239] Iteration 49940 (1.42989 iter/s, 6.99354s/10 iters), loss = 8.99612
I0523 04:46:06.458945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99612 (* 1 = 8.99612 loss)
I0523 04:46:07.352751 34819 sgd_solver.cpp:112] Iteration 49940, lr = 0.01
I0523 04:46:10.793084 34819 solver.cpp:239] Iteration 49950 (2.30737 iter/s, 4.33394s/10 iters), loss = 8.92366
I0523 04:46:10.793138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92366 (* 1 = 8.92366 loss)
I0523 04:46:11.540398 34819 sgd_solver.cpp:112] Iteration 49950, lr = 0.01
I0523 04:46:17.283926 34819 solver.cpp:239] Iteration 49960 (1.54071 iter/s, 6.49052s/10 iters), loss = 9.49328
I0523 04:46:17.283975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49328 (* 1 = 9.49328 loss)
I0523 04:46:17.353173 34819 sgd_solver.cpp:112] Iteration 49960, lr = 0.01
I0523 04:46:22.647533 34819 solver.cpp:239] Iteration 49970 (1.86451 iter/s, 5.36334s/10 iters), loss = 8.03463
I0523 04:46:22.647574 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03463 (* 1 = 8.03463 loss)
I0523 04:46:22.890570 34819 sgd_solver.cpp:112] Iteration 49970, lr = 0.01
I0523 04:46:27.160154 34819 solver.cpp:239] Iteration 49980 (2.21612 iter/s, 4.51239s/10 iters), loss = 8.07704
I0523 04:46:27.160208 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07704 (* 1 = 8.07704 loss)
I0523 04:46:27.991739 34819 sgd_solver.cpp:112] Iteration 49980, lr = 0.01
I0523 04:46:33.566159 34819 solver.cpp:239] Iteration 49990 (1.56111 iter/s, 6.40569s/10 iters), loss = 8.4065
I0523 04:46:33.566377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4065 (* 1 = 8.4065 loss)
I0523 04:46:34.271745 34819 sgd_solver.cpp:112] Iteration 49990, lr = 0.01
I0523 04:46:39.659513 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_50000.caffemodel
I0523 04:46:49.586858 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_50000.solverstate
I0523 04:46:49.814615 34819 solver.cpp:239] Iteration 50000 (0.615474 iter/s, 16.2476s/10 iters), loss = 9.74779
I0523 04:46:49.814654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.74779 (* 1 = 9.74779 loss)
I0523 04:46:49.877570 34819 sgd_solver.cpp:112] Iteration 50000, lr = 0.01
I0523 04:46:53.143930 34819 solver.cpp:239] Iteration 50010 (3.0038 iter/s, 3.32911s/10 iters), loss = 9.64324
I0523 04:46:53.143975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64324 (* 1 = 9.64324 loss)
I0523 04:46:53.210511 34819 sgd_solver.cpp:112] Iteration 50010, lr = 0.01
I0523 04:46:57.996232 34819 solver.cpp:239] Iteration 50020 (2.06099 iter/s, 4.85205s/10 iters), loss = 8.48135
I0523 04:46:57.996273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48135 (* 1 = 8.48135 loss)
I0523 04:46:58.824615 34819 sgd_solver.cpp:112] Iteration 50020, lr = 0.01
I0523 04:47:03.025513 34819 solver.cpp:239] Iteration 50030 (1.98846 iter/s, 5.02902s/10 iters), loss = 8.09345
I0523 04:47:03.025565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09345 (* 1 = 8.09345 loss)
I0523 04:47:03.640211 34819 sgd_solver.cpp:112] Iteration 50030, lr = 0.01
I0523 04:47:07.870328 34819 solver.cpp:239] Iteration 50040 (2.06417 iter/s, 4.84456s/10 iters), loss = 9.16425
I0523 04:47:07.870381 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16425 (* 1 = 9.16425 loss)
I0523 04:47:07.934440 34819 sgd_solver.cpp:112] Iteration 50040, lr = 0.01
I0523 04:47:13.753679 34819 solver.cpp:239] Iteration 50050 (1.6998 iter/s, 5.88304s/10 iters), loss = 8.38462
I0523 04:47:13.753728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38462 (* 1 = 8.38462 loss)
I0523 04:47:14.356813 34819 sgd_solver.cpp:112] Iteration 50050, lr = 0.01
I0523 04:47:17.732529 34819 solver.cpp:239] Iteration 50060 (2.51342 iter/s, 3.97864s/10 iters), loss = 8.83155
I0523 04:47:17.732570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83155 (* 1 = 8.83155 loss)
I0523 04:47:17.802747 34819 sgd_solver.cpp:112] Iteration 50060, lr = 0.01
I0523 04:47:23.655252 34819 solver.cpp:239] Iteration 50070 (1.68849 iter/s, 5.92244s/10 iters), loss = 8.71814
I0523 04:47:23.655316 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71814 (* 1 = 8.71814 loss)
I0523 04:47:23.714807 34819 sgd_solver.cpp:112] Iteration 50070, lr = 0.01
I0523 04:47:29.265053 34819 solver.cpp:239] Iteration 50080 (1.78269 iter/s, 5.60951s/10 iters), loss = 7.80255
I0523 04:47:29.265103 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80255 (* 1 = 7.80255 loss)
I0523 04:47:29.336701 34819 sgd_solver.cpp:112] Iteration 50080, lr = 0.01
I0523 04:47:34.979198 34819 solver.cpp:239] Iteration 50090 (1.75013 iter/s, 5.71385s/10 iters), loss = 8.78184
I0523 04:47:34.979449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78184 (* 1 = 8.78184 loss)
I0523 04:47:35.451848 34819 sgd_solver.cpp:112] Iteration 50090, lr = 0.01
I0523 04:47:39.788393 34819 solver.cpp:239] Iteration 50100 (2.07953 iter/s, 4.80877s/10 iters), loss = 7.93692
I0523 04:47:39.788435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93692 (* 1 = 7.93692 loss)
I0523 04:47:39.858316 34819 sgd_solver.cpp:112] Iteration 50100, lr = 0.01
I0523 04:47:44.153743 34819 solver.cpp:239] Iteration 50110 (2.2909 iter/s, 4.3651s/10 iters), loss = 8.72887
I0523 04:47:44.153798 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72887 (* 1 = 8.72887 loss)
I0523 04:47:44.458499 34819 sgd_solver.cpp:112] Iteration 50110, lr = 0.01
I0523 04:47:50.380285 34819 solver.cpp:239] Iteration 50120 (1.60611 iter/s, 6.22624s/10 iters), loss = 8.95483
I0523 04:47:50.380326 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95483 (* 1 = 8.95483 loss)
I0523 04:47:50.441929 34819 sgd_solver.cpp:112] Iteration 50120, lr = 0.01
I0523 04:47:56.529494 34819 solver.cpp:239] Iteration 50130 (1.62631 iter/s, 6.14891s/10 iters), loss = 8.70405
I0523 04:47:56.529536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70405 (* 1 = 8.70405 loss)
I0523 04:47:56.591223 34819 sgd_solver.cpp:112] Iteration 50130, lr = 0.01
I0523 04:48:01.430505 34819 solver.cpp:239] Iteration 50140 (2.0405 iter/s, 4.90076s/10 iters), loss = 9.67621
I0523 04:48:01.430557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67621 (* 1 = 9.67621 loss)
I0523 04:48:02.143806 34819 sgd_solver.cpp:112] Iteration 50140, lr = 0.01
I0523 04:48:09.270820 34819 solver.cpp:239] Iteration 50150 (1.27552 iter/s, 7.83994s/10 iters), loss = 8.42676
I0523 04:48:09.270965 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42676 (* 1 = 8.42676 loss)
I0523 04:48:09.343365 34819 sgd_solver.cpp:112] Iteration 50150, lr = 0.01
I0523 04:48:13.862553 34819 solver.cpp:239] Iteration 50160 (2.178 iter/s, 4.59138s/10 iters), loss = 8.54581
I0523 04:48:13.862617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54581 (* 1 = 8.54581 loss)
I0523 04:48:14.694202 34819 sgd_solver.cpp:112] Iteration 50160, lr = 0.01
I0523 04:48:18.659510 34819 solver.cpp:239] Iteration 50170 (2.08477 iter/s, 4.7967s/10 iters), loss = 9.56132
I0523 04:48:18.659552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56132 (* 1 = 9.56132 loss)
I0523 04:48:19.488744 34819 sgd_solver.cpp:112] Iteration 50170, lr = 0.01
I0523 04:48:25.623334 34819 solver.cpp:239] Iteration 50180 (1.43606 iter/s, 6.96349s/10 iters), loss = 8.60725
I0523 04:48:25.623375 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60725 (* 1 = 8.60725 loss)
I0523 04:48:26.377166 34819 sgd_solver.cpp:112] Iteration 50180, lr = 0.01
I0523 04:48:31.294152 34819 solver.cpp:239] Iteration 50190 (1.7635 iter/s, 5.67054s/10 iters), loss = 8.5723
I0523 04:48:31.294203 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5723 (* 1 = 8.5723 loss)
I0523 04:48:31.363672 34819 sgd_solver.cpp:112] Iteration 50190, lr = 0.01
I0523 04:48:35.225656 34819 solver.cpp:239] Iteration 50200 (2.5437 iter/s, 3.93128s/10 iters), loss = 9.44493
I0523 04:48:35.225706 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44493 (* 1 = 9.44493 loss)
I0523 04:48:35.288902 34819 sgd_solver.cpp:112] Iteration 50200, lr = 0.01
I0523 04:48:38.818198 34819 solver.cpp:239] Iteration 50210 (2.78371 iter/s, 3.59233s/10 iters), loss = 7.78247
I0523 04:48:38.818253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78247 (* 1 = 7.78247 loss)
I0523 04:48:39.552697 34819 sgd_solver.cpp:112] Iteration 50210, lr = 0.01
I0523 04:48:43.031678 34819 solver.cpp:239] Iteration 50220 (2.37347 iter/s, 4.21325s/10 iters), loss = 8.85813
I0523 04:48:43.031736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85813 (* 1 = 8.85813 loss)
I0523 04:48:43.872826 34819 sgd_solver.cpp:112] Iteration 50220, lr = 0.01
I0523 04:48:47.311702 34819 solver.cpp:239] Iteration 50230 (2.33656 iter/s, 4.27979s/10 iters), loss = 9.41037
I0523 04:48:47.311744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.41037 (* 1 = 9.41037 loss)
I0523 04:48:47.367909 34819 sgd_solver.cpp:112] Iteration 50230, lr = 0.01
I0523 04:48:52.443465 34819 solver.cpp:239] Iteration 50240 (1.94875 iter/s, 5.1315s/10 iters), loss = 9.15713
I0523 04:48:52.443527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15713 (* 1 = 9.15713 loss)
I0523 04:48:53.298858 34819 sgd_solver.cpp:112] Iteration 50240, lr = 0.01
I0523 04:48:56.421574 34819 solver.cpp:239] Iteration 50250 (2.5139 iter/s, 3.97788s/10 iters), loss = 9.61523
I0523 04:48:56.421630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.61523 (* 1 = 9.61523 loss)
I0523 04:48:57.195266 34819 sgd_solver.cpp:112] Iteration 50250, lr = 0.01
I0523 04:49:05.156401 34819 solver.cpp:239] Iteration 50260 (1.1449 iter/s, 8.73439s/10 iters), loss = 9.33115
I0523 04:49:05.156458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33115 (* 1 = 9.33115 loss)
I0523 04:49:05.223284 34819 sgd_solver.cpp:112] Iteration 50260, lr = 0.01
I0523 04:49:09.869455 34819 solver.cpp:239] Iteration 50270 (2.12188 iter/s, 4.7128s/10 iters), loss = 8.77337
I0523 04:49:09.869566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77337 (* 1 = 8.77337 loss)
I0523 04:49:10.299417 34819 sgd_solver.cpp:112] Iteration 50270, lr = 0.01
I0523 04:49:14.958824 34819 solver.cpp:239] Iteration 50280 (1.96501 iter/s, 5.08904s/10 iters), loss = 8.74181
I0523 04:49:14.958868 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74181 (* 1 = 8.74181 loss)
I0523 04:49:15.018051 34819 sgd_solver.cpp:112] Iteration 50280, lr = 0.01
I0523 04:49:18.916021 34819 solver.cpp:239] Iteration 50290 (2.52718 iter/s, 3.95698s/10 iters), loss = 9.15537
I0523 04:49:18.916070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15537 (* 1 = 9.15537 loss)
I0523 04:49:18.991554 34819 sgd_solver.cpp:112] Iteration 50290, lr = 0.01
I0523 04:49:23.806340 34819 solver.cpp:239] Iteration 50300 (2.04497 iter/s, 4.89005s/10 iters), loss = 8.22731
I0523 04:49:23.806399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22731 (* 1 = 8.22731 loss)
I0523 04:49:23.873069 34819 sgd_solver.cpp:112] Iteration 50300, lr = 0.01
I0523 04:49:28.880851 34819 solver.cpp:239] Iteration 50310 (1.97074 iter/s, 5.07424s/10 iters), loss = 8.63273
I0523 04:49:28.880893 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63273 (* 1 = 8.63273 loss)
I0523 04:49:28.950417 34819 sgd_solver.cpp:112] Iteration 50310, lr = 0.01
I0523 04:49:33.898743 34819 solver.cpp:239] Iteration 50320 (1.99298 iter/s, 5.01761s/10 iters), loss = 9.03795
I0523 04:49:33.898794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03795 (* 1 = 9.03795 loss)
I0523 04:49:34.732493 34819 sgd_solver.cpp:112] Iteration 50320, lr = 0.01
I0523 04:49:37.308667 34819 solver.cpp:239] Iteration 50330 (2.9328 iter/s, 3.40972s/10 iters), loss = 9.00184
I0523 04:49:37.308712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00184 (* 1 = 9.00184 loss)
I0523 04:49:37.847970 34819 sgd_solver.cpp:112] Iteration 50330, lr = 0.01
I0523 04:49:42.663837 34819 solver.cpp:239] Iteration 50340 (1.86745 iter/s, 5.3549s/10 iters), loss = 9.45027
I0523 04:49:42.664077 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45027 (* 1 = 9.45027 loss)
I0523 04:49:42.717036 34819 sgd_solver.cpp:112] Iteration 50340, lr = 0.01
I0523 04:49:46.335088 34819 solver.cpp:239] Iteration 50350 (2.72415 iter/s, 3.67087s/10 iters), loss = 7.53185
I0523 04:49:46.335141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53185 (* 1 = 7.53185 loss)
I0523 04:49:46.393574 34819 sgd_solver.cpp:112] Iteration 50350, lr = 0.01
I0523 04:49:52.416715 34819 solver.cpp:239] Iteration 50360 (1.64438 iter/s, 6.08133s/10 iters), loss = 8.77245
I0523 04:49:52.416755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77245 (* 1 = 8.77245 loss)
I0523 04:49:52.489171 34819 sgd_solver.cpp:112] Iteration 50360, lr = 0.01
I0523 04:49:58.308507 34819 solver.cpp:239] Iteration 50370 (1.69736 iter/s, 5.89151s/10 iters), loss = 8.99998
I0523 04:49:58.308549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99998 (* 1 = 8.99998 loss)
I0523 04:49:58.377619 34819 sgd_solver.cpp:112] Iteration 50370, lr = 0.01
I0523 04:50:03.828732 34819 solver.cpp:239] Iteration 50380 (1.81161 iter/s, 5.51995s/10 iters), loss = 8.65954
I0523 04:50:03.828773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65954 (* 1 = 8.65954 loss)
I0523 04:50:04.556068 34819 sgd_solver.cpp:112] Iteration 50380, lr = 0.01
I0523 04:50:08.240573 34819 solver.cpp:239] Iteration 50390 (2.26675 iter/s, 4.4116s/10 iters), loss = 8.98166
I0523 04:50:08.240614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98166 (* 1 = 8.98166 loss)
I0523 04:50:09.088791 34819 sgd_solver.cpp:112] Iteration 50390, lr = 0.01
I0523 04:50:14.402789 34819 solver.cpp:239] Iteration 50400 (1.62287 iter/s, 6.16192s/10 iters), loss = 8.30187
I0523 04:50:14.402968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30187 (* 1 = 8.30187 loss)
I0523 04:50:15.204695 34819 sgd_solver.cpp:112] Iteration 50400, lr = 0.01
I0523 04:50:18.293321 34819 solver.cpp:239] Iteration 50410 (2.57058 iter/s, 3.89018s/10 iters), loss = 8.30609
I0523 04:50:18.293368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30609 (* 1 = 8.30609 loss)
I0523 04:50:19.132980 34819 sgd_solver.cpp:112] Iteration 50410, lr = 0.01
I0523 04:50:26.352998 34819 solver.cpp:239] Iteration 50420 (1.2408 iter/s, 8.05929s/10 iters), loss = 9.67069
I0523 04:50:26.353049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.67069 (* 1 = 9.67069 loss)
I0523 04:50:26.425282 34819 sgd_solver.cpp:112] Iteration 50420, lr = 0.01
I0523 04:50:29.790944 34819 solver.cpp:239] Iteration 50430 (2.90888 iter/s, 3.43775s/10 iters), loss = 8.16929
I0523 04:50:29.790989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16929 (* 1 = 8.16929 loss)
I0523 04:50:30.592213 34819 sgd_solver.cpp:112] Iteration 50430, lr = 0.01
I0523 04:50:34.359452 34819 solver.cpp:239] Iteration 50440 (2.18902 iter/s, 4.56826s/10 iters), loss = 8.47359
I0523 04:50:34.359495 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47359 (* 1 = 8.47359 loss)
I0523 04:50:34.416119 34819 sgd_solver.cpp:112] Iteration 50440, lr = 0.01
I0523 04:50:37.026325 34819 solver.cpp:239] Iteration 50450 (3.74994 iter/s, 2.66671s/10 iters), loss = 8.69932
I0523 04:50:37.026373 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69932 (* 1 = 8.69932 loss)
I0523 04:50:37.091639 34819 sgd_solver.cpp:112] Iteration 50450, lr = 0.01
I0523 04:50:41.878567 34819 solver.cpp:239] Iteration 50460 (2.06101 iter/s, 4.85199s/10 iters), loss = 9.4306
I0523 04:50:41.878617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4306 (* 1 = 9.4306 loss)
I0523 04:50:41.955726 34819 sgd_solver.cpp:112] Iteration 50460, lr = 0.01
I0523 04:50:46.237176 34819 solver.cpp:239] Iteration 50470 (2.29444 iter/s, 4.35837s/10 iters), loss = 7.53149
I0523 04:50:46.237462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53149 (* 1 = 7.53149 loss)
I0523 04:50:46.506690 34819 sgd_solver.cpp:112] Iteration 50470, lr = 0.01
I0523 04:50:51.695170 34819 solver.cpp:239] Iteration 50480 (1.83234 iter/s, 5.4575s/10 iters), loss = 8.98079
I0523 04:50:51.695212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98079 (* 1 = 8.98079 loss)
I0523 04:50:51.773289 34819 sgd_solver.cpp:112] Iteration 50480, lr = 0.01
I0523 04:50:55.115154 34819 solver.cpp:239] Iteration 50490 (2.92415 iter/s, 3.41979s/10 iters), loss = 8.27586
I0523 04:50:55.115200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27586 (* 1 = 8.27586 loss)
I0523 04:50:55.984283 34819 sgd_solver.cpp:112] Iteration 50490, lr = 0.01
I0523 04:50:59.983896 34819 solver.cpp:239] Iteration 50500 (2.05402 iter/s, 4.86849s/10 iters), loss = 8.36792
I0523 04:50:59.983949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36792 (* 1 = 8.36792 loss)
I0523 04:51:00.059492 34819 sgd_solver.cpp:112] Iteration 50500, lr = 0.01
I0523 04:51:03.601977 34819 solver.cpp:239] Iteration 50510 (2.76406 iter/s, 3.61786s/10 iters), loss = 8.72725
I0523 04:51:03.602022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72725 (* 1 = 8.72725 loss)
I0523 04:51:04.118531 34819 sgd_solver.cpp:112] Iteration 50510, lr = 0.01
I0523 04:51:06.765822 34819 solver.cpp:239] Iteration 50520 (3.16089 iter/s, 3.16366s/10 iters), loss = 9.09156
I0523 04:51:06.765874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09156 (* 1 = 9.09156 loss)
I0523 04:51:07.630005 34819 sgd_solver.cpp:112] Iteration 50520, lr = 0.01
I0523 04:51:09.486652 34819 solver.cpp:239] Iteration 50530 (3.6756 iter/s, 2.72065s/10 iters), loss = 9.01288
I0523 04:51:09.486739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01288 (* 1 = 9.01288 loss)
I0523 04:51:09.543009 34819 sgd_solver.cpp:112] Iteration 50530, lr = 0.01
I0523 04:51:14.377490 34819 solver.cpp:239] Iteration 50540 (2.04476 iter/s, 4.89055s/10 iters), loss = 8.85435
I0523 04:51:14.377532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85435 (* 1 = 8.85435 loss)
I0523 04:51:14.441980 34819 sgd_solver.cpp:112] Iteration 50540, lr = 0.01
I0523 04:51:19.547212 34819 solver.cpp:239] Iteration 50550 (1.93444 iter/s, 5.16946s/10 iters), loss = 8.75279
I0523 04:51:19.547431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75279 (* 1 = 8.75279 loss)
I0523 04:51:20.293161 34819 sgd_solver.cpp:112] Iteration 50550, lr = 0.01
I0523 04:51:22.911023 34819 solver.cpp:239] Iteration 50560 (2.97312 iter/s, 3.36347s/10 iters), loss = 8.68268
I0523 04:51:22.911088 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68268 (* 1 = 8.68268 loss)
I0523 04:51:22.990193 34819 sgd_solver.cpp:112] Iteration 50560, lr = 0.01
I0523 04:51:26.230768 34819 solver.cpp:239] Iteration 50570 (3.01247 iter/s, 3.31954s/10 iters), loss = 9.07257
I0523 04:51:26.230814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07257 (* 1 = 9.07257 loss)
I0523 04:51:26.308063 34819 sgd_solver.cpp:112] Iteration 50570, lr = 0.01
I0523 04:51:30.873147 34819 solver.cpp:239] Iteration 50580 (2.15419 iter/s, 4.64213s/10 iters), loss = 7.95406
I0523 04:51:30.873201 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95406 (* 1 = 7.95406 loss)
I0523 04:51:30.955842 34819 sgd_solver.cpp:112] Iteration 50580, lr = 0.01
I0523 04:51:36.184859 34819 solver.cpp:239] Iteration 50590 (1.88273 iter/s, 5.31144s/10 iters), loss = 9.22564
I0523 04:51:36.184907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22564 (* 1 = 9.22564 loss)
I0523 04:51:36.248075 34819 sgd_solver.cpp:112] Iteration 50590, lr = 0.01
I0523 04:51:42.842077 34819 solver.cpp:239] Iteration 50600 (1.5022 iter/s, 6.6569s/10 iters), loss = 8.83612
I0523 04:51:42.842123 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83612 (* 1 = 8.83612 loss)
I0523 04:51:43.582468 34819 sgd_solver.cpp:112] Iteration 50600, lr = 0.01
I0523 04:51:50.565003 34819 solver.cpp:239] Iteration 50610 (1.29491 iter/s, 7.72256s/10 iters), loss = 9.11396
I0523 04:51:50.565197 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11396 (* 1 = 9.11396 loss)
I0523 04:51:51.239593 34819 sgd_solver.cpp:112] Iteration 50610, lr = 0.01
I0523 04:51:55.544860 34819 solver.cpp:239] Iteration 50620 (2.00825 iter/s, 4.97945s/10 iters), loss = 8.38407
I0523 04:51:55.544926 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38407 (* 1 = 8.38407 loss)
I0523 04:51:55.829188 34819 sgd_solver.cpp:112] Iteration 50620, lr = 0.01
I0523 04:52:02.275449 34819 solver.cpp:239] Iteration 50630 (1.48583 iter/s, 6.73025s/10 iters), loss = 7.92552
I0523 04:52:02.275487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92552 (* 1 = 7.92552 loss)
I0523 04:52:02.342972 34819 sgd_solver.cpp:112] Iteration 50630, lr = 0.01
I0523 04:52:05.722728 34819 solver.cpp:239] Iteration 50640 (2.90104 iter/s, 3.44704s/10 iters), loss = 8.9017
I0523 04:52:05.722779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9017 (* 1 = 8.9017 loss)
I0523 04:52:06.600625 34819 sgd_solver.cpp:112] Iteration 50640, lr = 0.01
I0523 04:52:10.654016 34819 solver.cpp:239] Iteration 50650 (2.02797 iter/s, 4.93103s/10 iters), loss = 9.4018
I0523 04:52:10.654067 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4018 (* 1 = 9.4018 loss)
I0523 04:52:11.454077 34819 sgd_solver.cpp:112] Iteration 50650, lr = 0.01
I0523 04:52:16.164937 34819 solver.cpp:239] Iteration 50660 (1.81468 iter/s, 5.51063s/10 iters), loss = 8.55591
I0523 04:52:16.165001 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55591 (* 1 = 8.55591 loss)
I0523 04:52:16.832350 34819 sgd_solver.cpp:112] Iteration 50660, lr = 0.01
I0523 04:52:22.542881 34819 solver.cpp:239] Iteration 50670 (1.56798 iter/s, 6.37761s/10 iters), loss = 8.34561
I0523 04:52:22.542981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34561 (* 1 = 8.34561 loss)
I0523 04:52:22.618589 34819 sgd_solver.cpp:112] Iteration 50670, lr = 0.01
I0523 04:52:27.345067 34819 solver.cpp:239] Iteration 50680 (2.08252 iter/s, 4.80188s/10 iters), loss = 8.20624
I0523 04:52:27.345110 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20624 (* 1 = 8.20624 loss)
I0523 04:52:27.423379 34819 sgd_solver.cpp:112] Iteration 50680, lr = 0.01
I0523 04:52:33.221638 34819 solver.cpp:239] Iteration 50690 (1.70176 iter/s, 5.87628s/10 iters), loss = 9.486
I0523 04:52:33.221693 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.486 (* 1 = 9.486 loss)
I0523 04:52:34.009687 34819 sgd_solver.cpp:112] Iteration 50690, lr = 0.01
I0523 04:52:39.687683 34819 solver.cpp:239] Iteration 50700 (1.54662 iter/s, 6.46572s/10 iters), loss = 8.63818
I0523 04:52:39.687726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63818 (* 1 = 8.63818 loss)
I0523 04:52:39.754755 34819 sgd_solver.cpp:112] Iteration 50700, lr = 0.01
I0523 04:52:44.504220 34819 solver.cpp:239] Iteration 50710 (2.07817 iter/s, 4.81194s/10 iters), loss = 8.47696
I0523 04:52:44.504273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47696 (* 1 = 8.47696 loss)
I0523 04:52:44.580662 34819 sgd_solver.cpp:112] Iteration 50710, lr = 0.01
I0523 04:52:50.115694 34819 solver.cpp:239] Iteration 50720 (1.78215 iter/s, 5.61119s/10 iters), loss = 8.53951
I0523 04:52:50.115739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53951 (* 1 = 8.53951 loss)
I0523 04:52:50.913208 34819 sgd_solver.cpp:112] Iteration 50720, lr = 0.01
I0523 04:52:56.384229 34819 solver.cpp:239] Iteration 50730 (1.59535 iter/s, 6.26823s/10 iters), loss = 9.23761
I0523 04:52:56.384455 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.23761 (* 1 = 9.23761 loss)
I0523 04:52:56.446038 34819 sgd_solver.cpp:112] Iteration 50730, lr = 0.01
I0523 04:53:02.289702 34819 solver.cpp:239] Iteration 50740 (1.69347 iter/s, 5.90502s/10 iters), loss = 8.34765
I0523 04:53:02.289744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34765 (* 1 = 8.34765 loss)
I0523 04:53:02.679533 34819 sgd_solver.cpp:112] Iteration 50740, lr = 0.01
I0523 04:53:07.821058 34819 solver.cpp:239] Iteration 50750 (1.80797 iter/s, 5.53108s/10 iters), loss = 8.48957
I0523 04:53:07.821121 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48957 (* 1 = 8.48957 loss)
I0523 04:53:07.971812 34819 sgd_solver.cpp:112] Iteration 50750, lr = 0.01
I0523 04:53:13.318675 34819 solver.cpp:239] Iteration 50760 (1.81907 iter/s, 5.49733s/10 iters), loss = 8.60035
I0523 04:53:13.318740 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60035 (* 1 = 8.60035 loss)
I0523 04:53:13.389513 34819 sgd_solver.cpp:112] Iteration 50760, lr = 0.01
I0523 04:53:19.001466 34819 solver.cpp:239] Iteration 50770 (1.75979 iter/s, 5.68249s/10 iters), loss = 9.2308
I0523 04:53:19.001513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.2308 (* 1 = 9.2308 loss)
I0523 04:53:19.695389 34819 sgd_solver.cpp:112] Iteration 50770, lr = 0.01
I0523 04:53:22.920218 34819 solver.cpp:239] Iteration 50780 (2.55198 iter/s, 3.91853s/10 iters), loss = 8.58991
I0523 04:53:22.920264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58991 (* 1 = 8.58991 loss)
I0523 04:53:22.982655 34819 sgd_solver.cpp:112] Iteration 50780, lr = 0.01
I0523 04:53:28.471756 34819 solver.cpp:239] Iteration 50790 (1.8014 iter/s, 5.55125s/10 iters), loss = 8.20959
I0523 04:53:28.471915 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20959 (* 1 = 8.20959 loss)
I0523 04:53:29.322212 34819 sgd_solver.cpp:112] Iteration 50790, lr = 0.01
I0523 04:53:33.425352 34819 solver.cpp:239] Iteration 50800 (2.01889 iter/s, 4.95322s/10 iters), loss = 8.66991
I0523 04:53:33.425405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66991 (* 1 = 8.66991 loss)
I0523 04:53:33.491943 34819 sgd_solver.cpp:112] Iteration 50800, lr = 0.01
I0523 04:53:38.694208 34819 solver.cpp:239] Iteration 50810 (1.89805 iter/s, 5.26858s/10 iters), loss = 8.49039
I0523 04:53:38.694250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49039 (* 1 = 8.49039 loss)
I0523 04:53:39.330425 34819 sgd_solver.cpp:112] Iteration 50810, lr = 0.01
I0523 04:53:43.479372 34819 solver.cpp:239] Iteration 50820 (2.0899 iter/s, 4.78492s/10 iters), loss = 8.81892
I0523 04:53:43.479415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81892 (* 1 = 8.81892 loss)
I0523 04:53:43.564200 34819 sgd_solver.cpp:112] Iteration 50820, lr = 0.01
I0523 04:53:48.448434 34819 solver.cpp:239] Iteration 50830 (2.01256 iter/s, 4.9688s/10 iters), loss = 8.46
I0523 04:53:48.448487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46 (* 1 = 8.46 loss)
I0523 04:53:48.513133 34819 sgd_solver.cpp:112] Iteration 50830, lr = 0.01
I0523 04:53:51.791126 34819 solver.cpp:239] Iteration 50840 (2.99177 iter/s, 3.3425s/10 iters), loss = 8.39702
I0523 04:53:51.791169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39702 (* 1 = 8.39702 loss)
I0523 04:53:52.525085 34819 sgd_solver.cpp:112] Iteration 50840, lr = 0.01
I0523 04:53:55.882755 34819 solver.cpp:239] Iteration 50850 (2.44414 iter/s, 4.09141s/10 iters), loss = 8.905
I0523 04:53:55.882810 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.905 (* 1 = 8.905 loss)
I0523 04:53:55.956298 34819 sgd_solver.cpp:112] Iteration 50850, lr = 0.01
I0523 04:54:00.936944 34819 solver.cpp:239] Iteration 50860 (1.97866 iter/s, 5.05392s/10 iters), loss = 8.65532
I0523 04:54:00.937108 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65532 (* 1 = 8.65532 loss)
I0523 04:54:01.010746 34819 sgd_solver.cpp:112] Iteration 50860, lr = 0.01
I0523 04:54:04.811022 34819 solver.cpp:239] Iteration 50870 (2.58147 iter/s, 3.87376s/10 iters), loss = 8.32713
I0523 04:54:04.811081 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32713 (* 1 = 8.32713 loss)
I0523 04:54:04.889358 34819 sgd_solver.cpp:112] Iteration 50870, lr = 0.01
I0523 04:54:09.314378 34819 solver.cpp:239] Iteration 50880 (2.22069 iter/s, 4.50311s/10 iters), loss = 8.17903
I0523 04:54:09.314421 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17903 (* 1 = 8.17903 loss)
I0523 04:54:10.110545 34819 sgd_solver.cpp:112] Iteration 50880, lr = 0.01
I0523 04:54:14.083393 34819 solver.cpp:239] Iteration 50890 (2.097 iter/s, 4.76873s/10 iters), loss = 8.3243
I0523 04:54:14.083449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3243 (* 1 = 8.3243 loss)
I0523 04:54:14.852996 34819 sgd_solver.cpp:112] Iteration 50890, lr = 0.01
I0523 04:54:20.264542 34819 solver.cpp:239] Iteration 50900 (1.61791 iter/s, 6.18083s/10 iters), loss = 7.91304
I0523 04:54:20.264593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91304 (* 1 = 7.91304 loss)
I0523 04:54:20.325368 34819 sgd_solver.cpp:112] Iteration 50900, lr = 0.01
I0523 04:54:24.505888 34819 solver.cpp:239] Iteration 50910 (2.35787 iter/s, 4.24112s/10 iters), loss = 9.27932
I0523 04:54:24.505942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27932 (* 1 = 9.27932 loss)
I0523 04:54:25.183625 34819 sgd_solver.cpp:112] Iteration 50910, lr = 0.01
I0523 04:54:30.575539 34819 solver.cpp:239] Iteration 50920 (1.64762 iter/s, 6.06934s/10 iters), loss = 8.33267
I0523 04:54:30.575593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33267 (* 1 = 8.33267 loss)
I0523 04:54:31.338964 34819 sgd_solver.cpp:112] Iteration 50920, lr = 0.01
I0523 04:54:36.258843 34819 solver.cpp:239] Iteration 50930 (1.75963 iter/s, 5.683s/10 iters), loss = 8.00504
I0523 04:54:36.258890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00504 (* 1 = 8.00504 loss)
I0523 04:54:37.074542 34819 sgd_solver.cpp:112] Iteration 50930, lr = 0.01
I0523 04:54:42.633281 34819 solver.cpp:239] Iteration 50940 (1.56884 iter/s, 6.37413s/10 iters), loss = 7.69841
I0523 04:54:42.633322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69841 (* 1 = 7.69841 loss)
I0523 04:54:43.480940 34819 sgd_solver.cpp:112] Iteration 50940, lr = 0.01
I0523 04:54:48.413449 34819 solver.cpp:239] Iteration 50950 (1.73014 iter/s, 5.77989s/10 iters), loss = 8.67483
I0523 04:54:48.413491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67483 (* 1 = 8.67483 loss)
I0523 04:54:48.471859 34819 sgd_solver.cpp:112] Iteration 50950, lr = 0.01
I0523 04:54:52.593123 34819 solver.cpp:239] Iteration 50960 (2.39266 iter/s, 4.17945s/10 iters), loss = 8.83163
I0523 04:54:52.593173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83163 (* 1 = 8.83163 loss)
I0523 04:54:52.660181 34819 sgd_solver.cpp:112] Iteration 50960, lr = 0.01
I0523 04:54:56.388583 34819 solver.cpp:239] Iteration 50970 (2.63487 iter/s, 3.79525s/10 iters), loss = 9.62637
I0523 04:54:56.388634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.62637 (* 1 = 9.62637 loss)
I0523 04:54:56.450711 34819 sgd_solver.cpp:112] Iteration 50970, lr = 0.01
I0523 04:54:59.796916 34819 solver.cpp:239] Iteration 50980 (2.93416 iter/s, 3.40813s/10 iters), loss = 8.82779
I0523 04:54:59.796977 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82779 (* 1 = 8.82779 loss)
I0523 04:55:00.653844 34819 sgd_solver.cpp:112] Iteration 50980, lr = 0.01
I0523 04:55:05.512272 34819 solver.cpp:239] Iteration 50990 (1.74976 iter/s, 5.71505s/10 iters), loss = 9.37276
I0523 04:55:05.512418 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37276 (* 1 = 9.37276 loss)
I0523 04:55:05.599251 34819 sgd_solver.cpp:112] Iteration 50990, lr = 0.01
I0523 04:55:09.686277 34819 solver.cpp:239] Iteration 51000 (2.39597 iter/s, 4.17368s/10 iters), loss = 8.5391
I0523 04:55:09.686326 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5391 (* 1 = 8.5391 loss)
I0523 04:55:09.755386 34819 sgd_solver.cpp:112] Iteration 51000, lr = 0.01
I0523 04:55:13.932394 34819 solver.cpp:239] Iteration 51010 (2.35522 iter/s, 4.24589s/10 iters), loss = 8.99301
I0523 04:55:13.932435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99301 (* 1 = 8.99301 loss)
I0523 04:55:14.014663 34819 sgd_solver.cpp:112] Iteration 51010, lr = 0.01
I0523 04:55:17.733942 34819 solver.cpp:239] Iteration 51020 (2.63066 iter/s, 3.80133s/10 iters), loss = 7.9182
I0523 04:55:17.733990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9182 (* 1 = 7.9182 loss)
I0523 04:55:17.839896 34819 sgd_solver.cpp:112] Iteration 51020, lr = 0.01
I0523 04:55:21.650717 34819 solver.cpp:239] Iteration 51030 (2.55328 iter/s, 3.91654s/10 iters), loss = 8.82521
I0523 04:55:21.650768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82521 (* 1 = 8.82521 loss)
I0523 04:55:22.433956 34819 sgd_solver.cpp:112] Iteration 51030, lr = 0.01
I0523 04:55:26.472965 34819 solver.cpp:239] Iteration 51040 (2.07383 iter/s, 4.82199s/10 iters), loss = 8.42005
I0523 04:55:26.473006 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42005 (* 1 = 8.42005 loss)
I0523 04:55:26.530953 34819 sgd_solver.cpp:112] Iteration 51040, lr = 0.01
I0523 04:55:30.113101 34819 solver.cpp:239] Iteration 51050 (2.74731 iter/s, 3.63993s/10 iters), loss = 7.58972
I0523 04:55:30.113140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58972 (* 1 = 7.58972 loss)
I0523 04:55:30.170208 34819 sgd_solver.cpp:112] Iteration 51050, lr = 0.01
I0523 04:55:33.398651 34819 solver.cpp:239] Iteration 51060 (3.04382 iter/s, 3.28535s/10 iters), loss = 8.6729
I0523 04:55:33.398727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6729 (* 1 = 8.6729 loss)
I0523 04:55:33.470683 34819 sgd_solver.cpp:112] Iteration 51060, lr = 0.01
I0523 04:55:38.734984 34819 solver.cpp:239] Iteration 51070 (1.87404 iter/s, 5.33607s/10 iters), loss = 8.02615
I0523 04:55:38.735069 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02615 (* 1 = 8.02615 loss)
I0523 04:55:38.797868 34819 sgd_solver.cpp:112] Iteration 51070, lr = 0.01
I0523 04:55:44.360540 34819 solver.cpp:239] Iteration 51080 (1.77771 iter/s, 5.62523s/10 iters), loss = 8.1327
I0523 04:55:44.360590 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1327 (* 1 = 8.1327 loss)
I0523 04:55:44.426123 34819 sgd_solver.cpp:112] Iteration 51080, lr = 0.01
I0523 04:55:49.696936 34819 solver.cpp:239] Iteration 51090 (1.87402 iter/s, 5.33612s/10 iters), loss = 8.96931
I0523 04:55:49.696988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96931 (* 1 = 8.96931 loss)
I0523 04:55:49.766414 34819 sgd_solver.cpp:112] Iteration 51090, lr = 0.01
I0523 04:55:54.533004 34819 solver.cpp:239] Iteration 51100 (2.0679 iter/s, 4.83581s/10 iters), loss = 8.09616
I0523 04:55:54.533052 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09616 (* 1 = 8.09616 loss)
I0523 04:55:55.297199 34819 sgd_solver.cpp:112] Iteration 51100, lr = 0.01
I0523 04:55:59.857488 34819 solver.cpp:239] Iteration 51110 (1.87821 iter/s, 5.32422s/10 iters), loss = 8.5189
I0523 04:55:59.857537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5189 (* 1 = 8.5189 loss)
I0523 04:56:00.628710 34819 sgd_solver.cpp:112] Iteration 51110, lr = 0.01
I0523 04:56:05.126464 34819 solver.cpp:239] Iteration 51120 (1.898 iter/s, 5.26871s/10 iters), loss = 8.52261
I0523 04:56:05.126505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52261 (* 1 = 8.52261 loss)
I0523 04:56:05.199398 34819 sgd_solver.cpp:112] Iteration 51120, lr = 0.01
I0523 04:56:10.302819 34819 solver.cpp:239] Iteration 51130 (1.93196 iter/s, 5.17609s/10 iters), loss = 8.50523
I0523 04:56:10.302963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50523 (* 1 = 8.50523 loss)
I0523 04:56:10.958029 34819 sgd_solver.cpp:112] Iteration 51130, lr = 0.01
I0523 04:56:14.181345 34819 solver.cpp:239] Iteration 51140 (2.57851 iter/s, 3.87821s/10 iters), loss = 7.68048
I0523 04:56:14.181385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68048 (* 1 = 7.68048 loss)
I0523 04:56:15.007439 34819 sgd_solver.cpp:112] Iteration 51140, lr = 0.01
I0523 04:56:19.733784 34819 solver.cpp:239] Iteration 51150 (1.80111 iter/s, 5.55215s/10 iters), loss = 8.09102
I0523 04:56:19.733829 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09102 (* 1 = 8.09102 loss)
I0523 04:56:20.551828 34819 sgd_solver.cpp:112] Iteration 51150, lr = 0.01
I0523 04:56:25.483165 34819 solver.cpp:239] Iteration 51160 (1.73941 iter/s, 5.74906s/10 iters), loss = 7.69924
I0523 04:56:25.483207 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69924 (* 1 = 7.69924 loss)
I0523 04:56:26.358584 34819 sgd_solver.cpp:112] Iteration 51160, lr = 0.01
I0523 04:56:29.669955 34819 solver.cpp:239] Iteration 51170 (2.3886 iter/s, 4.18655s/10 iters), loss = 8.219
I0523 04:56:29.670007 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.219 (* 1 = 8.219 loss)
I0523 04:56:29.736631 34819 sgd_solver.cpp:112] Iteration 51170, lr = 0.01
I0523 04:56:33.140172 34819 solver.cpp:239] Iteration 51180 (2.88184 iter/s, 3.47001s/10 iters), loss = 8.97742
I0523 04:56:33.140218 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97742 (* 1 = 8.97742 loss)
I0523 04:56:33.462783 34819 sgd_solver.cpp:112] Iteration 51180, lr = 0.01
I0523 04:56:39.866653 34819 solver.cpp:239] Iteration 51190 (1.48673 iter/s, 6.72615s/10 iters), loss = 8.35252
I0523 04:56:39.866727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35252 (* 1 = 8.35252 loss)
I0523 04:56:40.767208 34819 sgd_solver.cpp:112] Iteration 51190, lr = 0.01
I0523 04:56:44.162109 34819 solver.cpp:239] Iteration 51200 (2.32818 iter/s, 4.2952s/10 iters), loss = 9.63488
I0523 04:56:44.162160 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63488 (* 1 = 9.63488 loss)
I0523 04:56:44.240154 34819 sgd_solver.cpp:112] Iteration 51200, lr = 0.01
I0523 04:56:49.253556 34819 solver.cpp:239] Iteration 51210 (1.96418 iter/s, 5.09119s/10 iters), loss = 9.50993
I0523 04:56:49.253594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50993 (* 1 = 9.50993 loss)
I0523 04:56:49.358193 34819 sgd_solver.cpp:112] Iteration 51210, lr = 0.01
I0523 04:56:54.635207 34819 solver.cpp:239] Iteration 51220 (1.85826 iter/s, 5.38137s/10 iters), loss = 8.37298
I0523 04:56:54.635267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37298 (* 1 = 8.37298 loss)
I0523 04:56:55.482028 34819 sgd_solver.cpp:112] Iteration 51220, lr = 0.01
I0523 04:56:58.703256 34819 solver.cpp:239] Iteration 51230 (2.45832 iter/s, 4.06782s/10 iters), loss = 8.84851
I0523 04:56:58.703310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84851 (* 1 = 8.84851 loss)
I0523 04:56:58.768538 34819 sgd_solver.cpp:112] Iteration 51230, lr = 0.01
I0523 04:57:04.162012 34819 solver.cpp:239] Iteration 51240 (1.83201 iter/s, 5.45847s/10 iters), loss = 8.81431
I0523 04:57:04.162068 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81431 (* 1 = 8.81431 loss)
I0523 04:57:04.979636 34819 sgd_solver.cpp:112] Iteration 51240, lr = 0.01
I0523 04:57:09.470721 34819 solver.cpp:239] Iteration 51250 (1.8838 iter/s, 5.30841s/10 iters), loss = 8.62204
I0523 04:57:09.470762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62204 (* 1 = 8.62204 loss)
I0523 04:57:09.539964 34819 sgd_solver.cpp:112] Iteration 51250, lr = 0.01
I0523 04:57:13.732470 34819 solver.cpp:239] Iteration 51260 (2.34658 iter/s, 4.26151s/10 iters), loss = 7.90414
I0523 04:57:13.732656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90414 (* 1 = 7.90414 loss)
I0523 04:57:13.794446 34819 sgd_solver.cpp:112] Iteration 51260, lr = 0.01
I0523 04:57:17.177258 34819 solver.cpp:239] Iteration 51270 (2.90321 iter/s, 3.44446s/10 iters), loss = 8.35965
I0523 04:57:17.177296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35965 (* 1 = 8.35965 loss)
I0523 04:57:17.235934 34819 sgd_solver.cpp:112] Iteration 51270, lr = 0.01
I0523 04:57:24.590135 34819 solver.cpp:239] Iteration 51280 (1.34907 iter/s, 7.41253s/10 iters), loss = 8.98235
I0523 04:57:24.590174 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98235 (* 1 = 8.98235 loss)
I0523 04:57:25.464294 34819 sgd_solver.cpp:112] Iteration 51280, lr = 0.01
I0523 04:57:30.151360 34819 solver.cpp:239] Iteration 51290 (1.79825 iter/s, 5.56096s/10 iters), loss = 7.68048
I0523 04:57:30.151399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68048 (* 1 = 7.68048 loss)
I0523 04:57:30.216233 34819 sgd_solver.cpp:112] Iteration 51290, lr = 0.01
I0523 04:57:34.790000 34819 solver.cpp:239] Iteration 51300 (2.15592 iter/s, 4.6384s/10 iters), loss = 8.551
I0523 04:57:34.790048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.551 (* 1 = 8.551 loss)
I0523 04:57:34.851517 34819 sgd_solver.cpp:112] Iteration 51300, lr = 0.01
I0523 04:57:39.134989 34819 solver.cpp:239] Iteration 51310 (2.30163 iter/s, 4.34475s/10 iters), loss = 8.55424
I0523 04:57:39.135033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55424 (* 1 = 8.55424 loss)
I0523 04:57:39.651239 34819 sgd_solver.cpp:112] Iteration 51310, lr = 0.01
I0523 04:57:42.294764 34819 solver.cpp:239] Iteration 51320 (3.16496 iter/s, 3.1596s/10 iters), loss = 8.77899
I0523 04:57:42.294803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77899 (* 1 = 8.77899 loss)
I0523 04:57:43.105418 34819 sgd_solver.cpp:112] Iteration 51320, lr = 0.01
I0523 04:57:47.998432 34819 solver.cpp:239] Iteration 51330 (1.75335 iter/s, 5.70338s/10 iters), loss = 8.4764
I0523 04:57:47.998576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4764 (* 1 = 8.4764 loss)
I0523 04:57:48.074386 34819 sgd_solver.cpp:112] Iteration 51330, lr = 0.01
I0523 04:57:52.887096 34819 solver.cpp:239] Iteration 51340 (2.04569 iter/s, 4.88832s/10 iters), loss = 8.75601
I0523 04:57:52.887147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75601 (* 1 = 8.75601 loss)
I0523 04:57:52.961189 34819 sgd_solver.cpp:112] Iteration 51340, lr = 0.01
I0523 04:57:57.135963 34819 solver.cpp:239] Iteration 51350 (2.3537 iter/s, 4.24862s/10 iters), loss = 9.40984
I0523 04:57:57.136014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40984 (* 1 = 9.40984 loss)
I0523 04:57:57.204450 34819 sgd_solver.cpp:112] Iteration 51350, lr = 0.01
I0523 04:58:02.483783 34819 solver.cpp:239] Iteration 51360 (1.87002 iter/s, 5.34754s/10 iters), loss = 8.97046
I0523 04:58:02.483824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97046 (* 1 = 8.97046 loss)
I0523 04:58:02.564901 34819 sgd_solver.cpp:112] Iteration 51360, lr = 0.01
I0523 04:58:06.761816 34819 solver.cpp:239] Iteration 51370 (2.33765 iter/s, 4.27779s/10 iters), loss = 9.20445
I0523 04:58:06.761857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20445 (* 1 = 9.20445 loss)
I0523 04:58:07.626868 34819 sgd_solver.cpp:112] Iteration 51370, lr = 0.01
I0523 04:58:11.449414 34819 solver.cpp:239] Iteration 51380 (2.1334 iter/s, 4.68734s/10 iters), loss = 8.79713
I0523 04:58:11.449466 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79713 (* 1 = 8.79713 loss)
I0523 04:58:12.238122 34819 sgd_solver.cpp:112] Iteration 51380, lr = 0.01
I0523 04:58:16.146967 34819 solver.cpp:239] Iteration 51390 (2.1289 iter/s, 4.69727s/10 iters), loss = 8.49537
I0523 04:58:16.147019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49537 (* 1 = 8.49537 loss)
I0523 04:58:16.207888 34819 sgd_solver.cpp:112] Iteration 51390, lr = 0.01
I0523 04:58:19.999538 34819 solver.cpp:239] Iteration 51400 (2.59581 iter/s, 3.85236s/10 iters), loss = 8.41549
I0523 04:58:19.999682 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41549 (* 1 = 8.41549 loss)
I0523 04:58:20.877260 34819 sgd_solver.cpp:112] Iteration 51400, lr = 0.01
I0523 04:58:24.276717 34819 solver.cpp:239] Iteration 51410 (2.33817 iter/s, 4.27685s/10 iters), loss = 7.58093
I0523 04:58:24.276757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58093 (* 1 = 7.58093 loss)
I0523 04:58:25.076383 34819 sgd_solver.cpp:112] Iteration 51410, lr = 0.01
I0523 04:58:29.027359 34819 solver.cpp:239] Iteration 51420 (2.10508 iter/s, 4.7504s/10 iters), loss = 8.07893
I0523 04:58:29.027400 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07893 (* 1 = 8.07893 loss)
I0523 04:58:29.815757 34819 sgd_solver.cpp:112] Iteration 51420, lr = 0.01
I0523 04:58:34.670452 34819 solver.cpp:239] Iteration 51430 (1.77217 iter/s, 5.64281s/10 iters), loss = 9.00834
I0523 04:58:34.670493 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00834 (* 1 = 9.00834 loss)
I0523 04:58:35.488735 34819 sgd_solver.cpp:112] Iteration 51430, lr = 0.01
I0523 04:58:40.062578 34819 solver.cpp:239] Iteration 51440 (1.85465 iter/s, 5.39186s/10 iters), loss = 8.54813
I0523 04:58:40.062625 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54813 (* 1 = 8.54813 loss)
I0523 04:58:40.123826 34819 sgd_solver.cpp:112] Iteration 51440, lr = 0.01
I0523 04:58:46.533267 34819 solver.cpp:239] Iteration 51450 (1.54551 iter/s, 6.47037s/10 iters), loss = 8.61637
I0523 04:58:46.533318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61637 (* 1 = 8.61637 loss)
I0523 04:58:46.604506 34819 sgd_solver.cpp:112] Iteration 51450, lr = 0.01
I0523 04:58:51.586262 34819 solver.cpp:239] Iteration 51460 (1.97913 iter/s, 5.05273s/10 iters), loss = 7.36451
I0523 04:58:51.586388 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36451 (* 1 = 7.36451 loss)
I0523 04:58:52.394356 34819 sgd_solver.cpp:112] Iteration 51460, lr = 0.01
I0523 04:58:57.395545 34819 solver.cpp:239] Iteration 51470 (1.72149 iter/s, 5.80891s/10 iters), loss = 8.36954
I0523 04:58:57.395601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36954 (* 1 = 8.36954 loss)
I0523 04:58:58.099756 34819 sgd_solver.cpp:112] Iteration 51470, lr = 0.01
I0523 04:59:01.446030 34819 solver.cpp:239] Iteration 51480 (2.46898 iter/s, 4.05025s/10 iters), loss = 9.02011
I0523 04:59:01.446096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02011 (* 1 = 9.02011 loss)
I0523 04:59:01.504509 34819 sgd_solver.cpp:112] Iteration 51480, lr = 0.01
I0523 04:59:05.537328 34819 solver.cpp:239] Iteration 51490 (2.44437 iter/s, 4.09104s/10 iters), loss = 7.78225
I0523 04:59:05.537384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78225 (* 1 = 7.78225 loss)
I0523 04:59:06.375636 34819 sgd_solver.cpp:112] Iteration 51490, lr = 0.01
I0523 04:59:12.271836 34819 solver.cpp:239] Iteration 51500 (1.48496 iter/s, 6.73418s/10 iters), loss = 8.61489
I0523 04:59:12.271896 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61489 (* 1 = 8.61489 loss)
I0523 04:59:13.102617 34819 sgd_solver.cpp:112] Iteration 51500, lr = 0.01
I0523 04:59:17.308550 34819 solver.cpp:239] Iteration 51510 (1.98553 iter/s, 5.03644s/10 iters), loss = 8.24745
I0523 04:59:17.308591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24745 (* 1 = 8.24745 loss)
I0523 04:59:17.367182 34819 sgd_solver.cpp:112] Iteration 51510, lr = 0.01
I0523 04:59:20.526691 34819 solver.cpp:239] Iteration 51520 (3.10756 iter/s, 3.21796s/10 iters), loss = 8.61213
I0523 04:59:20.526773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61213 (* 1 = 8.61213 loss)
I0523 04:59:20.590775 34819 sgd_solver.cpp:112] Iteration 51520, lr = 0.01
I0523 04:59:25.175271 34819 solver.cpp:239] Iteration 51530 (2.15132 iter/s, 4.64831s/10 iters), loss = 8.188
I0523 04:59:25.175384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.188 (* 1 = 8.188 loss)
I0523 04:59:25.265936 34819 sgd_solver.cpp:112] Iteration 51530, lr = 0.01
I0523 04:59:28.878958 34819 solver.cpp:239] Iteration 51540 (2.70023 iter/s, 3.70339s/10 iters), loss = 9.38272
I0523 04:59:28.879020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.38272 (* 1 = 9.38272 loss)
I0523 04:59:29.156649 34819 sgd_solver.cpp:112] Iteration 51540, lr = 0.01
I0523 04:59:32.900022 34819 solver.cpp:239] Iteration 51550 (2.48705 iter/s, 4.02084s/10 iters), loss = 8.73311
I0523 04:59:32.900075 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73311 (* 1 = 8.73311 loss)
I0523 04:59:32.969907 34819 sgd_solver.cpp:112] Iteration 51550, lr = 0.01
I0523 04:59:36.181049 34819 solver.cpp:239] Iteration 51560 (3.04801 iter/s, 3.28083s/10 iters), loss = 8.70903
I0523 04:59:36.181090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70903 (* 1 = 8.70903 loss)
I0523 04:59:36.246498 34819 sgd_solver.cpp:112] Iteration 51560, lr = 0.01
I0523 04:59:39.977155 34819 solver.cpp:239] Iteration 51570 (2.63442 iter/s, 3.7959s/10 iters), loss = 9.40882
I0523 04:59:39.977197 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40882 (* 1 = 9.40882 loss)
I0523 04:59:40.739825 34819 sgd_solver.cpp:112] Iteration 51570, lr = 0.01
I0523 04:59:45.690196 34819 solver.cpp:239] Iteration 51580 (1.75047 iter/s, 5.71276s/10 iters), loss = 8.05067
I0523 04:59:45.690251 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05067 (* 1 = 8.05067 loss)
I0523 04:59:45.765231 34819 sgd_solver.cpp:112] Iteration 51580, lr = 0.01
I0523 04:59:49.585307 34819 solver.cpp:239] Iteration 51590 (2.56746 iter/s, 3.89489s/10 iters), loss = 8.4506
I0523 04:59:49.585361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4506 (* 1 = 8.4506 loss)
I0523 04:59:49.664497 34819 sgd_solver.cpp:112] Iteration 51590, lr = 0.01
I0523 04:59:53.436326 34819 solver.cpp:239] Iteration 51600 (2.59687 iter/s, 3.85079s/10 iters), loss = 8.50857
I0523 04:59:53.436364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50857 (* 1 = 8.50857 loss)
I0523 04:59:54.112251 34819 sgd_solver.cpp:112] Iteration 51600, lr = 0.01
I0523 04:59:58.477546 34819 solver.cpp:239] Iteration 51610 (1.98374 iter/s, 5.04097s/10 iters), loss = 8.3714
I0523 04:59:58.477659 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3714 (* 1 = 8.3714 loss)
I0523 04:59:58.534374 34819 sgd_solver.cpp:112] Iteration 51610, lr = 0.01
I0523 05:00:02.242221 34819 solver.cpp:239] Iteration 51620 (2.65648 iter/s, 3.76439s/10 iters), loss = 9.18594
I0523 05:00:02.242275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18594 (* 1 = 9.18594 loss)
I0523 05:00:02.314414 34819 sgd_solver.cpp:112] Iteration 51620, lr = 0.01
I0523 05:00:08.340113 34819 solver.cpp:239] Iteration 51630 (1.64 iter/s, 6.09755s/10 iters), loss = 9.17817
I0523 05:00:08.340173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17817 (* 1 = 9.17817 loss)
I0523 05:00:09.194619 34819 sgd_solver.cpp:112] Iteration 51630, lr = 0.01
I0523 05:00:10.998292 34819 solver.cpp:239] Iteration 51640 (3.76222 iter/s, 2.658s/10 iters), loss = 8.35715
I0523 05:00:10.998342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35715 (* 1 = 8.35715 loss)
I0523 05:00:11.067636 34819 sgd_solver.cpp:112] Iteration 51640, lr = 0.01
I0523 05:00:16.824875 34819 solver.cpp:239] Iteration 51650 (1.71636 iter/s, 5.82628s/10 iters), loss = 8.69001
I0523 05:00:16.824929 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69001 (* 1 = 8.69001 loss)
I0523 05:00:16.891433 34819 sgd_solver.cpp:112] Iteration 51650, lr = 0.01
I0523 05:00:20.448621 34819 solver.cpp:239] Iteration 51660 (2.75974 iter/s, 3.62353s/10 iters), loss = 8.46093
I0523 05:00:20.448680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46093 (* 1 = 8.46093 loss)
I0523 05:00:21.309864 34819 sgd_solver.cpp:112] Iteration 51660, lr = 0.01
I0523 05:00:25.266010 34819 solver.cpp:239] Iteration 51670 (2.07593 iter/s, 4.81712s/10 iters), loss = 8.34981
I0523 05:00:25.266050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34981 (* 1 = 8.34981 loss)
I0523 05:00:25.324849 34819 sgd_solver.cpp:112] Iteration 51670, lr = 0.01
I0523 05:00:30.483932 34819 solver.cpp:239] Iteration 51680 (1.91657 iter/s, 5.21766s/10 iters), loss = 8.62831
I0523 05:00:30.484127 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62831 (* 1 = 8.62831 loss)
I0523 05:00:30.551273 34819 sgd_solver.cpp:112] Iteration 51680, lr = 0.01
I0523 05:00:35.955608 34819 solver.cpp:239] Iteration 51690 (1.82774 iter/s, 5.47123s/10 iters), loss = 8.51903
I0523 05:00:35.955663 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51903 (* 1 = 8.51903 loss)
I0523 05:00:36.664641 34819 sgd_solver.cpp:112] Iteration 51690, lr = 0.01
I0523 05:00:39.746810 34819 solver.cpp:239] Iteration 51700 (2.63785 iter/s, 3.79097s/10 iters), loss = 8.78436
I0523 05:00:39.746865 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78436 (* 1 = 8.78436 loss)
I0523 05:00:39.811731 34819 sgd_solver.cpp:112] Iteration 51700, lr = 0.01
I0523 05:00:44.643496 34819 solver.cpp:239] Iteration 51710 (2.04231 iter/s, 4.89643s/10 iters), loss = 8.85833
I0523 05:00:44.643545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85833 (* 1 = 8.85833 loss)
I0523 05:00:44.961807 34819 sgd_solver.cpp:112] Iteration 51710, lr = 0.01
I0523 05:00:49.840983 34819 solver.cpp:239] Iteration 51720 (1.92411 iter/s, 5.19721s/10 iters), loss = 8.11473
I0523 05:00:49.841034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11473 (* 1 = 8.11473 loss)
I0523 05:00:49.911353 34819 sgd_solver.cpp:112] Iteration 51720, lr = 0.01
I0523 05:00:54.660169 34819 solver.cpp:239] Iteration 51730 (2.07515 iter/s, 4.81894s/10 iters), loss = 9.31066
I0523 05:00:54.660212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31066 (* 1 = 9.31066 loss)
I0523 05:00:54.729238 34819 sgd_solver.cpp:112] Iteration 51730, lr = 0.01
I0523 05:01:00.919736 34819 solver.cpp:239] Iteration 51740 (1.59763 iter/s, 6.25926s/10 iters), loss = 8.83743
I0523 05:01:00.919819 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83743 (* 1 = 8.83743 loss)
I0523 05:01:00.996548 34819 sgd_solver.cpp:112] Iteration 51740, lr = 0.01
I0523 05:01:05.610141 34819 solver.cpp:239] Iteration 51750 (2.13214 iter/s, 4.69012s/10 iters), loss = 8.40723
I0523 05:01:05.610193 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40723 (* 1 = 8.40723 loss)
I0523 05:01:05.690037 34819 sgd_solver.cpp:112] Iteration 51750, lr = 0.01
I0523 05:01:11.520823 34819 solver.cpp:239] Iteration 51760 (1.69194 iter/s, 5.91037s/10 iters), loss = 9.28438
I0523 05:01:11.520876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28438 (* 1 = 9.28438 loss)
I0523 05:01:11.915524 34819 sgd_solver.cpp:112] Iteration 51760, lr = 0.01
I0523 05:01:16.710192 34819 solver.cpp:239] Iteration 51770 (1.92712 iter/s, 5.1891s/10 iters), loss = 8.61199
I0523 05:01:16.710232 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61199 (* 1 = 8.61199 loss)
I0523 05:01:16.770548 34819 sgd_solver.cpp:112] Iteration 51770, lr = 0.01
I0523 05:01:20.743451 34819 solver.cpp:239] Iteration 51780 (2.47952 iter/s, 4.03304s/10 iters), loss = 7.84429
I0523 05:01:20.743492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84429 (* 1 = 7.84429 loss)
I0523 05:01:21.573432 34819 sgd_solver.cpp:112] Iteration 51780, lr = 0.01
I0523 05:01:26.739492 34819 solver.cpp:239] Iteration 51790 (1.66785 iter/s, 5.99575s/10 iters), loss = 8.41928
I0523 05:01:26.739533 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41928 (* 1 = 8.41928 loss)
I0523 05:01:27.570422 34819 sgd_solver.cpp:112] Iteration 51790, lr = 0.01
I0523 05:01:31.939385 34819 solver.cpp:239] Iteration 51800 (1.92322 iter/s, 5.19962s/10 iters), loss = 9.29667
I0523 05:01:31.939565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29667 (* 1 = 9.29667 loss)
I0523 05:01:31.992223 34819 sgd_solver.cpp:112] Iteration 51800, lr = 0.01
I0523 05:01:37.532819 34819 solver.cpp:239] Iteration 51810 (1.78793 iter/s, 5.59305s/10 iters), loss = 8.07253
I0523 05:01:37.532872 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07253 (* 1 = 8.07253 loss)
I0523 05:01:37.608359 34819 sgd_solver.cpp:112] Iteration 51810, lr = 0.01
I0523 05:01:41.310819 34819 solver.cpp:239] Iteration 51820 (2.64705 iter/s, 3.77779s/10 iters), loss = 8.16537
I0523 05:01:41.310864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16537 (* 1 = 8.16537 loss)
I0523 05:01:41.918323 34819 sgd_solver.cpp:112] Iteration 51820, lr = 0.01
I0523 05:01:46.527789 34819 solver.cpp:239] Iteration 51830 (1.91692 iter/s, 5.2167s/10 iters), loss = 9.33368
I0523 05:01:46.527854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33368 (* 1 = 9.33368 loss)
I0523 05:01:47.310242 34819 sgd_solver.cpp:112] Iteration 51830, lr = 0.01
I0523 05:01:52.379915 34819 solver.cpp:239] Iteration 51840 (1.70887 iter/s, 5.85181s/10 iters), loss = 8.63543
I0523 05:01:52.379957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63543 (* 1 = 8.63543 loss)
I0523 05:01:53.155714 34819 sgd_solver.cpp:112] Iteration 51840, lr = 0.01
I0523 05:01:55.809217 34819 solver.cpp:239] Iteration 51850 (2.91623 iter/s, 3.42908s/10 iters), loss = 8.76632
I0523 05:01:55.809281 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76632 (* 1 = 8.76632 loss)
I0523 05:01:55.882490 34819 sgd_solver.cpp:112] Iteration 51850, lr = 0.01
I0523 05:01:59.541766 34819 solver.cpp:239] Iteration 51860 (2.67929 iter/s, 3.73233s/10 iters), loss = 8.41961
I0523 05:01:59.541821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41961 (* 1 = 8.41961 loss)
I0523 05:02:00.279250 34819 sgd_solver.cpp:112] Iteration 51860, lr = 0.01
I0523 05:02:04.408630 34819 solver.cpp:239] Iteration 51870 (2.05482 iter/s, 4.8666s/10 iters), loss = 8.50802
I0523 05:02:04.408779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50802 (* 1 = 8.50802 loss)
I0523 05:02:05.217128 34819 sgd_solver.cpp:112] Iteration 51870, lr = 0.01
I0523 05:02:09.573990 34819 solver.cpp:239] Iteration 51880 (1.93611 iter/s, 5.165s/10 iters), loss = 9.25017
I0523 05:02:09.574040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25017 (* 1 = 9.25017 loss)
I0523 05:02:09.645999 34819 sgd_solver.cpp:112] Iteration 51880, lr = 0.01
I0523 05:02:14.515589 34819 solver.cpp:239] Iteration 51890 (2.02376 iter/s, 4.94131s/10 iters), loss = 8.39381
I0523 05:02:14.515637 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39381 (* 1 = 8.39381 loss)
I0523 05:02:15.207643 34819 sgd_solver.cpp:112] Iteration 51890, lr = 0.01
I0523 05:02:19.859475 34819 solver.cpp:239] Iteration 51900 (1.87139 iter/s, 5.34362s/10 iters), loss = 8.45303
I0523 05:02:19.859517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45303 (* 1 = 8.45303 loss)
I0523 05:02:19.917538 34819 sgd_solver.cpp:112] Iteration 51900, lr = 0.01
I0523 05:02:25.546084 34819 solver.cpp:239] Iteration 51910 (1.7586 iter/s, 5.68633s/10 iters), loss = 8.63292
I0523 05:02:25.546129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63292 (* 1 = 8.63292 loss)
I0523 05:02:26.371541 34819 sgd_solver.cpp:112] Iteration 51910, lr = 0.01
I0523 05:02:30.871886 34819 solver.cpp:239] Iteration 51920 (1.87776 iter/s, 5.32551s/10 iters), loss = 9.31663
I0523 05:02:30.871942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31663 (* 1 = 9.31663 loss)
I0523 05:02:31.700376 34819 sgd_solver.cpp:112] Iteration 51920, lr = 0.01
I0523 05:02:36.442488 34819 solver.cpp:239] Iteration 51930 (1.79523 iter/s, 5.57031s/10 iters), loss = 9.63399
I0523 05:02:36.442616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63399 (* 1 = 9.63399 loss)
I0523 05:02:36.511929 34819 sgd_solver.cpp:112] Iteration 51930, lr = 0.01
I0523 05:02:42.271111 34819 solver.cpp:239] Iteration 51940 (1.71578 iter/s, 5.82826s/10 iters), loss = 8.64118
I0523 05:02:42.271152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64118 (* 1 = 8.64118 loss)
I0523 05:02:42.342967 34819 sgd_solver.cpp:112] Iteration 51940, lr = 0.01
I0523 05:02:47.567842 34819 solver.cpp:239] Iteration 51950 (1.88805 iter/s, 5.29647s/10 iters), loss = 9.73522
I0523 05:02:47.567898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.73522 (* 1 = 9.73522 loss)
I0523 05:02:47.638360 34819 sgd_solver.cpp:112] Iteration 51950, lr = 0.01
I0523 05:02:52.605895 34819 solver.cpp:239] Iteration 51960 (1.98501 iter/s, 5.03777s/10 iters), loss = 8.26857
I0523 05:02:52.605949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26857 (* 1 = 8.26857 loss)
I0523 05:02:52.674878 34819 sgd_solver.cpp:112] Iteration 51960, lr = 0.01
I0523 05:02:55.930040 34819 solver.cpp:239] Iteration 51970 (3.00847 iter/s, 3.32395s/10 iters), loss = 8.80511
I0523 05:02:55.930093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80511 (* 1 = 8.80511 loss)
I0523 05:02:56.389168 34819 sgd_solver.cpp:112] Iteration 51970, lr = 0.01
I0523 05:03:00.384970 34819 solver.cpp:239] Iteration 51980 (2.24483 iter/s, 4.45469s/10 iters), loss = 7.36382
I0523 05:03:00.385018 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36382 (* 1 = 7.36382 loss)
I0523 05:03:00.458278 34819 sgd_solver.cpp:112] Iteration 51980, lr = 0.01
I0523 05:03:04.415273 34819 solver.cpp:239] Iteration 51990 (2.48135 iter/s, 4.03006s/10 iters), loss = 8.16796
I0523 05:03:04.415328 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16796 (* 1 = 8.16796 loss)
I0523 05:03:04.482034 34819 sgd_solver.cpp:112] Iteration 51990, lr = 0.01
I0523 05:03:07.769876 34819 solver.cpp:239] Iteration 52000 (2.98115 iter/s, 3.35441s/10 iters), loss = 8.75596
I0523 05:03:07.770015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75596 (* 1 = 8.75596 loss)
I0523 05:03:08.331262 34819 sgd_solver.cpp:112] Iteration 52000, lr = 0.01
I0523 05:03:14.590749 34819 solver.cpp:239] Iteration 52010 (1.46619 iter/s, 6.82042s/10 iters), loss = 9.24783
I0523 05:03:14.590795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24783 (* 1 = 9.24783 loss)
I0523 05:03:14.652814 34819 sgd_solver.cpp:112] Iteration 52010, lr = 0.01
I0523 05:03:18.174187 34819 solver.cpp:239] Iteration 52020 (2.79077 iter/s, 3.58324s/10 iters), loss = 8.61808
I0523 05:03:18.174242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61808 (* 1 = 8.61808 loss)
I0523 05:03:18.242642 34819 sgd_solver.cpp:112] Iteration 52020, lr = 0.01
I0523 05:03:22.178144 34819 solver.cpp:239] Iteration 52030 (2.49767 iter/s, 4.00373s/10 iters), loss = 8.45157
I0523 05:03:22.178206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45157 (* 1 = 8.45157 loss)
I0523 05:03:22.923864 34819 sgd_solver.cpp:112] Iteration 52030, lr = 0.01
I0523 05:03:28.006680 34819 solver.cpp:239] Iteration 52040 (1.71579 iter/s, 5.82823s/10 iters), loss = 8.54116
I0523 05:03:28.006737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54116 (* 1 = 8.54116 loss)
I0523 05:03:28.078629 34819 sgd_solver.cpp:112] Iteration 52040, lr = 0.01
I0523 05:03:34.706348 34819 solver.cpp:239] Iteration 52050 (1.49269 iter/s, 6.69933s/10 iters), loss = 9.21028
I0523 05:03:34.706392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21028 (* 1 = 9.21028 loss)
I0523 05:03:34.769954 34819 sgd_solver.cpp:112] Iteration 52050, lr = 0.01
I0523 05:03:40.780786 34819 solver.cpp:239] Iteration 52060 (1.64632 iter/s, 6.07414s/10 iters), loss = 8.59249
I0523 05:03:40.781031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59249 (* 1 = 8.59249 loss)
I0523 05:03:40.852288 34819 sgd_solver.cpp:112] Iteration 52060, lr = 0.01
I0523 05:03:45.692322 34819 solver.cpp:239] Iteration 52070 (2.03721 iter/s, 4.90866s/10 iters), loss = 8.8245
I0523 05:03:45.692371 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8245 (* 1 = 8.8245 loss)
I0523 05:03:45.767887 34819 sgd_solver.cpp:112] Iteration 52070, lr = 0.01
I0523 05:03:51.847110 34819 solver.cpp:239] Iteration 52080 (1.62483 iter/s, 6.15447s/10 iters), loss = 8.34942
I0523 05:03:51.847165 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34942 (* 1 = 8.34942 loss)
I0523 05:03:51.919878 34819 sgd_solver.cpp:112] Iteration 52080, lr = 0.01
I0523 05:03:57.474563 34819 solver.cpp:239] Iteration 52090 (1.77709 iter/s, 5.62716s/10 iters), loss = 8.14029
I0523 05:03:57.474615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14029 (* 1 = 8.14029 loss)
I0523 05:03:58.308751 34819 sgd_solver.cpp:112] Iteration 52090, lr = 0.01
I0523 05:04:02.196158 34819 solver.cpp:239] Iteration 52100 (2.11805 iter/s, 4.72133s/10 iters), loss = 8.74203
I0523 05:04:02.196209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74203 (* 1 = 8.74203 loss)
I0523 05:04:02.912150 34819 sgd_solver.cpp:112] Iteration 52100, lr = 0.01
I0523 05:04:07.389075 34819 solver.cpp:239] Iteration 52110 (1.9258 iter/s, 5.19263s/10 iters), loss = 9.40618
I0523 05:04:07.389128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40618 (* 1 = 9.40618 loss)
I0523 05:04:08.216886 34819 sgd_solver.cpp:112] Iteration 52110, lr = 0.01
I0523 05:04:10.916805 34819 solver.cpp:239] Iteration 52120 (2.83486 iter/s, 3.52751s/10 iters), loss = 9.01207
I0523 05:04:10.917052 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01207 (* 1 = 9.01207 loss)
I0523 05:04:11.740123 34819 sgd_solver.cpp:112] Iteration 52120, lr = 0.01
I0523 05:04:16.937325 34819 solver.cpp:239] Iteration 52130 (1.66111 iter/s, 6.02006s/10 iters), loss = 8.57817
I0523 05:04:16.937372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57817 (* 1 = 8.57817 loss)
I0523 05:04:17.000176 34819 sgd_solver.cpp:112] Iteration 52130, lr = 0.01
I0523 05:04:23.231292 34819 solver.cpp:239] Iteration 52140 (1.5889 iter/s, 6.29365s/10 iters), loss = 8.4405
I0523 05:04:23.231356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4405 (* 1 = 8.4405 loss)
I0523 05:04:23.303182 34819 sgd_solver.cpp:112] Iteration 52140, lr = 0.01
I0523 05:04:27.298243 34819 solver.cpp:239] Iteration 52150 (2.45899 iter/s, 4.0667s/10 iters), loss = 9.21447
I0523 05:04:27.298300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21447 (* 1 = 9.21447 loss)
I0523 05:04:27.365453 34819 sgd_solver.cpp:112] Iteration 52150, lr = 0.01
I0523 05:04:32.093533 34819 solver.cpp:239] Iteration 52160 (2.0855 iter/s, 4.79502s/10 iters), loss = 8.33873
I0523 05:04:32.093582 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33873 (* 1 = 8.33873 loss)
I0523 05:04:32.162822 34819 sgd_solver.cpp:112] Iteration 52160, lr = 0.01
I0523 05:04:35.537051 34819 solver.cpp:239] Iteration 52170 (2.90419 iter/s, 3.4433s/10 iters), loss = 8.77601
I0523 05:04:35.537111 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77601 (* 1 = 8.77601 loss)
I0523 05:04:36.257812 34819 sgd_solver.cpp:112] Iteration 52170, lr = 0.01
I0523 05:04:40.370812 34819 solver.cpp:239] Iteration 52180 (2.0689 iter/s, 4.83349s/10 iters), loss = 8.58753
I0523 05:04:40.370857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58753 (* 1 = 8.58753 loss)
I0523 05:04:41.165135 34819 sgd_solver.cpp:112] Iteration 52180, lr = 0.01
I0523 05:04:45.771708 34819 solver.cpp:239] Iteration 52190 (1.85164 iter/s, 5.40062s/10 iters), loss = 7.54459
I0523 05:04:45.771754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54459 (* 1 = 7.54459 loss)
I0523 05:04:46.613953 34819 sgd_solver.cpp:112] Iteration 52190, lr = 0.01
I0523 05:04:50.635074 34819 solver.cpp:239] Iteration 52200 (2.0563 iter/s, 4.86311s/10 iters), loss = 8.44194
I0523 05:04:50.635118 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44194 (* 1 = 8.44194 loss)
I0523 05:04:50.691980 34819 sgd_solver.cpp:112] Iteration 52200, lr = 0.01
I0523 05:04:57.917825 34819 solver.cpp:239] Iteration 52210 (1.37317 iter/s, 7.28241s/10 iters), loss = 8.30655
I0523 05:04:57.917870 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30655 (* 1 = 8.30655 loss)
I0523 05:04:57.990047 34819 sgd_solver.cpp:112] Iteration 52210, lr = 0.01
I0523 05:05:02.994010 34819 solver.cpp:239] Iteration 52220 (1.97008 iter/s, 5.07593s/10 iters), loss = 8.20802
I0523 05:05:02.994065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20802 (* 1 = 8.20802 loss)
I0523 05:05:03.069572 34819 sgd_solver.cpp:112] Iteration 52220, lr = 0.01
I0523 05:05:06.534593 34819 solver.cpp:239] Iteration 52230 (2.82456 iter/s, 3.54037s/10 iters), loss = 8.00846
I0523 05:05:06.534638 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00846 (* 1 = 8.00846 loss)
I0523 05:05:07.376687 34819 sgd_solver.cpp:112] Iteration 52230, lr = 0.01
I0523 05:05:12.316390 34819 solver.cpp:239] Iteration 52240 (1.72965 iter/s, 5.7815s/10 iters), loss = 8.31513
I0523 05:05:12.316572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31513 (* 1 = 8.31513 loss)
I0523 05:05:12.393882 34819 sgd_solver.cpp:112] Iteration 52240, lr = 0.01
I0523 05:05:17.417340 34819 solver.cpp:239] Iteration 52250 (1.96057 iter/s, 5.10056s/10 iters), loss = 8.14471
I0523 05:05:17.417392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14471 (* 1 = 8.14471 loss)
I0523 05:05:18.187487 34819 sgd_solver.cpp:112] Iteration 52250, lr = 0.01
I0523 05:05:22.406098 34819 solver.cpp:239] Iteration 52260 (2.00462 iter/s, 4.98848s/10 iters), loss = 8.6202
I0523 05:05:22.406155 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6202 (* 1 = 8.6202 loss)
I0523 05:05:23.238236 34819 sgd_solver.cpp:112] Iteration 52260, lr = 0.01
I0523 05:05:28.059247 34819 solver.cpp:239] Iteration 52270 (1.76902 iter/s, 5.65284s/10 iters), loss = 8.75766
I0523 05:05:28.059303 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75766 (* 1 = 8.75766 loss)
I0523 05:05:28.876077 34819 sgd_solver.cpp:112] Iteration 52270, lr = 0.01
I0523 05:05:31.529630 34819 solver.cpp:239] Iteration 52280 (2.88169 iter/s, 3.47018s/10 iters), loss = 8.63973
I0523 05:05:31.529675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63973 (* 1 = 8.63973 loss)
I0523 05:05:31.585064 34819 sgd_solver.cpp:112] Iteration 52280, lr = 0.01
I0523 05:05:36.194232 34819 solver.cpp:239] Iteration 52290 (2.14392 iter/s, 4.66435s/10 iters), loss = 7.88425
I0523 05:05:36.194285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88425 (* 1 = 7.88425 loss)
I0523 05:05:37.033589 34819 sgd_solver.cpp:112] Iteration 52290, lr = 0.01
I0523 05:05:41.212800 34819 solver.cpp:239] Iteration 52300 (1.99271 iter/s, 5.0183s/10 iters), loss = 9.19858
I0523 05:05:41.212841 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19858 (* 1 = 9.19858 loss)
I0523 05:05:41.968799 34819 sgd_solver.cpp:112] Iteration 52300, lr = 0.01
I0523 05:05:45.516240 34819 solver.cpp:239] Iteration 52310 (2.32384 iter/s, 4.30322s/10 iters), loss = 7.7369
I0523 05:05:45.516366 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7369 (* 1 = 7.7369 loss)
I0523 05:05:45.596817 34819 sgd_solver.cpp:112] Iteration 52310, lr = 0.01
I0523 05:05:49.514590 34819 solver.cpp:239] Iteration 52320 (2.50121 iter/s, 3.99806s/10 iters), loss = 8.19299
I0523 05:05:49.514631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19299 (* 1 = 8.19299 loss)
I0523 05:05:50.302698 34819 sgd_solver.cpp:112] Iteration 52320, lr = 0.01
I0523 05:05:55.296643 34819 solver.cpp:239] Iteration 52330 (1.72958 iter/s, 5.78177s/10 iters), loss = 8.51613
I0523 05:05:55.296685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51613 (* 1 = 8.51613 loss)
I0523 05:05:56.028755 34819 sgd_solver.cpp:112] Iteration 52330, lr = 0.01
I0523 05:06:01.079433 34819 solver.cpp:239] Iteration 52340 (1.72936 iter/s, 5.7825s/10 iters), loss = 8.50103
I0523 05:06:01.079474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50103 (* 1 = 8.50103 loss)
I0523 05:06:01.162106 34819 sgd_solver.cpp:112] Iteration 52340, lr = 0.01
I0523 05:06:05.994549 34819 solver.cpp:239] Iteration 52350 (2.03465 iter/s, 4.91486s/10 iters), loss = 9.06406
I0523 05:06:05.994592 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.06406 (* 1 = 9.06406 loss)
I0523 05:06:06.063915 34819 sgd_solver.cpp:112] Iteration 52350, lr = 0.01
I0523 05:06:12.253111 34819 solver.cpp:239] Iteration 52360 (1.59789 iter/s, 6.25825s/10 iters), loss = 8.36287
I0523 05:06:12.253165 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36287 (* 1 = 8.36287 loss)
I0523 05:06:13.123399 34819 sgd_solver.cpp:112] Iteration 52360, lr = 0.01
I0523 05:06:19.233463 34819 solver.cpp:239] Iteration 52370 (1.43266 iter/s, 6.98001s/10 iters), loss = 8.55682
I0523 05:06:19.233613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55682 (* 1 = 8.55682 loss)
I0523 05:06:19.299382 34819 sgd_solver.cpp:112] Iteration 52370, lr = 0.01
I0523 05:06:24.184280 34819 solver.cpp:239] Iteration 52380 (2.02002 iter/s, 4.95044s/10 iters), loss = 7.81365
I0523 05:06:24.184330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81365 (* 1 = 7.81365 loss)
I0523 05:06:24.628687 34819 sgd_solver.cpp:112] Iteration 52380, lr = 0.01
I0523 05:06:27.291501 34819 solver.cpp:239] Iteration 52390 (3.21851 iter/s, 3.10703s/10 iters), loss = 8.77846
I0523 05:06:27.291543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77846 (* 1 = 8.77846 loss)
I0523 05:06:27.349603 34819 sgd_solver.cpp:112] Iteration 52390, lr = 0.01
I0523 05:06:30.636186 34819 solver.cpp:239] Iteration 52400 (2.98999 iter/s, 3.34449s/10 iters), loss = 9.80982
I0523 05:06:30.636229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.80982 (* 1 = 9.80982 loss)
I0523 05:06:31.190371 34819 sgd_solver.cpp:112] Iteration 52400, lr = 0.01
I0523 05:06:35.812439 34819 solver.cpp:239] Iteration 52410 (1.932 iter/s, 5.17599s/10 iters), loss = 9.09282
I0523 05:06:35.812479 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09282 (* 1 = 9.09282 loss)
I0523 05:06:35.892088 34819 sgd_solver.cpp:112] Iteration 52410, lr = 0.01
I0523 05:06:40.757418 34819 solver.cpp:239] Iteration 52420 (2.02236 iter/s, 4.94471s/10 iters), loss = 8.66062
I0523 05:06:40.757467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66062 (* 1 = 8.66062 loss)
I0523 05:06:41.596922 34819 sgd_solver.cpp:112] Iteration 52420, lr = 0.01
I0523 05:06:45.568446 34819 solver.cpp:239] Iteration 52430 (2.07866 iter/s, 4.81078s/10 iters), loss = 8.07566
I0523 05:06:45.568488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07566 (* 1 = 8.07566 loss)
I0523 05:06:45.635807 34819 sgd_solver.cpp:112] Iteration 52430, lr = 0.01
I0523 05:06:49.964393 34819 solver.cpp:239] Iteration 52440 (2.27495 iter/s, 4.39571s/10 iters), loss = 9.0292
I0523 05:06:49.964644 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0292 (* 1 = 9.0292 loss)
I0523 05:06:50.038828 34819 sgd_solver.cpp:112] Iteration 52440, lr = 0.01
I0523 05:06:55.004724 34819 solver.cpp:239] Iteration 52450 (1.98417 iter/s, 5.0399s/10 iters), loss = 8.22013
I0523 05:06:55.004765 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22013 (* 1 = 8.22013 loss)
I0523 05:06:55.059795 34819 sgd_solver.cpp:112] Iteration 52450, lr = 0.01
I0523 05:07:00.693712 34819 solver.cpp:239] Iteration 52460 (1.75787 iter/s, 5.68871s/10 iters), loss = 9.52412
I0523 05:07:00.693759 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52412 (* 1 = 9.52412 loss)
I0523 05:07:00.745498 34819 sgd_solver.cpp:112] Iteration 52460, lr = 0.01
I0523 05:07:04.556525 34819 solver.cpp:239] Iteration 52470 (2.58893 iter/s, 3.8626s/10 iters), loss = 8.78545
I0523 05:07:04.556571 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78545 (* 1 = 8.78545 loss)
I0523 05:07:05.349820 34819 sgd_solver.cpp:112] Iteration 52470, lr = 0.01
I0523 05:07:10.153969 34819 solver.cpp:239] Iteration 52480 (1.78662 iter/s, 5.59716s/10 iters), loss = 9.24375
I0523 05:07:10.154037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24375 (* 1 = 9.24375 loss)
I0523 05:07:10.980108 34819 sgd_solver.cpp:112] Iteration 52480, lr = 0.01
I0523 05:07:15.239472 34819 solver.cpp:239] Iteration 52490 (1.96648 iter/s, 5.08523s/10 iters), loss = 9.40526
I0523 05:07:15.239526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40526 (* 1 = 9.40526 loss)
I0523 05:07:15.306917 34819 sgd_solver.cpp:112] Iteration 52490, lr = 0.01
I0523 05:07:20.042102 34819 solver.cpp:239] Iteration 52500 (2.0823 iter/s, 4.80237s/10 iters), loss = 8.68562
I0523 05:07:20.042281 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68562 (* 1 = 8.68562 loss)
I0523 05:07:20.110942 34819 sgd_solver.cpp:112] Iteration 52500, lr = 0.01
I0523 05:07:26.223220 34819 solver.cpp:239] Iteration 52510 (1.61794 iter/s, 6.18068s/10 iters), loss = 9.47024
I0523 05:07:26.223273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.47024 (* 1 = 9.47024 loss)
I0523 05:07:26.902770 34819 sgd_solver.cpp:112] Iteration 52510, lr = 0.01
I0523 05:07:31.453739 34819 solver.cpp:239] Iteration 52520 (1.91196 iter/s, 5.23024s/10 iters), loss = 8.23435
I0523 05:07:31.453781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23435 (* 1 = 8.23435 loss)
I0523 05:07:31.522019 34819 sgd_solver.cpp:112] Iteration 52520, lr = 0.01
I0523 05:07:37.999902 34819 solver.cpp:239] Iteration 52530 (1.52768 iter/s, 6.54586s/10 iters), loss = 8.47091
I0523 05:07:37.999943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47091 (* 1 = 8.47091 loss)
I0523 05:07:38.073724 34819 sgd_solver.cpp:112] Iteration 52530, lr = 0.01
I0523 05:07:42.814611 34819 solver.cpp:239] Iteration 52540 (2.07708 iter/s, 4.81446s/10 iters), loss = 8.55782
I0523 05:07:42.814656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55782 (* 1 = 8.55782 loss)
I0523 05:07:42.890722 34819 sgd_solver.cpp:112] Iteration 52540, lr = 0.01
I0523 05:07:46.977164 34819 solver.cpp:239] Iteration 52550 (2.4025 iter/s, 4.16233s/10 iters), loss = 8.17861
I0523 05:07:46.977205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17861 (* 1 = 8.17861 loss)
I0523 05:07:47.698202 34819 sgd_solver.cpp:112] Iteration 52550, lr = 0.01
I0523 05:07:55.623651 34819 solver.cpp:239] Iteration 52560 (1.15659 iter/s, 8.64609s/10 iters), loss = 8.75298
I0523 05:07:55.623775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75298 (* 1 = 8.75298 loss)
I0523 05:07:55.697594 34819 sgd_solver.cpp:112] Iteration 52560, lr = 0.01
I0523 05:08:02.362357 34819 solver.cpp:239] Iteration 52570 (1.48405 iter/s, 6.73831s/10 iters), loss = 7.69479
I0523 05:08:02.362399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69479 (* 1 = 7.69479 loss)
I0523 05:08:02.425933 34819 sgd_solver.cpp:112] Iteration 52570, lr = 0.01
I0523 05:08:04.821446 34819 solver.cpp:239] Iteration 52580 (4.0668 iter/s, 2.45894s/10 iters), loss = 8.61077
I0523 05:08:04.821490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61077 (* 1 = 8.61077 loss)
I0523 05:08:05.653084 34819 sgd_solver.cpp:112] Iteration 52580, lr = 0.01
I0523 05:08:09.661592 34819 solver.cpp:239] Iteration 52590 (2.06616 iter/s, 4.8399s/10 iters), loss = 8.9055
I0523 05:08:09.661635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9055 (* 1 = 8.9055 loss)
I0523 05:08:09.724582 34819 sgd_solver.cpp:112] Iteration 52590, lr = 0.01
I0523 05:08:12.710065 34819 solver.cpp:239] Iteration 52600 (3.28054 iter/s, 3.04828s/10 iters), loss = 8.41112
I0523 05:08:12.710109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41112 (* 1 = 8.41112 loss)
I0523 05:08:13.482846 34819 sgd_solver.cpp:112] Iteration 52600, lr = 0.01
I0523 05:08:16.871421 34819 solver.cpp:239] Iteration 52610 (2.4032 iter/s, 4.16112s/10 iters), loss = 9.27262
I0523 05:08:16.871474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27262 (* 1 = 9.27262 loss)
I0523 05:08:17.411706 34819 sgd_solver.cpp:112] Iteration 52610, lr = 0.01
I0523 05:08:23.059520 34819 solver.cpp:239] Iteration 52620 (1.61609 iter/s, 6.18779s/10 iters), loss = 8.58462
I0523 05:08:23.059562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58462 (* 1 = 8.58462 loss)
I0523 05:08:23.131888 34819 sgd_solver.cpp:112] Iteration 52620, lr = 0.01
I0523 05:08:27.626771 34819 solver.cpp:239] Iteration 52630 (2.18961 iter/s, 4.56702s/10 iters), loss = 8.42648
I0523 05:08:27.627022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42648 (* 1 = 8.42648 loss)
I0523 05:08:27.694082 34819 sgd_solver.cpp:112] Iteration 52630, lr = 0.01
I0523 05:08:31.982283 34819 solver.cpp:239] Iteration 52640 (2.29616 iter/s, 4.3551s/10 iters), loss = 8.41521
I0523 05:08:31.982327 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41521 (* 1 = 8.41521 loss)
I0523 05:08:32.757393 34819 sgd_solver.cpp:112] Iteration 52640, lr = 0.01
I0523 05:08:36.245955 34819 solver.cpp:239] Iteration 52650 (2.34552 iter/s, 4.26344s/10 iters), loss = 8.90132
I0523 05:08:36.246008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90132 (* 1 = 8.90132 loss)
I0523 05:08:36.324105 34819 sgd_solver.cpp:112] Iteration 52650, lr = 0.01
I0523 05:08:39.636062 34819 solver.cpp:239] Iteration 52660 (2.94993 iter/s, 3.38991s/10 iters), loss = 8.26047
I0523 05:08:39.636103 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26047 (* 1 = 8.26047 loss)
I0523 05:08:39.696225 34819 sgd_solver.cpp:112] Iteration 52660, lr = 0.01
I0523 05:08:45.299944 34819 solver.cpp:239] Iteration 52670 (1.76566 iter/s, 5.6636s/10 iters), loss = 9.04675
I0523 05:08:45.299988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04675 (* 1 = 9.04675 loss)
I0523 05:08:46.075656 34819 sgd_solver.cpp:112] Iteration 52670, lr = 0.01
I0523 05:08:51.805008 34819 solver.cpp:239] Iteration 52680 (1.53734 iter/s, 6.50476s/10 iters), loss = 8.42462
I0523 05:08:51.805050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42462 (* 1 = 8.42462 loss)
I0523 05:08:51.880383 34819 sgd_solver.cpp:112] Iteration 52680, lr = 0.01
I0523 05:08:56.329946 34819 solver.cpp:239] Iteration 52690 (2.21009 iter/s, 4.52469s/10 iters), loss = 8.45601
I0523 05:08:56.329984 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45601 (* 1 = 8.45601 loss)
I0523 05:08:56.407470 34819 sgd_solver.cpp:112] Iteration 52690, lr = 0.01
I0523 05:09:02.022248 34819 solver.cpp:239] Iteration 52700 (1.75685 iter/s, 5.69202s/10 iters), loss = 8.16059
I0523 05:09:02.022465 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16059 (* 1 = 8.16059 loss)
I0523 05:09:02.085513 34819 sgd_solver.cpp:112] Iteration 52700, lr = 0.01
I0523 05:09:04.671195 34819 solver.cpp:239] Iteration 52710 (3.77554 iter/s, 2.64863s/10 iters), loss = 9.11619
I0523 05:09:04.671252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11619 (* 1 = 9.11619 loss)
I0523 05:09:05.523514 34819 sgd_solver.cpp:112] Iteration 52710, lr = 0.01
I0523 05:09:12.150632 34819 solver.cpp:239] Iteration 52720 (1.33707 iter/s, 7.47907s/10 iters), loss = 8.22381
I0523 05:09:12.150681 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22381 (* 1 = 8.22381 loss)
I0523 05:09:12.207720 34819 sgd_solver.cpp:112] Iteration 52720, lr = 0.01
I0523 05:09:17.249117 34819 solver.cpp:239] Iteration 52730 (1.96147 iter/s, 5.09823s/10 iters), loss = 9.16849
I0523 05:09:17.249158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16849 (* 1 = 9.16849 loss)
I0523 05:09:17.321241 34819 sgd_solver.cpp:112] Iteration 52730, lr = 0.01
I0523 05:09:19.339198 34819 solver.cpp:239] Iteration 52740 (4.78486 iter/s, 2.08993s/10 iters), loss = 8.99169
I0523 05:09:19.339251 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99169 (* 1 = 8.99169 loss)
I0523 05:09:19.413168 34819 sgd_solver.cpp:112] Iteration 52740, lr = 0.01
I0523 05:09:24.025965 34819 solver.cpp:239] Iteration 52750 (2.13378 iter/s, 4.68652s/10 iters), loss = 8.70391
I0523 05:09:24.026007 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70391 (* 1 = 8.70391 loss)
I0523 05:09:24.098498 34819 sgd_solver.cpp:112] Iteration 52750, lr = 0.01
I0523 05:09:28.337631 34819 solver.cpp:239] Iteration 52760 (2.31941 iter/s, 4.31144s/10 iters), loss = 8.86096
I0523 05:09:28.337672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86096 (* 1 = 8.86096 loss)
I0523 05:09:29.211128 34819 sgd_solver.cpp:112] Iteration 52760, lr = 0.01
I0523 05:09:34.762737 34819 solver.cpp:239] Iteration 52770 (1.55648 iter/s, 6.42477s/10 iters), loss = 8.85729
I0523 05:09:34.762975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85729 (* 1 = 8.85729 loss)
I0523 05:09:34.840023 34819 sgd_solver.cpp:112] Iteration 52770, lr = 0.01
I0523 05:09:39.713119 34819 solver.cpp:239] Iteration 52780 (2.02022 iter/s, 4.94996s/10 iters), loss = 8.0197
I0523 05:09:39.713163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0197 (* 1 = 8.0197 loss)
I0523 05:09:39.793804 34819 sgd_solver.cpp:112] Iteration 52780, lr = 0.01
I0523 05:09:45.432853 34819 solver.cpp:239] Iteration 52790 (1.74842 iter/s, 5.71946s/10 iters), loss = 8.68885
I0523 05:09:45.432899 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68885 (* 1 = 8.68885 loss)
I0523 05:09:46.269888 34819 sgd_solver.cpp:112] Iteration 52790, lr = 0.01
I0523 05:09:50.064316 34819 solver.cpp:239] Iteration 52800 (2.15926 iter/s, 4.63122s/10 iters), loss = 9.22755
I0523 05:09:50.064357 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22755 (* 1 = 9.22755 loss)
I0523 05:09:50.132479 34819 sgd_solver.cpp:112] Iteration 52800, lr = 0.01
I0523 05:09:53.415858 34819 solver.cpp:239] Iteration 52810 (2.98388 iter/s, 3.35135s/10 iters), loss = 8.3344
I0523 05:09:53.415900 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3344 (* 1 = 8.3344 loss)
I0523 05:09:54.295526 34819 sgd_solver.cpp:112] Iteration 52810, lr = 0.01
I0523 05:09:59.334365 34819 solver.cpp:239] Iteration 52820 (1.6897 iter/s, 5.91821s/10 iters), loss = 9.40095
I0523 05:09:59.334412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40095 (* 1 = 9.40095 loss)
I0523 05:10:00.163130 34819 sgd_solver.cpp:112] Iteration 52820, lr = 0.01
I0523 05:10:03.402796 34819 solver.cpp:239] Iteration 52830 (2.45808 iter/s, 4.06821s/10 iters), loss = 7.83924
I0523 05:10:03.402835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83924 (* 1 = 7.83924 loss)
I0523 05:10:04.223729 34819 sgd_solver.cpp:112] Iteration 52830, lr = 0.01
I0523 05:10:08.114647 34819 solver.cpp:239] Iteration 52840 (2.12243 iter/s, 4.71159s/10 iters), loss = 8.08846
I0523 05:10:08.114845 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08846 (* 1 = 8.08846 loss)
I0523 05:10:08.948319 34819 sgd_solver.cpp:112] Iteration 52840, lr = 0.01
I0523 05:10:12.764504 34819 solver.cpp:239] Iteration 52850 (2.15078 iter/s, 4.64947s/10 iters), loss = 8.87627
I0523 05:10:12.764559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87627 (* 1 = 8.87627 loss)
I0523 05:10:12.846004 34819 sgd_solver.cpp:112] Iteration 52850, lr = 0.01
I0523 05:10:17.416591 34819 solver.cpp:239] Iteration 52860 (2.14969 iter/s, 4.65184s/10 iters), loss = 9.33167
I0523 05:10:17.416636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.33167 (* 1 = 9.33167 loss)
I0523 05:10:17.487720 34819 sgd_solver.cpp:112] Iteration 52860, lr = 0.01
I0523 05:10:20.746732 34819 solver.cpp:239] Iteration 52870 (3.00306 iter/s, 3.32993s/10 iters), loss = 8.81521
I0523 05:10:20.746779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81521 (* 1 = 8.81521 loss)
I0523 05:10:20.805780 34819 sgd_solver.cpp:112] Iteration 52870, lr = 0.01
I0523 05:10:25.658777 34819 solver.cpp:239] Iteration 52880 (2.03592 iter/s, 4.91178s/10 iters), loss = 8.51714
I0523 05:10:25.658819 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51714 (* 1 = 8.51714 loss)
I0523 05:10:25.737089 34819 sgd_solver.cpp:112] Iteration 52880, lr = 0.01
I0523 05:10:29.949893 34819 solver.cpp:239] Iteration 52890 (2.33053 iter/s, 4.29088s/10 iters), loss = 8.69978
I0523 05:10:29.949939 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69978 (* 1 = 8.69978 loss)
I0523 05:10:30.007652 34819 sgd_solver.cpp:112] Iteration 52890, lr = 0.01
I0523 05:10:35.686779 34819 solver.cpp:239] Iteration 52900 (1.74319 iter/s, 5.73661s/10 iters), loss = 8.32924
I0523 05:10:35.686820 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32924 (* 1 = 8.32924 loss)
I0523 05:10:35.751711 34819 sgd_solver.cpp:112] Iteration 52900, lr = 0.01
I0523 05:10:39.526818 34819 solver.cpp:239] Iteration 52910 (2.60428 iter/s, 3.83983s/10 iters), loss = 9.18811
I0523 05:10:39.526988 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.18811 (* 1 = 9.18811 loss)
I0523 05:10:39.585603 34819 sgd_solver.cpp:112] Iteration 52910, lr = 0.01
I0523 05:10:45.315987 34819 solver.cpp:239] Iteration 52920 (1.72749 iter/s, 5.78876s/10 iters), loss = 8.61195
I0523 05:10:45.316035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61195 (* 1 = 8.61195 loss)
I0523 05:10:45.915870 34819 sgd_solver.cpp:112] Iteration 52920, lr = 0.01
I0523 05:10:49.303573 34819 solver.cpp:239] Iteration 52930 (2.50792 iter/s, 3.98737s/10 iters), loss = 7.80289
I0523 05:10:49.303617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80289 (* 1 = 7.80289 loss)
I0523 05:10:49.356832 34819 sgd_solver.cpp:112] Iteration 52930, lr = 0.01
I0523 05:10:54.565469 34819 solver.cpp:239] Iteration 52940 (1.90055 iter/s, 5.26163s/10 iters), loss = 8.92673
I0523 05:10:54.565518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92673 (* 1 = 8.92673 loss)
I0523 05:10:55.402139 34819 sgd_solver.cpp:112] Iteration 52940, lr = 0.01
I0523 05:10:58.787904 34819 solver.cpp:239] Iteration 52950 (2.36843 iter/s, 4.2222s/10 iters), loss = 8.71062
I0523 05:10:58.787959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71062 (* 1 = 8.71062 loss)
I0523 05:10:59.632400 34819 sgd_solver.cpp:112] Iteration 52950, lr = 0.01
I0523 05:11:04.133136 34819 solver.cpp:239] Iteration 52960 (1.87092 iter/s, 5.34496s/10 iters), loss = 8.41662
I0523 05:11:04.133186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41662 (* 1 = 8.41662 loss)
I0523 05:11:04.936818 34819 sgd_solver.cpp:112] Iteration 52960, lr = 0.01
I0523 05:11:10.728682 34819 solver.cpp:239] Iteration 52970 (1.51625 iter/s, 6.59521s/10 iters), loss = 7.48828
I0523 05:11:10.728826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.48828 (* 1 = 7.48828 loss)
I0523 05:11:10.788405 34819 sgd_solver.cpp:112] Iteration 52970, lr = 0.01
I0523 05:11:16.264958 34819 solver.cpp:239] Iteration 52980 (1.80639 iter/s, 5.53589s/10 iters), loss = 8.57665
I0523 05:11:16.265015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57665 (* 1 = 8.57665 loss)
I0523 05:11:16.334331 34819 sgd_solver.cpp:112] Iteration 52980, lr = 0.01
I0523 05:11:21.524426 34819 solver.cpp:239] Iteration 52990 (1.90144 iter/s, 5.25917s/10 iters), loss = 9.39198
I0523 05:11:21.524488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.39198 (* 1 = 9.39198 loss)
I0523 05:11:22.259621 34819 sgd_solver.cpp:112] Iteration 52990, lr = 0.01
I0523 05:11:25.659548 34819 solver.cpp:239] Iteration 53000 (2.41845 iter/s, 4.13489s/10 iters), loss = 8.78382
I0523 05:11:25.659598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78382 (* 1 = 8.78382 loss)
I0523 05:11:25.716776 34819 sgd_solver.cpp:112] Iteration 53000, lr = 0.01
I0523 05:11:30.282515 34819 solver.cpp:239] Iteration 53010 (2.16323 iter/s, 4.62272s/10 iters), loss = 8.95836
I0523 05:11:30.282573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95836 (* 1 = 8.95836 loss)
I0523 05:11:31.150924 34819 sgd_solver.cpp:112] Iteration 53010, lr = 0.01
I0523 05:11:34.595731 34819 solver.cpp:239] Iteration 53020 (2.31858 iter/s, 4.31298s/10 iters), loss = 8.03586
I0523 05:11:34.595772 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03586 (* 1 = 8.03586 loss)
I0523 05:11:35.395326 34819 sgd_solver.cpp:112] Iteration 53020, lr = 0.01
I0523 05:11:39.328507 34819 solver.cpp:239] Iteration 53030 (2.11303 iter/s, 4.73254s/10 iters), loss = 9.13502
I0523 05:11:39.328548 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13502 (* 1 = 9.13502 loss)
I0523 05:11:39.400781 34819 sgd_solver.cpp:112] Iteration 53030, lr = 0.01
I0523 05:11:43.578615 34819 solver.cpp:239] Iteration 53040 (2.35301 iter/s, 4.24988s/10 iters), loss = 7.81849
I0523 05:11:43.578799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81849 (* 1 = 7.81849 loss)
I0523 05:11:43.648955 34819 sgd_solver.cpp:112] Iteration 53040, lr = 0.01
I0523 05:11:47.667745 34819 solver.cpp:239] Iteration 53050 (2.44572 iter/s, 4.08877s/10 iters), loss = 7.86596
I0523 05:11:47.667804 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86596 (* 1 = 7.86596 loss)
I0523 05:11:48.457751 34819 sgd_solver.cpp:112] Iteration 53050, lr = 0.01
I0523 05:11:53.324810 34819 solver.cpp:239] Iteration 53060 (1.7678 iter/s, 5.65673s/10 iters), loss = 8.51429
I0523 05:11:53.324858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51429 (* 1 = 8.51429 loss)
I0523 05:11:54.070870 34819 sgd_solver.cpp:112] Iteration 53060, lr = 0.01
I0523 05:11:59.697360 34819 solver.cpp:239] Iteration 53070 (1.56931 iter/s, 6.37221s/10 iters), loss = 8.02861
I0523 05:11:59.697417 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02861 (* 1 = 8.02861 loss)
I0523 05:11:59.800374 34819 sgd_solver.cpp:112] Iteration 53070, lr = 0.01
I0523 05:12:03.807479 34819 solver.cpp:239] Iteration 53080 (2.43316 iter/s, 4.10988s/10 iters), loss = 8.15981
I0523 05:12:03.807518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15981 (* 1 = 8.15981 loss)
I0523 05:12:04.551461 34819 sgd_solver.cpp:112] Iteration 53080, lr = 0.01
I0523 05:12:08.195854 34819 solver.cpp:239] Iteration 53090 (2.27886 iter/s, 4.38815s/10 iters), loss = 8.28704
I0523 05:12:08.195896 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28704 (* 1 = 8.28704 loss)
I0523 05:12:08.818716 34819 sgd_solver.cpp:112] Iteration 53090, lr = 0.01
I0523 05:12:12.381456 34819 solver.cpp:239] Iteration 53100 (2.38928 iter/s, 4.18537s/10 iters), loss = 8.18816
I0523 05:12:12.381510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18816 (* 1 = 8.18816 loss)
I0523 05:12:13.011471 34819 sgd_solver.cpp:112] Iteration 53100, lr = 0.01
I0523 05:12:16.486496 34819 solver.cpp:239] Iteration 53110 (2.43617 iter/s, 4.10481s/10 iters), loss = 7.96795
I0523 05:12:16.486627 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96795 (* 1 = 7.96795 loss)
I0523 05:12:16.544178 34819 sgd_solver.cpp:112] Iteration 53110, lr = 0.01
I0523 05:12:20.395572 34819 solver.cpp:239] Iteration 53120 (2.55834 iter/s, 3.90878s/10 iters), loss = 8.53825
I0523 05:12:20.395622 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53825 (* 1 = 8.53825 loss)
I0523 05:12:20.458238 34819 sgd_solver.cpp:112] Iteration 53120, lr = 0.01
I0523 05:12:25.023381 34819 solver.cpp:239] Iteration 53130 (2.16096 iter/s, 4.62757s/10 iters), loss = 8.26391
I0523 05:12:25.023429 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26391 (* 1 = 8.26391 loss)
I0523 05:12:25.098081 34819 sgd_solver.cpp:112] Iteration 53130, lr = 0.01
I0523 05:12:30.673933 34819 solver.cpp:239] Iteration 53140 (1.76983 iter/s, 5.65027s/10 iters), loss = 8.0985
I0523 05:12:30.673975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0985 (* 1 = 8.0985 loss)
I0523 05:12:30.731454 34819 sgd_solver.cpp:112] Iteration 53140, lr = 0.01
I0523 05:12:35.528146 34819 solver.cpp:239] Iteration 53150 (2.06017 iter/s, 4.85396s/10 iters), loss = 8.28732
I0523 05:12:35.528187 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28732 (* 1 = 8.28732 loss)
I0523 05:12:36.344717 34819 sgd_solver.cpp:112] Iteration 53150, lr = 0.01
I0523 05:12:41.529388 34819 solver.cpp:239] Iteration 53160 (1.66641 iter/s, 6.00094s/10 iters), loss = 8.18602
I0523 05:12:41.529444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18602 (* 1 = 8.18602 loss)
I0523 05:12:41.618119 34819 sgd_solver.cpp:112] Iteration 53160, lr = 0.01
I0523 05:12:48.423053 34819 solver.cpp:239] Iteration 53170 (1.45068 iter/s, 6.89333s/10 iters), loss = 8.3854
I0523 05:12:48.423168 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3854 (* 1 = 8.3854 loss)
I0523 05:12:48.493541 34819 sgd_solver.cpp:112] Iteration 53170, lr = 0.01
I0523 05:12:53.346779 34819 solver.cpp:239] Iteration 53180 (2.03112 iter/s, 4.9234s/10 iters), loss = 7.85818
I0523 05:12:53.346843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85818 (* 1 = 7.85818 loss)
I0523 05:12:53.865126 34819 sgd_solver.cpp:112] Iteration 53180, lr = 0.01
I0523 05:12:59.808900 34819 solver.cpp:239] Iteration 53190 (1.54756 iter/s, 6.4618s/10 iters), loss = 8.17331
I0523 05:12:59.808953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17331 (* 1 = 8.17331 loss)
I0523 05:13:00.563100 34819 sgd_solver.cpp:112] Iteration 53190, lr = 0.01
I0523 05:13:04.584081 34819 solver.cpp:239] Iteration 53200 (2.09428 iter/s, 4.77492s/10 iters), loss = 8.9221
I0523 05:13:04.584131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9221 (* 1 = 8.9221 loss)
I0523 05:13:04.653518 34819 sgd_solver.cpp:112] Iteration 53200, lr = 0.01
I0523 05:13:08.825943 34819 solver.cpp:239] Iteration 53210 (2.35759 iter/s, 4.24162s/10 iters), loss = 8.97521
I0523 05:13:08.825994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97521 (* 1 = 8.97521 loss)
I0523 05:13:09.267136 34819 sgd_solver.cpp:112] Iteration 53210, lr = 0.01
I0523 05:13:13.777783 34819 solver.cpp:239] Iteration 53220 (2.01956 iter/s, 4.95157s/10 iters), loss = 8.19764
I0523 05:13:13.777837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19764 (* 1 = 8.19764 loss)
I0523 05:13:13.854631 34819 sgd_solver.cpp:112] Iteration 53220, lr = 0.01
I0523 05:13:18.748965 34819 solver.cpp:239] Iteration 53230 (2.0117 iter/s, 4.97092s/10 iters), loss = 8.07511
I0523 05:13:18.749131 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07511 (* 1 = 8.07511 loss)
I0523 05:13:19.588591 34819 sgd_solver.cpp:112] Iteration 53230, lr = 0.01
I0523 05:13:22.312420 34819 solver.cpp:239] Iteration 53240 (2.80651 iter/s, 3.56314s/10 iters), loss = 7.84745
I0523 05:13:22.312463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84745 (* 1 = 7.84745 loss)
I0523 05:13:22.379478 34819 sgd_solver.cpp:112] Iteration 53240, lr = 0.01
I0523 05:13:26.418042 34819 solver.cpp:239] Iteration 53250 (2.43581 iter/s, 4.10541s/10 iters), loss = 9.5175
I0523 05:13:26.418084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.5175 (* 1 = 9.5175 loss)
I0523 05:13:27.063992 34819 sgd_solver.cpp:112] Iteration 53250, lr = 0.01
I0523 05:13:32.563622 34819 solver.cpp:239] Iteration 53260 (1.62726 iter/s, 6.14529s/10 iters), loss = 8.39851
I0523 05:13:32.563665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39851 (* 1 = 8.39851 loss)
I0523 05:13:32.632803 34819 sgd_solver.cpp:112] Iteration 53260, lr = 0.01
I0523 05:13:36.192793 34819 solver.cpp:239] Iteration 53270 (2.75561 iter/s, 3.62896s/10 iters), loss = 8.5721
I0523 05:13:36.192848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5721 (* 1 = 8.5721 loss)
I0523 05:13:36.497167 34819 sgd_solver.cpp:112] Iteration 53270, lr = 0.01
I0523 05:13:40.675774 34819 solver.cpp:239] Iteration 53280 (2.23078 iter/s, 4.48274s/10 iters), loss = 8.67886
I0523 05:13:40.675825 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67886 (* 1 = 8.67886 loss)
I0523 05:13:40.746408 34819 sgd_solver.cpp:112] Iteration 53280, lr = 0.01
I0523 05:13:44.496970 34819 solver.cpp:239] Iteration 53290 (2.61713 iter/s, 3.82098s/10 iters), loss = 8.30765
I0523 05:13:44.497012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30765 (* 1 = 8.30765 loss)
I0523 05:13:44.568122 34819 sgd_solver.cpp:112] Iteration 53290, lr = 0.01
I0523 05:13:48.741315 34819 solver.cpp:239] Iteration 53300 (2.3562 iter/s, 4.24413s/10 iters), loss = 9.14481
I0523 05:13:48.741358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14481 (* 1 = 9.14481 loss)
I0523 05:13:48.816969 34819 sgd_solver.cpp:112] Iteration 53300, lr = 0.01
I0523 05:13:52.571781 34819 solver.cpp:239] Iteration 53310 (2.61079 iter/s, 3.83026s/10 iters), loss = 9.75217
I0523 05:13:52.571825 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75217 (* 1 = 9.75217 loss)
I0523 05:13:53.160630 34819 sgd_solver.cpp:112] Iteration 53310, lr = 0.01
I0523 05:13:56.919963 34819 solver.cpp:239] Iteration 53320 (2.29993 iter/s, 4.34795s/10 iters), loss = 7.51557
I0523 05:13:56.920018 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51557 (* 1 = 7.51557 loss)
I0523 05:13:57.751834 34819 sgd_solver.cpp:112] Iteration 53320, lr = 0.01
I0523 05:14:02.461215 34819 solver.cpp:239] Iteration 53330 (1.80474 iter/s, 5.54097s/10 iters), loss = 8.19584
I0523 05:14:02.461271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19584 (* 1 = 8.19584 loss)
I0523 05:14:02.522109 34819 sgd_solver.cpp:112] Iteration 53330, lr = 0.01
I0523 05:14:06.817137 34819 solver.cpp:239] Iteration 53340 (2.29585 iter/s, 4.35568s/10 iters), loss = 8.6616
I0523 05:14:06.817179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6616 (* 1 = 8.6616 loss)
I0523 05:14:07.612437 34819 sgd_solver.cpp:112] Iteration 53340, lr = 0.01
I0523 05:14:11.906508 34819 solver.cpp:239] Iteration 53350 (1.96498 iter/s, 5.08912s/10 iters), loss = 9.34459
I0523 05:14:11.906556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34459 (* 1 = 9.34459 loss)
I0523 05:14:12.495334 34819 sgd_solver.cpp:112] Iteration 53350, lr = 0.01
I0523 05:14:17.648353 34819 solver.cpp:239] Iteration 53360 (1.74169 iter/s, 5.74154s/10 iters), loss = 7.64914
I0523 05:14:17.648394 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64914 (* 1 = 7.64914 loss)
I0523 05:14:18.513919 34819 sgd_solver.cpp:112] Iteration 53360, lr = 0.01
I0523 05:14:24.220667 34819 solver.cpp:239] Iteration 53370 (1.52161 iter/s, 6.57199s/10 iters), loss = 8.21124
I0523 05:14:24.220836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21124 (* 1 = 8.21124 loss)
I0523 05:14:24.295388 34819 sgd_solver.cpp:112] Iteration 53370, lr = 0.01
I0523 05:14:28.439162 34819 solver.cpp:239] Iteration 53380 (2.37072 iter/s, 4.21813s/10 iters), loss = 8.26333
I0523 05:14:28.439225 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26333 (* 1 = 8.26333 loss)
I0523 05:14:29.300357 34819 sgd_solver.cpp:112] Iteration 53380, lr = 0.01
I0523 05:14:32.386023 34819 solver.cpp:239] Iteration 53390 (2.53381 iter/s, 3.94663s/10 iters), loss = 8.05421
I0523 05:14:32.386073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05421 (* 1 = 8.05421 loss)
I0523 05:14:33.206295 34819 sgd_solver.cpp:112] Iteration 53390, lr = 0.01
I0523 05:14:39.237062 34819 solver.cpp:239] Iteration 53400 (1.4597 iter/s, 6.8507s/10 iters), loss = 8.4385
I0523 05:14:39.237103 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4385 (* 1 = 8.4385 loss)
I0523 05:14:40.088353 34819 sgd_solver.cpp:112] Iteration 53400, lr = 0.01
I0523 05:14:44.881866 34819 solver.cpp:239] Iteration 53410 (1.77163 iter/s, 5.64452s/10 iters), loss = 8.57442
I0523 05:14:44.881906 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57442 (* 1 = 8.57442 loss)
I0523 05:14:45.666748 34819 sgd_solver.cpp:112] Iteration 53410, lr = 0.01
I0523 05:14:52.400296 34819 solver.cpp:239] Iteration 53420 (1.33013 iter/s, 7.51807s/10 iters), loss = 8.13877
I0523 05:14:52.400346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13877 (* 1 = 8.13877 loss)
I0523 05:14:53.249188 34819 sgd_solver.cpp:112] Iteration 53420, lr = 0.01
I0523 05:14:57.523187 34819 solver.cpp:239] Iteration 53430 (1.95213 iter/s, 5.12261s/10 iters), loss = 7.68868
I0523 05:14:57.523396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68868 (* 1 = 7.68868 loss)
I0523 05:14:58.286733 34819 sgd_solver.cpp:112] Iteration 53430, lr = 0.01
I0523 05:15:03.184835 34819 solver.cpp:239] Iteration 53440 (1.76641 iter/s, 5.66121s/10 iters), loss = 7.99958
I0523 05:15:03.184888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99958 (* 1 = 7.99958 loss)
I0523 05:15:03.484549 34819 sgd_solver.cpp:112] Iteration 53440, lr = 0.01
I0523 05:15:07.462611 34819 solver.cpp:239] Iteration 53450 (2.33779 iter/s, 4.27755s/10 iters), loss = 9.04159
I0523 05:15:07.462652 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04159 (* 1 = 9.04159 loss)
I0523 05:15:07.530911 34819 sgd_solver.cpp:112] Iteration 53450, lr = 0.01
I0523 05:15:11.623307 34819 solver.cpp:239] Iteration 53460 (2.40357 iter/s, 4.16048s/10 iters), loss = 9.24067
I0523 05:15:11.623363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24067 (* 1 = 9.24067 loss)
I0523 05:15:11.689651 34819 sgd_solver.cpp:112] Iteration 53460, lr = 0.01
I0523 05:15:14.180698 34819 solver.cpp:239] Iteration 53470 (3.9105 iter/s, 2.55722s/10 iters), loss = 9.99525
I0523 05:15:14.180752 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.99525 (* 1 = 9.99525 loss)
I0523 05:15:14.849386 34819 sgd_solver.cpp:112] Iteration 53470, lr = 0.01
I0523 05:15:20.566758 34819 solver.cpp:239] Iteration 53480 (1.56599 iter/s, 6.38574s/10 iters), loss = 8.81814
I0523 05:15:20.566819 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81814 (* 1 = 8.81814 loss)
I0523 05:15:21.382483 34819 sgd_solver.cpp:112] Iteration 53480, lr = 0.01
I0523 05:15:26.846822 34819 solver.cpp:239] Iteration 53490 (1.59242 iter/s, 6.27975s/10 iters), loss = 8.9212
I0523 05:15:26.846865 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9212 (* 1 = 8.9212 loss)
I0523 05:15:27.049118 34819 sgd_solver.cpp:112] Iteration 53490, lr = 0.01
I0523 05:15:29.826546 34819 solver.cpp:239] Iteration 53500 (3.35621 iter/s, 2.97955s/10 iters), loss = 8.42955
I0523 05:15:29.826712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42955 (* 1 = 8.42955 loss)
I0523 05:15:29.913314 34819 sgd_solver.cpp:112] Iteration 53500, lr = 0.01
I0523 05:15:34.784649 34819 solver.cpp:239] Iteration 53510 (2.01705 iter/s, 4.95774s/10 iters), loss = 8.40325
I0523 05:15:34.784711 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40325 (* 1 = 8.40325 loss)
I0523 05:15:34.820467 34819 sgd_solver.cpp:112] Iteration 53510, lr = 0.01
I0523 05:15:36.017918 34819 solver.cpp:239] Iteration 53520 (8.10931 iter/s, 1.23315s/10 iters), loss = 9.1895
I0523 05:15:36.017967 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1895 (* 1 = 9.1895 loss)
I0523 05:15:36.057443 34819 sgd_solver.cpp:112] Iteration 53520, lr = 0.01
I0523 05:15:37.697252 34819 solver.cpp:239] Iteration 53530 (5.95519 iter/s, 1.67921s/10 iters), loss = 8.87725
I0523 05:15:37.697296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87725 (* 1 = 8.87725 loss)
I0523 05:15:37.740087 34819 sgd_solver.cpp:112] Iteration 53530, lr = 0.01
I0523 05:15:42.336119 34819 solver.cpp:239] Iteration 53540 (2.15581 iter/s, 4.63862s/10 iters), loss = 7.63003
I0523 05:15:42.336159 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63003 (* 1 = 7.63003 loss)
I0523 05:15:43.152950 34819 sgd_solver.cpp:112] Iteration 53540, lr = 0.01
I0523 05:15:47.938024 34819 solver.cpp:239] Iteration 53550 (1.78519 iter/s, 5.60163s/10 iters), loss = 8.39163
I0523 05:15:47.938078 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39163 (* 1 = 8.39163 loss)
I0523 05:15:47.990705 34819 sgd_solver.cpp:112] Iteration 53550, lr = 0.01
I0523 05:15:52.577266 34819 solver.cpp:239] Iteration 53560 (2.15564 iter/s, 4.639s/10 iters), loss = 8.40702
I0523 05:15:52.577308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40702 (* 1 = 8.40702 loss)
I0523 05:15:52.634860 34819 sgd_solver.cpp:112] Iteration 53560, lr = 0.01
I0523 05:15:56.679996 34819 solver.cpp:239] Iteration 53570 (2.43753 iter/s, 4.10251s/10 iters), loss = 8.02028
I0523 05:15:56.680042 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02028 (* 1 = 8.02028 loss)
I0523 05:15:57.346843 34819 sgd_solver.cpp:112] Iteration 53570, lr = 0.01
I0523 05:16:00.697870 34819 solver.cpp:239] Iteration 53580 (2.48902 iter/s, 4.01765s/10 iters), loss = 9.49139
I0523 05:16:00.698107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49139 (* 1 = 9.49139 loss)
I0523 05:16:00.755769 34819 sgd_solver.cpp:112] Iteration 53580, lr = 0.01
I0523 05:16:06.896394 34819 solver.cpp:239] Iteration 53590 (1.61341 iter/s, 6.19806s/10 iters), loss = 9.063
I0523 05:16:06.896442 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.063 (* 1 = 9.063 loss)
I0523 05:16:07.176980 34819 sgd_solver.cpp:112] Iteration 53590, lr = 0.01
I0523 05:16:12.887300 34819 solver.cpp:239] Iteration 53600 (1.66928 iter/s, 5.9906s/10 iters), loss = 7.93888
I0523 05:16:12.887339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93888 (* 1 = 7.93888 loss)
I0523 05:16:13.734285 34819 sgd_solver.cpp:112] Iteration 53600, lr = 0.01
I0523 05:16:16.994266 34819 solver.cpp:239] Iteration 53610 (2.43502 iter/s, 4.10674s/10 iters), loss = 8.46218
I0523 05:16:16.994307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46218 (* 1 = 8.46218 loss)
I0523 05:16:17.074857 34819 sgd_solver.cpp:112] Iteration 53610, lr = 0.01
I0523 05:16:22.603780 34819 solver.cpp:239] Iteration 53620 (1.78277 iter/s, 5.60924s/10 iters), loss = 8.13835
I0523 05:16:22.603823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13835 (* 1 = 8.13835 loss)
I0523 05:16:23.469776 34819 sgd_solver.cpp:112] Iteration 53620, lr = 0.01
I0523 05:16:26.861062 34819 solver.cpp:239] Iteration 53630 (2.34904 iter/s, 4.25705s/10 iters), loss = 8.85679
I0523 05:16:26.861102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85679 (* 1 = 8.85679 loss)
I0523 05:16:27.727840 34819 sgd_solver.cpp:112] Iteration 53630, lr = 0.01
I0523 05:16:32.112259 34819 solver.cpp:239] Iteration 53640 (1.90442 iter/s, 5.25093s/10 iters), loss = 8.58338
I0523 05:16:32.112355 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58338 (* 1 = 8.58338 loss)
I0523 05:16:32.638835 34819 sgd_solver.cpp:112] Iteration 53640, lr = 0.01
I0523 05:16:37.403306 34819 solver.cpp:239] Iteration 53650 (1.89011 iter/s, 5.29069s/10 iters), loss = 8.79234
I0523 05:16:37.403372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79234 (* 1 = 8.79234 loss)
I0523 05:16:38.192116 34819 sgd_solver.cpp:112] Iteration 53650, lr = 0.01
I0523 05:16:41.449118 34819 solver.cpp:239] Iteration 53660 (2.47183 iter/s, 4.04558s/10 iters), loss = 7.9472
I0523 05:16:41.449163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9472 (* 1 = 7.9472 loss)
I0523 05:16:42.308001 34819 sgd_solver.cpp:112] Iteration 53660, lr = 0.01
I0523 05:16:46.627517 34819 solver.cpp:239] Iteration 53670 (1.9312 iter/s, 5.17813s/10 iters), loss = 8.3643
I0523 05:16:46.627558 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3643 (* 1 = 8.3643 loss)
I0523 05:16:47.386627 34819 sgd_solver.cpp:112] Iteration 53670, lr = 0.01
I0523 05:16:52.911171 34819 solver.cpp:239] Iteration 53680 (1.59151 iter/s, 6.28334s/10 iters), loss = 7.95103
I0523 05:16:52.911222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95103 (* 1 = 7.95103 loss)
I0523 05:16:52.979176 34819 sgd_solver.cpp:112] Iteration 53680, lr = 0.01
I0523 05:16:56.990540 34819 solver.cpp:239] Iteration 53690 (2.45151 iter/s, 4.07912s/10 iters), loss = 8.54428
I0523 05:16:56.990594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54428 (* 1 = 8.54428 loss)
I0523 05:16:57.744920 34819 sgd_solver.cpp:112] Iteration 53690, lr = 0.01
I0523 05:17:03.135210 34819 solver.cpp:239] Iteration 53700 (1.62751 iter/s, 6.14436s/10 iters), loss = 9.24455
I0523 05:17:03.135406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24455 (* 1 = 9.24455 loss)
I0523 05:17:03.212312 34819 sgd_solver.cpp:112] Iteration 53700, lr = 0.01
I0523 05:17:09.116227 34819 solver.cpp:239] Iteration 53710 (1.67207 iter/s, 5.9806s/10 iters), loss = 8.66886
I0523 05:17:09.116272 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66886 (* 1 = 8.66886 loss)
I0523 05:17:09.872607 34819 sgd_solver.cpp:112] Iteration 53710, lr = 0.01
I0523 05:17:13.780133 34819 solver.cpp:239] Iteration 53720 (2.14424 iter/s, 4.66366s/10 iters), loss = 9.3599
I0523 05:17:13.780184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3599 (* 1 = 9.3599 loss)
I0523 05:17:13.843302 34819 sgd_solver.cpp:112] Iteration 53720, lr = 0.01
I0523 05:17:17.760035 34819 solver.cpp:239] Iteration 53730 (2.51277 iter/s, 3.97968s/10 iters), loss = 8.90767
I0523 05:17:17.760092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90767 (* 1 = 8.90767 loss)
I0523 05:17:17.818960 34819 sgd_solver.cpp:112] Iteration 53730, lr = 0.01
I0523 05:17:24.235114 34819 solver.cpp:239] Iteration 53740 (1.54446 iter/s, 6.47475s/10 iters), loss = 7.96729
I0523 05:17:24.235170 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96729 (* 1 = 7.96729 loss)
I0523 05:17:25.067791 34819 sgd_solver.cpp:112] Iteration 53740, lr = 0.01
I0523 05:17:29.968186 34819 solver.cpp:239] Iteration 53750 (1.74435 iter/s, 5.73278s/10 iters), loss = 7.95847
I0523 05:17:29.968245 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95847 (* 1 = 7.95847 loss)
I0523 05:17:30.020923 34819 sgd_solver.cpp:112] Iteration 53750, lr = 0.01
I0523 05:17:35.647064 34819 solver.cpp:239] Iteration 53760 (1.761 iter/s, 5.67858s/10 iters), loss = 8.89238
I0523 05:17:35.647195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89238 (* 1 = 8.89238 loss)
I0523 05:17:35.739826 34819 sgd_solver.cpp:112] Iteration 53760, lr = 0.01
I0523 05:17:39.777441 34819 solver.cpp:239] Iteration 53770 (2.42127 iter/s, 4.13007s/10 iters), loss = 7.77827
I0523 05:17:39.777489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77827 (* 1 = 7.77827 loss)
I0523 05:17:40.669700 34819 sgd_solver.cpp:112] Iteration 53770, lr = 0.01
I0523 05:17:44.678453 34819 solver.cpp:239] Iteration 53780 (2.0405 iter/s, 4.90076s/10 iters), loss = 9.34023
I0523 05:17:44.678495 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.34023 (* 1 = 9.34023 loss)
I0523 05:17:44.733181 34819 sgd_solver.cpp:112] Iteration 53780, lr = 0.01
I0523 05:17:47.517693 34819 solver.cpp:239] Iteration 53790 (3.52229 iter/s, 2.83906s/10 iters), loss = 8.24075
I0523 05:17:47.517748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24075 (* 1 = 8.24075 loss)
I0523 05:17:47.593736 34819 sgd_solver.cpp:112] Iteration 53790, lr = 0.01
I0523 05:17:52.377132 34819 solver.cpp:239] Iteration 53800 (2.05796 iter/s, 4.85917s/10 iters), loss = 8.57829
I0523 05:17:52.377185 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57829 (* 1 = 8.57829 loss)
I0523 05:17:52.445114 34819 sgd_solver.cpp:112] Iteration 53800, lr = 0.01
I0523 05:17:56.713403 34819 solver.cpp:239] Iteration 53810 (2.30759 iter/s, 4.33353s/10 iters), loss = 7.90527
I0523 05:17:56.713456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90527 (* 1 = 7.90527 loss)
I0523 05:17:57.568843 34819 sgd_solver.cpp:112] Iteration 53810, lr = 0.01
I0523 05:18:03.200397 34819 solver.cpp:239] Iteration 53820 (1.54162 iter/s, 6.48667s/10 iters), loss = 8.97174
I0523 05:18:03.200471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97174 (* 1 = 8.97174 loss)
I0523 05:18:03.268573 34819 sgd_solver.cpp:112] Iteration 53820, lr = 0.01
I0523 05:18:08.406628 34819 solver.cpp:239] Iteration 53830 (1.92088 iter/s, 5.20594s/10 iters), loss = 8.36096
I0523 05:18:08.406755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36096 (* 1 = 8.36096 loss)
I0523 05:18:08.471185 34819 sgd_solver.cpp:112] Iteration 53830, lr = 0.01
I0523 05:18:14.224859 34819 solver.cpp:239] Iteration 53840 (1.71884 iter/s, 5.81786s/10 iters), loss = 8.92011
I0523 05:18:14.224901 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92011 (* 1 = 8.92011 loss)
I0523 05:18:14.299224 34819 sgd_solver.cpp:112] Iteration 53840, lr = 0.01
I0523 05:18:18.451020 34819 solver.cpp:239] Iteration 53850 (2.36634 iter/s, 4.22593s/10 iters), loss = 7.38408
I0523 05:18:18.451077 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38408 (* 1 = 7.38408 loss)
I0523 05:18:19.317142 34819 sgd_solver.cpp:112] Iteration 53850, lr = 0.01
I0523 05:18:22.662864 34819 solver.cpp:239] Iteration 53860 (2.37439 iter/s, 4.21161s/10 iters), loss = 8.49955
I0523 05:18:22.662906 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49955 (* 1 = 8.49955 loss)
I0523 05:18:23.467520 34819 sgd_solver.cpp:112] Iteration 53860, lr = 0.01
I0523 05:18:28.167762 34819 solver.cpp:239] Iteration 53870 (1.81666 iter/s, 5.50462s/10 iters), loss = 8.00636
I0523 05:18:28.167811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00636 (* 1 = 8.00636 loss)
I0523 05:18:28.913544 34819 sgd_solver.cpp:112] Iteration 53870, lr = 0.01
I0523 05:18:33.047338 34819 solver.cpp:239] Iteration 53880 (2.04946 iter/s, 4.87932s/10 iters), loss = 8.75842
I0523 05:18:33.047379 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75842 (* 1 = 8.75842 loss)
I0523 05:18:33.105770 34819 sgd_solver.cpp:112] Iteration 53880, lr = 0.01
I0523 05:18:35.925739 34819 solver.cpp:239] Iteration 53890 (3.47438 iter/s, 2.87821s/10 iters), loss = 8.74125
I0523 05:18:35.925787 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74125 (* 1 = 8.74125 loss)
I0523 05:18:36.640755 34819 sgd_solver.cpp:112] Iteration 53890, lr = 0.01
I0523 05:18:41.472149 34819 solver.cpp:239] Iteration 53900 (1.80306 iter/s, 5.54613s/10 iters), loss = 8.49308
I0523 05:18:41.472299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49308 (* 1 = 8.49308 loss)
I0523 05:18:41.533354 34819 sgd_solver.cpp:112] Iteration 53900, lr = 0.01
I0523 05:18:46.055279 34819 solver.cpp:239] Iteration 53910 (2.18209 iter/s, 4.58277s/10 iters), loss = 8.31679
I0523 05:18:46.055337 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31679 (* 1 = 8.31679 loss)
I0523 05:18:46.927798 34819 sgd_solver.cpp:112] Iteration 53910, lr = 0.01
I0523 05:18:50.229528 34819 solver.cpp:239] Iteration 53920 (2.39578 iter/s, 4.17401s/10 iters), loss = 8.90269
I0523 05:18:50.229569 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90269 (* 1 = 8.90269 loss)
I0523 05:18:50.294634 34819 sgd_solver.cpp:112] Iteration 53920, lr = 0.01
I0523 05:18:54.192476 34819 solver.cpp:239] Iteration 53930 (2.52351 iter/s, 3.96273s/10 iters), loss = 7.68759
I0523 05:18:54.192522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68759 (* 1 = 7.68759 loss)
I0523 05:18:54.250387 34819 sgd_solver.cpp:112] Iteration 53930, lr = 0.01
I0523 05:19:00.608399 34819 solver.cpp:239] Iteration 53940 (1.5587 iter/s, 6.41561s/10 iters), loss = 8.10228
I0523 05:19:00.608441 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10228 (* 1 = 8.10228 loss)
I0523 05:19:00.676368 34819 sgd_solver.cpp:112] Iteration 53940, lr = 0.01
I0523 05:19:05.287827 34819 solver.cpp:239] Iteration 53950 (2.13713 iter/s, 4.67918s/10 iters), loss = 8.30882
I0523 05:19:05.287868 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30882 (* 1 = 8.30882 loss)
I0523 05:19:06.114887 34819 sgd_solver.cpp:112] Iteration 53950, lr = 0.01
I0523 05:19:11.066004 34819 solver.cpp:239] Iteration 53960 (1.73074 iter/s, 5.77789s/10 iters), loss = 8.43616
I0523 05:19:11.066046 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43616 (* 1 = 8.43616 loss)
I0523 05:19:11.125777 34819 sgd_solver.cpp:112] Iteration 53960, lr = 0.01
I0523 05:19:16.592777 34819 solver.cpp:239] Iteration 53970 (1.80946 iter/s, 5.5265s/10 iters), loss = 8.00699
I0523 05:19:16.592978 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00699 (* 1 = 8.00699 loss)
I0523 05:19:17.277726 34819 sgd_solver.cpp:112] Iteration 53970, lr = 0.01
I0523 05:19:20.390674 34819 solver.cpp:239] Iteration 53980 (2.63327 iter/s, 3.79756s/10 iters), loss = 8.65293
I0523 05:19:20.390743 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65293 (* 1 = 8.65293 loss)
I0523 05:19:20.464416 34819 sgd_solver.cpp:112] Iteration 53980, lr = 0.01
I0523 05:19:23.817293 34819 solver.cpp:239] Iteration 53990 (2.91853 iter/s, 3.42639s/10 iters), loss = 8.53635
I0523 05:19:23.817354 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53635 (* 1 = 8.53635 loss)
I0523 05:19:24.603941 34819 sgd_solver.cpp:112] Iteration 53990, lr = 0.01
I0523 05:19:28.837672 34819 solver.cpp:239] Iteration 54000 (1.99199 iter/s, 5.0201s/10 iters), loss = 8.44882
I0523 05:19:28.837726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44882 (* 1 = 8.44882 loss)
I0523 05:19:28.914132 34819 sgd_solver.cpp:112] Iteration 54000, lr = 0.01
I0523 05:19:32.107007 34819 solver.cpp:239] Iteration 54010 (3.05891 iter/s, 3.26914s/10 iters), loss = 9.56585
I0523 05:19:32.107061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56585 (* 1 = 9.56585 loss)
I0523 05:19:32.176257 34819 sgd_solver.cpp:112] Iteration 54010, lr = 0.01
I0523 05:19:38.310237 34819 solver.cpp:239] Iteration 54020 (1.61214 iter/s, 6.20292s/10 iters), loss = 8.08145
I0523 05:19:38.310292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08145 (* 1 = 8.08145 loss)
I0523 05:19:38.381294 34819 sgd_solver.cpp:112] Iteration 54020, lr = 0.01
I0523 05:19:42.234869 34819 solver.cpp:239] Iteration 54030 (2.54815 iter/s, 3.92441s/10 iters), loss = 8.12044
I0523 05:19:42.234920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12044 (* 1 = 8.12044 loss)
I0523 05:19:42.307835 34819 sgd_solver.cpp:112] Iteration 54030, lr = 0.01
I0523 05:19:48.889178 34819 solver.cpp:239] Iteration 54040 (1.50286 iter/s, 6.65397s/10 iters), loss = 8.83183
I0523 05:19:48.889364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83183 (* 1 = 8.83183 loss)
I0523 05:19:48.957463 34819 sgd_solver.cpp:112] Iteration 54040, lr = 0.01
I0523 05:19:54.999238 34819 solver.cpp:239] Iteration 54050 (1.63676 iter/s, 6.10962s/10 iters), loss = 8.1559
I0523 05:19:54.999290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1559 (* 1 = 8.1559 loss)
I0523 05:19:55.068353 34819 sgd_solver.cpp:112] Iteration 54050, lr = 0.01
I0523 05:20:00.557868 34819 solver.cpp:239] Iteration 54060 (1.7991 iter/s, 5.55835s/10 iters), loss = 8.28277
I0523 05:20:00.557919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28277 (* 1 = 8.28277 loss)
I0523 05:20:00.627287 34819 sgd_solver.cpp:112] Iteration 54060, lr = 0.01
I0523 05:20:05.332568 34819 solver.cpp:239] Iteration 54070 (2.09449 iter/s, 4.77444s/10 iters), loss = 8.93948
I0523 05:20:05.332620 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93948 (* 1 = 8.93948 loss)
I0523 05:20:05.403465 34819 sgd_solver.cpp:112] Iteration 54070, lr = 0.01
I0523 05:20:09.800747 34819 solver.cpp:239] Iteration 54080 (2.23817 iter/s, 4.46794s/10 iters), loss = 8.7024
I0523 05:20:09.800796 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7024 (* 1 = 8.7024 loss)
I0523 05:20:10.516475 34819 sgd_solver.cpp:112] Iteration 54080, lr = 0.01
I0523 05:20:14.760583 34819 solver.cpp:239] Iteration 54090 (2.0163 iter/s, 4.95958s/10 iters), loss = 8.57493
I0523 05:20:14.760632 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57493 (* 1 = 8.57493 loss)
I0523 05:20:15.393651 34819 sgd_solver.cpp:112] Iteration 54090, lr = 0.01
I0523 05:20:18.308481 34819 solver.cpp:239] Iteration 54100 (2.81874 iter/s, 3.54769s/10 iters), loss = 9.10763
I0523 05:20:18.308521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10763 (* 1 = 9.10763 loss)
I0523 05:20:18.968082 34819 sgd_solver.cpp:112] Iteration 54100, lr = 0.01
I0523 05:20:23.161307 34819 solver.cpp:239] Iteration 54110 (2.06076 iter/s, 4.85258s/10 iters), loss = 9.09165
I0523 05:20:23.161350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09165 (* 1 = 9.09165 loss)
I0523 05:20:23.385432 34819 sgd_solver.cpp:112] Iteration 54110, lr = 0.01
I0523 05:20:26.090514 34819 solver.cpp:239] Iteration 54120 (3.4141 iter/s, 2.92903s/10 iters), loss = 9.09714
I0523 05:20:26.090569 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09714 (* 1 = 9.09714 loss)
I0523 05:20:26.147379 34819 sgd_solver.cpp:112] Iteration 54120, lr = 0.01
I0523 05:20:30.887969 34819 solver.cpp:239] Iteration 54130 (2.08456 iter/s, 4.79719s/10 iters), loss = 8.20833
I0523 05:20:30.888015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20833 (* 1 = 8.20833 loss)
I0523 05:20:31.686838 34819 sgd_solver.cpp:112] Iteration 54130, lr = 0.01
I0523 05:20:37.317427 34819 solver.cpp:239] Iteration 54140 (1.55542 iter/s, 6.42914s/10 iters), loss = 8.8287
I0523 05:20:37.317471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8287 (* 1 = 8.8287 loss)
I0523 05:20:37.392769 34819 sgd_solver.cpp:112] Iteration 54140, lr = 0.01
I0523 05:20:43.585664 34819 solver.cpp:239] Iteration 54150 (1.59542 iter/s, 6.26794s/10 iters), loss = 8.64615
I0523 05:20:43.585716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64615 (* 1 = 8.64615 loss)
I0523 05:20:44.236554 34819 sgd_solver.cpp:112] Iteration 54150, lr = 0.01
I0523 05:20:48.075758 34819 solver.cpp:239] Iteration 54160 (2.22724 iter/s, 4.48986s/10 iters), loss = 8.34268
I0523 05:20:48.075803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34268 (* 1 = 8.34268 loss)
I0523 05:20:48.858749 34819 sgd_solver.cpp:112] Iteration 54160, lr = 0.01
I0523 05:20:52.329401 34819 solver.cpp:239] Iteration 54170 (2.35105 iter/s, 4.25342s/10 iters), loss = 8.44879
I0523 05:20:52.329524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44879 (* 1 = 8.44879 loss)
I0523 05:20:52.404299 34819 sgd_solver.cpp:112] Iteration 54170, lr = 0.01
I0523 05:20:56.531471 34819 solver.cpp:239] Iteration 54180 (2.37995 iter/s, 4.20177s/10 iters), loss = 9.1239
I0523 05:20:56.531514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1239 (* 1 = 9.1239 loss)
I0523 05:20:56.598922 34819 sgd_solver.cpp:112] Iteration 54180, lr = 0.01
I0523 05:20:58.711657 34819 solver.cpp:239] Iteration 54190 (4.58707 iter/s, 2.18004s/10 iters), loss = 8.55847
I0523 05:20:58.711699 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55847 (* 1 = 8.55847 loss)
I0523 05:20:59.566663 34819 sgd_solver.cpp:112] Iteration 54190, lr = 0.01
I0523 05:21:03.404609 34819 solver.cpp:239] Iteration 54200 (2.13096 iter/s, 4.69272s/10 iters), loss = 9.02121
I0523 05:21:03.404651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02121 (* 1 = 9.02121 loss)
I0523 05:21:03.473512 34819 sgd_solver.cpp:112] Iteration 54200, lr = 0.01
I0523 05:21:10.265694 34819 solver.cpp:239] Iteration 54210 (1.45757 iter/s, 6.86075s/10 iters), loss = 8.9185
I0523 05:21:10.265736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9185 (* 1 = 8.9185 loss)
I0523 05:21:10.339740 34819 sgd_solver.cpp:112] Iteration 54210, lr = 0.01
I0523 05:21:14.432785 34819 solver.cpp:239] Iteration 54220 (2.39989 iter/s, 4.16685s/10 iters), loss = 8.29873
I0523 05:21:14.432837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29873 (* 1 = 8.29873 loss)
I0523 05:21:15.246448 34819 sgd_solver.cpp:112] Iteration 54220, lr = 0.01
I0523 05:21:19.668843 34819 solver.cpp:239] Iteration 54230 (1.90994 iter/s, 5.23577s/10 iters), loss = 8.7523
I0523 05:21:19.668903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7523 (* 1 = 8.7523 loss)
I0523 05:21:20.419761 34819 sgd_solver.cpp:112] Iteration 54230, lr = 0.01
I0523 05:21:23.409503 34819 solver.cpp:239] Iteration 54240 (2.67348 iter/s, 3.74045s/10 iters), loss = 9.49796
I0523 05:21:23.409721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.49796 (* 1 = 9.49796 loss)
I0523 05:21:24.213359 34819 sgd_solver.cpp:112] Iteration 54240, lr = 0.01
I0523 05:21:29.264652 34819 solver.cpp:239] Iteration 54250 (1.70803 iter/s, 5.85471s/10 iters), loss = 8.07513
I0523 05:21:29.264694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07513 (* 1 = 8.07513 loss)
I0523 05:21:30.066444 34819 sgd_solver.cpp:112] Iteration 54250, lr = 0.01
I0523 05:21:34.188263 34819 solver.cpp:239] Iteration 54260 (2.03114 iter/s, 4.92335s/10 iters), loss = 8.7955
I0523 05:21:34.188318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7955 (* 1 = 8.7955 loss)
I0523 05:21:34.261044 34819 sgd_solver.cpp:112] Iteration 54260, lr = 0.01
I0523 05:21:38.315404 34819 solver.cpp:239] Iteration 54270 (2.42312 iter/s, 4.12692s/10 iters), loss = 8.68549
I0523 05:21:38.315448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68549 (* 1 = 8.68549 loss)
I0523 05:21:38.384227 34819 sgd_solver.cpp:112] Iteration 54270, lr = 0.01
I0523 05:21:42.560400 34819 solver.cpp:239] Iteration 54280 (2.35584 iter/s, 4.24477s/10 iters), loss = 8.5984
I0523 05:21:42.560443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5984 (* 1 = 8.5984 loss)
I0523 05:21:42.633265 34819 sgd_solver.cpp:112] Iteration 54280, lr = 0.01
I0523 05:21:47.173552 34819 solver.cpp:239] Iteration 54290 (2.16783 iter/s, 4.6129s/10 iters), loss = 9.05871
I0523 05:21:47.173605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05871 (* 1 = 9.05871 loss)
I0523 05:21:47.230433 34819 sgd_solver.cpp:112] Iteration 54290, lr = 0.01
I0523 05:21:51.421049 34819 solver.cpp:239] Iteration 54300 (2.35446 iter/s, 4.24726s/10 iters), loss = 8.63817
I0523 05:21:51.421100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63817 (* 1 = 8.63817 loss)
I0523 05:21:51.489181 34819 sgd_solver.cpp:112] Iteration 54300, lr = 0.01
I0523 05:21:56.372176 34819 solver.cpp:239] Iteration 54310 (2.01985 iter/s, 4.95087s/10 iters), loss = 8.65567
I0523 05:21:56.372418 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65567 (* 1 = 8.65567 loss)
I0523 05:21:56.431576 34819 sgd_solver.cpp:112] Iteration 54310, lr = 0.01
I0523 05:22:01.158855 34819 solver.cpp:239] Iteration 54320 (2.08932 iter/s, 4.78625s/10 iters), loss = 8.98696
I0523 05:22:01.158897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98696 (* 1 = 8.98696 loss)
I0523 05:22:01.577044 34819 sgd_solver.cpp:112] Iteration 54320, lr = 0.01
I0523 05:22:06.379205 34819 solver.cpp:239] Iteration 54330 (1.91568 iter/s, 5.22009s/10 iters), loss = 9.14321
I0523 05:22:06.379247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14321 (* 1 = 9.14321 loss)
I0523 05:22:06.833369 34819 sgd_solver.cpp:112] Iteration 54330, lr = 0.01
I0523 05:22:10.036703 34819 solver.cpp:239] Iteration 54340 (2.73426 iter/s, 3.65729s/10 iters), loss = 8.76055
I0523 05:22:10.036744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76055 (* 1 = 8.76055 loss)
I0523 05:22:10.099975 34819 sgd_solver.cpp:112] Iteration 54340, lr = 0.01
I0523 05:22:14.312894 34819 solver.cpp:239] Iteration 54350 (2.33866 iter/s, 4.27596s/10 iters), loss = 8.00752
I0523 05:22:14.312937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00752 (* 1 = 8.00752 loss)
I0523 05:22:14.381867 34819 sgd_solver.cpp:112] Iteration 54350, lr = 0.01
I0523 05:22:19.111754 34819 solver.cpp:239] Iteration 54360 (2.08394 iter/s, 4.79861s/10 iters), loss = 7.86664
I0523 05:22:19.111796 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86664 (* 1 = 7.86664 loss)
I0523 05:22:19.169175 34819 sgd_solver.cpp:112] Iteration 54360, lr = 0.01
I0523 05:22:23.044631 34819 solver.cpp:239] Iteration 54370 (2.54281 iter/s, 3.93266s/10 iters), loss = 8.51874
I0523 05:22:23.044682 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51874 (* 1 = 8.51874 loss)
I0523 05:22:23.856091 34819 sgd_solver.cpp:112] Iteration 54370, lr = 0.01
I0523 05:22:27.413486 34819 solver.cpp:239] Iteration 54380 (2.28906 iter/s, 4.36861s/10 iters), loss = 8.47155
I0523 05:22:27.413633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47155 (* 1 = 8.47155 loss)
I0523 05:22:28.175086 34819 sgd_solver.cpp:112] Iteration 54380, lr = 0.01
I0523 05:22:32.071614 34819 solver.cpp:239] Iteration 54390 (2.14694 iter/s, 4.65779s/10 iters), loss = 8.40111
I0523 05:22:32.071665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40111 (* 1 = 8.40111 loss)
I0523 05:22:32.787415 34819 sgd_solver.cpp:112] Iteration 54390, lr = 0.01
I0523 05:22:36.133821 34819 solver.cpp:239] Iteration 54400 (2.46185 iter/s, 4.06198s/10 iters), loss = 8.40481
I0523 05:22:36.133875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40481 (* 1 = 8.40481 loss)
I0523 05:22:36.205945 34819 sgd_solver.cpp:112] Iteration 54400, lr = 0.01
I0523 05:22:41.766922 34819 solver.cpp:239] Iteration 54410 (1.77531 iter/s, 5.63282s/10 iters), loss = 8.98587
I0523 05:22:41.766965 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98587 (* 1 = 8.98587 loss)
I0523 05:22:41.828032 34819 sgd_solver.cpp:112] Iteration 54410, lr = 0.01
I0523 05:22:44.431812 34819 solver.cpp:239] Iteration 54420 (3.75276 iter/s, 2.66471s/10 iters), loss = 9.50833
I0523 05:22:44.431866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.50833 (* 1 = 9.50833 loss)
I0523 05:22:44.500440 34819 sgd_solver.cpp:112] Iteration 54420, lr = 0.01
I0523 05:22:49.048058 34819 solver.cpp:239] Iteration 54430 (2.16638 iter/s, 4.616s/10 iters), loss = 9.10134
I0523 05:22:49.048101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10134 (* 1 = 9.10134 loss)
I0523 05:22:49.120894 34819 sgd_solver.cpp:112] Iteration 54430, lr = 0.01
I0523 05:22:54.871549 34819 solver.cpp:239] Iteration 54440 (1.71727 iter/s, 5.82319s/10 iters), loss = 8.65771
I0523 05:22:54.871598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65771 (* 1 = 8.65771 loss)
I0523 05:22:55.719687 34819 sgd_solver.cpp:112] Iteration 54440, lr = 0.01
I0523 05:22:59.899828 34819 solver.cpp:239] Iteration 54450 (1.98886 iter/s, 5.02801s/10 iters), loss = 8.49912
I0523 05:22:59.900001 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49912 (* 1 = 8.49912 loss)
I0523 05:23:00.728498 34819 sgd_solver.cpp:112] Iteration 54450, lr = 0.01
I0523 05:23:05.433095 34819 solver.cpp:239] Iteration 54460 (1.80738 iter/s, 5.53286s/10 iters), loss = 8.71584
I0523 05:23:05.433147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71584 (* 1 = 8.71584 loss)
I0523 05:23:05.499816 34819 sgd_solver.cpp:112] Iteration 54460, lr = 0.01
I0523 05:23:09.520295 34819 solver.cpp:239] Iteration 54470 (2.4468 iter/s, 4.08696s/10 iters), loss = 9.28268
I0523 05:23:09.520350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28268 (* 1 = 9.28268 loss)
I0523 05:23:10.393095 34819 sgd_solver.cpp:112] Iteration 54470, lr = 0.01
I0523 05:23:16.071916 34819 solver.cpp:239] Iteration 54480 (1.52641 iter/s, 6.5513s/10 iters), loss = 7.69766
I0523 05:23:16.071957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69766 (* 1 = 7.69766 loss)
I0523 05:23:16.148407 34819 sgd_solver.cpp:112] Iteration 54480, lr = 0.01
I0523 05:23:20.794584 34819 solver.cpp:239] Iteration 54490 (2.11755 iter/s, 4.72243s/10 iters), loss = 8.80279
I0523 05:23:20.794625 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80279 (* 1 = 8.80279 loss)
I0523 05:23:21.639230 34819 sgd_solver.cpp:112] Iteration 54490, lr = 0.01
I0523 05:23:26.929406 34819 solver.cpp:239] Iteration 54500 (1.63012 iter/s, 6.13452s/10 iters), loss = 8.80927
I0523 05:23:26.929450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80927 (* 1 = 8.80927 loss)
I0523 05:23:26.998615 34819 sgd_solver.cpp:112] Iteration 54500, lr = 0.01
I0523 05:23:30.343588 34819 solver.cpp:239] Iteration 54510 (2.92912 iter/s, 3.41399s/10 iters), loss = 8.43854
I0523 05:23:30.343773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43854 (* 1 = 8.43854 loss)
I0523 05:23:30.413411 34819 sgd_solver.cpp:112] Iteration 54510, lr = 0.01
I0523 05:23:34.657726 34819 solver.cpp:239] Iteration 54520 (2.31815 iter/s, 4.31378s/10 iters), loss = 9.12918
I0523 05:23:34.657775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12918 (* 1 = 9.12918 loss)
I0523 05:23:34.725281 34819 sgd_solver.cpp:112] Iteration 54520, lr = 0.01
I0523 05:23:40.020376 34819 solver.cpp:239] Iteration 54530 (1.86485 iter/s, 5.36237s/10 iters), loss = 8.29457
I0523 05:23:40.020428 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29457 (* 1 = 8.29457 loss)
I0523 05:23:40.079418 34819 sgd_solver.cpp:112] Iteration 54530, lr = 0.01
I0523 05:23:45.928274 34819 solver.cpp:239] Iteration 54540 (1.69273 iter/s, 5.9076s/10 iters), loss = 8.61085
I0523 05:23:45.928323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61085 (* 1 = 8.61085 loss)
I0523 05:23:46.714947 34819 sgd_solver.cpp:112] Iteration 54540, lr = 0.01
I0523 05:23:50.782770 34819 solver.cpp:239] Iteration 54550 (2.06005 iter/s, 4.85424s/10 iters), loss = 8.22899
I0523 05:23:50.782829 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22899 (* 1 = 8.22899 loss)
I0523 05:23:51.584386 34819 sgd_solver.cpp:112] Iteration 54550, lr = 0.01
I0523 05:23:56.370661 34819 solver.cpp:239] Iteration 54560 (1.78968 iter/s, 5.5876s/10 iters), loss = 9.21711
I0523 05:23:56.370718 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21711 (* 1 = 9.21711 loss)
I0523 05:23:56.445657 34819 sgd_solver.cpp:112] Iteration 54560, lr = 0.01
I0523 05:24:00.442034 34819 solver.cpp:239] Iteration 54570 (2.45631 iter/s, 4.07115s/10 iters), loss = 8.74797
I0523 05:24:00.442302 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74797 (* 1 = 8.74797 loss)
I0523 05:24:00.500946 34819 sgd_solver.cpp:112] Iteration 54570, lr = 0.01
I0523 05:24:05.422299 34819 solver.cpp:239] Iteration 54580 (2.00811 iter/s, 4.97982s/10 iters), loss = 8.13545
I0523 05:24:05.422353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13545 (* 1 = 8.13545 loss)
I0523 05:24:05.481413 34819 sgd_solver.cpp:112] Iteration 54580, lr = 0.01
I0523 05:24:09.632133 34819 solver.cpp:239] Iteration 54590 (2.37553 iter/s, 4.20959s/10 iters), loss = 8.83535
I0523 05:24:09.632199 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83535 (* 1 = 8.83535 loss)
I0523 05:24:10.422482 34819 sgd_solver.cpp:112] Iteration 54590, lr = 0.01
I0523 05:24:15.891981 34819 solver.cpp:239] Iteration 54600 (1.59757 iter/s, 6.2595s/10 iters), loss = 8.78292
I0523 05:24:15.892035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78292 (* 1 = 8.78292 loss)
I0523 05:24:16.042927 34819 sgd_solver.cpp:112] Iteration 54600, lr = 0.01
I0523 05:24:20.128986 34819 solver.cpp:239] Iteration 54610 (2.36029 iter/s, 4.23676s/10 iters), loss = 8.80316
I0523 05:24:20.129027 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80316 (* 1 = 8.80316 loss)
I0523 05:24:20.639267 34819 sgd_solver.cpp:112] Iteration 54610, lr = 0.01
I0523 05:24:25.262998 34819 solver.cpp:239] Iteration 54620 (1.9479 iter/s, 5.13375s/10 iters), loss = 8.99197
I0523 05:24:25.263046 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99197 (* 1 = 8.99197 loss)
I0523 05:24:26.102452 34819 sgd_solver.cpp:112] Iteration 54620, lr = 0.01
I0523 05:24:33.053247 34819 solver.cpp:239] Iteration 54630 (1.28372 iter/s, 7.78988s/10 iters), loss = 9.05554
I0523 05:24:33.053380 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05554 (* 1 = 9.05554 loss)
I0523 05:24:33.124938 34819 sgd_solver.cpp:112] Iteration 54630, lr = 0.01
I0523 05:24:35.564568 34819 solver.cpp:239] Iteration 54640 (3.98236 iter/s, 2.51108s/10 iters), loss = 8.46837
I0523 05:24:35.564618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46837 (* 1 = 8.46837 loss)
I0523 05:24:35.636322 34819 sgd_solver.cpp:112] Iteration 54640, lr = 0.01
I0523 05:24:40.424628 34819 solver.cpp:239] Iteration 54650 (2.0577 iter/s, 4.8598s/10 iters), loss = 9.04344
I0523 05:24:40.424672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04344 (* 1 = 9.04344 loss)
I0523 05:24:40.496610 34819 sgd_solver.cpp:112] Iteration 54650, lr = 0.01
I0523 05:24:45.006645 34819 solver.cpp:239] Iteration 54660 (2.18256 iter/s, 4.58178s/10 iters), loss = 8.36733
I0523 05:24:45.006688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36733 (* 1 = 8.36733 loss)
I0523 05:24:45.076409 34819 sgd_solver.cpp:112] Iteration 54660, lr = 0.01
I0523 05:24:49.108822 34819 solver.cpp:239] Iteration 54670 (2.43787 iter/s, 4.10194s/10 iters), loss = 7.78049
I0523 05:24:49.108875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78049 (* 1 = 7.78049 loss)
I0523 05:24:49.992941 34819 sgd_solver.cpp:112] Iteration 54670, lr = 0.01
I0523 05:24:54.977216 34819 solver.cpp:239] Iteration 54680 (1.70414 iter/s, 5.86808s/10 iters), loss = 8.12579
I0523 05:24:54.977273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12579 (* 1 = 8.12579 loss)
I0523 05:24:55.866623 34819 sgd_solver.cpp:112] Iteration 54680, lr = 0.01
I0523 05:24:59.854084 34819 solver.cpp:239] Iteration 54690 (2.0506 iter/s, 4.87661s/10 iters), loss = 8.65126
I0523 05:24:59.854127 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65126 (* 1 = 8.65126 loss)
I0523 05:25:00.311168 34819 sgd_solver.cpp:112] Iteration 54690, lr = 0.01
I0523 05:25:04.254658 34819 solver.cpp:239] Iteration 54700 (2.27255 iter/s, 4.40035s/10 iters), loss = 9.00784
I0523 05:25:04.254817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00784 (* 1 = 9.00784 loss)
I0523 05:25:04.313885 34819 sgd_solver.cpp:112] Iteration 54700, lr = 0.01
I0523 05:25:07.691206 34819 solver.cpp:239] Iteration 54710 (2.91016 iter/s, 3.43624s/10 iters), loss = 8.39863
I0523 05:25:07.691256 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39863 (* 1 = 8.39863 loss)
I0523 05:25:08.000634 34819 sgd_solver.cpp:112] Iteration 54710, lr = 0.01
I0523 05:25:12.257607 34819 solver.cpp:239] Iteration 54720 (2.19004 iter/s, 4.56613s/10 iters), loss = 7.66925
I0523 05:25:12.257661 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66925 (* 1 = 7.66925 loss)
I0523 05:25:12.327062 34819 sgd_solver.cpp:112] Iteration 54720, lr = 0.01
I0523 05:25:19.055912 34819 solver.cpp:239] Iteration 54730 (1.47103 iter/s, 6.79798s/10 iters), loss = 8.30696
I0523 05:25:19.055954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30696 (* 1 = 8.30696 loss)
I0523 05:25:19.763346 34819 sgd_solver.cpp:112] Iteration 54730, lr = 0.01
I0523 05:25:22.462517 34819 solver.cpp:239] Iteration 54740 (2.93565 iter/s, 3.4064s/10 iters), loss = 8.3672
I0523 05:25:22.462580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3672 (* 1 = 8.3672 loss)
I0523 05:25:23.217383 34819 sgd_solver.cpp:112] Iteration 54740, lr = 0.01
I0523 05:25:28.176069 34819 solver.cpp:239] Iteration 54750 (1.75031 iter/s, 5.71326s/10 iters), loss = 9.05952
I0523 05:25:28.176120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05952 (* 1 = 9.05952 loss)
I0523 05:25:28.243458 34819 sgd_solver.cpp:112] Iteration 54750, lr = 0.01
I0523 05:25:34.015594 34819 solver.cpp:239] Iteration 54760 (1.71256 iter/s, 5.83921s/10 iters), loss = 9.27739
I0523 05:25:34.015653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27739 (* 1 = 9.27739 loss)
I0523 05:25:34.730679 34819 sgd_solver.cpp:112] Iteration 54760, lr = 0.01
I0523 05:25:39.471050 34819 solver.cpp:239] Iteration 54770 (1.83312 iter/s, 5.45517s/10 iters), loss = 9.12212
I0523 05:25:39.471091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12212 (* 1 = 9.12212 loss)
I0523 05:25:40.059626 34819 sgd_solver.cpp:112] Iteration 54770, lr = 0.01
I0523 05:25:45.379901 34819 solver.cpp:239] Iteration 54780 (1.69246 iter/s, 5.90855s/10 iters), loss = 8.11113
I0523 05:25:45.379952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11113 (* 1 = 8.11113 loss)
I0523 05:25:46.036478 34819 sgd_solver.cpp:112] Iteration 54780, lr = 0.01
I0523 05:25:52.419744 34819 solver.cpp:239] Iteration 54790 (1.42056 iter/s, 7.03949s/10 iters), loss = 8.24742
I0523 05:25:52.419795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24742 (* 1 = 8.24742 loss)
I0523 05:25:52.482097 34819 sgd_solver.cpp:112] Iteration 54790, lr = 0.01
I0523 05:25:57.062867 34819 solver.cpp:239] Iteration 54800 (2.15384 iter/s, 4.64287s/10 iters), loss = 8.36814
I0523 05:25:57.062942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36814 (* 1 = 8.36814 loss)
I0523 05:25:57.130080 34819 sgd_solver.cpp:112] Iteration 54800, lr = 0.01
I0523 05:26:02.603919 34819 solver.cpp:239] Iteration 54810 (1.80481 iter/s, 5.54074s/10 iters), loss = 8.15858
I0523 05:26:02.603958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15858 (* 1 = 8.15858 loss)
I0523 05:26:02.671325 34819 sgd_solver.cpp:112] Iteration 54810, lr = 0.01
I0523 05:26:07.691115 34819 solver.cpp:239] Iteration 54820 (1.96582 iter/s, 5.08695s/10 iters), loss = 9.29324
I0523 05:26:07.691376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29324 (* 1 = 9.29324 loss)
I0523 05:26:08.500500 34819 sgd_solver.cpp:112] Iteration 54820, lr = 0.01
I0523 05:26:12.267158 34819 solver.cpp:239] Iteration 54830 (2.1855 iter/s, 4.57561s/10 iters), loss = 6.78855
I0523 05:26:12.267206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.78855 (* 1 = 6.78855 loss)
I0523 05:26:12.340718 34819 sgd_solver.cpp:112] Iteration 54830, lr = 0.01
I0523 05:26:17.334657 34819 solver.cpp:239] Iteration 54840 (1.97346 iter/s, 5.06724s/10 iters), loss = 8.41663
I0523 05:26:17.334712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41663 (* 1 = 8.41663 loss)
I0523 05:26:17.394559 34819 sgd_solver.cpp:112] Iteration 54840, lr = 0.01
I0523 05:26:22.001652 34819 solver.cpp:239] Iteration 54850 (2.14283 iter/s, 4.66672s/10 iters), loss = 9.20151
I0523 05:26:22.001727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20151 (* 1 = 9.20151 loss)
I0523 05:26:22.149811 34819 sgd_solver.cpp:112] Iteration 54850, lr = 0.01
I0523 05:26:26.805291 34819 solver.cpp:239] Iteration 54860 (2.08188 iter/s, 4.80335s/10 iters), loss = 8.81056
I0523 05:26:26.805352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81056 (* 1 = 8.81056 loss)
I0523 05:26:26.877108 34819 sgd_solver.cpp:112] Iteration 54860, lr = 0.01
I0523 05:26:32.780268 34819 solver.cpp:239] Iteration 54870 (1.67374 iter/s, 5.97465s/10 iters), loss = 7.86765
I0523 05:26:32.780330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86765 (* 1 = 7.86765 loss)
I0523 05:26:33.406843 34819 sgd_solver.cpp:112] Iteration 54870, lr = 0.01
I0523 05:26:37.040026 34819 solver.cpp:239] Iteration 54880 (2.34768 iter/s, 4.25952s/10 iters), loss = 8.65642
I0523 05:26:37.040083 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65642 (* 1 = 8.65642 loss)
I0523 05:26:37.804051 34819 sgd_solver.cpp:112] Iteration 54880, lr = 0.01
I0523 05:26:43.569443 34819 solver.cpp:239] Iteration 54890 (1.53161 iter/s, 6.52909s/10 iters), loss = 7.54974
I0523 05:26:43.569485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54974 (* 1 = 7.54974 loss)
I0523 05:26:43.629462 34819 sgd_solver.cpp:112] Iteration 54890, lr = 0.01
I0523 05:26:48.825361 34819 solver.cpp:239] Iteration 54900 (1.90272 iter/s, 5.25564s/10 iters), loss = 9.45722
I0523 05:26:48.825412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45722 (* 1 = 9.45722 loss)
I0523 05:26:48.896862 34819 sgd_solver.cpp:112] Iteration 54900, lr = 0.01
I0523 05:26:55.098899 34819 solver.cpp:239] Iteration 54910 (1.59407 iter/s, 6.27323s/10 iters), loss = 9.63826
I0523 05:26:55.098951 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63826 (* 1 = 9.63826 loss)
I0523 05:26:55.158670 34819 sgd_solver.cpp:112] Iteration 54910, lr = 0.01
I0523 05:26:58.678961 34819 solver.cpp:239] Iteration 54920 (2.79342 iter/s, 3.57985s/10 iters), loss = 8.1272
I0523 05:26:58.679020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1272 (* 1 = 8.1272 loss)
I0523 05:26:59.308948 34819 sgd_solver.cpp:112] Iteration 54920, lr = 0.01
I0523 05:27:02.700659 34819 solver.cpp:239] Iteration 54930 (2.48666 iter/s, 4.02146s/10 iters), loss = 8.42579
I0523 05:27:02.700708 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42579 (* 1 = 8.42579 loss)
I0523 05:27:03.548298 34819 sgd_solver.cpp:112] Iteration 54930, lr = 0.01
I0523 05:27:10.465603 34819 solver.cpp:239] Iteration 54940 (1.28791 iter/s, 7.76454s/10 iters), loss = 8.41179
I0523 05:27:10.465828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41179 (* 1 = 8.41179 loss)
I0523 05:27:11.261976 34819 sgd_solver.cpp:112] Iteration 54940, lr = 0.01
I0523 05:27:18.553185 34819 solver.cpp:239] Iteration 54950 (1.23654 iter/s, 8.08706s/10 iters), loss = 7.75162
I0523 05:27:18.553226 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75162 (* 1 = 7.75162 loss)
I0523 05:27:19.197726 34819 sgd_solver.cpp:112] Iteration 54950, lr = 0.01
I0523 05:27:24.673560 34819 solver.cpp:239] Iteration 54960 (1.63397 iter/s, 6.12008s/10 iters), loss = 8.03414
I0523 05:27:24.673615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03414 (* 1 = 8.03414 loss)
I0523 05:27:24.740682 34819 sgd_solver.cpp:112] Iteration 54960, lr = 0.01
I0523 05:27:28.872537 34819 solver.cpp:239] Iteration 54970 (2.38166 iter/s, 4.19875s/10 iters), loss = 8.48848
I0523 05:27:28.872591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48848 (* 1 = 8.48848 loss)
I0523 05:27:28.949491 34819 sgd_solver.cpp:112] Iteration 54970, lr = 0.01
I0523 05:27:35.165997 34819 solver.cpp:239] Iteration 54980 (1.58903 iter/s, 6.29314s/10 iters), loss = 7.97936
I0523 05:27:35.166050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97936 (* 1 = 7.97936 loss)
I0523 05:27:35.238381 34819 sgd_solver.cpp:112] Iteration 54980, lr = 0.01
I0523 05:27:40.074920 34819 solver.cpp:239] Iteration 54990 (2.03722 iter/s, 4.90865s/10 iters), loss = 8.67138
I0523 05:27:40.074973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67138 (* 1 = 8.67138 loss)
I0523 05:27:40.132831 34819 sgd_solver.cpp:112] Iteration 54990, lr = 0.01
I0523 05:27:42.510931 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_55000.caffemodel
I0523 05:27:46.974478 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_55000.solverstate
I0523 05:27:47.215023 34819 solver.cpp:239] Iteration 55000 (1.40061 iter/s, 7.13977s/10 iters), loss = 9.51153
I0523 05:27:47.215059 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51153 (* 1 = 9.51153 loss)
I0523 05:27:47.931099 34819 sgd_solver.cpp:112] Iteration 55000, lr = 0.01
I0523 05:27:52.533978 34819 solver.cpp:239] Iteration 55010 (1.88016 iter/s, 5.3187s/10 iters), loss = 7.87802
I0523 05:27:52.534021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87802 (* 1 = 7.87802 loss)
I0523 05:27:53.368865 34819 sgd_solver.cpp:112] Iteration 55010, lr = 0.01
I0523 05:27:58.197643 34819 solver.cpp:239] Iteration 55020 (1.76573 iter/s, 5.66339s/10 iters), loss = 7.9979
I0523 05:27:58.197697 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9979 (* 1 = 7.9979 loss)
I0523 05:27:59.031702 34819 sgd_solver.cpp:112] Iteration 55020, lr = 0.01
I0523 05:28:04.449033 34819 solver.cpp:239] Iteration 55030 (1.59972 iter/s, 6.25108s/10 iters), loss = 8.61978
I0523 05:28:04.449082 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61978 (* 1 = 8.61978 loss)
I0523 05:28:05.334972 34819 sgd_solver.cpp:112] Iteration 55030, lr = 0.01
I0523 05:28:07.884603 34819 solver.cpp:239] Iteration 55040 (2.91091 iter/s, 3.43535s/10 iters), loss = 9.00209
I0523 05:28:07.884662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00209 (* 1 = 9.00209 loss)
I0523 05:28:08.739972 34819 sgd_solver.cpp:112] Iteration 55040, lr = 0.01
I0523 05:28:13.116097 34819 solver.cpp:239] Iteration 55050 (1.9116 iter/s, 5.23121s/10 iters), loss = 8.91712
I0523 05:28:13.116227 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91712 (* 1 = 8.91712 loss)
I0523 05:28:13.176707 34819 sgd_solver.cpp:112] Iteration 55050, lr = 0.01
I0523 05:28:17.668737 34819 solver.cpp:239] Iteration 55060 (2.19669 iter/s, 4.55231s/10 iters), loss = 8.39725
I0523 05:28:17.668778 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39725 (* 1 = 8.39725 loss)
I0523 05:28:18.474969 34819 sgd_solver.cpp:112] Iteration 55060, lr = 0.01
I0523 05:28:25.733620 34819 solver.cpp:239] Iteration 55070 (1.24 iter/s, 8.06451s/10 iters), loss = 8.62718
I0523 05:28:25.733660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62718 (* 1 = 8.62718 loss)
I0523 05:28:25.806515 34819 sgd_solver.cpp:112] Iteration 55070, lr = 0.01
I0523 05:28:29.825098 34819 solver.cpp:239] Iteration 55080 (2.44423 iter/s, 4.09127s/10 iters), loss = 8.92009
I0523 05:28:29.825141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92009 (* 1 = 8.92009 loss)
I0523 05:28:29.912326 34819 sgd_solver.cpp:112] Iteration 55080, lr = 0.01
I0523 05:28:33.036389 34819 solver.cpp:239] Iteration 55090 (3.1142 iter/s, 3.2111s/10 iters), loss = 8.49606
I0523 05:28:33.036433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49606 (* 1 = 8.49606 loss)
I0523 05:28:33.114115 34819 sgd_solver.cpp:112] Iteration 55090, lr = 0.01
I0523 05:28:37.846196 34819 solver.cpp:239] Iteration 55100 (2.07919 iter/s, 4.80956s/10 iters), loss = 9.25577
I0523 05:28:37.846237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25577 (* 1 = 9.25577 loss)
I0523 05:28:38.706418 34819 sgd_solver.cpp:112] Iteration 55100, lr = 0.01
I0523 05:28:43.390627 34819 solver.cpp:239] Iteration 55110 (1.8037 iter/s, 5.54415s/10 iters), loss = 9.25024
I0523 05:28:43.390797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25024 (* 1 = 9.25024 loss)
I0523 05:28:44.250486 34819 sgd_solver.cpp:112] Iteration 55110, lr = 0.01
I0523 05:28:49.156407 34819 solver.cpp:239] Iteration 55120 (1.7345 iter/s, 5.76537s/10 iters), loss = 7.48185
I0523 05:28:49.156447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.48185 (* 1 = 7.48185 loss)
I0523 05:28:49.213457 34819 sgd_solver.cpp:112] Iteration 55120, lr = 0.01
I0523 05:28:54.717932 34819 solver.cpp:239] Iteration 55130 (1.79816 iter/s, 5.56125s/10 iters), loss = 7.76949
I0523 05:28:54.717974 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76949 (* 1 = 7.76949 loss)
I0523 05:28:54.793234 34819 sgd_solver.cpp:112] Iteration 55130, lr = 0.01
I0523 05:28:59.442931 34819 solver.cpp:239] Iteration 55140 (2.11651 iter/s, 4.72476s/10 iters), loss = 8.30779
I0523 05:28:59.442991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30779 (* 1 = 8.30779 loss)
I0523 05:28:59.505017 34819 sgd_solver.cpp:112] Iteration 55140, lr = 0.01
I0523 05:29:04.239617 34819 solver.cpp:239] Iteration 55150 (2.08488 iter/s, 4.79644s/10 iters), loss = 9.01947
I0523 05:29:04.239660 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01947 (* 1 = 9.01947 loss)
I0523 05:29:04.313168 34819 sgd_solver.cpp:112] Iteration 55150, lr = 0.01
I0523 05:29:09.272626 34819 solver.cpp:239] Iteration 55160 (1.98699 iter/s, 5.03275s/10 iters), loss = 8.35203
I0523 05:29:09.272665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35203 (* 1 = 8.35203 loss)
I0523 05:29:09.329887 34819 sgd_solver.cpp:112] Iteration 55160, lr = 0.01
I0523 05:29:14.176187 34819 solver.cpp:239] Iteration 55170 (2.03944 iter/s, 4.90331s/10 iters), loss = 8.8371
I0523 05:29:14.176290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8371 (* 1 = 8.8371 loss)
I0523 05:29:14.243419 34819 sgd_solver.cpp:112] Iteration 55170, lr = 0.01
I0523 05:29:17.512392 34819 solver.cpp:239] Iteration 55180 (2.99764 iter/s, 3.33595s/10 iters), loss = 7.7213
I0523 05:29:17.512434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7213 (* 1 = 7.7213 loss)
I0523 05:29:17.570849 34819 sgd_solver.cpp:112] Iteration 55180, lr = 0.01
I0523 05:29:21.985527 34819 solver.cpp:239] Iteration 55190 (2.23568 iter/s, 4.47291s/10 iters), loss = 8.45099
I0523 05:29:21.985568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45099 (* 1 = 8.45099 loss)
I0523 05:29:22.057168 34819 sgd_solver.cpp:112] Iteration 55190, lr = 0.01
I0523 05:29:27.435279 34819 solver.cpp:239] Iteration 55200 (1.83504 iter/s, 5.44946s/10 iters), loss = 7.87268
I0523 05:29:27.435339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87268 (* 1 = 7.87268 loss)
I0523 05:29:27.832007 34819 sgd_solver.cpp:112] Iteration 55200, lr = 0.01
I0523 05:29:33.486716 34819 solver.cpp:239] Iteration 55210 (1.65259 iter/s, 6.05112s/10 iters), loss = 8.11302
I0523 05:29:33.486760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11302 (* 1 = 8.11302 loss)
I0523 05:29:34.310098 34819 sgd_solver.cpp:112] Iteration 55210, lr = 0.01
I0523 05:29:37.910377 34819 solver.cpp:239] Iteration 55220 (2.26069 iter/s, 4.42342s/10 iters), loss = 8.04254
I0523 05:29:37.910420 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04254 (* 1 = 8.04254 loss)
I0523 05:29:37.973719 34819 sgd_solver.cpp:112] Iteration 55220, lr = 0.01
I0523 05:29:43.393421 34819 solver.cpp:239] Iteration 55230 (1.8239 iter/s, 5.48276s/10 iters), loss = 8.91961
I0523 05:29:43.393467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91961 (* 1 = 8.91961 loss)
I0523 05:29:43.465291 34819 sgd_solver.cpp:112] Iteration 55230, lr = 0.01
I0523 05:29:48.324124 34819 solver.cpp:239] Iteration 55240 (2.02823 iter/s, 4.93042s/10 iters), loss = 9.04092
I0523 05:29:48.324352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04092 (* 1 = 9.04092 loss)
I0523 05:29:49.086052 34819 sgd_solver.cpp:112] Iteration 55240, lr = 0.01
I0523 05:29:54.140938 34819 solver.cpp:239] Iteration 55250 (1.71929 iter/s, 5.81637s/10 iters), loss = 8.93552
I0523 05:29:54.140992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93552 (* 1 = 8.93552 loss)
I0523 05:29:54.216042 34819 sgd_solver.cpp:112] Iteration 55250, lr = 0.01
I0523 05:29:57.423969 34819 solver.cpp:239] Iteration 55260 (3.04614 iter/s, 3.28284s/10 iters), loss = 8.88893
I0523 05:29:57.424021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88893 (* 1 = 8.88893 loss)
I0523 05:29:57.501128 34819 sgd_solver.cpp:112] Iteration 55260, lr = 0.01
I0523 05:30:00.080924 34819 solver.cpp:239] Iteration 55270 (3.76395 iter/s, 2.65678s/10 iters), loss = 8.5186
I0523 05:30:00.080976 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5186 (* 1 = 8.5186 loss)
I0523 05:30:00.802642 34819 sgd_solver.cpp:112] Iteration 55270, lr = 0.01
I0523 05:30:04.717197 34819 solver.cpp:239] Iteration 55280 (2.15702 iter/s, 4.63603s/10 iters), loss = 8.72297
I0523 05:30:04.717238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72297 (* 1 = 8.72297 loss)
I0523 05:30:05.424942 34819 sgd_solver.cpp:112] Iteration 55280, lr = 0.01
I0523 05:30:09.769779 34819 solver.cpp:239] Iteration 55290 (1.97929 iter/s, 5.05232s/10 iters), loss = 8.97798
I0523 05:30:09.769839 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97798 (* 1 = 8.97798 loss)
I0523 05:30:10.478582 34819 sgd_solver.cpp:112] Iteration 55290, lr = 0.01
I0523 05:30:15.573861 34819 solver.cpp:239] Iteration 55300 (1.72301 iter/s, 5.80378s/10 iters), loss = 7.93844
I0523 05:30:15.573904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93844 (* 1 = 7.93844 loss)
I0523 05:30:15.657044 34819 sgd_solver.cpp:112] Iteration 55300, lr = 0.01
I0523 05:30:21.200954 34819 solver.cpp:239] Iteration 55310 (1.77721 iter/s, 5.62681s/10 iters), loss = 8.18443
I0523 05:30:21.201140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18443 (* 1 = 8.18443 loss)
I0523 05:30:21.270011 34819 sgd_solver.cpp:112] Iteration 55310, lr = 0.01
I0523 05:30:24.428772 34819 solver.cpp:239] Iteration 55320 (3.09837 iter/s, 3.2275s/10 iters), loss = 9.02894
I0523 05:30:24.428825 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02894 (* 1 = 9.02894 loss)
I0523 05:30:25.276846 34819 sgd_solver.cpp:112] Iteration 55320, lr = 0.01
I0523 05:30:28.824743 34819 solver.cpp:239] Iteration 55330 (2.27493 iter/s, 4.39574s/10 iters), loss = 8.07266
I0523 05:30:28.824795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07266 (* 1 = 8.07266 loss)
I0523 05:30:28.889799 34819 sgd_solver.cpp:112] Iteration 55330, lr = 0.01
I0523 05:30:31.708415 34819 solver.cpp:239] Iteration 55340 (3.46804 iter/s, 2.88347s/10 iters), loss = 8.09135
I0523 05:30:31.708472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09135 (* 1 = 8.09135 loss)
I0523 05:30:31.766273 34819 sgd_solver.cpp:112] Iteration 55340, lr = 0.01
I0523 05:30:37.087136 34819 solver.cpp:239] Iteration 55350 (1.85927 iter/s, 5.37844s/10 iters), loss = 8.72152
I0523 05:30:37.087182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72152 (* 1 = 8.72152 loss)
I0523 05:30:37.157492 34819 sgd_solver.cpp:112] Iteration 55350, lr = 0.01
I0523 05:30:43.006481 34819 solver.cpp:239] Iteration 55360 (1.68946 iter/s, 5.91903s/10 iters), loss = 8.21593
I0523 05:30:43.006557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21593 (* 1 = 8.21593 loss)
I0523 05:30:43.548621 34819 sgd_solver.cpp:112] Iteration 55360, lr = 0.01
I0523 05:30:48.320446 34819 solver.cpp:239] Iteration 55370 (1.88194 iter/s, 5.31366s/10 iters), loss = 8.77911
I0523 05:30:48.320487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77911 (* 1 = 8.77911 loss)
I0523 05:30:49.114289 34819 sgd_solver.cpp:112] Iteration 55370, lr = 0.01
I0523 05:30:55.079823 34819 solver.cpp:239] Iteration 55380 (1.4795 iter/s, 6.75906s/10 iters), loss = 8.64172
I0523 05:30:55.079952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64172 (* 1 = 8.64172 loss)
I0523 05:30:55.153688 34819 sgd_solver.cpp:112] Iteration 55380, lr = 0.01
I0523 05:31:00.174484 34819 solver.cpp:239] Iteration 55390 (1.96297 iter/s, 5.09432s/10 iters), loss = 7.92432
I0523 05:31:00.174535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92432 (* 1 = 7.92432 loss)
I0523 05:31:00.244560 34819 sgd_solver.cpp:112] Iteration 55390, lr = 0.01
I0523 05:31:04.480796 34819 solver.cpp:239] Iteration 55400 (2.3223 iter/s, 4.30608s/10 iters), loss = 7.68377
I0523 05:31:04.480839 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68377 (* 1 = 7.68377 loss)
I0523 05:31:04.539602 34819 sgd_solver.cpp:112] Iteration 55400, lr = 0.01
I0523 05:31:09.325240 34819 solver.cpp:239] Iteration 55410 (2.06433 iter/s, 4.84419s/10 iters), loss = 8.65784
I0523 05:31:09.325294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65784 (* 1 = 8.65784 loss)
I0523 05:31:09.403414 34819 sgd_solver.cpp:112] Iteration 55410, lr = 0.01
I0523 05:31:14.258046 34819 solver.cpp:239] Iteration 55420 (2.02735 iter/s, 4.93254s/10 iters), loss = 8.5244
I0523 05:31:14.258088 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5244 (* 1 = 8.5244 loss)
I0523 05:31:14.330950 34819 sgd_solver.cpp:112] Iteration 55420, lr = 0.01
I0523 05:31:19.262272 34819 solver.cpp:239] Iteration 55430 (1.99842 iter/s, 5.00395s/10 iters), loss = 8.84088
I0523 05:31:19.262320 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84088 (* 1 = 8.84088 loss)
I0523 05:31:20.124999 34819 sgd_solver.cpp:112] Iteration 55430, lr = 0.01
I0523 05:31:23.437330 34819 solver.cpp:239] Iteration 55440 (2.39531 iter/s, 4.17482s/10 iters), loss = 8.99881
I0523 05:31:23.437384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99881 (* 1 = 8.99881 loss)
I0523 05:31:24.174528 34819 sgd_solver.cpp:112] Iteration 55440, lr = 0.01
I0523 05:31:28.517247 34819 solver.cpp:239] Iteration 55450 (1.96864 iter/s, 5.07964s/10 iters), loss = 8.39747
I0523 05:31:28.517385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39747 (* 1 = 8.39747 loss)
I0523 05:31:28.598131 34819 sgd_solver.cpp:112] Iteration 55450, lr = 0.01
I0523 05:31:33.328300 34819 solver.cpp:239] Iteration 55460 (2.0787 iter/s, 4.81071s/10 iters), loss = 8.6632
I0523 05:31:33.328348 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6632 (* 1 = 8.6632 loss)
I0523 05:31:34.185057 34819 sgd_solver.cpp:112] Iteration 55460, lr = 0.01
I0523 05:31:40.676914 34819 solver.cpp:239] Iteration 55470 (1.36087 iter/s, 7.34826s/10 iters), loss = 7.93997
I0523 05:31:40.676955 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93997 (* 1 = 7.93997 loss)
I0523 05:31:40.735081 34819 sgd_solver.cpp:112] Iteration 55470, lr = 0.01
I0523 05:31:45.494989 34819 solver.cpp:239] Iteration 55480 (2.07563 iter/s, 4.81783s/10 iters), loss = 8.05005
I0523 05:31:45.495040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05005 (* 1 = 8.05005 loss)
I0523 05:31:45.814131 34819 sgd_solver.cpp:112] Iteration 55480, lr = 0.01
I0523 05:31:48.681784 34819 solver.cpp:239] Iteration 55490 (3.13815 iter/s, 3.18659s/10 iters), loss = 8.72434
I0523 05:31:48.681835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72434 (* 1 = 8.72434 loss)
I0523 05:31:48.750442 34819 sgd_solver.cpp:112] Iteration 55490, lr = 0.01
I0523 05:31:53.804476 34819 solver.cpp:239] Iteration 55500 (1.9522 iter/s, 5.12241s/10 iters), loss = 9.43261
I0523 05:31:53.804524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.43261 (* 1 = 9.43261 loss)
I0523 05:31:54.404933 34819 sgd_solver.cpp:112] Iteration 55500, lr = 0.01
I0523 05:32:00.050720 34819 solver.cpp:239] Iteration 55510 (1.60104 iter/s, 6.24593s/10 iters), loss = 8.39238
I0523 05:32:00.050881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39238 (* 1 = 8.39238 loss)
I0523 05:32:00.118829 34819 sgd_solver.cpp:112] Iteration 55510, lr = 0.01
I0523 05:32:03.445960 34819 solver.cpp:239] Iteration 55520 (2.94557 iter/s, 3.39493s/10 iters), loss = 7.89115
I0523 05:32:03.445999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89115 (* 1 = 7.89115 loss)
I0523 05:32:03.508808 34819 sgd_solver.cpp:112] Iteration 55520, lr = 0.01
I0523 05:32:08.280715 34819 solver.cpp:239] Iteration 55530 (2.06846 iter/s, 4.83451s/10 iters), loss = 8.10367
I0523 05:32:08.280771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10367 (* 1 = 8.10367 loss)
I0523 05:32:08.350067 34819 sgd_solver.cpp:112] Iteration 55530, lr = 0.01
I0523 05:32:13.989786 34819 solver.cpp:239] Iteration 55540 (1.75169 iter/s, 5.70877s/10 iters), loss = 8.14738
I0523 05:32:13.989835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14738 (* 1 = 8.14738 loss)
I0523 05:32:14.852854 34819 sgd_solver.cpp:112] Iteration 55540, lr = 0.01
I0523 05:32:20.892567 34819 solver.cpp:239] Iteration 55550 (1.44876 iter/s, 6.90245s/10 iters), loss = 8.18891
I0523 05:32:20.892608 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18891 (* 1 = 8.18891 loss)
I0523 05:32:20.958340 34819 sgd_solver.cpp:112] Iteration 55550, lr = 0.01
I0523 05:32:25.527323 34819 solver.cpp:239] Iteration 55560 (2.15773 iter/s, 4.6345s/10 iters), loss = 8.41441
I0523 05:32:25.527371 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41441 (* 1 = 8.41441 loss)
I0523 05:32:25.586274 34819 sgd_solver.cpp:112] Iteration 55560, lr = 0.01
I0523 05:32:29.948498 34819 solver.cpp:239] Iteration 55570 (2.26196 iter/s, 4.42094s/10 iters), loss = 9.17335
I0523 05:32:29.948545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17335 (* 1 = 9.17335 loss)
I0523 05:32:30.793301 34819 sgd_solver.cpp:112] Iteration 55570, lr = 0.01
I0523 05:32:34.405699 34819 solver.cpp:239] Iteration 55580 (2.24368 iter/s, 4.45696s/10 iters), loss = 7.70542
I0523 05:32:34.405740 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70542 (* 1 = 7.70542 loss)
I0523 05:32:35.248028 34819 sgd_solver.cpp:112] Iteration 55580, lr = 0.01
I0523 05:32:40.139852 34819 solver.cpp:239] Iteration 55590 (1.74403 iter/s, 5.73384s/10 iters), loss = 7.85342
I0523 05:32:40.139919 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85342 (* 1 = 7.85342 loss)
I0523 05:32:40.865654 34819 sgd_solver.cpp:112] Iteration 55590, lr = 0.01
I0523 05:32:46.668118 34819 solver.cpp:239] Iteration 55600 (1.53188 iter/s, 6.52793s/10 iters), loss = 8.8316
I0523 05:32:46.668170 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8316 (* 1 = 8.8316 loss)
I0523 05:32:46.735675 34819 sgd_solver.cpp:112] Iteration 55600, lr = 0.01
I0523 05:32:50.477479 34819 solver.cpp:239] Iteration 55610 (2.62527 iter/s, 3.80913s/10 iters), loss = 8.80687
I0523 05:32:50.477550 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80687 (* 1 = 8.80687 loss)
I0523 05:32:50.536885 34819 sgd_solver.cpp:112] Iteration 55610, lr = 0.01
I0523 05:32:57.062685 34819 solver.cpp:239] Iteration 55620 (1.51863 iter/s, 6.58487s/10 iters), loss = 7.86036
I0523 05:32:57.062752 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86036 (* 1 = 7.86036 loss)
I0523 05:32:57.773581 34819 sgd_solver.cpp:112] Iteration 55620, lr = 0.01
I0523 05:33:02.320628 34819 solver.cpp:239] Iteration 55630 (1.90199 iter/s, 5.25765s/10 iters), loss = 8.01212
I0523 05:33:02.320863 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01212 (* 1 = 8.01212 loss)
I0523 05:33:02.386379 34819 sgd_solver.cpp:112] Iteration 55630, lr = 0.01
I0523 05:33:08.260046 34819 solver.cpp:239] Iteration 55640 (1.6838 iter/s, 5.93896s/10 iters), loss = 8.43325
I0523 05:33:08.260094 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43325 (* 1 = 8.43325 loss)
I0523 05:33:08.326831 34819 sgd_solver.cpp:112] Iteration 55640, lr = 0.01
I0523 05:33:12.756711 34819 solver.cpp:239] Iteration 55650 (2.22399 iter/s, 4.49643s/10 iters), loss = 8.48051
I0523 05:33:12.756763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48051 (* 1 = 8.48051 loss)
I0523 05:33:13.582430 34819 sgd_solver.cpp:112] Iteration 55650, lr = 0.01
I0523 05:33:16.209477 34819 solver.cpp:239] Iteration 55660 (2.89641 iter/s, 3.45256s/10 iters), loss = 8.50733
I0523 05:33:16.209527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50733 (* 1 = 8.50733 loss)
I0523 05:33:16.447001 34819 sgd_solver.cpp:112] Iteration 55660, lr = 0.01
I0523 05:33:19.718924 34819 solver.cpp:239] Iteration 55670 (2.84963 iter/s, 3.50923s/10 iters), loss = 9.07726
I0523 05:33:19.718976 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07726 (* 1 = 9.07726 loss)
I0523 05:33:19.792903 34819 sgd_solver.cpp:112] Iteration 55670, lr = 0.01
I0523 05:33:23.227519 34819 solver.cpp:239] Iteration 55680 (2.85031 iter/s, 3.50839s/10 iters), loss = 8.55028
I0523 05:33:23.227563 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55028 (* 1 = 8.55028 loss)
I0523 05:33:24.035675 34819 sgd_solver.cpp:112] Iteration 55680, lr = 0.01
I0523 05:33:27.623334 34819 solver.cpp:239] Iteration 55690 (2.27501 iter/s, 4.39558s/10 iters), loss = 9.12763
I0523 05:33:27.623386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12763 (* 1 = 9.12763 loss)
I0523 05:33:28.322650 34819 sgd_solver.cpp:112] Iteration 55690, lr = 0.01
I0523 05:33:34.286020 34819 solver.cpp:239] Iteration 55700 (1.50097 iter/s, 6.66236s/10 iters), loss = 8.27276
I0523 05:33:34.286120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27276 (* 1 = 8.27276 loss)
I0523 05:33:34.353114 34819 sgd_solver.cpp:112] Iteration 55700, lr = 0.01
I0523 05:33:38.243775 34819 solver.cpp:239] Iteration 55710 (2.52686 iter/s, 3.95748s/10 iters), loss = 8.59978
I0523 05:33:38.243830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59978 (* 1 = 8.59978 loss)
I0523 05:33:38.313125 34819 sgd_solver.cpp:112] Iteration 55710, lr = 0.01
I0523 05:33:43.179479 34819 solver.cpp:239] Iteration 55720 (2.02617 iter/s, 4.93542s/10 iters), loss = 8.42829
I0523 05:33:43.179535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42829 (* 1 = 8.42829 loss)
I0523 05:33:43.250778 34819 sgd_solver.cpp:112] Iteration 55720, lr = 0.01
I0523 05:33:47.765595 34819 solver.cpp:239] Iteration 55730 (2.18061 iter/s, 4.58587s/10 iters), loss = 8.26365
I0523 05:33:47.765648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26365 (* 1 = 8.26365 loss)
I0523 05:33:47.858147 34819 sgd_solver.cpp:112] Iteration 55730, lr = 0.01
I0523 05:33:53.013870 34819 solver.cpp:239] Iteration 55740 (1.90549 iter/s, 5.248s/10 iters), loss = 8.38408
I0523 05:33:53.013918 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38408 (* 1 = 8.38408 loss)
I0523 05:33:53.643018 34819 sgd_solver.cpp:112] Iteration 55740, lr = 0.01
I0523 05:33:58.467345 34819 solver.cpp:239] Iteration 55750 (1.83378 iter/s, 5.4532s/10 iters), loss = 8.37366
I0523 05:33:58.467389 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37366 (* 1 = 8.37366 loss)
I0523 05:33:59.270272 34819 sgd_solver.cpp:112] Iteration 55750, lr = 0.01
I0523 05:34:02.713732 34819 solver.cpp:239] Iteration 55760 (2.35507 iter/s, 4.24616s/10 iters), loss = 8.10916
I0523 05:34:02.713786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10916 (* 1 = 8.10916 loss)
I0523 05:34:03.514859 34819 sgd_solver.cpp:112] Iteration 55760, lr = 0.01
I0523 05:34:10.003114 34819 solver.cpp:239] Iteration 55770 (1.37192 iter/s, 7.28904s/10 iters), loss = 8.15774
I0523 05:34:10.003286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15774 (* 1 = 8.15774 loss)
I0523 05:34:10.072909 34819 sgd_solver.cpp:112] Iteration 55770, lr = 0.01
I0523 05:34:12.773221 34819 solver.cpp:239] Iteration 55780 (3.61036 iter/s, 2.7698s/10 iters), loss = 7.44712
I0523 05:34:12.773277 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44712 (* 1 = 7.44712 loss)
I0523 05:34:12.829210 34819 sgd_solver.cpp:112] Iteration 55780, lr = 0.01
I0523 05:34:19.701643 34819 solver.cpp:239] Iteration 55790 (1.4434 iter/s, 6.92809s/10 iters), loss = 9.15984
I0523 05:34:19.701689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15984 (* 1 = 9.15984 loss)
I0523 05:34:20.446099 34819 sgd_solver.cpp:112] Iteration 55790, lr = 0.01
I0523 05:34:24.743983 34819 solver.cpp:239] Iteration 55800 (1.98331 iter/s, 5.04208s/10 iters), loss = 8.461
I0523 05:34:24.744040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.461 (* 1 = 8.461 loss)
I0523 05:34:24.814756 34819 sgd_solver.cpp:112] Iteration 55800, lr = 0.01
I0523 05:34:27.797250 34819 solver.cpp:239] Iteration 55810 (3.27538 iter/s, 3.05308s/10 iters), loss = 8.22218
I0523 05:34:27.797294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22218 (* 1 = 8.22218 loss)
I0523 05:34:27.871615 34819 sgd_solver.cpp:112] Iteration 55810, lr = 0.01
I0523 05:34:32.808555 34819 solver.cpp:239] Iteration 55820 (1.99559 iter/s, 5.01104s/10 iters), loss = 8.10331
I0523 05:34:32.808601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10331 (* 1 = 8.10331 loss)
I0523 05:34:32.881105 34819 sgd_solver.cpp:112] Iteration 55820, lr = 0.01
I0523 05:34:36.933594 34819 solver.cpp:239] Iteration 55830 (2.42435 iter/s, 4.12481s/10 iters), loss = 7.88421
I0523 05:34:36.933655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88421 (* 1 = 7.88421 loss)
I0523 05:34:36.997987 34819 sgd_solver.cpp:112] Iteration 55830, lr = 0.01
I0523 05:34:42.784030 34819 solver.cpp:239] Iteration 55840 (1.70936 iter/s, 5.85013s/10 iters), loss = 8.45455
I0523 05:34:42.784253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45455 (* 1 = 8.45455 loss)
I0523 05:34:42.868414 34819 sgd_solver.cpp:112] Iteration 55840, lr = 0.01
I0523 05:34:46.787467 34819 solver.cpp:239] Iteration 55850 (2.49809 iter/s, 4.00305s/10 iters), loss = 8.4757
I0523 05:34:46.787528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4757 (* 1 = 8.4757 loss)
I0523 05:34:47.560344 34819 sgd_solver.cpp:112] Iteration 55850, lr = 0.01
I0523 05:34:51.537032 34819 solver.cpp:239] Iteration 55860 (2.10557 iter/s, 4.7493s/10 iters), loss = 8.48137
I0523 05:34:51.537076 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48137 (* 1 = 8.48137 loss)
I0523 05:34:51.614861 34819 sgd_solver.cpp:112] Iteration 55860, lr = 0.01
I0523 05:34:55.156451 34819 solver.cpp:239] Iteration 55870 (2.76303 iter/s, 3.61921s/10 iters), loss = 7.62291
I0523 05:34:55.156500 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62291 (* 1 = 7.62291 loss)
I0523 05:34:55.977305 34819 sgd_solver.cpp:112] Iteration 55870, lr = 0.01
I0523 05:35:00.185600 34819 solver.cpp:239] Iteration 55880 (1.98852 iter/s, 5.02887s/10 iters), loss = 8.63431
I0523 05:35:00.185647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63431 (* 1 = 8.63431 loss)
I0523 05:35:00.252915 34819 sgd_solver.cpp:112] Iteration 55880, lr = 0.01
I0523 05:35:03.662628 34819 solver.cpp:239] Iteration 55890 (2.87618 iter/s, 3.47683s/10 iters), loss = 8.47206
I0523 05:35:03.662686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47206 (* 1 = 8.47206 loss)
I0523 05:35:03.736908 34819 sgd_solver.cpp:112] Iteration 55890, lr = 0.01
I0523 05:35:10.302824 34819 solver.cpp:239] Iteration 55900 (1.50606 iter/s, 6.63986s/10 iters), loss = 8.45911
I0523 05:35:10.302878 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45911 (* 1 = 8.45911 loss)
I0523 05:35:10.372323 34819 sgd_solver.cpp:112] Iteration 55900, lr = 0.01
I0523 05:35:15.090509 34819 solver.cpp:239] Iteration 55910 (2.08881 iter/s, 4.78742s/10 iters), loss = 9.0048
I0523 05:35:15.090689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0048 (* 1 = 9.0048 loss)
I0523 05:35:15.151659 34819 sgd_solver.cpp:112] Iteration 55910, lr = 0.01
I0523 05:35:19.083477 34819 solver.cpp:239] Iteration 55920 (2.50463 iter/s, 3.99261s/10 iters), loss = 8.50466
I0523 05:35:19.083521 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50466 (* 1 = 8.50466 loss)
I0523 05:35:19.143275 34819 sgd_solver.cpp:112] Iteration 55920, lr = 0.01
I0523 05:35:26.169550 34819 solver.cpp:239] Iteration 55930 (1.41128 iter/s, 7.08575s/10 iters), loss = 8.37547
I0523 05:35:26.169592 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37547 (* 1 = 8.37547 loss)
I0523 05:35:26.242596 34819 sgd_solver.cpp:112] Iteration 55930, lr = 0.01
I0523 05:35:32.390291 34819 solver.cpp:239] Iteration 55940 (1.6076 iter/s, 6.22045s/10 iters), loss = 8.50287
I0523 05:35:32.390332 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50287 (* 1 = 8.50287 loss)
I0523 05:35:32.453200 34819 sgd_solver.cpp:112] Iteration 55940, lr = 0.01
I0523 05:35:38.116014 34819 solver.cpp:239] Iteration 55950 (1.74659 iter/s, 5.72544s/10 iters), loss = 8.64257
I0523 05:35:38.116050 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64257 (* 1 = 8.64257 loss)
I0523 05:35:38.730612 34819 sgd_solver.cpp:112] Iteration 55950, lr = 0.01
I0523 05:35:43.601382 34819 solver.cpp:239] Iteration 55960 (1.82312 iter/s, 5.48511s/10 iters), loss = 8.38947
I0523 05:35:43.601423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38947 (* 1 = 8.38947 loss)
I0523 05:35:43.676194 34819 sgd_solver.cpp:112] Iteration 55960, lr = 0.01
I0523 05:35:47.191246 34819 solver.cpp:239] Iteration 55970 (2.78578 iter/s, 3.58966s/10 iters), loss = 8.87436
I0523 05:35:47.191359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87436 (* 1 = 8.87436 loss)
I0523 05:35:47.935933 34819 sgd_solver.cpp:112] Iteration 55970, lr = 0.01
I0523 05:35:53.480911 34819 solver.cpp:239] Iteration 55980 (1.59 iter/s, 6.28929s/10 iters), loss = 8.12494
I0523 05:35:53.480962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12494 (* 1 = 8.12494 loss)
I0523 05:35:54.171655 34819 sgd_solver.cpp:112] Iteration 55980, lr = 0.01
I0523 05:35:59.168180 34819 solver.cpp:239] Iteration 55990 (1.7584 iter/s, 5.68697s/10 iters), loss = 8.37662
I0523 05:35:59.168220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37662 (* 1 = 8.37662 loss)
I0523 05:35:59.232887 34819 sgd_solver.cpp:112] Iteration 55990, lr = 0.01
I0523 05:36:03.467011 34819 solver.cpp:239] Iteration 56000 (2.32634 iter/s, 4.2986s/10 iters), loss = 8.77107
I0523 05:36:03.467056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77107 (* 1 = 8.77107 loss)
I0523 05:36:04.289640 34819 sgd_solver.cpp:112] Iteration 56000, lr = 0.01
I0523 05:36:09.853415 34819 solver.cpp:239] Iteration 56010 (1.56591 iter/s, 6.38608s/10 iters), loss = 9.01923
I0523 05:36:09.853458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01923 (* 1 = 9.01923 loss)
I0523 05:36:09.926880 34819 sgd_solver.cpp:112] Iteration 56010, lr = 0.01
I0523 05:36:14.906808 34819 solver.cpp:239] Iteration 56020 (1.97897 iter/s, 5.05313s/10 iters), loss = 8.72429
I0523 05:36:14.906849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72429 (* 1 = 8.72429 loss)
I0523 05:36:14.973649 34819 sgd_solver.cpp:112] Iteration 56020, lr = 0.01
I0523 05:36:18.856024 34819 solver.cpp:239] Iteration 56030 (2.53229 iter/s, 3.949s/10 iters), loss = 8.41721
I0523 05:36:18.856153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41721 (* 1 = 8.41721 loss)
I0523 05:36:19.531136 34819 sgd_solver.cpp:112] Iteration 56030, lr = 0.01
I0523 05:36:23.309800 34819 solver.cpp:239] Iteration 56040 (2.24546 iter/s, 4.45343s/10 iters), loss = 7.46859
I0523 05:36:23.309845 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46859 (* 1 = 7.46859 loss)
I0523 05:36:24.147855 34819 sgd_solver.cpp:112] Iteration 56040, lr = 0.01
I0523 05:36:28.314393 34819 solver.cpp:239] Iteration 56050 (1.99828 iter/s, 5.00431s/10 iters), loss = 7.88668
I0523 05:36:28.314433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88668 (* 1 = 7.88668 loss)
I0523 05:36:28.997423 34819 sgd_solver.cpp:112] Iteration 56050, lr = 0.01
I0523 05:36:32.871299 34819 solver.cpp:239] Iteration 56060 (2.19458 iter/s, 4.55668s/10 iters), loss = 8.41815
I0523 05:36:32.871340 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41815 (* 1 = 8.41815 loss)
I0523 05:36:32.937983 34819 sgd_solver.cpp:112] Iteration 56060, lr = 0.01
I0523 05:36:38.791328 34819 solver.cpp:239] Iteration 56070 (1.68926 iter/s, 5.91974s/10 iters), loss = 8.9502
I0523 05:36:38.791369 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9502 (* 1 = 8.9502 loss)
I0523 05:36:38.855358 34819 sgd_solver.cpp:112] Iteration 56070, lr = 0.01
I0523 05:36:42.193933 34819 solver.cpp:239] Iteration 56080 (2.9391 iter/s, 3.40241s/10 iters), loss = 8.66092
I0523 05:36:42.193975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66092 (* 1 = 8.66092 loss)
I0523 05:36:42.974989 34819 sgd_solver.cpp:112] Iteration 56080, lr = 0.01
I0523 05:36:45.669523 34819 solver.cpp:239] Iteration 56090 (2.87738 iter/s, 3.47539s/10 iters), loss = 9.27905
I0523 05:36:45.669589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27905 (* 1 = 9.27905 loss)
I0523 05:36:45.733443 34819 sgd_solver.cpp:112] Iteration 56090, lr = 0.01
I0523 05:36:50.364943 34819 solver.cpp:239] Iteration 56100 (2.12986 iter/s, 4.69514s/10 iters), loss = 8.055
I0523 05:36:50.365085 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.055 (* 1 = 8.055 loss)
I0523 05:36:51.224594 34819 sgd_solver.cpp:112] Iteration 56100, lr = 0.01
I0523 05:36:56.754375 34819 solver.cpp:239] Iteration 56110 (1.56519 iter/s, 6.38902s/10 iters), loss = 8.36112
I0523 05:36:56.754426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36112 (* 1 = 8.36112 loss)
I0523 05:36:56.830348 34819 sgd_solver.cpp:112] Iteration 56110, lr = 0.01
I0523 05:37:01.162757 34819 solver.cpp:239] Iteration 56120 (2.26853 iter/s, 4.40814s/10 iters), loss = 7.99134
I0523 05:37:01.162809 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99134 (* 1 = 7.99134 loss)
I0523 05:37:01.961818 34819 sgd_solver.cpp:112] Iteration 56120, lr = 0.01
I0523 05:37:05.367718 34819 solver.cpp:239] Iteration 56130 (2.37828 iter/s, 4.20472s/10 iters), loss = 9.1029
I0523 05:37:05.367775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1029 (* 1 = 9.1029 loss)
I0523 05:37:05.425782 34819 sgd_solver.cpp:112] Iteration 56130, lr = 0.01
I0523 05:37:08.684907 34819 solver.cpp:239] Iteration 56140 (3.01479 iter/s, 3.31698s/10 iters), loss = 8.64221
I0523 05:37:08.684973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64221 (* 1 = 8.64221 loss)
I0523 05:37:08.744987 34819 sgd_solver.cpp:112] Iteration 56140, lr = 0.01
I0523 05:37:13.077877 34819 solver.cpp:239] Iteration 56150 (2.27649 iter/s, 4.39272s/10 iters), loss = 8.54952
I0523 05:37:13.077922 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54952 (* 1 = 8.54952 loss)
I0523 05:37:13.150594 34819 sgd_solver.cpp:112] Iteration 56150, lr = 0.01
I0523 05:37:19.666100 34819 solver.cpp:239] Iteration 56160 (1.51793 iter/s, 6.58791s/10 iters), loss = 8.0885
I0523 05:37:19.666152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0885 (* 1 = 8.0885 loss)
I0523 05:37:20.351868 34819 sgd_solver.cpp:112] Iteration 56160, lr = 0.01
I0523 05:37:23.645568 34819 solver.cpp:239] Iteration 56170 (2.51305 iter/s, 3.97923s/10 iters), loss = 8.35947
I0523 05:37:23.645771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35947 (* 1 = 8.35947 loss)
I0523 05:37:23.707222 34819 sgd_solver.cpp:112] Iteration 56170, lr = 0.01
I0523 05:37:26.795500 34819 solver.cpp:239] Iteration 56180 (3.17501 iter/s, 3.1496s/10 iters), loss = 9.35799
I0523 05:37:26.795549 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.35799 (* 1 = 9.35799 loss)
I0523 05:37:26.853307 34819 sgd_solver.cpp:112] Iteration 56180, lr = 0.01
I0523 05:37:31.889822 34819 solver.cpp:239] Iteration 56190 (1.96307 iter/s, 5.09405s/10 iters), loss = 8.59151
I0523 05:37:31.889875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59151 (* 1 = 8.59151 loss)
I0523 05:37:31.946247 34819 sgd_solver.cpp:112] Iteration 56190, lr = 0.01
I0523 05:37:35.220144 34819 solver.cpp:239] Iteration 56200 (3.00291 iter/s, 3.33011s/10 iters), loss = 8.37223
I0523 05:37:35.220196 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37223 (* 1 = 8.37223 loss)
I0523 05:37:35.302913 34819 sgd_solver.cpp:112] Iteration 56200, lr = 0.01
I0523 05:37:38.765811 34819 solver.cpp:239] Iteration 56210 (2.8205 iter/s, 3.54546s/10 iters), loss = 8.64648
I0523 05:37:38.765867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64648 (* 1 = 8.64648 loss)
I0523 05:37:38.830387 34819 sgd_solver.cpp:112] Iteration 56210, lr = 0.01
I0523 05:37:44.457495 34819 solver.cpp:239] Iteration 56220 (1.75704 iter/s, 5.6914s/10 iters), loss = 8.10411
I0523 05:37:44.457542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10411 (* 1 = 8.10411 loss)
I0523 05:37:44.519367 34819 sgd_solver.cpp:112] Iteration 56220, lr = 0.01
I0523 05:37:49.494740 34819 solver.cpp:239] Iteration 56230 (1.98532 iter/s, 5.03698s/10 iters), loss = 8.3217
I0523 05:37:49.494791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3217 (* 1 = 8.3217 loss)
I0523 05:37:50.206734 34819 sgd_solver.cpp:112] Iteration 56230, lr = 0.01
I0523 05:37:53.577222 34819 solver.cpp:239] Iteration 56240 (2.44962 iter/s, 4.08226s/10 iters), loss = 8.45333
I0523 05:37:53.577265 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45333 (* 1 = 8.45333 loss)
I0523 05:37:54.417115 34819 sgd_solver.cpp:112] Iteration 56240, lr = 0.01
I0523 05:37:59.309109 34819 solver.cpp:239] Iteration 56250 (1.74471 iter/s, 5.73161s/10 iters), loss = 8.89291
I0523 05:37:59.309154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89291 (* 1 = 8.89291 loss)
I0523 05:37:59.372464 34819 sgd_solver.cpp:112] Iteration 56250, lr = 0.01
I0523 05:38:02.349330 34819 solver.cpp:239] Iteration 56260 (3.28942 iter/s, 3.04005s/10 iters), loss = 8.72177
I0523 05:38:02.349373 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72177 (* 1 = 8.72177 loss)
I0523 05:38:03.058562 34819 sgd_solver.cpp:112] Iteration 56260, lr = 0.01
I0523 05:38:07.020040 34819 solver.cpp:239] Iteration 56270 (2.14111 iter/s, 4.67047s/10 iters), loss = 7.59083
I0523 05:38:07.020092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59083 (* 1 = 7.59083 loss)
I0523 05:38:07.105044 34819 sgd_solver.cpp:112] Iteration 56270, lr = 0.01
I0523 05:38:12.889748 34819 solver.cpp:239] Iteration 56280 (1.70375 iter/s, 5.8694s/10 iters), loss = 8.57455
I0523 05:38:12.889793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57455 (* 1 = 8.57455 loss)
I0523 05:38:12.959975 34819 sgd_solver.cpp:112] Iteration 56280, lr = 0.01
I0523 05:38:16.152916 34819 solver.cpp:239] Iteration 56290 (3.06469 iter/s, 3.26297s/10 iters), loss = 8.96774
I0523 05:38:16.152962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96774 (* 1 = 8.96774 loss)
I0523 05:38:16.993459 34819 sgd_solver.cpp:112] Iteration 56290, lr = 0.01
I0523 05:38:21.159781 34819 solver.cpp:239] Iteration 56300 (1.99737 iter/s, 5.00658s/10 iters), loss = 8.15482
I0523 05:38:21.159843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15482 (* 1 = 8.15482 loss)
I0523 05:38:21.915444 34819 sgd_solver.cpp:112] Iteration 56300, lr = 0.01
I0523 05:38:28.377763 34819 solver.cpp:239] Iteration 56310 (1.3855 iter/s, 7.21761s/10 iters), loss = 7.76078
I0523 05:38:28.377920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76078 (* 1 = 7.76078 loss)
I0523 05:38:28.437919 34819 sgd_solver.cpp:112] Iteration 56310, lr = 0.01
I0523 05:38:34.508930 34819 solver.cpp:239] Iteration 56320 (1.63112 iter/s, 6.13076s/10 iters), loss = 8.80815
I0523 05:38:34.508982 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80815 (* 1 = 8.80815 loss)
I0523 05:38:34.589530 34819 sgd_solver.cpp:112] Iteration 56320, lr = 0.01
I0523 05:38:40.350910 34819 solver.cpp:239] Iteration 56330 (1.71184 iter/s, 5.84168s/10 iters), loss = 8.89698
I0523 05:38:40.350966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89698 (* 1 = 8.89698 loss)
I0523 05:38:41.061919 34819 sgd_solver.cpp:112] Iteration 56330, lr = 0.01
I0523 05:38:44.374225 34819 solver.cpp:239] Iteration 56340 (2.48565 iter/s, 4.0231s/10 iters), loss = 8.54909
I0523 05:38:44.374266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54909 (* 1 = 8.54909 loss)
I0523 05:38:44.449510 34819 sgd_solver.cpp:112] Iteration 56340, lr = 0.01
I0523 05:38:47.789865 34819 solver.cpp:239] Iteration 56350 (2.92787 iter/s, 3.41545s/10 iters), loss = 7.83126
I0523 05:38:47.789907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83126 (* 1 = 7.83126 loss)
I0523 05:38:47.852567 34819 sgd_solver.cpp:112] Iteration 56350, lr = 0.01
I0523 05:38:51.086573 34819 solver.cpp:239] Iteration 56360 (3.03645 iter/s, 3.29332s/10 iters), loss = 7.83684
I0523 05:38:51.086618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83684 (* 1 = 7.83684 loss)
I0523 05:38:51.151494 34819 sgd_solver.cpp:112] Iteration 56360, lr = 0.01
I0523 05:38:55.678258 34819 solver.cpp:239] Iteration 56370 (2.17796 iter/s, 4.59144s/10 iters), loss = 8.43992
I0523 05:38:55.678309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43992 (* 1 = 8.43992 loss)
I0523 05:38:56.286124 34819 sgd_solver.cpp:112] Iteration 56370, lr = 0.01
I0523 05:39:03.234562 34819 solver.cpp:239] Iteration 56380 (1.32346 iter/s, 7.55593s/10 iters), loss = 8.88561
I0523 05:39:03.234670 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88561 (* 1 = 8.88561 loss)
I0523 05:39:03.305013 34819 sgd_solver.cpp:112] Iteration 56380, lr = 0.01
I0523 05:39:07.885308 34819 solver.cpp:239] Iteration 56390 (2.15035 iter/s, 4.65041s/10 iters), loss = 8.18144
I0523 05:39:07.885395 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18144 (* 1 = 8.18144 loss)
I0523 05:39:07.948182 34819 sgd_solver.cpp:112] Iteration 56390, lr = 0.01
I0523 05:39:13.243130 34819 solver.cpp:239] Iteration 56400 (1.86654 iter/s, 5.35751s/10 iters), loss = 7.54264
I0523 05:39:13.243186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54264 (* 1 = 7.54264 loss)
I0523 05:39:13.386106 34819 sgd_solver.cpp:112] Iteration 56400, lr = 0.01
I0523 05:39:17.634918 34819 solver.cpp:239] Iteration 56410 (2.2771 iter/s, 4.39154s/10 iters), loss = 7.62801
I0523 05:39:17.634968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62801 (* 1 = 7.62801 loss)
I0523 05:39:18.362856 34819 sgd_solver.cpp:112] Iteration 56410, lr = 0.01
I0523 05:39:23.225796 34819 solver.cpp:239] Iteration 56420 (1.78872 iter/s, 5.59058s/10 iters), loss = 7.34347
I0523 05:39:23.225849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.34347 (* 1 = 7.34347 loss)
I0523 05:39:23.284270 34819 sgd_solver.cpp:112] Iteration 56420, lr = 0.01
I0523 05:39:28.610635 34819 solver.cpp:239] Iteration 56430 (1.85717 iter/s, 5.38455s/10 iters), loss = 8.58404
I0523 05:39:28.610734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58404 (* 1 = 8.58404 loss)
I0523 05:39:29.462209 34819 sgd_solver.cpp:112] Iteration 56430, lr = 0.01
I0523 05:39:32.163638 34819 solver.cpp:239] Iteration 56440 (2.8147 iter/s, 3.55278s/10 iters), loss = 8.17946
I0523 05:39:32.163686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17946 (* 1 = 8.17946 loss)
I0523 05:39:32.227532 34819 sgd_solver.cpp:112] Iteration 56440, lr = 0.01
I0523 05:39:39.087477 34819 solver.cpp:239] Iteration 56450 (1.44435 iter/s, 6.92351s/10 iters), loss = 8.83319
I0523 05:39:39.087610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83319 (* 1 = 8.83319 loss)
I0523 05:39:39.780751 34819 sgd_solver.cpp:112] Iteration 56450, lr = 0.01
I0523 05:39:43.347652 34819 solver.cpp:239] Iteration 56460 (2.3475 iter/s, 4.25986s/10 iters), loss = 8.61919
I0523 05:39:43.347719 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61919 (* 1 = 8.61919 loss)
I0523 05:39:44.178035 34819 sgd_solver.cpp:112] Iteration 56460, lr = 0.01
I0523 05:39:48.286357 34819 solver.cpp:239] Iteration 56470 (2.02494 iter/s, 4.93842s/10 iters), loss = 8.28182
I0523 05:39:48.286415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28182 (* 1 = 8.28182 loss)
I0523 05:39:49.114805 34819 sgd_solver.cpp:112] Iteration 56470, lr = 0.01
I0523 05:39:51.605199 34819 solver.cpp:239] Iteration 56480 (3.01328 iter/s, 3.31864s/10 iters), loss = 8.25023
I0523 05:39:51.605244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25023 (* 1 = 8.25023 loss)
I0523 05:39:52.446183 34819 sgd_solver.cpp:112] Iteration 56480, lr = 0.01
I0523 05:39:57.259310 34819 solver.cpp:239] Iteration 56490 (1.76871 iter/s, 5.65384s/10 iters), loss = 8.19485
I0523 05:39:57.259351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19485 (* 1 = 8.19485 loss)
I0523 05:39:57.340972 34819 sgd_solver.cpp:112] Iteration 56490, lr = 0.01
I0523 05:40:00.511857 34819 solver.cpp:239] Iteration 56500 (3.07469 iter/s, 3.25236s/10 iters), loss = 8.08671
I0523 05:40:00.511907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08671 (* 1 = 8.08671 loss)
I0523 05:40:00.565479 34819 sgd_solver.cpp:112] Iteration 56500, lr = 0.01
I0523 05:40:03.885735 34819 solver.cpp:239] Iteration 56510 (2.96413 iter/s, 3.37368s/10 iters), loss = 7.49797
I0523 05:40:03.885781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.49797 (* 1 = 7.49797 loss)
I0523 05:40:03.948007 34819 sgd_solver.cpp:112] Iteration 56510, lr = 0.01
I0523 05:40:07.355290 34819 solver.cpp:239] Iteration 56520 (2.88239 iter/s, 3.46934s/10 iters), loss = 8.92922
I0523 05:40:07.355345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92922 (* 1 = 8.92922 loss)
I0523 05:40:07.433382 34819 sgd_solver.cpp:112] Iteration 56520, lr = 0.01
I0523 05:40:11.806655 34819 solver.cpp:239] Iteration 56530 (2.24663 iter/s, 4.45112s/10 iters), loss = 9.22368
I0523 05:40:11.806805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22368 (* 1 = 9.22368 loss)
I0523 05:40:11.867965 34819 sgd_solver.cpp:112] Iteration 56530, lr = 0.01
I0523 05:40:15.841073 34819 solver.cpp:239] Iteration 56540 (2.47887 iter/s, 4.0341s/10 iters), loss = 7.7719
I0523 05:40:15.841117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7719 (* 1 = 7.7719 loss)
I0523 05:40:15.888873 34819 sgd_solver.cpp:112] Iteration 56540, lr = 0.01
I0523 05:40:17.958431 34819 solver.cpp:239] Iteration 56550 (4.72318 iter/s, 2.11722s/10 iters), loss = 8.03071
I0523 05:40:17.958469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03071 (* 1 = 8.03071 loss)
I0523 05:40:18.808022 34819 sgd_solver.cpp:112] Iteration 56550, lr = 0.01
I0523 05:40:23.795617 34819 solver.cpp:239] Iteration 56560 (1.71324 iter/s, 5.8369s/10 iters), loss = 8.98771
I0523 05:40:23.795666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98771 (* 1 = 8.98771 loss)
I0523 05:40:24.620738 34819 sgd_solver.cpp:112] Iteration 56560, lr = 0.01
I0523 05:40:29.483088 34819 solver.cpp:239] Iteration 56570 (1.75834 iter/s, 5.68719s/10 iters), loss = 8.91013
I0523 05:40:29.483130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91013 (* 1 = 8.91013 loss)
I0523 05:40:29.542054 34819 sgd_solver.cpp:112] Iteration 56570, lr = 0.01
I0523 05:40:35.657212 34819 solver.cpp:239] Iteration 56580 (1.61974 iter/s, 6.17383s/10 iters), loss = 8.88151
I0523 05:40:35.657251 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88151 (* 1 = 8.88151 loss)
I0523 05:40:35.729080 34819 sgd_solver.cpp:112] Iteration 56580, lr = 0.01
I0523 05:40:37.595546 34819 solver.cpp:239] Iteration 56590 (5.15945 iter/s, 1.93819s/10 iters), loss = 8.42666
I0523 05:40:37.595587 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42666 (* 1 = 8.42666 loss)
I0523 05:40:38.120038 34819 sgd_solver.cpp:112] Iteration 56590, lr = 0.01
I0523 05:40:42.979038 34819 solver.cpp:239] Iteration 56600 (1.85762 iter/s, 5.38323s/10 iters), loss = 8.64796
I0523 05:40:42.979228 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64796 (* 1 = 8.64796 loss)
I0523 05:40:43.057669 34819 sgd_solver.cpp:112] Iteration 56600, lr = 0.01
I0523 05:40:47.131000 34819 solver.cpp:239] Iteration 56610 (2.40871 iter/s, 4.1516s/10 iters), loss = 9.04803
I0523 05:40:47.131049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04803 (* 1 = 9.04803 loss)
I0523 05:40:47.207890 34819 sgd_solver.cpp:112] Iteration 56610, lr = 0.01
I0523 05:40:51.824332 34819 solver.cpp:239] Iteration 56620 (2.13079 iter/s, 4.69309s/10 iters), loss = 7.90867
I0523 05:40:51.824374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90867 (* 1 = 7.90867 loss)
I0523 05:40:51.898070 34819 sgd_solver.cpp:112] Iteration 56620, lr = 0.01
I0523 05:40:58.234148 34819 solver.cpp:239] Iteration 56630 (1.56019 iter/s, 6.40949s/10 iters), loss = 9.4694
I0523 05:40:58.234203 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4694 (* 1 = 9.4694 loss)
I0523 05:40:58.302637 34819 sgd_solver.cpp:112] Iteration 56630, lr = 0.01
I0523 05:41:02.622541 34819 solver.cpp:239] Iteration 56640 (2.27887 iter/s, 4.38814s/10 iters), loss = 8.11804
I0523 05:41:02.622604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11804 (* 1 = 8.11804 loss)
I0523 05:41:03.356818 34819 sgd_solver.cpp:112] Iteration 56640, lr = 0.01
I0523 05:41:08.177496 34819 solver.cpp:239] Iteration 56650 (1.80029 iter/s, 5.55467s/10 iters), loss = 8.35499
I0523 05:41:08.177547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35499 (* 1 = 8.35499 loss)
I0523 05:41:08.238878 34819 sgd_solver.cpp:112] Iteration 56650, lr = 0.01
I0523 05:41:13.831673 34819 solver.cpp:239] Iteration 56660 (1.7687 iter/s, 5.65388s/10 iters), loss = 7.39976
I0523 05:41:13.831784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39976 (* 1 = 7.39976 loss)
I0523 05:41:13.905205 34819 sgd_solver.cpp:112] Iteration 56660, lr = 0.01
I0523 05:41:17.851181 34819 solver.cpp:239] Iteration 56670 (2.48804 iter/s, 4.01923s/10 iters), loss = 8.55418
I0523 05:41:17.851220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55418 (* 1 = 8.55418 loss)
I0523 05:41:17.905767 34819 sgd_solver.cpp:112] Iteration 56670, lr = 0.01
I0523 05:41:22.142913 34819 solver.cpp:239] Iteration 56680 (2.33019 iter/s, 4.2915s/10 iters), loss = 8.75765
I0523 05:41:22.142978 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75765 (* 1 = 8.75765 loss)
I0523 05:41:22.912503 34819 sgd_solver.cpp:112] Iteration 56680, lr = 0.01
I0523 05:41:27.250803 34819 solver.cpp:239] Iteration 56690 (1.95786 iter/s, 5.10762s/10 iters), loss = 8.33382
I0523 05:41:27.250844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33382 (* 1 = 8.33382 loss)
I0523 05:41:27.319557 34819 sgd_solver.cpp:112] Iteration 56690, lr = 0.01
I0523 05:41:32.795130 34819 solver.cpp:239] Iteration 56700 (1.80373 iter/s, 5.54406s/10 iters), loss = 8.3326
I0523 05:41:32.795171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3326 (* 1 = 8.3326 loss)
I0523 05:41:32.878499 34819 sgd_solver.cpp:112] Iteration 56700, lr = 0.01
I0523 05:41:37.756888 34819 solver.cpp:239] Iteration 56710 (2.01552 iter/s, 4.9615s/10 iters), loss = 8.15492
I0523 05:41:37.756928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15492 (* 1 = 8.15492 loss)
I0523 05:41:37.817276 34819 sgd_solver.cpp:112] Iteration 56710, lr = 0.01
I0523 05:41:41.878823 34819 solver.cpp:239] Iteration 56720 (2.42617 iter/s, 4.12172s/10 iters), loss = 7.86167
I0523 05:41:41.878867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86167 (* 1 = 7.86167 loss)
I0523 05:41:41.949049 34819 sgd_solver.cpp:112] Iteration 56720, lr = 0.01
I0523 05:41:46.270210 34819 solver.cpp:239] Iteration 56730 (2.27731 iter/s, 4.39115s/10 iters), loss = 7.96405
I0523 05:41:46.270364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96405 (* 1 = 7.96405 loss)
I0523 05:41:46.353292 34819 sgd_solver.cpp:112] Iteration 56730, lr = 0.01
I0523 05:41:51.436990 34819 solver.cpp:239] Iteration 56740 (1.93558 iter/s, 5.16641s/10 iters), loss = 9.27648
I0523 05:41:51.437031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27648 (* 1 = 9.27648 loss)
I0523 05:41:52.238989 34819 sgd_solver.cpp:112] Iteration 56740, lr = 0.01
I0523 05:41:55.795044 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 05:41:57.018405 34819 solver.cpp:239] Iteration 56750 (1.79175 iter/s, 5.58113s/10 iters), loss = 9.45248
I0523 05:41:57.018446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.45248 (* 1 = 9.45248 loss)
I0523 05:41:57.086215 34819 sgd_solver.cpp:112] Iteration 56750, lr = 0.01
I0523 05:42:02.586022 34819 solver.cpp:239] Iteration 56760 (1.79619 iter/s, 5.56733s/10 iters), loss = 7.61984
I0523 05:42:02.586071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61984 (* 1 = 7.61984 loss)
I0523 05:42:03.301046 34819 sgd_solver.cpp:112] Iteration 56760, lr = 0.01
I0523 05:42:08.071789 34819 solver.cpp:239] Iteration 56770 (1.82299 iter/s, 5.48549s/10 iters), loss = 8.3233
I0523 05:42:08.071832 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3233 (* 1 = 8.3233 loss)
I0523 05:42:08.879531 34819 sgd_solver.cpp:112] Iteration 56770, lr = 0.01
I0523 05:42:14.470388 34819 solver.cpp:239] Iteration 56780 (1.56292 iter/s, 6.3983s/10 iters), loss = 8.4852
I0523 05:42:14.470430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4852 (* 1 = 8.4852 loss)
I0523 05:42:14.537433 34819 sgd_solver.cpp:112] Iteration 56780, lr = 0.01
I0523 05:42:18.568011 34819 solver.cpp:239] Iteration 56790 (2.44057 iter/s, 4.09741s/10 iters), loss = 8.81217
I0523 05:42:18.568107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81217 (* 1 = 8.81217 loss)
I0523 05:42:18.627377 34819 sgd_solver.cpp:112] Iteration 56790, lr = 0.01
I0523 05:42:24.154748 34819 solver.cpp:239] Iteration 56800 (1.79006 iter/s, 5.58641s/10 iters), loss = 8.75331
I0523 05:42:24.154800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75331 (* 1 = 8.75331 loss)
I0523 05:42:25.008677 34819 sgd_solver.cpp:112] Iteration 56800, lr = 0.01
I0523 05:42:29.662475 34819 solver.cpp:239] Iteration 56810 (1.81572 iter/s, 5.50745s/10 iters), loss = 8.98115
I0523 05:42:29.662518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98115 (* 1 = 8.98115 loss)
I0523 05:42:29.730408 34819 sgd_solver.cpp:112] Iteration 56810, lr = 0.01
I0523 05:42:33.982362 34819 solver.cpp:239] Iteration 56820 (2.315 iter/s, 4.31966s/10 iters), loss = 8.56797
I0523 05:42:33.982403 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56797 (* 1 = 8.56797 loss)
I0523 05:42:34.122360 34819 sgd_solver.cpp:112] Iteration 56820, lr = 0.01
I0523 05:42:38.115581 34819 solver.cpp:239] Iteration 56830 (2.41955 iter/s, 4.13299s/10 iters), loss = 8.07144
I0523 05:42:38.115619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07144 (* 1 = 8.07144 loss)
I0523 05:42:38.194135 34819 sgd_solver.cpp:112] Iteration 56830, lr = 0.01
I0523 05:42:41.390002 34819 solver.cpp:239] Iteration 56840 (3.05416 iter/s, 3.27422s/10 iters), loss = 8.08231
I0523 05:42:41.390058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08231 (* 1 = 8.08231 loss)
I0523 05:42:41.808753 34819 sgd_solver.cpp:112] Iteration 56840, lr = 0.01
I0523 05:42:45.108469 34819 solver.cpp:239] Iteration 56850 (2.68944 iter/s, 3.71824s/10 iters), loss = 8.3308
I0523 05:42:45.108518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3308 (* 1 = 8.3308 loss)
I0523 05:42:45.786798 34819 sgd_solver.cpp:112] Iteration 56850, lr = 0.01
I0523 05:42:49.231814 34819 solver.cpp:239] Iteration 56860 (2.42535 iter/s, 4.12311s/10 iters), loss = 8.45798
I0523 05:42:49.232036 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45798 (* 1 = 8.45798 loss)
I0523 05:42:49.308166 34819 sgd_solver.cpp:112] Iteration 56860, lr = 0.01
I0523 05:42:54.084378 34819 solver.cpp:239] Iteration 56870 (2.06094 iter/s, 4.85216s/10 iters), loss = 8.8388
I0523 05:42:54.084419 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8388 (* 1 = 8.8388 loss)
I0523 05:42:54.791739 34819 sgd_solver.cpp:112] Iteration 56870, lr = 0.01
I0523 05:42:58.848321 34819 solver.cpp:239] Iteration 56880 (2.09922 iter/s, 4.76368s/10 iters), loss = 8.91631
I0523 05:42:58.848382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91631 (* 1 = 8.91631 loss)
I0523 05:42:58.917193 34819 sgd_solver.cpp:112] Iteration 56880, lr = 0.01
I0523 05:43:05.260861 34819 solver.cpp:239] Iteration 56890 (1.55952 iter/s, 6.41222s/10 iters), loss = 8.73725
I0523 05:43:05.260902 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73725 (* 1 = 8.73725 loss)
I0523 05:43:05.325453 34819 sgd_solver.cpp:112] Iteration 56890, lr = 0.01
I0523 05:43:09.469067 34819 solver.cpp:239] Iteration 56900 (2.37643 iter/s, 4.20798s/10 iters), loss = 8.8478
I0523 05:43:09.469122 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8478 (* 1 = 8.8478 loss)
I0523 05:43:09.548698 34819 sgd_solver.cpp:112] Iteration 56900, lr = 0.01
I0523 05:43:15.172101 34819 solver.cpp:239] Iteration 56910 (1.75356 iter/s, 5.7027s/10 iters), loss = 8.56425
I0523 05:43:15.172163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56425 (* 1 = 8.56425 loss)
I0523 05:43:15.792577 34819 sgd_solver.cpp:112] Iteration 56910, lr = 0.01
I0523 05:43:19.506616 34819 solver.cpp:239] Iteration 56920 (2.30719 iter/s, 4.33427s/10 iters), loss = 8.01673
I0523 05:43:19.506760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01673 (* 1 = 8.01673 loss)
I0523 05:43:20.206008 34819 sgd_solver.cpp:112] Iteration 56920, lr = 0.01
I0523 05:43:24.988109 34819 solver.cpp:239] Iteration 56930 (1.82444 iter/s, 5.48113s/10 iters), loss = 8.34728
I0523 05:43:24.988155 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34728 (* 1 = 8.34728 loss)
I0523 05:43:25.077091 34819 sgd_solver.cpp:112] Iteration 56930, lr = 0.01
I0523 05:43:28.725342 34819 solver.cpp:239] Iteration 56940 (2.67593 iter/s, 3.73702s/10 iters), loss = 7.3256
I0523 05:43:28.725385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3256 (* 1 = 7.3256 loss)
I0523 05:43:28.780391 34819 sgd_solver.cpp:112] Iteration 56940, lr = 0.01
I0523 05:43:32.838958 34819 solver.cpp:239] Iteration 56950 (2.43109 iter/s, 4.11339s/10 iters), loss = 7.80616
I0523 05:43:32.839010 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80616 (* 1 = 7.80616 loss)
I0523 05:43:33.642213 34819 sgd_solver.cpp:112] Iteration 56950, lr = 0.01
I0523 05:43:37.676275 34819 solver.cpp:239] Iteration 56960 (2.06737 iter/s, 4.83706s/10 iters), loss = 8.01631
I0523 05:43:37.676337 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01631 (* 1 = 8.01631 loss)
I0523 05:43:37.737869 34819 sgd_solver.cpp:112] Iteration 56960, lr = 0.01
I0523 05:43:40.997330 34819 solver.cpp:239] Iteration 56970 (3.01128 iter/s, 3.32085s/10 iters), loss = 8.68061
I0523 05:43:40.997390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68061 (* 1 = 8.68061 loss)
I0523 05:43:41.849073 34819 sgd_solver.cpp:112] Iteration 56970, lr = 0.01
I0523 05:43:46.793303 34819 solver.cpp:239] Iteration 56980 (1.72543 iter/s, 5.79567s/10 iters), loss = 8.77319
I0523 05:43:46.793344 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77319 (* 1 = 8.77319 loss)
I0523 05:43:46.871616 34819 sgd_solver.cpp:112] Iteration 56980, lr = 0.01
I0523 05:43:51.925217 34819 solver.cpp:239] Iteration 56990 (1.94869 iter/s, 5.13165s/10 iters), loss = 8.02806
I0523 05:43:51.925467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02806 (* 1 = 8.02806 loss)
I0523 05:43:52.710608 34819 sgd_solver.cpp:112] Iteration 56990, lr = 0.01
I0523 05:43:58.254729 34819 solver.cpp:239] Iteration 57000 (1.58003 iter/s, 6.32899s/10 iters), loss = 8.71739
I0523 05:43:58.254788 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71739 (* 1 = 8.71739 loss)
I0523 05:43:58.323331 34819 sgd_solver.cpp:112] Iteration 57000, lr = 0.01
I0523 05:44:02.274832 34819 solver.cpp:239] Iteration 57010 (2.48765 iter/s, 4.01986s/10 iters), loss = 8.01672
I0523 05:44:02.274884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01672 (* 1 = 8.01672 loss)
I0523 05:44:02.328610 34819 sgd_solver.cpp:112] Iteration 57010, lr = 0.01
I0523 05:44:06.850165 34819 solver.cpp:239] Iteration 57020 (2.18575 iter/s, 4.57508s/10 iters), loss = 9.17575
I0523 05:44:06.850224 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17575 (* 1 = 9.17575 loss)
I0523 05:44:06.913599 34819 sgd_solver.cpp:112] Iteration 57020, lr = 0.01
I0523 05:44:12.299549 34819 solver.cpp:239] Iteration 57030 (1.83516 iter/s, 5.44911s/10 iters), loss = 7.20629
I0523 05:44:12.299589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20629 (* 1 = 7.20629 loss)
I0523 05:44:12.358330 34819 sgd_solver.cpp:112] Iteration 57030, lr = 0.01
I0523 05:44:16.696933 34819 solver.cpp:239] Iteration 57040 (2.2742 iter/s, 4.39715s/10 iters), loss = 9.68076
I0523 05:44:16.696975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.68076 (* 1 = 9.68076 loss)
I0523 05:44:16.769940 34819 sgd_solver.cpp:112] Iteration 57040, lr = 0.01
I0523 05:44:22.291504 34819 solver.cpp:239] Iteration 57050 (1.78754 iter/s, 5.59429s/10 iters), loss = 8.76941
I0523 05:44:22.291709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76941 (* 1 = 8.76941 loss)
I0523 05:44:22.368238 34819 sgd_solver.cpp:112] Iteration 57050, lr = 0.01
I0523 05:44:27.056346 34819 solver.cpp:239] Iteration 57060 (2.09888 iter/s, 4.76445s/10 iters), loss = 8.36796
I0523 05:44:27.056406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36796 (* 1 = 8.36796 loss)
I0523 05:44:27.885995 34819 sgd_solver.cpp:112] Iteration 57060, lr = 0.01
I0523 05:44:32.625401 34819 solver.cpp:239] Iteration 57070 (1.79573 iter/s, 5.56876s/10 iters), loss = 8.27619
I0523 05:44:32.625452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27619 (* 1 = 8.27619 loss)
I0523 05:44:33.469624 34819 sgd_solver.cpp:112] Iteration 57070, lr = 0.01
I0523 05:44:37.361770 34819 solver.cpp:239] Iteration 57080 (2.11143 iter/s, 4.73612s/10 iters), loss = 8.40366
I0523 05:44:37.361814 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40366 (* 1 = 8.40366 loss)
I0523 05:44:37.428176 34819 sgd_solver.cpp:112] Iteration 57080, lr = 0.01
I0523 05:44:41.131253 34819 solver.cpp:239] Iteration 57090 (2.65304 iter/s, 3.76926s/10 iters), loss = 7.67949
I0523 05:44:41.131307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67949 (* 1 = 7.67949 loss)
I0523 05:44:41.877451 34819 sgd_solver.cpp:112] Iteration 57090, lr = 0.01
I0523 05:44:46.383111 34819 solver.cpp:239] Iteration 57100 (1.90419 iter/s, 5.25158s/10 iters), loss = 8.08025
I0523 05:44:46.383154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08025 (* 1 = 8.08025 loss)
I0523 05:44:46.700425 34819 sgd_solver.cpp:112] Iteration 57100, lr = 0.01
I0523 05:44:50.446519 34819 solver.cpp:239] Iteration 57110 (2.46112 iter/s, 4.06319s/10 iters), loss = 8.45496
I0523 05:44:50.446568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45496 (* 1 = 8.45496 loss)
I0523 05:44:50.522505 34819 sgd_solver.cpp:112] Iteration 57110, lr = 0.01
I0523 05:44:55.962843 34819 solver.cpp:239] Iteration 57120 (1.8129 iter/s, 5.51603s/10 iters), loss = 7.30602
I0523 05:44:55.962983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.30602 (* 1 = 7.30602 loss)
I0523 05:44:56.020349 34819 sgd_solver.cpp:112] Iteration 57120, lr = 0.01
I0523 05:45:00.696291 34819 solver.cpp:239] Iteration 57130 (2.11278 iter/s, 4.7331s/10 iters), loss = 8.12476
I0523 05:45:00.696341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12476 (* 1 = 8.12476 loss)
I0523 05:45:00.757737 34819 sgd_solver.cpp:112] Iteration 57130, lr = 0.01
I0523 05:45:06.548163 34819 solver.cpp:239] Iteration 57140 (1.70894 iter/s, 5.85158s/10 iters), loss = 8.41012
I0523 05:45:06.548205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41012 (* 1 = 8.41012 loss)
I0523 05:45:06.633255 34819 sgd_solver.cpp:112] Iteration 57140, lr = 0.01
I0523 05:45:08.924715 34819 solver.cpp:239] Iteration 57150 (4.20805 iter/s, 2.3764s/10 iters), loss = 7.57841
I0523 05:45:08.924755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57841 (* 1 = 7.57841 loss)
I0523 05:45:08.984658 34819 sgd_solver.cpp:112] Iteration 57150, lr = 0.01
I0523 05:45:14.143195 34819 solver.cpp:239] Iteration 57160 (1.91637 iter/s, 5.21821s/10 iters), loss = 8.41783
I0523 05:45:14.143245 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41783 (* 1 = 8.41783 loss)
I0523 05:45:14.200644 34819 sgd_solver.cpp:112] Iteration 57160, lr = 0.01
I0523 05:45:18.165937 34819 solver.cpp:239] Iteration 57170 (2.486 iter/s, 4.02253s/10 iters), loss = 7.65592
I0523 05:45:18.165980 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65592 (* 1 = 7.65592 loss)
I0523 05:45:18.241106 34819 sgd_solver.cpp:112] Iteration 57170, lr = 0.01
I0523 05:45:23.976867 34819 solver.cpp:239] Iteration 57180 (1.72098 iter/s, 5.81065s/10 iters), loss = 7.58005
I0523 05:45:23.976907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58005 (* 1 = 7.58005 loss)
I0523 05:45:24.774426 34819 sgd_solver.cpp:112] Iteration 57180, lr = 0.01
I0523 05:45:30.156319 34819 solver.cpp:239] Iteration 57190 (1.61834 iter/s, 6.17916s/10 iters), loss = 8.43027
I0523 05:45:30.156450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43027 (* 1 = 8.43027 loss)
I0523 05:45:30.214022 34819 sgd_solver.cpp:112] Iteration 57190, lr = 0.01
I0523 05:45:35.726353 34819 solver.cpp:239] Iteration 57200 (1.79544 iter/s, 5.56967s/10 iters), loss = 8.65718
I0523 05:45:35.726397 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65718 (* 1 = 8.65718 loss)
I0523 05:45:36.408766 34819 sgd_solver.cpp:112] Iteration 57200, lr = 0.01
I0523 05:45:41.206292 34819 solver.cpp:239] Iteration 57210 (1.82493 iter/s, 5.47967s/10 iters), loss = 8.30003
I0523 05:45:41.206334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30003 (* 1 = 8.30003 loss)
I0523 05:45:41.276453 34819 sgd_solver.cpp:112] Iteration 57210, lr = 0.01
I0523 05:45:44.454099 34819 solver.cpp:239] Iteration 57220 (3.07918 iter/s, 3.24762s/10 iters), loss = 7.31265
I0523 05:45:44.454143 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.31265 (* 1 = 7.31265 loss)
I0523 05:45:45.296175 34819 sgd_solver.cpp:112] Iteration 57220, lr = 0.01
I0523 05:45:50.204247 34819 solver.cpp:239] Iteration 57230 (1.73917 iter/s, 5.74986s/10 iters), loss = 8.31399
I0523 05:45:50.204293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31399 (* 1 = 8.31399 loss)
I0523 05:45:50.394739 34819 sgd_solver.cpp:112] Iteration 57230, lr = 0.01
I0523 05:45:54.867931 34819 solver.cpp:239] Iteration 57240 (2.14434 iter/s, 4.66344s/10 iters), loss = 8.70803
I0523 05:45:54.867975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70803 (* 1 = 8.70803 loss)
I0523 05:45:55.710649 34819 sgd_solver.cpp:112] Iteration 57240, lr = 0.01
I0523 05:45:59.261510 34819 solver.cpp:239] Iteration 57250 (2.27617 iter/s, 4.39334s/10 iters), loss = 8.72365
I0523 05:45:59.261554 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72365 (* 1 = 8.72365 loss)
I0523 05:45:59.334767 34819 sgd_solver.cpp:112] Iteration 57250, lr = 0.01
I0523 05:46:04.708417 34819 solver.cpp:239] Iteration 57260 (1.83695 iter/s, 5.44381s/10 iters), loss = 8.04509
I0523 05:46:04.708578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04509 (* 1 = 8.04509 loss)
I0523 05:46:04.776437 34819 sgd_solver.cpp:112] Iteration 57260, lr = 0.01
I0523 05:46:09.475102 34819 solver.cpp:239] Iteration 57270 (2.09805 iter/s, 4.76633s/10 iters), loss = 8.3872
I0523 05:46:09.475145 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3872 (* 1 = 8.3872 loss)
I0523 05:46:10.362807 34819 sgd_solver.cpp:112] Iteration 57270, lr = 0.01
I0523 05:46:14.521373 34819 solver.cpp:239] Iteration 57280 (1.98176 iter/s, 5.04602s/10 iters), loss = 7.83236
I0523 05:46:14.521423 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83236 (* 1 = 7.83236 loss)
I0523 05:46:14.594061 34819 sgd_solver.cpp:112] Iteration 57280, lr = 0.01
I0523 05:46:19.695204 34819 solver.cpp:239] Iteration 57290 (1.9329 iter/s, 5.17356s/10 iters), loss = 6.84334
I0523 05:46:19.695273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.84334 (* 1 = 6.84334 loss)
I0523 05:46:19.767190 34819 sgd_solver.cpp:112] Iteration 57290, lr = 0.01
I0523 05:46:26.140128 34819 solver.cpp:239] Iteration 57300 (1.55169 iter/s, 6.44458s/10 iters), loss = 8.89507
I0523 05:46:26.140177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89507 (* 1 = 8.89507 loss)
I0523 05:46:26.208639 34819 sgd_solver.cpp:112] Iteration 57300, lr = 0.01
I0523 05:46:32.595512 34819 solver.cpp:239] Iteration 57310 (1.54917 iter/s, 6.45507s/10 iters), loss = 8.1482
I0523 05:46:32.595568 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1482 (* 1 = 8.1482 loss)
I0523 05:46:33.390717 34819 sgd_solver.cpp:112] Iteration 57310, lr = 0.01
I0523 05:46:36.876595 34819 solver.cpp:239] Iteration 57320 (2.33599 iter/s, 4.28085s/10 iters), loss = 8.29782
I0523 05:46:36.876827 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29782 (* 1 = 8.29782 loss)
I0523 05:46:36.959628 34819 sgd_solver.cpp:112] Iteration 57320, lr = 0.01
I0523 05:46:42.395128 34819 solver.cpp:239] Iteration 57330 (1.81221 iter/s, 5.51811s/10 iters), loss = 8.62857
I0523 05:46:42.395169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62857 (* 1 = 8.62857 loss)
I0523 05:46:43.140904 34819 sgd_solver.cpp:112] Iteration 57330, lr = 0.01
I0523 05:46:47.051170 34819 solver.cpp:239] Iteration 57340 (2.14786 iter/s, 4.6558s/10 iters), loss = 8.8328
I0523 05:46:47.051226 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8328 (* 1 = 8.8328 loss)
I0523 05:46:47.126135 34819 sgd_solver.cpp:112] Iteration 57340, lr = 0.01
I0523 05:46:51.063387 34819 solver.cpp:239] Iteration 57350 (2.49253 iter/s, 4.01198s/10 iters), loss = 9.02264
I0523 05:46:51.063427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02264 (* 1 = 9.02264 loss)
I0523 05:46:51.120194 34819 sgd_solver.cpp:112] Iteration 57350, lr = 0.01
I0523 05:46:57.638288 34819 solver.cpp:239] Iteration 57360 (1.52101 iter/s, 6.57459s/10 iters), loss = 9.04549
I0523 05:46:57.638329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04549 (* 1 = 9.04549 loss)
I0523 05:46:57.704797 34819 sgd_solver.cpp:112] Iteration 57360, lr = 0.01
I0523 05:47:01.863020 34819 solver.cpp:239] Iteration 57370 (2.36714 iter/s, 4.22451s/10 iters), loss = 8.05638
I0523 05:47:01.863068 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05638 (* 1 = 8.05638 loss)
I0523 05:47:02.737998 34819 sgd_solver.cpp:112] Iteration 57370, lr = 0.01
I0523 05:47:08.172292 34819 solver.cpp:239] Iteration 57380 (1.58505 iter/s, 6.30896s/10 iters), loss = 9.22436
I0523 05:47:08.172406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22436 (* 1 = 9.22436 loss)
I0523 05:47:08.234810 34819 sgd_solver.cpp:112] Iteration 57380, lr = 0.01
I0523 05:47:11.728705 34819 solver.cpp:239] Iteration 57390 (2.81203 iter/s, 3.55615s/10 iters), loss = 7.36254
I0523 05:47:11.728746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36254 (* 1 = 7.36254 loss)
I0523 05:47:12.336066 34819 sgd_solver.cpp:112] Iteration 57390, lr = 0.01
I0523 05:47:15.553228 34819 solver.cpp:239] Iteration 57400 (2.61485 iter/s, 3.82431s/10 iters), loss = 7.62389
I0523 05:47:15.553270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62389 (* 1 = 7.62389 loss)
I0523 05:47:15.615761 34819 sgd_solver.cpp:112] Iteration 57400, lr = 0.01
I0523 05:47:20.750851 34819 solver.cpp:239] Iteration 57410 (1.92405 iter/s, 5.19737s/10 iters), loss = 8.90427
I0523 05:47:20.750895 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90427 (* 1 = 8.90427 loss)
I0523 05:47:21.277160 34819 sgd_solver.cpp:112] Iteration 57410, lr = 0.01
I0523 05:47:27.536875 34819 solver.cpp:239] Iteration 57420 (1.47369 iter/s, 6.7857s/10 iters), loss = 8.43446
I0523 05:47:27.536917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43446 (* 1 = 8.43446 loss)
I0523 05:47:27.596912 34819 sgd_solver.cpp:112] Iteration 57420, lr = 0.01
I0523 05:47:32.180467 34819 solver.cpp:239] Iteration 57430 (2.15362 iter/s, 4.64334s/10 iters), loss = 7.78939
I0523 05:47:32.180514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78939 (* 1 = 7.78939 loss)
I0523 05:47:33.001852 34819 sgd_solver.cpp:112] Iteration 57430, lr = 0.01
I0523 05:47:38.027424 34819 solver.cpp:239] Iteration 57440 (1.71038 iter/s, 5.84664s/10 iters), loss = 9.04814
I0523 05:47:38.027474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04814 (* 1 = 9.04814 loss)
I0523 05:47:38.089077 34819 sgd_solver.cpp:112] Iteration 57440, lr = 0.01
I0523 05:47:44.114976 34819 solver.cpp:239] Iteration 57450 (1.64278 iter/s, 6.08724s/10 iters), loss = 9.04525
I0523 05:47:44.115191 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04525 (* 1 = 9.04525 loss)
I0523 05:47:44.920032 34819 sgd_solver.cpp:112] Iteration 57450, lr = 0.01
I0523 05:47:50.195713 34819 solver.cpp:239] Iteration 57460 (1.64466 iter/s, 6.0803s/10 iters), loss = 8.32872
I0523 05:47:50.195753 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32872 (* 1 = 8.32872 loss)
I0523 05:47:50.256283 34819 sgd_solver.cpp:112] Iteration 57460, lr = 0.01
I0523 05:47:54.445999 34819 solver.cpp:239] Iteration 57470 (2.35291 iter/s, 4.25006s/10 iters), loss = 8.39336
I0523 05:47:54.446058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39336 (* 1 = 8.39336 loss)
I0523 05:47:55.027199 34819 sgd_solver.cpp:112] Iteration 57470, lr = 0.01
I0523 05:48:00.030892 34819 solver.cpp:239] Iteration 57480 (1.79064 iter/s, 5.58459s/10 iters), loss = 8.25607
I0523 05:48:00.030946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25607 (* 1 = 8.25607 loss)
I0523 05:48:00.099690 34819 sgd_solver.cpp:112] Iteration 57480, lr = 0.01
I0523 05:48:05.142133 34819 solver.cpp:239] Iteration 57490 (1.95658 iter/s, 5.11095s/10 iters), loss = 8.06593
I0523 05:48:05.142206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06593 (* 1 = 8.06593 loss)
I0523 05:48:05.988806 34819 sgd_solver.cpp:112] Iteration 57490, lr = 0.01
I0523 05:48:10.789899 34819 solver.cpp:239] Iteration 57500 (1.7707 iter/s, 5.64747s/10 iters), loss = 8.76955
I0523 05:48:10.789942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76955 (* 1 = 8.76955 loss)
I0523 05:48:10.845513 34819 sgd_solver.cpp:112] Iteration 57500, lr = 0.01
I0523 05:48:15.078563 34819 solver.cpp:239] Iteration 57510 (2.33186 iter/s, 4.28841s/10 iters), loss = 8.40928
I0523 05:48:15.078793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40928 (* 1 = 8.40928 loss)
I0523 05:48:15.923990 34819 sgd_solver.cpp:112] Iteration 57510, lr = 0.01
I0523 05:48:19.776145 34819 solver.cpp:239] Iteration 57520 (2.12894 iter/s, 4.69718s/10 iters), loss = 8.07113
I0523 05:48:19.776188 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07113 (* 1 = 8.07113 loss)
I0523 05:48:19.839102 34819 sgd_solver.cpp:112] Iteration 57520, lr = 0.01
I0523 05:48:24.098780 34819 solver.cpp:239] Iteration 57530 (2.31353 iter/s, 4.32239s/10 iters), loss = 7.55163
I0523 05:48:24.098835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55163 (* 1 = 7.55163 loss)
I0523 05:48:24.173398 34819 sgd_solver.cpp:112] Iteration 57530, lr = 0.01
I0523 05:48:29.604944 34819 solver.cpp:239] Iteration 57540 (1.81624 iter/s, 5.50587s/10 iters), loss = 8.42167
I0523 05:48:29.604997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42167 (* 1 = 8.42167 loss)
I0523 05:48:29.929822 34819 sgd_solver.cpp:112] Iteration 57540, lr = 0.01
I0523 05:48:34.884213 34819 solver.cpp:239] Iteration 57550 (1.8943 iter/s, 5.279s/10 iters), loss = 8.02925
I0523 05:48:34.884255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02925 (* 1 = 8.02925 loss)
I0523 05:48:34.962188 34819 sgd_solver.cpp:112] Iteration 57550, lr = 0.01
I0523 05:48:38.380952 34819 solver.cpp:239] Iteration 57560 (2.85997 iter/s, 3.49654s/10 iters), loss = 8.32082
I0523 05:48:38.381021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32082 (* 1 = 8.32082 loss)
I0523 05:48:38.449025 34819 sgd_solver.cpp:112] Iteration 57560, lr = 0.01
I0523 05:48:41.760466 34819 solver.cpp:239] Iteration 57570 (2.95919 iter/s, 3.3793s/10 iters), loss = 7.59441
I0523 05:48:41.760507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59441 (* 1 = 7.59441 loss)
I0523 05:48:42.643688 34819 sgd_solver.cpp:112] Iteration 57570, lr = 0.01
I0523 05:48:47.503438 34819 solver.cpp:239] Iteration 57580 (1.74135 iter/s, 5.74269s/10 iters), loss = 8.4949
I0523 05:48:47.503617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4949 (* 1 = 8.4949 loss)
I0523 05:48:48.343482 34819 sgd_solver.cpp:112] Iteration 57580, lr = 0.01
I0523 05:48:51.618289 34819 solver.cpp:239] Iteration 57590 (2.43044 iter/s, 4.11449s/10 iters), loss = 8.70932
I0523 05:48:51.618345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70932 (* 1 = 8.70932 loss)
I0523 05:48:51.681195 34819 sgd_solver.cpp:112] Iteration 57590, lr = 0.01
I0523 05:48:54.324554 34819 solver.cpp:239] Iteration 57600 (3.69537 iter/s, 2.70609s/10 iters), loss = 8.25355
I0523 05:48:54.324600 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25355 (* 1 = 8.25355 loss)
I0523 05:48:54.383244 34819 sgd_solver.cpp:112] Iteration 57600, lr = 0.01
I0523 05:48:59.567813 34819 solver.cpp:239] Iteration 57610 (1.90731 iter/s, 5.243s/10 iters), loss = 8.49124
I0523 05:48:59.567867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49124 (* 1 = 8.49124 loss)
I0523 05:48:59.649394 34819 sgd_solver.cpp:112] Iteration 57610, lr = 0.01
I0523 05:49:03.856904 34819 solver.cpp:239] Iteration 57620 (2.33163 iter/s, 4.28885s/10 iters), loss = 8.08561
I0523 05:49:03.856945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08561 (* 1 = 8.08561 loss)
I0523 05:49:03.926323 34819 sgd_solver.cpp:112] Iteration 57620, lr = 0.01
I0523 05:49:08.351269 34819 solver.cpp:239] Iteration 57630 (2.22512 iter/s, 4.49414s/10 iters), loss = 8.35814
I0523 05:49:08.351312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35814 (* 1 = 8.35814 loss)
I0523 05:49:09.218065 34819 sgd_solver.cpp:112] Iteration 57630, lr = 0.01
I0523 05:49:14.926160 34819 solver.cpp:239] Iteration 57640 (1.52101 iter/s, 6.57457s/10 iters), loss = 7.63063
I0523 05:49:14.926223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63063 (* 1 = 7.63063 loss)
I0523 05:49:15.637341 34819 sgd_solver.cpp:112] Iteration 57640, lr = 0.01
I0523 05:49:19.090051 34819 solver.cpp:239] Iteration 57650 (2.40174 iter/s, 4.16365s/10 iters), loss = 7.36065
I0523 05:49:19.090167 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36065 (* 1 = 7.36065 loss)
I0523 05:49:19.153707 34819 sgd_solver.cpp:112] Iteration 57650, lr = 0.01
I0523 05:49:25.585960 34819 solver.cpp:239] Iteration 57660 (1.53952 iter/s, 6.49553s/10 iters), loss = 8.03962
I0523 05:49:25.586011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03962 (* 1 = 8.03962 loss)
I0523 05:49:25.655961 34819 sgd_solver.cpp:112] Iteration 57660, lr = 0.01
I0523 05:49:30.550904 34819 solver.cpp:239] Iteration 57670 (2.01423 iter/s, 4.96467s/10 iters), loss = 7.70698
I0523 05:49:30.550958 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70698 (* 1 = 7.70698 loss)
I0523 05:49:31.417505 34819 sgd_solver.cpp:112] Iteration 57670, lr = 0.01
I0523 05:49:36.164057 34819 solver.cpp:239] Iteration 57680 (1.78162 iter/s, 5.61287s/10 iters), loss = 8.27831
I0523 05:49:36.164106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27831 (* 1 = 8.27831 loss)
I0523 05:49:36.238142 34819 sgd_solver.cpp:112] Iteration 57680, lr = 0.01
I0523 05:49:41.088062 34819 solver.cpp:239] Iteration 57690 (2.03098 iter/s, 4.92373s/10 iters), loss = 8.08302
I0523 05:49:41.088133 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08302 (* 1 = 8.08302 loss)
I0523 05:49:41.901607 34819 sgd_solver.cpp:112] Iteration 57690, lr = 0.01
I0523 05:49:46.041781 34819 solver.cpp:239] Iteration 57700 (2.0188 iter/s, 4.95344s/10 iters), loss = 8.01676
I0523 05:49:46.041823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01676 (* 1 = 8.01676 loss)
I0523 05:49:46.118422 34819 sgd_solver.cpp:112] Iteration 57700, lr = 0.01
I0523 05:49:50.809751 34819 solver.cpp:239] Iteration 57710 (2.09744 iter/s, 4.76771s/10 iters), loss = 8.41348
I0523 05:49:50.809926 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41348 (* 1 = 8.41348 loss)
I0523 05:49:50.889274 34819 sgd_solver.cpp:112] Iteration 57710, lr = 0.01
I0523 05:49:58.673902 34819 solver.cpp:239] Iteration 57720 (1.27167 iter/s, 7.86367s/10 iters), loss = 7.93099
I0523 05:49:58.673943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93099 (* 1 = 7.93099 loss)
I0523 05:49:58.739650 34819 sgd_solver.cpp:112] Iteration 57720, lr = 0.01
I0523 05:50:03.741890 34819 solver.cpp:239] Iteration 57730 (1.97328 iter/s, 5.0677s/10 iters), loss = 7.61676
I0523 05:50:03.741948 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61676 (* 1 = 7.61676 loss)
I0523 05:50:04.524075 34819 sgd_solver.cpp:112] Iteration 57730, lr = 0.01
I0523 05:50:09.000177 34819 solver.cpp:239] Iteration 57740 (1.90186 iter/s, 5.258s/10 iters), loss = 8.5801
I0523 05:50:09.000231 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5801 (* 1 = 8.5801 loss)
I0523 05:50:09.477962 34819 sgd_solver.cpp:112] Iteration 57740, lr = 0.01
I0523 05:50:13.470427 34819 solver.cpp:239] Iteration 57750 (2.23713 iter/s, 4.47s/10 iters), loss = 8.29196
I0523 05:50:13.470476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29196 (* 1 = 8.29196 loss)
I0523 05:50:14.211212 34819 sgd_solver.cpp:112] Iteration 57750, lr = 0.01
I0523 05:50:17.679795 34819 solver.cpp:239] Iteration 57760 (2.37579 iter/s, 4.20913s/10 iters), loss = 8.7627
I0523 05:50:17.679836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7627 (* 1 = 8.7627 loss)
I0523 05:50:17.743088 34819 sgd_solver.cpp:112] Iteration 57760, lr = 0.01
I0523 05:50:21.122059 34819 solver.cpp:239] Iteration 57770 (2.90523 iter/s, 3.44207s/10 iters), loss = 8.1339
I0523 05:50:21.122268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1339 (* 1 = 8.1339 loss)
I0523 05:50:21.906553 34819 sgd_solver.cpp:112] Iteration 57770, lr = 0.01
I0523 05:50:25.054421 34819 solver.cpp:239] Iteration 57780 (2.54323 iter/s, 3.932s/10 iters), loss = 7.56036
I0523 05:50:25.054477 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56036 (* 1 = 7.56036 loss)
I0523 05:50:25.876996 34819 sgd_solver.cpp:112] Iteration 57780, lr = 0.01
I0523 05:50:30.455339 34819 solver.cpp:239] Iteration 57790 (1.85164 iter/s, 5.40062s/10 iters), loss = 9.37075
I0523 05:50:30.455394 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.37075 (* 1 = 9.37075 loss)
I0523 05:50:30.527354 34819 sgd_solver.cpp:112] Iteration 57790, lr = 0.01
I0523 05:50:33.865406 34819 solver.cpp:239] Iteration 57800 (2.93267 iter/s, 3.40987s/10 iters), loss = 8.8542
I0523 05:50:33.865447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8542 (* 1 = 8.8542 loss)
I0523 05:50:33.926904 34819 sgd_solver.cpp:112] Iteration 57800, lr = 0.01
I0523 05:50:39.819689 34819 solver.cpp:239] Iteration 57810 (1.67955 iter/s, 5.95398s/10 iters), loss = 8.92343
I0523 05:50:39.819744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92343 (* 1 = 8.92343 loss)
I0523 05:50:40.512898 34819 sgd_solver.cpp:112] Iteration 57810, lr = 0.01
I0523 05:50:46.000753 34819 solver.cpp:239] Iteration 57820 (1.61793 iter/s, 6.18075s/10 iters), loss = 8.45148
I0523 05:50:46.000816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45148 (* 1 = 8.45148 loss)
I0523 05:50:46.063357 34819 sgd_solver.cpp:112] Iteration 57820, lr = 0.01
I0523 05:50:52.110026 34819 solver.cpp:239] Iteration 57830 (1.63694 iter/s, 6.10895s/10 iters), loss = 9.32435
I0523 05:50:52.110282 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32435 (* 1 = 9.32435 loss)
I0523 05:50:52.948626 34819 sgd_solver.cpp:112] Iteration 57830, lr = 0.01
I0523 05:50:56.605973 34819 solver.cpp:239] Iteration 57840 (2.22443 iter/s, 4.49554s/10 iters), loss = 8.94495
I0523 05:50:56.606019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94495 (* 1 = 8.94495 loss)
I0523 05:50:57.396132 34819 sgd_solver.cpp:112] Iteration 57840, lr = 0.01
I0523 05:51:02.552543 34819 solver.cpp:239] Iteration 57850 (1.68172 iter/s, 5.94629s/10 iters), loss = 8.7133
I0523 05:51:02.552584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7133 (* 1 = 8.7133 loss)
I0523 05:51:03.379710 34819 sgd_solver.cpp:112] Iteration 57850, lr = 0.01
I0523 05:51:06.598239 34819 solver.cpp:239] Iteration 57860 (2.4719 iter/s, 4.04548s/10 iters), loss = 8.95231
I0523 05:51:06.598294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95231 (* 1 = 8.95231 loss)
I0523 05:51:06.658535 34819 sgd_solver.cpp:112] Iteration 57860, lr = 0.01
I0523 05:51:12.021893 34819 solver.cpp:239] Iteration 57870 (1.84387 iter/s, 5.42337s/10 iters), loss = 7.13385
I0523 05:51:12.021941 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13385 (* 1 = 7.13385 loss)
I0523 05:51:12.082571 34819 sgd_solver.cpp:112] Iteration 57870, lr = 0.01
I0523 05:51:17.660176 34819 solver.cpp:239] Iteration 57880 (1.77368 iter/s, 5.63799s/10 iters), loss = 9.12672
I0523 05:51:17.660238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12672 (* 1 = 9.12672 loss)
I0523 05:51:18.365960 34819 sgd_solver.cpp:112] Iteration 57880, lr = 0.01
I0523 05:51:23.869689 34819 solver.cpp:239] Iteration 57890 (1.61051 iter/s, 6.2092s/10 iters), loss = 8.82502
I0523 05:51:23.869827 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82502 (* 1 = 8.82502 loss)
I0523 05:51:24.496707 34819 sgd_solver.cpp:112] Iteration 57890, lr = 0.01
I0523 05:51:29.738785 34819 solver.cpp:239] Iteration 57900 (1.70395 iter/s, 5.86871s/10 iters), loss = 8.34143
I0523 05:51:29.738831 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34143 (* 1 = 8.34143 loss)
I0523 05:51:29.796556 34819 sgd_solver.cpp:112] Iteration 57900, lr = 0.01
I0523 05:51:33.839054 34819 solver.cpp:239] Iteration 57910 (2.439 iter/s, 4.10004s/10 iters), loss = 7.83853
I0523 05:51:33.839095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83853 (* 1 = 7.83853 loss)
I0523 05:51:34.671931 34819 sgd_solver.cpp:112] Iteration 57910, lr = 0.01
I0523 05:51:39.225347 34819 solver.cpp:239] Iteration 57920 (1.85666 iter/s, 5.38602s/10 iters), loss = 8.55904
I0523 05:51:39.225399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55904 (* 1 = 8.55904 loss)
I0523 05:51:39.837055 34819 sgd_solver.cpp:112] Iteration 57920, lr = 0.01
I0523 05:51:42.462313 34819 solver.cpp:239] Iteration 57930 (3.08949 iter/s, 3.23677s/10 iters), loss = 7.28584
I0523 05:51:42.462363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28584 (* 1 = 7.28584 loss)
I0523 05:51:43.174039 34819 sgd_solver.cpp:112] Iteration 57930, lr = 0.01
I0523 05:51:47.842527 34819 solver.cpp:239] Iteration 57940 (1.85876 iter/s, 5.37994s/10 iters), loss = 8.02419
I0523 05:51:47.842567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02419 (* 1 = 8.02419 loss)
I0523 05:51:47.904125 34819 sgd_solver.cpp:112] Iteration 57940, lr = 0.01
I0523 05:51:53.582360 34819 solver.cpp:239] Iteration 57950 (1.7423 iter/s, 5.73955s/10 iters), loss = 7.76514
I0523 05:51:53.582408 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76514 (* 1 = 7.76514 loss)
I0523 05:51:53.644294 34819 sgd_solver.cpp:112] Iteration 57950, lr = 0.01
I0523 05:51:58.098176 34819 solver.cpp:239] Iteration 57960 (2.21456 iter/s, 4.51556s/10 iters), loss = 8.47104
I0523 05:51:58.098346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47104 (* 1 = 8.47104 loss)
I0523 05:51:58.888787 34819 sgd_solver.cpp:112] Iteration 57960, lr = 0.01
I0523 05:52:02.873034 34819 solver.cpp:239] Iteration 57970 (2.09583 iter/s, 4.77137s/10 iters), loss = 8.66825
I0523 05:52:02.873088 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66825 (* 1 = 8.66825 loss)
I0523 05:52:03.083145 34819 sgd_solver.cpp:112] Iteration 57970, lr = 0.01
I0523 05:52:07.070798 34819 solver.cpp:239] Iteration 57980 (2.38235 iter/s, 4.19753s/10 iters), loss = 7.9888
I0523 05:52:07.070842 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9888 (* 1 = 7.9888 loss)
I0523 05:52:07.737447 34819 sgd_solver.cpp:112] Iteration 57980, lr = 0.01
I0523 05:52:12.092387 34819 solver.cpp:239] Iteration 57990 (1.99151 iter/s, 5.02132s/10 iters), loss = 7.68413
I0523 05:52:12.092452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68413 (* 1 = 7.68413 loss)
I0523 05:52:12.167085 34819 sgd_solver.cpp:112] Iteration 57990, lr = 0.01
I0523 05:52:17.853231 34819 solver.cpp:239] Iteration 58000 (1.73595 iter/s, 5.76054s/10 iters), loss = 7.73995
I0523 05:52:17.853282 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73995 (* 1 = 7.73995 loss)
I0523 05:52:17.905107 34819 sgd_solver.cpp:112] Iteration 58000, lr = 0.01
I0523 05:52:21.719893 34819 solver.cpp:239] Iteration 58010 (2.58636 iter/s, 3.86644s/10 iters), loss = 9.4004
I0523 05:52:21.719949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.4004 (* 1 = 9.4004 loss)
I0523 05:52:22.535123 34819 sgd_solver.cpp:112] Iteration 58010, lr = 0.01
I0523 05:52:25.995613 34819 solver.cpp:239] Iteration 58020 (2.33891 iter/s, 4.27549s/10 iters), loss = 8.90941
I0523 05:52:25.995661 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90941 (* 1 = 8.90941 loss)
I0523 05:52:26.069684 34819 sgd_solver.cpp:112] Iteration 58020, lr = 0.01
I0523 05:52:29.833525 34819 solver.cpp:239] Iteration 58030 (2.60574 iter/s, 3.83768s/10 iters), loss = 8.48368
I0523 05:52:29.833664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48368 (* 1 = 8.48368 loss)
I0523 05:52:30.646009 34819 sgd_solver.cpp:112] Iteration 58030, lr = 0.01
I0523 05:52:34.596945 34819 solver.cpp:239] Iteration 58040 (2.09948 iter/s, 4.76308s/10 iters), loss = 8.33914
I0523 05:52:34.596999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33914 (* 1 = 8.33914 loss)
I0523 05:52:34.662772 34819 sgd_solver.cpp:112] Iteration 58040, lr = 0.01
I0523 05:52:38.961078 34819 solver.cpp:239] Iteration 58050 (2.29153 iter/s, 4.3639s/10 iters), loss = 8.51177
I0523 05:52:38.961132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51177 (* 1 = 8.51177 loss)
I0523 05:52:39.043241 34819 sgd_solver.cpp:112] Iteration 58050, lr = 0.01
I0523 05:52:42.957053 34819 solver.cpp:239] Iteration 58060 (2.50267 iter/s, 3.99574s/10 iters), loss = 8.36393
I0523 05:52:42.957108 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36393 (* 1 = 8.36393 loss)
I0523 05:52:43.779183 34819 sgd_solver.cpp:112] Iteration 58060, lr = 0.01
I0523 05:52:48.875481 34819 solver.cpp:239] Iteration 58070 (1.68973 iter/s, 5.91811s/10 iters), loss = 7.70227
I0523 05:52:48.875535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70227 (* 1 = 7.70227 loss)
I0523 05:52:48.928019 34819 sgd_solver.cpp:112] Iteration 58070, lr = 0.01
I0523 05:52:52.249570 34819 solver.cpp:239] Iteration 58080 (2.96394 iter/s, 3.37389s/10 iters), loss = 8.44321
I0523 05:52:52.249619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44321 (* 1 = 8.44321 loss)
I0523 05:52:52.309892 34819 sgd_solver.cpp:112] Iteration 58080, lr = 0.01
I0523 05:52:58.043473 34819 solver.cpp:239] Iteration 58090 (1.72604 iter/s, 5.79362s/10 iters), loss = 8.91625
I0523 05:52:58.043514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91625 (* 1 = 8.91625 loss)
I0523 05:52:58.117574 34819 sgd_solver.cpp:112] Iteration 58090, lr = 0.01
I0523 05:53:02.768829 34819 solver.cpp:239] Iteration 58100 (2.11636 iter/s, 4.7251s/10 iters), loss = 7.99233
I0523 05:53:02.769098 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99233 (* 1 = 7.99233 loss)
I0523 05:53:02.845158 34819 sgd_solver.cpp:112] Iteration 58100, lr = 0.01
I0523 05:53:09.730995 34819 solver.cpp:239] Iteration 58110 (1.43644 iter/s, 6.96164s/10 iters), loss = 8.73994
I0523 05:53:09.731053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73994 (* 1 = 8.73994 loss)
I0523 05:53:09.812633 34819 sgd_solver.cpp:112] Iteration 58110, lr = 0.01
I0523 05:53:13.401618 34819 solver.cpp:239] Iteration 58120 (2.7245 iter/s, 3.6704s/10 iters), loss = 8.17933
I0523 05:53:13.401686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17933 (* 1 = 8.17933 loss)
I0523 05:53:14.225539 34819 sgd_solver.cpp:112] Iteration 58120, lr = 0.01
I0523 05:53:18.457742 34819 solver.cpp:239] Iteration 58130 (1.97791 iter/s, 5.05584s/10 iters), loss = 9.12109
I0523 05:53:18.457808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.12109 (* 1 = 9.12109 loss)
I0523 05:53:19.292956 34819 sgd_solver.cpp:112] Iteration 58130, lr = 0.01
I0523 05:53:24.889017 34819 solver.cpp:239] Iteration 58140 (1.55498 iter/s, 6.43094s/10 iters), loss = 7.78227
I0523 05:53:24.889068 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78227 (* 1 = 7.78227 loss)
I0523 05:53:24.957789 34819 sgd_solver.cpp:112] Iteration 58140, lr = 0.01
I0523 05:53:28.975931 34819 solver.cpp:239] Iteration 58150 (2.44697 iter/s, 4.08669s/10 iters), loss = 8.77358
I0523 05:53:28.975984 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77358 (* 1 = 8.77358 loss)
I0523 05:53:29.037406 34819 sgd_solver.cpp:112] Iteration 58150, lr = 0.01
I0523 05:53:32.477685 34819 solver.cpp:239] Iteration 58160 (2.85588 iter/s, 3.50155s/10 iters), loss = 8.5767
I0523 05:53:32.477731 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5767 (* 1 = 8.5767 loss)
I0523 05:53:33.292639 34819 sgd_solver.cpp:112] Iteration 58160, lr = 0.01
I0523 05:53:38.033109 34819 solver.cpp:239] Iteration 58170 (1.80014 iter/s, 5.55514s/10 iters), loss = 8.20293
I0523 05:53:38.033176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20293 (* 1 = 8.20293 loss)
I0523 05:53:38.851367 34819 sgd_solver.cpp:112] Iteration 58170, lr = 0.01
I0523 05:53:44.513099 34819 solver.cpp:239] Iteration 58180 (1.54329 iter/s, 6.47965s/10 iters), loss = 7.57148
I0523 05:53:44.513152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57148 (* 1 = 7.57148 loss)
I0523 05:53:44.578008 34819 sgd_solver.cpp:112] Iteration 58180, lr = 0.01
I0523 05:53:49.141278 34819 solver.cpp:239] Iteration 58190 (2.16079 iter/s, 4.62793s/10 iters), loss = 8.24176
I0523 05:53:49.141327 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24176 (* 1 = 8.24176 loss)
I0523 05:53:49.205812 34819 sgd_solver.cpp:112] Iteration 58190, lr = 0.01
I0523 05:53:53.277935 34819 solver.cpp:239] Iteration 58200 (2.41754 iter/s, 4.13643s/10 iters), loss = 8.80543
I0523 05:53:53.277992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80543 (* 1 = 8.80543 loss)
I0523 05:53:53.342942 34819 sgd_solver.cpp:112] Iteration 58200, lr = 0.01
I0523 05:53:59.166759 34819 solver.cpp:239] Iteration 58210 (1.69822 iter/s, 5.88853s/10 iters), loss = 9.22237
I0523 05:53:59.166815 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22237 (* 1 = 9.22237 loss)
I0523 05:53:59.232498 34819 sgd_solver.cpp:112] Iteration 58210, lr = 0.01
I0523 05:54:03.235852 34819 solver.cpp:239] Iteration 58220 (2.45769 iter/s, 4.06886s/10 iters), loss = 8.76343
I0523 05:54:03.235898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76343 (* 1 = 8.76343 loss)
I0523 05:54:04.078284 34819 sgd_solver.cpp:112] Iteration 58220, lr = 0.01
I0523 05:54:07.767091 34819 solver.cpp:239] Iteration 58230 (2.20702 iter/s, 4.531s/10 iters), loss = 7.90171
I0523 05:54:07.767134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90171 (* 1 = 7.90171 loss)
I0523 05:54:07.825597 34819 sgd_solver.cpp:112] Iteration 58230, lr = 0.01
I0523 05:54:13.150799 34819 solver.cpp:239] Iteration 58240 (1.85755 iter/s, 5.38344s/10 iters), loss = 8.77424
I0523 05:54:13.150853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77424 (* 1 = 8.77424 loss)
I0523 05:54:13.947513 34819 sgd_solver.cpp:112] Iteration 58240, lr = 0.01
I0523 05:54:18.050730 34819 solver.cpp:239] Iteration 58250 (2.04097 iter/s, 4.89963s/10 iters), loss = 8.57216
I0523 05:54:18.050789 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57216 (* 1 = 8.57216 loss)
I0523 05:54:18.876313 34819 sgd_solver.cpp:112] Iteration 58250, lr = 0.01
I0523 05:54:23.002969 34819 solver.cpp:239] Iteration 58260 (2.0194 iter/s, 4.95197s/10 iters), loss = 8.90227
I0523 05:54:23.003024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90227 (* 1 = 8.90227 loss)
I0523 05:54:23.141279 34819 sgd_solver.cpp:112] Iteration 58260, lr = 0.01
I0523 05:54:27.486088 34819 solver.cpp:239] Iteration 58270 (2.23071 iter/s, 4.48288s/10 iters), loss = 8.57471
I0523 05:54:27.486130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57471 (* 1 = 8.57471 loss)
I0523 05:54:28.320413 34819 sgd_solver.cpp:112] Iteration 58270, lr = 0.01
I0523 05:54:33.286183 34819 solver.cpp:239] Iteration 58280 (1.7242 iter/s, 5.7998s/10 iters), loss = 8.36574
I0523 05:54:33.286244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36574 (* 1 = 8.36574 loss)
I0523 05:54:34.135787 34819 sgd_solver.cpp:112] Iteration 58280, lr = 0.01
I0523 05:54:39.043524 34819 solver.cpp:239] Iteration 58290 (1.737 iter/s, 5.75704s/10 iters), loss = 7.25707
I0523 05:54:39.043575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.25707 (* 1 = 7.25707 loss)
I0523 05:54:39.117219 34819 sgd_solver.cpp:112] Iteration 58290, lr = 0.01
I0523 05:54:43.218660 34819 solver.cpp:239] Iteration 58300 (2.39526 iter/s, 4.17491s/10 iters), loss = 8.01938
I0523 05:54:43.218727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01938 (* 1 = 8.01938 loss)
I0523 05:54:44.064393 34819 sgd_solver.cpp:112] Iteration 58300, lr = 0.01
I0523 05:54:47.304006 34819 solver.cpp:239] Iteration 58310 (2.44792 iter/s, 4.0851s/10 iters), loss = 8.86053
I0523 05:54:47.304060 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86053 (* 1 = 8.86053 loss)
I0523 05:54:47.867312 34819 sgd_solver.cpp:112] Iteration 58310, lr = 0.01
I0523 05:54:51.459453 34819 solver.cpp:239] Iteration 58320 (2.40662 iter/s, 4.1552s/10 iters), loss = 9.16949
I0523 05:54:51.459511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16949 (* 1 = 9.16949 loss)
I0523 05:54:51.514564 34819 sgd_solver.cpp:112] Iteration 58320, lr = 0.01
I0523 05:54:54.633615 34819 solver.cpp:239] Iteration 58330 (3.15063 iter/s, 3.17397s/10 iters), loss = 8.57994
I0523 05:54:54.633658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57994 (* 1 = 8.57994 loss)
I0523 05:54:54.754065 34819 sgd_solver.cpp:112] Iteration 58330, lr = 0.01
I0523 05:54:58.065614 34819 solver.cpp:239] Iteration 58340 (2.91394 iter/s, 3.43178s/10 iters), loss = 7.90556
I0523 05:54:58.065655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90556 (* 1 = 7.90556 loss)
I0523 05:54:58.903000 34819 sgd_solver.cpp:112] Iteration 58340, lr = 0.01
I0523 05:55:03.300411 34819 solver.cpp:239] Iteration 58350 (1.9104 iter/s, 5.2345s/10 iters), loss = 8.24343
I0523 05:55:03.300451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24343 (* 1 = 8.24343 loss)
I0523 05:55:04.140017 34819 sgd_solver.cpp:112] Iteration 58350, lr = 0.01
I0523 05:55:07.481798 34819 solver.cpp:239] Iteration 58360 (2.39168 iter/s, 4.18115s/10 iters), loss = 8.55074
I0523 05:55:07.481868 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55074 (* 1 = 8.55074 loss)
I0523 05:55:08.348222 34819 sgd_solver.cpp:112] Iteration 58360, lr = 0.01
I0523 05:55:14.059209 34819 solver.cpp:239] Iteration 58370 (1.52043 iter/s, 6.57708s/10 iters), loss = 8.5063
I0523 05:55:14.059252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5063 (* 1 = 8.5063 loss)
I0523 05:55:14.876412 34819 sgd_solver.cpp:112] Iteration 58370, lr = 0.01
I0523 05:55:19.757959 34819 solver.cpp:239] Iteration 58380 (1.75486 iter/s, 5.69846s/10 iters), loss = 8.85438
I0523 05:55:19.758013 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85438 (* 1 = 8.85438 loss)
I0523 05:55:20.269178 34819 sgd_solver.cpp:112] Iteration 58380, lr = 0.01
I0523 05:55:24.712352 34819 solver.cpp:239] Iteration 58390 (2.01852 iter/s, 4.95412s/10 iters), loss = 7.96813
I0523 05:55:24.712399 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96813 (* 1 = 7.96813 loss)
I0523 05:55:24.785281 34819 sgd_solver.cpp:112] Iteration 58390, lr = 0.01
I0523 05:55:31.161128 34819 solver.cpp:239] Iteration 58400 (1.55076 iter/s, 6.44846s/10 iters), loss = 8.61515
I0523 05:55:31.161170 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61515 (* 1 = 8.61515 loss)
I0523 05:55:31.218318 34819 sgd_solver.cpp:112] Iteration 58400, lr = 0.01
I0523 05:55:35.957911 34819 solver.cpp:239] Iteration 58410 (2.08484 iter/s, 4.79654s/10 iters), loss = 7.85319
I0523 05:55:35.958053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85319 (* 1 = 7.85319 loss)
I0523 05:55:36.020406 34819 sgd_solver.cpp:112] Iteration 58410, lr = 0.01
I0523 05:55:42.224205 34819 solver.cpp:239] Iteration 58420 (1.59594 iter/s, 6.26589s/10 iters), loss = 8.16115
I0523 05:55:42.224258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16115 (* 1 = 8.16115 loss)
I0523 05:55:42.308712 34819 sgd_solver.cpp:112] Iteration 58420, lr = 0.01
I0523 05:55:46.177500 34819 solver.cpp:239] Iteration 58430 (2.52968 iter/s, 3.95307s/10 iters), loss = 8.74287
I0523 05:55:46.177541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74287 (* 1 = 8.74287 loss)
I0523 05:55:46.254508 34819 sgd_solver.cpp:112] Iteration 58430, lr = 0.01
I0523 05:55:51.581501 34819 solver.cpp:239] Iteration 58440 (1.85058 iter/s, 5.40372s/10 iters), loss = 8.52188
I0523 05:55:51.581557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52188 (* 1 = 8.52188 loss)
I0523 05:55:51.662236 34819 sgd_solver.cpp:112] Iteration 58440, lr = 0.01
I0523 05:55:58.305611 34819 solver.cpp:239] Iteration 58450 (1.48726 iter/s, 6.72378s/10 iters), loss = 7.57076
I0523 05:55:58.305661 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57076 (* 1 = 7.57076 loss)
I0523 05:55:59.008754 34819 sgd_solver.cpp:112] Iteration 58450, lr = 0.01
I0523 05:56:02.388566 34819 solver.cpp:239] Iteration 58460 (2.44934 iter/s, 4.08274s/10 iters), loss = 8.73877
I0523 05:56:02.388608 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73877 (* 1 = 8.73877 loss)
I0523 05:56:03.025774 34819 sgd_solver.cpp:112] Iteration 58460, lr = 0.01
I0523 05:56:05.573729 34819 solver.cpp:239] Iteration 58470 (3.13975 iter/s, 3.18497s/10 iters), loss = 8.50074
I0523 05:56:05.573781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50074 (* 1 = 8.50074 loss)
I0523 05:56:06.395170 34819 sgd_solver.cpp:112] Iteration 58470, lr = 0.01
I0523 05:56:08.931303 34819 solver.cpp:239] Iteration 58480 (2.97852 iter/s, 3.35738s/10 iters), loss = 7.93461
I0523 05:56:08.931349 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93461 (* 1 = 7.93461 loss)
I0523 05:56:08.993763 34819 sgd_solver.cpp:112] Iteration 58480, lr = 0.01
I0523 05:56:12.871709 34819 solver.cpp:239] Iteration 58490 (2.53795 iter/s, 3.94019s/10 iters), loss = 8.68006
I0523 05:56:12.871767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68006 (* 1 = 8.68006 loss)
I0523 05:56:13.149200 34819 sgd_solver.cpp:112] Iteration 58490, lr = 0.01
I0523 05:56:18.070669 34819 solver.cpp:239] Iteration 58500 (1.92356 iter/s, 5.19869s/10 iters), loss = 7.6177
I0523 05:56:18.070736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6177 (* 1 = 7.6177 loss)
I0523 05:56:18.831089 34819 sgd_solver.cpp:112] Iteration 58500, lr = 0.01
I0523 05:56:21.320336 34819 solver.cpp:239] Iteration 58510 (3.07746 iter/s, 3.24944s/10 iters), loss = 8.7318
I0523 05:56:21.320397 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7318 (* 1 = 8.7318 loss)
I0523 05:56:21.363369 34819 sgd_solver.cpp:112] Iteration 58510, lr = 0.01
I0523 05:56:23.466506 34819 solver.cpp:239] Iteration 58520 (4.65981 iter/s, 2.14601s/10 iters), loss = 8.18111
I0523 05:56:23.466552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18111 (* 1 = 8.18111 loss)
I0523 05:56:23.534184 34819 sgd_solver.cpp:112] Iteration 58520, lr = 0.01
I0523 05:56:30.685231 34819 solver.cpp:239] Iteration 58530 (1.38535 iter/s, 7.21837s/10 iters), loss = 7.77235
I0523 05:56:30.685283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77235 (* 1 = 7.77235 loss)
I0523 05:56:31.543102 34819 sgd_solver.cpp:112] Iteration 58530, lr = 0.01
I0523 05:56:35.436635 34819 solver.cpp:239] Iteration 58540 (2.10475 iter/s, 4.75115s/10 iters), loss = 8.89513
I0523 05:56:35.436677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89513 (* 1 = 8.89513 loss)
I0523 05:56:36.211644 34819 sgd_solver.cpp:112] Iteration 58540, lr = 0.01
I0523 05:56:41.168905 34819 solver.cpp:239] Iteration 58550 (1.74459 iter/s, 5.73199s/10 iters), loss = 7.2037
I0523 05:56:41.169039 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2037 (* 1 = 7.2037 loss)
I0523 05:56:41.237185 34819 sgd_solver.cpp:112] Iteration 58550, lr = 0.01
I0523 05:56:45.900166 34819 solver.cpp:239] Iteration 58560 (2.11539 iter/s, 4.72726s/10 iters), loss = 8.29265
I0523 05:56:45.900220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29265 (* 1 = 8.29265 loss)
I0523 05:56:45.975878 34819 sgd_solver.cpp:112] Iteration 58560, lr = 0.01
I0523 05:56:48.434201 34819 solver.cpp:239] Iteration 58570 (3.94653 iter/s, 2.53387s/10 iters), loss = 8.23422
I0523 05:56:48.434247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23422 (* 1 = 8.23422 loss)
I0523 05:56:48.495571 34819 sgd_solver.cpp:112] Iteration 58570, lr = 0.01
I0523 05:56:54.148380 34819 solver.cpp:239] Iteration 58580 (1.75012 iter/s, 5.71389s/10 iters), loss = 8.81531
I0523 05:56:54.148430 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81531 (* 1 = 8.81531 loss)
I0523 05:56:54.220365 34819 sgd_solver.cpp:112] Iteration 58580, lr = 0.01
I0523 05:56:58.569787 34819 solver.cpp:239] Iteration 58590 (2.26185 iter/s, 4.42116s/10 iters), loss = 9.25844
I0523 05:56:58.569851 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.25844 (* 1 = 9.25844 loss)
I0523 05:56:59.446439 34819 sgd_solver.cpp:112] Iteration 58590, lr = 0.01
I0523 05:57:01.755210 34819 solver.cpp:239] Iteration 58600 (3.13952 iter/s, 3.1852s/10 iters), loss = 9.3521
I0523 05:57:01.755270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3521 (* 1 = 9.3521 loss)
I0523 05:57:01.813524 34819 sgd_solver.cpp:112] Iteration 58600, lr = 0.01
I0523 05:57:05.483434 34819 solver.cpp:239] Iteration 58610 (2.6824 iter/s, 3.72801s/10 iters), loss = 9.15195
I0523 05:57:05.483491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15195 (* 1 = 9.15195 loss)
I0523 05:57:05.559820 34819 sgd_solver.cpp:112] Iteration 58610, lr = 0.01
I0523 05:57:08.514179 34819 solver.cpp:239] Iteration 58620 (3.29972 iter/s, 3.03056s/10 iters), loss = 7.74095
I0523 05:57:08.514219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74095 (* 1 = 7.74095 loss)
I0523 05:57:09.332619 34819 sgd_solver.cpp:112] Iteration 58620, lr = 0.01
I0523 05:57:11.929311 34819 solver.cpp:239] Iteration 58630 (2.92831 iter/s, 3.41493s/10 iters), loss = 8.39514
I0523 05:57:11.929494 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39514 (* 1 = 8.39514 loss)
I0523 05:57:11.985371 34819 sgd_solver.cpp:112] Iteration 58630, lr = 0.01
I0523 05:57:14.771692 34819 solver.cpp:239] Iteration 58640 (3.51856 iter/s, 2.84207s/10 iters), loss = 8.66496
I0523 05:57:14.771744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66496 (* 1 = 8.66496 loss)
I0523 05:57:15.625707 34819 sgd_solver.cpp:112] Iteration 58640, lr = 0.01
I0523 05:57:20.738309 34819 solver.cpp:239] Iteration 58650 (1.67608 iter/s, 5.96632s/10 iters), loss = 7.96641
I0523 05:57:20.738363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96641 (* 1 = 7.96641 loss)
I0523 05:57:21.298228 34819 sgd_solver.cpp:112] Iteration 58650, lr = 0.01
I0523 05:57:25.002091 34819 solver.cpp:239] Iteration 58660 (2.34547 iter/s, 4.26353s/10 iters), loss = 8.76176
I0523 05:57:25.002147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76176 (* 1 = 8.76176 loss)
I0523 05:57:25.753993 34819 sgd_solver.cpp:112] Iteration 58660, lr = 0.01
I0523 05:57:30.397657 34819 solver.cpp:239] Iteration 58670 (1.85347 iter/s, 5.39529s/10 iters), loss = 9.14275
I0523 05:57:30.397697 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.14275 (* 1 = 9.14275 loss)
I0523 05:57:31.234163 34819 sgd_solver.cpp:112] Iteration 58670, lr = 0.01
I0523 05:57:36.602489 34819 solver.cpp:239] Iteration 58680 (1.61173 iter/s, 6.20453s/10 iters), loss = 8.23831
I0523 05:57:36.602555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23831 (* 1 = 8.23831 loss)
I0523 05:57:36.671133 34819 sgd_solver.cpp:112] Iteration 58680, lr = 0.01
I0523 05:57:41.606875 34819 solver.cpp:239] Iteration 58690 (1.99836 iter/s, 5.00411s/10 iters), loss = 7.74047
I0523 05:57:41.606943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74047 (* 1 = 7.74047 loss)
I0523 05:57:41.840174 34819 sgd_solver.cpp:112] Iteration 58690, lr = 0.01
I0523 05:57:47.685570 34819 solver.cpp:239] Iteration 58700 (1.64518 iter/s, 6.07837s/10 iters), loss = 7.86888
I0523 05:57:47.685786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86888 (* 1 = 7.86888 loss)
I0523 05:57:47.758818 34819 sgd_solver.cpp:112] Iteration 58700, lr = 0.01
I0523 05:57:54.717434 34819 solver.cpp:239] Iteration 58710 (1.42219 iter/s, 7.03139s/10 iters), loss = 7.82772
I0523 05:57:54.717486 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82772 (* 1 = 7.82772 loss)
I0523 05:57:55.286774 34819 sgd_solver.cpp:112] Iteration 58710, lr = 0.01
I0523 05:58:00.555294 34819 solver.cpp:239] Iteration 58720 (1.71305 iter/s, 5.83754s/10 iters), loss = 8.92383
I0523 05:58:00.555352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92383 (* 1 = 8.92383 loss)
I0523 05:58:01.351032 34819 sgd_solver.cpp:112] Iteration 58720, lr = 0.01
I0523 05:58:06.057818 34819 solver.cpp:239] Iteration 58730 (1.81745 iter/s, 5.50222s/10 iters), loss = 8.40836
I0523 05:58:06.057893 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40836 (* 1 = 8.40836 loss)
I0523 05:58:06.839509 34819 sgd_solver.cpp:112] Iteration 58730, lr = 0.01
I0523 05:58:11.713279 34819 solver.cpp:239] Iteration 58740 (1.7683 iter/s, 5.65515s/10 iters), loss = 8.49547
I0523 05:58:11.713322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49547 (* 1 = 8.49547 loss)
I0523 05:58:12.592181 34819 sgd_solver.cpp:112] Iteration 58740, lr = 0.01
I0523 05:58:15.977691 34819 solver.cpp:239] Iteration 58750 (2.34511 iter/s, 4.26418s/10 iters), loss = 8.3189
I0523 05:58:15.977741 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3189 (* 1 = 8.3189 loss)
I0523 05:58:16.792982 34819 sgd_solver.cpp:112] Iteration 58750, lr = 0.01
I0523 05:58:20.464467 34819 solver.cpp:239] Iteration 58760 (2.22889 iter/s, 4.48654s/10 iters), loss = 8.83382
I0523 05:58:20.464648 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83382 (* 1 = 8.83382 loss)
I0523 05:58:20.524565 34819 sgd_solver.cpp:112] Iteration 58760, lr = 0.01
I0523 05:58:25.519026 34819 solver.cpp:239] Iteration 58770 (1.97856 iter/s, 5.05418s/10 iters), loss = 8.13489
I0523 05:58:25.519067 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13489 (* 1 = 8.13489 loss)
I0523 05:58:26.381446 34819 sgd_solver.cpp:112] Iteration 58770, lr = 0.01
I0523 05:58:30.354846 34819 solver.cpp:239] Iteration 58780 (2.06802 iter/s, 4.83554s/10 iters), loss = 8.76572
I0523 05:58:30.354895 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76572 (* 1 = 8.76572 loss)
I0523 05:58:31.104751 34819 sgd_solver.cpp:112] Iteration 58780, lr = 0.01
I0523 05:58:35.282841 34819 solver.cpp:239] Iteration 58790 (2.02934 iter/s, 4.92772s/10 iters), loss = 8.73649
I0523 05:58:35.282892 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73649 (* 1 = 8.73649 loss)
I0523 05:58:36.085448 34819 sgd_solver.cpp:112] Iteration 58790, lr = 0.01
I0523 05:58:41.011579 34819 solver.cpp:239] Iteration 58800 (1.74567 iter/s, 5.72845s/10 iters), loss = 8.68846
I0523 05:58:41.011634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68846 (* 1 = 8.68846 loss)
I0523 05:58:41.073922 34819 sgd_solver.cpp:112] Iteration 58800, lr = 0.01
I0523 05:58:44.451586 34819 solver.cpp:239] Iteration 58810 (2.90714 iter/s, 3.43981s/10 iters), loss = 8.53182
I0523 05:58:44.451642 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53182 (* 1 = 8.53182 loss)
I0523 05:58:45.275343 34819 sgd_solver.cpp:112] Iteration 58810, lr = 0.01
I0523 05:58:51.503906 34819 solver.cpp:239] Iteration 58820 (1.41805 iter/s, 7.05196s/10 iters), loss = 8.21369
I0523 05:58:51.504164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21369 (* 1 = 8.21369 loss)
I0523 05:58:52.359927 34819 sgd_solver.cpp:112] Iteration 58820, lr = 0.01
I0523 05:58:55.609887 34819 solver.cpp:239] Iteration 58830 (2.4357 iter/s, 4.10559s/10 iters), loss = 8.11743
I0523 05:58:55.609930 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11743 (* 1 = 8.11743 loss)
I0523 05:58:55.874557 34819 sgd_solver.cpp:112] Iteration 58830, lr = 0.01
I0523 05:59:01.446822 34819 solver.cpp:239] Iteration 58840 (1.71331 iter/s, 5.83665s/10 iters), loss = 9.71194
I0523 05:59:01.446866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.71194 (* 1 = 9.71194 loss)
I0523 05:59:01.510721 34819 sgd_solver.cpp:112] Iteration 58840, lr = 0.01
I0523 05:59:04.976238 34819 solver.cpp:239] Iteration 58850 (2.8335 iter/s, 3.5292s/10 iters), loss = 8.32362
I0523 05:59:04.976302 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32362 (* 1 = 8.32362 loss)
I0523 05:59:05.791294 34819 sgd_solver.cpp:112] Iteration 58850, lr = 0.01
I0523 05:59:11.528818 34819 solver.cpp:239] Iteration 58860 (1.5262 iter/s, 6.55224s/10 iters), loss = 8.46283
I0523 05:59:11.528873 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46283 (* 1 = 8.46283 loss)
I0523 05:59:11.596398 34819 sgd_solver.cpp:112] Iteration 58860, lr = 0.01
I0523 05:59:17.506371 34819 solver.cpp:239] Iteration 58870 (1.67301 iter/s, 5.97725s/10 iters), loss = 9.10777
I0523 05:59:17.506410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10777 (* 1 = 9.10777 loss)
I0523 05:59:18.301004 34819 sgd_solver.cpp:112] Iteration 58870, lr = 0.01
I0523 05:59:23.202667 34819 solver.cpp:239] Iteration 58880 (1.75562 iter/s, 5.696s/10 iters), loss = 8.2038
I0523 05:59:23.202878 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2038 (* 1 = 8.2038 loss)
I0523 05:59:23.991268 34819 sgd_solver.cpp:112] Iteration 58880, lr = 0.01
I0523 05:59:29.020233 34819 solver.cpp:239] Iteration 58890 (1.71907 iter/s, 5.81711s/10 iters), loss = 9.04115
I0523 05:59:29.020275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04115 (* 1 = 9.04115 loss)
I0523 05:59:29.093684 34819 sgd_solver.cpp:112] Iteration 58890, lr = 0.01
I0523 05:59:35.438972 34819 solver.cpp:239] Iteration 58900 (1.55801 iter/s, 6.41843s/10 iters), loss = 7.68245
I0523 05:59:35.439028 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68245 (* 1 = 7.68245 loss)
I0523 05:59:36.278374 34819 sgd_solver.cpp:112] Iteration 58900, lr = 0.01
I0523 05:59:41.884284 34819 solver.cpp:239] Iteration 58910 (1.55159 iter/s, 6.44499s/10 iters), loss = 8.07075
I0523 05:59:41.884325 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07075 (* 1 = 8.07075 loss)
I0523 05:59:42.519675 34819 sgd_solver.cpp:112] Iteration 58910, lr = 0.01
I0523 05:59:45.875847 34819 solver.cpp:239] Iteration 58920 (2.50542 iter/s, 3.99134s/10 iters), loss = 8.43779
I0523 05:59:45.875905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43779 (* 1 = 8.43779 loss)
I0523 05:59:46.571951 34819 sgd_solver.cpp:112] Iteration 58920, lr = 0.01
I0523 05:59:52.733793 34819 solver.cpp:239] Iteration 58930 (1.45824 iter/s, 6.85759s/10 iters), loss = 9.52526
I0523 05:59:52.733844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52526 (* 1 = 9.52526 loss)
I0523 05:59:53.239751 34819 sgd_solver.cpp:112] Iteration 58930, lr = 0.01
I0523 05:59:57.780194 34819 solver.cpp:239] Iteration 58940 (1.98171 iter/s, 5.04614s/10 iters), loss = 7.99102
I0523 05:59:57.780252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99102 (* 1 = 7.99102 loss)
I0523 05:59:57.923995 34819 sgd_solver.cpp:112] Iteration 58940, lr = 0.01
I0523 06:00:03.684546 34819 solver.cpp:239] Iteration 58950 (1.69376 iter/s, 5.90404s/10 iters), loss = 8.48574
I0523 06:00:03.684605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48574 (* 1 = 8.48574 loss)
I0523 06:00:04.399598 34819 sgd_solver.cpp:112] Iteration 58950, lr = 0.01
I0523 06:00:08.766826 34819 solver.cpp:239] Iteration 58960 (1.96773 iter/s, 5.08201s/10 iters), loss = 8.74156
I0523 06:00:08.766870 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74156 (* 1 = 8.74156 loss)
I0523 06:00:08.836470 34819 sgd_solver.cpp:112] Iteration 58960, lr = 0.01
I0523 06:00:14.415169 34819 solver.cpp:239] Iteration 58970 (1.77052 iter/s, 5.64806s/10 iters), loss = 7.7461
I0523 06:00:14.415215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7461 (* 1 = 7.7461 loss)
I0523 06:00:15.160596 34819 sgd_solver.cpp:112] Iteration 58970, lr = 0.01
I0523 06:00:19.635426 34819 solver.cpp:239] Iteration 58980 (1.91571 iter/s, 5.22s/10 iters), loss = 8.45253
I0523 06:00:19.635468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45253 (* 1 = 8.45253 loss)
I0523 06:00:19.702266 34819 sgd_solver.cpp:112] Iteration 58980, lr = 0.01
I0523 06:00:25.961982 34819 solver.cpp:239] Iteration 58990 (1.58071 iter/s, 6.32626s/10 iters), loss = 8.28811
I0523 06:00:25.962175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28811 (* 1 = 8.28811 loss)
I0523 06:00:26.036109 34819 sgd_solver.cpp:112] Iteration 58990, lr = 0.01
I0523 06:00:30.762730 34819 solver.cpp:239] Iteration 59000 (2.08317 iter/s, 4.80038s/10 iters), loss = 9.40682
I0523 06:00:30.762774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.40682 (* 1 = 9.40682 loss)
I0523 06:00:30.834746 34819 sgd_solver.cpp:112] Iteration 59000, lr = 0.01
I0523 06:00:34.083631 34819 solver.cpp:239] Iteration 59010 (3.01141 iter/s, 3.32071s/10 iters), loss = 8.15191
I0523 06:00:34.083690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15191 (* 1 = 8.15191 loss)
I0523 06:00:34.912384 34819 sgd_solver.cpp:112] Iteration 59010, lr = 0.01
I0523 06:00:38.945987 34819 solver.cpp:239] Iteration 59020 (2.05673 iter/s, 4.8621s/10 iters), loss = 8.49815
I0523 06:00:38.946038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49815 (* 1 = 8.49815 loss)
I0523 06:00:39.015241 34819 sgd_solver.cpp:112] Iteration 59020, lr = 0.01
I0523 06:00:42.092965 34819 solver.cpp:239] Iteration 59030 (3.17784 iter/s, 3.14679s/10 iters), loss = 8.43839
I0523 06:00:42.093008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43839 (* 1 = 8.43839 loss)
I0523 06:00:42.913718 34819 sgd_solver.cpp:112] Iteration 59030, lr = 0.01
I0523 06:00:46.293251 34819 solver.cpp:239] Iteration 59040 (2.38092 iter/s, 4.20005s/10 iters), loss = 8.94467
I0523 06:00:46.293310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94467 (* 1 = 8.94467 loss)
I0523 06:00:46.876260 34819 sgd_solver.cpp:112] Iteration 59040, lr = 0.01
I0523 06:00:51.066637 34819 solver.cpp:239] Iteration 59050 (2.09507 iter/s, 4.77312s/10 iters), loss = 8.09415
I0523 06:00:51.066689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09415 (* 1 = 8.09415 loss)
I0523 06:00:51.130359 34819 sgd_solver.cpp:112] Iteration 59050, lr = 0.01
I0523 06:00:55.015684 34819 solver.cpp:239] Iteration 59060 (2.5324 iter/s, 3.94882s/10 iters), loss = 8.32328
I0523 06:00:55.015733 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32328 (* 1 = 8.32328 loss)
I0523 06:00:55.787539 34819 sgd_solver.cpp:112] Iteration 59060, lr = 0.01
I0523 06:01:00.390354 34819 solver.cpp:239] Iteration 59070 (1.86068 iter/s, 5.37438s/10 iters), loss = 9.63243
I0523 06:01:00.390508 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.63243 (* 1 = 9.63243 loss)
I0523 06:01:01.265800 34819 sgd_solver.cpp:112] Iteration 59070, lr = 0.01
I0523 06:01:06.476966 34819 solver.cpp:239] Iteration 59080 (1.64306 iter/s, 6.08621s/10 iters), loss = 8.26856
I0523 06:01:06.477021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26856 (* 1 = 8.26856 loss)
I0523 06:01:06.559959 34819 sgd_solver.cpp:112] Iteration 59080, lr = 0.01
I0523 06:01:10.643821 34819 solver.cpp:239] Iteration 59090 (2.40003 iter/s, 4.16662s/10 iters), loss = 8.66193
I0523 06:01:10.643877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66193 (* 1 = 8.66193 loss)
I0523 06:01:10.712656 34819 sgd_solver.cpp:112] Iteration 59090, lr = 0.01
I0523 06:01:14.073741 34819 solver.cpp:239] Iteration 59100 (2.91569 iter/s, 3.42972s/10 iters), loss = 8.6494
I0523 06:01:14.073788 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6494 (* 1 = 8.6494 loss)
I0523 06:01:14.836539 34819 sgd_solver.cpp:112] Iteration 59100, lr = 0.01
I0523 06:01:19.654104 34819 solver.cpp:239] Iteration 59110 (1.79209 iter/s, 5.58007s/10 iters), loss = 9.16098
I0523 06:01:19.654155 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16098 (* 1 = 9.16098 loss)
I0523 06:01:19.723223 34819 sgd_solver.cpp:112] Iteration 59110, lr = 0.01
I0523 06:01:24.558706 34819 solver.cpp:239] Iteration 59120 (2.03902 iter/s, 4.90433s/10 iters), loss = 7.55397
I0523 06:01:24.558751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55397 (* 1 = 7.55397 loss)
I0523 06:01:24.634307 34819 sgd_solver.cpp:112] Iteration 59120, lr = 0.01
I0523 06:01:29.018689 34819 solver.cpp:239] Iteration 59130 (2.24228 iter/s, 4.45975s/10 iters), loss = 8.54375
I0523 06:01:29.018741 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54375 (* 1 = 8.54375 loss)
I0523 06:01:29.077183 34819 sgd_solver.cpp:112] Iteration 59130, lr = 0.01
I0523 06:01:33.365491 34819 solver.cpp:239] Iteration 59140 (2.30068 iter/s, 4.34653s/10 iters), loss = 8.60839
I0523 06:01:33.365725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60839 (* 1 = 8.60839 loss)
I0523 06:01:34.072805 34819 sgd_solver.cpp:112] Iteration 59140, lr = 0.01
I0523 06:01:39.671072 34819 solver.cpp:239] Iteration 59150 (1.58602 iter/s, 6.3051s/10 iters), loss = 8.57912
I0523 06:01:39.671129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57912 (* 1 = 8.57912 loss)
I0523 06:01:39.813374 34819 sgd_solver.cpp:112] Iteration 59150, lr = 0.01
I0523 06:01:43.581776 34819 solver.cpp:239] Iteration 59160 (2.55723 iter/s, 3.91048s/10 iters), loss = 8.23825
I0523 06:01:43.581817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23825 (* 1 = 8.23825 loss)
I0523 06:01:44.437175 34819 sgd_solver.cpp:112] Iteration 59160, lr = 0.01
I0523 06:01:49.627027 34819 solver.cpp:239] Iteration 59170 (1.65427 iter/s, 6.04495s/10 iters), loss = 8.23706
I0523 06:01:49.627091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23706 (* 1 = 8.23706 loss)
I0523 06:01:50.430259 34819 sgd_solver.cpp:112] Iteration 59170, lr = 0.01
I0523 06:01:54.434442 34819 solver.cpp:239] Iteration 59180 (2.08025 iter/s, 4.80712s/10 iters), loss = 7.30519
I0523 06:01:54.434491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.30519 (* 1 = 7.30519 loss)
I0523 06:01:55.171483 34819 sgd_solver.cpp:112] Iteration 59180, lr = 0.01
I0523 06:02:01.648281 34819 solver.cpp:239] Iteration 59190 (1.38629 iter/s, 7.21349s/10 iters), loss = 8.32517
I0523 06:02:01.648324 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32517 (* 1 = 8.32517 loss)
I0523 06:02:01.723119 34819 sgd_solver.cpp:112] Iteration 59190, lr = 0.01
I0523 06:02:05.901140 34819 solver.cpp:239] Iteration 59200 (2.35149 iter/s, 4.25263s/10 iters), loss = 8.6708
I0523 06:02:05.901365 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6708 (* 1 = 8.6708 loss)
I0523 06:02:05.971349 34819 sgd_solver.cpp:112] Iteration 59200, lr = 0.01
I0523 06:02:11.068168 34819 solver.cpp:239] Iteration 59210 (1.93553 iter/s, 5.16655s/10 iters), loss = 8.39324
I0523 06:02:11.068218 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39324 (* 1 = 8.39324 loss)
I0523 06:02:11.626751 34819 sgd_solver.cpp:112] Iteration 59210, lr = 0.01
I0523 06:02:15.828166 34819 solver.cpp:239] Iteration 59220 (2.10095 iter/s, 4.75975s/10 iters), loss = 8.31086
I0523 06:02:15.828205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31086 (* 1 = 8.31086 loss)
I0523 06:02:16.626230 34819 sgd_solver.cpp:112] Iteration 59220, lr = 0.01
I0523 06:02:19.196648 34819 solver.cpp:239] Iteration 59230 (2.96887 iter/s, 3.36828s/10 iters), loss = 8.21661
I0523 06:02:19.196689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21661 (* 1 = 8.21661 loss)
I0523 06:02:20.025493 34819 sgd_solver.cpp:112] Iteration 59230, lr = 0.01
I0523 06:02:23.206480 34819 solver.cpp:239] Iteration 59240 (2.49401 iter/s, 4.00961s/10 iters), loss = 9.0176
I0523 06:02:23.206519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0176 (* 1 = 9.0176 loss)
I0523 06:02:23.267248 34819 sgd_solver.cpp:112] Iteration 59240, lr = 0.01
I0523 06:02:28.907980 34819 solver.cpp:239] Iteration 59250 (1.75401 iter/s, 5.70122s/10 iters), loss = 8.40491
I0523 06:02:28.908023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40491 (* 1 = 8.40491 loss)
I0523 06:02:28.977815 34819 sgd_solver.cpp:112] Iteration 59250, lr = 0.01
I0523 06:02:32.959401 34819 solver.cpp:239] Iteration 59260 (2.46841 iter/s, 4.0512s/10 iters), loss = 8.41194
I0523 06:02:32.959444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41194 (* 1 = 8.41194 loss)
I0523 06:02:33.726239 34819 sgd_solver.cpp:112] Iteration 59260, lr = 0.01
I0523 06:02:37.939738 34819 solver.cpp:239] Iteration 59270 (2.008 iter/s, 4.98009s/10 iters), loss = 8.92584
I0523 06:02:37.939857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92584 (* 1 = 8.92584 loss)
I0523 06:02:38.738632 34819 sgd_solver.cpp:112] Iteration 59270, lr = 0.01
I0523 06:02:42.251372 34819 solver.cpp:239] Iteration 59280 (2.31947 iter/s, 4.31134s/10 iters), loss = 8.36441
I0523 06:02:42.251415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36441 (* 1 = 8.36441 loss)
I0523 06:02:42.327414 34819 sgd_solver.cpp:112] Iteration 59280, lr = 0.01
I0523 06:02:48.165825 34819 solver.cpp:239] Iteration 59290 (1.69085 iter/s, 5.91417s/10 iters), loss = 8.27218
I0523 06:02:48.165875 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27218 (* 1 = 8.27218 loss)
I0523 06:02:48.234026 34819 sgd_solver.cpp:112] Iteration 59290, lr = 0.01
I0523 06:02:54.038945 34819 solver.cpp:239] Iteration 59300 (1.70276 iter/s, 5.87281s/10 iters), loss = 8.79658
I0523 06:02:54.039003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79658 (* 1 = 8.79658 loss)
I0523 06:02:54.110296 34819 sgd_solver.cpp:112] Iteration 59300, lr = 0.01
I0523 06:02:57.305152 34819 solver.cpp:239] Iteration 59310 (3.06185 iter/s, 3.266s/10 iters), loss = 8.32539
I0523 06:02:57.305207 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32539 (* 1 = 8.32539 loss)
I0523 06:02:57.363276 34819 sgd_solver.cpp:112] Iteration 59310, lr = 0.01
I0523 06:03:03.366600 34819 solver.cpp:239] Iteration 59320 (1.64985 iter/s, 6.06114s/10 iters), loss = 8.97578
I0523 06:03:03.366642 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97578 (* 1 = 8.97578 loss)
I0523 06:03:03.437892 34819 sgd_solver.cpp:112] Iteration 59320, lr = 0.01
I0523 06:03:08.701720 34819 solver.cpp:239] Iteration 59330 (1.87446 iter/s, 5.33486s/10 iters), loss = 8.61259
I0523 06:03:08.701846 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61259 (* 1 = 8.61259 loss)
I0523 06:03:08.763700 34819 sgd_solver.cpp:112] Iteration 59330, lr = 0.01
I0523 06:03:14.459113 34819 solver.cpp:239] Iteration 59340 (1.73701 iter/s, 5.75703s/10 iters), loss = 8.47573
I0523 06:03:14.459154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47573 (* 1 = 8.47573 loss)
I0523 06:03:14.524174 34819 sgd_solver.cpp:112] Iteration 59340, lr = 0.01
I0523 06:03:21.249444 34819 solver.cpp:239] Iteration 59350 (1.47275 iter/s, 6.79001s/10 iters), loss = 8.1712
I0523 06:03:21.249485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1712 (* 1 = 8.1712 loss)
I0523 06:03:21.323621 34819 sgd_solver.cpp:112] Iteration 59350, lr = 0.01
I0523 06:03:26.900172 34819 solver.cpp:239] Iteration 59360 (1.76977 iter/s, 5.65044s/10 iters), loss = 8.02316
I0523 06:03:26.900214 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02316 (* 1 = 8.02316 loss)
I0523 06:03:27.619348 34819 sgd_solver.cpp:112] Iteration 59360, lr = 0.01
I0523 06:03:31.976047 34819 solver.cpp:239] Iteration 59370 (1.97021 iter/s, 5.07561s/10 iters), loss = 8.01458
I0523 06:03:31.976089 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01458 (* 1 = 8.01458 loss)
I0523 06:03:32.516073 34819 sgd_solver.cpp:112] Iteration 59370, lr = 0.01
I0523 06:03:38.044677 34819 solver.cpp:239] Iteration 59380 (1.6479 iter/s, 6.06833s/10 iters), loss = 9.21848
I0523 06:03:38.044720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.21848 (* 1 = 9.21848 loss)
I0523 06:03:38.125057 34819 sgd_solver.cpp:112] Iteration 59380, lr = 0.01
I0523 06:03:43.233598 34819 solver.cpp:239] Iteration 59390 (1.92728 iter/s, 5.18865s/10 iters), loss = 8.47187
I0523 06:03:43.233666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47187 (* 1 = 8.47187 loss)
I0523 06:03:43.900076 34819 sgd_solver.cpp:112] Iteration 59390, lr = 0.01
I0523 06:03:48.812839 34819 solver.cpp:239] Iteration 59400 (1.79247 iter/s, 5.57891s/10 iters), loss = 8.11462
I0523 06:03:48.812893 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11462 (* 1 = 8.11462 loss)
I0523 06:03:49.684522 34819 sgd_solver.cpp:112] Iteration 59400, lr = 0.01
I0523 06:03:53.074717 34819 solver.cpp:239] Iteration 59410 (2.34653 iter/s, 4.26162s/10 iters), loss = 9.17722
I0523 06:03:53.074769 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.17722 (* 1 = 9.17722 loss)
I0523 06:03:53.895171 34819 sgd_solver.cpp:112] Iteration 59410, lr = 0.01
I0523 06:03:58.135303 34819 solver.cpp:239] Iteration 59420 (1.97616 iter/s, 5.06032s/10 iters), loss = 8.77324
I0523 06:03:58.135342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77324 (* 1 = 8.77324 loss)
I0523 06:03:58.923954 34819 sgd_solver.cpp:112] Iteration 59420, lr = 0.01
I0523 06:04:04.677400 34819 solver.cpp:239] Iteration 59430 (1.52864 iter/s, 6.54178s/10 iters), loss = 7.35181
I0523 06:04:04.677448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35181 (* 1 = 7.35181 loss)
I0523 06:04:04.737071 34819 sgd_solver.cpp:112] Iteration 59430, lr = 0.01
I0523 06:04:08.947760 34819 solver.cpp:239] Iteration 59440 (2.34185 iter/s, 4.27013s/10 iters), loss = 8.57606
I0523 06:04:08.947811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57606 (* 1 = 8.57606 loss)
I0523 06:04:09.022085 34819 sgd_solver.cpp:112] Iteration 59440, lr = 0.01
I0523 06:04:14.480295 34819 solver.cpp:239] Iteration 59450 (1.80758 iter/s, 5.53226s/10 iters), loss = 7.90663
I0523 06:04:14.480537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90663 (* 1 = 7.90663 loss)
I0523 06:04:14.556140 34819 sgd_solver.cpp:112] Iteration 59450, lr = 0.01
I0523 06:04:18.587430 34819 solver.cpp:239] Iteration 59460 (2.43502 iter/s, 4.10674s/10 iters), loss = 8.26441
I0523 06:04:18.587471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26441 (* 1 = 8.26441 loss)
I0523 06:04:18.652902 34819 sgd_solver.cpp:112] Iteration 59460, lr = 0.01
I0523 06:04:24.367883 34819 solver.cpp:239] Iteration 59470 (1.73006 iter/s, 5.78016s/10 iters), loss = 7.33014
I0523 06:04:24.367935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33014 (* 1 = 7.33014 loss)
I0523 06:04:24.428160 34819 sgd_solver.cpp:112] Iteration 59470, lr = 0.01
I0523 06:04:27.849185 34819 solver.cpp:239] Iteration 59480 (2.87265 iter/s, 3.4811s/10 iters), loss = 8.55429
I0523 06:04:27.849233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55429 (* 1 = 8.55429 loss)
I0523 06:04:27.908491 34819 sgd_solver.cpp:112] Iteration 59480, lr = 0.01
I0523 06:04:32.161458 34819 solver.cpp:239] Iteration 59490 (2.31909 iter/s, 4.31204s/10 iters), loss = 8.17751
I0523 06:04:32.161504 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17751 (* 1 = 8.17751 loss)
I0523 06:04:33.006585 34819 sgd_solver.cpp:112] Iteration 59490, lr = 0.01
I0523 06:04:36.301079 34819 solver.cpp:239] Iteration 59500 (2.41582 iter/s, 4.13939s/10 iters), loss = 8.52262
I0523 06:04:36.301127 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52262 (* 1 = 8.52262 loss)
I0523 06:04:36.360368 34819 sgd_solver.cpp:112] Iteration 59500, lr = 0.01
I0523 06:04:41.953508 34819 solver.cpp:239] Iteration 59510 (1.76924 iter/s, 5.65214s/10 iters), loss = 8.3073
I0523 06:04:41.953557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3073 (* 1 = 8.3073 loss)
I0523 06:04:42.789830 34819 sgd_solver.cpp:112] Iteration 59510, lr = 0.01
I0523 06:04:46.131645 34819 solver.cpp:239] Iteration 59520 (2.39355 iter/s, 4.1779s/10 iters), loss = 7.77439
I0523 06:04:46.131758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77439 (* 1 = 7.77439 loss)
I0523 06:04:46.213994 34819 sgd_solver.cpp:112] Iteration 59520, lr = 0.01
I0523 06:04:49.558188 34819 solver.cpp:239] Iteration 59530 (2.91861 iter/s, 3.42629s/10 iters), loss = 8.84671
I0523 06:04:49.558248 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84671 (* 1 = 8.84671 loss)
I0523 06:04:49.631394 34819 sgd_solver.cpp:112] Iteration 59530, lr = 0.01
I0523 06:04:53.116958 34819 solver.cpp:239] Iteration 59540 (2.81014 iter/s, 3.55854s/10 iters), loss = 8.05444
I0523 06:04:53.117014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05444 (* 1 = 8.05444 loss)
I0523 06:04:53.189445 34819 sgd_solver.cpp:112] Iteration 59540, lr = 0.01
I0523 06:04:55.297858 34819 solver.cpp:239] Iteration 59550 (4.58563 iter/s, 2.18073s/10 iters), loss = 7.44732
I0523 06:04:55.297920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44732 (* 1 = 7.44732 loss)
I0523 06:04:56.136940 34819 sgd_solver.cpp:112] Iteration 59550, lr = 0.01
I0523 06:05:01.233877 34819 solver.cpp:239] Iteration 59560 (1.68472 iter/s, 5.9357s/10 iters), loss = 7.7842
I0523 06:05:01.233934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7842 (* 1 = 7.7842 loss)
I0523 06:05:01.305261 34819 sgd_solver.cpp:112] Iteration 59560, lr = 0.01
I0523 06:05:06.167906 34819 solver.cpp:239] Iteration 59570 (2.02685 iter/s, 4.93377s/10 iters), loss = 8.90095
I0523 06:05:06.167946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90095 (* 1 = 8.90095 loss)
I0523 06:05:06.995702 34819 sgd_solver.cpp:112] Iteration 59570, lr = 0.01
I0523 06:05:11.658267 34819 solver.cpp:239] Iteration 59580 (1.82147 iter/s, 5.49009s/10 iters), loss = 8.50889
I0523 06:05:11.658324 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50889 (* 1 = 8.50889 loss)
I0523 06:05:11.716496 34819 sgd_solver.cpp:112] Iteration 59580, lr = 0.01
I0523 06:05:16.440148 34819 solver.cpp:239] Iteration 59590 (2.09135 iter/s, 4.78161s/10 iters), loss = 8.60597
I0523 06:05:16.440408 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60597 (* 1 = 8.60597 loss)
I0523 06:05:16.509554 34819 sgd_solver.cpp:112] Iteration 59590, lr = 0.01
I0523 06:05:19.606667 34819 solver.cpp:239] Iteration 59600 (3.15841 iter/s, 3.16615s/10 iters), loss = 8.3208
I0523 06:05:19.606731 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3208 (* 1 = 8.3208 loss)
I0523 06:05:20.467783 34819 sgd_solver.cpp:112] Iteration 59600, lr = 0.01
I0523 06:05:25.306980 34819 solver.cpp:239] Iteration 59610 (1.75438 iter/s, 5.70002s/10 iters), loss = 8.37504
I0523 06:05:25.307024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37504 (* 1 = 8.37504 loss)
I0523 06:05:25.362174 34819 sgd_solver.cpp:112] Iteration 59610, lr = 0.01
I0523 06:05:30.412433 34819 solver.cpp:239] Iteration 59620 (1.9588 iter/s, 5.10518s/10 iters), loss = 6.92212
I0523 06:05:30.412505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.92212 (* 1 = 6.92212 loss)
I0523 06:05:31.052505 34819 sgd_solver.cpp:112] Iteration 59620, lr = 0.01
I0523 06:05:35.848332 34819 solver.cpp:239] Iteration 59630 (1.83973 iter/s, 5.43559s/10 iters), loss = 8.45479
I0523 06:05:35.848382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45479 (* 1 = 8.45479 loss)
I0523 06:05:35.915468 34819 sgd_solver.cpp:112] Iteration 59630, lr = 0.01
I0523 06:05:38.996131 34819 solver.cpp:239] Iteration 59640 (3.17702 iter/s, 3.14761s/10 iters), loss = 8.464
I0523 06:05:38.996184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.464 (* 1 = 8.464 loss)
I0523 06:05:39.871299 34819 sgd_solver.cpp:112] Iteration 59640, lr = 0.01
I0523 06:05:43.763340 34819 solver.cpp:239] Iteration 59650 (2.09778 iter/s, 4.76695s/10 iters), loss = 7.43246
I0523 06:05:43.763396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.43246 (* 1 = 7.43246 loss)
I0523 06:05:43.827054 34819 sgd_solver.cpp:112] Iteration 59650, lr = 0.01
I0523 06:05:50.236923 34819 solver.cpp:239] Iteration 59660 (1.54482 iter/s, 6.47325s/10 iters), loss = 8.89552
I0523 06:05:50.237134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89552 (* 1 = 8.89552 loss)
I0523 06:05:50.301703 34819 sgd_solver.cpp:112] Iteration 59660, lr = 0.01
I0523 06:05:52.858086 34819 solver.cpp:239] Iteration 59670 (3.81556 iter/s, 2.62085s/10 iters), loss = 7.38153
I0523 06:05:52.858148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38153 (* 1 = 7.38153 loss)
I0523 06:05:53.649088 34819 sgd_solver.cpp:112] Iteration 59670, lr = 0.01
I0523 06:05:59.222738 34819 solver.cpp:239] Iteration 59680 (1.57126 iter/s, 6.36431s/10 iters), loss = 9.22256
I0523 06:05:59.222793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22256 (* 1 = 9.22256 loss)
I0523 06:06:00.074633 34819 sgd_solver.cpp:112] Iteration 59680, lr = 0.01
I0523 06:06:05.138011 34819 solver.cpp:239] Iteration 59690 (1.69063 iter/s, 5.91497s/10 iters), loss = 8.70183
I0523 06:06:05.138056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70183 (* 1 = 8.70183 loss)
I0523 06:06:05.856190 34819 sgd_solver.cpp:112] Iteration 59690, lr = 0.01
I0523 06:06:09.327538 34819 solver.cpp:239] Iteration 59700 (2.38703 iter/s, 4.1893s/10 iters), loss = 8.5679
I0523 06:06:09.327579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5679 (* 1 = 8.5679 loss)
I0523 06:06:09.399627 34819 sgd_solver.cpp:112] Iteration 59700, lr = 0.01
I0523 06:06:12.073447 34819 solver.cpp:239] Iteration 59710 (3.64201 iter/s, 2.74574s/10 iters), loss = 8.54639
I0523 06:06:12.073487 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54639 (* 1 = 8.54639 loss)
I0523 06:06:12.885465 34819 sgd_solver.cpp:112] Iteration 59710, lr = 0.01
I0523 06:06:18.198273 34819 solver.cpp:239] Iteration 59720 (1.63278 iter/s, 6.12453s/10 iters), loss = 7.44816
I0523 06:06:18.198315 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44816 (* 1 = 7.44816 loss)
I0523 06:06:19.053014 34819 sgd_solver.cpp:112] Iteration 59720, lr = 0.01
I0523 06:06:23.000975 34819 solver.cpp:239] Iteration 59730 (2.08227 iter/s, 4.80246s/10 iters), loss = 7.45727
I0523 06:06:23.001161 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.45727 (* 1 = 7.45727 loss)
I0523 06:06:23.829694 34819 sgd_solver.cpp:112] Iteration 59730, lr = 0.01
I0523 06:06:29.397159 34819 solver.cpp:239] Iteration 59740 (1.56354 iter/s, 6.39574s/10 iters), loss = 8.14371
I0523 06:06:29.397212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14371 (* 1 = 8.14371 loss)
I0523 06:06:29.461659 34819 sgd_solver.cpp:112] Iteration 59740, lr = 0.01
I0523 06:06:34.641710 34819 solver.cpp:239] Iteration 59750 (1.90684 iter/s, 5.24427s/10 iters), loss = 8.59541
I0523 06:06:34.641762 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59541 (* 1 = 8.59541 loss)
I0523 06:06:35.421854 34819 sgd_solver.cpp:112] Iteration 59750, lr = 0.01
I0523 06:06:37.755440 34819 solver.cpp:239] Iteration 59760 (3.2118 iter/s, 3.11352s/10 iters), loss = 8.24555
I0523 06:06:37.755506 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24555 (* 1 = 8.24555 loss)
I0523 06:06:38.615640 34819 sgd_solver.cpp:112] Iteration 59760, lr = 0.01
I0523 06:06:42.581703 34819 solver.cpp:239] Iteration 59770 (2.07212 iter/s, 4.82597s/10 iters), loss = 8.13063
I0523 06:06:42.581754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13063 (* 1 = 8.13063 loss)
I0523 06:06:43.008474 34819 sgd_solver.cpp:112] Iteration 59770, lr = 0.01
I0523 06:06:46.546772 34819 solver.cpp:239] Iteration 59780 (2.52217 iter/s, 3.96484s/10 iters), loss = 8.32665
I0523 06:06:46.546828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32665 (* 1 = 8.32665 loss)
I0523 06:06:47.389091 34819 sgd_solver.cpp:112] Iteration 59780, lr = 0.01
I0523 06:06:53.061924 34819 solver.cpp:239] Iteration 59790 (1.53497 iter/s, 6.5148s/10 iters), loss = 8.72083
I0523 06:06:53.062057 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72083 (* 1 = 8.72083 loss)
I0523 06:06:53.905138 34819 sgd_solver.cpp:112] Iteration 59790, lr = 0.01
I0523 06:06:58.116184 34819 solver.cpp:239] Iteration 59800 (1.97866 iter/s, 5.05392s/10 iters), loss = 7.38145
I0523 06:06:58.116237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38145 (* 1 = 7.38145 loss)
I0523 06:06:58.186637 34819 sgd_solver.cpp:112] Iteration 59800, lr = 0.01
I0523 06:07:02.308928 34819 solver.cpp:239] Iteration 59810 (2.38521 iter/s, 4.1925s/10 iters), loss = 8.04117
I0523 06:07:02.308981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04117 (* 1 = 8.04117 loss)
I0523 06:07:02.377212 34819 sgd_solver.cpp:112] Iteration 59810, lr = 0.01
I0523 06:07:08.652206 34819 solver.cpp:239] Iteration 59820 (1.57655 iter/s, 6.34296s/10 iters), loss = 8.44871
I0523 06:07:08.652256 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44871 (* 1 = 8.44871 loss)
I0523 06:07:09.449483 34819 sgd_solver.cpp:112] Iteration 59820, lr = 0.01
I0523 06:07:13.580054 34819 solver.cpp:239] Iteration 59830 (2.02939 iter/s, 4.92759s/10 iters), loss = 8.84485
I0523 06:07:13.580096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84485 (* 1 = 8.84485 loss)
I0523 06:07:14.402350 34819 sgd_solver.cpp:112] Iteration 59830, lr = 0.01
I0523 06:07:20.205399 34819 solver.cpp:239] Iteration 59840 (1.50943 iter/s, 6.62502s/10 iters), loss = 7.9516
I0523 06:07:20.205446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9516 (* 1 = 7.9516 loss)
I0523 06:07:20.274261 34819 sgd_solver.cpp:112] Iteration 59840, lr = 0.01
I0523 06:07:25.861160 34819 solver.cpp:239] Iteration 59850 (1.7682 iter/s, 5.65548s/10 iters), loss = 7.79274
I0523 06:07:25.861291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79274 (* 1 = 7.79274 loss)
I0523 06:07:26.693011 34819 sgd_solver.cpp:112] Iteration 59850, lr = 0.01
I0523 06:07:32.161396 34819 solver.cpp:239] Iteration 59860 (1.58735 iter/s, 6.29982s/10 iters), loss = 7.58579
I0523 06:07:32.161444 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58579 (* 1 = 7.58579 loss)
I0523 06:07:32.876446 34819 sgd_solver.cpp:112] Iteration 59860, lr = 0.01
I0523 06:07:36.905334 34819 solver.cpp:239] Iteration 59870 (2.10807 iter/s, 4.74368s/10 iters), loss = 8.39902
I0523 06:07:36.905378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39902 (* 1 = 8.39902 loss)
I0523 06:07:36.955987 34819 sgd_solver.cpp:112] Iteration 59870, lr = 0.01
I0523 06:07:44.161361 34819 solver.cpp:239] Iteration 59880 (1.37823 iter/s, 7.25568s/10 iters), loss = 7.86558
I0523 06:07:44.161403 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86558 (* 1 = 7.86558 loss)
I0523 06:07:44.230078 34819 sgd_solver.cpp:112] Iteration 59880, lr = 0.01
I0523 06:07:49.704424 34819 solver.cpp:239] Iteration 59890 (1.80415 iter/s, 5.54277s/10 iters), loss = 8.05207
I0523 06:07:49.704468 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05207 (* 1 = 8.05207 loss)
I0523 06:07:50.561807 34819 sgd_solver.cpp:112] Iteration 59890, lr = 0.01
I0523 06:07:54.940896 34819 solver.cpp:239] Iteration 59900 (1.90978 iter/s, 5.2362s/10 iters), loss = 8.73626
I0523 06:07:54.940963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73626 (* 1 = 8.73626 loss)
I0523 06:07:55.811549 34819 sgd_solver.cpp:112] Iteration 59900, lr = 0.01
I0523 06:08:01.517388 34819 solver.cpp:239] Iteration 59910 (1.52065 iter/s, 6.57614s/10 iters), loss = 7.76773
I0523 06:08:01.517614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76773 (* 1 = 7.76773 loss)
I0523 06:08:02.304059 34819 sgd_solver.cpp:112] Iteration 59910, lr = 0.01
I0523 06:08:07.730341 34819 solver.cpp:239] Iteration 59920 (1.60966 iter/s, 6.2125s/10 iters), loss = 8.2643
I0523 06:08:07.730396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2643 (* 1 = 8.2643 loss)
I0523 06:08:07.790268 34819 sgd_solver.cpp:112] Iteration 59920, lr = 0.01
I0523 06:08:12.648407 34819 solver.cpp:239] Iteration 59930 (2.03343 iter/s, 4.91781s/10 iters), loss = 7.95383
I0523 06:08:12.648448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95383 (* 1 = 7.95383 loss)
I0523 06:08:12.708817 34819 sgd_solver.cpp:112] Iteration 59930, lr = 0.01
I0523 06:08:16.578471 34819 solver.cpp:239] Iteration 59940 (2.54463 iter/s, 3.92985s/10 iters), loss = 8.0444
I0523 06:08:16.578522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0444 (* 1 = 8.0444 loss)
I0523 06:08:16.644893 34819 sgd_solver.cpp:112] Iteration 59940, lr = 0.01
I0523 06:08:22.182155 34819 solver.cpp:239] Iteration 59950 (1.78463 iter/s, 5.6034s/10 iters), loss = 7.69136
I0523 06:08:22.182199 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69136 (* 1 = 7.69136 loss)
I0523 06:08:22.250300 34819 sgd_solver.cpp:112] Iteration 59950, lr = 0.01
I0523 06:08:25.636478 34819 solver.cpp:239] Iteration 59960 (2.89509 iter/s, 3.45413s/10 iters), loss = 8.63661
I0523 06:08:25.636529 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63661 (* 1 = 8.63661 loss)
I0523 06:08:26.509495 34819 sgd_solver.cpp:112] Iteration 59960, lr = 0.01
I0523 06:08:31.734966 34819 solver.cpp:239] Iteration 59970 (1.63983 iter/s, 6.09819s/10 iters), loss = 8.77295
I0523 06:08:31.735177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77295 (* 1 = 8.77295 loss)
I0523 06:08:31.802450 34819 sgd_solver.cpp:112] Iteration 59970, lr = 0.01
I0523 06:08:36.833937 34819 solver.cpp:239] Iteration 59980 (1.96133 iter/s, 5.09858s/10 iters), loss = 8.26181
I0523 06:08:36.833981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26181 (* 1 = 8.26181 loss)
I0523 06:08:36.892712 34819 sgd_solver.cpp:112] Iteration 59980, lr = 0.01
I0523 06:08:40.636494 34819 solver.cpp:239] Iteration 59990 (2.62996 iter/s, 3.80235s/10 iters), loss = 8.09236
I0523 06:08:40.636541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09236 (* 1 = 8.09236 loss)
I0523 06:08:41.455605 34819 sgd_solver.cpp:112] Iteration 59990, lr = 0.01
I0523 06:08:44.580000 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_60000.caffemodel
I0523 06:08:51.229713 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_60000.solverstate
I0523 06:08:51.461201 34819 solver.cpp:239] Iteration 60000 (0.923853 iter/s, 10.8242s/10 iters), loss = 8.39332
I0523 06:08:51.461238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39332 (* 1 = 8.39332 loss)
I0523 06:08:51.693244 34819 sgd_solver.cpp:112] Iteration 60000, lr = 0.01
I0523 06:08:57.182469 34819 solver.cpp:239] Iteration 60010 (1.74795 iter/s, 5.72098s/10 iters), loss = 9.27259
I0523 06:08:57.182535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27259 (* 1 = 9.27259 loss)
I0523 06:08:57.923496 34819 sgd_solver.cpp:112] Iteration 60010, lr = 0.01
I0523 06:09:02.580304 34819 solver.cpp:239] Iteration 60020 (1.8527 iter/s, 5.39753s/10 iters), loss = 7.85273
I0523 06:09:02.580467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85273 (* 1 = 7.85273 loss)
I0523 06:09:03.183274 34819 sgd_solver.cpp:112] Iteration 60020, lr = 0.01
I0523 06:09:07.227720 34819 solver.cpp:239] Iteration 60030 (2.1519 iter/s, 4.64706s/10 iters), loss = 8.92033
I0523 06:09:07.227771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92033 (* 1 = 8.92033 loss)
I0523 06:09:08.056746 34819 sgd_solver.cpp:112] Iteration 60030, lr = 0.01
I0523 06:09:13.791172 34819 solver.cpp:239] Iteration 60040 (1.52367 iter/s, 6.56312s/10 iters), loss = 8.44693
I0523 06:09:13.791225 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44693 (* 1 = 8.44693 loss)
I0523 06:09:13.861049 34819 sgd_solver.cpp:112] Iteration 60040, lr = 0.01
I0523 06:09:19.550817 34819 solver.cpp:239] Iteration 60050 (1.7363 iter/s, 5.75936s/10 iters), loss = 8.29237
I0523 06:09:19.550858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29237 (* 1 = 8.29237 loss)
I0523 06:09:20.264916 34819 sgd_solver.cpp:112] Iteration 60050, lr = 0.01
I0523 06:09:22.057385 34819 solver.cpp:239] Iteration 60060 (3.98977 iter/s, 2.50641s/10 iters), loss = 8.89571
I0523 06:09:22.057440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89571 (* 1 = 8.89571 loss)
I0523 06:09:22.122169 34819 sgd_solver.cpp:112] Iteration 60060, lr = 0.01
I0523 06:09:23.861989 34819 solver.cpp:239] Iteration 60070 (5.54876 iter/s, 1.8022s/10 iters), loss = 7.95321
I0523 06:09:23.862038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95321 (* 1 = 7.95321 loss)
I0523 06:09:24.675595 34819 sgd_solver.cpp:112] Iteration 60070, lr = 0.01
I0523 06:09:27.944615 34819 solver.cpp:239] Iteration 60080 (2.44954 iter/s, 4.08239s/10 iters), loss = 7.74869
I0523 06:09:27.944669 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74869 (* 1 = 7.74869 loss)
I0523 06:09:28.757524 34819 sgd_solver.cpp:112] Iteration 60080, lr = 0.01
I0523 06:09:32.130053 34819 solver.cpp:239] Iteration 60090 (2.38937 iter/s, 4.1852s/10 iters), loss = 8.03155
I0523 06:09:32.130102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03155 (* 1 = 8.03155 loss)
I0523 06:09:32.195705 34819 sgd_solver.cpp:112] Iteration 60090, lr = 0.01
I0523 06:09:36.944614 34819 solver.cpp:239] Iteration 60100 (2.07715 iter/s, 4.81429s/10 iters), loss = 7.61364
I0523 06:09:36.944777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61364 (* 1 = 7.61364 loss)
I0523 06:09:37.029752 34819 sgd_solver.cpp:112] Iteration 60100, lr = 0.01
I0523 06:09:41.043303 34819 solver.cpp:239] Iteration 60110 (2.44 iter/s, 4.09835s/10 iters), loss = 8.25221
I0523 06:09:41.043359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25221 (* 1 = 8.25221 loss)
I0523 06:09:41.865478 34819 sgd_solver.cpp:112] Iteration 60110, lr = 0.01
I0523 06:09:46.877187 34819 solver.cpp:239] Iteration 60120 (1.71421 iter/s, 5.83359s/10 iters), loss = 8.30058
I0523 06:09:46.877239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30058 (* 1 = 8.30058 loss)
I0523 06:09:47.721484 34819 sgd_solver.cpp:112] Iteration 60120, lr = 0.01
I0523 06:09:52.582188 34819 solver.cpp:239] Iteration 60130 (1.75294 iter/s, 5.70471s/10 iters), loss = 8.08177
I0523 06:09:52.582231 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08177 (* 1 = 8.08177 loss)
I0523 06:09:53.424954 34819 sgd_solver.cpp:112] Iteration 60130, lr = 0.01
I0523 06:09:58.089740 34819 solver.cpp:239] Iteration 60140 (1.81578 iter/s, 5.50727s/10 iters), loss = 8.42285
I0523 06:09:58.089781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42285 (* 1 = 8.42285 loss)
I0523 06:09:58.155735 34819 sgd_solver.cpp:112] Iteration 60140, lr = 0.01
I0523 06:10:01.463313 34819 solver.cpp:239] Iteration 60150 (2.96439 iter/s, 3.37337s/10 iters), loss = 8.81864
I0523 06:10:01.463367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81864 (* 1 = 8.81864 loss)
I0523 06:10:01.533534 34819 sgd_solver.cpp:112] Iteration 60150, lr = 0.01
I0523 06:10:05.043095 34819 solver.cpp:239] Iteration 60160 (2.79363 iter/s, 3.57958s/10 iters), loss = 9.27075
I0523 06:10:05.043138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27075 (* 1 = 9.27075 loss)
I0523 06:10:05.123657 34819 sgd_solver.cpp:112] Iteration 60160, lr = 0.01
I0523 06:10:10.726425 34819 solver.cpp:239] Iteration 60170 (1.75963 iter/s, 5.68302s/10 iters), loss = 8.23431
I0523 06:10:10.726604 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23431 (* 1 = 8.23431 loss)
I0523 06:10:11.416998 34819 sgd_solver.cpp:112] Iteration 60170, lr = 0.01
I0523 06:10:16.290480 34819 solver.cpp:239] Iteration 60180 (1.79738 iter/s, 5.56365s/10 iters), loss = 8.49361
I0523 06:10:16.290534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49361 (* 1 = 8.49361 loss)
I0523 06:10:16.354387 34819 sgd_solver.cpp:112] Iteration 60180, lr = 0.01
I0523 06:10:21.060240 34819 solver.cpp:239] Iteration 60190 (2.09665 iter/s, 4.7695s/10 iters), loss = 8.56912
I0523 06:10:21.060297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56912 (* 1 = 8.56912 loss)
I0523 06:10:21.608233 34819 sgd_solver.cpp:112] Iteration 60190, lr = 0.01
I0523 06:10:27.230558 34819 solver.cpp:239] Iteration 60200 (1.62075 iter/s, 6.17s/10 iters), loss = 8.60329
I0523 06:10:27.230610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60329 (* 1 = 8.60329 loss)
I0523 06:10:28.081280 34819 sgd_solver.cpp:112] Iteration 60200, lr = 0.01
I0523 06:10:32.151196 34819 solver.cpp:239] Iteration 60210 (2.03237 iter/s, 4.92037s/10 iters), loss = 8.64874
I0523 06:10:32.151257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64874 (* 1 = 8.64874 loss)
I0523 06:10:32.934196 34819 sgd_solver.cpp:112] Iteration 60210, lr = 0.01
I0523 06:10:37.059073 34819 solver.cpp:239] Iteration 60220 (2.03765 iter/s, 4.9076s/10 iters), loss = 8.73592
I0523 06:10:37.059137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73592 (* 1 = 8.73592 loss)
I0523 06:10:37.851698 34819 sgd_solver.cpp:112] Iteration 60220, lr = 0.01
I0523 06:10:41.277326 34819 solver.cpp:239] Iteration 60230 (2.37079 iter/s, 4.218s/10 iters), loss = 9.11895
I0523 06:10:41.277478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11895 (* 1 = 9.11895 loss)
I0523 06:10:41.343799 34819 sgd_solver.cpp:112] Iteration 60230, lr = 0.01
I0523 06:10:46.069358 34819 solver.cpp:239] Iteration 60240 (2.08695 iter/s, 4.79168s/10 iters), loss = 8.0616
I0523 06:10:46.069407 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0616 (* 1 = 8.0616 loss)
I0523 06:10:46.917147 34819 sgd_solver.cpp:112] Iteration 60240, lr = 0.01
I0523 06:10:52.821961 34819 solver.cpp:239] Iteration 60250 (1.48098 iter/s, 6.75227s/10 iters), loss = 8.55405
I0523 06:10:52.822015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55405 (* 1 = 8.55405 loss)
I0523 06:10:53.533707 34819 sgd_solver.cpp:112] Iteration 60250, lr = 0.01
I0523 06:10:58.319699 34819 solver.cpp:239] Iteration 60260 (1.81903 iter/s, 5.49743s/10 iters), loss = 8.19262
I0523 06:10:58.319751 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19262 (* 1 = 8.19262 loss)
I0523 06:10:58.394172 34819 sgd_solver.cpp:112] Iteration 60260, lr = 0.01
I0523 06:11:04.020777 34819 solver.cpp:239] Iteration 60270 (1.75415 iter/s, 5.70078s/10 iters), loss = 7.78965
I0523 06:11:04.020845 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78965 (* 1 = 7.78965 loss)
I0523 06:11:04.077968 34819 sgd_solver.cpp:112] Iteration 60270, lr = 0.01
I0523 06:11:08.256765 34819 solver.cpp:239] Iteration 60280 (2.36086 iter/s, 4.23575s/10 iters), loss = 8.10562
I0523 06:11:08.256817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10562 (* 1 = 8.10562 loss)
I0523 06:11:08.322640 34819 sgd_solver.cpp:112] Iteration 60280, lr = 0.01
I0523 06:11:13.072794 34819 solver.cpp:239] Iteration 60290 (2.07651 iter/s, 4.81577s/10 iters), loss = 8.66567
I0523 06:11:13.072983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66567 (* 1 = 8.66567 loss)
I0523 06:11:13.130072 34819 sgd_solver.cpp:112] Iteration 60290, lr = 0.01
I0523 06:11:17.238101 34819 solver.cpp:239] Iteration 60300 (2.40099 iter/s, 4.16495s/10 iters), loss = 8.64868
I0523 06:11:17.238147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64868 (* 1 = 8.64868 loss)
I0523 06:11:18.095455 34819 sgd_solver.cpp:112] Iteration 60300, lr = 0.01
I0523 06:11:21.615128 34819 solver.cpp:239] Iteration 60310 (2.28478 iter/s, 4.37679s/10 iters), loss = 8.2903
I0523 06:11:21.615183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2903 (* 1 = 8.2903 loss)
I0523 06:11:22.425428 34819 sgd_solver.cpp:112] Iteration 60310, lr = 0.01
I0523 06:11:26.401577 34819 solver.cpp:239] Iteration 60320 (2.08934 iter/s, 4.78619s/10 iters), loss = 7.77416
I0523 06:11:26.401633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77416 (* 1 = 7.77416 loss)
I0523 06:11:26.468948 34819 sgd_solver.cpp:112] Iteration 60320, lr = 0.01
I0523 06:11:31.376336 34819 solver.cpp:239] Iteration 60330 (2.01026 iter/s, 4.97449s/10 iters), loss = 7.99054
I0523 06:11:31.376389 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99054 (* 1 = 7.99054 loss)
I0523 06:11:31.443774 34819 sgd_solver.cpp:112] Iteration 60330, lr = 0.01
I0523 06:11:34.810741 34819 solver.cpp:239] Iteration 60340 (2.91188 iter/s, 3.4342s/10 iters), loss = 7.8023
I0523 06:11:34.810794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8023 (* 1 = 7.8023 loss)
I0523 06:11:34.884558 34819 sgd_solver.cpp:112] Iteration 60340, lr = 0.01
I0523 06:11:40.458428 34819 solver.cpp:239] Iteration 60350 (1.77073 iter/s, 5.64739s/10 iters), loss = 6.88164
I0523 06:11:40.458483 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.88164 (* 1 = 6.88164 loss)
I0523 06:11:40.579536 34819 sgd_solver.cpp:112] Iteration 60350, lr = 0.01
I0523 06:11:43.956475 34819 solver.cpp:239] Iteration 60360 (2.85892 iter/s, 3.49783s/10 iters), loss = 8.77445
I0523 06:11:43.956696 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77445 (* 1 = 8.77445 loss)
I0523 06:11:44.035518 34819 sgd_solver.cpp:112] Iteration 60360, lr = 0.01
I0523 06:11:48.468813 34819 solver.cpp:239] Iteration 60370 (2.21634 iter/s, 4.51195s/10 iters), loss = 8.58561
I0523 06:11:48.468863 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58561 (* 1 = 8.58561 loss)
I0523 06:11:48.536350 34819 sgd_solver.cpp:112] Iteration 60370, lr = 0.01
I0523 06:11:53.502341 34819 solver.cpp:239] Iteration 60380 (1.98678 iter/s, 5.03327s/10 iters), loss = 7.82792
I0523 06:11:53.502383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82792 (* 1 = 7.82792 loss)
I0523 06:11:53.874644 34819 sgd_solver.cpp:112] Iteration 60380, lr = 0.01
I0523 06:11:58.791313 34819 solver.cpp:239] Iteration 60390 (1.89083 iter/s, 5.2887s/10 iters), loss = 7.86068
I0523 06:11:58.791364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86068 (* 1 = 7.86068 loss)
I0523 06:11:58.855105 34819 sgd_solver.cpp:112] Iteration 60390, lr = 0.01
I0523 06:12:01.658273 34819 solver.cpp:239] Iteration 60400 (3.48823 iter/s, 2.86678s/10 iters), loss = 8.51835
I0523 06:12:01.658318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51835 (* 1 = 8.51835 loss)
I0523 06:12:01.718987 34819 sgd_solver.cpp:112] Iteration 60400, lr = 0.01
I0523 06:12:07.640018 34819 solver.cpp:239] Iteration 60410 (1.67184 iter/s, 5.98145s/10 iters), loss = 8.59846
I0523 06:12:07.640081 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59846 (* 1 = 8.59846 loss)
I0523 06:12:07.709904 34819 sgd_solver.cpp:112] Iteration 60410, lr = 0.01
I0523 06:12:11.892055 34819 solver.cpp:239] Iteration 60420 (2.35195 iter/s, 4.25179s/10 iters), loss = 8.42191
I0523 06:12:11.892096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42191 (* 1 = 8.42191 loss)
I0523 06:12:11.952590 34819 sgd_solver.cpp:112] Iteration 60420, lr = 0.01
I0523 06:12:16.322017 34819 solver.cpp:239] Iteration 60430 (2.25747 iter/s, 4.42973s/10 iters), loss = 7.81699
I0523 06:12:16.322166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81699 (* 1 = 7.81699 loss)
I0523 06:12:16.394017 34819 sgd_solver.cpp:112] Iteration 60430, lr = 0.01
I0523 06:12:21.170210 34819 solver.cpp:239] Iteration 60440 (2.06278 iter/s, 4.84783s/10 iters), loss = 8.4089
I0523 06:12:21.170264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4089 (* 1 = 8.4089 loss)
I0523 06:12:21.248477 34819 sgd_solver.cpp:112] Iteration 60440, lr = 0.01
I0523 06:12:26.857556 34819 solver.cpp:239] Iteration 60450 (1.75838 iter/s, 5.68704s/10 iters), loss = 8.99657
I0523 06:12:26.857609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99657 (* 1 = 8.99657 loss)
I0523 06:12:26.918728 34819 sgd_solver.cpp:112] Iteration 60450, lr = 0.01
I0523 06:12:31.810974 34819 solver.cpp:239] Iteration 60460 (2.01892 iter/s, 4.95315s/10 iters), loss = 8.38044
I0523 06:12:31.811017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38044 (* 1 = 8.38044 loss)
I0523 06:12:32.622344 34819 sgd_solver.cpp:112] Iteration 60460, lr = 0.01
I0523 06:12:36.679359 34819 solver.cpp:239] Iteration 60470 (2.05417 iter/s, 4.86814s/10 iters), loss = 8.86633
I0523 06:12:36.679411 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86633 (* 1 = 8.86633 loss)
I0523 06:12:36.733748 34819 sgd_solver.cpp:112] Iteration 60470, lr = 0.01
I0523 06:12:40.822520 34819 solver.cpp:239] Iteration 60480 (2.41375 iter/s, 4.14294s/10 iters), loss = 8.32594
I0523 06:12:40.822564 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32594 (* 1 = 8.32594 loss)
I0523 06:12:41.645633 34819 sgd_solver.cpp:112] Iteration 60480, lr = 0.01
I0523 06:12:44.910419 34819 solver.cpp:239] Iteration 60490 (2.44638 iter/s, 4.08768s/10 iters), loss = 8.5225
I0523 06:12:44.910471 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5225 (* 1 = 8.5225 loss)
I0523 06:12:44.977134 34819 sgd_solver.cpp:112] Iteration 60490, lr = 0.01
I0523 06:12:49.735496 34819 solver.cpp:239] Iteration 60500 (2.07263 iter/s, 4.82478s/10 iters), loss = 8.85335
I0523 06:12:49.735641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85335 (* 1 = 8.85335 loss)
I0523 06:12:50.450472 34819 sgd_solver.cpp:112] Iteration 60500, lr = 0.01
I0523 06:12:54.094549 34819 solver.cpp:239] Iteration 60510 (2.29425 iter/s, 4.35873s/10 iters), loss = 8.45778
I0523 06:12:54.094602 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45778 (* 1 = 8.45778 loss)
I0523 06:12:54.171645 34819 sgd_solver.cpp:112] Iteration 60510, lr = 0.01
I0523 06:12:59.180335 34819 solver.cpp:239] Iteration 60520 (1.96637 iter/s, 5.08553s/10 iters), loss = 8.4921
I0523 06:12:59.180377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4921 (* 1 = 8.4921 loss)
I0523 06:12:59.874672 34819 sgd_solver.cpp:112] Iteration 60520, lr = 0.01
I0523 06:13:03.263814 34819 solver.cpp:239] Iteration 60530 (2.44902 iter/s, 4.08326s/10 iters), loss = 7.8885
I0523 06:13:03.263857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8885 (* 1 = 7.8885 loss)
I0523 06:13:03.333490 34819 sgd_solver.cpp:112] Iteration 60530, lr = 0.01
I0523 06:13:08.962200 34819 solver.cpp:239] Iteration 60540 (1.75497 iter/s, 5.69811s/10 iters), loss = 8.39464
I0523 06:13:08.962242 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39464 (* 1 = 8.39464 loss)
I0523 06:13:09.032435 34819 sgd_solver.cpp:112] Iteration 60540, lr = 0.01
I0523 06:13:11.913007 34819 solver.cpp:239] Iteration 60550 (3.38912 iter/s, 2.95062s/10 iters), loss = 9.09644
I0523 06:13:11.913061 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09644 (* 1 = 9.09644 loss)
I0523 06:13:12.728374 34819 sgd_solver.cpp:112] Iteration 60550, lr = 0.01
I0523 06:13:18.196516 34819 solver.cpp:239] Iteration 60560 (1.59155 iter/s, 6.28317s/10 iters), loss = 7.40453
I0523 06:13:18.196559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40453 (* 1 = 7.40453 loss)
I0523 06:13:19.035785 34819 sgd_solver.cpp:112] Iteration 60560, lr = 0.01
I0523 06:13:24.569346 34819 solver.cpp:239] Iteration 60570 (1.56924 iter/s, 6.37251s/10 iters), loss = 8.85834
I0523 06:13:24.569491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85834 (* 1 = 8.85834 loss)
I0523 06:13:24.625429 34819 sgd_solver.cpp:112] Iteration 60570, lr = 0.01
I0523 06:13:28.670967 34819 solver.cpp:239] Iteration 60580 (2.43825 iter/s, 4.10131s/10 iters), loss = 8.24531
I0523 06:13:28.671012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24531 (* 1 = 8.24531 loss)
I0523 06:13:28.728905 34819 sgd_solver.cpp:112] Iteration 60580, lr = 0.01
I0523 06:13:32.808307 34819 solver.cpp:239] Iteration 60590 (2.41714 iter/s, 4.13712s/10 iters), loss = 7.8078
I0523 06:13:32.808362 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8078 (* 1 = 7.8078 loss)
I0523 06:13:32.883427 34819 sgd_solver.cpp:112] Iteration 60590, lr = 0.01
I0523 06:13:38.897840 34819 solver.cpp:239] Iteration 60600 (1.64224 iter/s, 6.08923s/10 iters), loss = 8.31377
I0523 06:13:38.897892 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31377 (* 1 = 8.31377 loss)
I0523 06:13:38.975394 34819 sgd_solver.cpp:112] Iteration 60600, lr = 0.01
I0523 06:13:43.620577 34819 solver.cpp:239] Iteration 60610 (2.11753 iter/s, 4.72248s/10 iters), loss = 6.8862
I0523 06:13:43.620621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.8862 (* 1 = 6.8862 loss)
I0523 06:13:43.702407 34819 sgd_solver.cpp:112] Iteration 60610, lr = 0.01
I0523 06:13:50.123345 34819 solver.cpp:239] Iteration 60620 (1.53788 iter/s, 6.50244s/10 iters), loss = 7.4548
I0523 06:13:50.123397 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4548 (* 1 = 7.4548 loss)
I0523 06:13:50.174096 34819 sgd_solver.cpp:112] Iteration 60620, lr = 0.01
I0523 06:13:56.226554 34819 solver.cpp:239] Iteration 60630 (1.63856 iter/s, 6.10291s/10 iters), loss = 8.74244
I0523 06:13:56.226791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74244 (* 1 = 8.74244 loss)
I0523 06:13:56.808101 34819 sgd_solver.cpp:112] Iteration 60630, lr = 0.01
I0523 06:14:02.833768 34819 solver.cpp:239] Iteration 60640 (1.51361 iter/s, 6.60672s/10 iters), loss = 8.06417
I0523 06:14:02.833817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06417 (* 1 = 8.06417 loss)
I0523 06:14:02.897418 34819 sgd_solver.cpp:112] Iteration 60640, lr = 0.01
I0523 06:14:06.579529 34819 solver.cpp:239] Iteration 60650 (2.66984 iter/s, 3.74554s/10 iters), loss = 8.18357
I0523 06:14:06.579572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18357 (* 1 = 8.18357 loss)
I0523 06:14:07.347584 34819 sgd_solver.cpp:112] Iteration 60650, lr = 0.01
I0523 06:14:13.247705 34819 solver.cpp:239] Iteration 60660 (1.49974 iter/s, 6.66784s/10 iters), loss = 8.18968
I0523 06:14:13.247776 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18968 (* 1 = 8.18968 loss)
I0523 06:14:14.083935 34819 sgd_solver.cpp:112] Iteration 60660, lr = 0.01
I0523 06:14:19.423115 34819 solver.cpp:239] Iteration 60670 (1.61941 iter/s, 6.17508s/10 iters), loss = 9.10438
I0523 06:14:19.423169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10438 (* 1 = 9.10438 loss)
I0523 06:14:19.493902 34819 sgd_solver.cpp:112] Iteration 60670, lr = 0.01
I0523 06:14:25.037245 34819 solver.cpp:239] Iteration 60680 (1.78132 iter/s, 5.61383s/10 iters), loss = 7.14135
I0523 06:14:25.037299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.14135 (* 1 = 7.14135 loss)
I0523 06:14:25.115810 34819 sgd_solver.cpp:112] Iteration 60680, lr = 0.01
I0523 06:14:30.009227 34819 solver.cpp:239] Iteration 60690 (2.01137 iter/s, 4.97172s/10 iters), loss = 7.83151
I0523 06:14:30.009377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83151 (* 1 = 7.83151 loss)
I0523 06:14:30.840126 34819 sgd_solver.cpp:112] Iteration 60690, lr = 0.01
I0523 06:14:36.260654 34819 solver.cpp:239] Iteration 60700 (1.59974 iter/s, 6.251s/10 iters), loss = 8.79176
I0523 06:14:36.260699 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79176 (* 1 = 8.79176 loss)
I0523 06:14:36.312419 34819 sgd_solver.cpp:112] Iteration 60700, lr = 0.01
I0523 06:14:41.467180 34819 solver.cpp:239] Iteration 60710 (1.92076 iter/s, 5.20627s/10 iters), loss = 7.57827
I0523 06:14:41.467222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57827 (* 1 = 7.57827 loss)
I0523 06:14:42.339395 34819 sgd_solver.cpp:112] Iteration 60710, lr = 0.01
I0523 06:14:46.343307 34819 solver.cpp:239] Iteration 60720 (2.05091 iter/s, 4.87588s/10 iters), loss = 8.62825
I0523 06:14:46.343358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62825 (* 1 = 8.62825 loss)
I0523 06:14:46.406877 34819 sgd_solver.cpp:112] Iteration 60720, lr = 0.01
I0523 06:14:51.745683 34819 solver.cpp:239] Iteration 60730 (1.85114 iter/s, 5.40209s/10 iters), loss = 7.86323
I0523 06:14:51.745725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86323 (* 1 = 7.86323 loss)
I0523 06:14:52.519402 34819 sgd_solver.cpp:112] Iteration 60730, lr = 0.01
I0523 06:14:57.256892 34819 solver.cpp:239] Iteration 60740 (1.81457 iter/s, 5.51094s/10 iters), loss = 7.64305
I0523 06:14:57.256933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64305 (* 1 = 7.64305 loss)
I0523 06:14:57.325769 34819 sgd_solver.cpp:112] Iteration 60740, lr = 0.01
I0523 06:15:01.170459 34819 solver.cpp:239] Iteration 60750 (2.55535 iter/s, 3.91335s/10 iters), loss = 7.89339
I0523 06:15:01.170581 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89339 (* 1 = 7.89339 loss)
I0523 06:15:01.716737 34819 sgd_solver.cpp:112] Iteration 60750, lr = 0.01
I0523 06:15:06.158849 34819 solver.cpp:239] Iteration 60760 (2.00479 iter/s, 4.98806s/10 iters), loss = 7.79533
I0523 06:15:06.158890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79533 (* 1 = 7.79533 loss)
I0523 06:15:06.230610 34819 sgd_solver.cpp:112] Iteration 60760, lr = 0.01
I0523 06:15:11.493631 34819 solver.cpp:239] Iteration 60770 (1.87459 iter/s, 5.33451s/10 iters), loss = 8.43657
I0523 06:15:11.493674 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43657 (* 1 = 8.43657 loss)
I0523 06:15:11.558560 34819 sgd_solver.cpp:112] Iteration 60770, lr = 0.01
I0523 06:15:16.210824 34819 solver.cpp:239] Iteration 60780 (2.12002 iter/s, 4.71695s/10 iters), loss = 8.01052
I0523 06:15:16.210866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01052 (* 1 = 8.01052 loss)
I0523 06:15:16.941040 34819 sgd_solver.cpp:112] Iteration 60780, lr = 0.01
I0523 06:15:21.145406 34819 solver.cpp:239] Iteration 60790 (2.02662 iter/s, 4.93433s/10 iters), loss = 8.291
I0523 06:15:21.145447 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.291 (* 1 = 8.291 loss)
I0523 06:15:21.214908 34819 sgd_solver.cpp:112] Iteration 60790, lr = 0.01
I0523 06:15:26.617835 34819 solver.cpp:239] Iteration 60800 (1.82744 iter/s, 5.47215s/10 iters), loss = 7.29842
I0523 06:15:26.617887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29842 (* 1 = 7.29842 loss)
I0523 06:15:27.307308 34819 sgd_solver.cpp:112] Iteration 60800, lr = 0.01
I0523 06:15:32.268939 34819 solver.cpp:239] Iteration 60810 (1.76966 iter/s, 5.65082s/10 iters), loss = 8.48462
I0523 06:15:32.269090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48462 (* 1 = 8.48462 loss)
I0523 06:15:32.359277 34819 sgd_solver.cpp:112] Iteration 60810, lr = 0.01
I0523 06:15:38.121680 34819 solver.cpp:239] Iteration 60820 (1.70872 iter/s, 5.85234s/10 iters), loss = 8.80189
I0523 06:15:38.121726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80189 (* 1 = 8.80189 loss)
I0523 06:15:38.191102 34819 sgd_solver.cpp:112] Iteration 60820, lr = 0.01
I0523 06:15:42.304280 34819 solver.cpp:239] Iteration 60830 (2.39098 iter/s, 4.18238s/10 iters), loss = 8.08216
I0523 06:15:42.304327 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08216 (* 1 = 8.08216 loss)
I0523 06:15:42.368494 34819 sgd_solver.cpp:112] Iteration 60830, lr = 0.01
I0523 06:15:46.618014 34819 solver.cpp:239] Iteration 60840 (2.3183 iter/s, 4.31351s/10 iters), loss = 8.44663
I0523 06:15:46.618062 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44663 (* 1 = 8.44663 loss)
I0523 06:15:47.441496 34819 sgd_solver.cpp:112] Iteration 60840, lr = 0.01
I0523 06:15:52.612864 34819 solver.cpp:239] Iteration 60850 (1.66818 iter/s, 5.99455s/10 iters), loss = 9.07241
I0523 06:15:52.612921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07241 (* 1 = 9.07241 loss)
I0523 06:15:53.401250 34819 sgd_solver.cpp:112] Iteration 60850, lr = 0.01
I0523 06:15:57.679262 34819 solver.cpp:239] Iteration 60860 (1.97389 iter/s, 5.06613s/10 iters), loss = 9.08443
I0523 06:15:57.679314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08443 (* 1 = 9.08443 loss)
I0523 06:15:57.733853 34819 sgd_solver.cpp:112] Iteration 60860, lr = 0.01
I0523 06:16:03.097659 34819 solver.cpp:239] Iteration 60870 (1.84566 iter/s, 5.41812s/10 iters), loss = 8.55726
I0523 06:16:03.097800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55726 (* 1 = 8.55726 loss)
I0523 06:16:03.167229 34819 sgd_solver.cpp:112] Iteration 60870, lr = 0.01
I0523 06:16:09.612521 34819 solver.cpp:239] Iteration 60880 (1.53505 iter/s, 6.51446s/10 iters), loss = 8.2888
I0523 06:16:09.612565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2888 (* 1 = 8.2888 loss)
I0523 06:16:09.688215 34819 sgd_solver.cpp:112] Iteration 60880, lr = 0.01
I0523 06:16:13.595435 34819 solver.cpp:239] Iteration 60890 (2.51087 iter/s, 3.98269s/10 iters), loss = 8.72793
I0523 06:16:13.595485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72793 (* 1 = 8.72793 loss)
I0523 06:16:13.667922 34819 sgd_solver.cpp:112] Iteration 60890, lr = 0.01
I0523 06:16:19.322882 34819 solver.cpp:239] Iteration 60900 (1.74606 iter/s, 5.72716s/10 iters), loss = 8.40278
I0523 06:16:19.322929 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40278 (* 1 = 8.40278 loss)
I0523 06:16:20.099687 34819 sgd_solver.cpp:112] Iteration 60900, lr = 0.01
I0523 06:16:24.038914 34819 solver.cpp:239] Iteration 60910 (2.12054 iter/s, 4.71579s/10 iters), loss = 8.60236
I0523 06:16:24.038959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60236 (* 1 = 8.60236 loss)
I0523 06:16:24.126201 34819 sgd_solver.cpp:112] Iteration 60910, lr = 0.01
I0523 06:16:29.890962 34819 solver.cpp:239] Iteration 60920 (1.70889 iter/s, 5.85176s/10 iters), loss = 8.78408
I0523 06:16:29.891019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78408 (* 1 = 8.78408 loss)
I0523 06:16:29.960472 34819 sgd_solver.cpp:112] Iteration 60920, lr = 0.01
I0523 06:16:33.528172 34819 solver.cpp:239] Iteration 60930 (2.74953 iter/s, 3.63698s/10 iters), loss = 8.45382
I0523 06:16:33.528435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45382 (* 1 = 8.45382 loss)
I0523 06:16:34.294785 34819 sgd_solver.cpp:112] Iteration 60930, lr = 0.01
I0523 06:16:39.941679 34819 solver.cpp:239] Iteration 60940 (1.55933 iter/s, 6.41299s/10 iters), loss = 8.48736
I0523 06:16:39.941735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48736 (* 1 = 8.48736 loss)
I0523 06:16:40.011739 34819 sgd_solver.cpp:112] Iteration 60940, lr = 0.01
I0523 06:16:45.696244 34819 solver.cpp:239] Iteration 60950 (1.73784 iter/s, 5.75426s/10 iters), loss = 7.95411
I0523 06:16:45.696311 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95411 (* 1 = 7.95411 loss)
I0523 06:16:46.554795 34819 sgd_solver.cpp:112] Iteration 60950, lr = 0.01
I0523 06:16:50.270961 34819 solver.cpp:239] Iteration 60960 (2.18605 iter/s, 4.57446s/10 iters), loss = 7.40551
I0523 06:16:50.271004 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40551 (* 1 = 7.40551 loss)
I0523 06:16:50.327318 34819 sgd_solver.cpp:112] Iteration 60960, lr = 0.01
I0523 06:16:55.404426 34819 solver.cpp:239] Iteration 60970 (1.9481 iter/s, 5.13321s/10 iters), loss = 7.4661
I0523 06:16:55.404467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4661 (* 1 = 7.4661 loss)
I0523 06:16:56.201313 34819 sgd_solver.cpp:112] Iteration 60970, lr = 0.01
I0523 06:17:01.926298 34819 solver.cpp:239] Iteration 60980 (1.53338 iter/s, 6.52154s/10 iters), loss = 7.21976
I0523 06:17:01.926347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.21976 (* 1 = 7.21976 loss)
I0523 06:17:02.707123 34819 sgd_solver.cpp:112] Iteration 60980, lr = 0.01
I0523 06:17:06.651232 34819 solver.cpp:239] Iteration 60990 (2.11655 iter/s, 4.72468s/10 iters), loss = 7.92738
I0523 06:17:06.651360 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92738 (* 1 = 7.92738 loss)
I0523 06:17:07.505071 34819 sgd_solver.cpp:112] Iteration 60990, lr = 0.01
I0523 06:17:12.252502 34819 solver.cpp:239] Iteration 61000 (1.78542 iter/s, 5.60091s/10 iters), loss = 8.09155
I0523 06:17:12.252555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09155 (* 1 = 8.09155 loss)
I0523 06:17:12.315212 34819 sgd_solver.cpp:112] Iteration 61000, lr = 0.01
I0523 06:17:15.851394 34819 solver.cpp:239] Iteration 61010 (2.7788 iter/s, 3.59868s/10 iters), loss = 7.83775
I0523 06:17:15.851449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83775 (* 1 = 7.83775 loss)
I0523 06:17:16.410461 34819 sgd_solver.cpp:112] Iteration 61010, lr = 0.01
I0523 06:17:21.549579 34819 solver.cpp:239] Iteration 61020 (1.75503 iter/s, 5.6979s/10 iters), loss = 8.87983
I0523 06:17:21.549636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87983 (* 1 = 8.87983 loss)
I0523 06:17:21.622162 34819 sgd_solver.cpp:112] Iteration 61020, lr = 0.01
I0523 06:17:25.271800 34819 solver.cpp:239] Iteration 61030 (2.68673 iter/s, 3.722s/10 iters), loss = 8.82464
I0523 06:17:25.271848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82464 (* 1 = 8.82464 loss)
I0523 06:17:25.331209 34819 sgd_solver.cpp:112] Iteration 61030, lr = 0.01
I0523 06:17:28.699301 34819 solver.cpp:239] Iteration 61040 (2.91775 iter/s, 3.4273s/10 iters), loss = 7.06124
I0523 06:17:28.699359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.06124 (* 1 = 7.06124 loss)
I0523 06:17:29.540781 34819 sgd_solver.cpp:112] Iteration 61040, lr = 0.01
I0523 06:17:33.532392 34819 solver.cpp:239] Iteration 61050 (2.06918 iter/s, 4.83283s/10 iters), loss = 8.32515
I0523 06:17:33.532449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32515 (* 1 = 8.32515 loss)
I0523 06:17:33.608026 34819 sgd_solver.cpp:112] Iteration 61050, lr = 0.01
I0523 06:17:37.694504 34819 solver.cpp:239] Iteration 61060 (2.40417 iter/s, 4.15944s/10 iters), loss = 7.42281
I0523 06:17:37.694658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42281 (* 1 = 7.42281 loss)
I0523 06:17:38.561174 34819 sgd_solver.cpp:112] Iteration 61060, lr = 0.01
I0523 06:17:42.356786 34819 solver.cpp:239] Iteration 61070 (2.14503 iter/s, 4.66193s/10 iters), loss = 9.05322
I0523 06:17:42.356842 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.05322 (* 1 = 9.05322 loss)
I0523 06:17:42.424729 34819 sgd_solver.cpp:112] Iteration 61070, lr = 0.01
I0523 06:17:47.550680 34819 solver.cpp:239] Iteration 61080 (1.92544 iter/s, 5.19363s/10 iters), loss = 7.76185
I0523 06:17:47.550737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76185 (* 1 = 7.76185 loss)
I0523 06:17:47.620673 34819 sgd_solver.cpp:112] Iteration 61080, lr = 0.01
I0523 06:17:52.560380 34819 solver.cpp:239] Iteration 61090 (1.99623 iter/s, 5.00944s/10 iters), loss = 7.58201
I0523 06:17:52.560422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58201 (* 1 = 7.58201 loss)
I0523 06:17:52.625708 34819 sgd_solver.cpp:112] Iteration 61090, lr = 0.01
I0523 06:17:57.671382 34819 solver.cpp:239] Iteration 61100 (1.95667 iter/s, 5.11073s/10 iters), loss = 8.29491
I0523 06:17:57.671437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29491 (* 1 = 8.29491 loss)
I0523 06:17:58.463815 34819 sgd_solver.cpp:112] Iteration 61100, lr = 0.01
I0523 06:18:03.273411 34819 solver.cpp:239] Iteration 61110 (1.78516 iter/s, 5.60174s/10 iters), loss = 7.68756
I0523 06:18:03.273458 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68756 (* 1 = 7.68756 loss)
I0523 06:18:04.082264 34819 sgd_solver.cpp:112] Iteration 61110, lr = 0.01
I0523 06:18:08.203496 34819 solver.cpp:239] Iteration 61120 (2.02847 iter/s, 4.92981s/10 iters), loss = 7.60791
I0523 06:18:08.203709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60791 (* 1 = 7.60791 loss)
I0523 06:18:09.074777 34819 sgd_solver.cpp:112] Iteration 61120, lr = 0.01
I0523 06:18:13.810879 34819 solver.cpp:239] Iteration 61130 (1.7835 iter/s, 5.60695s/10 iters), loss = 7.70768
I0523 06:18:13.810942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70768 (* 1 = 7.70768 loss)
I0523 06:18:13.894605 34819 sgd_solver.cpp:112] Iteration 61130, lr = 0.01
I0523 06:18:20.306007 34819 solver.cpp:239] Iteration 61140 (1.5397 iter/s, 6.49479s/10 iters), loss = 7.68149
I0523 06:18:20.306056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68149 (* 1 = 7.68149 loss)
I0523 06:18:21.170023 34819 sgd_solver.cpp:112] Iteration 61140, lr = 0.01
I0523 06:18:24.166261 34819 solver.cpp:239] Iteration 61150 (2.59064 iter/s, 3.86004s/10 iters), loss = 8.29726
I0523 06:18:24.166306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29726 (* 1 = 8.29726 loss)
I0523 06:18:25.001785 34819 sgd_solver.cpp:112] Iteration 61150, lr = 0.01
I0523 06:18:28.832602 34819 solver.cpp:239] Iteration 61160 (2.14312 iter/s, 4.66609s/10 iters), loss = 7.75077
I0523 06:18:28.832643 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75077 (* 1 = 7.75077 loss)
I0523 06:18:29.388079 34819 sgd_solver.cpp:112] Iteration 61160, lr = 0.01
I0523 06:18:33.500689 34819 solver.cpp:239] Iteration 61170 (2.14232 iter/s, 4.66784s/10 iters), loss = 8.6482
I0523 06:18:33.500737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6482 (* 1 = 8.6482 loss)
I0523 06:18:33.568193 34819 sgd_solver.cpp:112] Iteration 61170, lr = 0.01
I0523 06:18:39.869447 34819 solver.cpp:239] Iteration 61180 (1.57025 iter/s, 6.36841s/10 iters), loss = 7.57994
I0523 06:18:39.869585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57994 (* 1 = 7.57994 loss)
I0523 06:18:40.584406 34819 sgd_solver.cpp:112] Iteration 61180, lr = 0.01
I0523 06:18:43.081133 34819 solver.cpp:239] Iteration 61190 (3.1139 iter/s, 3.2114s/10 iters), loss = 8.03586
I0523 06:18:43.081174 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03586 (* 1 = 8.03586 loss)
I0523 06:18:43.151877 34819 sgd_solver.cpp:112] Iteration 61190, lr = 0.01
I0523 06:18:48.417433 34819 solver.cpp:239] Iteration 61200 (1.87405 iter/s, 5.33604s/10 iters), loss = 9.13554
I0523 06:18:48.417474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13554 (* 1 = 9.13554 loss)
I0523 06:18:48.479872 34819 sgd_solver.cpp:112] Iteration 61200, lr = 0.01
I0523 06:18:51.660449 34819 solver.cpp:239] Iteration 61210 (3.08373 iter/s, 3.24283s/10 iters), loss = 9.09357
I0523 06:18:51.660490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09357 (* 1 = 9.09357 loss)
I0523 06:18:51.737444 34819 sgd_solver.cpp:112] Iteration 61210, lr = 0.01
I0523 06:18:56.022017 34819 solver.cpp:239] Iteration 61220 (2.29288 iter/s, 4.36134s/10 iters), loss = 8.03061
I0523 06:18:56.022058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03061 (* 1 = 8.03061 loss)
I0523 06:18:56.802070 34819 sgd_solver.cpp:112] Iteration 61220, lr = 0.01
I0523 06:18:59.722229 34819 solver.cpp:239] Iteration 61230 (2.7027 iter/s, 3.70001s/10 iters), loss = 8.99948
I0523 06:18:59.722271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99948 (* 1 = 8.99948 loss)
I0523 06:18:59.794212 34819 sgd_solver.cpp:112] Iteration 61230, lr = 0.01
I0523 06:19:04.672341 34819 solver.cpp:239] Iteration 61240 (2.02026 iter/s, 4.94986s/10 iters), loss = 7.70225
I0523 06:19:04.672382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70225 (* 1 = 7.70225 loss)
I0523 06:19:04.744110 34819 sgd_solver.cpp:112] Iteration 61240, lr = 0.01
I0523 06:19:09.634790 34819 solver.cpp:239] Iteration 61250 (2.01524 iter/s, 4.96219s/10 iters), loss = 7.31258
I0523 06:19:09.634830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.31258 (* 1 = 7.31258 loss)
I0523 06:19:09.703430 34819 sgd_solver.cpp:112] Iteration 61250, lr = 0.01
I0523 06:19:12.232385 34819 solver.cpp:239] Iteration 61260 (3.84996 iter/s, 2.59743s/10 iters), loss = 8.82806
I0523 06:19:12.232514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82806 (* 1 = 8.82806 loss)
I0523 06:19:12.295264 34819 sgd_solver.cpp:112] Iteration 61260, lr = 0.01
I0523 06:19:17.152232 34819 solver.cpp:239] Iteration 61270 (2.03272 iter/s, 4.91951s/10 iters), loss = 8.01073
I0523 06:19:17.152273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01073 (* 1 = 8.01073 loss)
I0523 06:19:17.228560 34819 sgd_solver.cpp:112] Iteration 61270, lr = 0.01
I0523 06:19:23.283833 34819 solver.cpp:239] Iteration 61280 (1.63098 iter/s, 6.1313s/10 iters), loss = 8.30936
I0523 06:19:23.283887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30936 (* 1 = 8.30936 loss)
I0523 06:19:23.354048 34819 sgd_solver.cpp:112] Iteration 61280, lr = 0.01
I0523 06:19:28.277499 34819 solver.cpp:239] Iteration 61290 (2.00264 iter/s, 4.9934s/10 iters), loss = 7.76029
I0523 06:19:28.277539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76029 (* 1 = 7.76029 loss)
I0523 06:19:29.149443 34819 sgd_solver.cpp:112] Iteration 61290, lr = 0.01
I0523 06:19:33.969645 34819 solver.cpp:239] Iteration 61300 (1.75689 iter/s, 5.69186s/10 iters), loss = 8.44301
I0523 06:19:33.969686 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44301 (* 1 = 8.44301 loss)
I0523 06:19:34.783463 34819 sgd_solver.cpp:112] Iteration 61300, lr = 0.01
I0523 06:19:38.080801 34819 solver.cpp:239] Iteration 61310 (2.43254 iter/s, 4.11093s/10 iters), loss = 8.81026
I0523 06:19:38.080873 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81026 (* 1 = 8.81026 loss)
I0523 06:19:38.889688 34819 sgd_solver.cpp:112] Iteration 61310, lr = 0.01
I0523 06:19:44.669931 34819 solver.cpp:239] Iteration 61320 (1.51773 iter/s, 6.58877s/10 iters), loss = 8.12432
I0523 06:19:44.670079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12432 (* 1 = 8.12432 loss)
I0523 06:19:45.475153 34819 sgd_solver.cpp:112] Iteration 61320, lr = 0.01
I0523 06:19:49.196384 34819 solver.cpp:239] Iteration 61330 (2.20941 iter/s, 4.5261s/10 iters), loss = 8.76946
I0523 06:19:49.196449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76946 (* 1 = 8.76946 loss)
I0523 06:19:49.265853 34819 sgd_solver.cpp:112] Iteration 61330, lr = 0.01
I0523 06:19:55.906744 34819 solver.cpp:239] Iteration 61340 (1.49031 iter/s, 6.71002s/10 iters), loss = 7.51882
I0523 06:19:55.906800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51882 (* 1 = 7.51882 loss)
I0523 06:19:56.459939 34819 sgd_solver.cpp:112] Iteration 61340, lr = 0.01
I0523 06:20:00.925117 34819 solver.cpp:239] Iteration 61350 (1.99279 iter/s, 5.0181s/10 iters), loss = 8.32121
I0523 06:20:00.925173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32121 (* 1 = 8.32121 loss)
I0523 06:20:01.597568 34819 sgd_solver.cpp:112] Iteration 61350, lr = 0.01
I0523 06:20:05.513712 34819 solver.cpp:239] Iteration 61360 (2.17943 iter/s, 4.58835s/10 iters), loss = 8.6664
I0523 06:20:05.513758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6664 (* 1 = 8.6664 loss)
I0523 06:20:05.602603 34819 sgd_solver.cpp:112] Iteration 61360, lr = 0.01
I0523 06:20:08.880230 34819 solver.cpp:239] Iteration 61370 (2.97061 iter/s, 3.36631s/10 iters), loss = 8.60307
I0523 06:20:08.880295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60307 (* 1 = 8.60307 loss)
I0523 06:20:09.757483 34819 sgd_solver.cpp:112] Iteration 61370, lr = 0.01
I0523 06:20:15.221505 34819 solver.cpp:239] Iteration 61380 (1.57705 iter/s, 6.34095s/10 iters), loss = 7.88171
I0523 06:20:15.221730 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88171 (* 1 = 7.88171 loss)
I0523 06:20:15.278561 34819 sgd_solver.cpp:112] Iteration 61380, lr = 0.01
I0523 06:20:20.115803 34819 solver.cpp:239] Iteration 61390 (2.04336 iter/s, 4.89389s/10 iters), loss = 8.64829
I0523 06:20:20.115849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64829 (* 1 = 8.64829 loss)
I0523 06:20:20.377459 34819 sgd_solver.cpp:112] Iteration 61390, lr = 0.01
I0523 06:20:24.518806 34819 solver.cpp:239] Iteration 61400 (2.2713 iter/s, 4.40277s/10 iters), loss = 8.38046
I0523 06:20:24.518858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38046 (* 1 = 8.38046 loss)
I0523 06:20:25.290783 34819 sgd_solver.cpp:112] Iteration 61400, lr = 0.01
I0523 06:20:30.011643 34819 solver.cpp:239] Iteration 61410 (1.82064 iter/s, 5.49256s/10 iters), loss = 8.25359
I0523 06:20:30.011687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25359 (* 1 = 8.25359 loss)
I0523 06:20:30.852232 34819 sgd_solver.cpp:112] Iteration 61410, lr = 0.01
I0523 06:20:35.104607 34819 solver.cpp:239] Iteration 61420 (1.9636 iter/s, 5.09268s/10 iters), loss = 7.78286
I0523 06:20:35.104658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78286 (* 1 = 7.78286 loss)
I0523 06:20:35.943825 34819 sgd_solver.cpp:112] Iteration 61420, lr = 0.01
I0523 06:20:38.449522 34819 solver.cpp:239] Iteration 61430 (2.98979 iter/s, 3.34472s/10 iters), loss = 9.0762
I0523 06:20:38.449564 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.0762 (* 1 = 9.0762 loss)
I0523 06:20:38.525645 34819 sgd_solver.cpp:112] Iteration 61430, lr = 0.01
I0523 06:20:42.533020 34819 solver.cpp:239] Iteration 61440 (2.44901 iter/s, 4.08327s/10 iters), loss = 7.60199
I0523 06:20:42.533073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60199 (* 1 = 7.60199 loss)
I0523 06:20:43.336513 34819 sgd_solver.cpp:112] Iteration 61440, lr = 0.01
I0523 06:20:46.719568 34819 solver.cpp:239] Iteration 61450 (2.38873 iter/s, 4.18632s/10 iters), loss = 8.72929
I0523 06:20:46.719668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72929 (* 1 = 8.72929 loss)
I0523 06:20:46.793990 34819 sgd_solver.cpp:112] Iteration 61450, lr = 0.01
I0523 06:20:51.851389 34819 solver.cpp:239] Iteration 61460 (1.94875 iter/s, 5.13151s/10 iters), loss = 8.3011
I0523 06:20:51.851442 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3011 (* 1 = 8.3011 loss)
I0523 06:20:52.651760 34819 sgd_solver.cpp:112] Iteration 61460, lr = 0.01
I0523 06:20:57.515849 34819 solver.cpp:239] Iteration 61470 (1.76549 iter/s, 5.66416s/10 iters), loss = 9.32469
I0523 06:20:57.515902 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32469 (* 1 = 9.32469 loss)
I0523 06:20:57.581652 34819 sgd_solver.cpp:112] Iteration 61470, lr = 0.01
I0523 06:21:02.436362 34819 solver.cpp:239] Iteration 61480 (2.03243 iter/s, 4.92022s/10 iters), loss = 7.7641
I0523 06:21:02.436410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7641 (* 1 = 7.7641 loss)
I0523 06:21:02.636159 34819 sgd_solver.cpp:112] Iteration 61480, lr = 0.01
I0523 06:21:06.913110 34819 solver.cpp:239] Iteration 61490 (2.23389 iter/s, 4.4765s/10 iters), loss = 8.09184
I0523 06:21:06.913166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09184 (* 1 = 8.09184 loss)
I0523 06:21:06.984587 34819 sgd_solver.cpp:112] Iteration 61490, lr = 0.01
I0523 06:21:12.775050 34819 solver.cpp:239] Iteration 61500 (1.70601 iter/s, 5.86165s/10 iters), loss = 7.95302
I0523 06:21:12.775100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95302 (* 1 = 7.95302 loss)
I0523 06:21:12.833330 34819 sgd_solver.cpp:112] Iteration 61500, lr = 0.01
I0523 06:21:15.881083 34819 solver.cpp:239] Iteration 61510 (3.21974 iter/s, 3.10584s/10 iters), loss = 8.29883
I0523 06:21:15.881145 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29883 (* 1 = 8.29883 loss)
I0523 06:21:16.555634 34819 sgd_solver.cpp:112] Iteration 61510, lr = 0.01
I0523 06:21:21.485460 34819 solver.cpp:239] Iteration 61520 (1.78441 iter/s, 5.60409s/10 iters), loss = 7.84139
I0523 06:21:21.485656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84139 (* 1 = 7.84139 loss)
I0523 06:21:21.568073 34819 sgd_solver.cpp:112] Iteration 61520, lr = 0.01
I0523 06:21:27.270248 34819 solver.cpp:239] Iteration 61530 (1.7288 iter/s, 5.78436s/10 iters), loss = 8.08371
I0523 06:21:27.270301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08371 (* 1 = 8.08371 loss)
I0523 06:21:27.348153 34819 sgd_solver.cpp:112] Iteration 61530, lr = 0.01
I0523 06:21:33.101629 34819 solver.cpp:239] Iteration 61540 (1.71495 iter/s, 5.83108s/10 iters), loss = 8.0788
I0523 06:21:33.101685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0788 (* 1 = 8.0788 loss)
I0523 06:21:33.170604 34819 sgd_solver.cpp:112] Iteration 61540, lr = 0.01
I0523 06:21:37.591727 34819 solver.cpp:239] Iteration 61550 (2.22724 iter/s, 4.48985s/10 iters), loss = 8.56923
I0523 06:21:37.591775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56923 (* 1 = 8.56923 loss)
I0523 06:21:37.648144 34819 sgd_solver.cpp:112] Iteration 61550, lr = 0.01
I0523 06:21:41.240239 34819 solver.cpp:239] Iteration 61560 (2.741 iter/s, 3.64831s/10 iters), loss = 8.74007
I0523 06:21:41.240283 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74007 (* 1 = 8.74007 loss)
I0523 06:21:41.328548 34819 sgd_solver.cpp:112] Iteration 61560, lr = 0.01
I0523 06:21:46.795845 34819 solver.cpp:239] Iteration 61570 (1.80007 iter/s, 5.55532s/10 iters), loss = 8.71021
I0523 06:21:46.795887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71021 (* 1 = 8.71021 loss)
I0523 06:21:46.868547 34819 sgd_solver.cpp:112] Iteration 61570, lr = 0.01
I0523 06:21:49.812240 34819 solver.cpp:239] Iteration 61580 (3.31543 iter/s, 3.0162s/10 iters), loss = 8.41348
I0523 06:21:49.812306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41348 (* 1 = 8.41348 loss)
I0523 06:21:49.898198 34819 sgd_solver.cpp:112] Iteration 61580, lr = 0.01
I0523 06:21:54.809686 34819 solver.cpp:239] Iteration 61590 (2.00113 iter/s, 4.99717s/10 iters), loss = 8.58568
I0523 06:21:54.809844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58568 (* 1 = 8.58568 loss)
I0523 06:21:54.877883 34819 sgd_solver.cpp:112] Iteration 61590, lr = 0.01
I0523 06:21:59.359902 34819 solver.cpp:239] Iteration 61600 (2.19787 iter/s, 4.54987s/10 iters), loss = 8.02374
I0523 06:21:59.359944 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02374 (* 1 = 8.02374 loss)
I0523 06:22:00.199177 34819 sgd_solver.cpp:112] Iteration 61600, lr = 0.01
I0523 06:22:04.983940 34819 solver.cpp:239] Iteration 61610 (1.77817 iter/s, 5.62376s/10 iters), loss = 8.50556
I0523 06:22:04.983989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50556 (* 1 = 8.50556 loss)
I0523 06:22:05.850162 34819 sgd_solver.cpp:112] Iteration 61610, lr = 0.01
I0523 06:22:12.217944 34819 solver.cpp:239] Iteration 61620 (1.38243 iter/s, 7.23366s/10 iters), loss = 8.86235
I0523 06:22:12.217989 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86235 (* 1 = 8.86235 loss)
I0523 06:22:13.010102 34819 sgd_solver.cpp:112] Iteration 61620, lr = 0.01
I0523 06:22:20.133107 34819 solver.cpp:239] Iteration 61630 (1.26346 iter/s, 7.91479s/10 iters), loss = 8.56888
I0523 06:22:20.133162 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56888 (* 1 = 8.56888 loss)
I0523 06:22:20.199226 34819 sgd_solver.cpp:112] Iteration 61630, lr = 0.01
I0523 06:22:24.814105 34819 solver.cpp:239] Iteration 61640 (2.13641 iter/s, 4.68075s/10 iters), loss = 8.22352
I0523 06:22:24.814389 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22352 (* 1 = 8.22352 loss)
I0523 06:22:25.344414 34819 sgd_solver.cpp:112] Iteration 61640, lr = 0.01
I0523 06:22:29.463781 34819 solver.cpp:239] Iteration 61650 (2.1509 iter/s, 4.64923s/10 iters), loss = 8.92604
I0523 06:22:29.463834 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92604 (* 1 = 8.92604 loss)
I0523 06:22:29.517462 34819 sgd_solver.cpp:112] Iteration 61650, lr = 0.01
I0523 06:22:35.699396 34819 solver.cpp:239] Iteration 61660 (1.60377 iter/s, 6.23529s/10 iters), loss = 7.847
I0523 06:22:35.699451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.847 (* 1 = 7.847 loss)
I0523 06:22:36.574771 34819 sgd_solver.cpp:112] Iteration 61660, lr = 0.01
I0523 06:22:40.871889 34819 solver.cpp:239] Iteration 61670 (1.93341 iter/s, 5.17222s/10 iters), loss = 7.64608
I0523 06:22:40.871949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64608 (* 1 = 7.64608 loss)
I0523 06:22:41.659497 34819 sgd_solver.cpp:112] Iteration 61670, lr = 0.01
I0523 06:22:46.300433 34819 solver.cpp:239] Iteration 61680 (1.84221 iter/s, 5.42825s/10 iters), loss = 7.79034
I0523 06:22:46.300485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79034 (* 1 = 7.79034 loss)
I0523 06:22:46.843617 34819 sgd_solver.cpp:112] Iteration 61680, lr = 0.01
I0523 06:22:50.098008 34819 solver.cpp:239] Iteration 61690 (2.63341 iter/s, 3.79736s/10 iters), loss = 8.28243
I0523 06:22:50.098065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28243 (* 1 = 8.28243 loss)
I0523 06:22:50.884156 34819 sgd_solver.cpp:112] Iteration 61690, lr = 0.01
I0523 06:22:55.575759 34819 solver.cpp:239] Iteration 61700 (1.82566 iter/s, 5.47746s/10 iters), loss = 7.93661
I0523 06:22:55.575970 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93661 (* 1 = 7.93661 loss)
I0523 06:22:56.281447 34819 sgd_solver.cpp:112] Iteration 61700, lr = 0.01
I0523 06:22:59.398002 34819 solver.cpp:239] Iteration 61710 (2.6165 iter/s, 3.8219s/10 iters), loss = 8.72705
I0523 06:22:59.398043 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72705 (* 1 = 8.72705 loss)
I0523 06:23:00.049458 34819 sgd_solver.cpp:112] Iteration 61710, lr = 0.01
I0523 06:23:02.232878 34819 solver.cpp:239] Iteration 61720 (3.5277 iter/s, 2.83471s/10 iters), loss = 7.91213
I0523 06:23:02.232934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91213 (* 1 = 7.91213 loss)
I0523 06:23:03.002061 34819 sgd_solver.cpp:112] Iteration 61720, lr = 0.01
I0523 06:23:07.270638 34819 solver.cpp:239] Iteration 61730 (1.98512 iter/s, 5.03747s/10 iters), loss = 8.43876
I0523 06:23:07.270692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43876 (* 1 = 8.43876 loss)
I0523 06:23:08.038255 34819 sgd_solver.cpp:112] Iteration 61730, lr = 0.01
I0523 06:23:12.753283 34819 solver.cpp:239] Iteration 61740 (1.82403 iter/s, 5.48237s/10 iters), loss = 8.66746
I0523 06:23:12.753324 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66746 (* 1 = 8.66746 loss)
I0523 06:23:13.598587 34819 sgd_solver.cpp:112] Iteration 61740, lr = 0.01
I0523 06:23:17.043854 34819 solver.cpp:239] Iteration 61750 (2.33081 iter/s, 4.29035s/10 iters), loss = 7.53583
I0523 06:23:17.043910 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53583 (* 1 = 7.53583 loss)
I0523 06:23:17.746444 34819 sgd_solver.cpp:112] Iteration 61750, lr = 0.01
I0523 06:23:21.594970 34819 solver.cpp:239] Iteration 61760 (2.19738 iter/s, 4.55087s/10 iters), loss = 7.28118
I0523 06:23:21.595021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28118 (* 1 = 7.28118 loss)
I0523 06:23:22.410814 34819 sgd_solver.cpp:112] Iteration 61760, lr = 0.01
I0523 06:23:26.571207 34819 solver.cpp:239] Iteration 61770 (2.00966 iter/s, 4.97596s/10 iters), loss = 8.44015
I0523 06:23:26.571363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44015 (* 1 = 8.44015 loss)
I0523 06:23:27.423578 34819 sgd_solver.cpp:112] Iteration 61770, lr = 0.01
I0523 06:23:30.935696 34819 solver.cpp:239] Iteration 61780 (2.2914 iter/s, 4.36415s/10 iters), loss = 8.11393
I0523 06:23:30.935739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11393 (* 1 = 8.11393 loss)
I0523 06:23:31.008585 34819 sgd_solver.cpp:112] Iteration 61780, lr = 0.01
I0523 06:23:34.225492 34819 solver.cpp:239] Iteration 61790 (3.03988 iter/s, 3.28961s/10 iters), loss = 9.31996
I0523 06:23:34.225543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.31996 (* 1 = 9.31996 loss)
I0523 06:23:34.296458 34819 sgd_solver.cpp:112] Iteration 61790, lr = 0.01
I0523 06:23:36.898088 34819 solver.cpp:239] Iteration 61800 (3.74193 iter/s, 2.67242s/10 iters), loss = 8.95749
I0523 06:23:36.898128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95749 (* 1 = 8.95749 loss)
I0523 06:23:36.972609 34819 sgd_solver.cpp:112] Iteration 61800, lr = 0.01
I0523 06:23:40.279157 34819 solver.cpp:239] Iteration 61810 (2.95782 iter/s, 3.38087s/10 iters), loss = 8.2419
I0523 06:23:40.279227 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2419 (* 1 = 8.2419 loss)
I0523 06:23:41.142153 34819 sgd_solver.cpp:112] Iteration 61810, lr = 0.01
I0523 06:23:45.364756 34819 solver.cpp:239] Iteration 61820 (1.96644 iter/s, 5.08532s/10 iters), loss = 7.99987
I0523 06:23:45.364799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99987 (* 1 = 7.99987 loss)
I0523 06:23:46.011844 34819 sgd_solver.cpp:112] Iteration 61820, lr = 0.01
I0523 06:23:51.232165 34819 solver.cpp:239] Iteration 61830 (1.70441 iter/s, 5.86712s/10 iters), loss = 8.40882
I0523 06:23:51.232223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40882 (* 1 = 8.40882 loss)
I0523 06:23:51.621929 34819 sgd_solver.cpp:112] Iteration 61830, lr = 0.01
I0523 06:23:56.270473 34819 solver.cpp:239] Iteration 61840 (1.98491 iter/s, 5.03801s/10 iters), loss = 8.90206
I0523 06:23:56.270527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.90206 (* 1 = 8.90206 loss)
I0523 06:23:56.409714 34819 sgd_solver.cpp:112] Iteration 61840, lr = 0.01
I0523 06:24:02.349408 34819 solver.cpp:239] Iteration 61850 (1.64511 iter/s, 6.07863s/10 iters), loss = 7.55858
I0523 06:24:02.349512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55858 (* 1 = 7.55858 loss)
I0523 06:24:03.237776 34819 sgd_solver.cpp:112] Iteration 61850, lr = 0.01
I0523 06:24:08.158112 34819 solver.cpp:239] Iteration 61860 (1.72166 iter/s, 5.80836s/10 iters), loss = 7.90185
I0523 06:24:08.158161 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90185 (* 1 = 7.90185 loss)
I0523 06:24:08.979487 34819 sgd_solver.cpp:112] Iteration 61860, lr = 0.01
I0523 06:24:12.381299 34819 solver.cpp:239] Iteration 61870 (2.36801 iter/s, 4.22296s/10 iters), loss = 8.2791
I0523 06:24:12.381353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2791 (* 1 = 8.2791 loss)
I0523 06:24:12.446599 34819 sgd_solver.cpp:112] Iteration 61870, lr = 0.01
I0523 06:24:17.443320 34819 solver.cpp:239] Iteration 61880 (1.9756 iter/s, 5.06176s/10 iters), loss = 7.83286
I0523 06:24:17.443369 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83286 (* 1 = 7.83286 loss)
I0523 06:24:17.519507 34819 sgd_solver.cpp:112] Iteration 61880, lr = 0.01
I0523 06:24:22.001829 34819 solver.cpp:239] Iteration 61890 (2.19382 iter/s, 4.55826s/10 iters), loss = 8.78498
I0523 06:24:22.001878 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78498 (* 1 = 8.78498 loss)
I0523 06:24:22.901305 34819 sgd_solver.cpp:112] Iteration 61890, lr = 0.01
I0523 06:24:27.825899 34819 solver.cpp:239] Iteration 61900 (1.7171 iter/s, 5.82378s/10 iters), loss = 8.39151
I0523 06:24:27.825949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39151 (* 1 = 8.39151 loss)
I0523 06:24:27.881079 34819 sgd_solver.cpp:112] Iteration 61900, lr = 0.01
I0523 06:24:32.124006 34819 solver.cpp:239] Iteration 61910 (2.32674 iter/s, 4.29787s/10 iters), loss = 9.51389
I0523 06:24:32.124068 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.51389 (* 1 = 9.51389 loss)
I0523 06:24:32.828784 34819 sgd_solver.cpp:112] Iteration 61910, lr = 0.01
I0523 06:24:36.233275 34819 solver.cpp:239] Iteration 61920 (2.43367 iter/s, 4.10902s/10 iters), loss = 7.82034
I0523 06:24:36.233322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82034 (* 1 = 7.82034 loss)
I0523 06:24:36.982463 34819 sgd_solver.cpp:112] Iteration 61920, lr = 0.01
I0523 06:24:43.525207 34819 solver.cpp:239] Iteration 61930 (1.37144 iter/s, 7.29159s/10 iters), loss = 8.82147
I0523 06:24:43.525249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82147 (* 1 = 8.82147 loss)
I0523 06:24:43.724793 34819 sgd_solver.cpp:112] Iteration 61930, lr = 0.01
I0523 06:24:47.867128 34819 solver.cpp:239] Iteration 61940 (2.30325 iter/s, 4.3417s/10 iters), loss = 7.54524
I0523 06:24:47.867171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54524 (* 1 = 7.54524 loss)
I0523 06:24:48.084637 34819 sgd_solver.cpp:112] Iteration 61940, lr = 0.01
I0523 06:24:53.855332 34819 solver.cpp:239] Iteration 61950 (1.67003 iter/s, 5.98791s/10 iters), loss = 7.20345
I0523 06:24:53.855377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20345 (* 1 = 7.20345 loss)
I0523 06:24:53.916540 34819 sgd_solver.cpp:112] Iteration 61950, lr = 0.01
I0523 06:25:00.353919 34819 solver.cpp:239] Iteration 61960 (1.53887 iter/s, 6.49827s/10 iters), loss = 7.62912
I0523 06:25:00.353957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62912 (* 1 = 7.62912 loss)
I0523 06:25:00.425245 34819 sgd_solver.cpp:112] Iteration 61960, lr = 0.01
I0523 06:25:05.345201 34819 solver.cpp:239] Iteration 61970 (2.00359 iter/s, 4.99103s/10 iters), loss = 8.67925
I0523 06:25:05.345410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67925 (* 1 = 8.67925 loss)
I0523 06:25:05.415128 34819 sgd_solver.cpp:112] Iteration 61970, lr = 0.01
I0523 06:25:09.148511 34819 solver.cpp:239] Iteration 61980 (2.62953 iter/s, 3.80296s/10 iters), loss = 6.51367
I0523 06:25:09.148551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.51367 (* 1 = 6.51367 loss)
I0523 06:25:09.221005 34819 sgd_solver.cpp:112] Iteration 61980, lr = 0.01
I0523 06:25:11.589251 34819 solver.cpp:239] Iteration 61990 (4.09737 iter/s, 2.44059s/10 iters), loss = 7.3703
I0523 06:25:11.589293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3703 (* 1 = 7.3703 loss)
I0523 06:25:12.394126 34819 sgd_solver.cpp:112] Iteration 61990, lr = 0.01
I0523 06:25:15.906335 34819 solver.cpp:239] Iteration 62000 (2.3165 iter/s, 4.31685s/10 iters), loss = 9.84387
I0523 06:25:15.906374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.84387 (* 1 = 9.84387 loss)
I0523 06:25:15.979506 34819 sgd_solver.cpp:112] Iteration 62000, lr = 0.01
I0523 06:25:19.392671 34819 solver.cpp:239] Iteration 62010 (2.8685 iter/s, 3.48614s/10 iters), loss = 7.85585
I0523 06:25:19.392712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85585 (* 1 = 7.85585 loss)
I0523 06:25:19.465626 34819 sgd_solver.cpp:112] Iteration 62010, lr = 0.01
I0523 06:25:23.354447 34819 solver.cpp:239] Iteration 62020 (2.52426 iter/s, 3.96156s/10 iters), loss = 8.3051
I0523 06:25:23.354490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3051 (* 1 = 8.3051 loss)
I0523 06:25:23.424125 34819 sgd_solver.cpp:112] Iteration 62020, lr = 0.01
I0523 06:25:28.336788 34819 solver.cpp:239] Iteration 62030 (2.0072 iter/s, 4.98207s/10 iters), loss = 7.90559
I0523 06:25:28.336841 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90559 (* 1 = 7.90559 loss)
I0523 06:25:28.403167 34819 sgd_solver.cpp:112] Iteration 62030, lr = 0.01
I0523 06:25:32.578204 34819 solver.cpp:239] Iteration 62040 (2.35783 iter/s, 4.24118s/10 iters), loss = 8.32187
I0523 06:25:32.578245 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32187 (* 1 = 8.32187 loss)
I0523 06:25:33.362812 34819 sgd_solver.cpp:112] Iteration 62040, lr = 0.01
I0523 06:25:37.305232 34819 solver.cpp:239] Iteration 62050 (2.1156 iter/s, 4.72679s/10 iters), loss = 8.43504
I0523 06:25:37.305374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43504 (* 1 = 8.43504 loss)
I0523 06:25:38.181414 34819 sgd_solver.cpp:112] Iteration 62050, lr = 0.01
I0523 06:25:42.282722 34819 solver.cpp:239] Iteration 62060 (2.0092 iter/s, 4.97712s/10 iters), loss = 8.4872
I0523 06:25:42.282779 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4872 (* 1 = 8.4872 loss)
I0523 06:25:42.342229 34819 sgd_solver.cpp:112] Iteration 62060, lr = 0.01
I0523 06:25:46.285588 34819 solver.cpp:239] Iteration 62070 (2.49836 iter/s, 4.00263s/10 iters), loss = 8.46806
I0523 06:25:46.285629 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46806 (* 1 = 8.46806 loss)
I0523 06:25:46.400588 34819 sgd_solver.cpp:112] Iteration 62070, lr = 0.01
I0523 06:25:51.529523 34819 solver.cpp:239] Iteration 62080 (1.90706 iter/s, 5.24368s/10 iters), loss = 8.53194
I0523 06:25:51.529578 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53194 (* 1 = 8.53194 loss)
I0523 06:25:51.597332 34819 sgd_solver.cpp:112] Iteration 62080, lr = 0.01
I0523 06:25:56.187798 34819 solver.cpp:239] Iteration 62090 (2.14683 iter/s, 4.65803s/10 iters), loss = 8.00029
I0523 06:25:56.187842 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00029 (* 1 = 8.00029 loss)
I0523 06:25:56.262326 34819 sgd_solver.cpp:112] Iteration 62090, lr = 0.01
I0523 06:26:00.299352 34819 solver.cpp:239] Iteration 62100 (2.43231 iter/s, 4.11132s/10 iters), loss = 8.15025
I0523 06:26:00.299404 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15025 (* 1 = 8.15025 loss)
I0523 06:26:00.369818 34819 sgd_solver.cpp:112] Iteration 62100, lr = 0.01
I0523 06:26:06.471850 34819 solver.cpp:239] Iteration 62110 (1.62017 iter/s, 6.17218s/10 iters), loss = 8.35777
I0523 06:26:06.471922 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35777 (* 1 = 8.35777 loss)
I0523 06:26:07.159308 34819 sgd_solver.cpp:112] Iteration 62110, lr = 0.01
I0523 06:26:12.101932 34819 solver.cpp:239] Iteration 62120 (1.77627 iter/s, 5.62976s/10 iters), loss = 7.56546
I0523 06:26:12.102134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56546 (* 1 = 7.56546 loss)
I0523 06:26:12.962405 34819 sgd_solver.cpp:112] Iteration 62120, lr = 0.01
I0523 06:26:19.222270 34819 solver.cpp:239] Iteration 62130 (1.40452 iter/s, 7.11987s/10 iters), loss = 8.28061
I0523 06:26:19.222313 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28061 (* 1 = 8.28061 loss)
I0523 06:26:19.889888 34819 sgd_solver.cpp:112] Iteration 62130, lr = 0.01
I0523 06:26:23.134224 34819 solver.cpp:239] Iteration 62140 (2.55641 iter/s, 3.91173s/10 iters), loss = 8.20796
I0523 06:26:23.134275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20796 (* 1 = 8.20796 loss)
I0523 06:26:23.194046 34819 sgd_solver.cpp:112] Iteration 62140, lr = 0.01
I0523 06:26:26.515450 34819 solver.cpp:239] Iteration 62150 (2.95768 iter/s, 3.38102s/10 iters), loss = 8.13936
I0523 06:26:26.515501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13936 (* 1 = 8.13936 loss)
I0523 06:26:26.571347 34819 sgd_solver.cpp:112] Iteration 62150, lr = 0.01
I0523 06:26:33.029634 34819 solver.cpp:239] Iteration 62160 (1.53519 iter/s, 6.51386s/10 iters), loss = 7.71735
I0523 06:26:33.029675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71735 (* 1 = 7.71735 loss)
I0523 06:26:33.088050 34819 sgd_solver.cpp:112] Iteration 62160, lr = 0.01
I0523 06:26:37.461982 34819 solver.cpp:239] Iteration 62170 (2.25626 iter/s, 4.43212s/10 iters), loss = 8.05019
I0523 06:26:37.462034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05019 (* 1 = 8.05019 loss)
I0523 06:26:37.530838 34819 sgd_solver.cpp:112] Iteration 62170, lr = 0.01
I0523 06:26:42.015897 34819 solver.cpp:239] Iteration 62180 (2.19603 iter/s, 4.55367s/10 iters), loss = 8.59274
I0523 06:26:42.015946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59274 (* 1 = 8.59274 loss)
I0523 06:26:42.077875 34819 sgd_solver.cpp:112] Iteration 62180, lr = 0.01
I0523 06:26:47.090421 34819 solver.cpp:239] Iteration 62190 (1.97073 iter/s, 5.07426s/10 iters), loss = 8.29427
I0523 06:26:47.090584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29427 (* 1 = 8.29427 loss)
I0523 06:26:47.944178 34819 sgd_solver.cpp:112] Iteration 62190, lr = 0.01
I0523 06:26:53.806870 34819 solver.cpp:239] Iteration 62200 (1.48898 iter/s, 6.716s/10 iters), loss = 7.45327
I0523 06:26:53.806936 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.45327 (* 1 = 7.45327 loss)
I0523 06:26:54.661825 34819 sgd_solver.cpp:112] Iteration 62200, lr = 0.01
I0523 06:26:59.833284 34819 solver.cpp:239] Iteration 62210 (1.65945 iter/s, 6.02611s/10 iters), loss = 8.14731
I0523 06:26:59.833335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14731 (* 1 = 8.14731 loss)
I0523 06:26:59.906966 34819 sgd_solver.cpp:112] Iteration 62210, lr = 0.01
I0523 06:27:03.595609 34819 solver.cpp:239] Iteration 62220 (2.65808 iter/s, 3.76211s/10 iters), loss = 7.72231
I0523 06:27:03.595657 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72231 (* 1 = 7.72231 loss)
I0523 06:27:03.658903 34819 sgd_solver.cpp:112] Iteration 62220, lr = 0.01
I0523 06:27:07.989583 34819 solver.cpp:239] Iteration 62230 (2.27597 iter/s, 4.39374s/10 iters), loss = 7.89256
I0523 06:27:07.989636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89256 (* 1 = 7.89256 loss)
I0523 06:27:08.804368 34819 sgd_solver.cpp:112] Iteration 62230, lr = 0.01
I0523 06:27:13.712352 34819 solver.cpp:239] Iteration 62240 (1.7475 iter/s, 5.72247s/10 iters), loss = 8.45893
I0523 06:27:13.712405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45893 (* 1 = 8.45893 loss)
I0523 06:27:13.777081 34819 sgd_solver.cpp:112] Iteration 62240, lr = 0.01
I0523 06:27:18.776265 34819 solver.cpp:239] Iteration 62250 (1.97486 iter/s, 5.06365s/10 iters), loss = 7.89439
I0523 06:27:18.776403 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89439 (* 1 = 7.89439 loss)
I0523 06:27:18.851833 34819 sgd_solver.cpp:112] Iteration 62250, lr = 0.01
I0523 06:27:24.628648 34819 solver.cpp:239] Iteration 62260 (1.70882 iter/s, 5.85201s/10 iters), loss = 8.21294
I0523 06:27:24.628701 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21294 (* 1 = 8.21294 loss)
I0523 06:27:24.702286 34819 sgd_solver.cpp:112] Iteration 62260, lr = 0.01
I0523 06:27:27.616081 34819 solver.cpp:239] Iteration 62270 (3.34755 iter/s, 2.98725s/10 iters), loss = 8.31727
I0523 06:27:27.616124 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31727 (* 1 = 8.31727 loss)
I0523 06:27:27.684284 34819 sgd_solver.cpp:112] Iteration 62270, lr = 0.01
I0523 06:27:33.230402 34819 solver.cpp:239] Iteration 62280 (1.78125 iter/s, 5.61403s/10 iters), loss = 8.33873
I0523 06:27:33.230456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33873 (* 1 = 8.33873 loss)
I0523 06:27:33.310722 34819 sgd_solver.cpp:112] Iteration 62280, lr = 0.01
I0523 06:27:39.009279 34819 solver.cpp:239] Iteration 62290 (1.73053 iter/s, 5.77858s/10 iters), loss = 8.123
I0523 06:27:39.009333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.123 (* 1 = 8.123 loss)
I0523 06:27:39.153365 34819 sgd_solver.cpp:112] Iteration 62290, lr = 0.01
I0523 06:27:43.991854 34819 solver.cpp:239] Iteration 62300 (2.0071 iter/s, 4.98232s/10 iters), loss = 8.16767
I0523 06:27:43.991896 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16767 (* 1 = 8.16767 loss)
I0523 06:27:44.831714 34819 sgd_solver.cpp:112] Iteration 62300, lr = 0.01
I0523 06:27:50.533413 34819 solver.cpp:239] Iteration 62310 (1.52876 iter/s, 6.54123s/10 iters), loss = 8.07567
I0523 06:27:50.533668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07567 (* 1 = 8.07567 loss)
I0523 06:27:51.311497 34819 sgd_solver.cpp:112] Iteration 62310, lr = 0.01
I0523 06:27:55.666005 34819 solver.cpp:239] Iteration 62320 (1.9485 iter/s, 5.13214s/10 iters), loss = 8.58658
I0523 06:27:55.666048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58658 (* 1 = 8.58658 loss)
I0523 06:27:56.483340 34819 sgd_solver.cpp:112] Iteration 62320, lr = 0.01
I0523 06:28:01.256999 34819 solver.cpp:239] Iteration 62330 (1.78868 iter/s, 5.59072s/10 iters), loss = 8.73978
I0523 06:28:01.257056 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73978 (* 1 = 8.73978 loss)
I0523 06:28:02.096904 34819 sgd_solver.cpp:112] Iteration 62330, lr = 0.01
I0523 06:28:06.284478 34819 solver.cpp:239] Iteration 62340 (1.98917 iter/s, 5.02721s/10 iters), loss = 8.09348
I0523 06:28:06.284533 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09348 (* 1 = 8.09348 loss)
I0523 06:28:06.370141 34819 sgd_solver.cpp:112] Iteration 62340, lr = 0.01
I0523 06:28:13.009371 34819 solver.cpp:239] Iteration 62350 (1.48709 iter/s, 6.72456s/10 iters), loss = 8.39925
I0523 06:28:13.009425 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39925 (* 1 = 8.39925 loss)
I0523 06:28:13.776496 34819 sgd_solver.cpp:112] Iteration 62350, lr = 0.01
I0523 06:28:16.519882 34819 solver.cpp:239] Iteration 62360 (2.84875 iter/s, 3.51031s/10 iters), loss = 8.22388
I0523 06:28:16.519939 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22388 (* 1 = 8.22388 loss)
I0523 06:28:16.587637 34819 sgd_solver.cpp:112] Iteration 62360, lr = 0.01
I0523 06:28:21.563153 34819 solver.cpp:239] Iteration 62370 (1.98295 iter/s, 5.04299s/10 iters), loss = 8.00315
I0523 06:28:21.563371 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00315 (* 1 = 8.00315 loss)
I0523 06:28:21.618911 34819 sgd_solver.cpp:112] Iteration 62370, lr = 0.01
I0523 06:28:25.202482 34819 solver.cpp:239] Iteration 62380 (2.74802 iter/s, 3.63898s/10 iters), loss = 8.91232
I0523 06:28:25.202555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91232 (* 1 = 8.91232 loss)
I0523 06:28:25.281415 34819 sgd_solver.cpp:112] Iteration 62380, lr = 0.01
I0523 06:28:31.013931 34819 solver.cpp:239] Iteration 62390 (1.72084 iter/s, 5.81113s/10 iters), loss = 8.88552
I0523 06:28:31.013980 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88552 (* 1 = 8.88552 loss)
I0523 06:28:31.086643 34819 sgd_solver.cpp:112] Iteration 62390, lr = 0.01
I0523 06:28:34.926532 34819 solver.cpp:239] Iteration 62400 (2.556 iter/s, 3.91236s/10 iters), loss = 8.4278
I0523 06:28:34.926589 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4278 (* 1 = 8.4278 loss)
I0523 06:28:35.002539 34819 sgd_solver.cpp:112] Iteration 62400, lr = 0.01
I0523 06:28:39.198457 34819 solver.cpp:239] Iteration 62410 (2.34101 iter/s, 4.27166s/10 iters), loss = 8.20664
I0523 06:28:39.198519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20664 (* 1 = 8.20664 loss)
I0523 06:28:40.015508 34819 sgd_solver.cpp:112] Iteration 62410, lr = 0.01
I0523 06:28:44.259714 34819 solver.cpp:239] Iteration 62420 (1.9759 iter/s, 5.06098s/10 iters), loss = 8.99334
I0523 06:28:44.259768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99334 (* 1 = 8.99334 loss)
I0523 06:28:45.115588 34819 sgd_solver.cpp:112] Iteration 62420, lr = 0.01
I0523 06:28:48.526254 34819 solver.cpp:239] Iteration 62430 (2.34395 iter/s, 4.2663s/10 iters), loss = 7.54157
I0523 06:28:48.526298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54157 (* 1 = 7.54157 loss)
I0523 06:28:48.585508 34819 sgd_solver.cpp:112] Iteration 62430, lr = 0.01
I0523 06:28:54.812782 34819 solver.cpp:239] Iteration 62440 (1.59078 iter/s, 6.28622s/10 iters), loss = 8.63473
I0523 06:28:54.812947 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63473 (* 1 = 8.63473 loss)
I0523 06:28:55.622071 34819 sgd_solver.cpp:112] Iteration 62440, lr = 0.01
I0523 06:29:01.539546 34819 solver.cpp:239] Iteration 62450 (1.48669 iter/s, 6.72633s/10 iters), loss = 8.57065
I0523 06:29:01.539598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57065 (* 1 = 8.57065 loss)
I0523 06:29:01.613278 34819 sgd_solver.cpp:112] Iteration 62450, lr = 0.01
I0523 06:29:05.002439 34819 solver.cpp:239] Iteration 62460 (2.88793 iter/s, 3.46268s/10 iters), loss = 7.94708
I0523 06:29:05.002496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94708 (* 1 = 7.94708 loss)
I0523 06:29:05.850080 34819 sgd_solver.cpp:112] Iteration 62460, lr = 0.01
I0523 06:29:09.039465 34819 solver.cpp:239] Iteration 62470 (2.47721 iter/s, 4.0368s/10 iters), loss = 7.09693
I0523 06:29:09.039508 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.09693 (* 1 = 7.09693 loss)
I0523 06:29:09.407151 34819 sgd_solver.cpp:112] Iteration 62470, lr = 0.01
I0523 06:29:13.878233 34819 solver.cpp:239] Iteration 62480 (2.06675 iter/s, 4.83852s/10 iters), loss = 8.00029
I0523 06:29:13.878274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00029 (* 1 = 8.00029 loss)
I0523 06:29:13.932145 34819 sgd_solver.cpp:112] Iteration 62480, lr = 0.01
I0523 06:29:17.686295 34819 solver.cpp:239] Iteration 62490 (2.62615 iter/s, 3.80786s/10 iters), loss = 8.69453
I0523 06:29:17.686341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69453 (* 1 = 8.69453 loss)
I0523 06:29:18.473599 34819 sgd_solver.cpp:112] Iteration 62490, lr = 0.01
I0523 06:29:21.848697 34819 solver.cpp:239] Iteration 62500 (2.4026 iter/s, 4.16215s/10 iters), loss = 7.86171
I0523 06:29:21.848755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86171 (* 1 = 7.86171 loss)
I0523 06:29:22.729857 34819 sgd_solver.cpp:112] Iteration 62500, lr = 0.01
I0523 06:29:28.915297 34819 solver.cpp:239] Iteration 62510 (1.41518 iter/s, 7.06626s/10 iters), loss = 8.3498
I0523 06:29:28.915452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3498 (* 1 = 8.3498 loss)
I0523 06:29:29.665364 34819 sgd_solver.cpp:112] Iteration 62510, lr = 0.01
I0523 06:29:34.161671 34819 solver.cpp:239] Iteration 62520 (1.90621 iter/s, 5.246s/10 iters), loss = 6.64169
I0523 06:29:34.161726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.64169 (* 1 = 6.64169 loss)
I0523 06:29:34.825284 34819 sgd_solver.cpp:112] Iteration 62520, lr = 0.01
I0523 06:29:38.730042 34819 solver.cpp:239] Iteration 62530 (2.18908 iter/s, 4.56812s/10 iters), loss = 8.68236
I0523 06:29:38.730092 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68236 (* 1 = 8.68236 loss)
I0523 06:29:38.798699 34819 sgd_solver.cpp:112] Iteration 62530, lr = 0.01
I0523 06:29:43.806931 34819 solver.cpp:239] Iteration 62540 (1.96982 iter/s, 5.07661s/10 iters), loss = 8.00346
I0523 06:29:43.806982 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00346 (* 1 = 8.00346 loss)
I0523 06:29:44.670770 34819 sgd_solver.cpp:112] Iteration 62540, lr = 0.01
I0523 06:29:48.212983 34819 solver.cpp:239] Iteration 62550 (2.26973 iter/s, 4.40581s/10 iters), loss = 6.84474
I0523 06:29:48.213022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.84474 (* 1 = 6.84474 loss)
I0523 06:29:48.272008 34819 sgd_solver.cpp:112] Iteration 62550, lr = 0.01
I0523 06:29:53.063429 34819 solver.cpp:239] Iteration 62560 (2.06177 iter/s, 4.8502s/10 iters), loss = 8.56472
I0523 06:29:53.063472 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56472 (* 1 = 8.56472 loss)
I0523 06:29:53.878984 34819 sgd_solver.cpp:112] Iteration 62560, lr = 0.01
I0523 06:29:58.743315 34819 solver.cpp:239] Iteration 62570 (1.76069 iter/s, 5.6796s/10 iters), loss = 7.93678
I0523 06:29:58.743356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93678 (* 1 = 7.93678 loss)
I0523 06:29:59.617530 34819 sgd_solver.cpp:112] Iteration 62570, lr = 0.01
I0523 06:30:04.672029 34819 solver.cpp:239] Iteration 62580 (1.68679 iter/s, 5.92842s/10 iters), loss = 8.63117
I0523 06:30:04.672070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63117 (* 1 = 8.63117 loss)
I0523 06:30:04.753083 34819 sgd_solver.cpp:112] Iteration 62580, lr = 0.01
I0523 06:30:10.952621 34819 solver.cpp:239] Iteration 62590 (1.59229 iter/s, 6.28028s/10 iters), loss = 7.92414
I0523 06:30:10.952687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92414 (* 1 = 7.92414 loss)
I0523 06:30:11.731518 34819 sgd_solver.cpp:112] Iteration 62590, lr = 0.01
I0523 06:30:15.944178 34819 solver.cpp:239] Iteration 62600 (2.00349 iter/s, 4.99128s/10 iters), loss = 7.75985
I0523 06:30:15.944221 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75985 (* 1 = 7.75985 loss)
I0523 06:30:16.292973 34819 sgd_solver.cpp:112] Iteration 62600, lr = 0.01
I0523 06:30:21.892398 34819 solver.cpp:239] Iteration 62610 (1.68126 iter/s, 5.94793s/10 iters), loss = 8.03684
I0523 06:30:21.892449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03684 (* 1 = 8.03684 loss)
I0523 06:30:22.678325 34819 sgd_solver.cpp:112] Iteration 62610, lr = 0.01
I0523 06:30:25.345777 34819 solver.cpp:239] Iteration 62620 (2.89589 iter/s, 3.45317s/10 iters), loss = 8.24516
I0523 06:30:25.345827 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24516 (* 1 = 8.24516 loss)
I0523 06:30:25.404194 34819 sgd_solver.cpp:112] Iteration 62620, lr = 0.01
I0523 06:30:30.434691 34819 solver.cpp:239] Iteration 62630 (1.96516 iter/s, 5.08864s/10 iters), loss = 7.66652
I0523 06:30:30.434844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66652 (* 1 = 7.66652 loss)
I0523 06:30:30.496599 34819 sgd_solver.cpp:112] Iteration 62630, lr = 0.01
I0523 06:30:34.547881 34819 solver.cpp:239] Iteration 62640 (2.43139 iter/s, 4.11287s/10 iters), loss = 8.05275
I0523 06:30:34.547940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05275 (* 1 = 8.05275 loss)
I0523 06:30:35.233924 34819 sgd_solver.cpp:112] Iteration 62640, lr = 0.01
I0523 06:30:39.282559 34819 solver.cpp:239] Iteration 62650 (2.11219 iter/s, 4.73442s/10 iters), loss = 8.83459
I0523 06:30:39.282613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83459 (* 1 = 8.83459 loss)
I0523 06:30:39.335489 34819 sgd_solver.cpp:112] Iteration 62650, lr = 0.01
I0523 06:30:44.181473 34819 solver.cpp:239] Iteration 62660 (2.04138 iter/s, 4.89865s/10 iters), loss = 7.99253
I0523 06:30:44.181514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99253 (* 1 = 7.99253 loss)
I0523 06:30:44.998085 34819 sgd_solver.cpp:112] Iteration 62660, lr = 0.01
I0523 06:30:49.928688 34819 solver.cpp:239] Iteration 62670 (1.74006 iter/s, 5.74693s/10 iters), loss = 7.87158
I0523 06:30:49.928728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87158 (* 1 = 7.87158 loss)
I0523 06:30:50.664510 34819 sgd_solver.cpp:112] Iteration 62670, lr = 0.01
I0523 06:30:54.063650 34819 solver.cpp:239] Iteration 62680 (2.41853 iter/s, 4.13474s/10 iters), loss = 7.71017
I0523 06:30:54.063688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71017 (* 1 = 7.71017 loss)
I0523 06:30:54.134675 34819 sgd_solver.cpp:112] Iteration 62680, lr = 0.01
I0523 06:30:58.974233 34819 solver.cpp:239] Iteration 62690 (2.03652 iter/s, 4.91033s/10 iters), loss = 7.80774
I0523 06:30:58.974277 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80774 (* 1 = 7.80774 loss)
I0523 06:30:59.213469 34819 sgd_solver.cpp:112] Iteration 62690, lr = 0.01
I0523 06:31:05.900445 34819 solver.cpp:239] Iteration 62700 (1.44386 iter/s, 6.92588s/10 iters), loss = 8.99949
I0523 06:31:05.900575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99949 (* 1 = 8.99949 loss)
I0523 06:31:05.969097 34819 sgd_solver.cpp:112] Iteration 62700, lr = 0.01
I0523 06:31:10.675088 34819 solver.cpp:239] Iteration 62710 (2.09455 iter/s, 4.7743s/10 iters), loss = 7.99379
I0523 06:31:10.675140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99379 (* 1 = 7.99379 loss)
I0523 06:31:10.749251 34819 sgd_solver.cpp:112] Iteration 62710, lr = 0.01
I0523 06:31:14.229313 34819 solver.cpp:239] Iteration 62720 (2.8157 iter/s, 3.55151s/10 iters), loss = 8.28868
I0523 06:31:14.229353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28868 (* 1 = 8.28868 loss)
I0523 06:31:14.289481 34819 sgd_solver.cpp:112] Iteration 62720, lr = 0.01
I0523 06:31:21.322084 34819 solver.cpp:239] Iteration 62730 (1.40995 iter/s, 7.09244s/10 iters), loss = 7.57665
I0523 06:31:21.322139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57665 (* 1 = 7.57665 loss)
I0523 06:31:22.159724 34819 sgd_solver.cpp:112] Iteration 62730, lr = 0.01
I0523 06:31:27.906844 34819 solver.cpp:239] Iteration 62740 (1.51873 iter/s, 6.58443s/10 iters), loss = 7.51007
I0523 06:31:27.906884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51007 (* 1 = 7.51007 loss)
I0523 06:31:28.495782 34819 sgd_solver.cpp:112] Iteration 62740, lr = 0.01
I0523 06:31:34.885768 34819 solver.cpp:239] Iteration 62750 (1.43295 iter/s, 6.9786s/10 iters), loss = 8.4509
I0523 06:31:34.885823 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4509 (* 1 = 8.4509 loss)
I0523 06:31:34.965795 34819 sgd_solver.cpp:112] Iteration 62750, lr = 0.01
I0523 06:31:39.594182 34819 solver.cpp:239] Iteration 62760 (2.12397 iter/s, 4.70816s/10 iters), loss = 8.24605
I0523 06:31:39.594429 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24605 (* 1 = 8.24605 loss)
I0523 06:31:39.797619 34819 sgd_solver.cpp:112] Iteration 62760, lr = 0.01
I0523 06:31:42.999455 34819 solver.cpp:239] Iteration 62770 (2.93695 iter/s, 3.40489s/10 iters), loss = 8.92114
I0523 06:31:42.999514 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92114 (* 1 = 8.92114 loss)
I0523 06:31:43.856670 34819 sgd_solver.cpp:112] Iteration 62770, lr = 0.01
I0523 06:31:49.060084 34819 solver.cpp:239] Iteration 62780 (1.65008 iter/s, 6.06032s/10 iters), loss = 7.82356
I0523 06:31:49.060135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82356 (* 1 = 7.82356 loss)
I0523 06:31:49.123159 34819 sgd_solver.cpp:112] Iteration 62780, lr = 0.01
I0523 06:31:55.556777 34819 solver.cpp:239] Iteration 62790 (1.53932 iter/s, 6.49638s/10 iters), loss = 7.86139
I0523 06:31:55.556829 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86139 (* 1 = 7.86139 loss)
I0523 06:31:55.621243 34819 sgd_solver.cpp:112] Iteration 62790, lr = 0.01
I0523 06:32:01.206934 34819 solver.cpp:239] Iteration 62800 (1.76995 iter/s, 5.64987s/10 iters), loss = 8.22172
I0523 06:32:01.206975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22172 (* 1 = 8.22172 loss)
I0523 06:32:01.954033 34819 sgd_solver.cpp:112] Iteration 62800, lr = 0.01
I0523 06:32:06.860679 34819 solver.cpp:239] Iteration 62810 (1.76883 iter/s, 5.65346s/10 iters), loss = 7.94772
I0523 06:32:06.860726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94772 (* 1 = 7.94772 loss)
I0523 06:32:06.928228 34819 sgd_solver.cpp:112] Iteration 62810, lr = 0.01
I0523 06:32:12.435315 34819 solver.cpp:239] Iteration 62820 (1.79393 iter/s, 5.57435s/10 iters), loss = 7.65822
I0523 06:32:12.435513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65822 (* 1 = 7.65822 loss)
I0523 06:32:13.257241 34819 sgd_solver.cpp:112] Iteration 62820, lr = 0.01
I0523 06:32:16.637035 34819 solver.cpp:239] Iteration 62830 (2.38019 iter/s, 4.20135s/10 iters), loss = 7.77416
I0523 06:32:16.637089 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77416 (* 1 = 7.77416 loss)
I0523 06:32:17.404420 34819 sgd_solver.cpp:112] Iteration 62830, lr = 0.01
I0523 06:32:21.376914 34819 solver.cpp:239] Iteration 62840 (2.10987 iter/s, 4.73963s/10 iters), loss = 8.0804
I0523 06:32:21.376955 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0804 (* 1 = 8.0804 loss)
I0523 06:32:22.173131 34819 sgd_solver.cpp:112] Iteration 62840, lr = 0.01
I0523 06:32:25.039634 34819 solver.cpp:239] Iteration 62850 (2.73036 iter/s, 3.66252s/10 iters), loss = 7.78263
I0523 06:32:25.039681 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78263 (* 1 = 7.78263 loss)
I0523 06:32:25.093416 34819 sgd_solver.cpp:112] Iteration 62850, lr = 0.01
I0523 06:32:29.875282 34819 solver.cpp:239] Iteration 62860 (2.06809 iter/s, 4.83537s/10 iters), loss = 7.81396
I0523 06:32:29.875344 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81396 (* 1 = 7.81396 loss)
I0523 06:32:30.609071 34819 sgd_solver.cpp:112] Iteration 62860, lr = 0.01
I0523 06:32:37.147392 34819 solver.cpp:239] Iteration 62870 (1.37519 iter/s, 7.27174s/10 iters), loss = 8.96141
I0523 06:32:37.147452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96141 (* 1 = 8.96141 loss)
I0523 06:32:37.787339 34819 sgd_solver.cpp:112] Iteration 62870, lr = 0.01
I0523 06:32:42.844472 34819 solver.cpp:239] Iteration 62880 (1.75538 iter/s, 5.69678s/10 iters), loss = 8.54614
I0523 06:32:42.844609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54614 (* 1 = 8.54614 loss)
I0523 06:32:42.919453 34819 sgd_solver.cpp:112] Iteration 62880, lr = 0.01
I0523 06:32:44.736949 34819 solver.cpp:239] Iteration 62890 (5.28472 iter/s, 1.89225s/10 iters), loss = 8.58902
I0523 06:32:44.736996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58902 (* 1 = 8.58902 loss)
I0523 06:32:45.574471 34819 sgd_solver.cpp:112] Iteration 62890, lr = 0.01
I0523 06:32:48.913578 34819 solver.cpp:239] Iteration 62900 (2.39442 iter/s, 4.17638s/10 iters), loss = 7.94203
I0523 06:32:48.913640 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94203 (* 1 = 7.94203 loss)
I0523 06:32:49.772337 34819 sgd_solver.cpp:112] Iteration 62900, lr = 0.01
I0523 06:32:53.100839 34819 solver.cpp:239] Iteration 62910 (2.38833 iter/s, 4.18702s/10 iters), loss = 7.26845
I0523 06:32:53.100894 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26845 (* 1 = 7.26845 loss)
I0523 06:32:53.896291 34819 sgd_solver.cpp:112] Iteration 62910, lr = 0.01
I0523 06:32:57.799727 34819 solver.cpp:239] Iteration 62920 (2.12828 iter/s, 4.69863s/10 iters), loss = 8.80885
I0523 06:32:57.799777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80885 (* 1 = 8.80885 loss)
I0523 06:32:57.855980 34819 sgd_solver.cpp:112] Iteration 62920, lr = 0.01
I0523 06:33:02.375643 34819 solver.cpp:239] Iteration 62930 (2.18548 iter/s, 4.57566s/10 iters), loss = 8.23898
I0523 06:33:02.375695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23898 (* 1 = 8.23898 loss)
I0523 06:33:02.451802 34819 sgd_solver.cpp:112] Iteration 62930, lr = 0.01
I0523 06:33:06.844120 34819 solver.cpp:239] Iteration 62940 (2.23803 iter/s, 4.46822s/10 iters), loss = 8.83247
I0523 06:33:06.844177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83247 (* 1 = 8.83247 loss)
I0523 06:33:06.910301 34819 sgd_solver.cpp:112] Iteration 62940, lr = 0.01
I0523 06:33:11.153609 34819 solver.cpp:239] Iteration 62950 (2.32059 iter/s, 4.30925s/10 iters), loss = 9.52457
I0523 06:33:11.153651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.52457 (* 1 = 9.52457 loss)
I0523 06:33:12.009706 34819 sgd_solver.cpp:112] Iteration 62950, lr = 0.01
I0523 06:33:16.857136 34819 solver.cpp:239] Iteration 62960 (1.75339 iter/s, 5.70325s/10 iters), loss = 8.83695
I0523 06:33:16.857275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83695 (* 1 = 8.83695 loss)
I0523 06:33:16.937161 34819 sgd_solver.cpp:112] Iteration 62960, lr = 0.01
I0523 06:33:21.783836 34819 solver.cpp:239] Iteration 62970 (2.0299 iter/s, 4.92635s/10 iters), loss = 8.78842
I0523 06:33:21.783887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78842 (* 1 = 8.78842 loss)
I0523 06:33:21.841469 34819 sgd_solver.cpp:112] Iteration 62970, lr = 0.01
I0523 06:33:26.386538 34819 solver.cpp:239] Iteration 62980 (2.17276 iter/s, 4.60244s/10 iters), loss = 8.08518
I0523 06:33:26.386595 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08518 (* 1 = 8.08518 loss)
I0523 06:33:27.235702 34819 sgd_solver.cpp:112] Iteration 62980, lr = 0.01
I0523 06:33:31.939468 34819 solver.cpp:239] Iteration 62990 (1.80095 iter/s, 5.55264s/10 iters), loss = 8.85703
I0523 06:33:31.939512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85703 (* 1 = 8.85703 loss)
I0523 06:33:32.011694 34819 sgd_solver.cpp:112] Iteration 62990, lr = 0.01
I0523 06:33:38.426623 34819 solver.cpp:239] Iteration 63000 (1.54158 iter/s, 6.48684s/10 iters), loss = 8.36592
I0523 06:33:38.426667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36592 (* 1 = 8.36592 loss)
I0523 06:33:39.076259 34819 sgd_solver.cpp:112] Iteration 63000, lr = 0.01
I0523 06:33:43.994949 34819 solver.cpp:239] Iteration 63010 (1.79596 iter/s, 5.56805s/10 iters), loss = 8.40251
I0523 06:33:43.994992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40251 (* 1 = 8.40251 loss)
I0523 06:33:44.058342 34819 sgd_solver.cpp:112] Iteration 63010, lr = 0.01
I0523 06:33:47.440968 34819 solver.cpp:239] Iteration 63020 (2.90206 iter/s, 3.44582s/10 iters), loss = 8.21308
I0523 06:33:47.441205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21308 (* 1 = 8.21308 loss)
I0523 06:33:47.521622 34819 sgd_solver.cpp:112] Iteration 63020, lr = 0.01
I0523 06:33:51.790730 34819 solver.cpp:239] Iteration 63030 (2.29921 iter/s, 4.34932s/10 iters), loss = 8.58761
I0523 06:33:51.790794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58761 (* 1 = 8.58761 loss)
I0523 06:33:51.858595 34819 sgd_solver.cpp:112] Iteration 63030, lr = 0.01
I0523 06:33:55.767752 34819 solver.cpp:239] Iteration 63040 (2.5146 iter/s, 3.97678s/10 iters), loss = 8.15198
I0523 06:33:55.767801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15198 (* 1 = 8.15198 loss)
I0523 06:33:55.837441 34819 sgd_solver.cpp:112] Iteration 63040, lr = 0.01
I0523 06:34:00.357476 34819 solver.cpp:239] Iteration 63050 (2.17889 iter/s, 4.58948s/10 iters), loss = 9.13791
I0523 06:34:00.357518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13791 (* 1 = 9.13791 loss)
I0523 06:34:01.039835 34819 sgd_solver.cpp:112] Iteration 63050, lr = 0.01
I0523 06:34:05.513402 34819 solver.cpp:239] Iteration 63060 (1.93962 iter/s, 5.15566s/10 iters), loss = 8.08307
I0523 06:34:05.513443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08307 (* 1 = 8.08307 loss)
I0523 06:34:05.570492 34819 sgd_solver.cpp:112] Iteration 63060, lr = 0.01
I0523 06:34:10.561615 34819 solver.cpp:239] Iteration 63070 (1.981 iter/s, 5.04796s/10 iters), loss = 7.89506
I0523 06:34:10.561664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89506 (* 1 = 7.89506 loss)
I0523 06:34:11.331113 34819 sgd_solver.cpp:112] Iteration 63070, lr = 0.01
I0523 06:34:16.651903 34819 solver.cpp:239] Iteration 63080 (1.64204 iter/s, 6.08998s/10 iters), loss = 8.24166
I0523 06:34:16.651953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24166 (* 1 = 8.24166 loss)
I0523 06:34:16.722642 34819 sgd_solver.cpp:112] Iteration 63080, lr = 0.01
I0523 06:34:20.450731 34819 solver.cpp:239] Iteration 63090 (2.63255 iter/s, 3.79859s/10 iters), loss = 7.79293
I0523 06:34:20.450947 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79293 (* 1 = 7.79293 loss)
I0523 06:34:21.345795 34819 sgd_solver.cpp:112] Iteration 63090, lr = 0.01
I0523 06:34:26.453836 34819 solver.cpp:239] Iteration 63100 (1.66592 iter/s, 6.00268s/10 iters), loss = 7.5243
I0523 06:34:26.453878 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5243 (* 1 = 7.5243 loss)
I0523 06:34:26.527238 34819 sgd_solver.cpp:112] Iteration 63100, lr = 0.01
I0523 06:34:33.884017 34819 solver.cpp:239] Iteration 63110 (1.34592 iter/s, 7.42984s/10 iters), loss = 8.74512
I0523 06:34:33.884065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74512 (* 1 = 8.74512 loss)
I0523 06:34:33.946390 34819 sgd_solver.cpp:112] Iteration 63110, lr = 0.01
I0523 06:34:37.494837 34819 solver.cpp:239] Iteration 63120 (2.76962 iter/s, 3.6106s/10 iters), loss = 8.3328
I0523 06:34:37.494889 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3328 (* 1 = 8.3328 loss)
I0523 06:34:37.567914 34819 sgd_solver.cpp:112] Iteration 63120, lr = 0.01
I0523 06:34:41.300240 34819 solver.cpp:239] Iteration 63130 (2.62799 iter/s, 3.80519s/10 iters), loss = 9.64212
I0523 06:34:41.300292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.64212 (* 1 = 9.64212 loss)
I0523 06:34:41.387307 34819 sgd_solver.cpp:112] Iteration 63130, lr = 0.01
I0523 06:34:47.166803 34819 solver.cpp:239] Iteration 63140 (1.70466 iter/s, 5.86626s/10 iters), loss = 7.52091
I0523 06:34:47.166859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52091 (* 1 = 7.52091 loss)
I0523 06:34:47.885202 34819 sgd_solver.cpp:112] Iteration 63140, lr = 0.01
I0523 06:34:52.039706 34819 solver.cpp:239] Iteration 63150 (2.05228 iter/s, 4.87262s/10 iters), loss = 8.18593
I0523 06:34:52.039901 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18593 (* 1 = 8.18593 loss)
I0523 06:34:52.109433 34819 sgd_solver.cpp:112] Iteration 63150, lr = 0.01
I0523 06:34:56.841228 34819 solver.cpp:239] Iteration 63160 (2.08284 iter/s, 4.80113s/10 iters), loss = 7.39803
I0523 06:34:56.841274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39803 (* 1 = 7.39803 loss)
I0523 06:34:56.919126 34819 sgd_solver.cpp:112] Iteration 63160, lr = 0.01
I0523 06:35:01.396648 34819 solver.cpp:239] Iteration 63170 (2.19531 iter/s, 4.55517s/10 iters), loss = 8.06321
I0523 06:35:01.396697 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06321 (* 1 = 8.06321 loss)
I0523 06:35:01.465777 34819 sgd_solver.cpp:112] Iteration 63170, lr = 0.01
I0523 06:35:05.473134 34819 solver.cpp:239] Iteration 63180 (2.45323 iter/s, 4.07625s/10 iters), loss = 8.54744
I0523 06:35:05.473186 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54744 (* 1 = 8.54744 loss)
I0523 06:35:06.307224 34819 sgd_solver.cpp:112] Iteration 63180, lr = 0.01
I0523 06:35:12.460084 34819 solver.cpp:239] Iteration 63190 (1.43131 iter/s, 6.9866s/10 iters), loss = 7.65399
I0523 06:35:12.460134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65399 (* 1 = 7.65399 loss)
I0523 06:35:12.525794 34819 sgd_solver.cpp:112] Iteration 63190, lr = 0.01
I0523 06:35:17.447124 34819 solver.cpp:239] Iteration 63200 (2.0053 iter/s, 4.98678s/10 iters), loss = 7.87528
I0523 06:35:17.447177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87528 (* 1 = 7.87528 loss)
I0523 06:35:17.509727 34819 sgd_solver.cpp:112] Iteration 63200, lr = 0.01
I0523 06:35:20.793450 34819 solver.cpp:239] Iteration 63210 (2.98853 iter/s, 3.34612s/10 iters), loss = 7.75306
I0523 06:35:20.793499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75306 (* 1 = 7.75306 loss)
I0523 06:35:21.266515 34819 sgd_solver.cpp:112] Iteration 63210, lr = 0.01
I0523 06:35:25.285807 34819 solver.cpp:239] Iteration 63220 (2.22613 iter/s, 4.49211s/10 iters), loss = 8.32966
I0523 06:35:25.285920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32966 (* 1 = 8.32966 loss)
I0523 06:35:25.360901 34819 sgd_solver.cpp:112] Iteration 63220, lr = 0.01
I0523 06:35:28.069036 34819 solver.cpp:239] Iteration 63230 (3.59326 iter/s, 2.78299s/10 iters), loss = 8.14926
I0523 06:35:28.069090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14926 (* 1 = 8.14926 loss)
I0523 06:35:28.853407 34819 sgd_solver.cpp:112] Iteration 63230, lr = 0.01
I0523 06:35:34.388015 34819 solver.cpp:239] Iteration 63240 (1.58261 iter/s, 6.31867s/10 iters), loss = 8.25345
I0523 06:35:34.388062 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25345 (* 1 = 8.25345 loss)
I0523 06:35:35.146033 34819 sgd_solver.cpp:112] Iteration 63240, lr = 0.01
I0523 06:35:38.779284 34819 solver.cpp:239] Iteration 63250 (2.27936 iter/s, 4.3872s/10 iters), loss = 8.60637
I0523 06:35:38.779325 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60637 (* 1 = 8.60637 loss)
I0523 06:35:39.626238 34819 sgd_solver.cpp:112] Iteration 63250, lr = 0.01
I0523 06:35:43.217613 34819 solver.cpp:239] Iteration 63260 (2.25322 iter/s, 4.4381s/10 iters), loss = 8.43932
I0523 06:35:43.217654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43932 (* 1 = 8.43932 loss)
I0523 06:35:43.291455 34819 sgd_solver.cpp:112] Iteration 63260, lr = 0.01
I0523 06:35:48.850528 34819 solver.cpp:239] Iteration 63270 (1.77537 iter/s, 5.63262s/10 iters), loss = 8.3266
I0523 06:35:48.850598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3266 (* 1 = 8.3266 loss)
I0523 06:35:49.468435 34819 sgd_solver.cpp:112] Iteration 63270, lr = 0.01
I0523 06:35:52.086604 34819 solver.cpp:239] Iteration 63280 (3.09037 iter/s, 3.23586s/10 iters), loss = 8.53988
I0523 06:35:52.086650 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53988 (* 1 = 8.53988 loss)
I0523 06:35:52.153573 34819 sgd_solver.cpp:112] Iteration 63280, lr = 0.01
I0523 06:35:57.883621 34819 solver.cpp:239] Iteration 63290 (1.72511 iter/s, 5.79672s/10 iters), loss = 7.65836
I0523 06:35:57.884136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65836 (* 1 = 7.65836 loss)
I0523 06:35:57.959522 34819 sgd_solver.cpp:112] Iteration 63290, lr = 0.01
I0523 06:36:02.870723 34819 solver.cpp:239] Iteration 63300 (2.00547 iter/s, 4.98637s/10 iters), loss = 8.85242
I0523 06:36:02.870764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85242 (* 1 = 8.85242 loss)
I0523 06:36:02.945948 34819 sgd_solver.cpp:112] Iteration 63300, lr = 0.01
I0523 06:36:08.073328 34819 solver.cpp:239] Iteration 63310 (1.92221 iter/s, 5.20234s/10 iters), loss = 8.19544
I0523 06:36:08.073369 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19544 (* 1 = 8.19544 loss)
I0523 06:36:08.136524 34819 sgd_solver.cpp:112] Iteration 63310, lr = 0.01
I0523 06:36:11.522521 34819 solver.cpp:239] Iteration 63320 (2.8994 iter/s, 3.44899s/10 iters), loss = 7.79857
I0523 06:36:11.522562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79857 (* 1 = 7.79857 loss)
I0523 06:36:11.595686 34819 sgd_solver.cpp:112] Iteration 63320, lr = 0.01
I0523 06:36:15.644515 34819 solver.cpp:239] Iteration 63330 (2.42614 iter/s, 4.12178s/10 iters), loss = 8.72233
I0523 06:36:15.644559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72233 (* 1 = 8.72233 loss)
I0523 06:36:15.705819 34819 sgd_solver.cpp:112] Iteration 63330, lr = 0.01
I0523 06:36:19.039530 34819 solver.cpp:239] Iteration 63340 (2.94567 iter/s, 3.39481s/10 iters), loss = 7.6882
I0523 06:36:19.039579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6882 (* 1 = 7.6882 loss)
I0523 06:36:19.115638 34819 sgd_solver.cpp:112] Iteration 63340, lr = 0.01
I0523 06:36:23.863397 34819 solver.cpp:239] Iteration 63350 (2.07313 iter/s, 4.82362s/10 iters), loss = 8.52542
I0523 06:36:23.863446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52542 (* 1 = 8.52542 loss)
I0523 06:36:23.937366 34819 sgd_solver.cpp:112] Iteration 63350, lr = 0.01
I0523 06:36:28.394716 34819 solver.cpp:239] Iteration 63360 (2.20699 iter/s, 4.53105s/10 iters), loss = 7.8442
I0523 06:36:28.394848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8442 (* 1 = 7.8442 loss)
I0523 06:36:28.499889 34819 sgd_solver.cpp:112] Iteration 63360, lr = 0.01
I0523 06:36:32.503630 34819 solver.cpp:239] Iteration 63370 (2.43391 iter/s, 4.10861s/10 iters), loss = 7.97557
I0523 06:36:32.503680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97557 (* 1 = 7.97557 loss)
I0523 06:36:32.568564 34819 sgd_solver.cpp:112] Iteration 63370, lr = 0.01
I0523 06:36:36.515465 34819 solver.cpp:239] Iteration 63380 (2.49277 iter/s, 4.01159s/10 iters), loss = 8.09473
I0523 06:36:36.515516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09473 (* 1 = 8.09473 loss)
I0523 06:36:37.243737 34819 sgd_solver.cpp:112] Iteration 63380, lr = 0.01
I0523 06:36:39.102269 34819 solver.cpp:239] Iteration 63390 (3.86603 iter/s, 2.58663s/10 iters), loss = 8.80049
I0523 06:36:39.102311 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80049 (* 1 = 8.80049 loss)
I0523 06:36:39.161998 34819 sgd_solver.cpp:112] Iteration 63390, lr = 0.01
I0523 06:36:42.658200 34819 solver.cpp:239] Iteration 63400 (2.81236 iter/s, 3.55574s/10 iters), loss = 8.17232
I0523 06:36:42.658241 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17232 (* 1 = 8.17232 loss)
I0523 06:36:43.379276 34819 sgd_solver.cpp:112] Iteration 63400, lr = 0.01
I0523 06:36:49.365422 34819 solver.cpp:239] Iteration 63410 (1.491 iter/s, 6.7069s/10 iters), loss = 8.6909
I0523 06:36:49.365474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6909 (* 1 = 8.6909 loss)
I0523 06:36:50.164166 34819 sgd_solver.cpp:112] Iteration 63410, lr = 0.01
I0523 06:36:55.317638 34819 solver.cpp:239] Iteration 63420 (1.68013 iter/s, 5.95191s/10 iters), loss = 7.82979
I0523 06:36:55.317682 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82979 (* 1 = 7.82979 loss)
I0523 06:36:55.383694 34819 sgd_solver.cpp:112] Iteration 63420, lr = 0.01
I0523 06:36:59.575984 34819 solver.cpp:239] Iteration 63430 (2.34846 iter/s, 4.25811s/10 iters), loss = 8.4325
I0523 06:36:59.576212 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4325 (* 1 = 8.4325 loss)
I0523 06:36:59.645130 34819 sgd_solver.cpp:112] Iteration 63430, lr = 0.01
I0523 06:37:04.468082 34819 solver.cpp:239] Iteration 63440 (2.04429 iter/s, 4.89169s/10 iters), loss = 8.13571
I0523 06:37:04.468123 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13571 (* 1 = 8.13571 loss)
I0523 06:37:04.542768 34819 sgd_solver.cpp:112] Iteration 63440, lr = 0.01
I0523 06:37:07.995703 34819 solver.cpp:239] Iteration 63450 (2.83493 iter/s, 3.52742s/10 iters), loss = 7.39059
I0523 06:37:07.995772 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39059 (* 1 = 7.39059 loss)
I0523 06:37:08.784596 34819 sgd_solver.cpp:112] Iteration 63450, lr = 0.01
I0523 06:37:12.935350 34819 solver.cpp:239] Iteration 63460 (2.02455 iter/s, 4.93936s/10 iters), loss = 8.68248
I0523 06:37:12.935405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68248 (* 1 = 8.68248 loss)
I0523 06:37:13.644699 34819 sgd_solver.cpp:112] Iteration 63460, lr = 0.01
I0523 06:37:18.096010 34819 solver.cpp:239] Iteration 63470 (1.93784 iter/s, 5.16039s/10 iters), loss = 8.1107
I0523 06:37:18.096055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1107 (* 1 = 8.1107 loss)
I0523 06:37:18.141376 34819 sgd_solver.cpp:112] Iteration 63470, lr = 0.01
I0523 06:37:19.489516 34819 solver.cpp:239] Iteration 63480 (7.17677 iter/s, 1.39338s/10 iters), loss = 8.38995
I0523 06:37:19.489573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38995 (* 1 = 8.38995 loss)
I0523 06:37:19.538120 34819 sgd_solver.cpp:112] Iteration 63480, lr = 0.01
I0523 06:37:21.213920 34819 solver.cpp:239] Iteration 63490 (5.79956 iter/s, 1.72427s/10 iters), loss = 7.621
I0523 06:37:21.213964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.621 (* 1 = 7.621 loss)
I0523 06:37:21.254124 34819 sgd_solver.cpp:112] Iteration 63490, lr = 0.01
I0523 06:37:22.465967 34819 solver.cpp:239] Iteration 63500 (7.98761 iter/s, 1.25194s/10 iters), loss = 8.99029
I0523 06:37:22.466012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99029 (* 1 = 8.99029 loss)
I0523 06:37:22.536659 34819 sgd_solver.cpp:112] Iteration 63500, lr = 0.01
I0523 06:37:26.528542 34819 solver.cpp:239] Iteration 63510 (2.46163 iter/s, 4.06235s/10 iters), loss = 7.98006
I0523 06:37:26.528599 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98006 (* 1 = 7.98006 loss)
I0523 06:37:26.613781 34819 sgd_solver.cpp:112] Iteration 63510, lr = 0.01
I0523 06:37:30.737891 34819 solver.cpp:239] Iteration 63520 (2.3758 iter/s, 4.20911s/10 iters), loss = 7.7863
I0523 06:37:30.738049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7863 (* 1 = 7.7863 loss)
I0523 06:37:30.810768 34819 sgd_solver.cpp:112] Iteration 63520, lr = 0.01
I0523 06:37:34.258138 34819 solver.cpp:239] Iteration 63530 (2.84096 iter/s, 3.51994s/10 iters), loss = 7.13118
I0523 06:37:34.258193 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13118 (* 1 = 7.13118 loss)
I0523 06:37:35.102715 34819 sgd_solver.cpp:112] Iteration 63530, lr = 0.01
I0523 06:37:41.186784 34819 solver.cpp:239] Iteration 63540 (1.44335 iter/s, 6.92831s/10 iters), loss = 8.36364
I0523 06:37:41.186834 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36364 (* 1 = 8.36364 loss)
I0523 06:37:41.247916 34819 sgd_solver.cpp:112] Iteration 63540, lr = 0.01
I0523 06:37:45.894181 34819 solver.cpp:239] Iteration 63550 (2.12443 iter/s, 4.70714s/10 iters), loss = 9.04484
I0523 06:37:45.894235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04484 (* 1 = 9.04484 loss)
I0523 06:37:45.962044 34819 sgd_solver.cpp:112] Iteration 63550, lr = 0.01
I0523 06:37:51.625890 34819 solver.cpp:239] Iteration 63560 (1.74477 iter/s, 5.73142s/10 iters), loss = 7.77891
I0523 06:37:51.625944 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77891 (* 1 = 7.77891 loss)
I0523 06:37:51.702755 34819 sgd_solver.cpp:112] Iteration 63560, lr = 0.01
I0523 06:37:55.806324 34819 solver.cpp:239] Iteration 63570 (2.39223 iter/s, 4.1802s/10 iters), loss = 8.62585
I0523 06:37:55.806368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62585 (* 1 = 8.62585 loss)
I0523 06:37:55.859292 34819 sgd_solver.cpp:112] Iteration 63570, lr = 0.01
I0523 06:38:00.868628 34819 solver.cpp:239] Iteration 63580 (1.97549 iter/s, 5.06203s/10 iters), loss = 7.90907
I0523 06:38:00.868763 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90907 (* 1 = 7.90907 loss)
I0523 06:38:00.948246 34819 sgd_solver.cpp:112] Iteration 63580, lr = 0.01
I0523 06:38:05.232251 34819 solver.cpp:239] Iteration 63590 (2.29184 iter/s, 4.3633s/10 iters), loss = 7.41774
I0523 06:38:05.232308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41774 (* 1 = 7.41774 loss)
I0523 06:38:06.048867 34819 sgd_solver.cpp:112] Iteration 63590, lr = 0.01
I0523 06:38:10.060964 34819 solver.cpp:239] Iteration 63600 (2.07106 iter/s, 4.82844s/10 iters), loss = 8.22756
I0523 06:38:10.061020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22756 (* 1 = 8.22756 loss)
I0523 06:38:10.131829 34819 sgd_solver.cpp:112] Iteration 63600, lr = 0.01
I0523 06:38:16.168148 34819 solver.cpp:239] Iteration 63610 (1.6375 iter/s, 6.10687s/10 iters), loss = 8.80214
I0523 06:38:16.168205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80214 (* 1 = 8.80214 loss)
I0523 06:38:16.990584 34819 sgd_solver.cpp:112] Iteration 63610, lr = 0.01
I0523 06:38:22.510962 34819 solver.cpp:239] Iteration 63620 (1.57667 iter/s, 6.3425s/10 iters), loss = 7.90899
I0523 06:38:22.511014 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90899 (* 1 = 7.90899 loss)
I0523 06:38:22.570636 34819 sgd_solver.cpp:112] Iteration 63620, lr = 0.01
I0523 06:38:28.150185 34819 solver.cpp:239] Iteration 63630 (1.77338 iter/s, 5.63894s/10 iters), loss = 9.44072
I0523 06:38:28.150243 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.44072 (* 1 = 9.44072 loss)
I0523 06:38:28.220408 34819 sgd_solver.cpp:112] Iteration 63630, lr = 0.01
I0523 06:38:32.716120 34819 solver.cpp:239] Iteration 63640 (2.19025 iter/s, 4.56569s/10 iters), loss = 7.37939
I0523 06:38:32.716341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.37939 (* 1 = 7.37939 loss)
I0523 06:38:33.008919 34819 sgd_solver.cpp:112] Iteration 63640, lr = 0.01
I0523 06:38:37.022804 34819 solver.cpp:239] Iteration 63650 (2.32217 iter/s, 4.30631s/10 iters), loss = 7.83563
I0523 06:38:37.022869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83563 (* 1 = 7.83563 loss)
I0523 06:38:37.089586 34819 sgd_solver.cpp:112] Iteration 63650, lr = 0.01
I0523 06:38:41.167593 34819 solver.cpp:239] Iteration 63660 (2.41281 iter/s, 4.14455s/10 iters), loss = 9.75524
I0523 06:38:41.167649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.75524 (* 1 = 9.75524 loss)
I0523 06:38:41.238409 34819 sgd_solver.cpp:112] Iteration 63660, lr = 0.01
I0523 06:38:47.266914 34819 solver.cpp:239] Iteration 63670 (1.63961 iter/s, 6.09901s/10 iters), loss = 8.31918
I0523 06:38:47.266957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31918 (* 1 = 8.31918 loss)
I0523 06:38:48.112129 34819 sgd_solver.cpp:112] Iteration 63670, lr = 0.01
I0523 06:38:54.562857 34819 solver.cpp:239] Iteration 63680 (1.37069 iter/s, 7.29559s/10 iters), loss = 8.14074
I0523 06:38:54.562902 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14074 (* 1 = 8.14074 loss)
I0523 06:38:54.620457 34819 sgd_solver.cpp:112] Iteration 63680, lr = 0.01
I0523 06:38:58.871623 34819 solver.cpp:239] Iteration 63690 (2.32097 iter/s, 4.30854s/10 iters), loss = 7.29021
I0523 06:38:58.871664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29021 (* 1 = 7.29021 loss)
I0523 06:38:58.940711 34819 sgd_solver.cpp:112] Iteration 63690, lr = 0.01
I0523 06:39:02.927436 34819 solver.cpp:239] Iteration 63700 (2.46573 iter/s, 4.0556s/10 iters), loss = 8.11457
I0523 06:39:02.927696 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11457 (* 1 = 8.11457 loss)
I0523 06:39:02.997223 34819 sgd_solver.cpp:112] Iteration 63700, lr = 0.01
I0523 06:39:09.072731 34819 solver.cpp:239] Iteration 63710 (1.62739 iter/s, 6.14481s/10 iters), loss = 7.98992
I0523 06:39:09.072783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98992 (* 1 = 7.98992 loss)
I0523 06:39:09.149561 34819 sgd_solver.cpp:112] Iteration 63710, lr = 0.01
I0523 06:39:13.770126 34819 solver.cpp:239] Iteration 63720 (2.12895 iter/s, 4.69715s/10 iters), loss = 7.60094
I0523 06:39:13.770175 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60094 (* 1 = 7.60094 loss)
I0523 06:39:14.369786 34819 sgd_solver.cpp:112] Iteration 63720, lr = 0.01
I0523 06:39:19.303596 34819 solver.cpp:239] Iteration 63730 (1.80728 iter/s, 5.53318s/10 iters), loss = 7.77838
I0523 06:39:19.303642 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77838 (* 1 = 7.77838 loss)
I0523 06:39:19.365891 34819 sgd_solver.cpp:112] Iteration 63730, lr = 0.01
I0523 06:39:24.022784 34819 solver.cpp:239] Iteration 63740 (2.11912 iter/s, 4.71894s/10 iters), loss = 9.56787
I0523 06:39:24.022845 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.56787 (* 1 = 9.56787 loss)
I0523 06:39:24.099822 34819 sgd_solver.cpp:112] Iteration 63740, lr = 0.01
I0523 06:39:28.945694 34819 solver.cpp:239] Iteration 63750 (2.03143 iter/s, 4.92265s/10 iters), loss = 7.8097
I0523 06:39:28.945739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8097 (* 1 = 7.8097 loss)
I0523 06:39:29.015470 34819 sgd_solver.cpp:112] Iteration 63750, lr = 0.01
I0523 06:39:32.371805 34819 solver.cpp:239] Iteration 63760 (2.91893 iter/s, 3.42592s/10 iters), loss = 8.37658
I0523 06:39:32.371850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37658 (* 1 = 8.37658 loss)
I0523 06:39:32.446633 34819 sgd_solver.cpp:112] Iteration 63760, lr = 0.01
I0523 06:39:36.724520 34819 solver.cpp:239] Iteration 63770 (2.29754 iter/s, 4.35247s/10 iters), loss = 8.75838
I0523 06:39:36.724658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75838 (* 1 = 8.75838 loss)
I0523 06:39:37.540015 34819 sgd_solver.cpp:112] Iteration 63770, lr = 0.01
I0523 06:39:41.919250 34819 solver.cpp:239] Iteration 63780 (1.92516 iter/s, 5.19438s/10 iters), loss = 8.95129
I0523 06:39:41.919293 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95129 (* 1 = 8.95129 loss)
I0523 06:39:42.756942 34819 sgd_solver.cpp:112] Iteration 63780, lr = 0.01
I0523 06:39:48.226420 34819 solver.cpp:239] Iteration 63790 (1.58557 iter/s, 6.30687s/10 iters), loss = 8.48585
I0523 06:39:48.226469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48585 (* 1 = 8.48585 loss)
I0523 06:39:48.979353 34819 sgd_solver.cpp:112] Iteration 63790, lr = 0.01
I0523 06:39:53.317883 34819 solver.cpp:239] Iteration 63800 (1.96418 iter/s, 5.09119s/10 iters), loss = 8.33277
I0523 06:39:53.317934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33277 (* 1 = 8.33277 loss)
I0523 06:39:53.386489 34819 sgd_solver.cpp:112] Iteration 63800, lr = 0.01
I0523 06:39:57.614502 34819 solver.cpp:239] Iteration 63810 (2.32754 iter/s, 4.29637s/10 iters), loss = 8.39412
I0523 06:39:57.614562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39412 (* 1 = 8.39412 loss)
I0523 06:39:57.687361 34819 sgd_solver.cpp:112] Iteration 63810, lr = 0.01
I0523 06:40:00.146875 34819 solver.cpp:239] Iteration 63820 (3.94916 iter/s, 2.53219s/10 iters), loss = 9.02221
I0523 06:40:00.146929 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.02221 (* 1 = 9.02221 loss)
I0523 06:40:00.218204 34819 sgd_solver.cpp:112] Iteration 63820, lr = 0.01
I0523 06:40:05.136103 34819 solver.cpp:239] Iteration 63830 (2.00442 iter/s, 4.98897s/10 iters), loss = 8.38995
I0523 06:40:05.136144 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38995 (* 1 = 8.38995 loss)
I0523 06:40:05.190623 34819 sgd_solver.cpp:112] Iteration 63830, lr = 0.01
I0523 06:40:07.775372 34819 solver.cpp:239] Iteration 63840 (3.78923 iter/s, 2.63906s/10 iters), loss = 7.84702
I0523 06:40:07.775552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84702 (* 1 = 7.84702 loss)
I0523 06:40:08.521739 34819 sgd_solver.cpp:112] Iteration 63840, lr = 0.01
I0523 06:40:14.721474 34819 solver.cpp:239] Iteration 63850 (1.43975 iter/s, 6.94565s/10 iters), loss = 8.4065
I0523 06:40:14.721516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4065 (* 1 = 8.4065 loss)
I0523 06:40:15.595103 34819 sgd_solver.cpp:112] Iteration 63850, lr = 0.01
I0523 06:40:19.007478 34819 solver.cpp:239] Iteration 63860 (2.3333 iter/s, 4.28577s/10 iters), loss = 8.04824
I0523 06:40:19.007525 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04824 (* 1 = 8.04824 loss)
I0523 06:40:19.841229 34819 sgd_solver.cpp:112] Iteration 63860, lr = 0.01
I0523 06:40:23.827780 34819 solver.cpp:239] Iteration 63870 (2.07467 iter/s, 4.82005s/10 iters), loss = 7.78445
I0523 06:40:23.827837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78445 (* 1 = 7.78445 loss)
I0523 06:40:23.885673 34819 sgd_solver.cpp:112] Iteration 63870, lr = 0.01
I0523 06:40:28.683794 34819 solver.cpp:239] Iteration 63880 (2.05941 iter/s, 4.85576s/10 iters), loss = 8.26593
I0523 06:40:28.683850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26593 (* 1 = 8.26593 loss)
I0523 06:40:28.748893 34819 sgd_solver.cpp:112] Iteration 63880, lr = 0.01
I0523 06:40:31.841321 34819 solver.cpp:239] Iteration 63890 (3.16725 iter/s, 3.15731s/10 iters), loss = 7.3824
I0523 06:40:31.841400 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3824 (* 1 = 7.3824 loss)
I0523 06:40:32.674794 34819 sgd_solver.cpp:112] Iteration 63890, lr = 0.01
I0523 06:40:37.215457 34819 solver.cpp:239] Iteration 63900 (1.86088 iter/s, 5.37381s/10 iters), loss = 8.1425
I0523 06:40:37.215513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1425 (* 1 = 8.1425 loss)
I0523 06:40:38.052287 34819 sgd_solver.cpp:112] Iteration 63900, lr = 0.01
I0523 06:40:41.447011 34819 solver.cpp:239] Iteration 63910 (2.36333 iter/s, 4.23132s/10 iters), loss = 8.50594
I0523 06:40:41.447052 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50594 (* 1 = 8.50594 loss)
I0523 06:40:42.297217 34819 sgd_solver.cpp:112] Iteration 63910, lr = 0.01
I0523 06:40:48.791586 34819 solver.cpp:239] Iteration 63920 (1.36161 iter/s, 7.34423s/10 iters), loss = 7.66752
I0523 06:40:48.791627 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66752 (* 1 = 7.66752 loss)
I0523 06:40:48.866578 34819 sgd_solver.cpp:112] Iteration 63920, lr = 0.01
I0523 06:40:54.530293 34819 solver.cpp:239] Iteration 63930 (1.74264 iter/s, 5.73843s/10 iters), loss = 9.08646
I0523 06:40:54.530333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08646 (* 1 = 9.08646 loss)
I0523 06:40:54.606992 34819 sgd_solver.cpp:112] Iteration 63930, lr = 0.01
I0523 06:40:58.350987 34819 solver.cpp:239] Iteration 63940 (2.61747 iter/s, 3.82048s/10 iters), loss = 8.25362
I0523 06:40:58.351027 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25362 (* 1 = 8.25362 loss)
I0523 06:40:58.424114 34819 sgd_solver.cpp:112] Iteration 63940, lr = 0.01
I0523 06:41:02.654547 34819 solver.cpp:239] Iteration 63950 (2.32378 iter/s, 4.30333s/10 iters), loss = 7.61992
I0523 06:41:02.654588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61992 (* 1 = 7.61992 loss)
I0523 06:41:02.721969 34819 sgd_solver.cpp:112] Iteration 63950, lr = 0.01
I0523 06:41:06.257632 34819 solver.cpp:239] Iteration 63960 (2.77556 iter/s, 3.60287s/10 iters), loss = 9.04958
I0523 06:41:06.257673 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04958 (* 1 = 9.04958 loss)
I0523 06:41:06.327044 34819 sgd_solver.cpp:112] Iteration 63960, lr = 0.01
I0523 06:41:11.884110 34819 solver.cpp:239] Iteration 63970 (1.7774 iter/s, 5.6262s/10 iters), loss = 8.09905
I0523 06:41:11.884268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09905 (* 1 = 8.09905 loss)
I0523 06:41:12.737005 34819 sgd_solver.cpp:112] Iteration 63970, lr = 0.01
I0523 06:41:17.730229 34819 solver.cpp:239] Iteration 63980 (1.71065 iter/s, 5.84573s/10 iters), loss = 8.48709
I0523 06:41:17.730269 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48709 (* 1 = 8.48709 loss)
I0523 06:41:17.790303 34819 sgd_solver.cpp:112] Iteration 63980, lr = 0.01
I0523 06:41:20.406190 34819 solver.cpp:239] Iteration 63990 (3.73721 iter/s, 2.67579s/10 iters), loss = 8.11727
I0523 06:41:20.406232 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11727 (* 1 = 8.11727 loss)
I0523 06:41:20.464893 34819 sgd_solver.cpp:112] Iteration 63990, lr = 0.01
I0523 06:41:24.402115 34819 solver.cpp:239] Iteration 64000 (2.50268 iter/s, 3.99572s/10 iters), loss = 8.48936
I0523 06:41:24.402155 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48936 (* 1 = 8.48936 loss)
I0523 06:41:25.286844 34819 sgd_solver.cpp:112] Iteration 64000, lr = 0.01
I0523 06:41:31.000022 34819 solver.cpp:239] Iteration 64010 (1.5157 iter/s, 6.59759s/10 iters), loss = 8.23452
I0523 06:41:31.000063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23452 (* 1 = 8.23452 loss)
I0523 06:41:31.659027 34819 sgd_solver.cpp:112] Iteration 64010, lr = 0.01
I0523 06:41:36.425498 34819 solver.cpp:239] Iteration 64020 (1.84325 iter/s, 5.42521s/10 iters), loss = 8.32963
I0523 06:41:36.425537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32963 (* 1 = 8.32963 loss)
I0523 06:41:36.502341 34819 sgd_solver.cpp:112] Iteration 64020, lr = 0.01
I0523 06:41:41.502233 34819 solver.cpp:239] Iteration 64030 (1.96988 iter/s, 5.07645s/10 iters), loss = 8.38111
I0523 06:41:41.502287 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38111 (* 1 = 8.38111 loss)
I0523 06:41:42.367084 34819 sgd_solver.cpp:112] Iteration 64030, lr = 0.01
I0523 06:41:46.057371 34819 solver.cpp:239] Iteration 64040 (2.19544 iter/s, 4.55489s/10 iters), loss = 8.33641
I0523 06:41:46.057412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33641 (* 1 = 8.33641 loss)
I0523 06:41:46.126451 34819 sgd_solver.cpp:112] Iteration 64040, lr = 0.01
I0523 06:41:49.921393 34819 solver.cpp:239] Iteration 64050 (2.58813 iter/s, 3.86379s/10 iters), loss = 8.66219
I0523 06:41:49.921452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66219 (* 1 = 8.66219 loss)
I0523 06:41:50.716187 34819 sgd_solver.cpp:112] Iteration 64050, lr = 0.01
I0523 06:41:55.526682 34819 solver.cpp:239] Iteration 64060 (1.78412 iter/s, 5.605s/10 iters), loss = 8.54081
I0523 06:41:55.526734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54081 (* 1 = 8.54081 loss)
I0523 06:41:55.600558 34819 sgd_solver.cpp:112] Iteration 64060, lr = 0.01
I0523 06:41:58.630656 34819 solver.cpp:239] Iteration 64070 (3.22188 iter/s, 3.10378s/10 iters), loss = 8.6707
I0523 06:41:58.630712 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6707 (* 1 = 8.6707 loss)
I0523 06:41:58.687983 34819 sgd_solver.cpp:112] Iteration 64070, lr = 0.01
I0523 06:42:03.859117 34819 solver.cpp:239] Iteration 64080 (1.91271 iter/s, 5.2282s/10 iters), loss = 7.735
I0523 06:42:03.859158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.735 (* 1 = 7.735 loss)
I0523 06:42:04.729704 34819 sgd_solver.cpp:112] Iteration 64080, lr = 0.01
I0523 06:42:10.512814 34819 solver.cpp:239] Iteration 64090 (1.503 iter/s, 6.65338s/10 iters), loss = 8.07578
I0523 06:42:10.512876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07578 (* 1 = 8.07578 loss)
I0523 06:42:11.030416 34819 sgd_solver.cpp:112] Iteration 64090, lr = 0.01
I0523 06:42:15.448746 34819 solver.cpp:239] Iteration 64100 (2.02606 iter/s, 4.93568s/10 iters), loss = 7.49501
I0523 06:42:15.448887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.49501 (* 1 = 7.49501 loss)
I0523 06:42:15.519686 34819 sgd_solver.cpp:112] Iteration 64100, lr = 0.01
I0523 06:42:21.185374 34819 solver.cpp:239] Iteration 64110 (1.7433 iter/s, 5.73625s/10 iters), loss = 8.45033
I0523 06:42:21.185420 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45033 (* 1 = 8.45033 loss)
I0523 06:42:22.030611 34819 sgd_solver.cpp:112] Iteration 64110, lr = 0.01
I0523 06:42:25.921365 34819 solver.cpp:239] Iteration 64120 (2.1116 iter/s, 4.73574s/10 iters), loss = 8.76376
I0523 06:42:25.921413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76376 (* 1 = 8.76376 loss)
I0523 06:42:26.753756 34819 sgd_solver.cpp:112] Iteration 64120, lr = 0.01
I0523 06:42:29.960237 34819 solver.cpp:239] Iteration 64130 (2.47607 iter/s, 4.03865s/10 iters), loss = 8.67326
I0523 06:42:29.960286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67326 (* 1 = 8.67326 loss)
I0523 06:42:30.037917 34819 sgd_solver.cpp:112] Iteration 64130, lr = 0.01
I0523 06:42:34.892601 34819 solver.cpp:239] Iteration 64140 (2.02754 iter/s, 4.93209s/10 iters), loss = 7.69891
I0523 06:42:34.892653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69891 (* 1 = 7.69891 loss)
I0523 06:42:35.735981 34819 sgd_solver.cpp:112] Iteration 64140, lr = 0.01
I0523 06:42:39.497581 34819 solver.cpp:239] Iteration 64150 (2.17168 iter/s, 4.60472s/10 iters), loss = 7.55043
I0523 06:42:39.497622 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55043 (* 1 = 7.55043 loss)
I0523 06:42:40.347245 34819 sgd_solver.cpp:112] Iteration 64150, lr = 0.01
I0523 06:42:44.449842 34819 solver.cpp:239] Iteration 64160 (2.01939 iter/s, 4.95199s/10 iters), loss = 7.03478
I0523 06:42:44.449908 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.03478 (* 1 = 7.03478 loss)
I0523 06:42:44.530462 34819 sgd_solver.cpp:112] Iteration 64160, lr = 0.01
I0523 06:42:48.870571 34819 solver.cpp:239] Iteration 64170 (2.2622 iter/s, 4.42048s/10 iters), loss = 8.22686
I0523 06:42:48.870730 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22686 (* 1 = 8.22686 loss)
I0523 06:42:49.552573 34819 sgd_solver.cpp:112] Iteration 64170, lr = 0.01
I0523 06:42:55.522287 34819 solver.cpp:239] Iteration 64180 (1.50347 iter/s, 6.65128s/10 iters), loss = 8.64765
I0523 06:42:55.522341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64765 (* 1 = 8.64765 loss)
I0523 06:42:55.583425 34819 sgd_solver.cpp:112] Iteration 64180, lr = 0.01
I0523 06:43:01.523983 34819 solver.cpp:239] Iteration 64190 (1.66628 iter/s, 6.00139s/10 iters), loss = 7.39703
I0523 06:43:01.524044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39703 (* 1 = 7.39703 loss)
I0523 06:43:01.665725 34819 sgd_solver.cpp:112] Iteration 64190, lr = 0.01
I0523 06:43:05.435848 34819 solver.cpp:239] Iteration 64200 (2.55647 iter/s, 3.91164s/10 iters), loss = 7.96904
I0523 06:43:05.435900 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96904 (* 1 = 7.96904 loss)
I0523 06:43:05.511562 34819 sgd_solver.cpp:112] Iteration 64200, lr = 0.01
I0523 06:43:08.756088 34819 solver.cpp:239] Iteration 64210 (3.01201 iter/s, 3.32005s/10 iters), loss = 8.04462
I0523 06:43:08.756134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04462 (* 1 = 8.04462 loss)
I0523 06:43:09.576694 34819 sgd_solver.cpp:112] Iteration 64210, lr = 0.01
I0523 06:43:15.241966 34819 solver.cpp:239] Iteration 64220 (1.54189 iter/s, 6.48556s/10 iters), loss = 8.13894
I0523 06:43:15.242020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13894 (* 1 = 8.13894 loss)
I0523 06:43:15.311601 34819 sgd_solver.cpp:112] Iteration 64220, lr = 0.01
I0523 06:43:20.040364 34819 solver.cpp:239] Iteration 64230 (2.08415 iter/s, 4.79812s/10 iters), loss = 8.55173
I0523 06:43:20.040616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55173 (* 1 = 8.55173 loss)
I0523 06:43:20.908485 34819 sgd_solver.cpp:112] Iteration 64230, lr = 0.01
I0523 06:43:25.769624 34819 solver.cpp:239] Iteration 64240 (1.74557 iter/s, 5.72878s/10 iters), loss = 8.40414
I0523 06:43:25.769699 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40414 (* 1 = 8.40414 loss)
I0523 06:43:26.597656 34819 sgd_solver.cpp:112] Iteration 64240, lr = 0.01
I0523 06:43:30.745290 34819 solver.cpp:239] Iteration 64250 (2.00989 iter/s, 4.97538s/10 iters), loss = 7.77324
I0523 06:43:30.745347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77324 (* 1 = 7.77324 loss)
I0523 06:43:30.802212 34819 sgd_solver.cpp:112] Iteration 64250, lr = 0.01
I0523 06:43:35.960005 34819 solver.cpp:239] Iteration 64260 (1.91775 iter/s, 5.21444s/10 iters), loss = 8.60966
I0523 06:43:35.960047 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60966 (* 1 = 8.60966 loss)
I0523 06:43:36.814662 34819 sgd_solver.cpp:112] Iteration 64260, lr = 0.01
I0523 06:43:42.287158 34819 solver.cpp:239] Iteration 64270 (1.58057 iter/s, 6.32685s/10 iters), loss = 8.4418
I0523 06:43:42.287200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4418 (* 1 = 8.4418 loss)
I0523 06:43:42.346032 34819 sgd_solver.cpp:112] Iteration 64270, lr = 0.01
I0523 06:43:47.548143 34819 solver.cpp:239] Iteration 64280 (1.90089 iter/s, 5.2607s/10 iters), loss = 8.37358
I0523 06:43:47.548202 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37358 (* 1 = 8.37358 loss)
I0523 06:43:47.613221 34819 sgd_solver.cpp:112] Iteration 64280, lr = 0.01
I0523 06:43:51.574286 34819 solver.cpp:239] Iteration 64290 (2.48391 iter/s, 4.02591s/10 iters), loss = 8.64458
I0523 06:43:51.574434 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64458 (* 1 = 8.64458 loss)
I0523 06:43:52.088958 34819 sgd_solver.cpp:112] Iteration 64290, lr = 0.01
I0523 06:43:56.056571 34819 solver.cpp:239] Iteration 64300 (2.23117 iter/s, 4.48196s/10 iters), loss = 8.52483
I0523 06:43:56.056641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52483 (* 1 = 8.52483 loss)
I0523 06:43:56.718782 34819 sgd_solver.cpp:112] Iteration 64300, lr = 0.01
I0523 06:44:03.355834 34819 solver.cpp:239] Iteration 64310 (1.37007 iter/s, 7.29889s/10 iters), loss = 8.68439
I0523 06:44:03.355886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68439 (* 1 = 8.68439 loss)
I0523 06:44:03.416036 34819 sgd_solver.cpp:112] Iteration 64310, lr = 0.01
I0523 06:44:06.028949 34819 solver.cpp:239] Iteration 64320 (3.74119 iter/s, 2.67294s/10 iters), loss = 7.62034
I0523 06:44:06.028991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62034 (* 1 = 7.62034 loss)
I0523 06:44:06.856544 34819 sgd_solver.cpp:112] Iteration 64320, lr = 0.01
I0523 06:44:12.394352 34819 solver.cpp:239] Iteration 64330 (1.57107 iter/s, 6.3651s/10 iters), loss = 9.00088
I0523 06:44:12.394410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00088 (* 1 = 9.00088 loss)
I0523 06:44:12.452726 34819 sgd_solver.cpp:112] Iteration 64330, lr = 0.01
I0523 06:44:17.207446 34819 solver.cpp:239] Iteration 64340 (2.07778 iter/s, 4.81282s/10 iters), loss = 8.54896
I0523 06:44:17.207499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54896 (* 1 = 8.54896 loss)
I0523 06:44:17.269327 34819 sgd_solver.cpp:112] Iteration 64340, lr = 0.01
I0523 06:44:23.754953 34819 solver.cpp:239] Iteration 64350 (1.52738 iter/s, 6.54718s/10 iters), loss = 8.22986
I0523 06:44:23.755223 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22986 (* 1 = 8.22986 loss)
I0523 06:44:24.624536 34819 sgd_solver.cpp:112] Iteration 64350, lr = 0.01
I0523 06:44:29.420320 34819 solver.cpp:239] Iteration 64360 (1.76526 iter/s, 5.6649s/10 iters), loss = 9.24178
I0523 06:44:29.420377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24178 (* 1 = 9.24178 loss)
I0523 06:44:29.493501 34819 sgd_solver.cpp:112] Iteration 64360, lr = 0.01
I0523 06:44:34.439483 34819 solver.cpp:239] Iteration 64370 (1.99247 iter/s, 5.01891s/10 iters), loss = 7.59419
I0523 06:44:34.439524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59419 (* 1 = 7.59419 loss)
I0523 06:44:34.959704 34819 sgd_solver.cpp:112] Iteration 64370, lr = 0.01
I0523 06:44:40.650918 34819 solver.cpp:239] Iteration 64380 (1.61001 iter/s, 6.21114s/10 iters), loss = 8.20926
I0523 06:44:40.650959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20926 (* 1 = 8.20926 loss)
I0523 06:44:40.706802 34819 sgd_solver.cpp:112] Iteration 64380, lr = 0.01
I0523 06:44:43.696665 34819 solver.cpp:239] Iteration 64390 (3.28347 iter/s, 3.04556s/10 iters), loss = 7.343
I0523 06:44:43.696722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.343 (* 1 = 7.343 loss)
I0523 06:44:44.512986 34819 sgd_solver.cpp:112] Iteration 64390, lr = 0.01
I0523 06:44:49.192629 34819 solver.cpp:239] Iteration 64400 (1.81961 iter/s, 5.49569s/10 iters), loss = 7.19205
I0523 06:44:49.192672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.19205 (* 1 = 7.19205 loss)
I0523 06:44:49.750775 34819 sgd_solver.cpp:112] Iteration 64400, lr = 0.01
I0523 06:44:53.738509 34819 solver.cpp:239] Iteration 64410 (2.19991 iter/s, 4.54563s/10 iters), loss = 7.61559
I0523 06:44:53.738574 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61559 (* 1 = 7.61559 loss)
I0523 06:44:54.501690 34819 sgd_solver.cpp:112] Iteration 64410, lr = 0.01
I0523 06:45:00.007146 34819 solver.cpp:239] Iteration 64420 (1.59532 iter/s, 6.26832s/10 iters), loss = 8.50199
I0523 06:45:00.007192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50199 (* 1 = 8.50199 loss)
I0523 06:45:00.825965 34819 sgd_solver.cpp:112] Iteration 64420, lr = 0.01
I0523 06:45:07.358111 34819 solver.cpp:239] Iteration 64430 (1.36043 iter/s, 7.35061s/10 iters), loss = 8.92304
I0523 06:45:07.358163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92304 (* 1 = 8.92304 loss)
I0523 06:45:07.862491 34819 sgd_solver.cpp:112] Iteration 64430, lr = 0.01
I0523 06:45:11.633049 34819 solver.cpp:239] Iteration 64440 (2.33935 iter/s, 4.27469s/10 iters), loss = 7.89023
I0523 06:45:11.633106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89023 (* 1 = 7.89023 loss)
I0523 06:45:12.392051 34819 sgd_solver.cpp:112] Iteration 64440, lr = 0.01
I0523 06:45:16.432552 34819 solver.cpp:239] Iteration 64450 (2.08367 iter/s, 4.79923s/10 iters), loss = 7.99297
I0523 06:45:16.432605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99297 (* 1 = 7.99297 loss)
I0523 06:45:17.082619 34819 sgd_solver.cpp:112] Iteration 64450, lr = 0.01
I0523 06:45:23.210337 34819 solver.cpp:239] Iteration 64460 (1.47548 iter/s, 6.77745s/10 iters), loss = 7.06334
I0523 06:45:23.210377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.06334 (* 1 = 7.06334 loss)
I0523 06:45:23.278306 34819 sgd_solver.cpp:112] Iteration 64460, lr = 0.01
I0523 06:45:28.287207 34819 solver.cpp:239] Iteration 64470 (1.96982 iter/s, 5.0766s/10 iters), loss = 8.93913
I0523 06:45:28.287367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93913 (* 1 = 8.93913 loss)
I0523 06:45:29.090709 34819 sgd_solver.cpp:112] Iteration 64470, lr = 0.01
I0523 06:45:35.273047 34819 solver.cpp:239] Iteration 64480 (1.43156 iter/s, 6.9854s/10 iters), loss = 7.97828
I0523 06:45:35.273090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97828 (* 1 = 7.97828 loss)
I0523 06:45:35.346452 34819 sgd_solver.cpp:112] Iteration 64480, lr = 0.01
I0523 06:45:39.552911 34819 solver.cpp:239] Iteration 64490 (2.33665 iter/s, 4.27964s/10 iters), loss = 8.09609
I0523 06:45:39.552954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09609 (* 1 = 8.09609 loss)
I0523 06:45:40.377308 34819 sgd_solver.cpp:112] Iteration 64490, lr = 0.01
I0523 06:45:45.249039 34819 solver.cpp:239] Iteration 64500 (1.75567 iter/s, 5.69584s/10 iters), loss = 7.76768
I0523 06:45:45.249078 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76768 (* 1 = 7.76768 loss)
I0523 06:45:45.322216 34819 sgd_solver.cpp:112] Iteration 64500, lr = 0.01
I0523 06:45:50.822087 34819 solver.cpp:239] Iteration 64510 (1.79444 iter/s, 5.57277s/10 iters), loss = 8.22774
I0523 06:45:50.822129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22774 (* 1 = 8.22774 loss)
I0523 06:45:50.897716 34819 sgd_solver.cpp:112] Iteration 64510, lr = 0.01
I0523 06:45:55.838143 34819 solver.cpp:239] Iteration 64520 (1.9937 iter/s, 5.01581s/10 iters), loss = 8.38331
I0523 06:45:55.838184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38331 (* 1 = 8.38331 loss)
I0523 06:45:55.911015 34819 sgd_solver.cpp:112] Iteration 64520, lr = 0.01
I0523 06:46:01.067028 34819 solver.cpp:239] Iteration 64530 (1.91255 iter/s, 5.22862s/10 iters), loss = 8.23262
I0523 06:46:01.067216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23262 (* 1 = 8.23262 loss)
I0523 06:46:01.139459 34819 sgd_solver.cpp:112] Iteration 64530, lr = 0.01
I0523 06:46:05.565881 34819 solver.cpp:239] Iteration 64540 (2.22507 iter/s, 4.49424s/10 iters), loss = 7.19978
I0523 06:46:05.565937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.19978 (* 1 = 7.19978 loss)
I0523 06:46:06.382685 34819 sgd_solver.cpp:112] Iteration 64540, lr = 0.01
I0523 06:46:10.911437 34819 solver.cpp:239] Iteration 64550 (1.87081 iter/s, 5.34527s/10 iters), loss = 8.6928
I0523 06:46:10.911490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6928 (* 1 = 8.6928 loss)
I0523 06:46:11.605144 34819 sgd_solver.cpp:112] Iteration 64550, lr = 0.01
I0523 06:46:14.207907 34819 solver.cpp:239] Iteration 64560 (3.03708 iter/s, 3.29263s/10 iters), loss = 7.77851
I0523 06:46:14.207952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77851 (* 1 = 7.77851 loss)
I0523 06:46:14.258416 34819 sgd_solver.cpp:112] Iteration 64560, lr = 0.01
I0523 06:46:19.343386 34819 solver.cpp:239] Iteration 64570 (1.94734 iter/s, 5.13522s/10 iters), loss = 7.59268
I0523 06:46:19.343435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59268 (* 1 = 7.59268 loss)
I0523 06:46:19.414652 34819 sgd_solver.cpp:112] Iteration 64570, lr = 0.01
I0523 06:46:21.406044 34819 solver.cpp:239] Iteration 64580 (4.84847 iter/s, 2.06251s/10 iters), loss = 7.93468
I0523 06:46:21.406097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93468 (* 1 = 7.93468 loss)
I0523 06:46:22.274621 34819 sgd_solver.cpp:112] Iteration 64580, lr = 0.01
I0523 06:46:27.569622 34819 solver.cpp:239] Iteration 64590 (1.62251 iter/s, 6.16327s/10 iters), loss = 8.20181
I0523 06:46:27.569664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20181 (* 1 = 8.20181 loss)
I0523 06:46:27.633432 34819 sgd_solver.cpp:112] Iteration 64590, lr = 0.01
I0523 06:46:33.253770 34819 solver.cpp:239] Iteration 64600 (1.75937 iter/s, 5.68386s/10 iters), loss = 8.44105
I0523 06:46:33.253897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44105 (* 1 = 8.44105 loss)
I0523 06:46:33.325419 34819 sgd_solver.cpp:112] Iteration 64600, lr = 0.01
I0523 06:46:36.619664 34819 solver.cpp:239] Iteration 64610 (2.97121 iter/s, 3.36563s/10 iters), loss = 7.8394
I0523 06:46:36.619709 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8394 (* 1 = 7.8394 loss)
I0523 06:46:37.415057 34819 sgd_solver.cpp:112] Iteration 64610, lr = 0.01
I0523 06:46:42.918927 34819 solver.cpp:239] Iteration 64620 (1.58756 iter/s, 6.29896s/10 iters), loss = 8.48993
I0523 06:46:42.918969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48993 (* 1 = 8.48993 loss)
I0523 06:46:42.999709 34819 sgd_solver.cpp:112] Iteration 64620, lr = 0.01
I0523 06:46:48.656800 34819 solver.cpp:239] Iteration 64630 (1.74289 iter/s, 5.73759s/10 iters), loss = 8.25823
I0523 06:46:48.656846 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25823 (* 1 = 8.25823 loss)
I0523 06:46:49.258225 34819 sgd_solver.cpp:112] Iteration 64630, lr = 0.01
I0523 06:46:54.904028 34819 solver.cpp:239] Iteration 64640 (1.60079 iter/s, 6.24693s/10 iters), loss = 8.05078
I0523 06:46:54.904070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05078 (* 1 = 8.05078 loss)
I0523 06:46:55.621577 34819 sgd_solver.cpp:112] Iteration 64640, lr = 0.01
I0523 06:47:01.049695 34819 solver.cpp:239] Iteration 64650 (1.62724 iter/s, 6.14537s/10 iters), loss = 8.69723
I0523 06:47:01.049738 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69723 (* 1 = 8.69723 loss)
I0523 06:47:01.135910 34819 sgd_solver.cpp:112] Iteration 64650, lr = 0.01
I0523 06:47:06.114738 34819 solver.cpp:239] Iteration 64660 (1.97443 iter/s, 5.06476s/10 iters), loss = 7.39495
I0523 06:47:06.114881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39495 (* 1 = 7.39495 loss)
I0523 06:47:06.945600 34819 sgd_solver.cpp:112] Iteration 64660, lr = 0.01
I0523 06:47:11.167701 34819 solver.cpp:239] Iteration 64670 (1.97917 iter/s, 5.05261s/10 iters), loss = 8.70922
I0523 06:47:11.167742 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70922 (* 1 = 8.70922 loss)
I0523 06:47:11.227766 34819 sgd_solver.cpp:112] Iteration 64670, lr = 0.01
I0523 06:47:15.599999 34819 solver.cpp:239] Iteration 64680 (2.25629 iter/s, 4.43204s/10 iters), loss = 8.12098
I0523 06:47:15.600051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12098 (* 1 = 8.12098 loss)
I0523 06:47:16.421509 34819 sgd_solver.cpp:112] Iteration 64680, lr = 0.01
I0523 06:47:20.535712 34819 solver.cpp:239] Iteration 64690 (2.02615 iter/s, 4.93546s/10 iters), loss = 8.97451
I0523 06:47:20.535754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97451 (* 1 = 8.97451 loss)
I0523 06:47:20.598963 34819 sgd_solver.cpp:112] Iteration 64690, lr = 0.01
I0523 06:47:25.378960 34819 solver.cpp:239] Iteration 64700 (2.06484 iter/s, 4.84299s/10 iters), loss = 8.50112
I0523 06:47:25.379011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50112 (* 1 = 8.50112 loss)
I0523 06:47:25.442245 34819 sgd_solver.cpp:112] Iteration 64700, lr = 0.01
I0523 06:47:29.952960 34819 solver.cpp:239] Iteration 64710 (2.18639 iter/s, 4.57376s/10 iters), loss = 7.93427
I0523 06:47:29.953003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93427 (* 1 = 7.93427 loss)
I0523 06:47:30.022280 34819 sgd_solver.cpp:112] Iteration 64710, lr = 0.01
I0523 06:47:34.237809 34819 solver.cpp:239] Iteration 64720 (2.33393 iter/s, 4.28461s/10 iters), loss = 8.26484
I0523 06:47:34.237861 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26484 (* 1 = 8.26484 loss)
I0523 06:47:35.015951 34819 sgd_solver.cpp:112] Iteration 64720, lr = 0.01
I0523 06:47:39.006836 34819 solver.cpp:239] Iteration 64730 (2.09698 iter/s, 4.76877s/10 iters), loss = 8.51124
I0523 06:47:39.006999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51124 (* 1 = 8.51124 loss)
I0523 06:47:39.087357 34819 sgd_solver.cpp:112] Iteration 64730, lr = 0.01
I0523 06:47:43.320471 34819 solver.cpp:239] Iteration 64740 (2.31841 iter/s, 4.3133s/10 iters), loss = 7.87701
I0523 06:47:43.320515 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87701 (* 1 = 7.87701 loss)
I0523 06:47:43.378041 34819 sgd_solver.cpp:112] Iteration 64740, lr = 0.01
I0523 06:47:49.099498 34819 solver.cpp:239] Iteration 64750 (1.73048 iter/s, 5.77874s/10 iters), loss = 8.22564
I0523 06:47:49.099553 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22564 (* 1 = 8.22564 loss)
I0523 06:47:49.183437 34819 sgd_solver.cpp:112] Iteration 64750, lr = 0.01
I0523 06:47:56.360527 34819 solver.cpp:239] Iteration 64760 (1.37728 iter/s, 7.26068s/10 iters), loss = 8.49387
I0523 06:47:56.360570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49387 (* 1 = 8.49387 loss)
I0523 06:47:56.419796 34819 sgd_solver.cpp:112] Iteration 64760, lr = 0.01
I0523 06:48:02.862819 34819 solver.cpp:239] Iteration 64770 (1.53799 iter/s, 6.50198s/10 iters), loss = 8.49194
I0523 06:48:02.862872 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49194 (* 1 = 8.49194 loss)
I0523 06:48:03.695322 34819 sgd_solver.cpp:112] Iteration 64770, lr = 0.01
I0523 06:48:06.871706 34819 solver.cpp:239] Iteration 64780 (2.4946 iter/s, 4.00865s/10 iters), loss = 9.28978
I0523 06:48:06.871758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28978 (* 1 = 9.28978 loss)
I0523 06:48:06.945789 34819 sgd_solver.cpp:112] Iteration 64780, lr = 0.01
I0523 06:48:12.414994 34819 solver.cpp:239] Iteration 64790 (1.80408 iter/s, 5.543s/10 iters), loss = 8.36833
I0523 06:48:12.415206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36833 (* 1 = 8.36833 loss)
I0523 06:48:12.487783 34819 sgd_solver.cpp:112] Iteration 64790, lr = 0.01
I0523 06:48:18.527416 34819 solver.cpp:239] Iteration 64800 (1.63614 iter/s, 6.11196s/10 iters), loss = 8.1757
I0523 06:48:18.527470 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1757 (* 1 = 8.1757 loss)
I0523 06:48:18.584161 34819 sgd_solver.cpp:112] Iteration 64800, lr = 0.01
I0523 06:48:24.601171 34819 solver.cpp:239] Iteration 64810 (1.64651 iter/s, 6.07344s/10 iters), loss = 8.1815
I0523 06:48:24.601225 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1815 (* 1 = 8.1815 loss)
I0523 06:48:24.663915 34819 sgd_solver.cpp:112] Iteration 64810, lr = 0.01
I0523 06:48:30.301787 34819 solver.cpp:239] Iteration 64820 (1.7543 iter/s, 5.70029s/10 iters), loss = 7.93921
I0523 06:48:30.301849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93921 (* 1 = 7.93921 loss)
I0523 06:48:31.161322 34819 sgd_solver.cpp:112] Iteration 64820, lr = 0.01
I0523 06:48:35.330731 34819 solver.cpp:239] Iteration 64830 (1.9886 iter/s, 5.02866s/10 iters), loss = 8.89947
I0523 06:48:35.330773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89947 (* 1 = 8.89947 loss)
I0523 06:48:35.391093 34819 sgd_solver.cpp:112] Iteration 64830, lr = 0.01
I0523 06:48:39.999176 34819 solver.cpp:239] Iteration 64840 (2.14216 iter/s, 4.66819s/10 iters), loss = 7.16169
I0523 06:48:39.999233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.16169 (* 1 = 7.16169 loss)
I0523 06:48:40.056452 34819 sgd_solver.cpp:112] Iteration 64840, lr = 0.01
I0523 06:48:45.852399 34819 solver.cpp:239] Iteration 64850 (1.70855 iter/s, 5.85293s/10 iters), loss = 7.47045
I0523 06:48:45.852485 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47045 (* 1 = 7.47045 loss)
I0523 06:48:45.922716 34819 sgd_solver.cpp:112] Iteration 64850, lr = 0.01
I0523 06:48:48.127095 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 06:48:50.762624 34819 solver.cpp:239] Iteration 64860 (2.03669 iter/s, 4.90993s/10 iters), loss = 8.14866
I0523 06:48:50.762671 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14866 (* 1 = 8.14866 loss)
I0523 06:48:51.587656 34819 sgd_solver.cpp:112] Iteration 64860, lr = 0.01
I0523 06:48:55.691474 34819 solver.cpp:239] Iteration 64870 (2.02898 iter/s, 4.92859s/10 iters), loss = 8.8185
I0523 06:48:55.691530 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8185 (* 1 = 8.8185 loss)
I0523 06:48:55.909622 34819 sgd_solver.cpp:112] Iteration 64870, lr = 0.01
I0523 06:49:00.006397 34819 solver.cpp:239] Iteration 64880 (2.31767 iter/s, 4.31468s/10 iters), loss = 8.09494
I0523 06:49:00.006451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09494 (* 1 = 8.09494 loss)
I0523 06:49:00.075780 34819 sgd_solver.cpp:112] Iteration 64880, lr = 0.01
I0523 06:49:03.335189 34819 solver.cpp:239] Iteration 64890 (3.00428 iter/s, 3.32858s/10 iters), loss = 9.22374
I0523 06:49:03.335252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22374 (* 1 = 9.22374 loss)
I0523 06:49:03.399435 34819 sgd_solver.cpp:112] Iteration 64890, lr = 0.01
I0523 06:49:08.746465 34819 solver.cpp:239] Iteration 64900 (1.84809 iter/s, 5.41098s/10 iters), loss = 8.35944
I0523 06:49:08.746517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35944 (* 1 = 8.35944 loss)
I0523 06:49:08.811000 34819 sgd_solver.cpp:112] Iteration 64900, lr = 0.01
I0523 06:49:11.740401 34819 solver.cpp:239] Iteration 64910 (3.34029 iter/s, 2.99375s/10 iters), loss = 6.93268
I0523 06:49:11.740454 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.93268 (* 1 = 6.93268 loss)
I0523 06:49:11.803126 34819 sgd_solver.cpp:112] Iteration 64910, lr = 0.01
I0523 06:49:16.179720 34819 solver.cpp:239] Iteration 64920 (2.25272 iter/s, 4.43907s/10 iters), loss = 8.38098
I0523 06:49:16.179945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38098 (* 1 = 8.38098 loss)
I0523 06:49:16.247457 34819 sgd_solver.cpp:112] Iteration 64920, lr = 0.01
I0523 06:49:18.803500 34819 solver.cpp:239] Iteration 64930 (3.81646 iter/s, 2.62023s/10 iters), loss = 7.9092
I0523 06:49:18.803544 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9092 (* 1 = 7.9092 loss)
I0523 06:49:18.871745 34819 sgd_solver.cpp:112] Iteration 64930, lr = 0.01
I0523 06:49:22.392565 34819 solver.cpp:239] Iteration 64940 (2.78831 iter/s, 3.5864s/10 iters), loss = 6.8374
I0523 06:49:22.392611 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.8374 (* 1 = 6.8374 loss)
I0523 06:49:23.174075 34819 sgd_solver.cpp:112] Iteration 64940, lr = 0.01
I0523 06:49:27.994511 34819 solver.cpp:239] Iteration 64950 (1.78519 iter/s, 5.60163s/10 iters), loss = 7.74973
I0523 06:49:27.994570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74973 (* 1 = 7.74973 loss)
I0523 06:49:28.777865 34819 sgd_solver.cpp:112] Iteration 64950, lr = 0.01
I0523 06:49:31.904043 34819 solver.cpp:239] Iteration 64960 (2.55799 iter/s, 3.90931s/10 iters), loss = 8.82245
I0523 06:49:31.904086 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82245 (* 1 = 8.82245 loss)
I0523 06:49:31.970757 34819 sgd_solver.cpp:112] Iteration 64960, lr = 0.01
I0523 06:49:35.813041 34819 solver.cpp:239] Iteration 64970 (2.55834 iter/s, 3.90879s/10 iters), loss = 8.04176
I0523 06:49:35.813100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04176 (* 1 = 8.04176 loss)
I0523 06:49:36.602031 34819 sgd_solver.cpp:112] Iteration 64970, lr = 0.01
I0523 06:49:42.894392 34819 solver.cpp:239] Iteration 64980 (1.41224 iter/s, 7.08096s/10 iters), loss = 8.37808
I0523 06:49:42.894453 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37808 (* 1 = 8.37808 loss)
I0523 06:49:43.780715 34819 sgd_solver.cpp:112] Iteration 64980, lr = 0.01
I0523 06:49:49.149961 34819 solver.cpp:239] Iteration 64990 (1.59866 iter/s, 6.25525s/10 iters), loss = 8.31636
I0523 06:49:49.150100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31636 (* 1 = 8.31636 loss)
I0523 06:49:49.203913 34819 sgd_solver.cpp:112] Iteration 64990, lr = 0.01
I0523 06:49:54.799867 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_65000.caffemodel
I0523 06:50:03.604382 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_65000.solverstate
I0523 06:50:03.833989 34819 solver.cpp:239] Iteration 65000 (0.681045 iter/s, 14.6833s/10 iters), loss = 8.08386
I0523 06:50:03.834033 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08386 (* 1 = 8.08386 loss)
I0523 06:50:03.897538 34819 sgd_solver.cpp:112] Iteration 65000, lr = 0.01
I0523 06:50:08.948951 34819 solver.cpp:239] Iteration 65010 (1.95515 iter/s, 5.11469s/10 iters), loss = 7.8118
I0523 06:50:08.949002 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8118 (* 1 = 7.8118 loss)
I0523 06:50:09.014662 34819 sgd_solver.cpp:112] Iteration 65010, lr = 0.01
I0523 06:50:13.806677 34819 solver.cpp:239] Iteration 65020 (2.05869 iter/s, 4.85746s/10 iters), loss = 9.10888
I0523 06:50:13.806735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.10888 (* 1 = 9.10888 loss)
I0523 06:50:13.864765 34819 sgd_solver.cpp:112] Iteration 65020, lr = 0.01
I0523 06:50:19.276465 34819 solver.cpp:239] Iteration 65030 (1.82833 iter/s, 5.46947s/10 iters), loss = 7.9911
I0523 06:50:19.276612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9911 (* 1 = 7.9911 loss)
I0523 06:50:20.097419 34819 sgd_solver.cpp:112] Iteration 65030, lr = 0.01
I0523 06:50:24.144225 34819 solver.cpp:239] Iteration 65040 (2.05448 iter/s, 4.86741s/10 iters), loss = 7.446
I0523 06:50:24.144275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.446 (* 1 = 7.446 loss)
I0523 06:50:24.204573 34819 sgd_solver.cpp:112] Iteration 65040, lr = 0.01
I0523 06:50:28.582759 34819 solver.cpp:239] Iteration 65050 (2.25312 iter/s, 4.4383s/10 iters), loss = 8.3659
I0523 06:50:28.582800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3659 (* 1 = 8.3659 loss)
I0523 06:50:28.650403 34819 sgd_solver.cpp:112] Iteration 65050, lr = 0.01
I0523 06:50:35.729496 34819 solver.cpp:239] Iteration 65060 (1.3993 iter/s, 7.14641s/10 iters), loss = 7.13017
I0523 06:50:35.729537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13017 (* 1 = 7.13017 loss)
I0523 06:50:36.586148 34819 sgd_solver.cpp:112] Iteration 65060, lr = 0.01
I0523 06:50:40.561941 34819 solver.cpp:239] Iteration 65070 (2.06946 iter/s, 4.83218s/10 iters), loss = 7.49424
I0523 06:50:40.562010 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.49424 (* 1 = 7.49424 loss)
I0523 06:50:41.415060 34819 sgd_solver.cpp:112] Iteration 65070, lr = 0.01
I0523 06:50:44.013957 34819 solver.cpp:239] Iteration 65080 (2.89704 iter/s, 3.4518s/10 iters), loss = 8.17476
I0523 06:50:44.014008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17476 (* 1 = 8.17476 loss)
I0523 06:50:44.082803 34819 sgd_solver.cpp:112] Iteration 65080, lr = 0.01
I0523 06:50:48.202798 34819 solver.cpp:239] Iteration 65090 (2.38743 iter/s, 4.18861s/10 iters), loss = 8.56876
I0523 06:50:48.202854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56876 (* 1 = 8.56876 loss)
I0523 06:50:48.262464 34819 sgd_solver.cpp:112] Iteration 65090, lr = 0.01
I0523 06:50:52.828043 34819 solver.cpp:239] Iteration 65100 (2.16217 iter/s, 4.62499s/10 iters), loss = 8.08121
I0523 06:50:52.828260 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08121 (* 1 = 8.08121 loss)
I0523 06:50:52.902213 34819 sgd_solver.cpp:112] Iteration 65100, lr = 0.01
I0523 06:50:57.024435 34819 solver.cpp:239] Iteration 65110 (2.38322 iter/s, 4.19601s/10 iters), loss = 8.55239
I0523 06:50:57.024489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55239 (* 1 = 8.55239 loss)
I0523 06:50:57.685513 34819 sgd_solver.cpp:112] Iteration 65110, lr = 0.01
I0523 06:51:01.587131 34819 solver.cpp:239] Iteration 65120 (2.1918 iter/s, 4.56246s/10 iters), loss = 8.77512
I0523 06:51:01.587173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77512 (* 1 = 8.77512 loss)
I0523 06:51:01.656534 34819 sgd_solver.cpp:112] Iteration 65120, lr = 0.01
I0523 06:51:08.217706 34819 solver.cpp:239] Iteration 65130 (1.50824 iter/s, 6.63023s/10 iters), loss = 9.19446
I0523 06:51:08.217756 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19446 (* 1 = 9.19446 loss)
I0523 06:51:08.633273 34819 sgd_solver.cpp:112] Iteration 65130, lr = 0.01
I0523 06:51:12.593014 34819 solver.cpp:239] Iteration 65140 (2.28569 iter/s, 4.37505s/10 iters), loss = 8.17503
I0523 06:51:12.593067 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17503 (* 1 = 8.17503 loss)
I0523 06:51:13.420691 34819 sgd_solver.cpp:112] Iteration 65140, lr = 0.01
I0523 06:51:17.533038 34819 solver.cpp:239] Iteration 65150 (2.02439 iter/s, 4.93975s/10 iters), loss = 8.9049
I0523 06:51:17.533095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9049 (* 1 = 8.9049 loss)
I0523 06:51:17.601518 34819 sgd_solver.cpp:112] Iteration 65150, lr = 0.01
I0523 06:51:21.533617 34819 solver.cpp:239] Iteration 65160 (2.49978 iter/s, 4.00036s/10 iters), loss = 8.83639
I0523 06:51:21.533658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83639 (* 1 = 8.83639 loss)
I0523 06:51:21.595588 34819 sgd_solver.cpp:112] Iteration 65160, lr = 0.01
I0523 06:51:28.626160 34819 solver.cpp:239] Iteration 65170 (1.41 iter/s, 7.09219s/10 iters), loss = 7.93893
I0523 06:51:28.626426 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93893 (* 1 = 7.93893 loss)
I0523 06:51:28.692241 34819 sgd_solver.cpp:112] Iteration 65170, lr = 0.01
I0523 06:51:33.337970 34819 solver.cpp:239] Iteration 65180 (2.12253 iter/s, 4.71135s/10 iters), loss = 7.4912
I0523 06:51:33.338027 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4912 (* 1 = 7.4912 loss)
I0523 06:51:34.215543 34819 sgd_solver.cpp:112] Iteration 65180, lr = 0.01
I0523 06:51:38.588881 34819 solver.cpp:239] Iteration 65190 (1.90453 iter/s, 5.25063s/10 iters), loss = 6.72838
I0523 06:51:38.588927 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.72838 (* 1 = 6.72838 loss)
I0523 06:51:38.648699 34819 sgd_solver.cpp:112] Iteration 65190, lr = 0.01
I0523 06:51:43.004392 34819 solver.cpp:239] Iteration 65200 (2.26486 iter/s, 4.41528s/10 iters), loss = 7.80241
I0523 06:51:43.004432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80241 (* 1 = 7.80241 loss)
I0523 06:51:43.829538 34819 sgd_solver.cpp:112] Iteration 65200, lr = 0.01
I0523 06:51:49.359876 34819 solver.cpp:239] Iteration 65210 (1.57352 iter/s, 6.35517s/10 iters), loss = 8.07626
I0523 06:51:49.359916 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07626 (* 1 = 8.07626 loss)
I0523 06:51:49.422565 34819 sgd_solver.cpp:112] Iteration 65210, lr = 0.01
I0523 06:51:53.930217 34819 solver.cpp:239] Iteration 65220 (2.18814 iter/s, 4.57009s/10 iters), loss = 7.47193
I0523 06:51:53.930263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47193 (* 1 = 7.47193 loss)
I0523 06:51:54.694070 34819 sgd_solver.cpp:112] Iteration 65220, lr = 0.01
I0523 06:51:59.591104 34819 solver.cpp:239] Iteration 65230 (1.76659 iter/s, 5.66061s/10 iters), loss = 9.07567
I0523 06:51:59.591320 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07567 (* 1 = 9.07567 loss)
I0523 06:51:59.662298 34819 sgd_solver.cpp:112] Iteration 65230, lr = 0.01
I0523 06:52:04.400084 34819 solver.cpp:239] Iteration 65240 (2.07961 iter/s, 4.80859s/10 iters), loss = 7.976
I0523 06:52:04.400137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.976 (* 1 = 7.976 loss)
I0523 06:52:04.484607 34819 sgd_solver.cpp:112] Iteration 65240, lr = 0.01
I0523 06:52:09.275943 34819 solver.cpp:239] Iteration 65250 (2.05103 iter/s, 4.87561s/10 iters), loss = 8.5485
I0523 06:52:09.275985 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5485 (* 1 = 8.5485 loss)
I0523 06:52:09.351951 34819 sgd_solver.cpp:112] Iteration 65250, lr = 0.01
I0523 06:52:13.682927 34819 solver.cpp:239] Iteration 65260 (2.26924 iter/s, 4.40675s/10 iters), loss = 7.10815
I0523 06:52:13.682973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.10815 (* 1 = 7.10815 loss)
I0523 06:52:13.741735 34819 sgd_solver.cpp:112] Iteration 65260, lr = 0.01
I0523 06:52:18.773528 34819 solver.cpp:239] Iteration 65270 (1.96451 iter/s, 5.09033s/10 iters), loss = 8.03969
I0523 06:52:18.773584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03969 (* 1 = 8.03969 loss)
I0523 06:52:18.848067 34819 sgd_solver.cpp:112] Iteration 65270, lr = 0.01
I0523 06:52:22.959270 34819 solver.cpp:239] Iteration 65280 (2.3892 iter/s, 4.18551s/10 iters), loss = 8.39247
I0523 06:52:22.959318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39247 (* 1 = 8.39247 loss)
I0523 06:52:23.800063 34819 sgd_solver.cpp:112] Iteration 65280, lr = 0.01
I0523 06:52:28.804656 34819 solver.cpp:239] Iteration 65290 (1.71084 iter/s, 5.8451s/10 iters), loss = 8.51522
I0523 06:52:28.804695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51522 (* 1 = 8.51522 loss)
I0523 06:52:29.621737 34819 sgd_solver.cpp:112] Iteration 65290, lr = 0.01
I0523 06:52:33.557533 34819 solver.cpp:239] Iteration 65300 (2.10409 iter/s, 4.75264s/10 iters), loss = 7.75056
I0523 06:52:33.557584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75056 (* 1 = 7.75056 loss)
I0523 06:52:33.622256 34819 sgd_solver.cpp:112] Iteration 65300, lr = 0.01
I0523 06:52:37.345489 34819 solver.cpp:239] Iteration 65310 (2.64009 iter/s, 3.78774s/10 iters), loss = 9.19594
I0523 06:52:37.345541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19594 (* 1 = 9.19594 loss)
I0523 06:52:37.420423 34819 sgd_solver.cpp:112] Iteration 65310, lr = 0.01
I0523 06:52:41.284461 34819 solver.cpp:239] Iteration 65320 (2.53888 iter/s, 3.93875s/10 iters), loss = 8.28051
I0523 06:52:41.284517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28051 (* 1 = 8.28051 loss)
I0523 06:52:41.353776 34819 sgd_solver.cpp:112] Iteration 65320, lr = 0.01
I0523 06:52:43.905552 34819 solver.cpp:239] Iteration 65330 (3.81546 iter/s, 2.62092s/10 iters), loss = 8.61529
I0523 06:52:43.905601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61529 (* 1 = 8.61529 loss)
I0523 06:52:43.980718 34819 sgd_solver.cpp:112] Iteration 65330, lr = 0.01
I0523 06:52:48.534925 34819 solver.cpp:239] Iteration 65340 (2.16024 iter/s, 4.62912s/10 iters), loss = 7.80626
I0523 06:52:48.534967 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80626 (* 1 = 7.80626 loss)
I0523 06:52:49.331127 34819 sgd_solver.cpp:112] Iteration 65340, lr = 0.01
I0523 06:52:53.256408 34819 solver.cpp:239] Iteration 65350 (2.11809 iter/s, 4.72124s/10 iters), loss = 8.85654
I0523 06:52:53.256459 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85654 (* 1 = 8.85654 loss)
I0523 06:52:53.337445 34819 sgd_solver.cpp:112] Iteration 65350, lr = 0.01
I0523 06:52:58.250758 34819 solver.cpp:239] Iteration 65360 (2.00237 iter/s, 4.99407s/10 iters), loss = 7.56554
I0523 06:52:58.250811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56554 (* 1 = 7.56554 loss)
I0523 06:52:58.957046 34819 sgd_solver.cpp:112] Iteration 65360, lr = 0.01
I0523 06:53:04.223898 34819 solver.cpp:239] Iteration 65370 (1.67425 iter/s, 5.97283s/10 iters), loss = 8.46117
I0523 06:53:04.224045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46117 (* 1 = 8.46117 loss)
I0523 06:53:04.310559 34819 sgd_solver.cpp:112] Iteration 65370, lr = 0.01
I0523 06:53:09.147495 34819 solver.cpp:239] Iteration 65380 (2.03118 iter/s, 4.92325s/10 iters), loss = 8.33352
I0523 06:53:09.147536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33352 (* 1 = 8.33352 loss)
I0523 06:53:09.209817 34819 sgd_solver.cpp:112] Iteration 65380, lr = 0.01
I0523 06:53:14.651294 34819 solver.cpp:239] Iteration 65390 (1.81702 iter/s, 5.50352s/10 iters), loss = 8.62539
I0523 06:53:14.651336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62539 (* 1 = 8.62539 loss)
I0523 06:53:15.297763 34819 sgd_solver.cpp:112] Iteration 65390, lr = 0.01
I0523 06:53:21.575743 34819 solver.cpp:239] Iteration 65400 (1.44423 iter/s, 6.92412s/10 iters), loss = 7.91046
I0523 06:53:21.575783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91046 (* 1 = 7.91046 loss)
I0523 06:53:21.646093 34819 sgd_solver.cpp:112] Iteration 65400, lr = 0.01
I0523 06:53:26.418254 34819 solver.cpp:239] Iteration 65410 (2.06699 iter/s, 4.83794s/10 iters), loss = 8.71989
I0523 06:53:26.418295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71989 (* 1 = 8.71989 loss)
I0523 06:53:26.473481 34819 sgd_solver.cpp:112] Iteration 65410, lr = 0.01
I0523 06:53:29.903671 34819 solver.cpp:239] Iteration 65420 (2.86926 iter/s, 3.48521s/10 iters), loss = 7.30752
I0523 06:53:29.903717 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.30752 (* 1 = 7.30752 loss)
I0523 06:53:30.751616 34819 sgd_solver.cpp:112] Iteration 65420, lr = 0.01
I0523 06:53:35.407608 34819 solver.cpp:239] Iteration 65430 (1.81698 iter/s, 5.50365s/10 iters), loss = 8.34869
I0523 06:53:35.407773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34869 (* 1 = 8.34869 loss)
I0523 06:53:35.749037 34819 sgd_solver.cpp:112] Iteration 65430, lr = 0.01
I0523 06:53:40.285049 34819 solver.cpp:239] Iteration 65440 (2.05041 iter/s, 4.87708s/10 iters), loss = 8.67208
I0523 06:53:40.285102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67208 (* 1 = 8.67208 loss)
I0523 06:53:40.355350 34819 sgd_solver.cpp:112] Iteration 65440, lr = 0.01
I0523 06:53:46.455471 34819 solver.cpp:239] Iteration 65450 (1.62072 iter/s, 6.1701s/10 iters), loss = 8.3593
I0523 06:53:46.455524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3593 (* 1 = 8.3593 loss)
I0523 06:53:46.523113 34819 sgd_solver.cpp:112] Iteration 65450, lr = 0.01
I0523 06:53:51.507972 34819 solver.cpp:239] Iteration 65460 (1.97933 iter/s, 5.05222s/10 iters), loss = 8.904
I0523 06:53:51.508028 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.904 (* 1 = 8.904 loss)
I0523 06:53:52.355690 34819 sgd_solver.cpp:112] Iteration 65460, lr = 0.01
I0523 06:53:56.517547 34819 solver.cpp:239] Iteration 65470 (1.99629 iter/s, 5.0093s/10 iters), loss = 7.579
I0523 06:53:56.517594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.579 (* 1 = 7.579 loss)
I0523 06:53:56.577958 34819 sgd_solver.cpp:112] Iteration 65470, lr = 0.01
I0523 06:54:01.549324 34819 solver.cpp:239] Iteration 65480 (1.98747 iter/s, 5.03152s/10 iters), loss = 8.78107
I0523 06:54:01.549381 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78107 (* 1 = 8.78107 loss)
I0523 06:54:01.607656 34819 sgd_solver.cpp:112] Iteration 65480, lr = 0.01
I0523 06:54:07.872079 34819 solver.cpp:239] Iteration 65490 (1.58167 iter/s, 6.32244s/10 iters), loss = 8.06669
I0523 06:54:07.872299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06669 (* 1 = 8.06669 loss)
I0523 06:54:07.933290 34819 sgd_solver.cpp:112] Iteration 65490, lr = 0.01
I0523 06:54:12.298095 34819 solver.cpp:239] Iteration 65500 (2.25956 iter/s, 4.42565s/10 iters), loss = 8.47284
I0523 06:54:12.298143 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47284 (* 1 = 8.47284 loss)
I0523 06:54:12.371913 34819 sgd_solver.cpp:112] Iteration 65500, lr = 0.01
I0523 06:54:16.620270 34819 solver.cpp:239] Iteration 65510 (2.31377 iter/s, 4.32194s/10 iters), loss = 8.55439
I0523 06:54:16.620309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55439 (* 1 = 8.55439 loss)
I0523 06:54:16.694833 34819 sgd_solver.cpp:112] Iteration 65510, lr = 0.01
I0523 06:54:20.021927 34819 solver.cpp:239] Iteration 65520 (2.93991 iter/s, 3.40146s/10 iters), loss = 8.26347
I0523 06:54:20.021981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26347 (* 1 = 8.26347 loss)
I0523 06:54:20.845737 34819 sgd_solver.cpp:112] Iteration 65520, lr = 0.01
I0523 06:54:27.263509 34819 solver.cpp:239] Iteration 65530 (1.38098 iter/s, 7.24123s/10 iters), loss = 7.67471
I0523 06:54:27.263551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67471 (* 1 = 7.67471 loss)
I0523 06:54:27.322474 34819 sgd_solver.cpp:112] Iteration 65530, lr = 0.01
I0523 06:54:31.119845 34819 solver.cpp:239] Iteration 65540 (2.59328 iter/s, 3.85613s/10 iters), loss = 8.45142
I0523 06:54:31.119886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45142 (* 1 = 8.45142 loss)
I0523 06:54:31.188928 34819 sgd_solver.cpp:112] Iteration 65540, lr = 0.01
I0523 06:54:35.413477 34819 solver.cpp:239] Iteration 65550 (2.32915 iter/s, 4.2934s/10 iters), loss = 7.3179
I0523 06:54:35.413517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3179 (* 1 = 7.3179 loss)
I0523 06:54:35.471803 34819 sgd_solver.cpp:112] Iteration 65550, lr = 0.01
I0523 06:54:41.016543 34819 solver.cpp:239] Iteration 65560 (1.78483 iter/s, 5.60279s/10 iters), loss = 7.61591
I0523 06:54:41.016793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61591 (* 1 = 7.61591 loss)
I0523 06:54:41.095408 34819 sgd_solver.cpp:112] Iteration 65560, lr = 0.01
I0523 06:54:45.663978 34819 solver.cpp:239] Iteration 65570 (2.15193 iter/s, 4.647s/10 iters), loss = 7.54611
I0523 06:54:45.664026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54611 (* 1 = 7.54611 loss)
I0523 06:54:45.721530 34819 sgd_solver.cpp:112] Iteration 65570, lr = 0.01
I0523 06:54:50.470948 34819 solver.cpp:239] Iteration 65580 (2.08042 iter/s, 4.80672s/10 iters), loss = 8.06303
I0523 06:54:50.470990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06303 (* 1 = 8.06303 loss)
I0523 06:54:50.537967 34819 sgd_solver.cpp:112] Iteration 65580, lr = 0.01
I0523 06:54:54.833940 34819 solver.cpp:239] Iteration 65590 (2.29213 iter/s, 4.36276s/10 iters), loss = 8.25586
I0523 06:54:54.833992 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25586 (* 1 = 8.25586 loss)
I0523 06:54:55.630962 34819 sgd_solver.cpp:112] Iteration 65590, lr = 0.01
I0523 06:54:58.073045 34819 solver.cpp:239] Iteration 65600 (3.08746 iter/s, 3.23891s/10 iters), loss = 7.9116
I0523 06:54:58.073096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9116 (* 1 = 7.9116 loss)
I0523 06:54:58.155956 34819 sgd_solver.cpp:112] Iteration 65600, lr = 0.01
I0523 06:55:01.386173 34819 solver.cpp:239] Iteration 65610 (3.01847 iter/s, 3.31293s/10 iters), loss = 7.85153
I0523 06:55:01.386216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85153 (* 1 = 7.85153 loss)
I0523 06:55:02.229769 34819 sgd_solver.cpp:112] Iteration 65610, lr = 0.01
I0523 06:55:05.422288 34819 solver.cpp:239] Iteration 65620 (2.47776 iter/s, 4.0359s/10 iters), loss = 8.22289
I0523 06:55:05.422333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22289 (* 1 = 8.22289 loss)
I0523 06:55:05.495170 34819 sgd_solver.cpp:112] Iteration 65620, lr = 0.01
I0523 06:55:11.000237 34819 solver.cpp:239] Iteration 65630 (1.79286 iter/s, 5.57768s/10 iters), loss = 8.67396
I0523 06:55:11.000278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67396 (* 1 = 8.67396 loss)
I0523 06:55:11.758299 34819 sgd_solver.cpp:112] Iteration 65630, lr = 0.01
I0523 06:55:16.341403 34819 solver.cpp:239] Iteration 65640 (1.87235 iter/s, 5.34089s/10 iters), loss = 7.38756
I0523 06:55:16.341462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38756 (* 1 = 7.38756 loss)
I0523 06:55:17.152842 34819 sgd_solver.cpp:112] Iteration 65640, lr = 0.01
I0523 06:55:20.607699 34819 solver.cpp:239] Iteration 65650 (2.3441 iter/s, 4.26602s/10 iters), loss = 8.02912
I0523 06:55:20.607749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02912 (* 1 = 8.02912 loss)
I0523 06:55:21.464762 34819 sgd_solver.cpp:112] Iteration 65650, lr = 0.01
I0523 06:55:25.339004 34819 solver.cpp:239] Iteration 65660 (2.11369 iter/s, 4.73106s/10 iters), loss = 7.9049
I0523 06:55:25.339048 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9049 (* 1 = 7.9049 loss)
I0523 06:55:26.130007 34819 sgd_solver.cpp:112] Iteration 65660, lr = 0.01
I0523 06:55:28.786092 34819 solver.cpp:239] Iteration 65670 (2.90116 iter/s, 3.44689s/10 iters), loss = 8.4251
I0523 06:55:28.786136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4251 (* 1 = 8.4251 loss)
I0523 06:55:28.893926 34819 sgd_solver.cpp:112] Iteration 65670, lr = 0.01
I0523 06:55:32.986233 34819 solver.cpp:239] Iteration 65680 (2.38101 iter/s, 4.1999s/10 iters), loss = 7.74473
I0523 06:55:32.986289 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74473 (* 1 = 7.74473 loss)
I0523 06:55:33.050179 34819 sgd_solver.cpp:112] Iteration 65680, lr = 0.01
I0523 06:55:38.038797 34819 solver.cpp:239] Iteration 65690 (1.9793 iter/s, 5.05229s/10 iters), loss = 8.93036
I0523 06:55:38.038841 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93036 (* 1 = 8.93036 loss)
I0523 06:55:38.114506 34819 sgd_solver.cpp:112] Iteration 65690, lr = 0.01
I0523 06:55:41.866477 34819 solver.cpp:239] Iteration 65700 (2.61269 iter/s, 3.82747s/10 iters), loss = 7.93582
I0523 06:55:41.866652 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93582 (* 1 = 7.93582 loss)
I0523 06:55:41.934115 34819 sgd_solver.cpp:112] Iteration 65700, lr = 0.01
I0523 06:55:46.477448 34819 solver.cpp:239] Iteration 65710 (2.16892 iter/s, 4.6106s/10 iters), loss = 8.69938
I0523 06:55:46.477491 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69938 (* 1 = 8.69938 loss)
I0523 06:55:46.549196 34819 sgd_solver.cpp:112] Iteration 65710, lr = 0.01
I0523 06:55:50.491875 34819 solver.cpp:239] Iteration 65720 (2.49115 iter/s, 4.01421s/10 iters), loss = 7.78829
I0523 06:55:50.491914 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78829 (* 1 = 7.78829 loss)
I0523 06:55:50.534330 34819 sgd_solver.cpp:112] Iteration 65720, lr = 0.01
I0523 06:55:54.000519 34819 solver.cpp:239] Iteration 65730 (2.85027 iter/s, 3.50844s/10 iters), loss = 8.69362
I0523 06:55:54.000577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69362 (* 1 = 8.69362 loss)
I0523 06:55:54.801980 34819 sgd_solver.cpp:112] Iteration 65730, lr = 0.01
I0523 06:55:59.798390 34819 solver.cpp:239] Iteration 65740 (1.72486 iter/s, 5.79757s/10 iters), loss = 7.69011
I0523 06:55:59.798442 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69011 (* 1 = 7.69011 loss)
I0523 06:56:00.050326 34819 sgd_solver.cpp:112] Iteration 65740, lr = 0.01
I0523 06:56:04.027102 34819 solver.cpp:239] Iteration 65750 (2.36492 iter/s, 4.22848s/10 iters), loss = 8.37258
I0523 06:56:04.027149 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37258 (* 1 = 8.37258 loss)
I0523 06:56:04.085294 34819 sgd_solver.cpp:112] Iteration 65750, lr = 0.01
I0523 06:56:09.043045 34819 solver.cpp:239] Iteration 65760 (1.99375 iter/s, 5.01567s/10 iters), loss = 8.3348
I0523 06:56:09.043095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3348 (* 1 = 8.3348 loss)
I0523 06:56:09.901491 34819 sgd_solver.cpp:112] Iteration 65760, lr = 0.01
I0523 06:56:17.054739 34819 solver.cpp:239] Iteration 65770 (1.24824 iter/s, 8.0113s/10 iters), loss = 7.6328
I0523 06:56:17.054872 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6328 (* 1 = 7.6328 loss)
I0523 06:56:17.918519 34819 sgd_solver.cpp:112] Iteration 65770, lr = 0.01
I0523 06:56:22.005802 34819 solver.cpp:239] Iteration 65780 (2.01991 iter/s, 4.95071s/10 iters), loss = 8.32392
I0523 06:56:22.005858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32392 (* 1 = 8.32392 loss)
I0523 06:56:22.070042 34819 sgd_solver.cpp:112] Iteration 65780, lr = 0.01
I0523 06:56:27.564754 34819 solver.cpp:239] Iteration 65790 (1.79899 iter/s, 5.55867s/10 iters), loss = 8.49313
I0523 06:56:27.564797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49313 (* 1 = 8.49313 loss)
I0523 06:56:28.019835 34819 sgd_solver.cpp:112] Iteration 65790, lr = 0.01
I0523 06:56:30.573570 34819 solver.cpp:239] Iteration 65800 (3.32378 iter/s, 3.00862s/10 iters), loss = 7.40629
I0523 06:56:30.573624 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40629 (* 1 = 7.40629 loss)
I0523 06:56:31.333961 34819 sgd_solver.cpp:112] Iteration 65800, lr = 0.01
I0523 06:56:36.123433 34819 solver.cpp:239] Iteration 65810 (1.80194 iter/s, 5.54957s/10 iters), loss = 8.49016
I0523 06:56:36.123476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49016 (* 1 = 8.49016 loss)
I0523 06:56:36.181347 34819 sgd_solver.cpp:112] Iteration 65810, lr = 0.01
I0523 06:56:38.854981 34819 solver.cpp:239] Iteration 65820 (3.66115 iter/s, 2.73138s/10 iters), loss = 8.15694
I0523 06:56:38.855022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15694 (* 1 = 8.15694 loss)
I0523 06:56:39.734380 34819 sgd_solver.cpp:112] Iteration 65820, lr = 0.01
I0523 06:56:45.200032 34819 solver.cpp:239] Iteration 65830 (1.57611 iter/s, 6.34475s/10 iters), loss = 8.15419
I0523 06:56:45.200074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15419 (* 1 = 8.15419 loss)
I0523 06:56:46.066630 34819 sgd_solver.cpp:112] Iteration 65830, lr = 0.01
I0523 06:56:51.029371 34819 solver.cpp:239] Iteration 65840 (1.71554 iter/s, 5.82906s/10 iters), loss = 7.85402
I0523 06:56:51.029613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85402 (* 1 = 7.85402 loss)
I0523 06:56:51.084827 34819 sgd_solver.cpp:112] Iteration 65840, lr = 0.01
I0523 06:56:55.015097 34819 solver.cpp:239] Iteration 65850 (2.5092 iter/s, 3.98534s/10 iters), loss = 7.85152
I0523 06:56:55.015141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85152 (* 1 = 7.85152 loss)
I0523 06:56:55.074862 34819 sgd_solver.cpp:112] Iteration 65850, lr = 0.01
I0523 06:56:59.720831 34819 solver.cpp:239] Iteration 65860 (2.12518 iter/s, 4.70548s/10 iters), loss = 7.95986
I0523 06:56:59.720885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95986 (* 1 = 7.95986 loss)
I0523 06:56:59.797078 34819 sgd_solver.cpp:112] Iteration 65860, lr = 0.01
I0523 06:57:03.919433 34819 solver.cpp:239] Iteration 65870 (2.38187 iter/s, 4.19838s/10 iters), loss = 7.44379
I0523 06:57:03.919474 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44379 (* 1 = 7.44379 loss)
I0523 06:57:04.510082 34819 sgd_solver.cpp:112] Iteration 65870, lr = 0.01
I0523 06:57:09.087311 34819 solver.cpp:239] Iteration 65880 (1.93513 iter/s, 5.1676s/10 iters), loss = 8.55237
I0523 06:57:09.087365 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55237 (* 1 = 8.55237 loss)
I0523 06:57:09.248713 34819 sgd_solver.cpp:112] Iteration 65880, lr = 0.01
I0523 06:57:12.858525 34819 solver.cpp:239] Iteration 65890 (2.65181 iter/s, 3.771s/10 iters), loss = 8.54092
I0523 06:57:12.858566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54092 (* 1 = 8.54092 loss)
I0523 06:57:12.932236 34819 sgd_solver.cpp:112] Iteration 65890, lr = 0.01
I0523 06:57:18.839792 34819 solver.cpp:239] Iteration 65900 (1.67265 iter/s, 5.97853s/10 iters), loss = 8.68662
I0523 06:57:18.839851 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68662 (* 1 = 8.68662 loss)
I0523 06:57:19.705483 34819 sgd_solver.cpp:112] Iteration 65900, lr = 0.01
I0523 06:57:25.445158 34819 solver.cpp:239] Iteration 65910 (1.514 iter/s, 6.60504s/10 iters), loss = 8.32638
I0523 06:57:25.445354 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32638 (* 1 = 8.32638 loss)
I0523 06:57:25.523175 34819 sgd_solver.cpp:112] Iteration 65910, lr = 0.01
I0523 06:57:29.543187 34819 solver.cpp:239] Iteration 65920 (2.44042 iter/s, 4.09765s/10 iters), loss = 7.18985
I0523 06:57:29.543236 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.18985 (* 1 = 7.18985 loss)
I0523 06:57:30.234923 34819 sgd_solver.cpp:112] Iteration 65920, lr = 0.01
I0523 06:57:34.975823 34819 solver.cpp:239] Iteration 65930 (1.84083 iter/s, 5.43233s/10 iters), loss = 8.65981
I0523 06:57:34.975872 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65981 (* 1 = 8.65981 loss)
I0523 06:57:35.657534 34819 sgd_solver.cpp:112] Iteration 65930, lr = 0.01
I0523 06:57:39.546525 34819 solver.cpp:239] Iteration 65940 (2.18796 iter/s, 4.57046s/10 iters), loss = 8.1125
I0523 06:57:39.546567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1125 (* 1 = 8.1125 loss)
I0523 06:57:39.609653 34819 sgd_solver.cpp:112] Iteration 65940, lr = 0.01
I0523 06:57:44.969838 34819 solver.cpp:239] Iteration 65950 (1.84399 iter/s, 5.42304s/10 iters), loss = 7.98593
I0523 06:57:44.969883 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98593 (* 1 = 7.98593 loss)
I0523 06:57:45.030359 34819 sgd_solver.cpp:112] Iteration 65950, lr = 0.01
I0523 06:57:50.073915 34819 solver.cpp:239] Iteration 65960 (1.95932 iter/s, 5.10381s/10 iters), loss = 8.47042
I0523 06:57:50.073968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47042 (* 1 = 8.47042 loss)
I0523 06:57:50.144469 34819 sgd_solver.cpp:112] Iteration 65960, lr = 0.01
I0523 06:57:54.618223 34819 solver.cpp:239] Iteration 65970 (2.20068 iter/s, 4.54405s/10 iters), loss = 8.94341
I0523 06:57:54.618276 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94341 (* 1 = 8.94341 loss)
I0523 06:57:54.690387 34819 sgd_solver.cpp:112] Iteration 65970, lr = 0.01
I0523 06:57:58.234233 34819 solver.cpp:239] Iteration 65980 (2.76565 iter/s, 3.61579s/10 iters), loss = 7.73351
I0523 06:57:58.234475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73351 (* 1 = 7.73351 loss)
I0523 06:57:58.306279 34819 sgd_solver.cpp:112] Iteration 65980, lr = 0.01
I0523 06:58:03.844290 34819 solver.cpp:239] Iteration 65990 (1.78344 iter/s, 5.60713s/10 iters), loss = 8.08287
I0523 06:58:03.844334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08287 (* 1 = 8.08287 loss)
I0523 06:58:03.915418 34819 sgd_solver.cpp:112] Iteration 65990, lr = 0.01
I0523 06:58:08.883776 34819 solver.cpp:239] Iteration 66000 (1.98443 iter/s, 5.03923s/10 iters), loss = 7.64695
I0523 06:58:08.883816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64695 (* 1 = 7.64695 loss)
I0523 06:58:08.960629 34819 sgd_solver.cpp:112] Iteration 66000, lr = 0.01
I0523 06:58:13.702826 34819 solver.cpp:239] Iteration 66010 (2.07521 iter/s, 4.8188s/10 iters), loss = 8.65005
I0523 06:58:13.702893 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65005 (* 1 = 8.65005 loss)
I0523 06:58:13.765633 34819 sgd_solver.cpp:112] Iteration 66010, lr = 0.01
I0523 06:58:17.395611 34819 solver.cpp:239] Iteration 66020 (2.70815 iter/s, 3.69256s/10 iters), loss = 7.85249
I0523 06:58:17.395661 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85249 (* 1 = 7.85249 loss)
I0523 06:58:18.258708 34819 sgd_solver.cpp:112] Iteration 66020, lr = 0.01
I0523 06:58:23.821032 34819 solver.cpp:239] Iteration 66030 (1.5564 iter/s, 6.4251s/10 iters), loss = 7.86163
I0523 06:58:23.821089 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86163 (* 1 = 7.86163 loss)
I0523 06:58:24.642475 34819 sgd_solver.cpp:112] Iteration 66030, lr = 0.01
I0523 06:58:27.985553 34819 solver.cpp:239] Iteration 66040 (2.40137 iter/s, 4.16428s/10 iters), loss = 7.16594
I0523 06:58:27.985594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.16594 (* 1 = 7.16594 loss)
I0523 06:58:28.063140 34819 sgd_solver.cpp:112] Iteration 66040, lr = 0.01
I0523 06:58:33.084179 34819 solver.cpp:239] Iteration 66050 (1.96141 iter/s, 5.09837s/10 iters), loss = 7.92856
I0523 06:58:33.084305 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92856 (* 1 = 7.92856 loss)
I0523 06:58:33.173885 34819 sgd_solver.cpp:112] Iteration 66050, lr = 0.01
I0523 06:58:37.930757 34819 solver.cpp:239] Iteration 66060 (2.06345 iter/s, 4.84625s/10 iters), loss = 7.82703
I0523 06:58:37.930815 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82703 (* 1 = 7.82703 loss)
I0523 06:58:37.996645 34819 sgd_solver.cpp:112] Iteration 66060, lr = 0.01
I0523 06:58:42.398600 34819 solver.cpp:239] Iteration 66070 (2.23835 iter/s, 4.46759s/10 iters), loss = 7.8091
I0523 06:58:42.398643 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8091 (* 1 = 7.8091 loss)
I0523 06:58:43.174825 34819 sgd_solver.cpp:112] Iteration 66070, lr = 0.01
I0523 06:58:47.707720 34819 solver.cpp:239] Iteration 66080 (1.88365 iter/s, 5.30883s/10 iters), loss = 8.25501
I0523 06:58:47.707777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25501 (* 1 = 8.25501 loss)
I0523 06:58:48.541281 34819 sgd_solver.cpp:112] Iteration 66080, lr = 0.01
I0523 06:58:52.572566 34819 solver.cpp:239] Iteration 66090 (2.05568 iter/s, 4.86458s/10 iters), loss = 7.6556
I0523 06:58:52.572607 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6556 (* 1 = 7.6556 loss)
I0523 06:58:53.388715 34819 sgd_solver.cpp:112] Iteration 66090, lr = 0.01
I0523 06:58:57.269953 34819 solver.cpp:239] Iteration 66100 (2.12895 iter/s, 4.69714s/10 iters), loss = 7.89165
I0523 06:58:57.269990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89165 (* 1 = 7.89165 loss)
I0523 06:58:57.350641 34819 sgd_solver.cpp:112] Iteration 66100, lr = 0.01
I0523 06:59:02.124212 34819 solver.cpp:239] Iteration 66110 (2.06015 iter/s, 4.85402s/10 iters), loss = 7.80825
I0523 06:59:02.124264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80825 (* 1 = 7.80825 loss)
I0523 06:59:02.197427 34819 sgd_solver.cpp:112] Iteration 66110, lr = 0.01
I0523 06:59:05.843312 34819 solver.cpp:239] Iteration 66120 (2.68898 iter/s, 3.71889s/10 iters), loss = 8.09811
I0523 06:59:05.843492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09811 (* 1 = 8.09811 loss)
I0523 06:59:05.904916 34819 sgd_solver.cpp:112] Iteration 66120, lr = 0.01
I0523 06:59:11.453810 34819 solver.cpp:239] Iteration 66130 (1.78251 iter/s, 5.61006s/10 iters), loss = 8.58386
I0523 06:59:11.453874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58386 (* 1 = 8.58386 loss)
I0523 06:59:12.300326 34819 sgd_solver.cpp:112] Iteration 66130, lr = 0.01
I0523 06:59:16.455054 34819 solver.cpp:239] Iteration 66140 (1.99961 iter/s, 5.00096s/10 iters), loss = 8.72165
I0523 06:59:16.455096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.72165 (* 1 = 8.72165 loss)
I0523 06:59:17.093521 34819 sgd_solver.cpp:112] Iteration 66140, lr = 0.01
I0523 06:59:21.910311 34819 solver.cpp:239] Iteration 66150 (1.83318 iter/s, 5.45499s/10 iters), loss = 8.88358
I0523 06:59:21.910365 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88358 (* 1 = 8.88358 loss)
I0523 06:59:21.985440 34819 sgd_solver.cpp:112] Iteration 66150, lr = 0.01
I0523 06:59:27.309990 34819 solver.cpp:239] Iteration 66160 (1.85206 iter/s, 5.39941s/10 iters), loss = 9.1301
I0523 06:59:27.310031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.1301 (* 1 = 9.1301 loss)
I0523 06:59:28.010030 34819 sgd_solver.cpp:112] Iteration 66160, lr = 0.01
I0523 06:59:31.421934 34819 solver.cpp:239] Iteration 66170 (2.43207 iter/s, 4.11173s/10 iters), loss = 7.83969
I0523 06:59:31.421974 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83969 (* 1 = 7.83969 loss)
I0523 06:59:32.279606 34819 sgd_solver.cpp:112] Iteration 66170, lr = 0.01
I0523 06:59:35.986122 34819 solver.cpp:239] Iteration 66180 (2.19108 iter/s, 4.56395s/10 iters), loss = 8.7336
I0523 06:59:35.986258 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7336 (* 1 = 8.7336 loss)
I0523 06:59:36.059010 34819 sgd_solver.cpp:112] Iteration 66180, lr = 0.01
I0523 06:59:40.139130 34819 solver.cpp:239] Iteration 66190 (2.40807 iter/s, 4.1527s/10 iters), loss = 9.42763
I0523 06:59:40.139183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.42763 (* 1 = 9.42763 loss)
I0523 06:59:40.195179 34819 sgd_solver.cpp:112] Iteration 66190, lr = 0.01
I0523 06:59:43.581512 34819 solver.cpp:239] Iteration 66200 (2.90514 iter/s, 3.44217s/10 iters), loss = 8.82389
I0523 06:59:43.581565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82389 (* 1 = 8.82389 loss)
I0523 06:59:43.661937 34819 sgd_solver.cpp:112] Iteration 66200, lr = 0.01
I0523 06:59:46.790271 34819 solver.cpp:239] Iteration 66210 (3.11667 iter/s, 3.20855s/10 iters), loss = 9.58009
I0523 06:59:46.790334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.58009 (* 1 = 9.58009 loss)
I0523 06:59:47.658499 34819 sgd_solver.cpp:112] Iteration 66210, lr = 0.01
I0523 06:59:52.157074 34819 solver.cpp:239] Iteration 66220 (1.86341 iter/s, 5.36651s/10 iters), loss = 8.20906
I0523 06:59:52.157136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20906 (* 1 = 8.20906 loss)
I0523 06:59:52.946035 34819 sgd_solver.cpp:112] Iteration 66220, lr = 0.01
I0523 06:59:59.340185 34819 solver.cpp:239] Iteration 66230 (1.39223 iter/s, 7.18274s/10 iters), loss = 7.66975
I0523 06:59:59.340239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66975 (* 1 = 7.66975 loss)
I0523 07:00:00.181123 34819 sgd_solver.cpp:112] Iteration 66230, lr = 0.01
I0523 07:00:04.869187 34819 solver.cpp:239] Iteration 66240 (1.80874 iter/s, 5.52871s/10 iters), loss = 8.23375
I0523 07:00:04.869232 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23375 (* 1 = 8.23375 loss)
I0523 07:00:05.631945 34819 sgd_solver.cpp:112] Iteration 66240, lr = 0.01
I0523 07:00:09.694958 34819 solver.cpp:239] Iteration 66250 (2.07231 iter/s, 4.82553s/10 iters), loss = 7.77388
I0523 07:00:09.695150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77388 (* 1 = 7.77388 loss)
I0523 07:00:09.765295 34819 sgd_solver.cpp:112] Iteration 66250, lr = 0.01
I0523 07:00:15.285738 34819 solver.cpp:239] Iteration 66260 (1.7888 iter/s, 5.59035s/10 iters), loss = 8.97458
I0523 07:00:15.285789 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.97458 (* 1 = 8.97458 loss)
I0523 07:00:15.357422 34819 sgd_solver.cpp:112] Iteration 66260, lr = 0.01
I0523 07:00:21.203141 34819 solver.cpp:239] Iteration 66270 (1.69001 iter/s, 5.91711s/10 iters), loss = 8.55998
I0523 07:00:21.203196 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55998 (* 1 = 8.55998 loss)
I0523 07:00:21.274905 34819 sgd_solver.cpp:112] Iteration 66270, lr = 0.01
I0523 07:00:24.606171 34819 solver.cpp:239] Iteration 66280 (2.93873 iter/s, 3.40283s/10 iters), loss = 8.36814
I0523 07:00:24.606226 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36814 (* 1 = 8.36814 loss)
I0523 07:00:24.676975 34819 sgd_solver.cpp:112] Iteration 66280, lr = 0.01
I0523 07:00:30.416646 34819 solver.cpp:239] Iteration 66290 (1.72112 iter/s, 5.81017s/10 iters), loss = 8.2146
I0523 07:00:30.416695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2146 (* 1 = 8.2146 loss)
I0523 07:00:30.476049 34819 sgd_solver.cpp:112] Iteration 66290, lr = 0.01
I0523 07:00:34.609607 34819 solver.cpp:239] Iteration 66300 (2.38508 iter/s, 4.19273s/10 iters), loss = 8.63028
I0523 07:00:34.609652 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63028 (* 1 = 8.63028 loss)
I0523 07:00:34.680431 34819 sgd_solver.cpp:112] Iteration 66300, lr = 0.01
I0523 07:00:39.391656 34819 solver.cpp:239] Iteration 66310 (2.09126 iter/s, 4.7818s/10 iters), loss = 8.65263
I0523 07:00:39.391715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65263 (* 1 = 8.65263 loss)
I0523 07:00:40.168406 34819 sgd_solver.cpp:112] Iteration 66310, lr = 0.01
I0523 07:00:44.382241 34819 solver.cpp:239] Iteration 66320 (2.00388 iter/s, 4.99031s/10 iters), loss = 8.43717
I0523 07:00:44.382304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43717 (* 1 = 8.43717 loss)
I0523 07:00:45.210247 34819 sgd_solver.cpp:112] Iteration 66320, lr = 0.01
I0523 07:00:50.097785 34819 solver.cpp:239] Iteration 66330 (1.74971 iter/s, 5.71523s/10 iters), loss = 8.31587
I0523 07:00:50.097847 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31587 (* 1 = 8.31587 loss)
I0523 07:00:50.158197 34819 sgd_solver.cpp:112] Iteration 66330, lr = 0.01
I0523 07:00:55.790170 34819 solver.cpp:239] Iteration 66340 (1.75683 iter/s, 5.69208s/10 iters), loss = 8.68881
I0523 07:00:55.790225 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68881 (* 1 = 8.68881 loss)
I0523 07:00:55.870919 34819 sgd_solver.cpp:112] Iteration 66340, lr = 0.01
I0523 07:01:00.592845 34819 solver.cpp:239] Iteration 66350 (2.0823 iter/s, 4.80239s/10 iters), loss = 8.50757
I0523 07:01:00.592926 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50757 (* 1 = 8.50757 loss)
I0523 07:01:00.659472 34819 sgd_solver.cpp:112] Iteration 66350, lr = 0.01
I0523 07:01:06.229952 34819 solver.cpp:239] Iteration 66360 (1.77406 iter/s, 5.63678s/10 iters), loss = 7.74398
I0523 07:01:06.230000 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74398 (* 1 = 7.74398 loss)
I0523 07:01:06.977058 34819 sgd_solver.cpp:112] Iteration 66360, lr = 0.01
I0523 07:01:11.286129 34819 solver.cpp:239] Iteration 66370 (1.97788 iter/s, 5.05592s/10 iters), loss = 8.39249
I0523 07:01:11.286324 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39249 (* 1 = 8.39249 loss)
I0523 07:01:12.147552 34819 sgd_solver.cpp:112] Iteration 66370, lr = 0.01
I0523 07:01:16.244415 34819 solver.cpp:239] Iteration 66380 (2.01698 iter/s, 4.95791s/10 iters), loss = 8.00861
I0523 07:01:16.244467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00861 (* 1 = 8.00861 loss)
I0523 07:01:16.302814 34819 sgd_solver.cpp:112] Iteration 66380, lr = 0.01
I0523 07:01:22.570977 34819 solver.cpp:239] Iteration 66390 (1.58072 iter/s, 6.32625s/10 iters), loss = 8.58974
I0523 07:01:22.571045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58974 (* 1 = 8.58974 loss)
I0523 07:01:23.372697 34819 sgd_solver.cpp:112] Iteration 66390, lr = 0.01
I0523 07:01:27.513933 34819 solver.cpp:239] Iteration 66400 (2.02319 iter/s, 4.94269s/10 iters), loss = 7.56431
I0523 07:01:27.513975 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56431 (* 1 = 7.56431 loss)
I0523 07:01:27.577553 34819 sgd_solver.cpp:112] Iteration 66400, lr = 0.01
I0523 07:01:32.578271 34819 solver.cpp:239] Iteration 66410 (1.97469 iter/s, 5.06408s/10 iters), loss = 7.38637
I0523 07:01:32.578339 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38637 (* 1 = 7.38637 loss)
I0523 07:01:32.641033 34819 sgd_solver.cpp:112] Iteration 66410, lr = 0.01
I0523 07:01:37.723286 34819 solver.cpp:239] Iteration 66420 (1.94373 iter/s, 5.14474s/10 iters), loss = 8.158
I0523 07:01:37.723335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.158 (* 1 = 8.158 loss)
I0523 07:01:37.786250 34819 sgd_solver.cpp:112] Iteration 66420, lr = 0.01
I0523 07:01:41.045617 34819 solver.cpp:239] Iteration 66430 (3.0101 iter/s, 3.32214s/10 iters), loss = 8.27183
I0523 07:01:41.045661 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27183 (* 1 = 8.27183 loss)
I0523 07:01:41.125191 34819 sgd_solver.cpp:112] Iteration 66430, lr = 0.01
I0523 07:01:47.514444 34819 solver.cpp:239] Iteration 66440 (1.54595 iter/s, 6.46851s/10 iters), loss = 8.44137
I0523 07:01:47.514739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44137 (* 1 = 8.44137 loss)
I0523 07:01:47.585850 34819 sgd_solver.cpp:112] Iteration 66440, lr = 0.01
I0523 07:01:50.931701 34819 solver.cpp:239] Iteration 66450 (2.92667 iter/s, 3.41685s/10 iters), loss = 7.53073
I0523 07:01:50.931768 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53073 (* 1 = 7.53073 loss)
I0523 07:01:51.714215 34819 sgd_solver.cpp:112] Iteration 66450, lr = 0.01
I0523 07:01:56.528059 34819 solver.cpp:239] Iteration 66460 (1.78698 iter/s, 5.59604s/10 iters), loss = 8.55639
I0523 07:01:56.528113 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55639 (* 1 = 8.55639 loss)
I0523 07:01:57.240394 34819 sgd_solver.cpp:112] Iteration 66460, lr = 0.01
I0523 07:02:02.747042 34819 solver.cpp:239] Iteration 66470 (1.60806 iter/s, 6.21867s/10 iters), loss = 8.73903
I0523 07:02:02.747097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73903 (* 1 = 8.73903 loss)
I0523 07:02:03.010288 34819 sgd_solver.cpp:112] Iteration 66470, lr = 0.01
I0523 07:02:07.038890 34819 solver.cpp:239] Iteration 66480 (2.33013 iter/s, 4.29161s/10 iters), loss = 8.5
I0523 07:02:07.038938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5 (* 1 = 8.5 loss)
I0523 07:02:07.107679 34819 sgd_solver.cpp:112] Iteration 66480, lr = 0.01
I0523 07:02:11.145442 34819 solver.cpp:239] Iteration 66490 (2.43527 iter/s, 4.10632s/10 iters), loss = 8.55292
I0523 07:02:11.145498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55292 (* 1 = 8.55292 loss)
I0523 07:02:12.011690 34819 sgd_solver.cpp:112] Iteration 66490, lr = 0.01
I0523 07:02:19.187304 34819 solver.cpp:239] Iteration 66500 (1.24355 iter/s, 8.04148s/10 iters), loss = 7.64333
I0523 07:02:19.187429 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64333 (* 1 = 7.64333 loss)
I0523 07:02:19.959388 34819 sgd_solver.cpp:112] Iteration 66500, lr = 0.01
I0523 07:02:24.775532 34819 solver.cpp:239] Iteration 66510 (1.78959 iter/s, 5.58788s/10 iters), loss = 8.15799
I0523 07:02:24.775583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15799 (* 1 = 8.15799 loss)
I0523 07:02:24.843708 34819 sgd_solver.cpp:112] Iteration 66510, lr = 0.01
I0523 07:02:28.168678 34819 solver.cpp:239] Iteration 66520 (2.94729 iter/s, 3.39295s/10 iters), loss = 8.00669
I0523 07:02:28.168725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00669 (* 1 = 8.00669 loss)
I0523 07:02:28.231106 34819 sgd_solver.cpp:112] Iteration 66520, lr = 0.01
I0523 07:02:35.222324 34819 solver.cpp:239] Iteration 66530 (1.41778 iter/s, 7.05329s/10 iters), loss = 7.8979
I0523 07:02:35.222383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8979 (* 1 = 7.8979 loss)
I0523 07:02:35.294813 34819 sgd_solver.cpp:112] Iteration 66530, lr = 0.01
I0523 07:02:40.243372 34819 solver.cpp:239] Iteration 66540 (1.99173 iter/s, 5.02077s/10 iters), loss = 7.7835
I0523 07:02:40.243427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7835 (* 1 = 7.7835 loss)
I0523 07:02:40.965504 34819 sgd_solver.cpp:112] Iteration 66540, lr = 0.01
I0523 07:02:46.671088 34819 solver.cpp:239] Iteration 66550 (1.55584 iter/s, 6.4274s/10 iters), loss = 8.30198
I0523 07:02:46.671133 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30198 (* 1 = 8.30198 loss)
I0523 07:02:46.736454 34819 sgd_solver.cpp:112] Iteration 66550, lr = 0.01
I0523 07:02:50.496831 34819 solver.cpp:239] Iteration 66560 (2.61402 iter/s, 3.82552s/10 iters), loss = 8.02959
I0523 07:02:50.497023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02959 (* 1 = 8.02959 loss)
I0523 07:02:50.568446 34819 sgd_solver.cpp:112] Iteration 66560, lr = 0.01
I0523 07:02:56.193249 34819 solver.cpp:239] Iteration 66570 (1.75561 iter/s, 5.69602s/10 iters), loss = 7.52673
I0523 07:02:56.193290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52673 (* 1 = 7.52673 loss)
I0523 07:02:57.054267 34819 sgd_solver.cpp:112] Iteration 66570, lr = 0.01
I0523 07:03:01.933466 34819 solver.cpp:239] Iteration 66580 (1.74218 iter/s, 5.73992s/10 iters), loss = 8.29061
I0523 07:03:01.933519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29061 (* 1 = 8.29061 loss)
I0523 07:03:02.718088 34819 sgd_solver.cpp:112] Iteration 66580, lr = 0.01
I0523 07:03:07.498396 34819 solver.cpp:239] Iteration 66590 (1.79706 iter/s, 5.56464s/10 iters), loss = 7.41323
I0523 07:03:07.498452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41323 (* 1 = 7.41323 loss)
I0523 07:03:08.344785 34819 sgd_solver.cpp:112] Iteration 66590, lr = 0.01
I0523 07:03:14.258196 34819 solver.cpp:239] Iteration 66600 (1.47941 iter/s, 6.75944s/10 iters), loss = 7.86285
I0523 07:03:14.258262 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86285 (* 1 = 7.86285 loss)
I0523 07:03:15.052525 34819 sgd_solver.cpp:112] Iteration 66600, lr = 0.01
I0523 07:03:18.747411 34819 solver.cpp:239] Iteration 66610 (2.22769 iter/s, 4.48896s/10 iters), loss = 7.8634
I0523 07:03:18.747457 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8634 (* 1 = 7.8634 loss)
I0523 07:03:18.807818 34819 sgd_solver.cpp:112] Iteration 66610, lr = 0.01
I0523 07:03:23.174582 34819 solver.cpp:239] Iteration 66620 (2.2589 iter/s, 4.42694s/10 iters), loss = 7.46113
I0523 07:03:23.174798 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46113 (* 1 = 7.46113 loss)
I0523 07:03:23.239886 34819 sgd_solver.cpp:112] Iteration 66620, lr = 0.01
I0523 07:03:27.537519 34819 solver.cpp:239] Iteration 66630 (2.29223 iter/s, 4.36256s/10 iters), loss = 8.91951
I0523 07:03:27.537562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.91951 (* 1 = 8.91951 loss)
I0523 07:03:28.166733 34819 sgd_solver.cpp:112] Iteration 66630, lr = 0.01
I0523 07:03:32.133636 34819 solver.cpp:239] Iteration 66640 (2.17587 iter/s, 4.59587s/10 iters), loss = 8.60569
I0523 07:03:32.133677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60569 (* 1 = 8.60569 loss)
I0523 07:03:32.205898 34819 sgd_solver.cpp:112] Iteration 66640, lr = 0.01
I0523 07:03:36.333214 34819 solver.cpp:239] Iteration 66650 (2.38132 iter/s, 4.19935s/10 iters), loss = 9.09344
I0523 07:03:36.333253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.09344 (* 1 = 9.09344 loss)
I0523 07:03:36.982115 34819 sgd_solver.cpp:112] Iteration 66650, lr = 0.01
I0523 07:03:38.762035 34819 solver.cpp:239] Iteration 66660 (4.11749 iter/s, 2.42866s/10 iters), loss = 8.39892
I0523 07:03:38.762078 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39892 (* 1 = 8.39892 loss)
I0523 07:03:39.306488 34819 sgd_solver.cpp:112] Iteration 66660, lr = 0.01
I0523 07:03:45.471704 34819 solver.cpp:239] Iteration 66670 (1.49046 iter/s, 6.70935s/10 iters), loss = 8.05654
I0523 07:03:45.471746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05654 (* 1 = 8.05654 loss)
I0523 07:03:46.206903 34819 sgd_solver.cpp:112] Iteration 66670, lr = 0.01
I0523 07:03:50.780714 34819 solver.cpp:239] Iteration 66680 (1.88369 iter/s, 5.30874s/10 iters), loss = 8.10052
I0523 07:03:50.780766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10052 (* 1 = 8.10052 loss)
I0523 07:03:51.654151 34819 sgd_solver.cpp:112] Iteration 66680, lr = 0.01
I0523 07:03:55.780505 34819 solver.cpp:239] Iteration 66690 (2.00019 iter/s, 4.99953s/10 iters), loss = 7.94763
I0523 07:03:55.780748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94763 (* 1 = 7.94763 loss)
I0523 07:03:56.577251 34819 sgd_solver.cpp:112] Iteration 66690, lr = 0.01
I0523 07:03:59.123811 34819 solver.cpp:239] Iteration 66700 (2.99137 iter/s, 3.34295s/10 iters), loss = 7.10159
I0523 07:03:59.123852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.10159 (* 1 = 7.10159 loss)
I0523 07:03:59.181280 34819 sgd_solver.cpp:112] Iteration 66700, lr = 0.01
I0523 07:04:03.280607 34819 solver.cpp:239] Iteration 66710 (2.40582 iter/s, 4.15658s/10 iters), loss = 7.41699
I0523 07:04:03.280647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41699 (* 1 = 7.41699 loss)
I0523 07:04:03.355139 34819 sgd_solver.cpp:112] Iteration 66710, lr = 0.01
I0523 07:04:09.894763 34819 solver.cpp:239] Iteration 66720 (1.51198 iter/s, 6.61384s/10 iters), loss = 7.77075
I0523 07:04:09.894812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77075 (* 1 = 7.77075 loss)
I0523 07:04:09.958801 34819 sgd_solver.cpp:112] Iteration 66720, lr = 0.01
I0523 07:04:15.317744 34819 solver.cpp:239] Iteration 66730 (1.8441 iter/s, 5.42269s/10 iters), loss = 7.96934
I0523 07:04:15.317795 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96934 (* 1 = 7.96934 loss)
I0523 07:04:16.180464 34819 sgd_solver.cpp:112] Iteration 66730, lr = 0.01
I0523 07:04:18.822609 34819 solver.cpp:239] Iteration 66740 (2.85334 iter/s, 3.50467s/10 iters), loss = 9.32326
I0523 07:04:18.822650 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.32326 (* 1 = 9.32326 loss)
I0523 07:04:18.877055 34819 sgd_solver.cpp:112] Iteration 66740, lr = 0.01
I0523 07:04:22.140760 34819 solver.cpp:239] Iteration 66750 (3.0139 iter/s, 3.31796s/10 iters), loss = 7.81587
I0523 07:04:22.140811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81587 (* 1 = 7.81587 loss)
I0523 07:04:22.816839 34819 sgd_solver.cpp:112] Iteration 66750, lr = 0.01
I0523 07:04:27.573698 34819 solver.cpp:239] Iteration 66760 (1.84073 iter/s, 5.43264s/10 iters), loss = 8.1302
I0523 07:04:27.573921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1302 (* 1 = 8.1302 loss)
I0523 07:04:28.340487 34819 sgd_solver.cpp:112] Iteration 66760, lr = 0.01
I0523 07:04:31.691547 34819 solver.cpp:239] Iteration 66770 (2.42867 iter/s, 4.11748s/10 iters), loss = 8.39209
I0523 07:04:31.691588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39209 (* 1 = 8.39209 loss)
I0523 07:04:32.554661 34819 sgd_solver.cpp:112] Iteration 66770, lr = 0.01
I0523 07:04:40.763674 34819 solver.cpp:239] Iteration 66780 (1.10233 iter/s, 9.07171s/10 iters), loss = 8.61761
I0523 07:04:40.763738 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61761 (* 1 = 8.61761 loss)
I0523 07:04:41.498003 34819 sgd_solver.cpp:112] Iteration 66780, lr = 0.01
I0523 07:04:45.658689 34819 solver.cpp:239] Iteration 66790 (2.043 iter/s, 4.89475s/10 iters), loss = 8.81159
I0523 07:04:45.658749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81159 (* 1 = 8.81159 loss)
I0523 07:04:45.911872 34819 sgd_solver.cpp:112] Iteration 66790, lr = 0.01
I0523 07:04:49.341033 34819 solver.cpp:239] Iteration 66800 (2.71582 iter/s, 3.68213s/10 iters), loss = 8.78777
I0523 07:04:49.341076 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78777 (* 1 = 8.78777 loss)
I0523 07:04:49.410394 34819 sgd_solver.cpp:112] Iteration 66800, lr = 0.01
I0523 07:04:53.580571 34819 solver.cpp:239] Iteration 66810 (2.35887 iter/s, 4.23932s/10 iters), loss = 7.42974
I0523 07:04:53.580612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42974 (* 1 = 7.42974 loss)
I0523 07:04:53.642683 34819 sgd_solver.cpp:112] Iteration 66810, lr = 0.01
I0523 07:04:57.221475 34819 solver.cpp:239] Iteration 66820 (2.74672 iter/s, 3.6407s/10 iters), loss = 7.87381
I0523 07:04:57.221516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87381 (* 1 = 7.87381 loss)
I0523 07:04:57.303937 34819 sgd_solver.cpp:112] Iteration 66820, lr = 0.01
I0523 07:05:02.013566 34819 solver.cpp:239] Iteration 66830 (2.08688 iter/s, 4.79185s/10 iters), loss = 8.41582
I0523 07:05:02.013695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41582 (* 1 = 8.41582 loss)
I0523 07:05:02.068578 34819 sgd_solver.cpp:112] Iteration 66830, lr = 0.01
I0523 07:05:06.315770 34819 solver.cpp:239] Iteration 66840 (2.32455 iter/s, 4.3019s/10 iters), loss = 8.45775
I0523 07:05:06.315812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45775 (* 1 = 8.45775 loss)
I0523 07:05:06.380728 34819 sgd_solver.cpp:112] Iteration 66840, lr = 0.01
I0523 07:05:11.459635 34819 solver.cpp:239] Iteration 66850 (1.94416 iter/s, 5.1436s/10 iters), loss = 7.86333
I0523 07:05:11.459676 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86333 (* 1 = 7.86333 loss)
I0523 07:05:12.356699 34819 sgd_solver.cpp:112] Iteration 66850, lr = 0.01
I0523 07:05:15.950095 34819 solver.cpp:239] Iteration 66860 (2.22706 iter/s, 4.49022s/10 iters), loss = 8.71206
I0523 07:05:15.950136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71206 (* 1 = 8.71206 loss)
I0523 07:05:16.022997 34819 sgd_solver.cpp:112] Iteration 66860, lr = 0.01
I0523 07:05:21.788898 34819 solver.cpp:239] Iteration 66870 (1.71276 iter/s, 5.83852s/10 iters), loss = 7.97931
I0523 07:05:21.788940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97931 (* 1 = 7.97931 loss)
I0523 07:05:22.552888 34819 sgd_solver.cpp:112] Iteration 66870, lr = 0.01
I0523 07:05:26.141592 34819 solver.cpp:239] Iteration 66880 (2.29755 iter/s, 4.35247s/10 iters), loss = 8.04792
I0523 07:05:26.141636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04792 (* 1 = 8.04792 loss)
I0523 07:05:26.965713 34819 sgd_solver.cpp:112] Iteration 66880, lr = 0.01
I0523 07:05:31.836192 34819 solver.cpp:239] Iteration 66890 (1.75614 iter/s, 5.6943s/10 iters), loss = 7.73394
I0523 07:05:31.836241 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73394 (* 1 = 7.73394 loss)
I0523 07:05:31.909258 34819 sgd_solver.cpp:112] Iteration 66890, lr = 0.01
I0523 07:05:38.253618 34819 solver.cpp:239] Iteration 66900 (1.55834 iter/s, 6.41711s/10 iters), loss = 7.30841
I0523 07:05:38.253777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.30841 (* 1 = 7.30841 loss)
I0523 07:05:38.319977 34819 sgd_solver.cpp:112] Iteration 66900, lr = 0.01
I0523 07:05:41.489516 34819 solver.cpp:239] Iteration 66910 (3.09061 iter/s, 3.23561s/10 iters), loss = 8.22065
I0523 07:05:41.489585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22065 (* 1 = 8.22065 loss)
I0523 07:05:41.559218 34819 sgd_solver.cpp:112] Iteration 66910, lr = 0.01
I0523 07:05:45.972815 34819 solver.cpp:239] Iteration 66920 (2.23063 iter/s, 4.48304s/10 iters), loss = 8.88172
I0523 07:05:45.972864 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88172 (* 1 = 8.88172 loss)
I0523 07:05:46.042484 34819 sgd_solver.cpp:112] Iteration 66920, lr = 0.01
I0523 07:05:52.304563 34819 solver.cpp:239] Iteration 66930 (1.57942 iter/s, 6.33144s/10 iters), loss = 8.30628
I0523 07:05:52.304615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30628 (* 1 = 8.30628 loss)
I0523 07:05:52.371722 34819 sgd_solver.cpp:112] Iteration 66930, lr = 0.01
I0523 07:05:57.621891 34819 solver.cpp:239] Iteration 66940 (1.88074 iter/s, 5.31706s/10 iters), loss = 7.68687
I0523 07:05:57.621940 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68687 (* 1 = 7.68687 loss)
I0523 07:05:58.474388 34819 sgd_solver.cpp:112] Iteration 66940, lr = 0.01
I0523 07:06:03.697515 34819 solver.cpp:239] Iteration 66950 (1.64601 iter/s, 6.07532s/10 iters), loss = 8.56056
I0523 07:06:03.697579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56056 (* 1 = 8.56056 loss)
I0523 07:06:04.008038 34819 sgd_solver.cpp:112] Iteration 66950, lr = 0.01
I0523 07:06:09.151413 34819 solver.cpp:239] Iteration 66960 (1.83365 iter/s, 5.4536s/10 iters), loss = 7.70328
I0523 07:06:09.151526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70328 (* 1 = 7.70328 loss)
I0523 07:06:09.222822 34819 sgd_solver.cpp:112] Iteration 66960, lr = 0.01
I0523 07:06:14.576473 34819 solver.cpp:239] Iteration 66970 (1.84341 iter/s, 5.42472s/10 iters), loss = 7.26225
I0523 07:06:14.576524 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26225 (* 1 = 7.26225 loss)
I0523 07:06:15.145478 34819 sgd_solver.cpp:112] Iteration 66970, lr = 0.01
I0523 07:06:20.488054 34819 solver.cpp:239] Iteration 66980 (1.69168 iter/s, 5.91128s/10 iters), loss = 8.65956
I0523 07:06:20.488095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65956 (* 1 = 8.65956 loss)
I0523 07:06:21.170716 34819 sgd_solver.cpp:112] Iteration 66980, lr = 0.01
I0523 07:06:24.275244 34819 solver.cpp:239] Iteration 66990 (2.64063 iter/s, 3.78697s/10 iters), loss = 7.47704
I0523 07:06:24.275287 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47704 (* 1 = 7.47704 loss)
I0523 07:06:24.991103 34819 sgd_solver.cpp:112] Iteration 66990, lr = 0.01
I0523 07:06:29.107708 34819 solver.cpp:239] Iteration 67000 (2.06944 iter/s, 4.83222s/10 iters), loss = 8.22186
I0523 07:06:29.107750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22186 (* 1 = 8.22186 loss)
I0523 07:06:29.345947 34819 sgd_solver.cpp:112] Iteration 67000, lr = 0.01
I0523 07:06:33.145349 34819 solver.cpp:239] Iteration 67010 (2.47684 iter/s, 4.03741s/10 iters), loss = 8.9877
I0523 07:06:33.145401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9877 (* 1 = 8.9877 loss)
I0523 07:06:33.975739 34819 sgd_solver.cpp:112] Iteration 67010, lr = 0.01
I0523 07:06:38.745285 34819 solver.cpp:239] Iteration 67020 (1.78583 iter/s, 5.59964s/10 iters), loss = 8.64852
I0523 07:06:38.745326 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64852 (* 1 = 8.64852 loss)
I0523 07:06:38.814608 34819 sgd_solver.cpp:112] Iteration 67020, lr = 0.01
I0523 07:06:45.049237 34819 solver.cpp:239] Iteration 67030 (1.58638 iter/s, 6.30366s/10 iters), loss = 8.64397
I0523 07:06:45.049345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64397 (* 1 = 8.64397 loss)
I0523 07:06:45.620440 34819 sgd_solver.cpp:112] Iteration 67030, lr = 0.01
I0523 07:06:48.910276 34819 solver.cpp:239] Iteration 67040 (2.59016 iter/s, 3.86077s/10 iters), loss = 8.28584
I0523 07:06:48.910329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28584 (* 1 = 8.28584 loss)
I0523 07:06:49.700567 34819 sgd_solver.cpp:112] Iteration 67040, lr = 0.01
I0523 07:06:54.729465 34819 solver.cpp:239] Iteration 67050 (1.71854 iter/s, 5.8189s/10 iters), loss = 8.95185
I0523 07:06:54.729507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.95185 (* 1 = 8.95185 loss)
I0523 07:06:54.804852 34819 sgd_solver.cpp:112] Iteration 67050, lr = 0.01
I0523 07:06:58.797065 34819 solver.cpp:239] Iteration 67060 (2.45859 iter/s, 4.06738s/10 iters), loss = 6.77727
I0523 07:06:58.797107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.77727 (* 1 = 6.77727 loss)
I0523 07:06:59.536249 34819 sgd_solver.cpp:112] Iteration 67060, lr = 0.01
I0523 07:07:03.493227 34819 solver.cpp:239] Iteration 67070 (2.12951 iter/s, 4.69591s/10 iters), loss = 7.33809
I0523 07:07:03.493268 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33809 (* 1 = 7.33809 loss)
I0523 07:07:04.064926 34819 sgd_solver.cpp:112] Iteration 67070, lr = 0.01
I0523 07:07:09.533139 34819 solver.cpp:239] Iteration 67080 (1.65573 iter/s, 6.03962s/10 iters), loss = 8.34559
I0523 07:07:09.533188 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34559 (* 1 = 8.34559 loss)
I0523 07:07:09.591318 34819 sgd_solver.cpp:112] Iteration 67080, lr = 0.01
I0523 07:07:15.047363 34819 solver.cpp:239] Iteration 67090 (1.81359 iter/s, 5.51394s/10 iters), loss = 7.92926
I0523 07:07:15.047406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92926 (* 1 = 7.92926 loss)
I0523 07:07:15.580773 34819 sgd_solver.cpp:112] Iteration 67090, lr = 0.01
I0523 07:07:21.643555 34819 solver.cpp:239] Iteration 67100 (1.5161 iter/s, 6.59587s/10 iters), loss = 8.11932
I0523 07:07:21.643599 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11932 (* 1 = 8.11932 loss)
I0523 07:07:21.695658 34819 sgd_solver.cpp:112] Iteration 67100, lr = 0.01
I0523 07:07:24.278884 34819 solver.cpp:239] Iteration 67110 (3.79483 iter/s, 2.63517s/10 iters), loss = 8.01093
I0523 07:07:24.278929 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01093 (* 1 = 8.01093 loss)
I0523 07:07:25.116178 34819 sgd_solver.cpp:112] Iteration 67110, lr = 0.01
I0523 07:07:30.826457 34819 solver.cpp:239] Iteration 67120 (1.52736 iter/s, 6.54726s/10 iters), loss = 8.4578
I0523 07:07:30.826498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4578 (* 1 = 8.4578 loss)
I0523 07:07:31.637653 34819 sgd_solver.cpp:112] Iteration 67120, lr = 0.01
I0523 07:07:32.969133 34819 solver.cpp:239] Iteration 67130 (4.66738 iter/s, 2.14253s/10 iters), loss = 7.96599
I0523 07:07:32.969179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96599 (* 1 = 7.96599 loss)
I0523 07:07:33.008028 34819 sgd_solver.cpp:112] Iteration 67130, lr = 0.01
I0523 07:07:36.194505 34819 solver.cpp:239] Iteration 67140 (3.10061 iter/s, 3.22518s/10 iters), loss = 8.8102
I0523 07:07:36.194557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8102 (* 1 = 8.8102 loss)
I0523 07:07:36.271042 34819 sgd_solver.cpp:112] Iteration 67140, lr = 0.01
I0523 07:07:39.797577 34819 solver.cpp:239] Iteration 67150 (2.77558 iter/s, 3.60285s/10 iters), loss = 7.59847
I0523 07:07:39.797631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59847 (* 1 = 7.59847 loss)
I0523 07:07:40.632815 34819 sgd_solver.cpp:112] Iteration 67150, lr = 0.01
I0523 07:07:44.696774 34819 solver.cpp:239] Iteration 67160 (2.04126 iter/s, 4.89893s/10 iters), loss = 8.70897
I0523 07:07:44.696830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70897 (* 1 = 8.70897 loss)
I0523 07:07:44.776693 34819 sgd_solver.cpp:112] Iteration 67160, lr = 0.01
I0523 07:07:50.979650 34819 solver.cpp:239] Iteration 67170 (1.59171 iter/s, 6.28255s/10 iters), loss = 7.79374
I0523 07:07:50.979786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79374 (* 1 = 7.79374 loss)
I0523 07:07:51.035746 34819 sgd_solver.cpp:112] Iteration 67170, lr = 0.01
I0523 07:07:55.234441 34819 solver.cpp:239] Iteration 67180 (2.35047 iter/s, 4.25446s/10 iters), loss = 8.9544
I0523 07:07:55.234498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.9544 (* 1 = 8.9544 loss)
I0523 07:07:55.298069 34819 sgd_solver.cpp:112] Iteration 67180, lr = 0.01
I0523 07:08:00.803469 34819 solver.cpp:239] Iteration 67190 (1.79574 iter/s, 5.56875s/10 iters), loss = 7.43055
I0523 07:08:00.803509 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.43055 (* 1 = 7.43055 loss)
I0523 07:08:01.633004 34819 sgd_solver.cpp:112] Iteration 67190, lr = 0.01
I0523 07:08:05.627965 34819 solver.cpp:239] Iteration 67200 (2.07286 iter/s, 4.82425s/10 iters), loss = 7.5317
I0523 07:08:05.628017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5317 (* 1 = 7.5317 loss)
I0523 07:08:05.686220 34819 sgd_solver.cpp:112] Iteration 67200, lr = 0.01
I0523 07:08:11.295017 34819 solver.cpp:239] Iteration 67210 (1.76468 iter/s, 5.66674s/10 iters), loss = 8.45511
I0523 07:08:11.295073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45511 (* 1 = 8.45511 loss)
I0523 07:08:11.357678 34819 sgd_solver.cpp:112] Iteration 67210, lr = 0.01
I0523 07:08:17.129091 34819 solver.cpp:239] Iteration 67220 (1.71416 iter/s, 5.83376s/10 iters), loss = 7.17955
I0523 07:08:17.129148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.17955 (* 1 = 7.17955 loss)
I0523 07:08:17.898617 34819 sgd_solver.cpp:112] Iteration 67220, lr = 0.01
I0523 07:08:24.003206 34819 solver.cpp:239] Iteration 67230 (1.45481 iter/s, 6.87377s/10 iters), loss = 7.46085
I0523 07:08:24.003382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46085 (* 1 = 7.46085 loss)
I0523 07:08:24.772248 34819 sgd_solver.cpp:112] Iteration 67230, lr = 0.01
I0523 07:08:28.016060 34819 solver.cpp:239] Iteration 67240 (2.4922 iter/s, 4.01252s/10 iters), loss = 8.08254
I0523 07:08:28.016103 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08254 (* 1 = 8.08254 loss)
I0523 07:08:28.096276 34819 sgd_solver.cpp:112] Iteration 67240, lr = 0.01
I0523 07:08:32.235354 34819 solver.cpp:239] Iteration 67250 (2.37019 iter/s, 4.21907s/10 iters), loss = 8.51778
I0523 07:08:32.235393 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51778 (* 1 = 8.51778 loss)
I0523 07:08:32.287108 34819 sgd_solver.cpp:112] Iteration 67250, lr = 0.01
I0523 07:08:35.654214 34819 solver.cpp:239] Iteration 67260 (2.92512 iter/s, 3.41866s/10 iters), loss = 8.92611
I0523 07:08:35.654289 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92611 (* 1 = 8.92611 loss)
I0523 07:08:35.826862 34819 sgd_solver.cpp:112] Iteration 67260, lr = 0.01
I0523 07:08:40.459533 34819 solver.cpp:239] Iteration 67270 (2.08114 iter/s, 4.80505s/10 iters), loss = 7.80258
I0523 07:08:40.459576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80258 (* 1 = 7.80258 loss)
I0523 07:08:40.520745 34819 sgd_solver.cpp:112] Iteration 67270, lr = 0.01
I0523 07:08:44.084076 34819 solver.cpp:239] Iteration 67280 (2.75912 iter/s, 3.62434s/10 iters), loss = 7.76762
I0523 07:08:44.084125 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76762 (* 1 = 7.76762 loss)
I0523 07:08:44.150310 34819 sgd_solver.cpp:112] Iteration 67280, lr = 0.01
I0523 07:08:48.185647 34819 solver.cpp:239] Iteration 67290 (2.43823 iter/s, 4.10134s/10 iters), loss = 7.89241
I0523 07:08:48.185699 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89241 (* 1 = 7.89241 loss)
I0523 07:08:48.242514 34819 sgd_solver.cpp:112] Iteration 67290, lr = 0.01
I0523 07:08:53.284580 34819 solver.cpp:239] Iteration 67300 (1.9613 iter/s, 5.09867s/10 iters), loss = 7.69555
I0523 07:08:53.284629 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69555 (* 1 = 7.69555 loss)
I0523 07:08:53.347038 34819 sgd_solver.cpp:112] Iteration 67300, lr = 0.01
I0523 07:08:58.411401 34819 solver.cpp:239] Iteration 67310 (1.95063 iter/s, 5.12654s/10 iters), loss = 7.75231
I0523 07:08:58.411620 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75231 (* 1 = 7.75231 loss)
I0523 07:08:59.271847 34819 sgd_solver.cpp:112] Iteration 67310, lr = 0.01
I0523 07:09:03.640274 34819 solver.cpp:239] Iteration 67320 (1.91261 iter/s, 5.22845s/10 iters), loss = 7.77245
I0523 07:09:03.640314 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77245 (* 1 = 7.77245 loss)
I0523 07:09:04.220154 34819 sgd_solver.cpp:112] Iteration 67320, lr = 0.01
I0523 07:09:08.265470 34819 solver.cpp:239] Iteration 67330 (2.16219 iter/s, 4.62494s/10 iters), loss = 8.19186
I0523 07:09:08.265534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19186 (* 1 = 8.19186 loss)
I0523 07:09:09.068401 34819 sgd_solver.cpp:112] Iteration 67330, lr = 0.01
I0523 07:09:12.044461 34819 solver.cpp:239] Iteration 67340 (2.64637 iter/s, 3.77876s/10 iters), loss = 8.10913
I0523 07:09:12.044500 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10913 (* 1 = 8.10913 loss)
I0523 07:09:12.102138 34819 sgd_solver.cpp:112] Iteration 67340, lr = 0.01
I0523 07:09:16.753280 34819 solver.cpp:239] Iteration 67350 (2.12378 iter/s, 4.70858s/10 iters), loss = 8.49558
I0523 07:09:16.753334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49558 (* 1 = 8.49558 loss)
I0523 07:09:16.838208 34819 sgd_solver.cpp:112] Iteration 67350, lr = 0.01
I0523 07:09:21.081626 34819 solver.cpp:239] Iteration 67360 (2.31048 iter/s, 4.32811s/10 iters), loss = 7.85744
I0523 07:09:21.081663 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85744 (* 1 = 7.85744 loss)
I0523 07:09:21.148670 34819 sgd_solver.cpp:112] Iteration 67360, lr = 0.01
I0523 07:09:22.976250 34819 solver.cpp:239] Iteration 67370 (5.27846 iter/s, 1.89449s/10 iters), loss = 9.13722
I0523 07:09:22.976296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13722 (* 1 = 9.13722 loss)
I0523 07:09:23.047106 34819 sgd_solver.cpp:112] Iteration 67370, lr = 0.01
I0523 07:09:25.789091 34819 solver.cpp:239] Iteration 67380 (3.55534 iter/s, 2.81267s/10 iters), loss = 8.67903
I0523 07:09:25.789132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67903 (* 1 = 8.67903 loss)
I0523 07:09:26.603099 34819 sgd_solver.cpp:112] Iteration 67380, lr = 0.01
I0523 07:09:28.430533 34819 solver.cpp:239] Iteration 67390 (3.78605 iter/s, 2.64128s/10 iters), loss = 8.79594
I0523 07:09:28.431301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79594 (* 1 = 8.79594 loss)
I0523 07:09:28.500583 34819 sgd_solver.cpp:112] Iteration 67390, lr = 0.01
I0523 07:09:33.574961 34819 solver.cpp:239] Iteration 67400 (1.94402 iter/s, 5.14397s/10 iters), loss = 8.17632
I0523 07:09:33.575003 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17632 (* 1 = 8.17632 loss)
I0523 07:09:33.629603 34819 sgd_solver.cpp:112] Iteration 67400, lr = 0.01
I0523 07:09:37.548770 34819 solver.cpp:239] Iteration 67410 (2.51662 iter/s, 3.97359s/10 iters), loss = 8.71528
I0523 07:09:37.548813 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71528 (* 1 = 8.71528 loss)
I0523 07:09:37.608664 34819 sgd_solver.cpp:112] Iteration 67410, lr = 0.01
I0523 07:09:43.150024 34819 solver.cpp:239] Iteration 67420 (1.7854 iter/s, 5.60097s/10 iters), loss = 8.06075
I0523 07:09:43.150065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06075 (* 1 = 8.06075 loss)
I0523 07:09:43.211505 34819 sgd_solver.cpp:112] Iteration 67420, lr = 0.01
I0523 07:09:48.022616 34819 solver.cpp:239] Iteration 67430 (2.05241 iter/s, 4.87232s/10 iters), loss = 7.73279
I0523 07:09:48.022670 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73279 (* 1 = 7.73279 loss)
I0523 07:09:48.832638 34819 sgd_solver.cpp:112] Iteration 67430, lr = 0.01
I0523 07:09:54.223959 34819 solver.cpp:239] Iteration 67440 (1.61263 iter/s, 6.20103s/10 iters), loss = 8.6543
I0523 07:09:54.224009 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6543 (* 1 = 8.6543 loss)
I0523 07:09:55.089747 34819 sgd_solver.cpp:112] Iteration 67440, lr = 0.01
I0523 07:09:59.978791 34819 solver.cpp:239] Iteration 67450 (1.73776 iter/s, 5.75454s/10 iters), loss = 8.19391
I0523 07:09:59.978921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19391 (* 1 = 8.19391 loss)
I0523 07:10:00.638259 34819 sgd_solver.cpp:112] Iteration 67450, lr = 0.01
I0523 07:10:03.459933 34819 solver.cpp:239] Iteration 67460 (2.87287 iter/s, 3.48084s/10 iters), loss = 8.57671
I0523 07:10:03.459991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57671 (* 1 = 8.57671 loss)
I0523 07:10:04.185979 34819 sgd_solver.cpp:112] Iteration 67460, lr = 0.01
I0523 07:10:09.111822 34819 solver.cpp:239] Iteration 67470 (1.76942 iter/s, 5.65158s/10 iters), loss = 7.54738
I0523 07:10:09.111869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54738 (* 1 = 7.54738 loss)
I0523 07:10:09.722659 34819 sgd_solver.cpp:112] Iteration 67470, lr = 0.01
I0523 07:10:13.148600 34819 solver.cpp:239] Iteration 67480 (2.47737 iter/s, 4.03654s/10 iters), loss = 8.40369
I0523 07:10:13.148650 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40369 (* 1 = 8.40369 loss)
I0523 07:10:13.989753 34819 sgd_solver.cpp:112] Iteration 67480, lr = 0.01
I0523 07:10:17.329449 34819 solver.cpp:239] Iteration 67490 (2.39199 iter/s, 4.18062s/10 iters), loss = 7.99478
I0523 07:10:17.329493 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99478 (* 1 = 7.99478 loss)
I0523 07:10:17.391896 34819 sgd_solver.cpp:112] Iteration 67490, lr = 0.01
I0523 07:10:21.829054 34819 solver.cpp:239] Iteration 67500 (2.22254 iter/s, 4.49936s/10 iters), loss = 7.78029
I0523 07:10:21.829113 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78029 (* 1 = 7.78029 loss)
I0523 07:10:22.569161 34819 sgd_solver.cpp:112] Iteration 67500, lr = 0.01
I0523 07:10:27.563792 34819 solver.cpp:239] Iteration 67510 (1.74385 iter/s, 5.73445s/10 iters), loss = 7.99538
I0523 07:10:27.563833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99538 (* 1 = 7.99538 loss)
I0523 07:10:27.618568 34819 sgd_solver.cpp:112] Iteration 67510, lr = 0.01
I0523 07:10:33.831408 34819 solver.cpp:239] Iteration 67520 (1.59558 iter/s, 6.26732s/10 iters), loss = 7.80338
I0523 07:10:33.831637 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80338 (* 1 = 7.80338 loss)
I0523 07:10:34.591493 34819 sgd_solver.cpp:112] Iteration 67520, lr = 0.01
I0523 07:10:38.814136 34819 solver.cpp:239] Iteration 67530 (2.0071 iter/s, 4.98232s/10 iters), loss = 7.95781
I0523 07:10:38.814188 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95781 (* 1 = 7.95781 loss)
I0523 07:10:39.641738 34819 sgd_solver.cpp:112] Iteration 67530, lr = 0.01
I0523 07:10:43.021663 34819 solver.cpp:239] Iteration 67540 (2.37682 iter/s, 4.20729s/10 iters), loss = 7.95281
I0523 07:10:43.021716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95281 (* 1 = 7.95281 loss)
I0523 07:10:43.896064 34819 sgd_solver.cpp:112] Iteration 67540, lr = 0.01
I0523 07:10:48.001058 34819 solver.cpp:239] Iteration 67550 (2.00839 iter/s, 4.97912s/10 iters), loss = 8.40859
I0523 07:10:48.001109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40859 (* 1 = 8.40859 loss)
I0523 07:10:48.765468 34819 sgd_solver.cpp:112] Iteration 67550, lr = 0.01
I0523 07:10:54.794272 34819 solver.cpp:239] Iteration 67560 (1.47213 iter/s, 6.79287s/10 iters), loss = 7.07509
I0523 07:10:54.794333 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.07509 (* 1 = 7.07509 loss)
I0523 07:10:55.527055 34819 sgd_solver.cpp:112] Iteration 67560, lr = 0.01
I0523 07:10:59.326110 34819 solver.cpp:239] Iteration 67570 (2.20674 iter/s, 4.53158s/10 iters), loss = 8.1084
I0523 07:10:59.326153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1084 (* 1 = 8.1084 loss)
I0523 07:10:59.977564 34819 sgd_solver.cpp:112] Iteration 67570, lr = 0.01
I0523 07:11:05.215536 34819 solver.cpp:239] Iteration 67580 (1.69804 iter/s, 5.88913s/10 iters), loss = 8.11484
I0523 07:11:05.215718 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11484 (* 1 = 8.11484 loss)
I0523 07:11:05.275470 34819 sgd_solver.cpp:112] Iteration 67580, lr = 0.01
I0523 07:11:09.135339 34819 solver.cpp:239] Iteration 67590 (2.55138 iter/s, 3.91945s/10 iters), loss = 7.81176
I0523 07:11:09.135386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81176 (* 1 = 7.81176 loss)
I0523 07:11:09.196099 34819 sgd_solver.cpp:112] Iteration 67590, lr = 0.01
I0523 07:11:13.835145 34819 solver.cpp:239] Iteration 67600 (2.12787 iter/s, 4.69955s/10 iters), loss = 7.05897
I0523 07:11:13.835196 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.05897 (* 1 = 7.05897 loss)
I0523 07:11:13.893540 34819 sgd_solver.cpp:112] Iteration 67600, lr = 0.01
I0523 07:11:16.919538 34819 solver.cpp:239] Iteration 67610 (3.24235 iter/s, 3.08418s/10 iters), loss = 8.37345
I0523 07:11:16.919598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37345 (* 1 = 8.37345 loss)
I0523 07:11:17.503904 34819 sgd_solver.cpp:112] Iteration 67610, lr = 0.01
I0523 07:11:22.658133 34819 solver.cpp:239] Iteration 67620 (1.74268 iter/s, 5.73829s/10 iters), loss = 7.84635
I0523 07:11:22.658201 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84635 (* 1 = 7.84635 loss)
I0523 07:11:22.931799 34819 sgd_solver.cpp:112] Iteration 67620, lr = 0.01
I0523 07:11:26.530392 34819 solver.cpp:239] Iteration 67630 (2.58264 iter/s, 3.87201s/10 iters), loss = 7.87292
I0523 07:11:26.530467 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87292 (* 1 = 7.87292 loss)
I0523 07:11:27.387002 34819 sgd_solver.cpp:112] Iteration 67630, lr = 0.01
I0523 07:11:32.262054 34819 solver.cpp:239] Iteration 67640 (1.74479 iter/s, 5.73136s/10 iters), loss = 8.18331
I0523 07:11:32.262099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18331 (* 1 = 8.18331 loss)
I0523 07:11:32.884007 34819 sgd_solver.cpp:112] Iteration 67640, lr = 0.01
I0523 07:11:38.557076 34819 solver.cpp:239] Iteration 67650 (1.58863 iter/s, 6.29471s/10 iters), loss = 8.49912
I0523 07:11:38.557194 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49912 (* 1 = 8.49912 loss)
I0523 07:11:38.632411 34819 sgd_solver.cpp:112] Iteration 67650, lr = 0.01
I0523 07:11:44.208756 34819 solver.cpp:239] Iteration 67660 (1.7695 iter/s, 5.65131s/10 iters), loss = 7.35255
I0523 07:11:44.208803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35255 (* 1 = 7.35255 loss)
I0523 07:11:44.444630 34819 sgd_solver.cpp:112] Iteration 67660, lr = 0.01
I0523 07:11:49.858774 34819 solver.cpp:239] Iteration 67670 (1.77 iter/s, 5.64973s/10 iters), loss = 8.15232
I0523 07:11:49.858815 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15232 (* 1 = 8.15232 loss)
I0523 07:11:50.691087 34819 sgd_solver.cpp:112] Iteration 67670, lr = 0.01
I0523 07:11:53.113464 34819 solver.cpp:239] Iteration 67680 (3.07266 iter/s, 3.25451s/10 iters), loss = 8.83655
I0523 07:11:53.113505 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83655 (* 1 = 8.83655 loss)
I0523 07:11:53.959604 34819 sgd_solver.cpp:112] Iteration 67680, lr = 0.01
I0523 07:11:57.423044 34819 solver.cpp:239] Iteration 67690 (2.32054 iter/s, 4.30934s/10 iters), loss = 8.13298
I0523 07:11:57.423095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13298 (* 1 = 8.13298 loss)
I0523 07:11:58.154513 34819 sgd_solver.cpp:112] Iteration 67690, lr = 0.01
I0523 07:12:02.947032 34819 solver.cpp:239] Iteration 67700 (1.81038 iter/s, 5.5237s/10 iters), loss = 7.63273
I0523 07:12:02.947084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63273 (* 1 = 7.63273 loss)
I0523 07:12:03.096441 34819 sgd_solver.cpp:112] Iteration 67700, lr = 0.01
I0523 07:12:07.981639 34819 solver.cpp:239] Iteration 67710 (1.98636 iter/s, 5.03434s/10 iters), loss = 7.81181
I0523 07:12:07.981681 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81181 (* 1 = 7.81181 loss)
I0523 07:12:08.543421 34819 sgd_solver.cpp:112] Iteration 67710, lr = 0.01
I0523 07:12:13.380784 34819 solver.cpp:239] Iteration 67720 (1.85224 iter/s, 5.39888s/10 iters), loss = 8.50177
I0523 07:12:13.380910 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50177 (* 1 = 8.50177 loss)
I0523 07:12:13.443696 34819 sgd_solver.cpp:112] Iteration 67720, lr = 0.01
I0523 07:12:17.403923 34819 solver.cpp:239] Iteration 67730 (2.4858 iter/s, 4.02284s/10 iters), loss = 8.45213
I0523 07:12:17.403964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45213 (* 1 = 8.45213 loss)
I0523 07:12:18.220382 34819 sgd_solver.cpp:112] Iteration 67730, lr = 0.01
I0523 07:12:20.692481 34819 solver.cpp:239] Iteration 67740 (3.04102 iter/s, 3.28838s/10 iters), loss = 7.64359
I0523 07:12:20.692523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64359 (* 1 = 7.64359 loss)
I0523 07:12:21.532815 34819 sgd_solver.cpp:112] Iteration 67740, lr = 0.01
I0523 07:12:25.193102 34819 solver.cpp:239] Iteration 67750 (2.22203 iter/s, 4.50039s/10 iters), loss = 7.58549
I0523 07:12:25.193140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58549 (* 1 = 7.58549 loss)
I0523 07:12:25.255568 34819 sgd_solver.cpp:112] Iteration 67750, lr = 0.01
I0523 07:12:31.420290 34819 solver.cpp:239] Iteration 67760 (1.60594 iter/s, 6.22688s/10 iters), loss = 8.75622
I0523 07:12:31.420338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75622 (* 1 = 8.75622 loss)
I0523 07:12:31.723587 34819 sgd_solver.cpp:112] Iteration 67760, lr = 0.01
I0523 07:12:35.655221 34819 solver.cpp:239] Iteration 67770 (2.36145 iter/s, 4.23469s/10 iters), loss = 8.34582
I0523 07:12:35.655270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34582 (* 1 = 8.34582 loss)
I0523 07:12:36.122902 34819 sgd_solver.cpp:112] Iteration 67770, lr = 0.01
I0523 07:12:40.599524 34819 solver.cpp:239] Iteration 67780 (2.02263 iter/s, 4.94405s/10 iters), loss = 6.77883
I0523 07:12:40.599576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.77883 (* 1 = 6.77883 loss)
I0523 07:12:40.652348 34819 sgd_solver.cpp:112] Iteration 67780, lr = 0.01
I0523 07:12:47.722414 34819 solver.cpp:239] Iteration 67790 (1.40399 iter/s, 7.12254s/10 iters), loss = 8.15867
I0523 07:12:47.722565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15867 (* 1 = 8.15867 loss)
I0523 07:12:48.358140 34819 sgd_solver.cpp:112] Iteration 67790, lr = 0.01
I0523 07:12:51.987634 34819 solver.cpp:239] Iteration 67800 (2.34473 iter/s, 4.26488s/10 iters), loss = 7.96983
I0523 07:12:51.987694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96983 (* 1 = 7.96983 loss)
I0523 07:12:52.814329 34819 sgd_solver.cpp:112] Iteration 67800, lr = 0.01
I0523 07:12:56.246754 34819 solver.cpp:239] Iteration 67810 (2.34806 iter/s, 4.25884s/10 iters), loss = 9.15739
I0523 07:12:56.246819 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.15739 (* 1 = 9.15739 loss)
I0523 07:12:57.098811 34819 sgd_solver.cpp:112] Iteration 67810, lr = 0.01
I0523 07:13:00.136291 34819 solver.cpp:239] Iteration 67820 (2.57115 iter/s, 3.88931s/10 iters), loss = 8.33212
I0523 07:13:00.136343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33212 (* 1 = 8.33212 loss)
I0523 07:13:00.192008 34819 sgd_solver.cpp:112] Iteration 67820, lr = 0.01
I0523 07:13:05.118194 34819 solver.cpp:239] Iteration 67830 (2.00737 iter/s, 4.98164s/10 iters), loss = 7.72568
I0523 07:13:05.118252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72568 (* 1 = 7.72568 loss)
I0523 07:13:05.940251 34819 sgd_solver.cpp:112] Iteration 67830, lr = 0.01
I0523 07:13:11.386206 34819 solver.cpp:239] Iteration 67840 (1.59548 iter/s, 6.2677s/10 iters), loss = 8.2463
I0523 07:13:11.386260 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2463 (* 1 = 8.2463 loss)
I0523 07:13:12.249541 34819 sgd_solver.cpp:112] Iteration 67840, lr = 0.01
I0523 07:13:16.232291 34819 solver.cpp:239] Iteration 67850 (2.06363 iter/s, 4.84582s/10 iters), loss = 8.53819
I0523 07:13:16.232336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53819 (* 1 = 8.53819 loss)
I0523 07:13:16.311233 34819 sgd_solver.cpp:112] Iteration 67850, lr = 0.01
I0523 07:13:23.313120 34819 solver.cpp:239] Iteration 67860 (1.41233 iter/s, 7.0805s/10 iters), loss = 6.87121
I0523 07:13:23.313251 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.87121 (* 1 = 6.87121 loss)
I0523 07:13:23.971846 34819 sgd_solver.cpp:112] Iteration 67860, lr = 0.01
I0523 07:13:28.906922 34819 solver.cpp:239] Iteration 67870 (1.78781 iter/s, 5.59345s/10 iters), loss = 8.17532
I0523 07:13:28.906966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17532 (* 1 = 8.17532 loss)
I0523 07:13:28.966840 34819 sgd_solver.cpp:112] Iteration 67870, lr = 0.01
I0523 07:13:31.628002 34819 solver.cpp:239] Iteration 67880 (3.67523 iter/s, 2.72091s/10 iters), loss = 8.19603
I0523 07:13:31.628044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19603 (* 1 = 8.19603 loss)
I0523 07:13:32.197365 34819 sgd_solver.cpp:112] Iteration 67880, lr = 0.01
I0523 07:13:36.964062 34819 solver.cpp:239] Iteration 67890 (1.87414 iter/s, 5.33579s/10 iters), loss = 7.82856
I0523 07:13:36.964118 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82856 (* 1 = 7.82856 loss)
I0523 07:13:37.023334 34819 sgd_solver.cpp:112] Iteration 67890, lr = 0.01
I0523 07:13:40.899327 34819 solver.cpp:239] Iteration 67900 (2.54127 iter/s, 3.93504s/10 iters), loss = 8.39684
I0523 07:13:40.899381 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39684 (* 1 = 8.39684 loss)
I0523 07:13:41.416147 34819 sgd_solver.cpp:112] Iteration 67900, lr = 0.01
I0523 07:13:47.446310 34819 solver.cpp:239] Iteration 67910 (1.5275 iter/s, 6.54664s/10 iters), loss = 6.77526
I0523 07:13:47.446377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.77526 (* 1 = 6.77526 loss)
I0523 07:13:47.644984 34819 sgd_solver.cpp:112] Iteration 67910, lr = 0.01
I0523 07:13:52.914019 34819 solver.cpp:239] Iteration 67920 (1.82902 iter/s, 5.46741s/10 iters), loss = 8.01189
I0523 07:13:52.914073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01189 (* 1 = 8.01189 loss)
I0523 07:13:52.976059 34819 sgd_solver.cpp:112] Iteration 67920, lr = 0.01
I0523 07:13:56.506404 34819 solver.cpp:239] Iteration 67930 (2.78383 iter/s, 3.59217s/10 iters), loss = 7.94061
I0523 07:13:56.506547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94061 (* 1 = 7.94061 loss)
I0523 07:13:56.563439 34819 sgd_solver.cpp:112] Iteration 67930, lr = 0.01
I0523 07:14:00.697927 34819 solver.cpp:239] Iteration 67940 (2.38595 iter/s, 4.1912s/10 iters), loss = 6.41922
I0523 07:14:00.697978 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.41922 (* 1 = 6.41922 loss)
I0523 07:14:00.760493 34819 sgd_solver.cpp:112] Iteration 67940, lr = 0.01
I0523 07:14:05.646546 34819 solver.cpp:239] Iteration 67950 (2.02088 iter/s, 4.94835s/10 iters), loss = 9.27744
I0523 07:14:05.646608 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.27744 (* 1 = 9.27744 loss)
I0523 07:14:06.461231 34819 sgd_solver.cpp:112] Iteration 67950, lr = 0.01
I0523 07:14:10.501329 34819 solver.cpp:239] Iteration 67960 (2.05994 iter/s, 4.85452s/10 iters), loss = 8.37054
I0523 07:14:10.501381 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37054 (* 1 = 8.37054 loss)
I0523 07:14:11.255487 34819 sgd_solver.cpp:112] Iteration 67960, lr = 0.01
I0523 07:14:14.314715 34819 solver.cpp:239] Iteration 67970 (2.6225 iter/s, 3.81315s/10 iters), loss = 8.58328
I0523 07:14:14.314767 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58328 (* 1 = 8.58328 loss)
I0523 07:14:14.389575 34819 sgd_solver.cpp:112] Iteration 67970, lr = 0.01
I0523 07:14:18.558316 34819 solver.cpp:239] Iteration 67980 (2.35662 iter/s, 4.24337s/10 iters), loss = 8.11768
I0523 07:14:18.558367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11768 (* 1 = 8.11768 loss)
I0523 07:14:18.623342 34819 sgd_solver.cpp:112] Iteration 67980, lr = 0.01
I0523 07:14:23.149327 34819 solver.cpp:239] Iteration 67990 (2.17829 iter/s, 4.59075s/10 iters), loss = 7.8497
I0523 07:14:23.149384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8497 (* 1 = 7.8497 loss)
I0523 07:14:24.026372 34819 sgd_solver.cpp:112] Iteration 67990, lr = 0.01
I0523 07:14:30.688694 34819 solver.cpp:239] Iteration 68000 (1.32643 iter/s, 7.53901s/10 iters), loss = 7.58684
I0523 07:14:30.688815 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58684 (* 1 = 7.58684 loss)
I0523 07:14:30.744355 34819 sgd_solver.cpp:112] Iteration 68000, lr = 0.01
I0523 07:14:36.276651 34819 solver.cpp:239] Iteration 68010 (1.78968 iter/s, 5.58761s/10 iters), loss = 8.12825
I0523 07:14:36.276698 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12825 (* 1 = 8.12825 loss)
I0523 07:14:36.353183 34819 sgd_solver.cpp:112] Iteration 68010, lr = 0.01
I0523 07:14:41.577095 34819 solver.cpp:239] Iteration 68020 (1.88673 iter/s, 5.30018s/10 iters), loss = 8.32755
I0523 07:14:41.577141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32755 (* 1 = 8.32755 loss)
I0523 07:14:42.255228 34819 sgd_solver.cpp:112] Iteration 68020, lr = 0.01
I0523 07:14:46.858480 34819 solver.cpp:239] Iteration 68030 (1.89354 iter/s, 5.28112s/10 iters), loss = 8.73607
I0523 07:14:46.858532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.73607 (* 1 = 8.73607 loss)
I0523 07:14:46.936648 34819 sgd_solver.cpp:112] Iteration 68030, lr = 0.01
I0523 07:14:51.103595 34819 solver.cpp:239] Iteration 68040 (2.35578 iter/s, 4.24489s/10 iters), loss = 8.23865
I0523 07:14:51.103636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23865 (* 1 = 8.23865 loss)
I0523 07:14:51.169591 34819 sgd_solver.cpp:112] Iteration 68040, lr = 0.01
I0523 07:14:56.215335 34819 solver.cpp:239] Iteration 68050 (1.95638 iter/s, 5.11148s/10 iters), loss = 7.6193
I0523 07:14:56.215378 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6193 (* 1 = 7.6193 loss)
I0523 07:14:56.282341 34819 sgd_solver.cpp:112] Iteration 68050, lr = 0.01
I0523 07:15:01.194921 34819 solver.cpp:239] Iteration 68060 (2.0083 iter/s, 4.97933s/10 iters), loss = 8.79635
I0523 07:15:01.195066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79635 (* 1 = 8.79635 loss)
I0523 07:15:01.255722 34819 sgd_solver.cpp:112] Iteration 68060, lr = 0.01
I0523 07:15:05.416680 34819 solver.cpp:239] Iteration 68070 (2.36886 iter/s, 4.22144s/10 iters), loss = 8.88981
I0523 07:15:05.416723 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88981 (* 1 = 8.88981 loss)
I0523 07:15:06.106348 34819 sgd_solver.cpp:112] Iteration 68070, lr = 0.01
I0523 07:15:10.120440 34819 solver.cpp:239] Iteration 68080 (2.12607 iter/s, 4.70352s/10 iters), loss = 8.66614
I0523 07:15:10.120481 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66614 (* 1 = 8.66614 loss)
I0523 07:15:10.195606 34819 sgd_solver.cpp:112] Iteration 68080, lr = 0.01
I0523 07:15:13.890590 34819 solver.cpp:239] Iteration 68090 (2.65256 iter/s, 3.76995s/10 iters), loss = 8.98137
I0523 07:15:13.890631 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.98137 (* 1 = 8.98137 loss)
I0523 07:15:13.951170 34819 sgd_solver.cpp:112] Iteration 68090, lr = 0.01
I0523 07:15:19.162248 34819 solver.cpp:239] Iteration 68100 (1.89703 iter/s, 5.2714s/10 iters), loss = 7.52666
I0523 07:15:19.162292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52666 (* 1 = 7.52666 loss)
I0523 07:15:19.821306 34819 sgd_solver.cpp:112] Iteration 68100, lr = 0.01
I0523 07:15:25.529250 34819 solver.cpp:239] Iteration 68110 (1.57067 iter/s, 6.3667s/10 iters), loss = 8.12369
I0523 07:15:25.529291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12369 (* 1 = 8.12369 loss)
I0523 07:15:26.354228 34819 sgd_solver.cpp:112] Iteration 68110, lr = 0.01
I0523 07:15:31.210780 34819 solver.cpp:239] Iteration 68120 (1.76018 iter/s, 5.68125s/10 iters), loss = 7.51643
I0523 07:15:31.210970 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51643 (* 1 = 7.51643 loss)
I0523 07:15:31.279731 34819 sgd_solver.cpp:112] Iteration 68120, lr = 0.01
I0523 07:15:37.676868 34819 solver.cpp:239] Iteration 68130 (1.54664 iter/s, 6.46565s/10 iters), loss = 7.36737
I0523 07:15:37.676920 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36737 (* 1 = 7.36737 loss)
I0523 07:15:37.741935 34819 sgd_solver.cpp:112] Iteration 68130, lr = 0.01
I0523 07:15:40.319365 34819 solver.cpp:239] Iteration 68140 (3.78454 iter/s, 2.64233s/10 iters), loss = 8.85989
I0523 07:15:40.319406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85989 (* 1 = 8.85989 loss)
I0523 07:15:40.385061 34819 sgd_solver.cpp:112] Iteration 68140, lr = 0.01
I0523 07:15:44.252895 34819 solver.cpp:239] Iteration 68150 (2.54238 iter/s, 3.93333s/10 iters), loss = 8.09689
I0523 07:15:44.252938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09689 (* 1 = 8.09689 loss)
I0523 07:15:45.075012 34819 sgd_solver.cpp:112] Iteration 68150, lr = 0.01
I0523 07:15:49.228884 34819 solver.cpp:239] Iteration 68160 (2.00975 iter/s, 4.97574s/10 iters), loss = 8.7288
I0523 07:15:49.228929 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7288 (* 1 = 8.7288 loss)
I0523 07:15:49.316063 34819 sgd_solver.cpp:112] Iteration 68160, lr = 0.01
I0523 07:15:55.913302 34819 solver.cpp:239] Iteration 68170 (1.49609 iter/s, 6.68407s/10 iters), loss = 8.20287
I0523 07:15:55.913369 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20287 (* 1 = 8.20287 loss)
I0523 07:15:56.738023 34819 sgd_solver.cpp:112] Iteration 68170, lr = 0.01
I0523 07:16:01.591907 34819 solver.cpp:239] Iteration 68180 (1.76109 iter/s, 5.67831s/10 iters), loss = 8.39911
I0523 07:16:01.592172 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39911 (* 1 = 8.39911 loss)
I0523 07:16:02.391060 34819 sgd_solver.cpp:112] Iteration 68180, lr = 0.01
I0523 07:16:07.470453 34819 solver.cpp:239] Iteration 68190 (1.70124 iter/s, 5.87805s/10 iters), loss = 8.80332
I0523 07:16:07.470495 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80332 (* 1 = 8.80332 loss)
I0523 07:16:07.546491 34819 sgd_solver.cpp:112] Iteration 68190, lr = 0.01
I0523 07:16:13.015612 34819 solver.cpp:239] Iteration 68200 (1.80347 iter/s, 5.54487s/10 iters), loss = 8.26196
I0523 07:16:13.015664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26196 (* 1 = 8.26196 loss)
I0523 07:16:13.084874 34819 sgd_solver.cpp:112] Iteration 68200, lr = 0.01
I0523 07:16:16.152909 34819 solver.cpp:239] Iteration 68210 (3.18765 iter/s, 3.13711s/10 iters), loss = 7.54958
I0523 07:16:16.152951 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54958 (* 1 = 7.54958 loss)
I0523 07:16:16.227087 34819 sgd_solver.cpp:112] Iteration 68210, lr = 0.01
I0523 07:16:19.764930 34819 solver.cpp:239] Iteration 68220 (2.76869 iter/s, 3.61182s/10 iters), loss = 7.47813
I0523 07:16:19.764991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47813 (* 1 = 7.47813 loss)
I0523 07:16:20.479811 34819 sgd_solver.cpp:112] Iteration 68220, lr = 0.01
I0523 07:16:26.051733 34819 solver.cpp:239] Iteration 68230 (1.59072 iter/s, 6.28647s/10 iters), loss = 7.46151
I0523 07:16:26.051775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46151 (* 1 = 7.46151 loss)
I0523 07:16:26.867405 34819 sgd_solver.cpp:112] Iteration 68230, lr = 0.01
I0523 07:16:32.231683 34819 solver.cpp:239] Iteration 68240 (1.61822 iter/s, 6.17965s/10 iters), loss = 8.81586
I0523 07:16:32.231791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.81586 (* 1 = 8.81586 loss)
I0523 07:16:32.292117 34819 sgd_solver.cpp:112] Iteration 68240, lr = 0.01
I0523 07:16:36.609314 34819 solver.cpp:239] Iteration 68250 (2.28449 iter/s, 4.37734s/10 iters), loss = 7.88233
I0523 07:16:36.609356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88233 (* 1 = 7.88233 loss)
I0523 07:16:36.671543 34819 sgd_solver.cpp:112] Iteration 68250, lr = 0.01
I0523 07:16:43.126842 34819 solver.cpp:239] Iteration 68260 (1.5344 iter/s, 6.51721s/10 iters), loss = 7.94843
I0523 07:16:43.126885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94843 (* 1 = 7.94843 loss)
I0523 07:16:43.941856 34819 sgd_solver.cpp:112] Iteration 68260, lr = 0.01
I0523 07:16:48.457377 34819 solver.cpp:239] Iteration 68270 (1.87608 iter/s, 5.33027s/10 iters), loss = 8.48321
I0523 07:16:48.457432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48321 (* 1 = 8.48321 loss)
I0523 07:16:48.543277 34819 sgd_solver.cpp:112] Iteration 68270, lr = 0.01
I0523 07:16:53.703491 34819 solver.cpp:239] Iteration 68280 (1.90627 iter/s, 5.24584s/10 iters), loss = 8.37735
I0523 07:16:53.703547 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37735 (* 1 = 8.37735 loss)
I0523 07:16:53.766486 34819 sgd_solver.cpp:112] Iteration 68280, lr = 0.01
I0523 07:16:58.103615 34819 solver.cpp:239] Iteration 68290 (2.27279 iter/s, 4.39988s/10 iters), loss = 8.13024
I0523 07:16:58.103663 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13024 (* 1 = 8.13024 loss)
I0523 07:16:58.167744 34819 sgd_solver.cpp:112] Iteration 68290, lr = 0.01
I0523 07:17:04.226732 34819 solver.cpp:239] Iteration 68300 (1.63325 iter/s, 6.12278s/10 iters), loss = 8.74649
I0523 07:17:04.226888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74649 (* 1 = 8.74649 loss)
I0523 07:17:05.037153 34819 sgd_solver.cpp:112] Iteration 68300, lr = 0.01
I0523 07:17:10.872630 34819 solver.cpp:239] Iteration 68310 (1.50478 iter/s, 6.64547s/10 iters), loss = 7.68181
I0523 07:17:10.872673 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68181 (* 1 = 7.68181 loss)
I0523 07:17:10.939524 34819 sgd_solver.cpp:112] Iteration 68310, lr = 0.01
I0523 07:17:15.068967 34819 solver.cpp:239] Iteration 68320 (2.38316 iter/s, 4.19612s/10 iters), loss = 8.94325
I0523 07:17:15.069015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94325 (* 1 = 8.94325 loss)
I0523 07:17:15.817349 34819 sgd_solver.cpp:112] Iteration 68320, lr = 0.01
I0523 07:17:21.170681 34819 solver.cpp:239] Iteration 68330 (1.63897 iter/s, 6.10139s/10 iters), loss = 7.67451
I0523 07:17:21.170750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67451 (* 1 = 7.67451 loss)
I0523 07:17:21.968753 34819 sgd_solver.cpp:112] Iteration 68330, lr = 0.01
I0523 07:17:25.545783 34819 solver.cpp:239] Iteration 68340 (2.2858 iter/s, 4.37483s/10 iters), loss = 8.3193
I0523 07:17:25.545835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3193 (* 1 = 8.3193 loss)
I0523 07:17:25.605690 34819 sgd_solver.cpp:112] Iteration 68340, lr = 0.01
I0523 07:17:29.045243 34819 solver.cpp:239] Iteration 68350 (2.85775 iter/s, 3.49926s/10 iters), loss = 7.96894
I0523 07:17:29.045287 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96894 (* 1 = 7.96894 loss)
I0523 07:17:29.370645 34819 sgd_solver.cpp:112] Iteration 68350, lr = 0.01
I0523 07:17:35.120136 34819 solver.cpp:239] Iteration 68360 (1.6462 iter/s, 6.0746s/10 iters), loss = 8.67171
I0523 07:17:35.120261 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67171 (* 1 = 8.67171 loss)
I0523 07:17:35.969192 34819 sgd_solver.cpp:112] Iteration 68360, lr = 0.01
I0523 07:17:40.992302 34819 solver.cpp:239] Iteration 68370 (1.70306 iter/s, 5.87178s/10 iters), loss = 8.52631
I0523 07:17:40.992358 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52631 (* 1 = 8.52631 loss)
I0523 07:17:41.791990 34819 sgd_solver.cpp:112] Iteration 68370, lr = 0.01
I0523 07:17:45.671341 34819 solver.cpp:239] Iteration 68380 (2.13731 iter/s, 4.67878s/10 iters), loss = 8.23509
I0523 07:17:45.671396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23509 (* 1 = 8.23509 loss)
I0523 07:17:45.746060 34819 sgd_solver.cpp:112] Iteration 68380, lr = 0.01
I0523 07:17:52.041596 34819 solver.cpp:239] Iteration 68390 (1.56988 iter/s, 6.36993s/10 iters), loss = 7.91171
I0523 07:17:52.041651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91171 (* 1 = 7.91171 loss)
I0523 07:17:52.103962 34819 sgd_solver.cpp:112] Iteration 68390, lr = 0.01
I0523 07:17:55.528434 34819 solver.cpp:239] Iteration 68400 (2.8681 iter/s, 3.48663s/10 iters), loss = 8.44796
I0523 07:17:55.528475 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44796 (* 1 = 8.44796 loss)
I0523 07:17:55.601209 34819 sgd_solver.cpp:112] Iteration 68400, lr = 0.01
I0523 07:17:59.637764 34819 solver.cpp:239] Iteration 68410 (2.43362 iter/s, 4.1091s/10 iters), loss = 7.41395
I0523 07:17:59.637816 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41395 (* 1 = 7.41395 loss)
I0523 07:17:59.716948 34819 sgd_solver.cpp:112] Iteration 68410, lr = 0.01
I0523 07:18:02.308022 34819 solver.cpp:239] Iteration 68420 (3.74519 iter/s, 2.67009s/10 iters), loss = 7.96199
I0523 07:18:02.308063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96199 (* 1 = 7.96199 loss)
I0523 07:18:03.136692 34819 sgd_solver.cpp:112] Iteration 68420, lr = 0.01
I0523 07:18:06.283931 34819 solver.cpp:239] Iteration 68430 (2.51528 iter/s, 3.9757s/10 iters), loss = 7.10947
I0523 07:18:06.284163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.10947 (* 1 = 7.10947 loss)
I0523 07:18:06.329360 34819 sgd_solver.cpp:112] Iteration 68430, lr = 0.01
I0523 07:18:07.483933 34819 solver.cpp:239] Iteration 68440 (8.33515 iter/s, 1.19974s/10 iters), loss = 8.62707
I0523 07:18:07.483978 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62707 (* 1 = 8.62707 loss)
I0523 07:18:07.529894 34819 sgd_solver.cpp:112] Iteration 68440, lr = 0.01
I0523 07:18:11.972493 34819 solver.cpp:239] Iteration 68450 (2.228 iter/s, 4.48832s/10 iters), loss = 8.32012
I0523 07:18:11.972537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32012 (* 1 = 8.32012 loss)
I0523 07:18:12.044718 34819 sgd_solver.cpp:112] Iteration 68450, lr = 0.01
I0523 07:18:16.140708 34819 solver.cpp:239] Iteration 68460 (2.39924 iter/s, 4.16799s/10 iters), loss = 7.85892
I0523 07:18:16.140749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85892 (* 1 = 7.85892 loss)
I0523 07:18:16.211848 34819 sgd_solver.cpp:112] Iteration 68460, lr = 0.01
I0523 07:18:22.366109 34819 solver.cpp:239] Iteration 68470 (1.6064 iter/s, 6.22509s/10 iters), loss = 7.67006
I0523 07:18:22.366153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67006 (* 1 = 7.67006 loss)
I0523 07:18:22.438627 34819 sgd_solver.cpp:112] Iteration 68470, lr = 0.01
I0523 07:18:27.138166 34819 solver.cpp:239] Iteration 68480 (2.09564 iter/s, 4.77181s/10 iters), loss = 8.28736
I0523 07:18:27.138207 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28736 (* 1 = 8.28736 loss)
I0523 07:18:27.211488 34819 sgd_solver.cpp:112] Iteration 68480, lr = 0.01
I0523 07:18:33.301249 34819 solver.cpp:239] Iteration 68490 (1.62264 iter/s, 6.16278s/10 iters), loss = 9.13041
I0523 07:18:33.301301 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13041 (* 1 = 9.13041 loss)
I0523 07:18:33.376543 34819 sgd_solver.cpp:112] Iteration 68490, lr = 0.01
I0523 07:18:38.077872 34819 solver.cpp:239] Iteration 68500 (2.09364 iter/s, 4.77637s/10 iters), loss = 9.03996
I0523 07:18:38.078063 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.03996 (* 1 = 9.03996 loss)
I0523 07:18:38.140826 34819 sgd_solver.cpp:112] Iteration 68500, lr = 0.01
I0523 07:18:42.442260 34819 solver.cpp:239] Iteration 68510 (2.29146 iter/s, 4.36403s/10 iters), loss = 7.57778
I0523 07:18:42.442306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57778 (* 1 = 7.57778 loss)
I0523 07:18:42.517278 34819 sgd_solver.cpp:112] Iteration 68510, lr = 0.01
I0523 07:18:47.405584 34819 solver.cpp:239] Iteration 68520 (2.01488 iter/s, 4.96307s/10 iters), loss = 7.68629
I0523 07:18:47.405637 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68629 (* 1 = 7.68629 loss)
I0523 07:18:47.483407 34819 sgd_solver.cpp:112] Iteration 68520, lr = 0.01
I0523 07:18:53.971639 34819 solver.cpp:239] Iteration 68530 (1.52306 iter/s, 6.56572s/10 iters), loss = 7.55742
I0523 07:18:53.971693 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55742 (* 1 = 7.55742 loss)
I0523 07:18:54.832214 34819 sgd_solver.cpp:112] Iteration 68530, lr = 0.01
I0523 07:18:58.828549 34819 solver.cpp:239] Iteration 68540 (2.05903 iter/s, 4.85664s/10 iters), loss = 7.9592
I0523 07:18:58.828609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9592 (* 1 = 7.9592 loss)
I0523 07:18:59.656339 34819 sgd_solver.cpp:112] Iteration 68540, lr = 0.01
I0523 07:19:05.255204 34819 solver.cpp:239] Iteration 68550 (1.5561 iter/s, 6.42631s/10 iters), loss = 7.83212
I0523 07:19:05.255264 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83212 (* 1 = 7.83212 loss)
I0523 07:19:05.325444 34819 sgd_solver.cpp:112] Iteration 68550, lr = 0.01
I0523 07:19:09.357308 34819 solver.cpp:239] Iteration 68560 (2.43792 iter/s, 4.10186s/10 iters), loss = 8.17195
I0523 07:19:09.357527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17195 (* 1 = 8.17195 loss)
I0523 07:19:10.139884 34819 sgd_solver.cpp:112] Iteration 68560, lr = 0.01
I0523 07:19:16.073599 34819 solver.cpp:239] Iteration 68570 (1.48902 iter/s, 6.71582s/10 iters), loss = 8.6138
I0523 07:19:16.073655 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6138 (* 1 = 8.6138 loss)
I0523 07:19:16.850235 34819 sgd_solver.cpp:112] Iteration 68570, lr = 0.01
I0523 07:19:21.914815 34819 solver.cpp:239] Iteration 68580 (1.71206 iter/s, 5.84092s/10 iters), loss = 8.36657
I0523 07:19:21.914870 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36657 (* 1 = 8.36657 loss)
I0523 07:19:22.441224 34819 sgd_solver.cpp:112] Iteration 68580, lr = 0.01
I0523 07:19:25.782325 34819 solver.cpp:239] Iteration 68590 (2.58579 iter/s, 3.86729s/10 iters), loss = 7.93642
I0523 07:19:25.782374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93642 (* 1 = 7.93642 loss)
I0523 07:19:25.866863 34819 sgd_solver.cpp:112] Iteration 68590, lr = 0.01
I0523 07:19:30.393371 34819 solver.cpp:239] Iteration 68600 (2.16882 iter/s, 4.6108s/10 iters), loss = 8.36384
I0523 07:19:30.393422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36384 (* 1 = 8.36384 loss)
I0523 07:19:30.459029 34819 sgd_solver.cpp:112] Iteration 68600, lr = 0.01
I0523 07:19:34.557113 34819 solver.cpp:239] Iteration 68610 (2.40182 iter/s, 4.1635s/10 iters), loss = 7.31333
I0523 07:19:34.557171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.31333 (* 1 = 7.31333 loss)
I0523 07:19:35.374317 34819 sgd_solver.cpp:112] Iteration 68610, lr = 0.01
I0523 07:19:37.910974 34819 solver.cpp:239] Iteration 68620 (2.98184 iter/s, 3.35363s/10 iters), loss = 8.61124
I0523 07:19:37.911015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.61124 (* 1 = 8.61124 loss)
I0523 07:19:37.974932 34819 sgd_solver.cpp:112] Iteration 68620, lr = 0.01
I0523 07:19:43.051092 34819 solver.cpp:239] Iteration 68630 (1.94558 iter/s, 5.13985s/10 iters), loss = 7.37152
I0523 07:19:43.051367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.37152 (* 1 = 7.37152 loss)
I0523 07:19:43.912638 34819 sgd_solver.cpp:112] Iteration 68630, lr = 0.01
I0523 07:19:46.443295 34819 solver.cpp:239] Iteration 68640 (2.94829 iter/s, 3.3918s/10 iters), loss = 7.72106
I0523 07:19:46.443351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72106 (* 1 = 7.72106 loss)
I0523 07:19:47.268718 34819 sgd_solver.cpp:112] Iteration 68640, lr = 0.01
I0523 07:19:49.938624 34819 solver.cpp:239] Iteration 68650 (2.86114 iter/s, 3.4951s/10 iters), loss = 7.87008
I0523 07:19:49.938684 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87008 (* 1 = 7.87008 loss)
I0523 07:19:50.562878 34819 sgd_solver.cpp:112] Iteration 68650, lr = 0.01
I0523 07:19:53.743965 34819 solver.cpp:239] Iteration 68660 (2.62804 iter/s, 3.80512s/10 iters), loss = 6.79632
I0523 07:19:53.744017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.79632 (* 1 = 6.79632 loss)
I0523 07:19:54.559679 34819 sgd_solver.cpp:112] Iteration 68660, lr = 0.01
I0523 07:19:59.754356 34819 solver.cpp:239] Iteration 68670 (1.66387 iter/s, 6.01009s/10 iters), loss = 7.45175
I0523 07:19:59.754400 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.45175 (* 1 = 7.45175 loss)
I0523 07:19:59.999025 34819 sgd_solver.cpp:112] Iteration 68670, lr = 0.01
I0523 07:20:06.163631 34819 solver.cpp:239] Iteration 68680 (1.56031 iter/s, 6.40897s/10 iters), loss = 8.22064
I0523 07:20:06.163691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22064 (* 1 = 8.22064 loss)
I0523 07:20:06.792459 34819 sgd_solver.cpp:112] Iteration 68680, lr = 0.01
I0523 07:20:11.696514 34819 solver.cpp:239] Iteration 68690 (1.80747 iter/s, 5.5326s/10 iters), loss = 8.19948
I0523 07:20:11.696555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19948 (* 1 = 8.19948 loss)
I0523 07:20:12.506825 34819 sgd_solver.cpp:112] Iteration 68690, lr = 0.01
I0523 07:20:18.611860 34819 solver.cpp:239] Iteration 68700 (1.44613 iter/s, 6.91501s/10 iters), loss = 8.43781
I0523 07:20:18.612015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43781 (* 1 = 8.43781 loss)
I0523 07:20:18.669872 34819 sgd_solver.cpp:112] Iteration 68700, lr = 0.01
I0523 07:20:22.444661 34819 solver.cpp:239] Iteration 68710 (2.60927 iter/s, 3.83249s/10 iters), loss = 8.69066
I0523 07:20:22.444706 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.69066 (* 1 = 8.69066 loss)
I0523 07:20:23.273447 34819 sgd_solver.cpp:112] Iteration 68710, lr = 0.01
I0523 07:20:28.551962 34819 solver.cpp:239] Iteration 68720 (1.63746 iter/s, 6.107s/10 iters), loss = 7.95546
I0523 07:20:28.552012 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95546 (* 1 = 7.95546 loss)
I0523 07:20:29.235415 34819 sgd_solver.cpp:112] Iteration 68720, lr = 0.01
I0523 07:20:34.181324 34819 solver.cpp:239] Iteration 68730 (1.77649 iter/s, 5.62908s/10 iters), loss = 8.71831
I0523 07:20:34.181366 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71831 (* 1 = 8.71831 loss)
I0523 07:20:34.239313 34819 sgd_solver.cpp:112] Iteration 68730, lr = 0.01
I0523 07:20:40.270236 34819 solver.cpp:239] Iteration 68740 (1.64241 iter/s, 6.08862s/10 iters), loss = 7.56784
I0523 07:20:40.270275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56784 (* 1 = 7.56784 loss)
I0523 07:20:41.052043 34819 sgd_solver.cpp:112] Iteration 68740, lr = 0.01
I0523 07:20:45.218896 34819 solver.cpp:239] Iteration 68750 (2.02086 iter/s, 4.9484s/10 iters), loss = 8.92875
I0523 07:20:45.218946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.92875 (* 1 = 8.92875 loss)
I0523 07:20:46.070678 34819 sgd_solver.cpp:112] Iteration 68750, lr = 0.01
I0523 07:20:49.527974 34819 solver.cpp:239] Iteration 68760 (2.32081 iter/s, 4.30885s/10 iters), loss = 7.52582
I0523 07:20:49.528115 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52582 (* 1 = 7.52582 loss)
I0523 07:20:49.590576 34819 sgd_solver.cpp:112] Iteration 68760, lr = 0.01
I0523 07:20:53.674180 34819 solver.cpp:239] Iteration 68770 (2.41204 iter/s, 4.14588s/10 iters), loss = 7.53979
I0523 07:20:53.674250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53979 (* 1 = 7.53979 loss)
I0523 07:20:54.442570 34819 sgd_solver.cpp:112] Iteration 68770, lr = 0.01
I0523 07:20:57.529778 34819 solver.cpp:239] Iteration 68780 (2.59379 iter/s, 3.85536s/10 iters), loss = 8.43161
I0523 07:20:57.529830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43161 (* 1 = 8.43161 loss)
I0523 07:20:58.141032 34819 sgd_solver.cpp:112] Iteration 68780, lr = 0.01
I0523 07:21:05.781955 34819 solver.cpp:239] Iteration 68790 (1.21186 iter/s, 8.25178s/10 iters), loss = 8.13182
I0523 07:21:05.782006 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13182 (* 1 = 8.13182 loss)
I0523 07:21:05.848248 34819 sgd_solver.cpp:112] Iteration 68790, lr = 0.01
I0523 07:21:10.058351 34819 solver.cpp:239] Iteration 68800 (2.33855 iter/s, 4.27616s/10 iters), loss = 9.07775
I0523 07:21:10.058393 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.07775 (* 1 = 9.07775 loss)
I0523 07:21:10.132774 34819 sgd_solver.cpp:112] Iteration 68800, lr = 0.01
I0523 07:21:14.320518 34819 solver.cpp:239] Iteration 68810 (2.34635 iter/s, 4.26194s/10 iters), loss = 7.87734
I0523 07:21:14.320575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87734 (* 1 = 7.87734 loss)
I0523 07:21:14.388242 34819 sgd_solver.cpp:112] Iteration 68810, lr = 0.01
I0523 07:21:19.077332 34819 solver.cpp:239] Iteration 68820 (2.10236 iter/s, 4.75656s/10 iters), loss = 7.5703
I0523 07:21:19.077373 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5703 (* 1 = 7.5703 loss)
I0523 07:21:19.141906 34819 sgd_solver.cpp:112] Iteration 68820, lr = 0.01
I0523 07:21:24.951062 34819 solver.cpp:239] Iteration 68830 (1.70258 iter/s, 5.87345s/10 iters), loss = 8.68936
I0523 07:21:24.951270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68936 (* 1 = 8.68936 loss)
I0523 07:21:25.008513 34819 sgd_solver.cpp:112] Iteration 68830, lr = 0.01
I0523 07:21:28.157408 34819 solver.cpp:239] Iteration 68840 (3.11913 iter/s, 3.20602s/10 iters), loss = 8.12439
I0523 07:21:28.157464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12439 (* 1 = 8.12439 loss)
I0523 07:21:28.223692 34819 sgd_solver.cpp:112] Iteration 68840, lr = 0.01
I0523 07:21:34.509680 34819 solver.cpp:239] Iteration 68850 (1.57432 iter/s, 6.35195s/10 iters), loss = 8.01107
I0523 07:21:34.509721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01107 (* 1 = 8.01107 loss)
I0523 07:21:35.335510 34819 sgd_solver.cpp:112] Iteration 68850, lr = 0.01
I0523 07:21:40.192044 34819 solver.cpp:239] Iteration 68860 (1.75992 iter/s, 5.68209s/10 iters), loss = 8.6468
I0523 07:21:40.192086 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6468 (* 1 = 8.6468 loss)
I0523 07:21:40.250986 34819 sgd_solver.cpp:112] Iteration 68860, lr = 0.01
I0523 07:21:44.221104 34819 solver.cpp:239] Iteration 68870 (2.48211 iter/s, 4.02883s/10 iters), loss = 7.81241
I0523 07:21:44.221159 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81241 (* 1 = 7.81241 loss)
I0523 07:21:45.063040 34819 sgd_solver.cpp:112] Iteration 68870, lr = 0.01
I0523 07:21:48.481874 34819 solver.cpp:239] Iteration 68880 (2.34712 iter/s, 4.26053s/10 iters), loss = 8.05753
I0523 07:21:48.481930 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05753 (* 1 = 8.05753 loss)
I0523 07:21:48.549927 34819 sgd_solver.cpp:112] Iteration 68880, lr = 0.01
I0523 07:21:54.041123 34819 solver.cpp:239] Iteration 68890 (1.7989 iter/s, 5.55896s/10 iters), loss = 7.28264
I0523 07:21:54.041173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28264 (* 1 = 7.28264 loss)
I0523 07:21:54.097964 34819 sgd_solver.cpp:112] Iteration 68890, lr = 0.01
I0523 07:21:57.541623 34819 solver.cpp:239] Iteration 68900 (2.8569 iter/s, 3.5003s/10 iters), loss = 7.70664
I0523 07:21:57.541836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70664 (* 1 = 7.70664 loss)
I0523 07:21:57.609099 34819 sgd_solver.cpp:112] Iteration 68900, lr = 0.01
I0523 07:22:03.257262 34819 solver.cpp:239] Iteration 68910 (1.74972 iter/s, 5.71522s/10 iters), loss = 7.36684
I0523 07:22:03.257306 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36684 (* 1 = 7.36684 loss)
I0523 07:22:03.323066 34819 sgd_solver.cpp:112] Iteration 68910, lr = 0.01
I0523 07:22:07.974740 34819 solver.cpp:239] Iteration 68920 (2.11989 iter/s, 4.71722s/10 iters), loss = 8.54172
I0523 07:22:07.974781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54172 (* 1 = 8.54172 loss)
I0523 07:22:08.048951 34819 sgd_solver.cpp:112] Iteration 68920, lr = 0.01
I0523 07:22:12.063953 34819 solver.cpp:239] Iteration 68930 (2.44559 iter/s, 4.08899s/10 iters), loss = 8.16166
I0523 07:22:12.063995 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16166 (* 1 = 8.16166 loss)
I0523 07:22:12.132936 34819 sgd_solver.cpp:112] Iteration 68930, lr = 0.01
I0523 07:22:14.733227 34819 solver.cpp:239] Iteration 68940 (3.74657 iter/s, 2.66911s/10 iters), loss = 8.62139
I0523 07:22:14.733266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62139 (* 1 = 8.62139 loss)
I0523 07:22:14.807622 34819 sgd_solver.cpp:112] Iteration 68940, lr = 0.01
I0523 07:22:19.007068 34819 solver.cpp:239] Iteration 68950 (2.33993 iter/s, 4.27363s/10 iters), loss = 8.10904
I0523 07:22:19.007109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10904 (* 1 = 8.10904 loss)
I0523 07:22:19.074173 34819 sgd_solver.cpp:112] Iteration 68950, lr = 0.01
I0523 07:22:22.653906 34819 solver.cpp:239] Iteration 68960 (2.74226 iter/s, 3.64663s/10 iters), loss = 8.40164
I0523 07:22:22.653954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40164 (* 1 = 8.40164 loss)
I0523 07:22:23.384070 34819 sgd_solver.cpp:112] Iteration 68960, lr = 0.01
I0523 07:22:28.262152 34819 solver.cpp:239] Iteration 68970 (1.78318 iter/s, 5.60797s/10 iters), loss = 8.07893
I0523 07:22:28.262384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07893 (* 1 = 8.07893 loss)
I0523 07:22:28.317808 34819 sgd_solver.cpp:112] Iteration 68970, lr = 0.01
I0523 07:22:32.626744 34819 solver.cpp:239] Iteration 68980 (2.29136 iter/s, 4.36422s/10 iters), loss = 8.74721
I0523 07:22:32.626785 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74721 (* 1 = 8.74721 loss)
I0523 07:22:32.703183 34819 sgd_solver.cpp:112] Iteration 68980, lr = 0.01
I0523 07:22:36.086740 34819 solver.cpp:239] Iteration 68990 (2.89034 iter/s, 3.45981s/10 iters), loss = 7.65725
I0523 07:22:36.086781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65725 (* 1 = 7.65725 loss)
I0523 07:22:36.140825 34819 sgd_solver.cpp:112] Iteration 68990, lr = 0.01
I0523 07:22:39.759752 34819 solver.cpp:239] Iteration 69000 (2.72271 iter/s, 3.67281s/10 iters), loss = 6.94504
I0523 07:22:39.759791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.94504 (* 1 = 6.94504 loss)
I0523 07:22:40.557049 34819 sgd_solver.cpp:112] Iteration 69000, lr = 0.01
I0523 07:22:46.187695 34819 solver.cpp:239] Iteration 69010 (1.55578 iter/s, 6.42763s/10 iters), loss = 7.11646
I0523 07:22:46.187747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.11646 (* 1 = 7.11646 loss)
I0523 07:22:46.249498 34819 sgd_solver.cpp:112] Iteration 69010, lr = 0.01
I0523 07:22:51.296823 34819 solver.cpp:239] Iteration 69020 (1.95739 iter/s, 5.10885s/10 iters), loss = 7.38594
I0523 07:22:51.296877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38594 (* 1 = 7.38594 loss)
I0523 07:22:51.376032 34819 sgd_solver.cpp:112] Iteration 69020, lr = 0.01
I0523 07:22:55.288247 34819 solver.cpp:239] Iteration 69030 (2.50551 iter/s, 3.9912s/10 iters), loss = 8.39859
I0523 07:22:55.288303 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39859 (* 1 = 8.39859 loss)
I0523 07:22:56.116140 34819 sgd_solver.cpp:112] Iteration 69030, lr = 0.01
I0523 07:23:00.702473 34819 solver.cpp:239] Iteration 69040 (1.84708 iter/s, 5.41394s/10 iters), loss = 7.27284
I0523 07:23:00.702656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.27284 (* 1 = 7.27284 loss)
I0523 07:23:00.784595 34819 sgd_solver.cpp:112] Iteration 69040, lr = 0.01
I0523 07:23:05.011433 34819 solver.cpp:239] Iteration 69050 (2.32094 iter/s, 4.30859s/10 iters), loss = 7.06629
I0523 07:23:05.011473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.06629 (* 1 = 7.06629 loss)
I0523 07:23:05.705494 34819 sgd_solver.cpp:112] Iteration 69050, lr = 0.01
I0523 07:23:10.143858 34819 solver.cpp:239] Iteration 69060 (1.9485 iter/s, 5.13217s/10 iters), loss = 7.58279
I0523 07:23:10.143898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58279 (* 1 = 7.58279 loss)
I0523 07:23:10.216964 34819 sgd_solver.cpp:112] Iteration 69060, lr = 0.01
I0523 07:23:15.555402 34819 solver.cpp:239] Iteration 69070 (1.848 iter/s, 5.41126s/10 iters), loss = 8.22095
I0523 07:23:15.555451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22095 (* 1 = 8.22095 loss)
I0523 07:23:15.637495 34819 sgd_solver.cpp:112] Iteration 69070, lr = 0.01
I0523 07:23:21.270994 34819 solver.cpp:239] Iteration 69080 (1.74969 iter/s, 5.71531s/10 iters), loss = 6.75792
I0523 07:23:21.271034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.75792 (* 1 = 6.75792 loss)
I0523 07:23:22.130578 34819 sgd_solver.cpp:112] Iteration 69080, lr = 0.01
I0523 07:23:27.980628 34819 solver.cpp:239] Iteration 69090 (1.49047 iter/s, 6.70931s/10 iters), loss = 9.19742
I0523 07:23:27.980669 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.19742 (* 1 = 9.19742 loss)
I0523 07:23:28.051420 34819 sgd_solver.cpp:112] Iteration 69090, lr = 0.01
I0523 07:23:33.557042 34819 solver.cpp:239] Iteration 69100 (1.79337 iter/s, 5.57611s/10 iters), loss = 7.56126
I0523 07:23:33.557176 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56126 (* 1 = 7.56126 loss)
I0523 07:23:34.349447 34819 sgd_solver.cpp:112] Iteration 69100, lr = 0.01
I0523 07:23:39.967226 34819 solver.cpp:239] Iteration 69110 (1.56011 iter/s, 6.40979s/10 iters), loss = 7.05959
I0523 07:23:39.967278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.05959 (* 1 = 7.05959 loss)
I0523 07:23:40.035617 34819 sgd_solver.cpp:112] Iteration 69110, lr = 0.01
I0523 07:23:44.925834 34819 solver.cpp:239] Iteration 69120 (2.0168 iter/s, 4.95834s/10 iters), loss = 7.93262
I0523 07:23:44.925876 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93262 (* 1 = 7.93262 loss)
I0523 07:23:45.410182 34819 sgd_solver.cpp:112] Iteration 69120, lr = 0.01
I0523 07:23:49.348551 34819 solver.cpp:239] Iteration 69130 (2.26117 iter/s, 4.42249s/10 iters), loss = 7.35806
I0523 07:23:49.348594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35806 (* 1 = 7.35806 loss)
I0523 07:23:49.415241 34819 sgd_solver.cpp:112] Iteration 69130, lr = 0.01
I0523 07:23:54.144186 34819 solver.cpp:239] Iteration 69140 (2.08534 iter/s, 4.79539s/10 iters), loss = 7.99603
I0523 07:23:54.144240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99603 (* 1 = 7.99603 loss)
I0523 07:23:54.231010 34819 sgd_solver.cpp:112] Iteration 69140, lr = 0.01
I0523 07:23:59.325793 34819 solver.cpp:239] Iteration 69150 (1.93001 iter/s, 5.18133s/10 iters), loss = 8.50363
I0523 07:23:59.325848 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50363 (* 1 = 8.50363 loss)
I0523 07:23:59.390959 34819 sgd_solver.cpp:112] Iteration 69150, lr = 0.01
I0523 07:24:03.445928 34819 solver.cpp:239] Iteration 69160 (2.42724 iter/s, 4.1199s/10 iters), loss = 7.67011
I0523 07:24:03.445986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67011 (* 1 = 7.67011 loss)
I0523 07:24:04.229622 34819 sgd_solver.cpp:112] Iteration 69160, lr = 0.01
I0523 07:24:09.070279 34819 solver.cpp:239] Iteration 69170 (1.77807 iter/s, 5.62406s/10 iters), loss = 8.36406
I0523 07:24:09.070322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36406 (* 1 = 8.36406 loss)
I0523 07:24:09.854809 34819 sgd_solver.cpp:112] Iteration 69170, lr = 0.01
I0523 07:24:14.168838 34819 solver.cpp:239] Iteration 69180 (1.96144 iter/s, 5.09829s/10 iters), loss = 7.98317
I0523 07:24:14.168901 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98317 (* 1 = 7.98317 loss)
I0523 07:24:14.960628 34819 sgd_solver.cpp:112] Iteration 69180, lr = 0.01
I0523 07:24:20.193979 34819 solver.cpp:239] Iteration 69190 (1.6598 iter/s, 6.02482s/10 iters), loss = 8.2207
I0523 07:24:20.194020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2207 (* 1 = 8.2207 loss)
I0523 07:24:20.271600 34819 sgd_solver.cpp:112] Iteration 69190, lr = 0.01
I0523 07:24:24.602650 34819 solver.cpp:239] Iteration 69200 (2.26838 iter/s, 4.40843s/10 iters), loss = 7.32492
I0523 07:24:24.602691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.32492 (* 1 = 7.32492 loss)
I0523 07:24:24.676555 34819 sgd_solver.cpp:112] Iteration 69200, lr = 0.01
I0523 07:24:30.938854 34819 solver.cpp:239] Iteration 69210 (1.57831 iter/s, 6.33589s/10 iters), loss = 7.53247
I0523 07:24:30.938906 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53247 (* 1 = 7.53247 loss)
I0523 07:24:31.010546 34819 sgd_solver.cpp:112] Iteration 69210, lr = 0.01
I0523 07:24:36.116817 34819 solver.cpp:239] Iteration 69220 (1.93137 iter/s, 5.17768s/10 iters), loss = 8.00643
I0523 07:24:36.116996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00643 (* 1 = 8.00643 loss)
I0523 07:24:36.188241 34819 sgd_solver.cpp:112] Iteration 69220, lr = 0.01
I0523 07:24:40.828480 34819 solver.cpp:239] Iteration 69230 (2.1239 iter/s, 4.70831s/10 iters), loss = 7.0655
I0523 07:24:40.828536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.0655 (* 1 = 7.0655 loss)
I0523 07:24:41.670888 34819 sgd_solver.cpp:112] Iteration 69230, lr = 0.01
I0523 07:24:46.935443 34819 solver.cpp:239] Iteration 69240 (1.63756 iter/s, 6.10666s/10 iters), loss = 8.40854
I0523 07:24:46.935483 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40854 (* 1 = 8.40854 loss)
I0523 07:24:47.827917 34819 sgd_solver.cpp:112] Iteration 69240, lr = 0.01
I0523 07:24:51.870213 34819 solver.cpp:239] Iteration 69250 (2.02654 iter/s, 4.93452s/10 iters), loss = 9.00156
I0523 07:24:51.870267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.00156 (* 1 = 9.00156 loss)
I0523 07:24:51.927628 34819 sgd_solver.cpp:112] Iteration 69250, lr = 0.01
I0523 07:24:54.652635 34819 solver.cpp:239] Iteration 69260 (3.59422 iter/s, 2.78224s/10 iters), loss = 8.59585
I0523 07:24:54.652688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.59585 (* 1 = 8.59585 loss)
I0523 07:24:55.491192 34819 sgd_solver.cpp:112] Iteration 69260, lr = 0.01
I0523 07:25:00.220418 34819 solver.cpp:239] Iteration 69270 (1.79614 iter/s, 5.5675s/10 iters), loss = 8.27606
I0523 07:25:00.220463 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27606 (* 1 = 8.27606 loss)
I0523 07:25:00.290066 34819 sgd_solver.cpp:112] Iteration 69270, lr = 0.01
I0523 07:25:04.250358 34819 solver.cpp:239] Iteration 69280 (2.48156 iter/s, 4.02972s/10 iters), loss = 8.55493
I0523 07:25:04.250409 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55493 (* 1 = 8.55493 loss)
I0523 07:25:04.308575 34819 sgd_solver.cpp:112] Iteration 69280, lr = 0.01
I0523 07:25:08.890185 34819 solver.cpp:239] Iteration 69290 (2.15537 iter/s, 4.63957s/10 iters), loss = 8.04599
I0523 07:25:08.890354 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04599 (* 1 = 8.04599 loss)
I0523 07:25:08.957384 34819 sgd_solver.cpp:112] Iteration 69290, lr = 0.01
I0523 07:25:14.192785 34819 solver.cpp:239] Iteration 69300 (1.886 iter/s, 5.30221s/10 iters), loss = 7.06152
I0523 07:25:14.192829 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.06152 (* 1 = 7.06152 loss)
I0523 07:25:14.253983 34819 sgd_solver.cpp:112] Iteration 69300, lr = 0.01
I0523 07:25:19.747958 34819 solver.cpp:239] Iteration 69310 (1.80021 iter/s, 5.5549s/10 iters), loss = 8.32289
I0523 07:25:19.747999 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32289 (* 1 = 8.32289 loss)
I0523 07:25:19.820660 34819 sgd_solver.cpp:112] Iteration 69310, lr = 0.01
I0523 07:25:24.025722 34819 solver.cpp:239] Iteration 69320 (2.3378 iter/s, 4.27753s/10 iters), loss = 8.00884
I0523 07:25:24.025764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00884 (* 1 = 8.00884 loss)
I0523 07:25:24.106086 34819 sgd_solver.cpp:112] Iteration 69320, lr = 0.01
I0523 07:25:28.350638 34819 solver.cpp:239] Iteration 69330 (2.3123 iter/s, 4.32469s/10 iters), loss = 7.76652
I0523 07:25:28.350688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76652 (* 1 = 7.76652 loss)
I0523 07:25:29.186658 34819 sgd_solver.cpp:112] Iteration 69330, lr = 0.01
I0523 07:25:30.977388 34819 solver.cpp:239] Iteration 69340 (3.80727 iter/s, 2.62656s/10 iters), loss = 7.69112
I0523 07:25:30.977443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69112 (* 1 = 7.69112 loss)
I0523 07:25:31.051995 34819 sgd_solver.cpp:112] Iteration 69340, lr = 0.01
I0523 07:25:36.619084 34819 solver.cpp:239] Iteration 69350 (1.77261 iter/s, 5.64141s/10 iters), loss = 7.58065
I0523 07:25:36.619130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58065 (* 1 = 7.58065 loss)
I0523 07:25:36.681102 34819 sgd_solver.cpp:112] Iteration 69350, lr = 0.01
I0523 07:25:39.885457 34819 solver.cpp:239] Iteration 69360 (3.06168 iter/s, 3.26618s/10 iters), loss = 8.39559
I0523 07:25:39.885710 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39559 (* 1 = 8.39559 loss)
I0523 07:25:40.716640 34819 sgd_solver.cpp:112] Iteration 69360, lr = 0.01
I0523 07:25:47.974180 34819 solver.cpp:239] Iteration 69370 (1.23637 iter/s, 8.08817s/10 iters), loss = 8.29657
I0523 07:25:47.974243 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29657 (* 1 = 8.29657 loss)
I0523 07:25:48.836163 34819 sgd_solver.cpp:112] Iteration 69370, lr = 0.01
I0523 07:25:52.762331 34819 solver.cpp:239] Iteration 69380 (2.0886 iter/s, 4.78789s/10 iters), loss = 7.86757
I0523 07:25:52.762377 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86757 (* 1 = 7.86757 loss)
I0523 07:25:53.587286 34819 sgd_solver.cpp:112] Iteration 69380, lr = 0.01
I0523 07:25:56.980995 34819 solver.cpp:239] Iteration 69390 (2.37055 iter/s, 4.21842s/10 iters), loss = 7.3498
I0523 07:25:56.981045 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3498 (* 1 = 7.3498 loss)
I0523 07:25:57.732801 34819 sgd_solver.cpp:112] Iteration 69390, lr = 0.01
I0523 07:26:03.984134 34819 solver.cpp:239] Iteration 69400 (1.42801 iter/s, 7.00278s/10 iters), loss = 8.76687
I0523 07:26:03.984216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.76687 (* 1 = 8.76687 loss)
I0523 07:26:04.058471 34819 sgd_solver.cpp:112] Iteration 69400, lr = 0.01
I0523 07:26:07.310595 34819 solver.cpp:239] Iteration 69410 (3.0064 iter/s, 3.32624s/10 iters), loss = 8.5954
I0523 07:26:07.310647 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5954 (* 1 = 8.5954 loss)
I0523 07:26:07.384218 34819 sgd_solver.cpp:112] Iteration 69410, lr = 0.01
I0523 07:26:11.423732 34819 solver.cpp:239] Iteration 69420 (2.43137 iter/s, 4.11291s/10 iters), loss = 8.6101
I0523 07:26:11.423871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6101 (* 1 = 8.6101 loss)
I0523 07:26:11.478530 34819 sgd_solver.cpp:112] Iteration 69420, lr = 0.01
I0523 07:26:16.940532 34819 solver.cpp:239] Iteration 69430 (1.81277 iter/s, 5.51642s/10 iters), loss = 7.05986
I0523 07:26:16.940582 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.05986 (* 1 = 7.05986 loss)
I0523 07:26:17.011343 34819 sgd_solver.cpp:112] Iteration 69430, lr = 0.01
I0523 07:26:22.614022 34819 solver.cpp:239] Iteration 69440 (1.76267 iter/s, 5.67321s/10 iters), loss = 7.97975
I0523 07:26:22.614066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97975 (* 1 = 7.97975 loss)
I0523 07:26:22.683607 34819 sgd_solver.cpp:112] Iteration 69440, lr = 0.01
I0523 07:26:27.555984 34819 solver.cpp:239] Iteration 69450 (2.02538 iter/s, 4.93735s/10 iters), loss = 7.63293
I0523 07:26:27.556025 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63293 (* 1 = 7.63293 loss)
I0523 07:26:27.613953 34819 sgd_solver.cpp:112] Iteration 69450, lr = 0.01
I0523 07:26:30.990243 34819 solver.cpp:239] Iteration 69460 (2.912 iter/s, 3.43407s/10 iters), loss = 8.13878
I0523 07:26:30.990285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13878 (* 1 = 8.13878 loss)
I0523 07:26:31.798923 34819 sgd_solver.cpp:112] Iteration 69460, lr = 0.01
I0523 07:26:35.982136 34819 solver.cpp:239] Iteration 69470 (2.00335 iter/s, 4.99165s/10 iters), loss = 7.57058
I0523 07:26:35.982177 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57058 (* 1 = 7.57058 loss)
I0523 07:26:36.048125 34819 sgd_solver.cpp:112] Iteration 69470, lr = 0.01
I0523 07:26:41.014899 34819 solver.cpp:239] Iteration 69480 (1.98708 iter/s, 5.03251s/10 iters), loss = 8.12284
I0523 07:26:41.014952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12284 (* 1 = 8.12284 loss)
I0523 07:26:41.806143 34819 sgd_solver.cpp:112] Iteration 69480, lr = 0.01
I0523 07:26:45.615643 34819 solver.cpp:239] Iteration 69490 (2.17368 iter/s, 4.6005s/10 iters), loss = 7.88279
I0523 07:26:45.615695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88279 (* 1 = 7.88279 loss)
I0523 07:26:45.694216 34819 sgd_solver.cpp:112] Iteration 69490, lr = 0.01
I0523 07:26:50.063817 34819 solver.cpp:239] Iteration 69500 (2.24824 iter/s, 4.44793s/10 iters), loss = 8.3128
I0523 07:26:50.063869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3128 (* 1 = 8.3128 loss)
I0523 07:26:50.892192 34819 sgd_solver.cpp:112] Iteration 69500, lr = 0.01
I0523 07:26:57.050683 34819 solver.cpp:239] Iteration 69510 (1.43133 iter/s, 6.98652s/10 iters), loss = 8.13468
I0523 07:26:57.050750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13468 (* 1 = 8.13468 loss)
I0523 07:26:57.560998 34819 sgd_solver.cpp:112] Iteration 69510, lr = 0.01
I0523 07:27:03.248467 34819 solver.cpp:239] Iteration 69520 (1.61357 iter/s, 6.19745s/10 iters), loss = 8.60937
I0523 07:27:03.248522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60937 (* 1 = 8.60937 loss)
I0523 07:27:04.088650 34819 sgd_solver.cpp:112] Iteration 69520, lr = 0.01
I0523 07:27:07.631738 34819 solver.cpp:239] Iteration 69530 (2.28153 iter/s, 4.38303s/10 iters), loss = 7.68571
I0523 07:27:07.631786 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68571 (* 1 = 7.68571 loss)
I0523 07:27:08.465185 34819 sgd_solver.cpp:112] Iteration 69530, lr = 0.01
I0523 07:27:12.585978 34819 solver.cpp:239] Iteration 69540 (2.01858 iter/s, 4.95398s/10 iters), loss = 8.42641
I0523 07:27:12.586132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42641 (* 1 = 8.42641 loss)
I0523 07:27:12.650620 34819 sgd_solver.cpp:112] Iteration 69540, lr = 0.01
I0523 07:27:16.081540 34819 solver.cpp:239] Iteration 69550 (2.86102 iter/s, 3.49526s/10 iters), loss = 7.6448
I0523 07:27:16.081593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6448 (* 1 = 7.6448 loss)
I0523 07:27:16.140300 34819 sgd_solver.cpp:112] Iteration 69550, lr = 0.01
I0523 07:27:21.593255 34819 solver.cpp:239] Iteration 69560 (1.81441 iter/s, 5.51142s/10 iters), loss = 7.39127
I0523 07:27:21.593307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39127 (* 1 = 7.39127 loss)
I0523 07:27:21.662366 34819 sgd_solver.cpp:112] Iteration 69560, lr = 0.01
I0523 07:27:27.488045 34819 solver.cpp:239] Iteration 69570 (1.6965 iter/s, 5.89449s/10 iters), loss = 7.79756
I0523 07:27:27.488114 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79756 (* 1 = 7.79756 loss)
I0523 07:27:28.295703 34819 sgd_solver.cpp:112] Iteration 69570, lr = 0.01
I0523 07:27:32.668820 34819 solver.cpp:239] Iteration 69580 (1.93032 iter/s, 5.1805s/10 iters), loss = 7.78707
I0523 07:27:32.668869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78707 (* 1 = 7.78707 loss)
I0523 07:27:33.175490 34819 sgd_solver.cpp:112] Iteration 69580, lr = 0.01
I0523 07:27:38.055534 34819 solver.cpp:239] Iteration 69590 (1.85652 iter/s, 5.38644s/10 iters), loss = 8.50842
I0523 07:27:38.055577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50842 (* 1 = 8.50842 loss)
I0523 07:27:38.115749 34819 sgd_solver.cpp:112] Iteration 69590, lr = 0.01
I0523 07:27:44.746942 34819 solver.cpp:239] Iteration 69600 (1.49453 iter/s, 6.69108s/10 iters), loss = 7.84912
I0523 07:27:44.747185 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84912 (* 1 = 7.84912 loss)
I0523 07:27:44.819715 34819 sgd_solver.cpp:112] Iteration 69600, lr = 0.01
I0523 07:27:47.968330 34819 solver.cpp:239] Iteration 69610 (3.1046 iter/s, 3.22103s/10 iters), loss = 7.77802
I0523 07:27:47.968372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77802 (* 1 = 7.77802 loss)
I0523 07:27:48.658310 34819 sgd_solver.cpp:112] Iteration 69610, lr = 0.01
I0523 07:27:52.263671 34819 solver.cpp:239] Iteration 69620 (2.32823 iter/s, 4.29511s/10 iters), loss = 8.3057
I0523 07:27:52.263720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3057 (* 1 = 8.3057 loss)
I0523 07:27:52.816675 34819 sgd_solver.cpp:112] Iteration 69620, lr = 0.01
I0523 07:27:57.806896 34819 solver.cpp:239] Iteration 69630 (1.8041 iter/s, 5.54293s/10 iters), loss = 8.65924
I0523 07:27:57.806953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65924 (* 1 = 8.65924 loss)
I0523 07:27:58.272387 34819 sgd_solver.cpp:112] Iteration 69630, lr = 0.01
I0523 07:28:03.209929 34819 solver.cpp:239] Iteration 69640 (1.85091 iter/s, 5.40274s/10 iters), loss = 8.6756
I0523 07:28:03.209980 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6756 (* 1 = 8.6756 loss)
I0523 07:28:03.282140 34819 sgd_solver.cpp:112] Iteration 69640, lr = 0.01
I0523 07:28:09.830730 34819 solver.cpp:239] Iteration 69650 (1.51047 iter/s, 6.62047s/10 iters), loss = 8.54291
I0523 07:28:09.830771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54291 (* 1 = 8.54291 loss)
I0523 07:28:09.905561 34819 sgd_solver.cpp:112] Iteration 69650, lr = 0.01
I0523 07:28:15.654040 34819 solver.cpp:239] Iteration 69660 (1.71732 iter/s, 5.82303s/10 iters), loss = 7.53592
I0523 07:28:15.654274 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53592 (* 1 = 7.53592 loss)
I0523 07:28:15.723219 34819 sgd_solver.cpp:112] Iteration 69660, lr = 0.01
I0523 07:28:20.669371 34819 solver.cpp:239] Iteration 69670 (1.99501 iter/s, 5.0125s/10 iters), loss = 7.98062
I0523 07:28:20.669415 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98062 (* 1 = 7.98062 loss)
I0523 07:28:20.741837 34819 sgd_solver.cpp:112] Iteration 69670, lr = 0.01
I0523 07:28:26.056365 34819 solver.cpp:239] Iteration 69680 (1.85642 iter/s, 5.38672s/10 iters), loss = 8.83515
I0523 07:28:26.056414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83515 (* 1 = 8.83515 loss)
I0523 07:28:26.927556 34819 sgd_solver.cpp:112] Iteration 69680, lr = 0.01
I0523 07:28:31.006356 34819 solver.cpp:239] Iteration 69690 (2.02031 iter/s, 4.94974s/10 iters), loss = 8.20584
I0523 07:28:31.006405 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20584 (* 1 = 8.20584 loss)
I0523 07:28:31.820256 34819 sgd_solver.cpp:112] Iteration 69690, lr = 0.01
I0523 07:28:36.654978 34819 solver.cpp:239] Iteration 69700 (1.77044 iter/s, 5.64833s/10 iters), loss = 7.92452
I0523 07:28:36.655031 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92452 (* 1 = 7.92452 loss)
I0523 07:28:37.481839 34819 sgd_solver.cpp:112] Iteration 69700, lr = 0.01
I0523 07:28:40.009676 34819 solver.cpp:239] Iteration 69710 (2.98107 iter/s, 3.3545s/10 iters), loss = 8.49832
I0523 07:28:40.009718 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49832 (* 1 = 8.49832 loss)
I0523 07:28:40.837872 34819 sgd_solver.cpp:112] Iteration 69710, lr = 0.01
I0523 07:28:46.495558 34819 solver.cpp:239] Iteration 69720 (1.54189 iter/s, 6.48556s/10 iters), loss = 8.66314
I0523 07:28:46.495760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66314 (* 1 = 8.66314 loss)
I0523 07:28:47.213593 34819 sgd_solver.cpp:112] Iteration 69720, lr = 0.01
I0523 07:28:51.270400 34819 solver.cpp:239] Iteration 69730 (2.09448 iter/s, 4.77446s/10 iters), loss = 8.52833
I0523 07:28:51.270454 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52833 (* 1 = 8.52833 loss)
I0523 07:28:51.340009 34819 sgd_solver.cpp:112] Iteration 69730, lr = 0.01
I0523 07:28:55.313928 34819 solver.cpp:239] Iteration 69740 (2.47324 iter/s, 4.04328s/10 iters), loss = 7.48397
I0523 07:28:55.313983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.48397 (* 1 = 7.48397 loss)
I0523 07:28:55.377949 34819 sgd_solver.cpp:112] Iteration 69740, lr = 0.01
I0523 07:28:59.629539 34819 solver.cpp:239] Iteration 69750 (2.3173 iter/s, 4.31538s/10 iters), loss = 7.33029
I0523 07:28:59.629588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33029 (* 1 = 7.33029 loss)
I0523 07:29:00.366271 34819 sgd_solver.cpp:112] Iteration 69750, lr = 0.01
I0523 07:29:03.891997 34819 solver.cpp:239] Iteration 69760 (2.34619 iter/s, 4.26223s/10 iters), loss = 8.75564
I0523 07:29:03.892038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75564 (* 1 = 8.75564 loss)
I0523 07:29:03.965308 34819 sgd_solver.cpp:112] Iteration 69760, lr = 0.01
I0523 07:29:07.398744 34819 solver.cpp:239] Iteration 69770 (2.85183 iter/s, 3.50652s/10 iters), loss = 8.78049
I0523 07:29:07.398800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78049 (* 1 = 8.78049 loss)
I0523 07:29:08.238404 34819 sgd_solver.cpp:112] Iteration 69770, lr = 0.01
I0523 07:29:11.013839 34819 solver.cpp:239] Iteration 69780 (2.76634 iter/s, 3.61489s/10 iters), loss = 8.06184
I0523 07:29:11.013881 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06184 (* 1 = 8.06184 loss)
I0523 07:29:11.098148 34819 sgd_solver.cpp:112] Iteration 69780, lr = 0.01
I0523 07:29:15.731475 34819 solver.cpp:239] Iteration 69790 (2.11981 iter/s, 4.71739s/10 iters), loss = 8.44418
I0523 07:29:15.731519 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44418 (* 1 = 8.44418 loss)
I0523 07:29:16.485781 34819 sgd_solver.cpp:112] Iteration 69790, lr = 0.01
I0523 07:29:21.534845 34819 solver.cpp:239] Iteration 69800 (1.72322 iter/s, 5.80308s/10 iters), loss = 7.92651
I0523 07:29:21.535006 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92651 (* 1 = 7.92651 loss)
I0523 07:29:21.602123 34819 sgd_solver.cpp:112] Iteration 69800, lr = 0.01
I0523 07:29:27.156668 34819 solver.cpp:239] Iteration 69810 (1.77891 iter/s, 5.62141s/10 iters), loss = 7.23855
I0523 07:29:27.156728 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.23855 (* 1 = 7.23855 loss)
I0523 07:29:27.294857 34819 sgd_solver.cpp:112] Iteration 69810, lr = 0.01
I0523 07:29:32.295102 34819 solver.cpp:239] Iteration 69820 (1.94622 iter/s, 5.13815s/10 iters), loss = 8.24098
I0523 07:29:32.295152 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24098 (* 1 = 8.24098 loss)
I0523 07:29:33.122481 34819 sgd_solver.cpp:112] Iteration 69820, lr = 0.01
I0523 07:29:36.278852 34819 solver.cpp:239] Iteration 69830 (2.51034 iter/s, 3.98353s/10 iters), loss = 8.75755
I0523 07:29:36.278898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.75755 (* 1 = 8.75755 loss)
I0523 07:29:36.337278 34819 sgd_solver.cpp:112] Iteration 69830, lr = 0.01
I0523 07:29:39.658666 34819 solver.cpp:239] Iteration 69840 (2.95891 iter/s, 3.37962s/10 iters), loss = 7.52071
I0523 07:29:39.658740 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52071 (* 1 = 7.52071 loss)
I0523 07:29:39.706199 34819 sgd_solver.cpp:112] Iteration 69840, lr = 0.01
I0523 07:29:44.423053 34819 solver.cpp:239] Iteration 69850 (2.09903 iter/s, 4.76411s/10 iters), loss = 7.78597
I0523 07:29:44.423095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78597 (* 1 = 7.78597 loss)
I0523 07:29:44.498392 34819 sgd_solver.cpp:112] Iteration 69850, lr = 0.01
I0523 07:29:49.210160 34819 solver.cpp:239] Iteration 69860 (2.08905 iter/s, 4.78686s/10 iters), loss = 7.85408
I0523 07:29:49.210222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85408 (* 1 = 7.85408 loss)
I0523 07:29:50.002341 34819 sgd_solver.cpp:112] Iteration 69860, lr = 0.01
I0523 07:29:54.970341 34819 solver.cpp:239] Iteration 69870 (1.73615 iter/s, 5.75988s/10 iters), loss = 8.74516
I0523 07:29:54.970492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.74516 (* 1 = 8.74516 loss)
I0523 07:29:55.031386 34819 sgd_solver.cpp:112] Iteration 69870, lr = 0.01
I0523 07:29:59.922543 34819 solver.cpp:239] Iteration 69880 (2.01946 iter/s, 4.95182s/10 iters), loss = 8.53031
I0523 07:29:59.922617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53031 (* 1 = 8.53031 loss)
I0523 07:30:00.772217 34819 sgd_solver.cpp:112] Iteration 69880, lr = 0.01
I0523 07:30:06.516482 34819 solver.cpp:239] Iteration 69890 (1.51662 iter/s, 6.59359s/10 iters), loss = 7.82194
I0523 07:30:06.516522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82194 (* 1 = 7.82194 loss)
I0523 07:30:06.595809 34819 sgd_solver.cpp:112] Iteration 69890, lr = 0.01
I0523 07:30:11.176223 34819 solver.cpp:239] Iteration 69900 (2.14615 iter/s, 4.6595s/10 iters), loss = 7.38656
I0523 07:30:11.176265 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38656 (* 1 = 7.38656 loss)
I0523 07:30:11.234011 34819 sgd_solver.cpp:112] Iteration 69900, lr = 0.01
I0523 07:30:14.619350 34819 solver.cpp:239] Iteration 69910 (2.9045 iter/s, 3.44293s/10 iters), loss = 8.32418
I0523 07:30:14.619401 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32418 (* 1 = 8.32418 loss)
I0523 07:30:15.457113 34819 sgd_solver.cpp:112] Iteration 69910, lr = 0.01
I0523 07:30:20.394137 34819 solver.cpp:239] Iteration 69920 (1.73175 iter/s, 5.7745s/10 iters), loss = 7.9736
I0523 07:30:20.394184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9736 (* 1 = 7.9736 loss)
I0523 07:30:20.445960 34819 sgd_solver.cpp:112] Iteration 69920, lr = 0.01
I0523 07:30:26.160523 34819 solver.cpp:239] Iteration 69930 (1.73428 iter/s, 5.76609s/10 iters), loss = 7.92845
I0523 07:30:26.160727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92845 (* 1 = 7.92845 loss)
I0523 07:30:26.230191 34819 sgd_solver.cpp:112] Iteration 69930, lr = 0.01
I0523 07:30:28.612098 34819 solver.cpp:239] Iteration 69940 (4.07951 iter/s, 2.45127s/10 iters), loss = 8.47933
I0523 07:30:28.612150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47933 (* 1 = 8.47933 loss)
I0523 07:30:29.465898 34819 sgd_solver.cpp:112] Iteration 69940, lr = 0.01
I0523 07:30:34.977855 34819 solver.cpp:239] Iteration 69950 (1.57098 iter/s, 6.36544s/10 iters), loss = 7.59879
I0523 07:30:34.977910 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59879 (* 1 = 7.59879 loss)
I0523 07:30:35.709010 34819 sgd_solver.cpp:112] Iteration 69950, lr = 0.01
I0523 07:30:40.574787 34819 solver.cpp:239] Iteration 69960 (1.78678 iter/s, 5.59665s/10 iters), loss = 6.59343
I0523 07:30:40.574828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.59343 (* 1 = 6.59343 loss)
I0523 07:30:40.647385 34819 sgd_solver.cpp:112] Iteration 69960, lr = 0.01
I0523 07:30:45.236263 34819 solver.cpp:239] Iteration 69970 (2.14537 iter/s, 4.66119s/10 iters), loss = 8.06493
I0523 07:30:45.236318 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06493 (* 1 = 8.06493 loss)
I0523 07:30:45.321446 34819 sgd_solver.cpp:112] Iteration 69970, lr = 0.01
I0523 07:30:50.338672 34819 solver.cpp:239] Iteration 69980 (1.95997 iter/s, 5.10212s/10 iters), loss = 7.74885
I0523 07:30:50.338770 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74885 (* 1 = 7.74885 loss)
I0523 07:30:50.984549 34819 sgd_solver.cpp:112] Iteration 69980, lr = 0.01
I0523 07:30:55.152020 34819 solver.cpp:239] Iteration 69990 (2.0777 iter/s, 4.81302s/10 iters), loss = 8.63926
I0523 07:30:55.152084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63926 (* 1 = 8.63926 loss)
I0523 07:30:55.955796 34819 sgd_solver.cpp:112] Iteration 69990, lr = 0.01
I0523 07:30:59.017213 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_70000.caffemodel
I0523 07:31:11.113191 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_70000.solverstate
I0523 07:31:11.348537 34819 solver.cpp:239] Iteration 70000 (0.617443 iter/s, 16.1958s/10 iters), loss = 7.86843
I0523 07:31:11.348577 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86843 (* 1 = 7.86843 loss)
I0523 07:31:12.165661 34819 sgd_solver.cpp:112] Iteration 70000, lr = 0.01
I0523 07:31:16.530164 34819 solver.cpp:239] Iteration 70010 (1.93 iter/s, 5.18136s/10 iters), loss = 8.0174
I0523 07:31:16.530206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0174 (* 1 = 8.0174 loss)
I0523 07:31:17.325268 34819 sgd_solver.cpp:112] Iteration 70010, lr = 0.01
I0523 07:31:23.004334 34819 solver.cpp:239] Iteration 70020 (1.54467 iter/s, 6.47386s/10 iters), loss = 6.93902
I0523 07:31:23.004390 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.93902 (* 1 = 6.93902 loss)
I0523 07:31:23.080310 34819 sgd_solver.cpp:112] Iteration 70020, lr = 0.01
I0523 07:31:25.904302 34819 solver.cpp:239] Iteration 70030 (3.44853 iter/s, 2.89979s/10 iters), loss = 7.60001
I0523 07:31:25.904345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60001 (* 1 = 7.60001 loss)
I0523 07:31:25.972872 34819 sgd_solver.cpp:112] Iteration 70030, lr = 0.01
I0523 07:31:29.211514 34819 solver.cpp:239] Iteration 70040 (3.02387 iter/s, 3.30702s/10 iters), loss = 8.13517
I0523 07:31:29.211643 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13517 (* 1 = 8.13517 loss)
I0523 07:31:30.052117 34819 sgd_solver.cpp:112] Iteration 70040, lr = 0.01
I0523 07:31:35.386243 34819 solver.cpp:239] Iteration 70050 (1.61961 iter/s, 6.17434s/10 iters), loss = 6.98912
I0523 07:31:35.386312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.98912 (* 1 = 6.98912 loss)
I0523 07:31:36.159566 34819 sgd_solver.cpp:112] Iteration 70050, lr = 0.01
I0523 07:31:40.880043 34819 solver.cpp:239] Iteration 70060 (1.82033 iter/s, 5.49351s/10 iters), loss = 7.08968
I0523 07:31:40.880100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.08968 (* 1 = 7.08968 loss)
I0523 07:31:40.939677 34819 sgd_solver.cpp:112] Iteration 70060, lr = 0.01
I0523 07:31:44.361430 34819 solver.cpp:239] Iteration 70070 (2.8726 iter/s, 3.48117s/10 iters), loss = 9.22445
I0523 07:31:44.361496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.22445 (* 1 = 9.22445 loss)
I0523 07:31:45.192116 34819 sgd_solver.cpp:112] Iteration 70070, lr = 0.01
I0523 07:31:51.426625 34819 solver.cpp:239] Iteration 70080 (1.41546 iter/s, 7.06485s/10 iters), loss = 7.3399
I0523 07:31:51.426664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3399 (* 1 = 7.3399 loss)
I0523 07:31:52.286090 34819 sgd_solver.cpp:112] Iteration 70080, lr = 0.01
I0523 07:31:56.473246 34819 solver.cpp:239] Iteration 70090 (1.98163 iter/s, 5.04635s/10 iters), loss = 8.48067
I0523 07:31:56.473299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48067 (* 1 = 8.48067 loss)
I0523 07:31:56.535578 34819 sgd_solver.cpp:112] Iteration 70090, lr = 0.01
I0523 07:32:00.348695 34819 solver.cpp:239] Iteration 70100 (2.5805 iter/s, 3.87522s/10 iters), loss = 8.1571
I0523 07:32:00.348856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1571 (* 1 = 8.1571 loss)
I0523 07:32:00.431138 34819 sgd_solver.cpp:112] Iteration 70100, lr = 0.01
I0523 07:32:05.376646 34819 solver.cpp:239] Iteration 70110 (1.98904 iter/s, 5.02755s/10 iters), loss = 8.3973
I0523 07:32:05.376715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3973 (* 1 = 8.3973 loss)
I0523 07:32:06.129138 34819 sgd_solver.cpp:112] Iteration 70110, lr = 0.01
I0523 07:32:12.277546 34819 solver.cpp:239] Iteration 70120 (1.44916 iter/s, 6.90055s/10 iters), loss = 7.62864
I0523 07:32:12.277588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62864 (* 1 = 7.62864 loss)
I0523 07:32:12.357333 34819 sgd_solver.cpp:112] Iteration 70120, lr = 0.01
I0523 07:32:15.575249 34819 solver.cpp:239] Iteration 70130 (3.03259 iter/s, 3.29751s/10 iters), loss = 9.04541
I0523 07:32:15.575300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04541 (* 1 = 9.04541 loss)
I0523 07:32:16.426225 34819 sgd_solver.cpp:112] Iteration 70130, lr = 0.01
I0523 07:32:20.429327 34819 solver.cpp:239] Iteration 70140 (2.06023 iter/s, 4.85382s/10 iters), loss = 8.27506
I0523 07:32:20.429368 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27506 (* 1 = 8.27506 loss)
I0523 07:32:20.500710 34819 sgd_solver.cpp:112] Iteration 70140, lr = 0.01
I0523 07:32:23.300725 34819 solver.cpp:239] Iteration 70150 (3.48816 iter/s, 2.86684s/10 iters), loss = 6.87142
I0523 07:32:23.300766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.87142 (* 1 = 6.87142 loss)
I0523 07:32:24.108600 34819 sgd_solver.cpp:112] Iteration 70150, lr = 0.01
I0523 07:32:30.282131 34819 solver.cpp:239] Iteration 70160 (1.43244 iter/s, 6.98107s/10 iters), loss = 7.78032
I0523 07:32:30.282171 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78032 (* 1 = 7.78032 loss)
I0523 07:32:30.364419 34819 sgd_solver.cpp:112] Iteration 70160, lr = 0.01
I0523 07:32:35.841313 34819 solver.cpp:239] Iteration 70170 (1.79892 iter/s, 5.5589s/10 iters), loss = 8.03622
I0523 07:32:35.841353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03622 (* 1 = 8.03622 loss)
I0523 07:32:36.680009 34819 sgd_solver.cpp:112] Iteration 70170, lr = 0.01
I0523 07:32:41.728221 34819 solver.cpp:239] Iteration 70180 (1.69877 iter/s, 5.88662s/10 iters), loss = 7.8575
I0523 07:32:41.728263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8575 (* 1 = 7.8575 loss)
I0523 07:32:41.784440 34819 sgd_solver.cpp:112] Iteration 70180, lr = 0.01
I0523 07:32:46.538998 34819 solver.cpp:239] Iteration 70190 (2.07877 iter/s, 4.81053s/10 iters), loss = 6.92024
I0523 07:32:46.539038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.92024 (* 1 = 6.92024 loss)
I0523 07:32:46.611568 34819 sgd_solver.cpp:112] Iteration 70190, lr = 0.01
I0523 07:32:52.170006 34819 solver.cpp:239] Iteration 70200 (1.77597 iter/s, 5.63072s/10 iters), loss = 8.19519
I0523 07:32:52.170047 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19519 (* 1 = 8.19519 loss)
I0523 07:32:52.878738 34819 sgd_solver.cpp:112] Iteration 70200, lr = 0.01
I0523 07:32:57.896543 34819 solver.cpp:239] Iteration 70210 (1.74635 iter/s, 5.72624s/10 iters), loss = 7.96282
I0523 07:32:57.896597 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96282 (* 1 = 7.96282 loss)
I0523 07:32:58.623860 34819 sgd_solver.cpp:112] Iteration 70210, lr = 0.01
I0523 07:33:02.206841 34819 solver.cpp:239] Iteration 70220 (2.32016 iter/s, 4.31005s/10 iters), loss = 9.01032
I0523 07:33:02.207072 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01032 (* 1 = 9.01032 loss)
I0523 07:33:02.973462 34819 sgd_solver.cpp:112] Iteration 70220, lr = 0.01
I0523 07:33:06.400360 34819 solver.cpp:239] Iteration 70230 (2.38485 iter/s, 4.19313s/10 iters), loss = 7.61115
I0523 07:33:06.400418 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61115 (* 1 = 7.61115 loss)
I0523 07:33:06.471814 34819 sgd_solver.cpp:112] Iteration 70230, lr = 0.01
I0523 07:33:11.525085 34819 solver.cpp:239] Iteration 70240 (1.95143 iter/s, 5.12446s/10 iters), loss = 8.84629
I0523 07:33:11.525135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84629 (* 1 = 8.84629 loss)
I0523 07:33:11.598234 34819 sgd_solver.cpp:112] Iteration 70240, lr = 0.01
I0523 07:33:15.233628 34819 solver.cpp:239] Iteration 70250 (2.69664 iter/s, 3.70832s/10 iters), loss = 7.42137
I0523 07:33:15.233678 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42137 (* 1 = 7.42137 loss)
I0523 07:33:16.065063 34819 sgd_solver.cpp:112] Iteration 70250, lr = 0.01
I0523 07:33:20.154583 34819 solver.cpp:239] Iteration 70260 (2.03223 iter/s, 4.9207s/10 iters), loss = 8.39681
I0523 07:33:20.154639 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39681 (* 1 = 8.39681 loss)
I0523 07:33:20.234903 34819 sgd_solver.cpp:112] Iteration 70260, lr = 0.01
I0523 07:33:26.014308 34819 solver.cpp:239] Iteration 70270 (1.70665 iter/s, 5.85943s/10 iters), loss = 8.12796
I0523 07:33:26.014351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12796 (* 1 = 8.12796 loss)
I0523 07:33:26.085657 34819 sgd_solver.cpp:112] Iteration 70270, lr = 0.01
I0523 07:33:32.349825 34819 solver.cpp:239] Iteration 70280 (1.57848 iter/s, 6.33522s/10 iters), loss = 7.90856
I0523 07:33:32.350039 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90856 (* 1 = 7.90856 loss)
I0523 07:33:33.187469 34819 sgd_solver.cpp:112] Iteration 70280, lr = 0.01
I0523 07:33:37.137524 34819 solver.cpp:239] Iteration 70290 (2.08887 iter/s, 4.78727s/10 iters), loss = 8.39695
I0523 07:33:37.137583 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39695 (* 1 = 8.39695 loss)
I0523 07:33:37.976131 34819 sgd_solver.cpp:112] Iteration 70290, lr = 0.01
I0523 07:33:41.931908 34819 solver.cpp:239] Iteration 70300 (2.08589 iter/s, 4.79412s/10 iters), loss = 7.60283
I0523 07:33:41.931949 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60283 (* 1 = 7.60283 loss)
I0523 07:33:42.079468 34819 sgd_solver.cpp:112] Iteration 70300, lr = 0.01
I0523 07:33:48.089980 34819 solver.cpp:239] Iteration 70310 (1.62396 iter/s, 6.15778s/10 iters), loss = 7.88647
I0523 07:33:48.090021 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88647 (* 1 = 7.88647 loss)
I0523 07:33:48.166800 34819 sgd_solver.cpp:112] Iteration 70310, lr = 0.01
I0523 07:33:51.900972 34819 solver.cpp:239] Iteration 70320 (2.62414 iter/s, 3.81078s/10 iters), loss = 7.605
I0523 07:33:51.901015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.605 (* 1 = 7.605 loss)
I0523 07:33:52.239357 34819 sgd_solver.cpp:112] Iteration 70320, lr = 0.01
I0523 07:33:54.839534 34819 solver.cpp:239] Iteration 70330 (3.40323 iter/s, 2.93838s/10 iters), loss = 7.42773
I0523 07:33:54.839591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42773 (* 1 = 7.42773 loss)
I0523 07:33:55.423455 34819 sgd_solver.cpp:112] Iteration 70330, lr = 0.01
I0523 07:33:58.787989 34819 solver.cpp:239] Iteration 70340 (2.53278 iter/s, 3.94822s/10 iters), loss = 7.94951
I0523 07:33:58.788039 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94951 (* 1 = 7.94951 loss)
I0523 07:33:58.857424 34819 sgd_solver.cpp:112] Iteration 70340, lr = 0.01
I0523 07:34:01.651211 34819 solver.cpp:239] Iteration 70350 (3.49278 iter/s, 2.86305s/10 iters), loss = 7.4272
I0523 07:34:01.651255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4272 (* 1 = 7.4272 loss)
I0523 07:34:01.707720 34819 sgd_solver.cpp:112] Iteration 70350, lr = 0.01
I0523 07:34:07.735615 34819 solver.cpp:239] Iteration 70360 (1.64363 iter/s, 6.08411s/10 iters), loss = 8.80123
I0523 07:34:07.735780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80123 (* 1 = 8.80123 loss)
I0523 07:34:08.605859 34819 sgd_solver.cpp:112] Iteration 70360, lr = 0.01
I0523 07:34:11.306733 34819 solver.cpp:239] Iteration 70370 (2.80054 iter/s, 3.57074s/10 iters), loss = 7.07084
I0523 07:34:11.306797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.07084 (* 1 = 7.07084 loss)
I0523 07:34:12.138592 34819 sgd_solver.cpp:112] Iteration 70370, lr = 0.01
I0523 07:34:18.615442 34819 solver.cpp:239] Iteration 70380 (1.3683 iter/s, 7.30835s/10 iters), loss = 7.90613
I0523 07:34:18.615489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90613 (* 1 = 7.90613 loss)
I0523 07:34:19.414804 34819 sgd_solver.cpp:112] Iteration 70380, lr = 0.01
I0523 07:34:24.118656 34819 solver.cpp:239] Iteration 70390 (1.81721 iter/s, 5.50295s/10 iters), loss = 7.4639
I0523 07:34:24.118722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4639 (* 1 = 7.4639 loss)
I0523 07:34:24.933287 34819 sgd_solver.cpp:112] Iteration 70390, lr = 0.01
I0523 07:34:29.730293 34819 solver.cpp:239] Iteration 70400 (1.7821 iter/s, 5.61135s/10 iters), loss = 8.06603
I0523 07:34:29.730338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06603 (* 1 = 8.06603 loss)
I0523 07:34:29.797468 34819 sgd_solver.cpp:112] Iteration 70400, lr = 0.01
I0523 07:34:34.777817 34819 solver.cpp:239] Iteration 70410 (1.98127 iter/s, 5.04726s/10 iters), loss = 9.04265
I0523 07:34:34.777859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.04265 (* 1 = 9.04265 loss)
I0523 07:34:34.850836 34819 sgd_solver.cpp:112] Iteration 70410, lr = 0.01
I0523 07:34:39.573158 34819 solver.cpp:239] Iteration 70420 (2.08547 iter/s, 4.79508s/10 iters), loss = 7.16893
I0523 07:34:39.573352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.16893 (* 1 = 7.16893 loss)
I0523 07:34:39.642325 34819 sgd_solver.cpp:112] Iteration 70420, lr = 0.01
I0523 07:34:42.855531 34819 solver.cpp:239] Iteration 70430 (3.04686 iter/s, 3.28206s/10 iters), loss = 7.90644
I0523 07:34:42.855572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90644 (* 1 = 7.90644 loss)
I0523 07:34:43.631021 34819 sgd_solver.cpp:112] Iteration 70430, lr = 0.01
I0523 07:34:50.008713 34819 solver.cpp:239] Iteration 70440 (1.39805 iter/s, 7.15284s/10 iters), loss = 8.1205
I0523 07:34:50.008775 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1205 (* 1 = 8.1205 loss)
I0523 07:34:50.810797 34819 sgd_solver.cpp:112] Iteration 70440, lr = 0.01
I0523 07:34:54.355629 34819 solver.cpp:239] Iteration 70450 (2.30061 iter/s, 4.34667s/10 iters), loss = 8.51939
I0523 07:34:54.355675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51939 (* 1 = 8.51939 loss)
I0523 07:34:55.092934 34819 sgd_solver.cpp:112] Iteration 70450, lr = 0.01
I0523 07:34:59.867425 34819 solver.cpp:239] Iteration 70460 (1.81439 iter/s, 5.51151s/10 iters), loss = 7.22298
I0523 07:34:59.867476 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22298 (* 1 = 7.22298 loss)
I0523 07:35:00.703330 34819 sgd_solver.cpp:112] Iteration 70460, lr = 0.01
I0523 07:35:05.983247 34819 solver.cpp:239] Iteration 70470 (1.63518 iter/s, 6.11552s/10 iters), loss = 8.34908
I0523 07:35:05.983299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34908 (* 1 = 8.34908 loss)
I0523 07:35:06.813074 34819 sgd_solver.cpp:112] Iteration 70470, lr = 0.01
I0523 07:35:08.699316 34819 solver.cpp:239] Iteration 70480 (3.68204 iter/s, 2.71588s/10 iters), loss = 7.60254
I0523 07:35:08.699370 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60254 (* 1 = 7.60254 loss)
I0523 07:35:09.066290 34819 sgd_solver.cpp:112] Iteration 70480, lr = 0.01
I0523 07:35:13.038864 34819 solver.cpp:239] Iteration 70490 (2.30451 iter/s, 4.33931s/10 iters), loss = 8.22321
I0523 07:35:13.039039 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22321 (* 1 = 8.22321 loss)
I0523 07:35:13.270978 34819 sgd_solver.cpp:112] Iteration 70490, lr = 0.01
I0523 07:35:18.100271 34819 solver.cpp:239] Iteration 70500 (1.97589 iter/s, 5.06101s/10 iters), loss = 7.80748
I0523 07:35:18.100330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80748 (* 1 = 7.80748 loss)
I0523 07:35:18.168828 34819 sgd_solver.cpp:112] Iteration 70500, lr = 0.01
I0523 07:35:22.231050 34819 solver.cpp:239] Iteration 70510 (2.42099 iter/s, 4.13055s/10 iters), loss = 7.32666
I0523 07:35:22.231106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.32666 (* 1 = 7.32666 loss)
I0523 07:35:23.025939 34819 sgd_solver.cpp:112] Iteration 70510, lr = 0.01
I0523 07:35:27.915124 34819 solver.cpp:239] Iteration 70520 (1.75939 iter/s, 5.68378s/10 iters), loss = 8.01375
I0523 07:35:27.915180 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01375 (* 1 = 8.01375 loss)
I0523 07:35:27.984907 34819 sgd_solver.cpp:112] Iteration 70520, lr = 0.01
I0523 07:35:31.874004 34819 solver.cpp:239] Iteration 70530 (2.52612 iter/s, 3.95864s/10 iters), loss = 7.35133
I0523 07:35:31.874065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35133 (* 1 = 7.35133 loss)
I0523 07:35:32.507148 34819 sgd_solver.cpp:112] Iteration 70530, lr = 0.01
I0523 07:35:35.480631 34819 solver.cpp:239] Iteration 70540 (2.77286 iter/s, 3.60639s/10 iters), loss = 7.73393
I0523 07:35:35.480690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73393 (* 1 = 7.73393 loss)
I0523 07:35:36.350877 34819 sgd_solver.cpp:112] Iteration 70540, lr = 0.01
I0523 07:35:39.240278 34819 solver.cpp:239] Iteration 70550 (2.65998 iter/s, 3.75943s/10 iters), loss = 8.77406
I0523 07:35:39.240321 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.77406 (* 1 = 8.77406 loss)
I0523 07:35:40.092403 34819 sgd_solver.cpp:112] Iteration 70550, lr = 0.01
I0523 07:35:42.854898 34819 solver.cpp:239] Iteration 70560 (2.7667 iter/s, 3.61442s/10 iters), loss = 8.08512
I0523 07:35:42.854955 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08512 (* 1 = 8.08512 loss)
I0523 07:35:42.915127 34819 sgd_solver.cpp:112] Iteration 70560, lr = 0.01
I0523 07:35:47.804272 34819 solver.cpp:239] Iteration 70570 (2.02057 iter/s, 4.94911s/10 iters), loss = 8.11352
I0523 07:35:47.804540 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11352 (* 1 = 8.11352 loss)
I0523 07:35:48.125653 34819 sgd_solver.cpp:112] Iteration 70570, lr = 0.01
I0523 07:35:51.217039 34819 solver.cpp:239] Iteration 70580 (2.93051 iter/s, 3.41237s/10 iters), loss = 8.44728
I0523 07:35:51.217109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44728 (* 1 = 8.44728 loss)
I0523 07:35:51.275779 34819 sgd_solver.cpp:112] Iteration 70580, lr = 0.01
I0523 07:35:55.619110 34819 solver.cpp:239] Iteration 70590 (2.27179 iter/s, 4.40181s/10 iters), loss = 7.27573
I0523 07:35:55.619160 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.27573 (* 1 = 7.27573 loss)
I0523 07:35:55.689764 34819 sgd_solver.cpp:112] Iteration 70590, lr = 0.01
I0523 07:35:59.070122 34819 solver.cpp:239] Iteration 70600 (2.89788 iter/s, 3.4508s/10 iters), loss = 8.07354
I0523 07:35:59.070184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07354 (* 1 = 8.07354 loss)
I0523 07:35:59.916936 34819 sgd_solver.cpp:112] Iteration 70600, lr = 0.01
I0523 07:36:03.721277 34819 solver.cpp:239] Iteration 70610 (2.15012 iter/s, 4.65089s/10 iters), loss = 7.22665
I0523 07:36:03.721334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22665 (* 1 = 7.22665 loss)
I0523 07:36:04.440945 34819 sgd_solver.cpp:112] Iteration 70610, lr = 0.01
I0523 07:36:08.440135 34819 solver.cpp:239] Iteration 70620 (2.11927 iter/s, 4.71861s/10 iters), loss = 8.86584
I0523 07:36:08.440179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.86584 (* 1 = 8.86584 loss)
I0523 07:36:08.490392 34819 sgd_solver.cpp:112] Iteration 70620, lr = 0.01
I0523 07:36:11.751746 34819 solver.cpp:239] Iteration 70630 (3.01985 iter/s, 3.31142s/10 iters), loss = 8.28635
I0523 07:36:11.751788 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28635 (* 1 = 8.28635 loss)
I0523 07:36:11.813596 34819 sgd_solver.cpp:112] Iteration 70630, lr = 0.01
I0523 07:36:14.741864 34819 solver.cpp:239] Iteration 70640 (3.34454 iter/s, 2.98995s/10 iters), loss = 8.34249
I0523 07:36:14.741905 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34249 (* 1 = 8.34249 loss)
I0523 07:36:14.809566 34819 sgd_solver.cpp:112] Iteration 70640, lr = 0.01
I0523 07:36:20.140190 34819 solver.cpp:239] Iteration 70650 (1.85253 iter/s, 5.39804s/10 iters), loss = 7.95975
I0523 07:36:20.140446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95975 (* 1 = 7.95975 loss)
I0523 07:36:20.844955 34819 sgd_solver.cpp:112] Iteration 70650, lr = 0.01
I0523 07:36:25.092087 34819 solver.cpp:239] Iteration 70660 (2.01961 iter/s, 4.95145s/10 iters), loss = 7.09277
I0523 07:36:25.092136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.09277 (* 1 = 7.09277 loss)
I0523 07:36:25.165482 34819 sgd_solver.cpp:112] Iteration 70660, lr = 0.01
I0523 07:36:28.455514 34819 solver.cpp:239] Iteration 70670 (2.97668 iter/s, 3.35944s/10 iters), loss = 7.27449
I0523 07:36:28.455555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.27449 (* 1 = 7.27449 loss)
I0523 07:36:28.525735 34819 sgd_solver.cpp:112] Iteration 70670, lr = 0.01
I0523 07:36:33.970850 34819 solver.cpp:239] Iteration 70680 (1.81322 iter/s, 5.51506s/10 iters), loss = 8.24235
I0523 07:36:33.970886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24235 (* 1 = 8.24235 loss)
I0523 07:36:34.030294 34819 sgd_solver.cpp:112] Iteration 70680, lr = 0.01
I0523 07:36:39.027390 34819 solver.cpp:239] Iteration 70690 (1.97774 iter/s, 5.05627s/10 iters), loss = 7.22986
I0523 07:36:39.027446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22986 (* 1 = 7.22986 loss)
I0523 07:36:39.077944 34819 sgd_solver.cpp:112] Iteration 70690, lr = 0.01
I0523 07:36:44.040294 34819 solver.cpp:239] Iteration 70700 (1.99496 iter/s, 5.01264s/10 iters), loss = 8.11624
I0523 07:36:44.040347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11624 (* 1 = 8.11624 loss)
I0523 07:36:44.100590 34819 sgd_solver.cpp:112] Iteration 70700, lr = 0.01
I0523 07:36:47.315831 34819 solver.cpp:239] Iteration 70710 (3.05313 iter/s, 3.27533s/10 iters), loss = 7.41811
I0523 07:36:47.315892 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41811 (* 1 = 7.41811 loss)
I0523 07:36:47.377285 34819 sgd_solver.cpp:112] Iteration 70710, lr = 0.01
I0523 07:36:51.451572 34819 solver.cpp:239] Iteration 70720 (2.41808 iter/s, 4.13551s/10 iters), loss = 8.26982
I0523 07:36:51.451695 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26982 (* 1 = 8.26982 loss)
I0523 07:36:51.527424 34819 sgd_solver.cpp:112] Iteration 70720, lr = 0.01
I0523 07:36:54.502691 34819 solver.cpp:239] Iteration 70730 (3.27776 iter/s, 3.05086s/10 iters), loss = 8.40961
I0523 07:36:54.502750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40961 (* 1 = 8.40961 loss)
I0523 07:36:55.239591 34819 sgd_solver.cpp:112] Iteration 70730, lr = 0.01
I0523 07:36:59.768833 34819 solver.cpp:239] Iteration 70740 (1.89903 iter/s, 5.26586s/10 iters), loss = 7.21123
I0523 07:36:59.768877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.21123 (* 1 = 7.21123 loss)
I0523 07:36:59.842583 34819 sgd_solver.cpp:112] Iteration 70740, lr = 0.01
I0523 07:37:06.139701 34819 solver.cpp:239] Iteration 70750 (1.56972 iter/s, 6.37056s/10 iters), loss = 7.98452
I0523 07:37:06.139741 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98452 (* 1 = 7.98452 loss)
I0523 07:37:06.204167 34819 sgd_solver.cpp:112] Iteration 70750, lr = 0.01
I0523 07:37:10.753010 34819 solver.cpp:239] Iteration 70760 (2.16776 iter/s, 4.61307s/10 iters), loss = 9.26134
I0523 07:37:10.753052 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.26134 (* 1 = 9.26134 loss)
I0523 07:37:11.619211 34819 sgd_solver.cpp:112] Iteration 70760, lr = 0.01
I0523 07:37:18.066754 34819 solver.cpp:239] Iteration 70770 (1.36735 iter/s, 7.31339s/10 iters), loss = 8.02983
I0523 07:37:18.066817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02983 (* 1 = 8.02983 loss)
I0523 07:37:18.142249 34819 sgd_solver.cpp:112] Iteration 70770, lr = 0.01
I0523 07:37:24.707540 34819 solver.cpp:239] Iteration 70780 (1.50592 iter/s, 6.64045s/10 iters), loss = 8.05278
I0523 07:37:24.707720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05278 (* 1 = 8.05278 loss)
I0523 07:37:24.759882 34819 sgd_solver.cpp:112] Iteration 70780, lr = 0.01
I0523 07:37:29.844354 34819 solver.cpp:239] Iteration 70790 (1.94688 iter/s, 5.13643s/10 iters), loss = 7.30745
I0523 07:37:29.844396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.30745 (* 1 = 7.30745 loss)
I0523 07:37:30.159942 34819 sgd_solver.cpp:112] Iteration 70790, lr = 0.01
I0523 07:37:36.087656 34819 solver.cpp:239] Iteration 70800 (1.60179 iter/s, 6.243s/10 iters), loss = 8.50079
I0523 07:37:36.087713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50079 (* 1 = 8.50079 loss)
I0523 07:37:36.905555 34819 sgd_solver.cpp:112] Iteration 70800, lr = 0.01
I0523 07:37:42.853804 34819 solver.cpp:239] Iteration 70810 (1.47802 iter/s, 6.76579s/10 iters), loss = 7.29
I0523 07:37:42.853854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29 (* 1 = 7.29 loss)
I0523 07:37:42.911691 34819 sgd_solver.cpp:112] Iteration 70810, lr = 0.01
I0523 07:37:47.425056 34819 solver.cpp:239] Iteration 70820 (2.18771 iter/s, 4.571s/10 iters), loss = 8.43656
I0523 07:37:47.425108 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43656 (* 1 = 8.43656 loss)
I0523 07:37:47.479617 34819 sgd_solver.cpp:112] Iteration 70820, lr = 0.01
I0523 07:37:52.195796 34819 solver.cpp:239] Iteration 70830 (2.09623 iter/s, 4.77048s/10 iters), loss = 8.28175
I0523 07:37:52.195842 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28175 (* 1 = 8.28175 loss)
I0523 07:37:52.876312 34819 sgd_solver.cpp:112] Iteration 70830, lr = 0.01
I0523 07:37:57.892885 34819 solver.cpp:239] Iteration 70840 (1.75537 iter/s, 5.69679s/10 iters), loss = 7.91166
I0523 07:37:57.893025 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91166 (* 1 = 7.91166 loss)
I0523 07:37:58.614394 34819 sgd_solver.cpp:112] Iteration 70840, lr = 0.01
I0523 07:38:03.347159 34819 solver.cpp:239] Iteration 70850 (1.83355 iter/s, 5.45391s/10 iters), loss = 7.2613
I0523 07:38:03.347200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2613 (* 1 = 7.2613 loss)
I0523 07:38:03.423142 34819 sgd_solver.cpp:112] Iteration 70850, lr = 0.01
I0523 07:38:07.286351 34819 solver.cpp:239] Iteration 70860 (2.53873 iter/s, 3.93898s/10 iters), loss = 7.88539
I0523 07:38:07.286413 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88539 (* 1 = 7.88539 loss)
I0523 07:38:07.348027 34819 sgd_solver.cpp:112] Iteration 70860, lr = 0.01
I0523 07:38:11.197240 34819 solver.cpp:239] Iteration 70870 (2.55711 iter/s, 3.91066s/10 iters), loss = 7.89397
I0523 07:38:11.197291 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89397 (* 1 = 7.89397 loss)
I0523 07:38:11.263308 34819 sgd_solver.cpp:112] Iteration 70870, lr = 0.01
I0523 07:38:15.937572 34819 solver.cpp:239] Iteration 70880 (2.10967 iter/s, 4.74009s/10 iters), loss = 8.26622
I0523 07:38:15.937613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26622 (* 1 = 8.26622 loss)
I0523 07:38:16.004436 34819 sgd_solver.cpp:112] Iteration 70880, lr = 0.01
I0523 07:38:19.441829 34819 solver.cpp:239] Iteration 70890 (2.85384 iter/s, 3.50405s/10 iters), loss = 8.22157
I0523 07:38:19.441885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22157 (* 1 = 8.22157 loss)
I0523 07:38:19.516561 34819 sgd_solver.cpp:112] Iteration 70890, lr = 0.01
I0523 07:38:24.305076 34819 solver.cpp:239] Iteration 70900 (2.05635 iter/s, 4.86299s/10 iters), loss = 8.41351
I0523 07:38:24.305130 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41351 (* 1 = 8.41351 loss)
I0523 07:38:25.126514 34819 sgd_solver.cpp:112] Iteration 70900, lr = 0.01
I0523 07:38:30.008844 34819 solver.cpp:239] Iteration 70910 (1.75332 iter/s, 5.70347s/10 iters), loss = 8.96708
I0523 07:38:30.009011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.96708 (* 1 = 8.96708 loss)
I0523 07:38:30.838335 34819 sgd_solver.cpp:112] Iteration 70910, lr = 0.01
I0523 07:38:37.019399 34819 solver.cpp:239] Iteration 70920 (1.42651 iter/s, 7.01011s/10 iters), loss = 8.16257
I0523 07:38:37.019448 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16257 (* 1 = 8.16257 loss)
I0523 07:38:37.089834 34819 sgd_solver.cpp:112] Iteration 70920, lr = 0.01
I0523 07:38:44.020797 34819 solver.cpp:239] Iteration 70930 (1.42836 iter/s, 7.00104s/10 iters), loss = 7.21518
I0523 07:38:44.020844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.21518 (* 1 = 7.21518 loss)
I0523 07:38:44.746920 34819 sgd_solver.cpp:112] Iteration 70930, lr = 0.01
I0523 07:38:50.363706 34819 solver.cpp:239] Iteration 70940 (1.57664 iter/s, 6.3426s/10 iters), loss = 8.21062
I0523 07:38:50.363749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21062 (* 1 = 8.21062 loss)
I0523 07:38:50.445049 34819 sgd_solver.cpp:112] Iteration 70940, lr = 0.01
I0523 07:38:53.603915 34819 solver.cpp:239] Iteration 70950 (3.0864 iter/s, 3.24002s/10 iters), loss = 7.65633
I0523 07:38:53.603965 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65633 (* 1 = 7.65633 loss)
I0523 07:38:54.454460 34819 sgd_solver.cpp:112] Iteration 70950, lr = 0.01
I0523 07:38:57.638269 34819 solver.cpp:239] Iteration 70960 (2.47885 iter/s, 4.03413s/10 iters), loss = 7.19157
I0523 07:38:57.638319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.19157 (* 1 = 7.19157 loss)
I0523 07:38:58.412451 34819 sgd_solver.cpp:112] Iteration 70960, lr = 0.01
I0523 07:39:02.524969 34819 solver.cpp:239] Iteration 70970 (2.04648 iter/s, 4.88644s/10 iters), loss = 7.92736
I0523 07:39:02.525099 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92736 (* 1 = 7.92736 loss)
I0523 07:39:02.581828 34819 sgd_solver.cpp:112] Iteration 70970, lr = 0.01
I0523 07:39:08.145753 34819 solver.cpp:239] Iteration 70980 (1.77922 iter/s, 5.62043s/10 iters), loss = 8.37724
I0523 07:39:08.145793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37724 (* 1 = 8.37724 loss)
I0523 07:39:08.212801 34819 sgd_solver.cpp:112] Iteration 70980, lr = 0.01
I0523 07:39:11.941447 34819 solver.cpp:239] Iteration 70990 (2.63471 iter/s, 3.79548s/10 iters), loss = 8.24353
I0523 07:39:11.941490 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24353 (* 1 = 8.24353 loss)
I0523 07:39:12.810366 34819 sgd_solver.cpp:112] Iteration 70990, lr = 0.01
I0523 07:39:15.154626 34819 solver.cpp:239] Iteration 71000 (3.11236 iter/s, 3.213s/10 iters), loss = 7.50417
I0523 07:39:15.154670 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50417 (* 1 = 7.50417 loss)
I0523 07:39:15.985065 34819 sgd_solver.cpp:112] Iteration 71000, lr = 0.01
I0523 07:39:20.778288 34819 solver.cpp:239] Iteration 71010 (1.77829 iter/s, 5.62338s/10 iters), loss = 7.39023
I0523 07:39:20.778343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39023 (* 1 = 7.39023 loss)
I0523 07:39:20.838438 34819 sgd_solver.cpp:112] Iteration 71010, lr = 0.01
I0523 07:39:25.424727 34819 solver.cpp:239] Iteration 71020 (2.1523 iter/s, 4.64619s/10 iters), loss = 8.4175
I0523 07:39:25.424772 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4175 (* 1 = 8.4175 loss)
I0523 07:39:25.496515 34819 sgd_solver.cpp:112] Iteration 71020, lr = 0.01
I0523 07:39:30.685520 34819 solver.cpp:239] Iteration 71030 (1.90095 iter/s, 5.26053s/10 iters), loss = 8.27637
I0523 07:39:30.685580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27637 (* 1 = 8.27637 loss)
I0523 07:39:30.758111 34819 sgd_solver.cpp:112] Iteration 71030, lr = 0.01
I0523 07:39:34.007688 34819 solver.cpp:239] Iteration 71040 (3.01026 iter/s, 3.32197s/10 iters), loss = 7.94031
I0523 07:39:34.007812 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94031 (* 1 = 7.94031 loss)
I0523 07:39:34.089787 34819 sgd_solver.cpp:112] Iteration 71040, lr = 0.01
I0523 07:39:40.299826 34819 solver.cpp:239] Iteration 71050 (1.58938 iter/s, 6.29176s/10 iters), loss = 7.4162
I0523 07:39:40.299882 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4162 (* 1 = 7.4162 loss)
I0523 07:39:40.366399 34819 sgd_solver.cpp:112] Iteration 71050, lr = 0.01
I0523 07:39:43.386783 34819 solver.cpp:239] Iteration 71060 (3.23964 iter/s, 3.08677s/10 iters), loss = 7.87339
I0523 07:39:43.386831 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87339 (* 1 = 7.87339 loss)
I0523 07:39:43.453740 34819 sgd_solver.cpp:112] Iteration 71060, lr = 0.01
I0523 07:39:47.880563 34819 solver.cpp:239] Iteration 71070 (2.22541 iter/s, 4.49354s/10 iters), loss = 7.02742
I0523 07:39:47.880606 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.02742 (* 1 = 7.02742 loss)
I0523 07:39:47.936347 34819 sgd_solver.cpp:112] Iteration 71070, lr = 0.01
I0523 07:39:53.583534 34819 solver.cpp:239] Iteration 71080 (1.75356 iter/s, 5.70268s/10 iters), loss = 8.13813
I0523 07:39:53.583588 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13813 (* 1 = 8.13813 loss)
I0523 07:39:54.458916 34819 sgd_solver.cpp:112] Iteration 71080, lr = 0.01
I0523 07:39:58.638236 34819 solver.cpp:239] Iteration 71090 (1.97846 iter/s, 5.05443s/10 iters), loss = 7.79022
I0523 07:39:58.638288 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79022 (* 1 = 7.79022 loss)
I0523 07:39:58.723767 34819 sgd_solver.cpp:112] Iteration 71090, lr = 0.01
I0523 07:40:02.129423 34819 solver.cpp:239] Iteration 71100 (2.86453 iter/s, 3.49098s/10 iters), loss = 7.88524
I0523 07:40:02.129465 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88524 (* 1 = 7.88524 loss)
I0523 07:40:02.211393 34819 sgd_solver.cpp:112] Iteration 71100, lr = 0.01
I0523 07:40:07.158318 34819 solver.cpp:239] Iteration 71110 (1.98861 iter/s, 5.02863s/10 iters), loss = 7.04495
I0523 07:40:07.158432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.04495 (* 1 = 7.04495 loss)
I0523 07:40:07.206987 34819 sgd_solver.cpp:112] Iteration 71110, lr = 0.01
I0523 07:40:10.103745 34819 solver.cpp:239] Iteration 71120 (3.3954 iter/s, 2.94516s/10 iters), loss = 8.51363
I0523 07:40:10.103813 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51363 (* 1 = 8.51363 loss)
I0523 07:40:10.846879 34819 sgd_solver.cpp:112] Iteration 71120, lr = 0.01
I0523 07:40:13.780086 34819 solver.cpp:239] Iteration 71130 (2.72027 iter/s, 3.67611s/10 iters), loss = 8.30376
I0523 07:40:13.780139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30376 (* 1 = 8.30376 loss)
I0523 07:40:13.862740 34819 sgd_solver.cpp:112] Iteration 71130, lr = 0.01
I0523 07:40:17.644592 34819 solver.cpp:239] Iteration 71140 (2.58781 iter/s, 3.86428s/10 iters), loss = 8.11356
I0523 07:40:17.644644 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11356 (* 1 = 8.11356 loss)
I0523 07:40:18.433605 34819 sgd_solver.cpp:112] Iteration 71140, lr = 0.01
I0523 07:40:21.974764 34819 solver.cpp:239] Iteration 71150 (2.3095 iter/s, 4.32994s/10 iters), loss = 7.22938
I0523 07:40:21.974817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22938 (* 1 = 7.22938 loss)
I0523 07:40:22.817065 34819 sgd_solver.cpp:112] Iteration 71150, lr = 0.01
I0523 07:40:28.506940 34819 solver.cpp:239] Iteration 71160 (1.53096 iter/s, 6.53185s/10 iters), loss = 7.83025
I0523 07:40:28.506994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83025 (* 1 = 7.83025 loss)
I0523 07:40:29.319269 34819 sgd_solver.cpp:112] Iteration 71160, lr = 0.01
I0523 07:40:35.498870 34819 solver.cpp:239] Iteration 71170 (1.4303 iter/s, 6.99156s/10 iters), loss = 7.51954
I0523 07:40:35.498926 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51954 (* 1 = 7.51954 loss)
I0523 07:40:36.381758 34819 sgd_solver.cpp:112] Iteration 71170, lr = 0.01
I0523 07:40:40.482661 34819 solver.cpp:239] Iteration 71180 (2.00661 iter/s, 4.98353s/10 iters), loss = 8.02248
I0523 07:40:40.482836 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02248 (* 1 = 8.02248 loss)
I0523 07:40:40.542203 34819 sgd_solver.cpp:112] Iteration 71180, lr = 0.01
I0523 07:40:44.486605 34819 solver.cpp:239] Iteration 71190 (2.49775 iter/s, 4.0036s/10 iters), loss = 7.29968
I0523 07:40:44.486657 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29968 (* 1 = 7.29968 loss)
I0523 07:40:44.571863 34819 sgd_solver.cpp:112] Iteration 71190, lr = 0.01
I0523 07:40:48.567092 34819 solver.cpp:239] Iteration 71200 (2.45083 iter/s, 4.08025s/10 iters), loss = 7.23605
I0523 07:40:48.567139 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.23605 (* 1 = 7.23605 loss)
I0523 07:40:48.622429 34819 sgd_solver.cpp:112] Iteration 71200, lr = 0.01
I0523 07:40:51.870316 34819 solver.cpp:239] Iteration 71210 (3.02753 iter/s, 3.30302s/10 iters), loss = 8.29133
I0523 07:40:51.870359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29133 (* 1 = 8.29133 loss)
I0523 07:40:52.680325 34819 sgd_solver.cpp:112] Iteration 71210, lr = 0.01
I0523 07:40:57.455025 34819 solver.cpp:239] Iteration 71220 (1.79069 iter/s, 5.58443s/10 iters), loss = 8.3167
I0523 07:40:57.455073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3167 (* 1 = 8.3167 loss)
I0523 07:40:58.171887 34819 sgd_solver.cpp:112] Iteration 71220, lr = 0.01
I0523 07:41:02.520534 34819 solver.cpp:239] Iteration 71230 (1.97424 iter/s, 5.06525s/10 iters), loss = 7.76985
I0523 07:41:02.520586 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76985 (* 1 = 7.76985 loss)
I0523 07:41:02.587630 34819 sgd_solver.cpp:112] Iteration 71230, lr = 0.01
I0523 07:41:08.721807 34819 solver.cpp:239] Iteration 71240 (1.61265 iter/s, 6.20096s/10 iters), loss = 7.14528
I0523 07:41:08.721858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.14528 (* 1 = 7.14528 loss)
I0523 07:41:08.785780 34819 sgd_solver.cpp:112] Iteration 71240, lr = 0.01
I0523 07:41:14.319306 34819 solver.cpp:239] Iteration 71250 (1.78661 iter/s, 5.59721s/10 iters), loss = 6.73119
I0523 07:41:14.319546 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.73119 (* 1 = 6.73119 loss)
I0523 07:41:14.379806 34819 sgd_solver.cpp:112] Iteration 71250, lr = 0.01
I0523 07:41:17.826481 34819 solver.cpp:239] Iteration 71260 (2.85158 iter/s, 3.50683s/10 iters), loss = 7.91175
I0523 07:41:17.826539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91175 (* 1 = 7.91175 loss)
I0523 07:41:18.665745 34819 sgd_solver.cpp:112] Iteration 71260, lr = 0.01
I0523 07:41:24.252969 34819 solver.cpp:239] Iteration 71270 (1.55614 iter/s, 6.42616s/10 iters), loss = 7.56357
I0523 07:41:24.253010 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56357 (* 1 = 7.56357 loss)
I0523 07:41:24.325281 34819 sgd_solver.cpp:112] Iteration 71270, lr = 0.01
I0523 07:41:26.947806 34819 solver.cpp:239] Iteration 71280 (3.71102 iter/s, 2.69468s/10 iters), loss = 7.39428
I0523 07:41:26.947849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39428 (* 1 = 7.39428 loss)
I0523 07:41:27.027932 34819 sgd_solver.cpp:112] Iteration 71280, lr = 0.01
I0523 07:41:32.574939 34819 solver.cpp:239] Iteration 71290 (1.77719 iter/s, 5.62686s/10 iters), loss = 7.40136
I0523 07:41:32.574983 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40136 (* 1 = 7.40136 loss)
I0523 07:41:33.406350 34819 sgd_solver.cpp:112] Iteration 71290, lr = 0.01
I0523 07:41:38.302603 34819 solver.cpp:239] Iteration 71300 (1.746 iter/s, 5.72738s/10 iters), loss = 7.78882
I0523 07:41:38.302644 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78882 (* 1 = 7.78882 loss)
I0523 07:41:38.366771 34819 sgd_solver.cpp:112] Iteration 71300, lr = 0.01
I0523 07:41:42.481798 34819 solver.cpp:239] Iteration 71310 (2.39293 iter/s, 4.17897s/10 iters), loss = 7.56289
I0523 07:41:42.481842 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56289 (* 1 = 7.56289 loss)
I0523 07:41:42.549752 34819 sgd_solver.cpp:112] Iteration 71310, lr = 0.01
I0523 07:41:49.003566 34819 solver.cpp:239] Iteration 71320 (1.5334 iter/s, 6.52145s/10 iters), loss = 7.17391
I0523 07:41:49.003721 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.17391 (* 1 = 7.17391 loss)
I0523 07:41:49.067631 34819 sgd_solver.cpp:112] Iteration 71320, lr = 0.01
I0523 07:41:55.001052 34819 solver.cpp:239] Iteration 71330 (1.66748 iter/s, 5.99708s/10 iters), loss = 7.44873
I0523 07:41:55.001097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44873 (* 1 = 7.44873 loss)
I0523 07:41:55.683274 34819 sgd_solver.cpp:112] Iteration 71330, lr = 0.01
I0523 07:41:59.508952 34819 solver.cpp:239] Iteration 71340 (2.21845 iter/s, 4.50765s/10 iters), loss = 7.6478
I0523 07:41:59.509006 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6478 (* 1 = 7.6478 loss)
I0523 07:41:59.936688 34819 sgd_solver.cpp:112] Iteration 71340, lr = 0.01
I0523 07:42:04.419467 34819 solver.cpp:239] Iteration 71350 (2.03655 iter/s, 4.91026s/10 iters), loss = 8.60123
I0523 07:42:04.419509 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60123 (* 1 = 8.60123 loss)
I0523 07:42:04.472043 34819 sgd_solver.cpp:112] Iteration 71350, lr = 0.01
I0523 07:42:08.518728 34819 solver.cpp:239] Iteration 71360 (2.43961 iter/s, 4.09902s/10 iters), loss = 7.82602
I0523 07:42:08.518771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82602 (* 1 = 7.82602 loss)
I0523 07:42:09.248919 34819 sgd_solver.cpp:112] Iteration 71360, lr = 0.01
I0523 07:42:13.799265 34819 solver.cpp:239] Iteration 71370 (1.89385 iter/s, 5.28026s/10 iters), loss = 6.89175
I0523 07:42:13.799329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.89175 (* 1 = 6.89175 loss)
I0523 07:42:14.622014 34819 sgd_solver.cpp:112] Iteration 71370, lr = 0.01
I0523 07:42:17.567870 34819 solver.cpp:239] Iteration 71380 (2.65366 iter/s, 3.76838s/10 iters), loss = 7.02404
I0523 07:42:17.567939 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.02404 (* 1 = 7.02404 loss)
I0523 07:42:17.642930 34819 sgd_solver.cpp:112] Iteration 71380, lr = 0.01
I0523 07:42:21.899554 34819 solver.cpp:239] Iteration 71390 (2.3087 iter/s, 4.33144s/10 iters), loss = 8.51932
I0523 07:42:21.899680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51932 (* 1 = 8.51932 loss)
I0523 07:42:22.044044 34819 sgd_solver.cpp:112] Iteration 71390, lr = 0.01
I0523 07:42:26.731175 34819 solver.cpp:239] Iteration 71400 (2.06984 iter/s, 4.8313s/10 iters), loss = 7.89009
I0523 07:42:26.731216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89009 (* 1 = 7.89009 loss)
I0523 07:42:26.789443 34819 sgd_solver.cpp:112] Iteration 71400, lr = 0.01
I0523 07:42:30.986874 34819 solver.cpp:239] Iteration 71410 (2.34992 iter/s, 4.25547s/10 iters), loss = 8.57921
I0523 07:42:30.986927 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57921 (* 1 = 8.57921 loss)
I0523 07:42:31.050153 34819 sgd_solver.cpp:112] Iteration 71410, lr = 0.01
I0523 07:42:33.717067 34819 solver.cpp:239] Iteration 71420 (3.663 iter/s, 2.73s/10 iters), loss = 7.75638
I0523 07:42:33.717126 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75638 (* 1 = 7.75638 loss)
I0523 07:42:34.514946 34819 sgd_solver.cpp:112] Iteration 71420, lr = 0.01
I0523 07:42:38.988291 34819 solver.cpp:239] Iteration 71430 (1.89719 iter/s, 5.27095s/10 iters), loss = 8.07132
I0523 07:42:38.988340 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07132 (* 1 = 8.07132 loss)
I0523 07:42:39.053274 34819 sgd_solver.cpp:112] Iteration 71430, lr = 0.01
I0523 07:42:41.648253 34819 solver.cpp:239] Iteration 71440 (3.75969 iter/s, 2.65979s/10 iters), loss = 7.5
I0523 07:42:41.648300 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5 (* 1 = 7.5 loss)
I0523 07:42:42.499193 34819 sgd_solver.cpp:112] Iteration 71440, lr = 0.01
I0523 07:42:44.883185 34819 solver.cpp:239] Iteration 71450 (3.09144 iter/s, 3.23474s/10 iters), loss = 8.55694
I0523 07:42:44.883234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55694 (* 1 = 8.55694 loss)
I0523 07:42:44.936971 34819 sgd_solver.cpp:112] Iteration 71450, lr = 0.01
I0523 07:42:50.162773 34819 solver.cpp:239] Iteration 71460 (1.89418 iter/s, 5.27932s/10 iters), loss = 7.8904
I0523 07:42:50.162819 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8904 (* 1 = 7.8904 loss)
I0523 07:42:50.230017 34819 sgd_solver.cpp:112] Iteration 71460, lr = 0.01
I0523 07:42:54.543941 34819 solver.cpp:239] Iteration 71470 (2.28262 iter/s, 4.38094s/10 iters), loss = 8.48655
I0523 07:42:54.544093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48655 (* 1 = 8.48655 loss)
I0523 07:42:54.608883 34819 sgd_solver.cpp:112] Iteration 71470, lr = 0.01
I0523 07:43:00.778251 34819 solver.cpp:239] Iteration 71480 (1.60414 iter/s, 6.23389s/10 iters), loss = 6.57328
I0523 07:43:00.778309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.57328 (* 1 = 6.57328 loss)
I0523 07:43:00.850908 34819 sgd_solver.cpp:112] Iteration 71480, lr = 0.01
I0523 07:43:05.799450 34819 solver.cpp:239] Iteration 71490 (1.99166 iter/s, 5.02093s/10 iters), loss = 7.90155
I0523 07:43:05.799513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90155 (* 1 = 7.90155 loss)
I0523 07:43:05.861196 34819 sgd_solver.cpp:112] Iteration 71490, lr = 0.01
I0523 07:43:12.126006 34819 solver.cpp:239] Iteration 71500 (1.58072 iter/s, 6.32623s/10 iters), loss = 8.02074
I0523 07:43:12.126049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02074 (* 1 = 8.02074 loss)
I0523 07:43:12.210019 34819 sgd_solver.cpp:112] Iteration 71500, lr = 0.01
I0523 07:43:16.550097 34819 solver.cpp:239] Iteration 71510 (2.26047 iter/s, 4.42386s/10 iters), loss = 7.59517
I0523 07:43:16.550146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59517 (* 1 = 7.59517 loss)
I0523 07:43:17.369937 34819 sgd_solver.cpp:112] Iteration 71510, lr = 0.01
I0523 07:43:22.224252 34819 solver.cpp:239] Iteration 71520 (1.76246 iter/s, 5.67388s/10 iters), loss = 8.13394
I0523 07:43:22.224294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13394 (* 1 = 8.13394 loss)
I0523 07:43:22.280532 34819 sgd_solver.cpp:112] Iteration 71520, lr = 0.01
I0523 07:43:27.083695 34819 solver.cpp:239] Iteration 71530 (2.05796 iter/s, 4.85918s/10 iters), loss = 8.00109
I0523 07:43:27.083834 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00109 (* 1 = 8.00109 loss)
I0523 07:43:27.155932 34819 sgd_solver.cpp:112] Iteration 71530, lr = 0.01
I0523 07:43:34.472956 34819 solver.cpp:239] Iteration 71540 (1.35339 iter/s, 7.38883s/10 iters), loss = 7.84683
I0523 07:43:34.472997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84683 (* 1 = 7.84683 loss)
I0523 07:43:35.216352 34819 sgd_solver.cpp:112] Iteration 71540, lr = 0.01
I0523 07:43:39.343821 34819 solver.cpp:239] Iteration 71550 (2.05313 iter/s, 4.87062s/10 iters), loss = 8.41281
I0523 07:43:39.343863 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41281 (* 1 = 8.41281 loss)
I0523 07:43:40.240067 34819 sgd_solver.cpp:112] Iteration 71550, lr = 0.01
I0523 07:43:44.852577 34819 solver.cpp:239] Iteration 71560 (1.81539 iter/s, 5.50847s/10 iters), loss = 7.99953
I0523 07:43:44.852636 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99953 (* 1 = 7.99953 loss)
I0523 07:43:44.924716 34819 sgd_solver.cpp:112] Iteration 71560, lr = 0.01
I0523 07:43:50.762015 34819 solver.cpp:239] Iteration 71570 (1.69229 iter/s, 5.90914s/10 iters), loss = 7.8589
I0523 07:43:50.762058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8589 (* 1 = 7.8589 loss)
I0523 07:43:50.828048 34819 sgd_solver.cpp:112] Iteration 71570, lr = 0.01
I0523 07:43:54.564224 34819 solver.cpp:239] Iteration 71580 (2.6302 iter/s, 3.802s/10 iters), loss = 7.36353
I0523 07:43:54.564275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36353 (* 1 = 7.36353 loss)
I0523 07:43:55.118918 34819 sgd_solver.cpp:112] Iteration 71580, lr = 0.01
I0523 07:43:56.901918 34819 solver.cpp:239] Iteration 71590 (4.27801 iter/s, 2.33753s/10 iters), loss = 8.87977
I0523 07:43:56.901973 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87977 (* 1 = 8.87977 loss)
I0523 07:43:56.979528 34819 sgd_solver.cpp:112] Iteration 71590, lr = 0.01
I0523 07:44:00.436509 34819 solver.cpp:239] Iteration 71600 (2.82935 iter/s, 3.53438s/10 iters), loss = 7.26902
I0523 07:44:00.436677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26902 (* 1 = 7.26902 loss)
I0523 07:44:00.497761 34819 sgd_solver.cpp:112] Iteration 71600, lr = 0.01
I0523 07:44:03.801139 34819 solver.cpp:239] Iteration 71610 (2.97238 iter/s, 3.36431s/10 iters), loss = 8.53863
I0523 07:44:03.801195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53863 (* 1 = 8.53863 loss)
I0523 07:44:03.878124 34819 sgd_solver.cpp:112] Iteration 71610, lr = 0.01
I0523 07:44:08.645176 34819 solver.cpp:239] Iteration 71620 (2.0645 iter/s, 4.84378s/10 iters), loss = 8.02799
I0523 07:44:08.645217 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02799 (* 1 = 8.02799 loss)
I0523 07:44:08.707518 34819 sgd_solver.cpp:112] Iteration 71620, lr = 0.01
I0523 07:44:11.649866 34819 solver.cpp:239] Iteration 71630 (3.32832 iter/s, 3.00452s/10 iters), loss = 7.73354
I0523 07:44:11.649907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73354 (* 1 = 7.73354 loss)
I0523 07:44:12.434005 34819 sgd_solver.cpp:112] Iteration 71630, lr = 0.01
I0523 07:44:17.586877 34819 solver.cpp:239] Iteration 71640 (1.68444 iter/s, 5.93671s/10 iters), loss = 7.94079
I0523 07:44:17.586935 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94079 (* 1 = 7.94079 loss)
I0523 07:44:17.659260 34819 sgd_solver.cpp:112] Iteration 71640, lr = 0.01
I0523 07:44:22.998836 34819 solver.cpp:239] Iteration 71650 (1.84786 iter/s, 5.41167s/10 iters), loss = 7.0794
I0523 07:44:22.998877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.0794 (* 1 = 7.0794 loss)
I0523 07:44:23.052989 34819 sgd_solver.cpp:112] Iteration 71650, lr = 0.01
I0523 07:44:27.069404 34819 solver.cpp:239] Iteration 71660 (2.45679 iter/s, 4.07034s/10 iters), loss = 7.82542
I0523 07:44:27.069449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82542 (* 1 = 7.82542 loss)
I0523 07:44:27.915709 34819 sgd_solver.cpp:112] Iteration 71660, lr = 0.01
I0523 07:44:31.251338 34819 solver.cpp:239] Iteration 71670 (2.39136 iter/s, 4.18171s/10 iters), loss = 7.73939
I0523 07:44:31.251449 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73939 (* 1 = 7.73939 loss)
I0523 07:44:32.120236 34819 sgd_solver.cpp:112] Iteration 71670, lr = 0.01
I0523 07:44:35.432678 34819 solver.cpp:239] Iteration 71680 (2.39174 iter/s, 4.18106s/10 iters), loss = 7.73948
I0523 07:44:35.432719 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73948 (* 1 = 7.73948 loss)
I0523 07:44:36.244560 34819 sgd_solver.cpp:112] Iteration 71680, lr = 0.01
I0523 07:44:39.757696 34819 solver.cpp:239] Iteration 71690 (2.31225 iter/s, 4.32479s/10 iters), loss = 7.68974
I0523 07:44:39.757735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68974 (* 1 = 7.68974 loss)
I0523 07:44:39.818089 34819 sgd_solver.cpp:112] Iteration 71690, lr = 0.01
I0523 07:44:43.725713 34819 solver.cpp:239] Iteration 71700 (2.52028 iter/s, 3.96781s/10 iters), loss = 6.74534
I0523 07:44:43.725755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.74534 (* 1 = 6.74534 loss)
I0523 07:44:43.786895 34819 sgd_solver.cpp:112] Iteration 71700, lr = 0.01
I0523 07:44:48.775907 34819 solver.cpp:239] Iteration 71710 (1.98023 iter/s, 5.04993s/10 iters), loss = 7.71248
I0523 07:44:48.775954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71248 (* 1 = 7.71248 loss)
I0523 07:44:49.065956 34819 sgd_solver.cpp:112] Iteration 71710, lr = 0.01
I0523 07:44:51.836488 34819 solver.cpp:239] Iteration 71720 (3.26755 iter/s, 3.0604s/10 iters), loss = 7.79798
I0523 07:44:51.836527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79798 (* 1 = 7.79798 loss)
I0523 07:44:51.910727 34819 sgd_solver.cpp:112] Iteration 71720, lr = 0.01
I0523 07:44:55.760745 34819 solver.cpp:239] Iteration 71730 (2.54839 iter/s, 3.92405s/10 iters), loss = 8.45013
I0523 07:44:55.760782 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45013 (* 1 = 8.45013 loss)
I0523 07:44:56.582818 34819 sgd_solver.cpp:112] Iteration 71730, lr = 0.01
I0523 07:45:01.848789 34819 solver.cpp:239] Iteration 71740 (1.64264 iter/s, 6.08775s/10 iters), loss = 8.07078
I0523 07:45:01.849025 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07078 (* 1 = 8.07078 loss)
I0523 07:45:01.918120 34819 sgd_solver.cpp:112] Iteration 71740, lr = 0.01
I0523 07:45:06.759428 34819 solver.cpp:239] Iteration 71750 (2.03657 iter/s, 4.91022s/10 iters), loss = 7.76216
I0523 07:45:06.759469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76216 (* 1 = 7.76216 loss)
I0523 07:45:07.521369 34819 sgd_solver.cpp:112] Iteration 71750, lr = 0.01
I0523 07:45:12.439784 34819 solver.cpp:239] Iteration 71760 (1.76054 iter/s, 5.68007s/10 iters), loss = 7.99103
I0523 07:45:12.439824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99103 (* 1 = 7.99103 loss)
I0523 07:45:13.317425 34819 sgd_solver.cpp:112] Iteration 71760, lr = 0.01
I0523 07:45:17.812520 34819 solver.cpp:239] Iteration 71770 (1.86134 iter/s, 5.37246s/10 iters), loss = 8.20956
I0523 07:45:17.812562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20956 (* 1 = 8.20956 loss)
I0523 07:45:18.578822 34819 sgd_solver.cpp:112] Iteration 71770, lr = 0.01
I0523 07:45:22.652752 34819 solver.cpp:239] Iteration 71780 (2.06612 iter/s, 4.83999s/10 iters), loss = 7.55137
I0523 07:45:22.652797 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55137 (* 1 = 7.55137 loss)
I0523 07:45:23.481595 34819 sgd_solver.cpp:112] Iteration 71780, lr = 0.01
I0523 07:45:26.818542 34819 solver.cpp:239] Iteration 71790 (2.40064 iter/s, 4.16556s/10 iters), loss = 7.90489
I0523 07:45:26.818601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90489 (* 1 = 7.90489 loss)
I0523 07:45:26.886934 34819 sgd_solver.cpp:112] Iteration 71790, lr = 0.01
I0523 07:45:30.387318 34819 solver.cpp:239] Iteration 71800 (2.80225 iter/s, 3.56856s/10 iters), loss = 8.66381
I0523 07:45:30.387362 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66381 (* 1 = 8.66381 loss)
I0523 07:45:31.134138 34819 sgd_solver.cpp:112] Iteration 71800, lr = 0.01
I0523 07:45:36.653025 34819 solver.cpp:239] Iteration 71810 (1.59607 iter/s, 6.26538s/10 iters), loss = 8.24488
I0523 07:45:36.653267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24488 (* 1 = 8.24488 loss)
I0523 07:45:37.183532 34819 sgd_solver.cpp:112] Iteration 71810, lr = 0.01
I0523 07:45:42.057689 34819 solver.cpp:239] Iteration 71820 (1.85041 iter/s, 5.40421s/10 iters), loss = 8.1513
I0523 07:45:42.057741 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1513 (* 1 = 8.1513 loss)
I0523 07:45:42.116688 34819 sgd_solver.cpp:112] Iteration 71820, lr = 0.01
I0523 07:45:45.752502 34819 solver.cpp:239] Iteration 71830 (2.70665 iter/s, 3.6946s/10 iters), loss = 7.01144
I0523 07:45:45.752560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.01144 (* 1 = 7.01144 loss)
I0523 07:45:46.554278 34819 sgd_solver.cpp:112] Iteration 71830, lr = 0.01
I0523 07:45:50.365803 34819 solver.cpp:239] Iteration 71840 (2.16776 iter/s, 4.61305s/10 iters), loss = 8.79688
I0523 07:45:50.365855 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79688 (* 1 = 8.79688 loss)
I0523 07:45:51.135251 34819 sgd_solver.cpp:112] Iteration 71840, lr = 0.01
I0523 07:45:56.505622 34819 solver.cpp:239] Iteration 71850 (1.6288 iter/s, 6.1395s/10 iters), loss = 8.03949
I0523 07:45:56.505676 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03949 (* 1 = 8.03949 loss)
I0523 07:45:56.571761 34819 sgd_solver.cpp:112] Iteration 71850, lr = 0.01
I0523 07:46:02.424500 34819 solver.cpp:239] Iteration 71860 (1.6896 iter/s, 5.91857s/10 iters), loss = 7.93367
I0523 07:46:02.424543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93367 (* 1 = 7.93367 loss)
I0523 07:46:03.173977 34819 sgd_solver.cpp:112] Iteration 71860, lr = 0.01
I0523 07:46:07.692013 34819 solver.cpp:239] Iteration 71870 (1.89852 iter/s, 5.26725s/10 iters), loss = 7.0438
I0523 07:46:07.692174 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.0438 (* 1 = 7.0438 loss)
I0523 07:46:07.754684 34819 sgd_solver.cpp:112] Iteration 71870, lr = 0.01
I0523 07:46:12.687362 34819 solver.cpp:239] Iteration 71880 (2.00201 iter/s, 4.99497s/10 iters), loss = 7.33707
I0523 07:46:12.687412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33707 (* 1 = 7.33707 loss)
I0523 07:46:12.755568 34819 sgd_solver.cpp:112] Iteration 71880, lr = 0.01
I0523 07:46:17.745216 34819 solver.cpp:239] Iteration 71890 (1.97723 iter/s, 5.05759s/10 iters), loss = 7.43984
I0523 07:46:17.745275 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.43984 (* 1 = 7.43984 loss)
I0523 07:46:17.821053 34819 sgd_solver.cpp:112] Iteration 71890, lr = 0.01
I0523 07:46:22.974169 34819 solver.cpp:239] Iteration 71900 (1.91253 iter/s, 5.22867s/10 iters), loss = 7.8009
I0523 07:46:22.974222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8009 (* 1 = 7.8009 loss)
I0523 07:46:23.738442 34819 sgd_solver.cpp:112] Iteration 71900, lr = 0.01
I0523 07:46:30.095975 34819 solver.cpp:239] Iteration 71910 (1.4042 iter/s, 7.12147s/10 iters), loss = 8.09308
I0523 07:46:30.096017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09308 (* 1 = 8.09308 loss)
I0523 07:46:30.843263 34819 sgd_solver.cpp:112] Iteration 71910, lr = 0.01
I0523 07:46:36.364766 34819 solver.cpp:239] Iteration 71920 (1.59528 iter/s, 6.26849s/10 iters), loss = 7.07212
I0523 07:46:36.364825 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.07212 (* 1 = 7.07212 loss)
I0523 07:46:36.431262 34819 sgd_solver.cpp:112] Iteration 71920, lr = 0.01
I0523 07:46:39.574101 34819 solver.cpp:239] Iteration 71930 (3.1161 iter/s, 3.20914s/10 iters), loss = 9.28848
I0523 07:46:39.574219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.28848 (* 1 = 9.28848 loss)
I0523 07:46:39.656612 34819 sgd_solver.cpp:112] Iteration 71930, lr = 0.01
I0523 07:46:45.316946 34819 solver.cpp:239] Iteration 71940 (1.74141 iter/s, 5.74248s/10 iters), loss = 8.20784
I0523 07:46:45.317000 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20784 (* 1 = 8.20784 loss)
I0523 07:46:46.168802 34819 sgd_solver.cpp:112] Iteration 71940, lr = 0.01
I0523 07:46:49.679571 34819 solver.cpp:239] Iteration 71950 (2.29232 iter/s, 4.36239s/10 iters), loss = 8.47386
I0523 07:46:49.679613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47386 (* 1 = 8.47386 loss)
I0523 07:46:50.287040 34819 sgd_solver.cpp:112] Iteration 71950, lr = 0.01
I0523 07:46:54.265981 34819 solver.cpp:239] Iteration 71960 (2.18047 iter/s, 4.58617s/10 iters), loss = 8.08365
I0523 07:46:54.266037 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08365 (* 1 = 8.08365 loss)
I0523 07:46:54.336179 34819 sgd_solver.cpp:112] Iteration 71960, lr = 0.01
I0523 07:47:00.264883 34819 solver.cpp:239] Iteration 71970 (1.66706 iter/s, 5.99858s/10 iters), loss = 8.29977
I0523 07:47:00.264938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29977 (* 1 = 8.29977 loss)
I0523 07:47:00.318960 34819 sgd_solver.cpp:112] Iteration 71970, lr = 0.01
I0523 07:47:07.002005 34819 solver.cpp:239] Iteration 71980 (1.48439 iter/s, 6.73679s/10 iters), loss = 7.31348
I0523 07:47:07.002064 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.31348 (* 1 = 7.31348 loss)
I0523 07:47:07.074620 34819 sgd_solver.cpp:112] Iteration 71980, lr = 0.01
I0523 07:47:12.852627 34819 solver.cpp:239] Iteration 71990 (1.70931 iter/s, 5.85032s/10 iters), loss = 8.22277
I0523 07:47:12.852918 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22277 (* 1 = 8.22277 loss)
I0523 07:47:12.917034 34819 sgd_solver.cpp:112] Iteration 71990, lr = 0.01
I0523 07:47:17.155277 34819 solver.cpp:239] Iteration 72000 (2.3244 iter/s, 4.30218s/10 iters), loss = 7.66052
I0523 07:47:17.155329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66052 (* 1 = 7.66052 loss)
I0523 07:47:17.224787 34819 sgd_solver.cpp:112] Iteration 72000, lr = 0.01
I0523 07:47:22.189664 34819 solver.cpp:239] Iteration 72010 (1.98645 iter/s, 5.03411s/10 iters), loss = 8.06407
I0523 07:47:22.189718 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06407 (* 1 = 8.06407 loss)
I0523 07:47:22.900676 34819 sgd_solver.cpp:112] Iteration 72010, lr = 0.01
I0523 07:47:26.376113 34819 solver.cpp:239] Iteration 72020 (2.38879 iter/s, 4.18621s/10 iters), loss = 6.89491
I0523 07:47:26.376163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.89491 (* 1 = 6.89491 loss)
I0523 07:47:27.248605 34819 sgd_solver.cpp:112] Iteration 72020, lr = 0.01
I0523 07:47:32.823611 34819 solver.cpp:239] Iteration 72030 (1.55106 iter/s, 6.44718s/10 iters), loss = 8.18747
I0523 07:47:32.823652 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18747 (* 1 = 8.18747 loss)
I0523 07:47:33.343400 34819 sgd_solver.cpp:112] Iteration 72030, lr = 0.01
I0523 07:47:35.931700 34819 solver.cpp:239] Iteration 72040 (3.21761 iter/s, 3.10789s/10 iters), loss = 7.94462
I0523 07:47:35.931754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94462 (* 1 = 7.94462 loss)
I0523 07:47:36.721089 34819 sgd_solver.cpp:112] Iteration 72040, lr = 0.01
I0523 07:47:41.148798 34819 solver.cpp:239] Iteration 72050 (1.91689 iter/s, 5.21679s/10 iters), loss = 7.71269
I0523 07:47:41.148854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71269 (* 1 = 7.71269 loss)
I0523 07:47:41.866981 34819 sgd_solver.cpp:112] Iteration 72050, lr = 0.01
I0523 07:47:46.178019 34819 solver.cpp:239] Iteration 72060 (1.98848 iter/s, 5.02895s/10 iters), loss = 7.1411
I0523 07:47:46.178169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.1411 (* 1 = 7.1411 loss)
I0523 07:47:47.010917 34819 sgd_solver.cpp:112] Iteration 72060, lr = 0.01
I0523 07:47:50.678889 34819 solver.cpp:239] Iteration 72070 (2.22196 iter/s, 4.50052s/10 iters), loss = 7.35078
I0523 07:47:50.678943 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35078 (* 1 = 7.35078 loss)
I0523 07:47:50.733952 34819 sgd_solver.cpp:112] Iteration 72070, lr = 0.01
I0523 07:47:53.383281 34819 solver.cpp:239] Iteration 72080 (3.69793 iter/s, 2.70422s/10 iters), loss = 7.57835
I0523 07:47:53.383334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57835 (* 1 = 7.57835 loss)
I0523 07:47:53.950888 34819 sgd_solver.cpp:112] Iteration 72080, lr = 0.01
I0523 07:47:57.889057 34819 solver.cpp:239] Iteration 72090 (2.21949 iter/s, 4.50554s/10 iters), loss = 6.58588
I0523 07:47:57.889101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.58588 (* 1 = 6.58588 loss)
I0523 07:47:58.660372 34819 sgd_solver.cpp:112] Iteration 72090, lr = 0.01
I0523 07:48:03.445559 34819 solver.cpp:239] Iteration 72100 (1.79978 iter/s, 5.55623s/10 iters), loss = 6.96568
I0523 07:48:03.445605 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.96568 (* 1 = 6.96568 loss)
I0523 07:48:04.264072 34819 sgd_solver.cpp:112] Iteration 72100, lr = 0.01
I0523 07:48:10.021188 34819 solver.cpp:239] Iteration 72110 (1.52084 iter/s, 6.57531s/10 iters), loss = 8.40876
I0523 07:48:10.021229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40876 (* 1 = 8.40876 loss)
I0523 07:48:10.093194 34819 sgd_solver.cpp:112] Iteration 72110, lr = 0.01
I0523 07:48:16.084064 34819 solver.cpp:239] Iteration 72120 (1.64946 iter/s, 6.06258s/10 iters), loss = 7.20129
I0523 07:48:16.084105 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20129 (* 1 = 7.20129 loss)
I0523 07:48:16.154604 34819 sgd_solver.cpp:112] Iteration 72120, lr = 0.01
I0523 07:48:22.353219 34819 solver.cpp:239] Iteration 72130 (1.59519 iter/s, 6.26883s/10 iters), loss = 7.27086
I0523 07:48:22.353482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.27086 (* 1 = 7.27086 loss)
I0523 07:48:23.103502 34819 sgd_solver.cpp:112] Iteration 72130, lr = 0.01
I0523 07:48:27.166913 34819 solver.cpp:239] Iteration 72140 (2.07759 iter/s, 4.81326s/10 iters), loss = 8.11832
I0523 07:48:27.166956 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11832 (* 1 = 8.11832 loss)
I0523 07:48:27.235054 34819 sgd_solver.cpp:112] Iteration 72140, lr = 0.01
I0523 07:48:29.917503 34819 solver.cpp:239] Iteration 72150 (3.63581 iter/s, 2.75042s/10 iters), loss = 7.10846
I0523 07:48:29.917553 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.10846 (* 1 = 7.10846 loss)
I0523 07:48:29.992931 34819 sgd_solver.cpp:112] Iteration 72150, lr = 0.01
I0523 07:48:35.539083 34819 solver.cpp:239] Iteration 72160 (1.77895 iter/s, 5.6213s/10 iters), loss = 7.69163
I0523 07:48:35.539124 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69163 (* 1 = 7.69163 loss)
I0523 07:48:36.367676 34819 sgd_solver.cpp:112] Iteration 72160, lr = 0.01
I0523 07:48:42.683183 34819 solver.cpp:239] Iteration 72170 (1.39982 iter/s, 7.14376s/10 iters), loss = 7.78681
I0523 07:48:42.683234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78681 (* 1 = 7.78681 loss)
I0523 07:48:42.754565 34819 sgd_solver.cpp:112] Iteration 72170, lr = 0.01
I0523 07:48:48.852747 34819 solver.cpp:239] Iteration 72180 (1.62094 iter/s, 6.16925s/10 iters), loss = 7.88981
I0523 07:48:48.852802 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88981 (* 1 = 7.88981 loss)
I0523 07:48:48.933887 34819 sgd_solver.cpp:112] Iteration 72180, lr = 0.01
I0523 07:48:52.374413 34819 solver.cpp:239] Iteration 72190 (2.83973 iter/s, 3.52147s/10 iters), loss = 7.3102
I0523 07:48:52.374634 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3102 (* 1 = 7.3102 loss)
I0523 07:48:53.004384 34819 sgd_solver.cpp:112] Iteration 72190, lr = 0.01
I0523 07:48:58.748777 34819 solver.cpp:239] Iteration 72200 (1.5689 iter/s, 6.37391s/10 iters), loss = 8.49539
I0523 07:48:58.748821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49539 (* 1 = 8.49539 loss)
I0523 07:48:58.806406 34819 sgd_solver.cpp:112] Iteration 72200, lr = 0.01
I0523 07:49:04.080674 34819 solver.cpp:239] Iteration 72210 (1.8756 iter/s, 5.33162s/10 iters), loss = 7.33032
I0523 07:49:04.080725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33032 (* 1 = 7.33032 loss)
I0523 07:49:04.140070 34819 sgd_solver.cpp:112] Iteration 72210, lr = 0.01
I0523 07:49:09.592330 34819 solver.cpp:239] Iteration 72220 (1.81443 iter/s, 5.51137s/10 iters), loss = 8.47952
I0523 07:49:09.592382 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47952 (* 1 = 8.47952 loss)
I0523 07:49:09.655472 34819 sgd_solver.cpp:112] Iteration 72220, lr = 0.01
I0523 07:49:13.779750 34819 solver.cpp:239] Iteration 72230 (2.38824 iter/s, 4.18719s/10 iters), loss = 8.08379
I0523 07:49:13.779798 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08379 (* 1 = 8.08379 loss)
I0523 07:49:13.856945 34819 sgd_solver.cpp:112] Iteration 72230, lr = 0.01
I0523 07:49:19.796615 34819 solver.cpp:239] Iteration 72240 (1.66208 iter/s, 6.01657s/10 iters), loss = 8.4078
I0523 07:49:19.796658 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4078 (* 1 = 8.4078 loss)
I0523 07:49:19.854996 34819 sgd_solver.cpp:112] Iteration 72240, lr = 0.01
I0523 07:49:22.203624 34819 solver.cpp:239] Iteration 72250 (4.15483 iter/s, 2.40684s/10 iters), loss = 8.28282
I0523 07:49:22.203672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28282 (* 1 = 8.28282 loss)
I0523 07:49:22.562075 34819 sgd_solver.cpp:112] Iteration 72250, lr = 0.01
I0523 07:49:27.441006 34819 solver.cpp:239] Iteration 72260 (1.90945 iter/s, 5.2371s/10 iters), loss = 8.19374
I0523 07:49:27.441062 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19374 (* 1 = 8.19374 loss)
I0523 07:49:27.509382 34819 sgd_solver.cpp:112] Iteration 72260, lr = 0.01
I0523 07:49:29.894181 34819 solver.cpp:239] Iteration 72270 (4.07663 iter/s, 2.45301s/10 iters), loss = 8.42352
I0523 07:49:29.894237 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42352 (* 1 = 8.42352 loss)
I0523 07:49:30.658231 34819 sgd_solver.cpp:112] Iteration 72270, lr = 0.01
I0523 07:49:34.770486 34819 solver.cpp:239] Iteration 72280 (2.05084 iter/s, 4.87605s/10 iters), loss = 8.79178
I0523 07:49:34.770539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.79178 (* 1 = 8.79178 loss)
I0523 07:49:35.589579 34819 sgd_solver.cpp:112] Iteration 72280, lr = 0.01
I0523 07:49:39.597868 34819 solver.cpp:239] Iteration 72290 (2.07162 iter/s, 4.82713s/10 iters), loss = 7.73603
I0523 07:49:39.597913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73603 (* 1 = 7.73603 loss)
I0523 07:49:39.657444 34819 sgd_solver.cpp:112] Iteration 72290, lr = 0.01
I0523 07:49:43.754178 34819 solver.cpp:239] Iteration 72300 (2.40611 iter/s, 4.15609s/10 iters), loss = 7.96983
I0523 07:49:43.754222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96983 (* 1 = 7.96983 loss)
I0523 07:49:43.810838 34819 sgd_solver.cpp:112] Iteration 72300, lr = 0.01
I0523 07:49:50.407613 34819 solver.cpp:239] Iteration 72310 (1.50306 iter/s, 6.6531s/10 iters), loss = 6.89873
I0523 07:49:50.407667 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.89873 (* 1 = 6.89873 loss)
I0523 07:49:51.035786 34819 sgd_solver.cpp:112] Iteration 72310, lr = 0.01
I0523 07:49:53.838212 34819 solver.cpp:239] Iteration 72320 (2.91512 iter/s, 3.43039s/10 iters), loss = 8.00276
I0523 07:49:53.838376 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00276 (* 1 = 8.00276 loss)
I0523 07:49:53.908373 34819 sgd_solver.cpp:112] Iteration 72320, lr = 0.01
I0523 07:49:58.122957 34819 solver.cpp:239] Iteration 72330 (2.33405 iter/s, 4.2844s/10 iters), loss = 8.60999
I0523 07:49:58.123011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60999 (* 1 = 8.60999 loss)
I0523 07:49:58.182044 34819 sgd_solver.cpp:112] Iteration 72330, lr = 0.01
I0523 07:50:03.110937 34819 solver.cpp:239] Iteration 72340 (2.00492 iter/s, 4.98772s/10 iters), loss = 7.63281
I0523 07:50:03.110994 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63281 (* 1 = 7.63281 loss)
I0523 07:50:04.002728 34819 sgd_solver.cpp:112] Iteration 72340, lr = 0.01
I0523 07:50:09.028295 34819 solver.cpp:239] Iteration 72350 (1.69003 iter/s, 5.91704s/10 iters), loss = 7.33998
I0523 07:50:09.028360 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33998 (* 1 = 7.33998 loss)
I0523 07:50:09.890146 34819 sgd_solver.cpp:112] Iteration 72350, lr = 0.01
I0523 07:50:15.628615 34819 solver.cpp:239] Iteration 72360 (1.51515 iter/s, 6.59999s/10 iters), loss = 7.65198
I0523 07:50:15.628669 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65198 (* 1 = 7.65198 loss)
I0523 07:50:16.461840 34819 sgd_solver.cpp:112] Iteration 72360, lr = 0.01
I0523 07:50:20.155827 34819 solver.cpp:239] Iteration 72370 (2.20898 iter/s, 4.52697s/10 iters), loss = 8.60657
I0523 07:50:20.155869 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60657 (* 1 = 8.60657 loss)
I0523 07:50:20.214431 34819 sgd_solver.cpp:112] Iteration 72370, lr = 0.01
I0523 07:50:25.157250 34819 solver.cpp:239] Iteration 72380 (1.99954 iter/s, 5.00116s/10 iters), loss = 8.68838
I0523 07:50:25.157501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68838 (* 1 = 8.68838 loss)
I0523 07:50:25.959026 34819 sgd_solver.cpp:112] Iteration 72380, lr = 0.01
I0523 07:50:29.171794 34819 solver.cpp:239] Iteration 72390 (2.4912 iter/s, 4.01413s/10 iters), loss = 7.71672
I0523 07:50:29.171844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71672 (* 1 = 7.71672 loss)
I0523 07:50:29.932137 34819 sgd_solver.cpp:112] Iteration 72390, lr = 0.01
I0523 07:50:34.686764 34819 solver.cpp:239] Iteration 72400 (1.81334 iter/s, 5.51468s/10 iters), loss = 7.98478
I0523 07:50:34.686828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98478 (* 1 = 7.98478 loss)
I0523 07:50:34.836030 34819 sgd_solver.cpp:112] Iteration 72400, lr = 0.01
I0523 07:50:39.540442 34819 solver.cpp:239] Iteration 72410 (2.06041 iter/s, 4.85341s/10 iters), loss = 7.60601
I0523 07:50:39.540498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.60601 (* 1 = 7.60601 loss)
I0523 07:50:39.606709 34819 sgd_solver.cpp:112] Iteration 72410, lr = 0.01
I0523 07:50:44.928069 34819 solver.cpp:239] Iteration 72420 (1.85621 iter/s, 5.38733s/10 iters), loss = 8.10828
I0523 07:50:44.928129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10828 (* 1 = 8.10828 loss)
I0523 07:50:44.991863 34819 sgd_solver.cpp:112] Iteration 72420, lr = 0.01
I0523 07:50:50.028192 34819 solver.cpp:239] Iteration 72430 (1.96084 iter/s, 5.09985s/10 iters), loss = 8.3994
I0523 07:50:50.028249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3994 (* 1 = 8.3994 loss)
I0523 07:50:50.423337 34819 sgd_solver.cpp:112] Iteration 72430, lr = 0.01
I0523 07:50:54.627940 34819 solver.cpp:239] Iteration 72440 (2.17416 iter/s, 4.59948s/10 iters), loss = 7.92471
I0523 07:50:54.627997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92471 (* 1 = 7.92471 loss)
I0523 07:50:55.380183 34819 sgd_solver.cpp:112] Iteration 72440, lr = 0.01
I0523 07:50:59.245301 34819 solver.cpp:239] Iteration 72450 (2.16585 iter/s, 4.61711s/10 iters), loss = 7.984
I0523 07:50:59.245343 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.984 (* 1 = 7.984 loss)
I0523 07:50:59.309931 34819 sgd_solver.cpp:112] Iteration 72450, lr = 0.01
I0523 07:51:05.544312 34819 solver.cpp:239] Iteration 72460 (1.58763 iter/s, 6.29871s/10 iters), loss = 7.8045
I0523 07:51:05.544363 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8045 (* 1 = 7.8045 loss)
I0523 07:51:05.599715 34819 sgd_solver.cpp:112] Iteration 72460, lr = 0.01
I0523 07:51:10.186460 34819 solver.cpp:239] Iteration 72470 (2.15429 iter/s, 4.64189s/10 iters), loss = 8.13168
I0523 07:51:10.186513 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13168 (* 1 = 8.13168 loss)
I0523 07:51:10.246343 34819 sgd_solver.cpp:112] Iteration 72470, lr = 0.01
I0523 07:51:14.167537 34819 solver.cpp:239] Iteration 72480 (2.51202 iter/s, 3.98086s/10 iters), loss = 7.42018
I0523 07:51:14.167582 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42018 (* 1 = 7.42018 loss)
I0523 07:51:14.945363 34819 sgd_solver.cpp:112] Iteration 72480, lr = 0.01
I0523 07:51:21.003904 34819 solver.cpp:239] Iteration 72490 (1.46283 iter/s, 6.83604s/10 iters), loss = 7.53298
I0523 07:51:21.003953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53298 (* 1 = 7.53298 loss)
I0523 07:51:21.816853 34819 sgd_solver.cpp:112] Iteration 72490, lr = 0.01
I0523 07:51:25.284191 34819 solver.cpp:239] Iteration 72500 (2.33643 iter/s, 4.28003s/10 iters), loss = 7.23119
I0523 07:51:25.284235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.23119 (* 1 = 7.23119 loss)
I0523 07:51:25.361871 34819 sgd_solver.cpp:112] Iteration 72500, lr = 0.01
I0523 07:51:28.630368 34819 solver.cpp:239] Iteration 72510 (2.98866 iter/s, 3.34598s/10 iters), loss = 8.26512
I0523 07:51:28.630550 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26512 (* 1 = 8.26512 loss)
I0523 07:51:28.696190 34819 sgd_solver.cpp:112] Iteration 72510, lr = 0.01
I0523 07:51:32.937510 34819 solver.cpp:239] Iteration 72520 (2.32192 iter/s, 4.30679s/10 iters), loss = 8.53001
I0523 07:51:32.937563 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53001 (* 1 = 8.53001 loss)
I0523 07:51:32.999634 34819 sgd_solver.cpp:112] Iteration 72520, lr = 0.01
I0523 07:51:37.117383 34819 solver.cpp:239] Iteration 72530 (2.39255 iter/s, 4.17964s/10 iters), loss = 7.43784
I0523 07:51:37.117437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.43784 (* 1 = 7.43784 loss)
I0523 07:51:37.183286 34819 sgd_solver.cpp:112] Iteration 72530, lr = 0.01
I0523 07:51:43.214488 34819 solver.cpp:239] Iteration 72540 (1.6402 iter/s, 6.0968s/10 iters), loss = 8.29073
I0523 07:51:43.214542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29073 (* 1 = 8.29073 loss)
I0523 07:51:43.265100 34819 sgd_solver.cpp:112] Iteration 72540, lr = 0.01
I0523 07:51:48.470497 34819 solver.cpp:239] Iteration 72550 (1.90268 iter/s, 5.25574s/10 iters), loss = 7.90729
I0523 07:51:48.470541 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90729 (* 1 = 7.90729 loss)
I0523 07:51:49.361240 34819 sgd_solver.cpp:112] Iteration 72550, lr = 0.01
I0523 07:51:54.101125 34819 solver.cpp:239] Iteration 72560 (1.77609 iter/s, 5.63033s/10 iters), loss = 7.48516
I0523 07:51:54.101173 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.48516 (* 1 = 7.48516 loss)
I0523 07:51:54.980459 34819 sgd_solver.cpp:112] Iteration 72560, lr = 0.01
I0523 07:51:59.886925 34819 solver.cpp:239] Iteration 72570 (1.72846 iter/s, 5.7855s/10 iters), loss = 9.13789
I0523 07:51:59.887106 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.13789 (* 1 = 9.13789 loss)
I0523 07:51:59.959947 34819 sgd_solver.cpp:112] Iteration 72570, lr = 0.01
I0523 07:52:04.127835 34819 solver.cpp:239] Iteration 72580 (2.35819 iter/s, 4.24054s/10 iters), loss = 7.81029
I0523 07:52:04.127890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81029 (* 1 = 7.81029 loss)
I0523 07:52:04.989892 34819 sgd_solver.cpp:112] Iteration 72580, lr = 0.01
I0523 07:52:08.852017 34819 solver.cpp:239] Iteration 72590 (2.11688 iter/s, 4.72392s/10 iters), loss = 9.16619
I0523 07:52:08.852073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.16619 (* 1 = 9.16619 loss)
I0523 07:52:09.635042 34819 sgd_solver.cpp:112] Iteration 72590, lr = 0.01
I0523 07:52:13.862483 34819 solver.cpp:239] Iteration 72600 (1.99593 iter/s, 5.01019s/10 iters), loss = 8.33998
I0523 07:52:13.862526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33998 (* 1 = 8.33998 loss)
I0523 07:52:14.662792 34819 sgd_solver.cpp:112] Iteration 72600, lr = 0.01
I0523 07:52:18.337342 34819 solver.cpp:239] Iteration 72610 (2.23482 iter/s, 4.47463s/10 iters), loss = 8.30551
I0523 07:52:18.337389 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30551 (* 1 = 8.30551 loss)
I0523 07:52:18.399610 34819 sgd_solver.cpp:112] Iteration 72610, lr = 0.01
I0523 07:52:23.859282 34819 solver.cpp:239] Iteration 72620 (1.81105 iter/s, 5.52165s/10 iters), loss = 8.05232
I0523 07:52:23.859338 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05232 (* 1 = 8.05232 loss)
I0523 07:52:23.932967 34819 sgd_solver.cpp:112] Iteration 72620, lr = 0.01
I0523 07:52:28.480312 34819 solver.cpp:239] Iteration 72630 (2.16414 iter/s, 4.62078s/10 iters), loss = 8.04506
I0523 07:52:28.480365 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04506 (* 1 = 8.04506 loss)
I0523 07:52:28.539196 34819 sgd_solver.cpp:112] Iteration 72630, lr = 0.01
I0523 07:52:31.352141 34819 solver.cpp:239] Iteration 72640 (3.48235 iter/s, 2.87162s/10 iters), loss = 7.45298
I0523 07:52:31.352324 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.45298 (* 1 = 7.45298 loss)
I0523 07:52:32.054141 34819 sgd_solver.cpp:112] Iteration 72640, lr = 0.01
I0523 07:52:36.591830 34819 solver.cpp:239] Iteration 72650 (1.90865 iter/s, 5.2393s/10 iters), loss = 8.67231
I0523 07:52:36.591873 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67231 (* 1 = 8.67231 loss)
I0523 07:52:36.652729 34819 sgd_solver.cpp:112] Iteration 72650, lr = 0.01
I0523 07:52:39.852059 34819 solver.cpp:239] Iteration 72660 (3.06744 iter/s, 3.26005s/10 iters), loss = 8.04432
I0523 07:52:39.852107 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04432 (* 1 = 8.04432 loss)
I0523 07:52:39.917773 34819 sgd_solver.cpp:112] Iteration 72660, lr = 0.01
I0523 07:52:43.029356 34819 solver.cpp:239] Iteration 72670 (3.14752 iter/s, 3.1771s/10 iters), loss = 8.08076
I0523 07:52:43.029412 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08076 (* 1 = 8.08076 loss)
I0523 07:52:43.811803 34819 sgd_solver.cpp:112] Iteration 72670, lr = 0.01
I0523 07:52:49.655845 34819 solver.cpp:239] Iteration 72680 (1.50917 iter/s, 6.62617s/10 iters), loss = 8.2156
I0523 07:52:49.655897 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2156 (* 1 = 8.2156 loss)
I0523 07:52:49.732427 34819 sgd_solver.cpp:112] Iteration 72680, lr = 0.01
I0523 07:52:55.527395 34819 solver.cpp:239] Iteration 72690 (1.70321 iter/s, 5.87126s/10 iters), loss = 8.15107
I0523 07:52:55.527439 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15107 (* 1 = 8.15107 loss)
I0523 07:52:55.592075 34819 sgd_solver.cpp:112] Iteration 72690, lr = 0.01
I0523 07:53:00.559530 34819 solver.cpp:239] Iteration 72700 (1.98733 iter/s, 5.03188s/10 iters), loss = 8.67801
I0523 07:53:00.559573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.67801 (* 1 = 8.67801 loss)
I0523 07:53:00.622040 34819 sgd_solver.cpp:112] Iteration 72700, lr = 0.01
I0523 07:53:03.874334 34819 solver.cpp:239] Iteration 72710 (3.01694 iter/s, 3.31462s/10 iters), loss = 7.56861
I0523 07:53:03.874511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56861 (* 1 = 7.56861 loss)
I0523 07:53:04.711146 34819 sgd_solver.cpp:112] Iteration 72710, lr = 0.01
I0523 07:53:08.062893 34819 solver.cpp:239] Iteration 72720 (2.38767 iter/s, 4.18818s/10 iters), loss = 8.12313
I0523 07:53:08.062953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12313 (* 1 = 8.12313 loss)
I0523 07:53:08.802196 34819 sgd_solver.cpp:112] Iteration 72720, lr = 0.01
I0523 07:53:12.793473 34819 solver.cpp:239] Iteration 72730 (2.11402 iter/s, 4.73032s/10 iters), loss = 8.52515
I0523 07:53:12.793529 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52515 (* 1 = 8.52515 loss)
I0523 07:53:12.859072 34819 sgd_solver.cpp:112] Iteration 72730, lr = 0.01
I0523 07:53:17.775507 34819 solver.cpp:239] Iteration 72740 (2.00732 iter/s, 4.98176s/10 iters), loss = 8.37254
I0523 07:53:17.775560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37254 (* 1 = 8.37254 loss)
I0523 07:53:18.337029 34819 sgd_solver.cpp:112] Iteration 72740, lr = 0.01
I0523 07:53:24.685951 34819 solver.cpp:239] Iteration 72750 (1.44715 iter/s, 6.91012s/10 iters), loss = 7.95284
I0523 07:53:24.685993 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95284 (* 1 = 7.95284 loss)
I0523 07:53:24.758127 34819 sgd_solver.cpp:112] Iteration 72750, lr = 0.01
I0523 07:53:28.958516 34819 solver.cpp:239] Iteration 72760 (2.34064 iter/s, 4.27234s/10 iters), loss = 8.19579
I0523 07:53:28.958570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19579 (* 1 = 8.19579 loss)
I0523 07:53:29.037544 34819 sgd_solver.cpp:112] Iteration 72760, lr = 0.01
I0523 07:53:34.395222 34819 solver.cpp:239] Iteration 72770 (1.83944 iter/s, 5.43643s/10 iters), loss = 7.82071
I0523 07:53:34.395362 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82071 (* 1 = 7.82071 loss)
I0523 07:53:34.462962 34819 sgd_solver.cpp:112] Iteration 72770, lr = 0.01
I0523 07:53:36.465009 34819 solver.cpp:239] Iteration 72780 (4.83196 iter/s, 2.06955s/10 iters), loss = 7.7671
I0523 07:53:36.465066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7671 (* 1 = 7.7671 loss)
I0523 07:53:37.020988 34819 sgd_solver.cpp:112] Iteration 72780, lr = 0.01
I0523 07:53:41.023676 34819 solver.cpp:239] Iteration 72790 (2.19374 iter/s, 4.55842s/10 iters), loss = 7.69283
I0523 07:53:41.023725 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69283 (* 1 = 7.69283 loss)
I0523 07:53:41.792619 34819 sgd_solver.cpp:112] Iteration 72790, lr = 0.01
I0523 07:53:46.721141 34819 solver.cpp:239] Iteration 72800 (1.75526 iter/s, 5.69717s/10 iters), loss = 7.40987
I0523 07:53:46.721204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40987 (* 1 = 7.40987 loss)
I0523 07:53:47.396103 34819 sgd_solver.cpp:112] Iteration 72800, lr = 0.01
I0523 07:53:54.270052 34819 solver.cpp:239] Iteration 72810 (1.32476 iter/s, 7.54853s/10 iters), loss = 6.87678
I0523 07:53:54.270108 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.87678 (* 1 = 6.87678 loss)
I0523 07:53:54.516924 34819 sgd_solver.cpp:112] Iteration 72810, lr = 0.01
I0523 07:53:58.908562 34819 solver.cpp:239] Iteration 72820 (2.15598 iter/s, 4.63826s/10 iters), loss = 8.23936
I0523 07:53:58.908609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23936 (* 1 = 8.23936 loss)
I0523 07:53:59.139729 34819 sgd_solver.cpp:112] Iteration 72820, lr = 0.01
I0523 07:54:01.743894 34819 solver.cpp:239] Iteration 72830 (3.52714 iter/s, 2.83516s/10 iters), loss = 7.5158
I0523 07:54:01.743947 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5158 (* 1 = 7.5158 loss)
I0523 07:54:01.804962 34819 sgd_solver.cpp:112] Iteration 72830, lr = 0.01
I0523 07:54:07.544068 34819 solver.cpp:239] Iteration 72840 (1.72417 iter/s, 5.79989s/10 iters), loss = 8.07687
I0523 07:54:07.544247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07687 (* 1 = 8.07687 loss)
I0523 07:54:08.380404 34819 sgd_solver.cpp:112] Iteration 72840, lr = 0.01
I0523 07:54:12.724725 34819 solver.cpp:239] Iteration 72850 (1.9304 iter/s, 5.18026s/10 iters), loss = 7.2086
I0523 07:54:12.724781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2086 (* 1 = 7.2086 loss)
I0523 07:54:13.576086 34819 sgd_solver.cpp:112] Iteration 72850, lr = 0.01
I0523 07:54:17.570487 34819 solver.cpp:239] Iteration 72860 (2.06377 iter/s, 4.84551s/10 iters), loss = 7.18567
I0523 07:54:17.570534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.18567 (* 1 = 7.18567 loss)
I0523 07:54:17.645625 34819 sgd_solver.cpp:112] Iteration 72860, lr = 0.01
I0523 07:54:22.301903 34819 solver.cpp:239] Iteration 72870 (2.11365 iter/s, 4.73115s/10 iters), loss = 8.04955
I0523 07:54:22.301959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04955 (* 1 = 8.04955 loss)
I0523 07:54:22.358377 34819 sgd_solver.cpp:112] Iteration 72870, lr = 0.01
I0523 07:54:25.052242 34819 solver.cpp:239] Iteration 72880 (3.63616 iter/s, 2.75015s/10 iters), loss = 8.01941
I0523 07:54:25.052307 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01941 (* 1 = 8.01941 loss)
I0523 07:54:25.104552 34819 sgd_solver.cpp:112] Iteration 72880, lr = 0.01
I0523 07:54:29.378067 34819 solver.cpp:239] Iteration 72890 (2.31184 iter/s, 4.32557s/10 iters), loss = 8.71772
I0523 07:54:29.378123 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71772 (* 1 = 8.71772 loss)
I0523 07:54:30.188266 34819 sgd_solver.cpp:112] Iteration 72890, lr = 0.01
I0523 07:54:35.847470 34819 solver.cpp:239] Iteration 72900 (1.54582 iter/s, 6.46906s/10 iters), loss = 7.58452
I0523 07:54:35.847532 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58452 (* 1 = 7.58452 loss)
I0523 07:54:36.713922 34819 sgd_solver.cpp:112] Iteration 72900, lr = 0.01
I0523 07:54:41.809195 34819 solver.cpp:239] Iteration 72910 (1.67746 iter/s, 5.96141s/10 iters), loss = 8.63511
I0523 07:54:41.809340 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63511 (* 1 = 8.63511 loss)
I0523 07:54:41.881294 34819 sgd_solver.cpp:112] Iteration 72910, lr = 0.01
I0523 07:54:47.361743 34819 solver.cpp:239] Iteration 72920 (1.80191 iter/s, 5.54966s/10 iters), loss = 8.42622
I0523 07:54:47.361799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42622 (* 1 = 8.42622 loss)
I0523 07:54:47.416649 34819 sgd_solver.cpp:112] Iteration 72920, lr = 0.01
I0523 07:54:51.617732 34819 solver.cpp:239] Iteration 72930 (2.34976 iter/s, 4.25576s/10 iters), loss = 8.14628
I0523 07:54:51.617777 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14628 (* 1 = 8.14628 loss)
I0523 07:54:52.046134 34819 sgd_solver.cpp:112] Iteration 72930, lr = 0.01
I0523 07:54:57.311759 34819 solver.cpp:239] Iteration 72940 (1.75632 iter/s, 5.69373s/10 iters), loss = 7.58369
I0523 07:54:57.311813 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58369 (* 1 = 7.58369 loss)
I0523 07:54:58.178318 34819 sgd_solver.cpp:112] Iteration 72940, lr = 0.01
I0523 07:55:02.818528 34819 solver.cpp:239] Iteration 72950 (1.81604 iter/s, 5.50648s/10 iters), loss = 8.46111
I0523 07:55:02.818573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46111 (* 1 = 8.46111 loss)
I0523 07:55:02.887250 34819 sgd_solver.cpp:112] Iteration 72950, lr = 0.01
I0523 07:55:06.843479 34819 solver.cpp:239] Iteration 72960 (2.48465 iter/s, 4.02472s/10 iters), loss = 7.97941
I0523 07:55:06.843533 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97941 (* 1 = 7.97941 loss)
I0523 07:55:07.701400 34819 sgd_solver.cpp:112] Iteration 72960, lr = 0.01
I0523 07:55:07.751302 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 07:55:13.373558 34819 solver.cpp:239] Iteration 72970 (1.53145 iter/s, 6.52975s/10 iters), loss = 9.20219
I0523 07:55:13.373760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.20219 (* 1 = 9.20219 loss)
I0523 07:55:14.187856 34819 sgd_solver.cpp:112] Iteration 72970, lr = 0.01
I0523 07:55:16.635251 34819 solver.cpp:239] Iteration 72980 (3.06622 iter/s, 3.26135s/10 iters), loss = 8.14444
I0523 07:55:16.635323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14444 (* 1 = 8.14444 loss)
I0523 07:55:16.715718 34819 sgd_solver.cpp:112] Iteration 72980, lr = 0.01
I0523 07:55:19.510634 34819 solver.cpp:239] Iteration 72990 (3.47805 iter/s, 2.87517s/10 iters), loss = 8.26256
I0523 07:55:19.510691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26256 (* 1 = 8.26256 loss)
I0523 07:55:19.568698 34819 sgd_solver.cpp:112] Iteration 72990, lr = 0.01
I0523 07:55:23.494310 34819 solver.cpp:239] Iteration 73000 (2.51039 iter/s, 3.98345s/10 iters), loss = 7.34088
I0523 07:55:23.494351 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.34088 (* 1 = 7.34088 loss)
I0523 07:55:23.554777 34819 sgd_solver.cpp:112] Iteration 73000, lr = 0.01
I0523 07:55:28.548964 34819 solver.cpp:239] Iteration 73010 (1.97848 iter/s, 5.05439s/10 iters), loss = 8.36291
I0523 07:55:28.549019 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36291 (* 1 = 8.36291 loss)
I0523 07:55:29.370252 34819 sgd_solver.cpp:112] Iteration 73010, lr = 0.01
I0523 07:55:36.472570 34819 solver.cpp:239] Iteration 73020 (1.26211 iter/s, 7.92322s/10 iters), loss = 8.01603
I0523 07:55:36.472635 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01603 (* 1 = 8.01603 loss)
I0523 07:55:37.327999 34819 sgd_solver.cpp:112] Iteration 73020, lr = 0.01
I0523 07:55:42.980610 34819 solver.cpp:239] Iteration 73030 (1.53664 iter/s, 6.50771s/10 iters), loss = 7.79416
I0523 07:55:42.980654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79416 (* 1 = 7.79416 loss)
I0523 07:55:43.041503 34819 sgd_solver.cpp:112] Iteration 73030, lr = 0.01
I0523 07:55:47.807418 34819 solver.cpp:239] Iteration 73040 (2.07187 iter/s, 4.82656s/10 iters), loss = 7.00615
I0523 07:55:47.807567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.00615 (* 1 = 7.00615 loss)
I0523 07:55:48.058629 34819 sgd_solver.cpp:112] Iteration 73040, lr = 0.01
I0523 07:55:50.705337 34819 solver.cpp:239] Iteration 73050 (3.45112 iter/s, 2.89761s/10 iters), loss = 7.49156
I0523 07:55:50.705396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.49156 (* 1 = 7.49156 loss)
I0523 07:55:51.513000 34819 sgd_solver.cpp:112] Iteration 73050, lr = 0.01
I0523 07:55:56.170876 34819 solver.cpp:239] Iteration 73060 (1.82974 iter/s, 5.46525s/10 iters), loss = 8.201
I0523 07:55:56.170928 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.201 (* 1 = 8.201 loss)
I0523 07:55:56.886785 34819 sgd_solver.cpp:112] Iteration 73060, lr = 0.01
I0523 07:56:02.036957 34819 solver.cpp:239] Iteration 73070 (1.7048 iter/s, 5.86578s/10 iters), loss = 7.89226
I0523 07:56:02.037001 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89226 (* 1 = 7.89226 loss)
I0523 07:56:02.099123 34819 sgd_solver.cpp:112] Iteration 73070, lr = 0.01
I0523 07:56:09.694433 34819 solver.cpp:239] Iteration 73080 (1.30598 iter/s, 7.65711s/10 iters), loss = 7.73013
I0523 07:56:09.694478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73013 (* 1 = 7.73013 loss)
I0523 07:56:09.755134 34819 sgd_solver.cpp:112] Iteration 73080, lr = 0.01
I0523 07:56:16.894048 34819 solver.cpp:239] Iteration 73090 (1.38903 iter/s, 7.19927s/10 iters), loss = 7.58638
I0523 07:56:16.894093 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58638 (* 1 = 7.58638 loss)
I0523 07:56:16.965060 34819 sgd_solver.cpp:112] Iteration 73090, lr = 0.01
I0523 07:56:23.298718 34819 solver.cpp:239] Iteration 73100 (1.56144 iter/s, 6.40433s/10 iters), loss = 7.3111
I0523 07:56:23.298898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3111 (* 1 = 7.3111 loss)
I0523 07:56:24.125022 34819 sgd_solver.cpp:112] Iteration 73100, lr = 0.01
I0523 07:56:28.522646 34819 solver.cpp:239] Iteration 73110 (1.91441 iter/s, 5.22354s/10 iters), loss = 8.34437
I0523 07:56:28.522737 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34437 (* 1 = 8.34437 loss)
I0523 07:56:29.363687 34819 sgd_solver.cpp:112] Iteration 73110, lr = 0.01
I0523 07:56:32.712643 34819 solver.cpp:239] Iteration 73120 (2.38679 iter/s, 4.18973s/10 iters), loss = 7.51225
I0523 07:56:32.712688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51225 (* 1 = 7.51225 loss)
I0523 07:56:32.771029 34819 sgd_solver.cpp:112] Iteration 73120, lr = 0.01
I0523 07:56:37.815654 34819 solver.cpp:239] Iteration 73130 (1.95973 iter/s, 5.10274s/10 iters), loss = 9.24461
I0523 07:56:37.815708 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.24461 (* 1 = 9.24461 loss)
I0523 07:56:38.643699 34819 sgd_solver.cpp:112] Iteration 73130, lr = 0.01
I0523 07:56:42.028477 34819 solver.cpp:239] Iteration 73140 (2.37384 iter/s, 4.21259s/10 iters), loss = 7.29789
I0523 07:56:42.028527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29789 (* 1 = 7.29789 loss)
I0523 07:56:42.081991 34819 sgd_solver.cpp:112] Iteration 73140, lr = 0.01
I0523 07:56:46.934691 34819 solver.cpp:239] Iteration 73150 (2.04 iter/s, 4.90195s/10 iters), loss = 8.37376
I0523 07:56:46.934784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37376 (* 1 = 8.37376 loss)
I0523 07:56:47.647617 34819 sgd_solver.cpp:112] Iteration 73150, lr = 0.01
I0523 07:56:52.628607 34819 solver.cpp:239] Iteration 73160 (1.75636 iter/s, 5.69359s/10 iters), loss = 8.01679
I0523 07:56:52.628653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01679 (* 1 = 8.01679 loss)
I0523 07:56:52.691802 34819 sgd_solver.cpp:112] Iteration 73160, lr = 0.01
I0523 07:56:56.779680 34819 solver.cpp:239] Iteration 73170 (2.40915 iter/s, 4.15084s/10 iters), loss = 7.02704
I0523 07:56:56.779791 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.02704 (* 1 = 7.02704 loss)
I0523 07:56:56.853040 34819 sgd_solver.cpp:112] Iteration 73170, lr = 0.01
I0523 07:56:59.926097 34819 solver.cpp:239] Iteration 73180 (3.17847 iter/s, 3.14617s/10 iters), loss = 8.13649
I0523 07:56:59.926146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13649 (* 1 = 8.13649 loss)
I0523 07:57:00.000751 34819 sgd_solver.cpp:112] Iteration 73180, lr = 0.01
I0523 07:57:02.665943 34819 solver.cpp:239] Iteration 73190 (3.65009 iter/s, 2.73966s/10 iters), loss = 7.68845
I0523 07:57:02.665997 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68845 (* 1 = 7.68845 loss)
I0523 07:57:03.490278 34819 sgd_solver.cpp:112] Iteration 73190, lr = 0.01
I0523 07:57:07.690584 34819 solver.cpp:239] Iteration 73200 (1.9903 iter/s, 5.02438s/10 iters), loss = 7.27931
I0523 07:57:07.690641 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.27931 (* 1 = 7.27931 loss)
I0523 07:57:07.747483 34819 sgd_solver.cpp:112] Iteration 73200, lr = 0.01
I0523 07:57:11.819670 34819 solver.cpp:239] Iteration 73210 (2.42198 iter/s, 4.12885s/10 iters), loss = 8.20606
I0523 07:57:11.819722 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20606 (* 1 = 8.20606 loss)
I0523 07:57:11.876107 34819 sgd_solver.cpp:112] Iteration 73210, lr = 0.01
I0523 07:57:15.289223 34819 solver.cpp:239] Iteration 73220 (2.88238 iter/s, 3.46935s/10 iters), loss = 7.15357
I0523 07:57:15.289280 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.15357 (* 1 = 7.15357 loss)
I0523 07:57:15.366680 34819 sgd_solver.cpp:112] Iteration 73220, lr = 0.01
I0523 07:57:19.051126 34819 solver.cpp:239] Iteration 73230 (2.65839 iter/s, 3.76168s/10 iters), loss = 7.64513
I0523 07:57:19.051179 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64513 (* 1 = 7.64513 loss)
I0523 07:57:19.807070 34819 sgd_solver.cpp:112] Iteration 73230, lr = 0.01
I0523 07:57:23.732375 34819 solver.cpp:239] Iteration 73240 (2.1363 iter/s, 4.68099s/10 iters), loss = 8.20671
I0523 07:57:23.732431 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20671 (* 1 = 8.20671 loss)
I0523 07:57:23.794293 34819 sgd_solver.cpp:112] Iteration 73240, lr = 0.01
I0523 07:57:27.401381 34819 solver.cpp:239] Iteration 73250 (2.7257 iter/s, 3.66879s/10 iters), loss = 8.4005
I0523 07:57:27.401551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4005 (* 1 = 8.4005 loss)
I0523 07:57:27.471364 34819 sgd_solver.cpp:112] Iteration 73250, lr = 0.01
I0523 07:57:31.262328 34819 solver.cpp:239] Iteration 73260 (2.59026 iter/s, 3.86062s/10 iters), loss = 7.74812
I0523 07:57:31.262375 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74812 (* 1 = 7.74812 loss)
I0523 07:57:31.331022 34819 sgd_solver.cpp:112] Iteration 73260, lr = 0.01
I0523 07:57:36.063709 34819 solver.cpp:239] Iteration 73270 (2.08284 iter/s, 4.80113s/10 iters), loss = 8.20506
I0523 07:57:36.063755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20506 (* 1 = 8.20506 loss)
I0523 07:57:36.131495 34819 sgd_solver.cpp:112] Iteration 73270, lr = 0.01
I0523 07:57:40.076902 34819 solver.cpp:239] Iteration 73280 (2.49192 iter/s, 4.01297s/10 iters), loss = 8.47533
I0523 07:57:40.076953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47533 (* 1 = 8.47533 loss)
I0523 07:57:40.155891 34819 sgd_solver.cpp:112] Iteration 73280, lr = 0.01
I0523 07:57:45.157641 34819 solver.cpp:239] Iteration 73290 (1.96832 iter/s, 5.08048s/10 iters), loss = 7.6164
I0523 07:57:45.157683 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6164 (* 1 = 7.6164 loss)
I0523 07:57:45.230722 34819 sgd_solver.cpp:112] Iteration 73290, lr = 0.01
I0523 07:57:50.187219 34819 solver.cpp:239] Iteration 73300 (1.98834 iter/s, 5.02932s/10 iters), loss = 7.7409
I0523 07:57:50.187263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7409 (* 1 = 7.7409 loss)
I0523 07:57:50.251011 34819 sgd_solver.cpp:112] Iteration 73300, lr = 0.01
I0523 07:57:56.408829 34819 solver.cpp:239] Iteration 73310 (1.60738 iter/s, 6.2213s/10 iters), loss = 8.42146
I0523 07:57:56.408888 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42146 (* 1 = 8.42146 loss)
I0523 07:57:56.991536 34819 sgd_solver.cpp:112] Iteration 73310, lr = 0.01
I0523 07:58:03.140691 34819 solver.cpp:239] Iteration 73320 (1.48555 iter/s, 6.73153s/10 iters), loss = 7.90004
I0523 07:58:03.140938 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90004 (* 1 = 7.90004 loss)
I0523 07:58:03.988147 34819 sgd_solver.cpp:112] Iteration 73320, lr = 0.01
I0523 07:58:08.599484 34819 solver.cpp:239] Iteration 73330 (1.83206 iter/s, 5.45835s/10 iters), loss = 7.72526
I0523 07:58:08.599536 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72526 (* 1 = 7.72526 loss)
I0523 07:58:09.180122 34819 sgd_solver.cpp:112] Iteration 73330, lr = 0.01
I0523 07:58:13.673772 34819 solver.cpp:239] Iteration 73340 (1.97083 iter/s, 5.074s/10 iters), loss = 7.70254
I0523 07:58:13.673844 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70254 (* 1 = 7.70254 loss)
I0523 07:58:14.496950 34819 sgd_solver.cpp:112] Iteration 73340, lr = 0.01
I0523 07:58:18.695897 34819 solver.cpp:239] Iteration 73350 (1.9913 iter/s, 5.02185s/10 iters), loss = 8.44028
I0523 07:58:18.695966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44028 (* 1 = 8.44028 loss)
I0523 07:58:18.761304 34819 sgd_solver.cpp:112] Iteration 73350, lr = 0.01
I0523 07:58:22.758357 34819 solver.cpp:239] Iteration 73360 (2.46171 iter/s, 4.06221s/10 iters), loss = 7.7571
I0523 07:58:22.758404 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7571 (* 1 = 7.7571 loss)
I0523 07:58:22.815584 34819 sgd_solver.cpp:112] Iteration 73360, lr = 0.01
I0523 07:58:25.271091 34819 solver.cpp:239] Iteration 73370 (3.98001 iter/s, 2.51256s/10 iters), loss = 7.81676
I0523 07:58:25.271138 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81676 (* 1 = 7.81676 loss)
I0523 07:58:25.318717 34819 sgd_solver.cpp:112] Iteration 73370, lr = 0.01
I0523 07:58:28.966341 34819 solver.cpp:239] Iteration 73380 (2.70634 iter/s, 3.69503s/10 iters), loss = 8.11369
I0523 07:58:28.966392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11369 (* 1 = 8.11369 loss)
I0523 07:58:29.021814 34819 sgd_solver.cpp:112] Iteration 73380, lr = 0.01
I0523 07:58:32.318089 34819 solver.cpp:239] Iteration 73390 (2.98369 iter/s, 3.35155s/10 iters), loss = 7.59125
I0523 07:58:32.318140 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59125 (* 1 = 7.59125 loss)
I0523 07:58:33.126448 34819 sgd_solver.cpp:112] Iteration 73390, lr = 0.01
I0523 07:58:37.121310 34819 solver.cpp:239] Iteration 73400 (2.08205 iter/s, 4.80296s/10 iters), loss = 6.68926
I0523 07:58:37.121556 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.68926 (* 1 = 6.68926 loss)
I0523 07:58:37.867805 34819 sgd_solver.cpp:112] Iteration 73400, lr = 0.01
I0523 07:58:44.337903 34819 solver.cpp:239] Iteration 73410 (1.3858 iter/s, 7.21607s/10 iters), loss = 7.97527
I0523 07:58:44.337970 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97527 (* 1 = 7.97527 loss)
I0523 07:58:45.170737 34819 sgd_solver.cpp:112] Iteration 73410, lr = 0.01
I0523 07:58:49.387604 34819 solver.cpp:239] Iteration 73420 (1.98044 iter/s, 5.04939s/10 iters), loss = 8.84495
I0523 07:58:49.387665 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84495 (* 1 = 8.84495 loss)
I0523 07:58:49.513957 34819 sgd_solver.cpp:112] Iteration 73420, lr = 0.01
I0523 07:58:54.417234 34819 solver.cpp:239] Iteration 73430 (1.98833 iter/s, 5.02935s/10 iters), loss = 7.64099
I0523 07:58:54.417299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64099 (* 1 = 7.64099 loss)
I0523 07:58:55.119004 34819 sgd_solver.cpp:112] Iteration 73430, lr = 0.01
I0523 07:59:00.858480 34819 solver.cpp:239] Iteration 73440 (1.55257 iter/s, 6.44091s/10 iters), loss = 7.86038
I0523 07:59:00.858537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86038 (* 1 = 7.86038 loss)
I0523 07:59:01.726382 34819 sgd_solver.cpp:112] Iteration 73440, lr = 0.01
I0523 07:59:05.371552 34819 solver.cpp:239] Iteration 73450 (2.21592 iter/s, 4.5128s/10 iters), loss = 8.85507
I0523 07:59:05.371623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85507 (* 1 = 8.85507 loss)
I0523 07:59:05.439651 34819 sgd_solver.cpp:112] Iteration 73450, lr = 0.01
I0523 07:59:10.175243 34819 solver.cpp:239] Iteration 73460 (2.08185 iter/s, 4.80343s/10 iters), loss = 7.00055
I0523 07:59:10.175374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.00055 (* 1 = 7.00055 loss)
I0523 07:59:11.041673 34819 sgd_solver.cpp:112] Iteration 73460, lr = 0.01
I0523 07:59:15.342936 34819 solver.cpp:239] Iteration 73470 (1.93523 iter/s, 5.16734s/10 iters), loss = 7.42111
I0523 07:59:15.342996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42111 (* 1 = 7.42111 loss)
I0523 07:59:16.185117 34819 sgd_solver.cpp:112] Iteration 73470, lr = 0.01
I0523 07:59:20.777124 34819 solver.cpp:239] Iteration 73480 (1.8403 iter/s, 5.43389s/10 iters), loss = 8.11668
I0523 07:59:20.777166 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11668 (* 1 = 8.11668 loss)
I0523 07:59:20.842654 34819 sgd_solver.cpp:112] Iteration 73480, lr = 0.01
I0523 07:59:27.110523 34819 solver.cpp:239] Iteration 73490 (1.57901 iter/s, 6.33309s/10 iters), loss = 7.75141
I0523 07:59:27.110565 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75141 (* 1 = 7.75141 loss)
I0523 07:59:27.966195 34819 sgd_solver.cpp:112] Iteration 73490, lr = 0.01
I0523 07:59:32.256278 34819 solver.cpp:239] Iteration 73500 (1.94345 iter/s, 5.1455s/10 iters), loss = 7.35174
I0523 07:59:32.256335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35174 (* 1 = 7.35174 loss)
I0523 07:59:32.324831 34819 sgd_solver.cpp:112] Iteration 73500, lr = 0.01
I0523 07:59:38.213975 34819 solver.cpp:239] Iteration 73510 (1.67859 iter/s, 5.9574s/10 iters), loss = 7.74707
I0523 07:59:38.214030 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74707 (* 1 = 7.74707 loss)
I0523 07:59:38.290701 34819 sgd_solver.cpp:112] Iteration 73510, lr = 0.01
I0523 07:59:41.655966 34819 solver.cpp:239] Iteration 73520 (2.90547 iter/s, 3.44178s/10 iters), loss = 7.70373
I0523 07:59:41.656160 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70373 (* 1 = 7.70373 loss)
I0523 07:59:42.396600 34819 sgd_solver.cpp:112] Iteration 73520, lr = 0.01
I0523 07:59:45.538240 34819 solver.cpp:239] Iteration 73530 (2.57604 iter/s, 3.88192s/10 iters), loss = 8.17278
I0523 07:59:45.538281 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17278 (* 1 = 8.17278 loss)
I0523 07:59:45.970600 34819 sgd_solver.cpp:112] Iteration 73530, lr = 0.01
I0523 07:59:49.174468 34819 solver.cpp:239] Iteration 73540 (2.75025 iter/s, 3.63603s/10 iters), loss = 7.5349
I0523 07:59:49.174512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5349 (* 1 = 7.5349 loss)
I0523 07:59:50.021531 34819 sgd_solver.cpp:112] Iteration 73540, lr = 0.01
I0523 07:59:56.924196 34819 solver.cpp:239] Iteration 73550 (1.29043 iter/s, 7.74935s/10 iters), loss = 7.47317
I0523 07:59:56.924252 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47317 (* 1 = 7.47317 loss)
I0523 07:59:57.784521 34819 sgd_solver.cpp:112] Iteration 73550, lr = 0.01
I0523 08:00:00.845553 34819 solver.cpp:239] Iteration 73560 (2.55029 iter/s, 3.92113s/10 iters), loss = 7.85902
I0523 08:00:00.845613 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85902 (* 1 = 7.85902 loss)
I0523 08:00:01.714200 34819 sgd_solver.cpp:112] Iteration 73560, lr = 0.01
I0523 08:00:05.328915 34819 solver.cpp:239] Iteration 73570 (2.23059 iter/s, 4.48311s/10 iters), loss = 7.75713
I0523 08:00:05.328969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75713 (* 1 = 7.75713 loss)
I0523 08:00:05.402462 34819 sgd_solver.cpp:112] Iteration 73570, lr = 0.01
I0523 08:00:10.415149 34819 solver.cpp:239] Iteration 73580 (1.96619 iter/s, 5.08597s/10 iters), loss = 8.18912
I0523 08:00:10.415205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.18912 (* 1 = 8.18912 loss)
I0523 08:00:10.981359 34819 sgd_solver.cpp:112] Iteration 73580, lr = 0.01
I0523 08:00:14.264077 34819 solver.cpp:239] Iteration 73590 (2.59827 iter/s, 3.84871s/10 iters), loss = 8.03102
I0523 08:00:14.264219 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03102 (* 1 = 8.03102 loss)
I0523 08:00:15.070498 34819 sgd_solver.cpp:112] Iteration 73590, lr = 0.01
I0523 08:00:19.802556 34819 solver.cpp:239] Iteration 73600 (1.80567 iter/s, 5.53811s/10 iters), loss = 6.87178
I0523 08:00:19.802598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.87178 (* 1 = 6.87178 loss)
I0523 08:00:19.878542 34819 sgd_solver.cpp:112] Iteration 73600, lr = 0.01
I0523 08:00:24.712244 34819 solver.cpp:239] Iteration 73610 (2.0369 iter/s, 4.90943s/10 iters), loss = 7.72869
I0523 08:00:24.712296 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72869 (* 1 = 7.72869 loss)
I0523 08:00:25.397400 34819 sgd_solver.cpp:112] Iteration 73610, lr = 0.01
I0523 08:00:30.084712 34819 solver.cpp:239] Iteration 73620 (1.86144 iter/s, 5.37219s/10 iters), loss = 7.93314
I0523 08:00:30.084758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93314 (* 1 = 7.93314 loss)
I0523 08:00:30.148355 34819 sgd_solver.cpp:112] Iteration 73620, lr = 0.01
I0523 08:00:35.917497 34819 solver.cpp:239] Iteration 73630 (1.71453 iter/s, 5.83249s/10 iters), loss = 7.46697
I0523 08:00:35.917551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46697 (* 1 = 7.46697 loss)
I0523 08:00:35.985494 34819 sgd_solver.cpp:112] Iteration 73630, lr = 0.01
I0523 08:00:42.383469 34819 solver.cpp:239] Iteration 73640 (1.54663 iter/s, 6.46566s/10 iters), loss = 8.16278
I0523 08:00:42.383517 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16278 (* 1 = 8.16278 loss)
I0523 08:00:42.443063 34819 sgd_solver.cpp:112] Iteration 73640, lr = 0.01
I0523 08:00:48.124071 34819 solver.cpp:239] Iteration 73650 (1.74206 iter/s, 5.74032s/10 iters), loss = 7.49554
I0523 08:00:48.124220 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.49554 (* 1 = 7.49554 loss)
I0523 08:00:48.857872 34819 sgd_solver.cpp:112] Iteration 73650, lr = 0.01
I0523 08:00:54.069972 34819 solver.cpp:239] Iteration 73660 (1.68195 iter/s, 5.9455s/10 iters), loss = 7.25703
I0523 08:00:54.070017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.25703 (* 1 = 7.25703 loss)
I0523 08:00:54.128223 34819 sgd_solver.cpp:112] Iteration 73660, lr = 0.01
I0523 08:00:57.711774 34819 solver.cpp:239] Iteration 73670 (2.74605 iter/s, 3.64159s/10 iters), loss = 7.90977
I0523 08:00:57.711828 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90977 (* 1 = 7.90977 loss)
I0523 08:00:57.792927 34819 sgd_solver.cpp:112] Iteration 73670, lr = 0.01
I0523 08:01:02.117513 34819 solver.cpp:239] Iteration 73680 (2.27216 iter/s, 4.4011s/10 iters), loss = 8.44473
I0523 08:01:02.117580 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44473 (* 1 = 8.44473 loss)
I0523 08:01:02.972898 34819 sgd_solver.cpp:112] Iteration 73680, lr = 0.01
I0523 08:01:06.386195 34819 solver.cpp:239] Iteration 73690 (2.34278 iter/s, 4.26843s/10 iters), loss = 7.76988
I0523 08:01:06.386240 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76988 (* 1 = 7.76988 loss)
I0523 08:01:06.451367 34819 sgd_solver.cpp:112] Iteration 73690, lr = 0.01
I0523 08:01:09.867466 34819 solver.cpp:239] Iteration 73700 (2.87269 iter/s, 3.48106s/10 iters), loss = 7.54611
I0523 08:01:09.867527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54611 (* 1 = 7.54611 loss)
I0523 08:01:09.938729 34819 sgd_solver.cpp:112] Iteration 73700, lr = 0.01
I0523 08:01:14.410353 34819 solver.cpp:239] Iteration 73710 (2.20137 iter/s, 4.54262s/10 iters), loss = 7.66644
I0523 08:01:14.410406 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66644 (* 1 = 7.66644 loss)
I0523 08:01:14.483227 34819 sgd_solver.cpp:112] Iteration 73710, lr = 0.01
I0523 08:01:21.980044 34819 solver.cpp:239] Iteration 73720 (1.32112 iter/s, 7.56932s/10 iters), loss = 8.16486
I0523 08:01:21.980204 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16486 (* 1 = 8.16486 loss)
I0523 08:01:22.793910 34819 sgd_solver.cpp:112] Iteration 73720, lr = 0.01
I0523 08:01:25.418176 34819 solver.cpp:239] Iteration 73730 (2.90882 iter/s, 3.43782s/10 iters), loss = 8.34239
I0523 08:01:25.418229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34239 (* 1 = 8.34239 loss)
I0523 08:01:25.486852 34819 sgd_solver.cpp:112] Iteration 73730, lr = 0.01
I0523 08:01:29.638900 34819 solver.cpp:239] Iteration 73740 (2.3694 iter/s, 4.22048s/10 iters), loss = 7.66189
I0523 08:01:29.638945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66189 (* 1 = 7.66189 loss)
I0523 08:01:29.696956 34819 sgd_solver.cpp:112] Iteration 73740, lr = 0.01
I0523 08:01:35.677922 34819 solver.cpp:239] Iteration 73750 (1.65598 iter/s, 6.03872s/10 iters), loss = 7.8081
I0523 08:01:35.677969 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8081 (* 1 = 7.8081 loss)
I0523 08:01:35.736004 34819 sgd_solver.cpp:112] Iteration 73750, lr = 0.01
I0523 08:01:39.239812 34819 solver.cpp:239] Iteration 73760 (2.80767 iter/s, 3.56167s/10 iters), loss = 7.61342
I0523 08:01:39.239874 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61342 (* 1 = 7.61342 loss)
I0523 08:01:39.308668 34819 sgd_solver.cpp:112] Iteration 73760, lr = 0.01
I0523 08:01:43.480614 34819 solver.cpp:239] Iteration 73770 (2.35818 iter/s, 4.24056s/10 iters), loss = 7.87226
I0523 08:01:43.480669 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87226 (* 1 = 7.87226 loss)
I0523 08:01:43.540714 34819 sgd_solver.cpp:112] Iteration 73770, lr = 0.01
I0523 08:01:48.749065 34819 solver.cpp:239] Iteration 73780 (1.8982 iter/s, 5.26816s/10 iters), loss = 8.02968
I0523 08:01:48.749128 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02968 (* 1 = 8.02968 loss)
I0523 08:01:48.817229 34819 sgd_solver.cpp:112] Iteration 73780, lr = 0.01
I0523 08:01:54.484593 34819 solver.cpp:239] Iteration 73790 (1.74361 iter/s, 5.73523s/10 iters), loss = 7.6535
I0523 08:01:54.484877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6535 (* 1 = 7.6535 loss)
I0523 08:01:55.269940 34819 sgd_solver.cpp:112] Iteration 73790, lr = 0.01
I0523 08:02:00.625259 34819 solver.cpp:239] Iteration 73800 (1.62862 iter/s, 6.14015s/10 iters), loss = 7.79697
I0523 08:02:00.625308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79697 (* 1 = 7.79697 loss)
I0523 08:02:01.432734 34819 sgd_solver.cpp:112] Iteration 73800, lr = 0.01
I0523 08:02:06.332154 34819 solver.cpp:239] Iteration 73810 (1.75236 iter/s, 5.7066s/10 iters), loss = 7.86288
I0523 08:02:06.332206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86288 (* 1 = 7.86288 loss)
I0523 08:02:06.405323 34819 sgd_solver.cpp:112] Iteration 73810, lr = 0.01
I0523 08:02:10.406882 34819 solver.cpp:239] Iteration 73820 (2.4543 iter/s, 4.07449s/10 iters), loss = 7.271
I0523 08:02:10.406934 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.271 (* 1 = 7.271 loss)
I0523 08:02:10.477319 34819 sgd_solver.cpp:112] Iteration 73820, lr = 0.01
I0523 08:02:15.856134 34819 solver.cpp:239] Iteration 73830 (1.83521 iter/s, 5.44896s/10 iters), loss = 8.37505
I0523 08:02:15.856189 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37505 (* 1 = 8.37505 loss)
I0523 08:02:15.927657 34819 sgd_solver.cpp:112] Iteration 73830, lr = 0.01
I0523 08:02:19.334411 34819 solver.cpp:239] Iteration 73840 (2.87516 iter/s, 3.47807s/10 iters), loss = 7.89892
I0523 08:02:19.334453 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89892 (* 1 = 7.89892 loss)
I0523 08:02:19.406133 34819 sgd_solver.cpp:112] Iteration 73840, lr = 0.01
I0523 08:02:24.318629 34819 solver.cpp:239] Iteration 73850 (2.00644 iter/s, 4.98396s/10 iters), loss = 6.6843
I0523 08:02:24.318675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.6843 (* 1 = 6.6843 loss)
I0523 08:02:24.902000 34819 sgd_solver.cpp:112] Iteration 73850, lr = 0.01
I0523 08:02:28.551800 34819 solver.cpp:239] Iteration 73860 (2.36242 iter/s, 4.23295s/10 iters), loss = 8.04614
I0523 08:02:28.551843 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04614 (* 1 = 8.04614 loss)
I0523 08:02:29.313756 34819 sgd_solver.cpp:112] Iteration 73860, lr = 0.01
I0523 08:02:34.102432 34819 solver.cpp:239] Iteration 73870 (1.80168 iter/s, 5.55036s/10 iters), loss = 8.35872
I0523 08:02:34.102473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35872 (* 1 = 8.35872 loss)
I0523 08:02:34.179181 34819 sgd_solver.cpp:112] Iteration 73870, lr = 0.01
I0523 08:02:37.893826 34819 solver.cpp:239] Iteration 73880 (2.6377 iter/s, 3.79118s/10 iters), loss = 7.84127
I0523 08:02:37.893879 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84127 (* 1 = 7.84127 loss)
I0523 08:02:38.677848 34819 sgd_solver.cpp:112] Iteration 73880, lr = 0.01
I0523 08:02:44.095561 34819 solver.cpp:239] Iteration 73890 (1.61253 iter/s, 6.20143s/10 iters), loss = 8.06884
I0523 08:02:44.095603 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06884 (* 1 = 8.06884 loss)
I0523 08:02:44.156576 34819 sgd_solver.cpp:112] Iteration 73890, lr = 0.01
I0523 08:02:49.004395 34819 solver.cpp:239] Iteration 73900 (2.03725 iter/s, 4.90859s/10 iters), loss = 7.64303
I0523 08:02:49.004438 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64303 (* 1 = 7.64303 loss)
I0523 08:02:49.062670 34819 sgd_solver.cpp:112] Iteration 73900, lr = 0.01
I0523 08:02:53.144284 34819 solver.cpp:239] Iteration 73910 (2.41565 iter/s, 4.13967s/10 iters), loss = 7.89618
I0523 08:02:53.144326 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89618 (* 1 = 7.89618 loss)
I0523 08:02:53.944412 34819 sgd_solver.cpp:112] Iteration 73910, lr = 0.01
I0523 08:02:57.295166 34819 solver.cpp:239] Iteration 73920 (2.40926 iter/s, 4.15065s/10 iters), loss = 7.65348
I0523 08:02:57.295433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65348 (* 1 = 7.65348 loss)
I0523 08:02:57.362874 34819 sgd_solver.cpp:112] Iteration 73920, lr = 0.01
I0523 08:03:03.895552 34819 solver.cpp:239] Iteration 73930 (1.51518 iter/s, 6.59986s/10 iters), loss = 7.49117
I0523 08:03:03.895622 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.49117 (* 1 = 7.49117 loss)
I0523 08:03:03.950611 34819 sgd_solver.cpp:112] Iteration 73930, lr = 0.01
I0523 08:03:11.193706 34819 solver.cpp:239] Iteration 73940 (1.37028 iter/s, 7.29779s/10 iters), loss = 8.10575
I0523 08:03:11.193765 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10575 (* 1 = 8.10575 loss)
I0523 08:03:11.555433 34819 sgd_solver.cpp:112] Iteration 73940, lr = 0.01
I0523 08:03:17.541190 34819 solver.cpp:239] Iteration 73950 (1.57551 iter/s, 6.34716s/10 iters), loss = 7.68257
I0523 08:03:17.541245 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68257 (* 1 = 7.68257 loss)
I0523 08:03:17.608134 34819 sgd_solver.cpp:112] Iteration 73950, lr = 0.01
I0523 08:03:21.847749 34819 solver.cpp:239] Iteration 73960 (2.32218 iter/s, 4.3063s/10 iters), loss = 7.57213
I0523 08:03:21.847818 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57213 (* 1 = 7.57213 loss)
I0523 08:03:22.709527 34819 sgd_solver.cpp:112] Iteration 73960, lr = 0.01
I0523 08:03:26.841675 34819 solver.cpp:239] Iteration 73970 (2.00255 iter/s, 4.99364s/10 iters), loss = 7.48912
I0523 08:03:26.841747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.48912 (* 1 = 7.48912 loss)
I0523 08:03:27.555702 34819 sgd_solver.cpp:112] Iteration 73970, lr = 0.01
I0523 08:03:33.927557 34819 solver.cpp:239] Iteration 73980 (1.41133 iter/s, 7.0855s/10 iters), loss = 7.19118
I0523 08:03:33.927629 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.19118 (* 1 = 7.19118 loss)
I0523 08:03:34.762033 34819 sgd_solver.cpp:112] Iteration 73980, lr = 0.01
I0523 08:03:39.558174 34819 solver.cpp:239] Iteration 73990 (1.7761 iter/s, 5.63031s/10 iters), loss = 7.19746
I0523 08:03:39.558230 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.19746 (* 1 = 7.19746 loss)
I0523 08:03:39.616122 34819 sgd_solver.cpp:112] Iteration 73990, lr = 0.01
I0523 08:03:41.962155 34819 solver.cpp:239] Iteration 74000 (4.16006 iter/s, 2.40381s/10 iters), loss = 8.43015
I0523 08:03:41.962209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43015 (* 1 = 8.43015 loss)
I0523 08:03:42.046388 34819 sgd_solver.cpp:112] Iteration 74000, lr = 0.01
I0523 08:03:46.819299 34819 solver.cpp:239] Iteration 74010 (2.05893 iter/s, 4.85689s/10 iters), loss = 7.73992
I0523 08:03:46.819353 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73992 (* 1 = 7.73992 loss)
I0523 08:03:47.636386 34819 sgd_solver.cpp:112] Iteration 74010, lr = 0.01
I0523 08:03:51.617372 34819 solver.cpp:239] Iteration 74020 (2.08428 iter/s, 4.79781s/10 iters), loss = 8.5408
I0523 08:03:51.617441 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5408 (* 1 = 8.5408 loss)
I0523 08:03:51.678162 34819 sgd_solver.cpp:112] Iteration 74020, lr = 0.01
I0523 08:03:55.979552 34819 solver.cpp:239] Iteration 74030 (2.29257 iter/s, 4.36192s/10 iters), loss = 7.20552
I0523 08:03:55.979610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20552 (* 1 = 7.20552 loss)
I0523 08:03:56.811930 34819 sgd_solver.cpp:112] Iteration 74030, lr = 0.01
I0523 08:04:02.313767 34819 solver.cpp:239] Iteration 74040 (1.57881 iter/s, 6.33389s/10 iters), loss = 8.36056
I0523 08:04:02.314024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36056 (* 1 = 8.36056 loss)
I0523 08:04:02.374802 34819 sgd_solver.cpp:112] Iteration 74040, lr = 0.01
I0523 08:04:04.990905 34819 solver.cpp:239] Iteration 74050 (3.73583 iter/s, 2.67678s/10 iters), loss = 7.34164
I0523 08:04:04.990950 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.34164 (* 1 = 7.34164 loss)
I0523 08:04:05.863229 34819 sgd_solver.cpp:112] Iteration 74050, lr = 0.01
I0523 08:04:10.661087 34819 solver.cpp:239] Iteration 74060 (1.7638 iter/s, 5.66958s/10 iters), loss = 7.61017
I0523 08:04:10.661150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61017 (* 1 = 7.61017 loss)
I0523 08:04:11.417975 34819 sgd_solver.cpp:112] Iteration 74060, lr = 0.01
I0523 08:04:15.160987 34819 solver.cpp:239] Iteration 74070 (2.2224 iter/s, 4.49964s/10 iters), loss = 8.17337
I0523 08:04:15.161053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17337 (* 1 = 8.17337 loss)
I0523 08:04:15.997426 34819 sgd_solver.cpp:112] Iteration 74070, lr = 0.01
I0523 08:04:20.668969 34819 solver.cpp:239] Iteration 74080 (1.81565 iter/s, 5.50767s/10 iters), loss = 8.52278
I0523 08:04:20.669029 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52278 (* 1 = 8.52278 loss)
I0523 08:04:21.467188 34819 sgd_solver.cpp:112] Iteration 74080, lr = 0.01
I0523 08:04:24.825320 34819 solver.cpp:239] Iteration 74090 (2.40609 iter/s, 4.15611s/10 iters), loss = 7.4187
I0523 08:04:24.825372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4187 (* 1 = 7.4187 loss)
I0523 08:04:24.895583 34819 sgd_solver.cpp:112] Iteration 74090, lr = 0.01
I0523 08:04:30.061733 34819 solver.cpp:239] Iteration 74100 (1.90981 iter/s, 5.23613s/10 iters), loss = 7.8215
I0523 08:04:30.061794 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8215 (* 1 = 7.8215 loss)
I0523 08:04:30.912842 34819 sgd_solver.cpp:112] Iteration 74100, lr = 0.01
I0523 08:04:36.409590 34819 solver.cpp:239] Iteration 74110 (1.57542 iter/s, 6.34753s/10 iters), loss = 7.64468
I0523 08:04:36.409780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64468 (* 1 = 7.64468 loss)
I0523 08:04:37.125068 34819 sgd_solver.cpp:112] Iteration 74110, lr = 0.01
I0523 08:04:41.907965 34819 solver.cpp:239] Iteration 74120 (1.81886 iter/s, 5.49796s/10 iters), loss = 7.304
I0523 08:04:41.908018 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.304 (* 1 = 7.304 loss)
I0523 08:04:42.596099 34819 sgd_solver.cpp:112] Iteration 74120, lr = 0.01
I0523 08:04:47.494175 34819 solver.cpp:239] Iteration 74130 (1.79022 iter/s, 5.58592s/10 iters), loss = 8.06279
I0523 08:04:47.494221 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06279 (* 1 = 8.06279 loss)
I0523 08:04:47.551652 34819 sgd_solver.cpp:112] Iteration 74130, lr = 0.01
I0523 08:04:50.865145 34819 solver.cpp:239] Iteration 74140 (2.96668 iter/s, 3.37077s/10 iters), loss = 7.18373
I0523 08:04:50.865192 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.18373 (* 1 = 7.18373 loss)
I0523 08:04:50.952864 34819 sgd_solver.cpp:112] Iteration 74140, lr = 0.01
I0523 08:04:53.993098 34819 solver.cpp:239] Iteration 74150 (3.19718 iter/s, 3.12776s/10 iters), loss = 7.95473
I0523 08:04:53.993142 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95473 (* 1 = 7.95473 loss)
I0523 08:04:54.785094 34819 sgd_solver.cpp:112] Iteration 74150, lr = 0.01
I0523 08:04:58.195261 34819 solver.cpp:239] Iteration 74160 (2.37985 iter/s, 4.20194s/10 iters), loss = 8.23136
I0523 08:04:58.195312 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23136 (* 1 = 8.23136 loss)
I0523 08:04:58.999411 34819 sgd_solver.cpp:112] Iteration 74160, lr = 0.01
I0523 08:05:04.016358 34819 solver.cpp:239] Iteration 74170 (1.71798 iter/s, 5.8208s/10 iters), loss = 8.0896
I0523 08:05:04.016414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0896 (* 1 = 8.0896 loss)
I0523 08:05:04.839740 34819 sgd_solver.cpp:112] Iteration 74170, lr = 0.01
I0523 08:05:08.000339 34819 solver.cpp:239] Iteration 74180 (2.5102 iter/s, 3.98375s/10 iters), loss = 7.6843
I0523 08:05:08.000527 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6843 (* 1 = 7.6843 loss)
I0523 08:05:08.049608 34819 sgd_solver.cpp:112] Iteration 74180, lr = 0.01
I0523 08:05:11.390519 34819 solver.cpp:239] Iteration 74190 (2.95001 iter/s, 3.38982s/10 iters), loss = 8.28482
I0523 08:05:11.390630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28482 (* 1 = 8.28482 loss)
I0523 08:05:11.933154 34819 sgd_solver.cpp:112] Iteration 74190, lr = 0.01
I0523 08:05:14.682363 34819 solver.cpp:239] Iteration 74200 (3.03804 iter/s, 3.29159s/10 iters), loss = 8.50309
I0523 08:05:14.682433 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.50309 (* 1 = 8.50309 loss)
I0523 08:05:15.477562 34819 sgd_solver.cpp:112] Iteration 74200, lr = 0.01
I0523 08:05:19.201361 34819 solver.cpp:239] Iteration 74210 (2.21301 iter/s, 4.51874s/10 iters), loss = 7.24965
I0523 08:05:19.201418 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.24965 (* 1 = 7.24965 loss)
I0523 08:05:19.268105 34819 sgd_solver.cpp:112] Iteration 74210, lr = 0.01
I0523 08:05:24.239660 34819 solver.cpp:239] Iteration 74220 (1.98491 iter/s, 5.03801s/10 iters), loss = 7.85005
I0523 08:05:24.239715 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85005 (* 1 = 7.85005 loss)
I0523 08:05:25.100117 34819 sgd_solver.cpp:112] Iteration 74220, lr = 0.01
I0523 08:05:29.322396 34819 solver.cpp:239] Iteration 74230 (1.96755 iter/s, 5.08246s/10 iters), loss = 7.44821
I0523 08:05:29.322451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44821 (* 1 = 7.44821 loss)
I0523 08:05:29.391593 34819 sgd_solver.cpp:112] Iteration 74230, lr = 0.01
I0523 08:05:34.014183 34819 solver.cpp:239] Iteration 74240 (2.1315 iter/s, 4.69154s/10 iters), loss = 7.08279
I0523 08:05:34.014225 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.08279 (* 1 = 7.08279 loss)
I0523 08:05:34.670161 34819 sgd_solver.cpp:112] Iteration 74240, lr = 0.01
I0523 08:05:39.376366 34819 solver.cpp:239] Iteration 74250 (1.86501 iter/s, 5.36191s/10 iters), loss = 7.87443
I0523 08:05:39.376526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87443 (* 1 = 7.87443 loss)
I0523 08:05:39.432816 34819 sgd_solver.cpp:112] Iteration 74250, lr = 0.01
I0523 08:05:44.345257 34819 solver.cpp:239] Iteration 74260 (2.01267 iter/s, 4.96852s/10 iters), loss = 7.77366
I0523 08:05:44.345309 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77366 (* 1 = 7.77366 loss)
I0523 08:05:44.401202 34819 sgd_solver.cpp:112] Iteration 74260, lr = 0.01
I0523 08:05:47.751669 34819 solver.cpp:239] Iteration 74270 (2.93582 iter/s, 3.4062s/10 iters), loss = 7.68966
I0523 08:05:47.751729 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68966 (* 1 = 7.68966 loss)
I0523 08:05:48.478049 34819 sgd_solver.cpp:112] Iteration 74270, lr = 0.01
I0523 08:05:52.625134 34819 solver.cpp:239] Iteration 74280 (2.05205 iter/s, 4.87318s/10 iters), loss = 7.93817
I0523 08:05:52.625200 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93817 (* 1 = 7.93817 loss)
I0523 08:05:53.466609 34819 sgd_solver.cpp:112] Iteration 74280, lr = 0.01
I0523 08:05:59.001755 34819 solver.cpp:239] Iteration 74290 (1.56831 iter/s, 6.37628s/10 iters), loss = 8.5111
I0523 08:05:59.001811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.5111 (* 1 = 8.5111 loss)
I0523 08:05:59.060987 34819 sgd_solver.cpp:112] Iteration 74290, lr = 0.01
I0523 08:06:02.792021 34819 solver.cpp:239] Iteration 74300 (2.6385 iter/s, 3.79003s/10 iters), loss = 7.58901
I0523 08:06:02.792073 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58901 (* 1 = 7.58901 loss)
I0523 08:06:02.848866 34819 sgd_solver.cpp:112] Iteration 74300, lr = 0.01
I0523 08:06:08.418843 34819 solver.cpp:239] Iteration 74310 (1.7773 iter/s, 5.62652s/10 iters), loss = 7.21885
I0523 08:06:08.418893 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.21885 (* 1 = 7.21885 loss)
I0523 08:06:09.280726 34819 sgd_solver.cpp:112] Iteration 74310, lr = 0.01
I0523 08:06:14.051715 34819 solver.cpp:239] Iteration 74320 (1.77538 iter/s, 5.63259s/10 iters), loss = 8.16883
I0523 08:06:14.051884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16883 (* 1 = 8.16883 loss)
I0523 08:06:14.121827 34819 sgd_solver.cpp:112] Iteration 74320, lr = 0.01
I0523 08:06:19.422922 34819 solver.cpp:239] Iteration 74330 (1.86192 iter/s, 5.37081s/10 iters), loss = 7.73063
I0523 08:06:19.422966 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73063 (* 1 = 7.73063 loss)
I0523 08:06:19.502378 34819 sgd_solver.cpp:112] Iteration 74330, lr = 0.01
I0523 08:06:24.553519 34819 solver.cpp:239] Iteration 74340 (1.94919 iter/s, 5.13033s/10 iters), loss = 7.82245
I0523 08:06:24.553561 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82245 (* 1 = 7.82245 loss)
I0523 08:06:24.610144 34819 sgd_solver.cpp:112] Iteration 74340, lr = 0.01
I0523 08:06:29.398411 34819 solver.cpp:239] Iteration 74350 (2.06413 iter/s, 4.84465s/10 iters), loss = 7.8197
I0523 08:06:29.398456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8197 (* 1 = 7.8197 loss)
I0523 08:06:29.458685 34819 sgd_solver.cpp:112] Iteration 74350, lr = 0.01
I0523 08:06:32.034942 34819 solver.cpp:239] Iteration 74360 (3.7931 iter/s, 2.63636s/10 iters), loss = 8.1151
I0523 08:06:32.034981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1151 (* 1 = 8.1151 loss)
I0523 08:06:32.096822 34819 sgd_solver.cpp:112] Iteration 74360, lr = 0.01
I0523 08:06:37.706324 34819 solver.cpp:239] Iteration 74370 (1.76333 iter/s, 5.6711s/10 iters), loss = 8.06318
I0523 08:06:37.706369 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06318 (* 1 = 8.06318 loss)
I0523 08:06:37.785017 34819 sgd_solver.cpp:112] Iteration 74370, lr = 0.01
I0523 08:06:42.243201 34819 solver.cpp:239] Iteration 74380 (2.20427 iter/s, 4.53665s/10 iters), loss = 8.16648
I0523 08:06:42.243244 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16648 (* 1 = 8.16648 loss)
I0523 08:06:42.314574 34819 sgd_solver.cpp:112] Iteration 74380, lr = 0.01
I0523 08:06:48.608662 34819 solver.cpp:239] Iteration 74390 (1.57154 iter/s, 6.3632s/10 iters), loss = 7.51339
I0523 08:06:48.608798 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51339 (* 1 = 7.51339 loss)
I0523 08:06:48.668651 34819 sgd_solver.cpp:112] Iteration 74390, lr = 0.01
I0523 08:06:53.732287 34819 solver.cpp:239] Iteration 74400 (1.95238 iter/s, 5.12195s/10 iters), loss = 8.34418
I0523 08:06:53.732331 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34418 (* 1 = 8.34418 loss)
I0523 08:06:54.189267 34819 sgd_solver.cpp:112] Iteration 74400, lr = 0.01
I0523 08:06:58.357604 34819 solver.cpp:239] Iteration 74410 (2.16214 iter/s, 4.62506s/10 iters), loss = 8.71453
I0523 08:06:58.357666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71453 (* 1 = 8.71453 loss)
I0523 08:06:58.614325 34819 sgd_solver.cpp:112] Iteration 74410, lr = 0.01
I0523 08:07:03.739480 34819 solver.cpp:239] Iteration 74420 (1.85819 iter/s, 5.38159s/10 iters), loss = 8.08125
I0523 08:07:03.739531 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08125 (* 1 = 8.08125 loss)
I0523 08:07:03.802834 34819 sgd_solver.cpp:112] Iteration 74420, lr = 0.01
I0523 08:07:07.257447 34819 solver.cpp:239] Iteration 74430 (2.84272 iter/s, 3.51776s/10 iters), loss = 8.70078
I0523 08:07:07.257493 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.70078 (* 1 = 8.70078 loss)
I0523 08:07:07.324506 34819 sgd_solver.cpp:112] Iteration 74430, lr = 0.01
I0523 08:07:11.436601 34819 solver.cpp:239] Iteration 74440 (2.39297 iter/s, 4.17891s/10 iters), loss = 7.26431
I0523 08:07:11.436668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26431 (* 1 = 7.26431 loss)
I0523 08:07:11.583194 34819 sgd_solver.cpp:112] Iteration 74440, lr = 0.01
I0523 08:07:14.604754 34819 solver.cpp:239] Iteration 74450 (3.15661 iter/s, 3.16795s/10 iters), loss = 7.96672
I0523 08:07:14.604802 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96672 (* 1 = 7.96672 loss)
I0523 08:07:14.682059 34819 sgd_solver.cpp:112] Iteration 74450, lr = 0.01
I0523 08:07:18.339840 34819 solver.cpp:239] Iteration 74460 (2.67747 iter/s, 3.73487s/10 iters), loss = 7.55849
I0523 08:07:18.339903 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55849 (* 1 = 7.55849 loss)
I0523 08:07:18.408872 34819 sgd_solver.cpp:112] Iteration 74460, lr = 0.01
I0523 08:07:22.062793 34819 solver.cpp:239] Iteration 74470 (2.6862 iter/s, 3.72273s/10 iters), loss = 7.97448
I0523 08:07:22.062954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97448 (* 1 = 7.97448 loss)
I0523 08:07:22.125268 34819 sgd_solver.cpp:112] Iteration 74470, lr = 0.01
I0523 08:07:26.167534 34819 solver.cpp:239] Iteration 74480 (2.43641 iter/s, 4.10439s/10 iters), loss = 7.09856
I0523 08:07:26.167593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.09856 (* 1 = 7.09856 loss)
I0523 08:07:26.231143 34819 sgd_solver.cpp:112] Iteration 74480, lr = 0.01
I0523 08:07:28.021780 34819 solver.cpp:239] Iteration 74490 (5.39345 iter/s, 1.8541s/10 iters), loss = 7.17931
I0523 08:07:28.021826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.17931 (* 1 = 7.17931 loss)
I0523 08:07:28.888458 34819 sgd_solver.cpp:112] Iteration 74490, lr = 0.01
I0523 08:07:34.295776 34819 solver.cpp:239] Iteration 74500 (1.59396 iter/s, 6.27369s/10 iters), loss = 7.29002
I0523 08:07:34.295830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29002 (* 1 = 7.29002 loss)
I0523 08:07:34.372905 34819 sgd_solver.cpp:112] Iteration 74500, lr = 0.01
I0523 08:07:39.035197 34819 solver.cpp:239] Iteration 74510 (2.11007 iter/s, 4.73917s/10 iters), loss = 7.74027
I0523 08:07:39.035248 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74027 (* 1 = 7.74027 loss)
I0523 08:07:39.090958 34819 sgd_solver.cpp:112] Iteration 74510, lr = 0.01
I0523 08:07:44.648591 34819 solver.cpp:239] Iteration 74520 (1.78156 iter/s, 5.61307s/10 iters), loss = 8.3317
I0523 08:07:44.648645 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3317 (* 1 = 8.3317 loss)
I0523 08:07:45.461093 34819 sgd_solver.cpp:112] Iteration 74520, lr = 0.01
I0523 08:07:50.569599 34819 solver.cpp:239] Iteration 74530 (1.68899 iter/s, 5.92071s/10 iters), loss = 8.42836
I0523 08:07:50.569653 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42836 (* 1 = 8.42836 loss)
I0523 08:07:50.632586 34819 sgd_solver.cpp:112] Iteration 74530, lr = 0.01
I0523 08:07:54.010644 34819 solver.cpp:239] Iteration 74540 (2.90627 iter/s, 3.44084s/10 iters), loss = 8.3855
I0523 08:07:54.011384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.3855 (* 1 = 8.3855 loss)
I0523 08:07:54.834715 34819 sgd_solver.cpp:112] Iteration 74540, lr = 0.01
I0523 08:08:00.540913 34819 solver.cpp:239] Iteration 74550 (1.53157 iter/s, 6.52926s/10 iters), loss = 7.63833
I0523 08:08:00.540971 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63833 (* 1 = 7.63833 loss)
I0523 08:08:00.720561 34819 sgd_solver.cpp:112] Iteration 74550, lr = 0.01
I0523 08:08:04.829906 34819 solver.cpp:239] Iteration 74560 (2.33168 iter/s, 4.28875s/10 iters), loss = 7.28982
I0523 08:08:04.829948 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28982 (* 1 = 7.28982 loss)
I0523 08:08:04.887132 34819 sgd_solver.cpp:112] Iteration 74560, lr = 0.01
I0523 08:08:11.047075 34819 solver.cpp:239] Iteration 74570 (1.60853 iter/s, 6.21686s/10 iters), loss = 7.13747
I0523 08:08:11.047121 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13747 (* 1 = 7.13747 loss)
I0523 08:08:11.120420 34819 sgd_solver.cpp:112] Iteration 74570, lr = 0.01
I0523 08:08:14.714591 34819 solver.cpp:239] Iteration 74580 (2.72679 iter/s, 3.66731s/10 iters), loss = 7.09204
I0523 08:08:14.714649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.09204 (* 1 = 7.09204 loss)
I0523 08:08:14.782269 34819 sgd_solver.cpp:112] Iteration 74580, lr = 0.01
I0523 08:08:20.080770 34819 solver.cpp:239] Iteration 74590 (1.86362 iter/s, 5.36589s/10 iters), loss = 7.13103
I0523 08:08:20.080826 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13103 (* 1 = 7.13103 loss)
I0523 08:08:20.143121 34819 sgd_solver.cpp:112] Iteration 74590, lr = 0.01
I0523 08:08:25.906291 34819 solver.cpp:239] Iteration 74600 (1.71667 iter/s, 5.82522s/10 iters), loss = 7.81271
I0523 08:08:25.906478 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81271 (* 1 = 7.81271 loss)
I0523 08:08:26.744957 34819 sgd_solver.cpp:112] Iteration 74600, lr = 0.01
I0523 08:08:30.674479 34819 solver.cpp:239] Iteration 74610 (2.0974 iter/s, 4.7678s/10 iters), loss = 8.00417
I0523 08:08:30.674545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00417 (* 1 = 8.00417 loss)
I0523 08:08:31.459643 34819 sgd_solver.cpp:112] Iteration 74610, lr = 0.01
I0523 08:08:37.190593 34819 solver.cpp:239] Iteration 74620 (1.53474 iter/s, 6.51578s/10 iters), loss = 8.31694
I0523 08:08:37.190637 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31694 (* 1 = 8.31694 loss)
I0523 08:08:37.327705 34819 sgd_solver.cpp:112] Iteration 74620, lr = 0.01
I0523 08:08:40.059787 34819 solver.cpp:239] Iteration 74630 (3.48551 iter/s, 2.86902s/10 iters), loss = 8.14215
I0523 08:08:40.059849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14215 (* 1 = 8.14215 loss)
I0523 08:08:40.358165 34819 sgd_solver.cpp:112] Iteration 74630, lr = 0.01
I0523 08:08:44.306586 34819 solver.cpp:239] Iteration 74640 (2.35486 iter/s, 4.24653s/10 iters), loss = 7.67256
I0523 08:08:44.306654 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67256 (* 1 = 7.67256 loss)
I0523 08:08:45.165673 34819 sgd_solver.cpp:112] Iteration 74640, lr = 0.01
I0523 08:08:49.879680 34819 solver.cpp:239] Iteration 74650 (1.79443 iter/s, 5.5728s/10 iters), loss = 7.76093
I0523 08:08:49.879734 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76093 (* 1 = 7.76093 loss)
I0523 08:08:49.936571 34819 sgd_solver.cpp:112] Iteration 74650, lr = 0.01
I0523 08:08:54.079026 34819 solver.cpp:239] Iteration 74660 (2.38145 iter/s, 4.19912s/10 iters), loss = 7.41332
I0523 08:08:54.079074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41332 (* 1 = 7.41332 loss)
I0523 08:08:54.159889 34819 sgd_solver.cpp:112] Iteration 74660, lr = 0.01
I0523 08:08:57.876024 34819 solver.cpp:239] Iteration 74670 (2.63382 iter/s, 3.79677s/10 iters), loss = 8.14632
I0523 08:08:57.876267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14632 (* 1 = 8.14632 loss)
I0523 08:08:57.945103 34819 sgd_solver.cpp:112] Iteration 74670, lr = 0.01
I0523 08:09:02.897971 34819 solver.cpp:239] Iteration 74680 (1.99143 iter/s, 5.02151s/10 iters), loss = 7.75458
I0523 08:09:02.898025 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75458 (* 1 = 7.75458 loss)
I0523 08:09:03.764262 34819 sgd_solver.cpp:112] Iteration 74680, lr = 0.01
I0523 08:09:10.268499 34819 solver.cpp:239] Iteration 74690 (1.35682 iter/s, 7.37016s/10 iters), loss = 8.27568
I0523 08:09:10.268559 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27568 (* 1 = 8.27568 loss)
I0523 08:09:11.092540 34819 sgd_solver.cpp:112] Iteration 74690, lr = 0.01
I0523 08:09:15.077729 34819 solver.cpp:239] Iteration 74700 (2.07945 iter/s, 4.80897s/10 iters), loss = 7.91758
I0523 08:09:15.077774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91758 (* 1 = 7.91758 loss)
I0523 08:09:15.580116 34819 sgd_solver.cpp:112] Iteration 74700, lr = 0.01
I0523 08:09:21.318058 34819 solver.cpp:239] Iteration 74710 (1.60256 iter/s, 6.24003s/10 iters), loss = 7.38792
I0523 08:09:21.318100 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38792 (* 1 = 7.38792 loss)
I0523 08:09:22.176569 34819 sgd_solver.cpp:112] Iteration 74710, lr = 0.01
I0523 08:09:25.013058 34819 solver.cpp:239] Iteration 74720 (2.70651 iter/s, 3.6948s/10 iters), loss = 8.14982
I0523 08:09:25.013101 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14982 (* 1 = 8.14982 loss)
I0523 08:09:25.842582 34819 sgd_solver.cpp:112] Iteration 74720, lr = 0.01
I0523 08:09:30.390584 34819 solver.cpp:239] Iteration 74730 (1.85968 iter/s, 5.37726s/10 iters), loss = 7.56117
I0523 08:09:30.390807 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56117 (* 1 = 7.56117 loss)
I0523 08:09:30.472760 34819 sgd_solver.cpp:112] Iteration 74730, lr = 0.01
I0523 08:09:35.117806 34819 solver.cpp:239] Iteration 74740 (2.11559 iter/s, 4.72681s/10 iters), loss = 7.27162
I0523 08:09:35.117867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.27162 (* 1 = 7.27162 loss)
I0523 08:09:35.186957 34819 sgd_solver.cpp:112] Iteration 74740, lr = 0.01
I0523 08:09:39.817340 34819 solver.cpp:239] Iteration 74750 (2.128 iter/s, 4.69925s/10 iters), loss = 7.38641
I0523 08:09:39.817404 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38641 (* 1 = 7.38641 loss)
I0523 08:09:40.578970 34819 sgd_solver.cpp:112] Iteration 74750, lr = 0.01
I0523 08:09:43.707561 34819 solver.cpp:239] Iteration 74760 (2.5707 iter/s, 3.88999s/10 iters), loss = 7.30622
I0523 08:09:43.707612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.30622 (* 1 = 7.30622 loss)
I0523 08:09:43.764324 34819 sgd_solver.cpp:112] Iteration 74760, lr = 0.01
I0523 08:09:47.010093 34819 solver.cpp:239] Iteration 74770 (3.02816 iter/s, 3.30233s/10 iters), loss = 7.41472
I0523 08:09:47.010151 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41472 (* 1 = 7.41472 loss)
I0523 08:09:47.875988 34819 sgd_solver.cpp:112] Iteration 74770, lr = 0.01
I0523 08:09:52.801304 34819 solver.cpp:239] Iteration 74780 (1.72684 iter/s, 5.79092s/10 iters), loss = 7.67893
I0523 08:09:52.801348 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67893 (* 1 = 7.67893 loss)
I0523 08:09:53.614840 34819 sgd_solver.cpp:112] Iteration 74780, lr = 0.01
I0523 08:09:59.409504 34819 solver.cpp:239] Iteration 74790 (1.51334 iter/s, 6.60789s/10 iters), loss = 8.08418
I0523 08:09:59.409555 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08418 (* 1 = 8.08418 loss)
I0523 08:09:59.468201 34819 sgd_solver.cpp:112] Iteration 74790, lr = 0.01
I0523 08:10:04.992027 34819 solver.cpp:239] Iteration 74800 (1.7914 iter/s, 5.58224s/10 iters), loss = 7.50111
I0523 08:10:04.992169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50111 (* 1 = 7.50111 loss)
I0523 08:10:05.058859 34819 sgd_solver.cpp:112] Iteration 74800, lr = 0.01
I0523 08:10:09.309345 34819 solver.cpp:239] Iteration 74810 (2.31643 iter/s, 4.31699s/10 iters), loss = 7.68647
I0523 08:10:09.309408 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68647 (* 1 = 7.68647 loss)
I0523 08:10:10.123855 34819 sgd_solver.cpp:112] Iteration 74810, lr = 0.01
I0523 08:10:14.833226 34819 solver.cpp:239] Iteration 74820 (1.81042 iter/s, 5.52358s/10 iters), loss = 7.45454
I0523 08:10:14.833292 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.45454 (* 1 = 7.45454 loss)
I0523 08:10:15.589834 34819 sgd_solver.cpp:112] Iteration 74820, lr = 0.01
I0523 08:10:20.942836 34819 solver.cpp:239] Iteration 74830 (1.63685 iter/s, 6.10929s/10 iters), loss = 7.57419
I0523 08:10:20.942898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57419 (* 1 = 7.57419 loss)
I0523 08:10:21.780771 34819 sgd_solver.cpp:112] Iteration 74830, lr = 0.01
I0523 08:10:25.532117 34819 solver.cpp:239] Iteration 74840 (2.17911 iter/s, 4.58902s/10 iters), loss = 8.62949
I0523 08:10:25.532160 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62949 (* 1 = 8.62949 loss)
I0523 08:10:26.354255 34819 sgd_solver.cpp:112] Iteration 74840, lr = 0.01
I0523 08:10:31.551825 34819 solver.cpp:239] Iteration 74850 (1.66129 iter/s, 6.01941s/10 iters), loss = 7.33558
I0523 08:10:31.551868 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33558 (* 1 = 7.33558 loss)
I0523 08:10:31.622696 34819 sgd_solver.cpp:112] Iteration 74850, lr = 0.01
I0523 08:10:36.858136 34819 solver.cpp:239] Iteration 74860 (1.88464 iter/s, 5.30604s/10 iters), loss = 8.83069
I0523 08:10:36.858453 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.83069 (* 1 = 8.83069 loss)
I0523 08:10:36.919260 34819 sgd_solver.cpp:112] Iteration 74860, lr = 0.01
I0523 08:10:41.526607 34819 solver.cpp:239] Iteration 74870 (2.14226 iter/s, 4.66797s/10 iters), loss = 7.79333
I0523 08:10:41.526677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79333 (* 1 = 7.79333 loss)
I0523 08:10:42.225582 34819 sgd_solver.cpp:112] Iteration 74870, lr = 0.01
I0523 08:10:47.443264 34819 solver.cpp:239] Iteration 74880 (1.69024 iter/s, 5.91633s/10 iters), loss = 7.50794
I0523 08:10:47.443317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50794 (* 1 = 7.50794 loss)
I0523 08:10:48.241506 34819 sgd_solver.cpp:112] Iteration 74880, lr = 0.01
I0523 08:10:52.949261 34819 solver.cpp:239] Iteration 74890 (1.8163 iter/s, 5.50569s/10 iters), loss = 9.01485
I0523 08:10:52.949331 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.01485 (* 1 = 9.01485 loss)
I0523 08:10:53.791597 34819 sgd_solver.cpp:112] Iteration 74890, lr = 0.01
I0523 08:10:58.160333 34819 solver.cpp:239] Iteration 74900 (1.9191 iter/s, 5.21077s/10 iters), loss = 7.78685
I0523 08:10:58.160388 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78685 (* 1 = 7.78685 loss)
I0523 08:10:58.233079 34819 sgd_solver.cpp:112] Iteration 74900, lr = 0.01
I0523 08:11:02.997558 34819 solver.cpp:239] Iteration 74910 (2.06741 iter/s, 4.83697s/10 iters), loss = 8.53579
I0523 08:11:02.997612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53579 (* 1 = 8.53579 loss)
I0523 08:11:03.774260 34819 sgd_solver.cpp:112] Iteration 74910, lr = 0.01
I0523 08:11:06.417430 34819 solver.cpp:239] Iteration 74920 (2.92429 iter/s, 3.41964s/10 iters), loss = 8.05953
I0523 08:11:06.417496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05953 (* 1 = 8.05953 loss)
I0523 08:11:07.280606 34819 sgd_solver.cpp:112] Iteration 74920, lr = 0.01
I0523 08:11:12.628026 34819 solver.cpp:239] Iteration 74930 (1.61024 iter/s, 6.21025s/10 iters), loss = 6.87092
I0523 08:11:12.628083 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.87092 (* 1 = 6.87092 loss)
I0523 08:11:13.515504 34819 sgd_solver.cpp:112] Iteration 74930, lr = 0.01
I0523 08:11:19.304980 34819 solver.cpp:239] Iteration 74940 (1.49776 iter/s, 6.67662s/10 iters), loss = 8.22854
I0523 08:11:19.305035 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.22854 (* 1 = 8.22854 loss)
I0523 08:11:20.114003 34819 sgd_solver.cpp:112] Iteration 74940, lr = 0.01
I0523 08:11:24.249236 34819 solver.cpp:239] Iteration 74950 (2.02266 iter/s, 4.94399s/10 iters), loss = 8.68356
I0523 08:11:24.249290 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68356 (* 1 = 8.68356 loss)
I0523 08:11:24.318907 34819 sgd_solver.cpp:112] Iteration 74950, lr = 0.01
I0523 08:11:29.174106 34819 solver.cpp:239] Iteration 74960 (2.03062 iter/s, 4.9246s/10 iters), loss = 7.41841
I0523 08:11:29.174156 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41841 (* 1 = 7.41841 loss)
I0523 08:11:29.239851 34819 sgd_solver.cpp:112] Iteration 74960, lr = 0.01
I0523 08:11:32.608280 34819 solver.cpp:239] Iteration 74970 (2.91208 iter/s, 3.43397s/10 iters), loss = 8.6383
I0523 08:11:32.608325 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6383 (* 1 = 8.6383 loss)
I0523 08:11:33.392007 34819 sgd_solver.cpp:112] Iteration 74970, lr = 0.01
I0523 08:11:35.985738 34819 solver.cpp:239] Iteration 74980 (2.96098 iter/s, 3.37726s/10 iters), loss = 8.99677
I0523 08:11:35.985781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99677 (* 1 = 8.99677 loss)
I0523 08:11:36.051992 34819 sgd_solver.cpp:112] Iteration 74980, lr = 0.01
I0523 08:11:42.048004 34819 solver.cpp:239] Iteration 74990 (1.64963 iter/s, 6.06196s/10 iters), loss = 7.78973
I0523 08:11:42.048194 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78973 (* 1 = 7.78973 loss)
I0523 08:11:42.113719 34819 sgd_solver.cpp:112] Iteration 74990, lr = 0.01
I0523 08:11:46.718144 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_75000.caffemodel
I0523 08:11:50.855785 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_75000.solverstate
I0523 08:11:51.130069 34819 solver.cpp:239] Iteration 75000 (1.10114 iter/s, 9.08152s/10 iters), loss = 7.2513
I0523 08:11:51.130117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2513 (* 1 = 7.2513 loss)
I0523 08:11:51.777653 34819 sgd_solver.cpp:112] Iteration 75000, lr = 0.01
I0523 08:11:57.382722 34819 solver.cpp:239] Iteration 75010 (1.5994 iter/s, 6.25234s/10 iters), loss = 7.58119
I0523 08:11:57.382766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58119 (* 1 = 7.58119 loss)
I0523 08:11:57.453908 34819 sgd_solver.cpp:112] Iteration 75010, lr = 0.01
I0523 08:12:02.940871 34819 solver.cpp:239] Iteration 75020 (1.79925 iter/s, 5.55788s/10 iters), loss = 7.61943
I0523 08:12:02.940917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61943 (* 1 = 7.61943 loss)
I0523 08:12:03.022503 34819 sgd_solver.cpp:112] Iteration 75020, lr = 0.01
I0523 08:12:06.247897 34819 solver.cpp:239] Iteration 75030 (3.02405 iter/s, 3.30682s/10 iters), loss = 8.13179
I0523 08:12:06.247956 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13179 (* 1 = 8.13179 loss)
I0523 08:12:06.316417 34819 sgd_solver.cpp:112] Iteration 75030, lr = 0.01
I0523 08:12:11.186331 34819 solver.cpp:239] Iteration 75040 (2.02505 iter/s, 4.93814s/10 iters), loss = 8.08221
I0523 08:12:11.186395 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08221 (* 1 = 8.08221 loss)
I0523 08:12:12.076632 34819 sgd_solver.cpp:112] Iteration 75040, lr = 0.01
I0523 08:12:16.023573 34819 solver.cpp:239] Iteration 75050 (2.06741 iter/s, 4.83698s/10 iters), loss = 7.78906
I0523 08:12:16.023633 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78906 (* 1 = 7.78906 loss)
I0523 08:12:16.088377 34819 sgd_solver.cpp:112] Iteration 75050, lr = 0.01
I0523 08:12:20.291229 34819 solver.cpp:239] Iteration 75060 (2.34335 iter/s, 4.2674s/10 iters), loss = 8.26109
I0523 08:12:20.291270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26109 (* 1 = 8.26109 loss)
I0523 08:12:20.351085 34819 sgd_solver.cpp:112] Iteration 75060, lr = 0.01
I0523 08:12:25.170029 34819 solver.cpp:239] Iteration 75070 (2.0498 iter/s, 4.87853s/10 iters), loss = 8.54634
I0523 08:12:25.170097 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54634 (* 1 = 8.54634 loss)
I0523 08:12:25.770030 34819 sgd_solver.cpp:112] Iteration 75070, lr = 0.01
I0523 08:12:28.695549 34819 solver.cpp:239] Iteration 75080 (2.83665 iter/s, 3.52529s/10 iters), loss = 7.80459
I0523 08:12:28.695616 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80459 (* 1 = 7.80459 loss)
I0523 08:12:29.471663 34819 sgd_solver.cpp:112] Iteration 75080, lr = 0.01
I0523 08:12:34.289065 34819 solver.cpp:239] Iteration 75090 (1.78788 iter/s, 5.59321s/10 iters), loss = 7.90736
I0523 08:12:34.289129 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90736 (* 1 = 7.90736 loss)
I0523 08:12:35.148708 34819 sgd_solver.cpp:112] Iteration 75090, lr = 0.01
I0523 08:12:40.005333 34819 solver.cpp:239] Iteration 75100 (1.74949 iter/s, 5.71596s/10 iters), loss = 7.43348
I0523 08:12:40.005385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.43348 (* 1 = 7.43348 loss)
I0523 08:12:40.068202 34819 sgd_solver.cpp:112] Iteration 75100, lr = 0.01
I0523 08:12:43.936983 34819 solver.cpp:239] Iteration 75110 (2.54362 iter/s, 3.93141s/10 iters), loss = 6.98118
I0523 08:12:43.937180 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.98118 (* 1 = 6.98118 loss)
I0523 08:12:44.764924 34819 sgd_solver.cpp:112] Iteration 75110, lr = 0.01
I0523 08:12:51.612289 34819 solver.cpp:239] Iteration 75120 (1.30296 iter/s, 7.67481s/10 iters), loss = 9.11031
I0523 08:12:51.612334 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11031 (* 1 = 9.11031 loss)
I0523 08:12:52.126271 34819 sgd_solver.cpp:112] Iteration 75120, lr = 0.01
I0523 08:12:56.058352 34819 solver.cpp:239] Iteration 75130 (2.2493 iter/s, 4.44583s/10 iters), loss = 7.48542
I0523 08:12:56.058414 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.48542 (* 1 = 7.48542 loss)
I0523 08:12:56.117882 34819 sgd_solver.cpp:112] Iteration 75130, lr = 0.01
I0523 08:12:58.910760 34819 solver.cpp:239] Iteration 75140 (3.50616 iter/s, 2.85212s/10 iters), loss = 8.23755
I0523 08:12:58.910841 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23755 (* 1 = 8.23755 loss)
I0523 08:12:59.310962 34819 sgd_solver.cpp:112] Iteration 75140, lr = 0.01
I0523 08:13:04.814051 34819 solver.cpp:239] Iteration 75150 (1.69407 iter/s, 5.90296s/10 iters), loss = 8.14666
I0523 08:13:04.814102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14666 (* 1 = 8.14666 loss)
I0523 08:13:04.877334 34819 sgd_solver.cpp:112] Iteration 75150, lr = 0.01
I0523 08:13:10.356552 34819 solver.cpp:239] Iteration 75160 (1.80433 iter/s, 5.54222s/10 iters), loss = 8.66977
I0523 08:13:10.356601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66977 (* 1 = 8.66977 loss)
I0523 08:13:10.442235 34819 sgd_solver.cpp:112] Iteration 75160, lr = 0.01
I0523 08:13:15.748361 34819 solver.cpp:239] Iteration 75170 (1.85476 iter/s, 5.39153s/10 iters), loss = 7.88276
I0523 08:13:15.748515 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88276 (* 1 = 7.88276 loss)
I0523 08:13:15.799118 34819 sgd_solver.cpp:112] Iteration 75170, lr = 0.01
I0523 08:13:20.760504 34819 solver.cpp:239] Iteration 75180 (1.9953 iter/s, 5.01178s/10 iters), loss = 7.89429
I0523 08:13:20.760562 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89429 (* 1 = 7.89429 loss)
I0523 08:13:20.823848 34819 sgd_solver.cpp:112] Iteration 75180, lr = 0.01
I0523 08:13:23.744032 34819 solver.cpp:239] Iteration 75190 (3.35196 iter/s, 2.98333s/10 iters), loss = 7.55467
I0523 08:13:23.744084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55467 (* 1 = 7.55467 loss)
I0523 08:13:24.549010 34819 sgd_solver.cpp:112] Iteration 75190, lr = 0.01
I0523 08:13:29.639184 34819 solver.cpp:239] Iteration 75200 (1.6964 iter/s, 5.89483s/10 iters), loss = 7.17674
I0523 08:13:29.639278 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.17674 (* 1 = 7.17674 loss)
I0523 08:13:30.513914 34819 sgd_solver.cpp:112] Iteration 75200, lr = 0.01
I0523 08:13:34.731302 34819 solver.cpp:239] Iteration 75210 (1.96394 iter/s, 5.09182s/10 iters), loss = 7.32325
I0523 08:13:34.731350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.32325 (* 1 = 7.32325 loss)
I0523 08:13:35.573544 34819 sgd_solver.cpp:112] Iteration 75210, lr = 0.01
I0523 08:13:40.568300 34819 solver.cpp:239] Iteration 75220 (1.7133 iter/s, 5.8367s/10 iters), loss = 7.736
I0523 08:13:40.568341 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.736 (* 1 = 7.736 loss)
I0523 08:13:40.639456 34819 sgd_solver.cpp:112] Iteration 75220, lr = 0.01
I0523 08:13:45.981086 34819 solver.cpp:239] Iteration 75230 (1.84757 iter/s, 5.41251s/10 iters), loss = 8.07649
I0523 08:13:45.981205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07649 (* 1 = 8.07649 loss)
I0523 08:13:46.049230 34819 sgd_solver.cpp:112] Iteration 75230, lr = 0.01
I0523 08:13:49.793714 34819 solver.cpp:239] Iteration 75240 (2.62305 iter/s, 3.81235s/10 iters), loss = 7.62816
I0523 08:13:49.793754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62816 (* 1 = 7.62816 loss)
I0523 08:13:49.868669 34819 sgd_solver.cpp:112] Iteration 75240, lr = 0.01
I0523 08:13:54.819203 34819 solver.cpp:239] Iteration 75250 (1.98996 iter/s, 5.02523s/10 iters), loss = 8.21381
I0523 08:13:54.819249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21381 (* 1 = 8.21381 loss)
I0523 08:13:54.885040 34819 sgd_solver.cpp:112] Iteration 75250, lr = 0.01
I0523 08:13:59.164714 34819 solver.cpp:239] Iteration 75260 (2.30135 iter/s, 4.34527s/10 iters), loss = 7.07785
I0523 08:13:59.164770 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.07785 (* 1 = 7.07785 loss)
I0523 08:13:59.986724 34819 sgd_solver.cpp:112] Iteration 75260, lr = 0.01
I0523 08:14:05.345461 34819 solver.cpp:239] Iteration 75270 (1.61801 iter/s, 6.18044s/10 iters), loss = 7.70468
I0523 08:14:05.345501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70468 (* 1 = 7.70468 loss)
I0523 08:14:06.098862 34819 sgd_solver.cpp:112] Iteration 75270, lr = 0.01
I0523 08:14:11.174528 34819 solver.cpp:239] Iteration 75280 (1.71562 iter/s, 5.82879s/10 iters), loss = 7.02754
I0523 08:14:11.174585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.02754 (* 1 = 7.02754 loss)
I0523 08:14:11.943555 34819 sgd_solver.cpp:112] Iteration 75280, lr = 0.01
I0523 08:14:15.897456 34819 solver.cpp:239] Iteration 75290 (2.11745 iter/s, 4.72267s/10 iters), loss = 7.51165
I0523 08:14:15.897498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51165 (* 1 = 7.51165 loss)
I0523 08:14:16.379134 34819 sgd_solver.cpp:112] Iteration 75290, lr = 0.01
I0523 08:14:18.951519 34819 solver.cpp:239] Iteration 75300 (3.27452 iter/s, 3.05388s/10 iters), loss = 7.85754
I0523 08:14:18.951572 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85754 (* 1 = 7.85754 loss)
I0523 08:14:19.780138 34819 sgd_solver.cpp:112] Iteration 75300, lr = 0.01
I0523 08:14:23.766798 34819 solver.cpp:239] Iteration 75310 (2.07683 iter/s, 4.81502s/10 iters), loss = 7.76458
I0523 08:14:23.766850 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76458 (* 1 = 7.76458 loss)
I0523 08:14:24.634001 34819 sgd_solver.cpp:112] Iteration 75310, lr = 0.01
I0523 08:14:30.073072 34819 solver.cpp:239] Iteration 75320 (1.5858 iter/s, 6.30596s/10 iters), loss = 8.8952
I0523 08:14:30.073117 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8952 (* 1 = 8.8952 loss)
I0523 08:14:30.136230 34819 sgd_solver.cpp:112] Iteration 75320, lr = 0.01
I0523 08:14:35.794543 34819 solver.cpp:239] Iteration 75330 (1.7479 iter/s, 5.72117s/10 iters), loss = 7.72323
I0523 08:14:35.794600 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72323 (* 1 = 7.72323 loss)
I0523 08:14:36.529755 34819 sgd_solver.cpp:112] Iteration 75330, lr = 0.01
I0523 08:14:40.739249 34819 solver.cpp:239] Iteration 75340 (2.02248 iter/s, 4.94444s/10 iters), loss = 8.145
I0523 08:14:40.739322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.145 (* 1 = 8.145 loss)
I0523 08:14:41.573206 34819 sgd_solver.cpp:112] Iteration 75340, lr = 0.01
I0523 08:14:45.759119 34819 solver.cpp:239] Iteration 75350 (1.9922 iter/s, 5.01958s/10 iters), loss = 7.8686
I0523 08:14:45.759163 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8686 (* 1 = 7.8686 loss)
I0523 08:14:45.827736 34819 sgd_solver.cpp:112] Iteration 75350, lr = 0.01
I0523 08:14:51.511224 34819 solver.cpp:239] Iteration 75360 (1.73858 iter/s, 5.75182s/10 iters), loss = 8.31633
I0523 08:14:51.511456 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31633 (* 1 = 8.31633 loss)
I0523 08:14:51.580477 34819 sgd_solver.cpp:112] Iteration 75360, lr = 0.01
I0523 08:14:56.271509 34819 solver.cpp:239] Iteration 75370 (2.1009 iter/s, 4.75987s/10 iters), loss = 8.41892
I0523 08:14:56.271567 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.41892 (* 1 = 8.41892 loss)
I0523 08:14:57.142426 34819 sgd_solver.cpp:112] Iteration 75370, lr = 0.01
I0523 08:15:02.147843 34819 solver.cpp:239] Iteration 75380 (1.70183 iter/s, 5.87603s/10 iters), loss = 7.85102
I0523 08:15:02.147912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85102 (* 1 = 7.85102 loss)
I0523 08:15:02.216085 34819 sgd_solver.cpp:112] Iteration 75380, lr = 0.01
I0523 08:15:04.670575 34819 solver.cpp:239] Iteration 75390 (3.96424 iter/s, 2.52255s/10 iters), loss = 7.7954
I0523 08:15:04.670614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7954 (* 1 = 7.7954 loss)
I0523 08:15:05.408767 34819 sgd_solver.cpp:112] Iteration 75390, lr = 0.01
I0523 08:15:11.267088 34819 solver.cpp:239] Iteration 75400 (1.51603 iter/s, 6.59619s/10 iters), loss = 7.78337
I0523 08:15:11.267144 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78337 (* 1 = 7.78337 loss)
I0523 08:15:11.335294 34819 sgd_solver.cpp:112] Iteration 75400, lr = 0.01
I0523 08:15:15.344272 34819 solver.cpp:239] Iteration 75410 (2.45281 iter/s, 4.07696s/10 iters), loss = 7.6825
I0523 08:15:15.344329 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6825 (* 1 = 7.6825 loss)
I0523 08:15:15.400398 34819 sgd_solver.cpp:112] Iteration 75410, lr = 0.01
I0523 08:15:19.818017 34819 solver.cpp:239] Iteration 75420 (2.23541 iter/s, 4.47345s/10 iters), loss = 8.85582
I0523 08:15:19.818066 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.85582 (* 1 = 8.85582 loss)
I0523 08:15:20.096251 34819 sgd_solver.cpp:112] Iteration 75420, lr = 0.01
I0523 08:15:26.482523 34819 solver.cpp:239] Iteration 75430 (1.50056 iter/s, 6.66418s/10 iters), loss = 7.57441
I0523 08:15:26.482760 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57441 (* 1 = 7.57441 loss)
I0523 08:15:26.548435 34819 sgd_solver.cpp:112] Iteration 75430, lr = 0.01
I0523 08:15:30.120115 34819 solver.cpp:239] Iteration 75440 (2.74936 iter/s, 3.63721s/10 iters), loss = 7.90578
I0523 08:15:30.120170 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90578 (* 1 = 7.90578 loss)
I0523 08:15:30.942207 34819 sgd_solver.cpp:112] Iteration 75440, lr = 0.01
I0523 08:15:35.709568 34819 solver.cpp:239] Iteration 75450 (1.78918 iter/s, 5.58917s/10 iters), loss = 8.66265
I0523 08:15:35.709623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66265 (* 1 = 8.66265 loss)
I0523 08:15:35.780143 34819 sgd_solver.cpp:112] Iteration 75450, lr = 0.01
I0523 08:15:39.055383 34819 solver.cpp:239] Iteration 75460 (2.989 iter/s, 3.3456s/10 iters), loss = 7.57135
I0523 08:15:39.055440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57135 (* 1 = 7.57135 loss)
I0523 08:15:39.129220 34819 sgd_solver.cpp:112] Iteration 75460, lr = 0.01
I0523 08:15:43.194952 34819 solver.cpp:239] Iteration 75470 (2.41585 iter/s, 4.13933s/10 iters), loss = 7.42817
I0523 08:15:43.195005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42817 (* 1 = 7.42817 loss)
I0523 08:15:43.278017 34819 sgd_solver.cpp:112] Iteration 75470, lr = 0.01
I0523 08:15:47.903523 34819 solver.cpp:239] Iteration 75480 (2.12391 iter/s, 4.7083s/10 iters), loss = 7.93352
I0523 08:15:47.903584 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93352 (* 1 = 7.93352 loss)
I0523 08:15:48.770159 34819 sgd_solver.cpp:112] Iteration 75480, lr = 0.01
I0523 08:15:54.823196 34819 solver.cpp:239] Iteration 75490 (1.44523 iter/s, 6.91933s/10 iters), loss = 8.35967
I0523 08:15:54.823253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35967 (* 1 = 8.35967 loss)
I0523 08:15:54.957631 34819 sgd_solver.cpp:112] Iteration 75490, lr = 0.01
I0523 08:16:00.178911 34819 solver.cpp:239] Iteration 75500 (1.86726 iter/s, 5.35543s/10 iters), loss = 7.24319
I0523 08:16:00.179051 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.24319 (* 1 = 7.24319 loss)
I0523 08:16:00.237594 34819 sgd_solver.cpp:112] Iteration 75500, lr = 0.01
I0523 08:16:05.253931 34819 solver.cpp:239] Iteration 75510 (1.97058 iter/s, 5.07464s/10 iters), loss = 8.66644
I0523 08:16:05.253981 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.66644 (* 1 = 8.66644 loss)
I0523 08:16:06.084833 34819 sgd_solver.cpp:112] Iteration 75510, lr = 0.01
I0523 08:16:10.159243 34819 solver.cpp:239] Iteration 75520 (2.03872 iter/s, 4.90504s/10 iters), loss = 7.73125
I0523 08:16:10.159298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73125 (* 1 = 7.73125 loss)
I0523 08:16:10.226411 34819 sgd_solver.cpp:112] Iteration 75520, lr = 0.01
I0523 08:16:16.011466 34819 solver.cpp:239] Iteration 75530 (1.70884 iter/s, 5.85192s/10 iters), loss = 7.13607
I0523 08:16:16.011520 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13607 (* 1 = 7.13607 loss)
I0523 08:16:16.088073 34819 sgd_solver.cpp:112] Iteration 75530, lr = 0.01
I0523 08:16:21.708670 34819 solver.cpp:239] Iteration 75540 (1.75534 iter/s, 5.69691s/10 iters), loss = 8.03118
I0523 08:16:21.708736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03118 (* 1 = 8.03118 loss)
I0523 08:16:22.592084 34819 sgd_solver.cpp:112] Iteration 75540, lr = 0.01
I0523 08:16:27.290534 34819 solver.cpp:239] Iteration 75550 (1.79161 iter/s, 5.58156s/10 iters), loss = 7.46219
I0523 08:16:27.290585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46219 (* 1 = 7.46219 loss)
I0523 08:16:27.363787 34819 sgd_solver.cpp:112] Iteration 75550, lr = 0.01
I0523 08:16:30.817698 34819 solver.cpp:239] Iteration 75560 (2.83531 iter/s, 3.52695s/10 iters), loss = 7.35314
I0523 08:16:30.817804 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35314 (* 1 = 7.35314 loss)
I0523 08:16:30.890506 34819 sgd_solver.cpp:112] Iteration 75560, lr = 0.01
I0523 08:16:35.756307 34819 solver.cpp:239] Iteration 75570 (2.02499 iter/s, 4.93829s/10 iters), loss = 8.08836
I0523 08:16:35.756361 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08836 (* 1 = 8.08836 loss)
I0523 08:16:35.823179 34819 sgd_solver.cpp:112] Iteration 75570, lr = 0.01
I0523 08:16:39.753744 34819 solver.cpp:239] Iteration 75580 (2.50174 iter/s, 3.99722s/10 iters), loss = 6.93034
I0523 08:16:39.753808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.93034 (* 1 = 6.93034 loss)
I0523 08:16:40.423370 34819 sgd_solver.cpp:112] Iteration 75580, lr = 0.01
I0523 08:16:47.467694 34819 solver.cpp:239] Iteration 75590 (1.29642 iter/s, 7.71357s/10 iters), loss = 8.0617
I0523 08:16:47.467736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0617 (* 1 = 8.0617 loss)
I0523 08:16:47.522313 34819 sgd_solver.cpp:112] Iteration 75590, lr = 0.01
I0523 08:16:50.742818 34819 solver.cpp:239] Iteration 75600 (3.0535 iter/s, 3.27493s/10 iters), loss = 7.33277
I0523 08:16:50.742885 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33277 (* 1 = 7.33277 loss)
I0523 08:16:51.377431 34819 sgd_solver.cpp:112] Iteration 75600, lr = 0.01
I0523 08:16:55.303715 34819 solver.cpp:239] Iteration 75610 (2.19267 iter/s, 4.56064s/10 iters), loss = 7.64898
I0523 08:16:55.303783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64898 (* 1 = 7.64898 loss)
I0523 08:16:55.367574 34819 sgd_solver.cpp:112] Iteration 75610, lr = 0.01
I0523 08:17:00.172251 34819 solver.cpp:239] Iteration 75620 (2.05412 iter/s, 4.86826s/10 iters), loss = 7.68387
I0523 08:17:00.172297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68387 (* 1 = 7.68387 loss)
I0523 08:17:00.230676 34819 sgd_solver.cpp:112] Iteration 75620, lr = 0.01
I0523 08:17:05.291905 34819 solver.cpp:239] Iteration 75630 (1.95336 iter/s, 5.11939s/10 iters), loss = 7.76178
I0523 08:17:05.291996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76178 (* 1 = 7.76178 loss)
I0523 08:17:05.365911 34819 sgd_solver.cpp:112] Iteration 75630, lr = 0.01
I0523 08:17:10.859586 34819 solver.cpp:239] Iteration 75640 (1.79618 iter/s, 5.56736s/10 iters), loss = 7.68888
I0523 08:17:10.859630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68888 (* 1 = 7.68888 loss)
I0523 08:17:10.924813 34819 sgd_solver.cpp:112] Iteration 75640, lr = 0.01
I0523 08:17:17.311718 34819 solver.cpp:239] Iteration 75650 (1.54995 iter/s, 6.45182s/10 iters), loss = 7.26419
I0523 08:17:17.311764 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26419 (* 1 = 7.26419 loss)
I0523 08:17:17.388103 34819 sgd_solver.cpp:112] Iteration 75650, lr = 0.01
I0523 08:17:20.743808 34819 solver.cpp:239] Iteration 75660 (2.91385 iter/s, 3.43188s/10 iters), loss = 7.91494
I0523 08:17:20.743854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91494 (* 1 = 7.91494 loss)
I0523 08:17:21.581789 34819 sgd_solver.cpp:112] Iteration 75660, lr = 0.01
I0523 08:17:25.356022 34819 solver.cpp:239] Iteration 75670 (2.16827 iter/s, 4.61197s/10 iters), loss = 8.08183
I0523 08:17:25.356065 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08183 (* 1 = 8.08183 loss)
I0523 08:17:25.419661 34819 sgd_solver.cpp:112] Iteration 75670, lr = 0.01
I0523 08:17:27.967373 34819 solver.cpp:239] Iteration 75680 (3.83446 iter/s, 2.60793s/10 iters), loss = 8.12758
I0523 08:17:27.967418 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12758 (* 1 = 8.12758 loss)
I0523 08:17:28.781136 34819 sgd_solver.cpp:112] Iteration 75680, lr = 0.01
I0523 08:17:32.944703 34819 solver.cpp:239] Iteration 75690 (2.00921 iter/s, 4.97707s/10 iters), loss = 7.79542
I0523 08:17:32.944749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79542 (* 1 = 7.79542 loss)
I0523 08:17:33.011922 34819 sgd_solver.cpp:112] Iteration 75690, lr = 0.01
I0523 08:17:38.302117 34819 solver.cpp:239] Iteration 75700 (1.86667 iter/s, 5.35714s/10 iters), loss = 7.4962
I0523 08:17:38.302345 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4962 (* 1 = 7.4962 loss)
I0523 08:17:39.111016 34819 sgd_solver.cpp:112] Iteration 75700, lr = 0.01
I0523 08:17:44.479818 34819 solver.cpp:239] Iteration 75710 (1.61885 iter/s, 6.17723s/10 iters), loss = 7.63597
I0523 08:17:44.479873 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63597 (* 1 = 7.63597 loss)
I0523 08:17:44.553421 34819 sgd_solver.cpp:112] Iteration 75710, lr = 0.01
I0523 08:17:49.424547 34819 solver.cpp:239] Iteration 75720 (2.02246 iter/s, 4.94446s/10 iters), loss = 7.08564
I0523 08:17:49.424593 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.08564 (* 1 = 7.08564 loss)
I0523 08:17:50.074571 34819 sgd_solver.cpp:112] Iteration 75720, lr = 0.01
I0523 08:17:53.973239 34819 solver.cpp:239] Iteration 75730 (2.19855 iter/s, 4.54845s/10 iters), loss = 7.6932
I0523 08:17:53.973295 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6932 (* 1 = 7.6932 loss)
I0523 08:17:54.026903 34819 sgd_solver.cpp:112] Iteration 75730, lr = 0.01
I0523 08:17:59.086194 34819 solver.cpp:239] Iteration 75740 (1.95592 iter/s, 5.11268s/10 iters), loss = 8.08837
I0523 08:17:59.086236 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08837 (* 1 = 8.08837 loss)
I0523 08:17:59.824069 34819 sgd_solver.cpp:112] Iteration 75740, lr = 0.01
I0523 08:18:03.141697 34819 solver.cpp:239] Iteration 75750 (2.46592 iter/s, 4.05529s/10 iters), loss = 7.84109
I0523 08:18:03.141741 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84109 (* 1 = 7.84109 loss)
I0523 08:18:03.994062 34819 sgd_solver.cpp:112] Iteration 75750, lr = 0.01
I0523 08:18:08.072798 34819 solver.cpp:239] Iteration 75760 (2.02805 iter/s, 4.93085s/10 iters), loss = 7.79267
I0523 08:18:08.072840 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79267 (* 1 = 7.79267 loss)
I0523 08:18:08.156647 34819 sgd_solver.cpp:112] Iteration 75760, lr = 0.01
I0523 08:18:14.039548 34819 solver.cpp:239] Iteration 75770 (1.67604 iter/s, 5.96646s/10 iters), loss = 8.10989
I0523 08:18:14.039687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10989 (* 1 = 8.10989 loss)
I0523 08:18:14.847998 34819 sgd_solver.cpp:112] Iteration 75770, lr = 0.01
I0523 08:18:20.362485 34819 solver.cpp:239] Iteration 75780 (1.58164 iter/s, 6.32254s/10 iters), loss = 7.81365
I0523 08:18:20.362526 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.81365 (* 1 = 7.81365 loss)
I0523 08:18:20.438519 34819 sgd_solver.cpp:112] Iteration 75780, lr = 0.01
I0523 08:18:25.154781 34819 solver.cpp:239] Iteration 75790 (2.08679 iter/s, 4.79204s/10 iters), loss = 7.65334
I0523 08:18:25.154821 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65334 (* 1 = 7.65334 loss)
I0523 08:18:25.462069 34819 sgd_solver.cpp:112] Iteration 75790, lr = 0.01
I0523 08:18:29.572363 34819 solver.cpp:239] Iteration 75800 (2.2638 iter/s, 4.41736s/10 iters), loss = 7.64745
I0523 08:18:29.572407 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64745 (* 1 = 7.64745 loss)
I0523 08:18:29.640821 34819 sgd_solver.cpp:112] Iteration 75800, lr = 0.01
I0523 08:18:34.456780 34819 solver.cpp:239] Iteration 75810 (2.04743 iter/s, 4.88416s/10 iters), loss = 8.28005
I0523 08:18:34.456827 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28005 (* 1 = 8.28005 loss)
I0523 08:18:34.515902 34819 sgd_solver.cpp:112] Iteration 75810, lr = 0.01
I0523 08:18:38.623627 34819 solver.cpp:239] Iteration 75820 (2.40002 iter/s, 4.16663s/10 iters), loss = 7.34734
I0523 08:18:38.623672 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.34734 (* 1 = 7.34734 loss)
I0523 08:18:38.683643 34819 sgd_solver.cpp:112] Iteration 75820, lr = 0.01
I0523 08:18:43.624228 34819 solver.cpp:239] Iteration 75830 (1.99986 iter/s, 5.00035s/10 iters), loss = 8.13781
I0523 08:18:43.624270 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13781 (* 1 = 8.13781 loss)
I0523 08:18:43.693119 34819 sgd_solver.cpp:112] Iteration 75830, lr = 0.01
I0523 08:18:47.508332 34819 solver.cpp:239] Iteration 75840 (2.57474 iter/s, 3.88389s/10 iters), loss = 6.83225
I0523 08:18:47.508507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.83225 (* 1 = 6.83225 loss)
I0523 08:18:47.578646 34819 sgd_solver.cpp:112] Iteration 75840, lr = 0.01
I0523 08:18:50.877194 34819 solver.cpp:239] Iteration 75850 (2.96864 iter/s, 3.36855s/10 iters), loss = 7.6877
I0523 08:18:50.877238 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6877 (* 1 = 7.6877 loss)
I0523 08:18:51.738649 34819 sgd_solver.cpp:112] Iteration 75850, lr = 0.01
I0523 08:18:57.723387 34819 solver.cpp:239] Iteration 75860 (1.46074 iter/s, 6.84586s/10 iters), loss = 7.82784
I0523 08:18:57.723443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82784 (* 1 = 7.82784 loss)
I0523 08:18:57.796310 34819 sgd_solver.cpp:112] Iteration 75860, lr = 0.01
I0523 08:19:03.291826 34819 solver.cpp:239] Iteration 75870 (1.79593 iter/s, 5.56815s/10 iters), loss = 8.21659
I0523 08:19:03.291867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21659 (* 1 = 8.21659 loss)
I0523 08:19:04.114011 34819 sgd_solver.cpp:112] Iteration 75870, lr = 0.01
I0523 08:19:08.895061 34819 solver.cpp:239] Iteration 75880 (1.78477 iter/s, 5.60296s/10 iters), loss = 8.16774
I0523 08:19:08.895120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16774 (* 1 = 8.16774 loss)
I0523 08:19:09.613502 34819 sgd_solver.cpp:112] Iteration 75880, lr = 0.01
I0523 08:19:15.306464 34819 solver.cpp:239] Iteration 75890 (1.55981 iter/s, 6.41106s/10 iters), loss = 7.80868
I0523 08:19:15.306537 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80868 (* 1 = 7.80868 loss)
I0523 08:19:15.377686 34819 sgd_solver.cpp:112] Iteration 75890, lr = 0.01
I0523 08:19:20.762821 34819 solver.cpp:239] Iteration 75900 (1.83283 iter/s, 5.45606s/10 iters), loss = 7.92997
I0523 08:19:20.762961 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92997 (* 1 = 7.92997 loss)
I0523 08:19:20.832037 34819 sgd_solver.cpp:112] Iteration 75900, lr = 0.01
I0523 08:19:23.491711 34819 solver.cpp:239] Iteration 75910 (3.66484 iter/s, 2.72863s/10 iters), loss = 7.54304
I0523 08:19:23.491755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54304 (* 1 = 7.54304 loss)
I0523 08:19:23.564998 34819 sgd_solver.cpp:112] Iteration 75910, lr = 0.01
I0523 08:19:30.105607 34819 solver.cpp:239] Iteration 75920 (1.51204 iter/s, 6.61356s/10 iters), loss = 7.59472
I0523 08:19:30.105680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59472 (* 1 = 7.59472 loss)
I0523 08:19:30.177623 34819 sgd_solver.cpp:112] Iteration 75920, lr = 0.01
I0523 08:19:34.053256 34819 solver.cpp:239] Iteration 75930 (2.53331 iter/s, 3.94741s/10 iters), loss = 6.9218
I0523 08:19:34.053308 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.9218 (* 1 = 6.9218 loss)
I0523 08:19:34.130012 34819 sgd_solver.cpp:112] Iteration 75930, lr = 0.01
I0523 08:19:41.178858 34819 solver.cpp:239] Iteration 75940 (1.40346 iter/s, 7.12525s/10 iters), loss = 8.2929
I0523 08:19:41.178900 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2929 (* 1 = 8.2929 loss)
I0523 08:19:41.246515 34819 sgd_solver.cpp:112] Iteration 75940, lr = 0.01
I0523 08:19:43.908304 34819 solver.cpp:239] Iteration 75950 (3.66397 iter/s, 2.72928s/10 iters), loss = 8.11367
I0523 08:19:43.908350 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11367 (* 1 = 8.11367 loss)
I0523 08:19:44.768568 34819 sgd_solver.cpp:112] Iteration 75950, lr = 0.01
I0523 08:19:49.097460 34819 solver.cpp:239] Iteration 75960 (1.9272 iter/s, 5.18889s/10 iters), loss = 7.73202
I0523 08:19:49.097506 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73202 (* 1 = 7.73202 loss)
I0523 08:19:49.157665 34819 sgd_solver.cpp:112] Iteration 75960, lr = 0.01
I0523 08:19:52.597903 34819 solver.cpp:239] Iteration 75970 (2.85695 iter/s, 3.50024s/10 iters), loss = 8.29241
I0523 08:19:52.598074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29241 (* 1 = 8.29241 loss)
I0523 08:19:52.810672 34819 sgd_solver.cpp:112] Iteration 75970, lr = 0.01
I0523 08:19:57.560034 34819 solver.cpp:239] Iteration 75980 (2.01542 iter/s, 4.96175s/10 iters), loss = 7.03983
I0523 08:19:57.560084 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.03983 (* 1 = 7.03983 loss)
I0523 08:19:57.960198 34819 sgd_solver.cpp:112] Iteration 75980, lr = 0.01
I0523 08:20:01.222635 34819 solver.cpp:239] Iteration 75990 (2.73046 iter/s, 3.66238s/10 iters), loss = 8.26154
I0523 08:20:01.222679 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26154 (* 1 = 8.26154 loss)
I0523 08:20:02.079111 34819 sgd_solver.cpp:112] Iteration 75990, lr = 0.01
I0523 08:20:06.216567 34819 solver.cpp:239] Iteration 76000 (2.00253 iter/s, 4.99367s/10 iters), loss = 7.53613
I0523 08:20:06.216610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53613 (* 1 = 7.53613 loss)
I0523 08:20:06.286638 34819 sgd_solver.cpp:112] Iteration 76000, lr = 0.01
I0523 08:20:10.153182 34819 solver.cpp:239] Iteration 76010 (2.5404 iter/s, 3.93639s/10 iters), loss = 8.00778
I0523 08:20:10.153234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00778 (* 1 = 8.00778 loss)
I0523 08:20:10.371237 34819 sgd_solver.cpp:112] Iteration 76010, lr = 0.01
I0523 08:20:15.081733 34819 solver.cpp:239] Iteration 76020 (2.0291 iter/s, 4.92828s/10 iters), loss = 8.17966
I0523 08:20:15.081781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17966 (* 1 = 8.17966 loss)
I0523 08:20:15.630303 34819 sgd_solver.cpp:112] Iteration 76020, lr = 0.01
I0523 08:20:20.588023 34819 solver.cpp:239] Iteration 76030 (1.8162 iter/s, 5.50601s/10 iters), loss = 7.755
I0523 08:20:20.588068 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.755 (* 1 = 7.755 loss)
I0523 08:20:20.659996 34819 sgd_solver.cpp:112] Iteration 76030, lr = 0.01
I0523 08:20:24.024268 34819 solver.cpp:239] Iteration 76040 (2.91032 iter/s, 3.43605s/10 iters), loss = 7.64975
I0523 08:20:24.024392 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64975 (* 1 = 7.64975 loss)
I0523 08:20:24.890192 34819 sgd_solver.cpp:112] Iteration 76040, lr = 0.01
I0523 08:20:29.039192 34819 solver.cpp:239] Iteration 76050 (1.99418 iter/s, 5.01459s/10 iters), loss = 8.44829
I0523 08:20:29.039247 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.44829 (* 1 = 8.44829 loss)
I0523 08:20:29.836488 34819 sgd_solver.cpp:112] Iteration 76050, lr = 0.01
I0523 08:20:33.282335 34819 solver.cpp:239] Iteration 76060 (2.35687 iter/s, 4.24291s/10 iters), loss = 6.94231
I0523 08:20:33.282384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.94231 (* 1 = 6.94231 loss)
I0523 08:20:33.505870 34819 sgd_solver.cpp:112] Iteration 76060, lr = 0.01
I0523 08:20:37.041112 34819 solver.cpp:239] Iteration 76070 (2.66059 iter/s, 3.75856s/10 iters), loss = 7.36832
I0523 08:20:37.041167 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36832 (* 1 = 7.36832 loss)
I0523 08:20:37.123618 34819 sgd_solver.cpp:112] Iteration 76070, lr = 0.01
I0523 08:20:39.905088 34819 solver.cpp:239] Iteration 76080 (3.49189 iter/s, 2.86378s/10 iters), loss = 7.42849
I0523 08:20:39.905146 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42849 (* 1 = 7.42849 loss)
I0523 08:20:39.971632 34819 sgd_solver.cpp:112] Iteration 76080, lr = 0.01
I0523 08:20:42.588449 34819 solver.cpp:239] Iteration 76090 (3.72692 iter/s, 2.68318s/10 iters), loss = 8.78283
I0523 08:20:42.588508 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78283 (* 1 = 8.78283 loss)
I0523 08:20:42.656772 34819 sgd_solver.cpp:112] Iteration 76090, lr = 0.01
I0523 08:20:47.855150 34819 solver.cpp:239] Iteration 76100 (1.89882 iter/s, 5.26642s/10 iters), loss = 8.26679
I0523 08:20:47.855206 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26679 (* 1 = 8.26679 loss)
I0523 08:20:47.918830 34819 sgd_solver.cpp:112] Iteration 76100, lr = 0.01
I0523 08:20:53.153019 34819 solver.cpp:239] Iteration 76110 (1.88765 iter/s, 5.29758s/10 iters), loss = 8.57238
I0523 08:20:53.153079 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57238 (* 1 = 8.57238 loss)
I0523 08:20:54.016489 34819 sgd_solver.cpp:112] Iteration 76110, lr = 0.01
I0523 08:20:59.726794 34819 solver.cpp:239] Iteration 76120 (1.52127 iter/s, 6.57344s/10 iters), loss = 7.67215
I0523 08:20:59.726996 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67215 (* 1 = 7.67215 loss)
I0523 08:20:59.795238 34819 sgd_solver.cpp:112] Iteration 76120, lr = 0.01
I0523 08:21:03.690275 34819 solver.cpp:239] Iteration 76130 (2.52327 iter/s, 3.96311s/10 iters), loss = 8.84804
I0523 08:21:03.690347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.84804 (* 1 = 8.84804 loss)
I0523 08:21:03.768725 34819 sgd_solver.cpp:112] Iteration 76130, lr = 0.01
I0523 08:21:07.022145 34819 solver.cpp:239] Iteration 76140 (3.00152 iter/s, 3.33165s/10 iters), loss = 8.65262
I0523 08:21:07.022209 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65262 (* 1 = 8.65262 loss)
I0523 08:21:07.855279 34819 sgd_solver.cpp:112] Iteration 76140, lr = 0.01
I0523 08:21:14.256278 34819 solver.cpp:239] Iteration 76150 (1.38241 iter/s, 7.23376s/10 iters), loss = 7.76826
I0523 08:21:14.256330 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76826 (* 1 = 7.76826 loss)
I0523 08:21:15.028275 34819 sgd_solver.cpp:112] Iteration 76150, lr = 0.01
I0523 08:21:19.984546 34819 solver.cpp:239] Iteration 76160 (1.74582 iter/s, 5.72797s/10 iters), loss = 7.82344
I0523 08:21:19.984597 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82344 (* 1 = 7.82344 loss)
I0523 08:21:20.037106 34819 sgd_solver.cpp:112] Iteration 76160, lr = 0.01
I0523 08:21:24.965106 34819 solver.cpp:239] Iteration 76170 (2.00791 iter/s, 4.9803s/10 iters), loss = 7.97
I0523 08:21:24.965150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97 (* 1 = 7.97 loss)
I0523 08:21:25.039860 34819 sgd_solver.cpp:112] Iteration 76170, lr = 0.01
I0523 08:21:29.964643 34819 solver.cpp:239] Iteration 76180 (2.00029 iter/s, 4.99928s/10 iters), loss = 7.07416
I0523 08:21:29.964790 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.07416 (* 1 = 7.07416 loss)
I0523 08:21:30.037099 34819 sgd_solver.cpp:112] Iteration 76180, lr = 0.01
I0523 08:21:33.448920 34819 solver.cpp:239] Iteration 76190 (2.87028 iter/s, 3.48398s/10 iters), loss = 8.16215
I0523 08:21:33.448963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16215 (* 1 = 8.16215 loss)
I0523 08:21:33.535311 34819 sgd_solver.cpp:112] Iteration 76190, lr = 0.01
I0523 08:21:38.405639 34819 solver.cpp:239] Iteration 76200 (2.01756 iter/s, 4.95647s/10 iters), loss = 7.22732
I0523 08:21:38.405685 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22732 (* 1 = 7.22732 loss)
I0523 08:21:39.181443 34819 sgd_solver.cpp:112] Iteration 76200, lr = 0.01
I0523 08:21:43.936640 34819 solver.cpp:239] Iteration 76210 (1.80809 iter/s, 5.53071s/10 iters), loss = 6.60019
I0523 08:21:43.936689 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.60019 (* 1 = 6.60019 loss)
I0523 08:21:44.654103 34819 sgd_solver.cpp:112] Iteration 76210, lr = 0.01
I0523 08:21:48.044513 34819 solver.cpp:239] Iteration 76220 (2.43449 iter/s, 4.10764s/10 iters), loss = 7.74353
I0523 08:21:48.044566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74353 (* 1 = 7.74353 loss)
I0523 08:21:48.113590 34819 sgd_solver.cpp:112] Iteration 76220, lr = 0.01
I0523 08:21:53.407475 34819 solver.cpp:239] Iteration 76230 (1.86474 iter/s, 5.36268s/10 iters), loss = 8.49779
I0523 08:21:53.407518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49779 (* 1 = 8.49779 loss)
I0523 08:21:54.183230 34819 sgd_solver.cpp:112] Iteration 76230, lr = 0.01
I0523 08:21:58.764207 34819 solver.cpp:239] Iteration 76240 (1.86691 iter/s, 5.35644s/10 iters), loss = 8.88793
I0523 08:21:58.764251 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.88793 (* 1 = 8.88793 loss)
I0523 08:21:58.832267 34819 sgd_solver.cpp:112] Iteration 76240, lr = 0.01
I0523 08:22:02.126091 34819 solver.cpp:239] Iteration 76250 (2.9747 iter/s, 3.36169s/10 iters), loss = 8.01501
I0523 08:22:02.126222 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01501 (* 1 = 8.01501 loss)
I0523 08:22:02.911984 34819 sgd_solver.cpp:112] Iteration 76250, lr = 0.01
I0523 08:22:07.449313 34819 solver.cpp:239] Iteration 76260 (1.87869 iter/s, 5.32285s/10 iters), loss = 7.69482
I0523 08:22:07.449383 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69482 (* 1 = 7.69482 loss)
I0523 08:22:08.303530 34819 sgd_solver.cpp:112] Iteration 76260, lr = 0.01
I0523 08:22:14.300431 34819 solver.cpp:239] Iteration 76270 (1.45969 iter/s, 6.85076s/10 iters), loss = 8.11737
I0523 08:22:14.300496 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.11737 (* 1 = 8.11737 loss)
I0523 08:22:14.376338 34819 sgd_solver.cpp:112] Iteration 76270, lr = 0.01
I0523 08:22:18.846289 34819 solver.cpp:239] Iteration 76280 (2.19994 iter/s, 4.54558s/10 iters), loss = 7.80151
I0523 08:22:18.846355 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80151 (* 1 = 7.80151 loss)
I0523 08:22:18.904754 34819 sgd_solver.cpp:112] Iteration 76280, lr = 0.01
I0523 08:22:21.838016 34819 solver.cpp:239] Iteration 76290 (3.34279 iter/s, 2.99152s/10 iters), loss = 7.64018
I0523 08:22:21.838070 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64018 (* 1 = 7.64018 loss)
I0523 08:22:22.658731 34819 sgd_solver.cpp:112] Iteration 76290, lr = 0.01
I0523 08:22:25.963929 34819 solver.cpp:239] Iteration 76300 (2.42384 iter/s, 4.12568s/10 iters), loss = 7.09437
I0523 08:22:25.963991 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.09437 (* 1 = 7.09437 loss)
I0523 08:22:26.644863 34819 sgd_solver.cpp:112] Iteration 76300, lr = 0.01
I0523 08:22:31.258492 34819 solver.cpp:239] Iteration 76310 (1.88883 iter/s, 5.29427s/10 iters), loss = 7.42897
I0523 08:22:31.258535 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.42897 (* 1 = 7.42897 loss)
I0523 08:22:31.335134 34819 sgd_solver.cpp:112] Iteration 76310, lr = 0.01
I0523 08:22:35.244626 34819 solver.cpp:239] Iteration 76320 (2.50884 iter/s, 3.98591s/10 iters), loss = 8.237
I0523 08:22:35.244803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.237 (* 1 = 8.237 loss)
I0523 08:22:35.950541 34819 sgd_solver.cpp:112] Iteration 76320, lr = 0.01
I0523 08:22:40.879830 34819 solver.cpp:239] Iteration 76330 (1.77469 iter/s, 5.63478s/10 iters), loss = 8.38039
I0523 08:22:40.879886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38039 (* 1 = 8.38039 loss)
I0523 08:22:40.956562 34819 sgd_solver.cpp:112] Iteration 76330, lr = 0.01
I0523 08:22:46.846626 34819 solver.cpp:239] Iteration 76340 (1.67602 iter/s, 5.9665s/10 iters), loss = 7.88504
I0523 08:22:46.846681 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88504 (* 1 = 7.88504 loss)
I0523 08:22:47.647066 34819 sgd_solver.cpp:112] Iteration 76340, lr = 0.01
I0523 08:22:52.147804 34819 solver.cpp:239] Iteration 76350 (1.88647 iter/s, 5.3009s/10 iters), loss = 7.33121
I0523 08:22:52.147856 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33121 (* 1 = 7.33121 loss)
I0523 08:22:52.213748 34819 sgd_solver.cpp:112] Iteration 76350, lr = 0.01
I0523 08:22:55.243921 34819 solver.cpp:239] Iteration 76360 (3.23006 iter/s, 3.09592s/10 iters), loss = 7.80691
I0523 08:22:55.243968 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80691 (* 1 = 7.80691 loss)
I0523 08:22:55.318255 34819 sgd_solver.cpp:112] Iteration 76360, lr = 0.01
I0523 08:23:00.759891 34819 solver.cpp:239] Iteration 76370 (1.81302 iter/s, 5.51565s/10 iters), loss = 7.8954
I0523 08:23:00.759954 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8954 (* 1 = 7.8954 loss)
I0523 08:23:01.584496 34819 sgd_solver.cpp:112] Iteration 76370, lr = 0.01
I0523 08:23:05.858585 34819 solver.cpp:239] Iteration 76380 (1.9614 iter/s, 5.09841s/10 iters), loss = 7.6436
I0523 08:23:05.858783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6436 (* 1 = 7.6436 loss)
I0523 08:23:05.918848 34819 sgd_solver.cpp:112] Iteration 76380, lr = 0.01
I0523 08:23:12.652637 34819 solver.cpp:239] Iteration 76390 (1.47198 iter/s, 6.79358s/10 iters), loss = 8.68964
I0523 08:23:12.652694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68964 (* 1 = 8.68964 loss)
I0523 08:23:13.486901 34819 sgd_solver.cpp:112] Iteration 76390, lr = 0.01
I0523 08:23:17.441866 34819 solver.cpp:239] Iteration 76400 (2.08813 iter/s, 4.78898s/10 iters), loss = 7.99572
I0523 08:23:17.441912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99572 (* 1 = 7.99572 loss)
I0523 08:23:18.111434 34819 sgd_solver.cpp:112] Iteration 76400, lr = 0.01
I0523 08:23:19.883085 34819 solver.cpp:239] Iteration 76410 (4.09657 iter/s, 2.44107s/10 iters), loss = 8.00149
I0523 08:23:19.883126 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00149 (* 1 = 8.00149 loss)
I0523 08:23:19.963840 34819 sgd_solver.cpp:112] Iteration 76410, lr = 0.01
I0523 08:23:24.967646 34819 solver.cpp:239] Iteration 76420 (1.96684 iter/s, 5.08431s/10 iters), loss = 6.76604
I0523 08:23:24.967694 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.76604 (* 1 = 6.76604 loss)
I0523 08:23:25.818500 34819 sgd_solver.cpp:112] Iteration 76420, lr = 0.01
I0523 08:23:28.901554 34819 solver.cpp:239] Iteration 76430 (2.54215 iter/s, 3.93368s/10 iters), loss = 7.55664
I0523 08:23:28.901600 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55664 (* 1 = 7.55664 loss)
I0523 08:23:29.762656 34819 sgd_solver.cpp:112] Iteration 76430, lr = 0.01
I0523 08:23:36.015816 34819 solver.cpp:239] Iteration 76440 (1.40569 iter/s, 7.11393s/10 iters), loss = 7.77872
I0523 08:23:36.016042 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77872 (* 1 = 7.77872 loss)
I0523 08:23:36.889178 34819 sgd_solver.cpp:112] Iteration 76440, lr = 0.01
I0523 08:23:41.099058 34819 solver.cpp:239] Iteration 76450 (1.96741 iter/s, 5.08282s/10 iters), loss = 7.88559
I0523 08:23:41.099109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88559 (* 1 = 7.88559 loss)
I0523 08:23:41.889459 34819 sgd_solver.cpp:112] Iteration 76450, lr = 0.01
I0523 08:23:46.505534 34819 solver.cpp:239] Iteration 76460 (1.84973 iter/s, 5.40619s/10 iters), loss = 7.52186
I0523 08:23:46.505585 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52186 (* 1 = 7.52186 loss)
I0523 08:23:46.579077 34819 sgd_solver.cpp:112] Iteration 76460, lr = 0.01
I0523 08:23:52.224853 34819 solver.cpp:239] Iteration 76470 (1.74856 iter/s, 5.719s/10 iters), loss = 7.77696
I0523 08:23:52.224925 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77696 (* 1 = 7.77696 loss)
I0523 08:23:53.071599 34819 sgd_solver.cpp:112] Iteration 76470, lr = 0.01
I0523 08:23:58.203626 34819 solver.cpp:239] Iteration 76480 (1.67268 iter/s, 5.97844s/10 iters), loss = 7.96813
I0523 08:23:58.203677 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96813 (* 1 = 7.96813 loss)
I0523 08:23:58.274142 34819 sgd_solver.cpp:112] Iteration 76480, lr = 0.01
I0523 08:24:01.695595 34819 solver.cpp:239] Iteration 76490 (2.86389 iter/s, 3.49176s/10 iters), loss = 7.90172
I0523 08:24:01.695639 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90172 (* 1 = 7.90172 loss)
I0523 08:24:01.763913 34819 sgd_solver.cpp:112] Iteration 76490, lr = 0.01
I0523 08:24:07.071326 34819 solver.cpp:239] Iteration 76500 (1.86031 iter/s, 5.37545s/10 iters), loss = 7.5983
I0523 08:24:07.071470 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5983 (* 1 = 7.5983 loss)
I0523 08:24:07.914793 34819 sgd_solver.cpp:112] Iteration 76500, lr = 0.01
I0523 08:24:11.537215 34819 solver.cpp:239] Iteration 76510 (2.23936 iter/s, 4.46556s/10 iters), loss = 7.97385
I0523 08:24:11.537257 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.97385 (* 1 = 7.97385 loss)
I0523 08:24:12.362746 34819 sgd_solver.cpp:112] Iteration 76510, lr = 0.01
I0523 08:24:16.451441 34819 solver.cpp:239] Iteration 76520 (2.03501 iter/s, 4.91397s/10 iters), loss = 8.4934
I0523 08:24:16.451501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4934 (* 1 = 8.4934 loss)
I0523 08:24:16.519086 34819 sgd_solver.cpp:112] Iteration 76520, lr = 0.01
I0523 08:24:22.196835 34819 solver.cpp:239] Iteration 76530 (1.74062 iter/s, 5.74509s/10 iters), loss = 7.20368
I0523 08:24:22.196877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20368 (* 1 = 7.20368 loss)
I0523 08:24:22.262296 34819 sgd_solver.cpp:112] Iteration 76530, lr = 0.01
I0523 08:24:27.618013 34819 solver.cpp:239] Iteration 76540 (1.84471 iter/s, 5.4209s/10 iters), loss = 7.34147
I0523 08:24:27.618064 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.34147 (* 1 = 7.34147 loss)
I0523 08:24:27.723799 34819 sgd_solver.cpp:112] Iteration 76540, lr = 0.01
I0523 08:24:32.631819 34819 solver.cpp:239] Iteration 76550 (1.9946 iter/s, 5.01355s/10 iters), loss = 7.88213
I0523 08:24:32.631858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88213 (* 1 = 7.88213 loss)
I0523 08:24:32.691823 34819 sgd_solver.cpp:112] Iteration 76550, lr = 0.01
I0523 08:24:35.189870 34819 solver.cpp:239] Iteration 76560 (3.90951 iter/s, 2.55787s/10 iters), loss = 8.62796
I0523 08:24:35.189945 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62796 (* 1 = 8.62796 loss)
I0523 08:24:36.071035 34819 sgd_solver.cpp:112] Iteration 76560, lr = 0.01
I0523 08:24:41.127996 34819 solver.cpp:239] Iteration 76570 (1.68412 iter/s, 5.9378s/10 iters), loss = 7.62121
I0523 08:24:41.128155 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62121 (* 1 = 7.62121 loss)
I0523 08:24:41.997999 34819 sgd_solver.cpp:112] Iteration 76570, lr = 0.01
I0523 08:24:47.244578 34819 solver.cpp:239] Iteration 76580 (1.63501 iter/s, 6.11616s/10 iters), loss = 7.74645
I0523 08:24:47.244630 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74645 (* 1 = 7.74645 loss)
I0523 08:24:48.058923 34819 sgd_solver.cpp:112] Iteration 76580, lr = 0.01
I0523 08:24:50.906644 34819 solver.cpp:239] Iteration 76590 (2.73086 iter/s, 3.66185s/10 iters), loss = 6.55714
I0523 08:24:50.906724 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.55714 (* 1 = 6.55714 loss)
I0523 08:24:51.661936 34819 sgd_solver.cpp:112] Iteration 76590, lr = 0.01
I0523 08:24:55.642900 34819 solver.cpp:239] Iteration 76600 (2.1115 iter/s, 4.73596s/10 iters), loss = 7.69221
I0523 08:24:55.642959 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69221 (* 1 = 7.69221 loss)
I0523 08:24:56.424767 34819 sgd_solver.cpp:112] Iteration 76600, lr = 0.01
I0523 08:25:02.116868 34819 solver.cpp:239] Iteration 76610 (1.54472 iter/s, 6.47364s/10 iters), loss = 8.217
I0523 08:25:02.116924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.217 (* 1 = 8.217 loss)
I0523 08:25:02.168566 34819 sgd_solver.cpp:112] Iteration 76610, lr = 0.01
I0523 08:25:07.160238 34819 solver.cpp:239] Iteration 76620 (1.98291 iter/s, 5.04309s/10 iters), loss = 8.08341
I0523 08:25:07.160310 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08341 (* 1 = 8.08341 loss)
I0523 08:25:07.991982 34819 sgd_solver.cpp:112] Iteration 76620, lr = 0.01
I0523 08:25:13.959648 34819 solver.cpp:239] Iteration 76630 (1.47079 iter/s, 6.79905s/10 iters), loss = 7.2171
I0523 08:25:13.959867 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2171 (* 1 = 7.2171 loss)
I0523 08:25:14.029161 34819 sgd_solver.cpp:112] Iteration 76630, lr = 0.01
I0523 08:25:19.016458 34819 solver.cpp:239] Iteration 76640 (1.97769 iter/s, 5.0564s/10 iters), loss = 7.12917
I0523 08:25:19.016510 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.12917 (* 1 = 7.12917 loss)
I0523 08:25:19.876209 34819 sgd_solver.cpp:112] Iteration 76640, lr = 0.01
I0523 08:25:26.867560 34819 solver.cpp:239] Iteration 76650 (1.27377 iter/s, 7.85072s/10 iters), loss = 8.0611
I0523 08:25:26.867617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0611 (* 1 = 8.0611 loss)
I0523 08:25:27.710039 34819 sgd_solver.cpp:112] Iteration 76650, lr = 0.01
I0523 08:25:32.589399 34819 solver.cpp:239] Iteration 76660 (1.74778 iter/s, 5.72155s/10 iters), loss = 7.6716
I0523 08:25:32.589443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6716 (* 1 = 7.6716 loss)
I0523 08:25:33.431351 34819 sgd_solver.cpp:112] Iteration 76660, lr = 0.01
I0523 08:25:38.280854 34819 solver.cpp:239] Iteration 76670 (1.75711 iter/s, 5.69117s/10 iters), loss = 8.47458
I0523 08:25:38.280907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47458 (* 1 = 8.47458 loss)
I0523 08:25:39.148051 34819 sgd_solver.cpp:112] Iteration 76670, lr = 0.01
I0523 08:25:42.469269 34819 solver.cpp:239] Iteration 76680 (2.38767 iter/s, 4.18818s/10 iters), loss = 8.37547
I0523 08:25:42.469313 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.37547 (* 1 = 8.37547 loss)
I0523 08:25:43.267365 34819 sgd_solver.cpp:112] Iteration 76680, lr = 0.01
I0523 08:25:49.768643 34819 solver.cpp:239] Iteration 76690 (1.37005 iter/s, 7.29902s/10 iters), loss = 8.8794
I0523 08:25:49.768813 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.8794 (* 1 = 8.8794 loss)
I0523 08:25:49.833508 34819 sgd_solver.cpp:112] Iteration 76690, lr = 0.01
I0523 08:25:53.922751 34819 solver.cpp:239] Iteration 76700 (2.40747 iter/s, 4.15374s/10 iters), loss = 7.51763
I0523 08:25:53.922817 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51763 (* 1 = 7.51763 loss)
I0523 08:25:53.979898 34819 sgd_solver.cpp:112] Iteration 76700, lr = 0.01
I0523 08:25:57.321137 34819 solver.cpp:239] Iteration 76710 (2.94277 iter/s, 3.39816s/10 iters), loss = 6.91497
I0523 08:25:57.321195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.91497 (* 1 = 6.91497 loss)
I0523 08:25:57.377279 34819 sgd_solver.cpp:112] Iteration 76710, lr = 0.01
I0523 08:26:00.887004 34819 solver.cpp:239] Iteration 76720 (2.80454 iter/s, 3.56565s/10 iters), loss = 7.83938
I0523 08:26:00.887058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83938 (* 1 = 7.83938 loss)
I0523 08:26:01.779224 34819 sgd_solver.cpp:112] Iteration 76720, lr = 0.01
I0523 08:26:06.766461 34819 solver.cpp:239] Iteration 76730 (1.70092 iter/s, 5.87916s/10 iters), loss = 7.70853
I0523 08:26:06.766530 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70853 (* 1 = 7.70853 loss)
I0523 08:26:06.817718 34819 sgd_solver.cpp:112] Iteration 76730, lr = 0.01
I0523 08:26:11.867555 34819 solver.cpp:239] Iteration 76740 (1.96047 iter/s, 5.10081s/10 iters), loss = 8.49139
I0523 08:26:11.867609 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49139 (* 1 = 8.49139 loss)
I0523 08:26:11.927413 34819 sgd_solver.cpp:112] Iteration 76740, lr = 0.01
I0523 08:26:15.833792 34819 solver.cpp:239] Iteration 76750 (2.52142 iter/s, 3.96602s/10 iters), loss = 7.35143
I0523 08:26:15.833837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35143 (* 1 = 7.35143 loss)
I0523 08:26:15.902084 34819 sgd_solver.cpp:112] Iteration 76750, lr = 0.01
I0523 08:26:20.923996 34819 solver.cpp:239] Iteration 76760 (1.96466 iter/s, 5.08993s/10 iters), loss = 7.65203
I0523 08:26:20.924207 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65203 (* 1 = 7.65203 loss)
I0523 08:26:20.986901 34819 sgd_solver.cpp:112] Iteration 76760, lr = 0.01
I0523 08:26:26.709520 34819 solver.cpp:239] Iteration 76770 (1.72859 iter/s, 5.78507s/10 iters), loss = 8.08943
I0523 08:26:26.709586 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08943 (* 1 = 8.08943 loss)
I0523 08:26:27.567466 34819 sgd_solver.cpp:112] Iteration 76770, lr = 0.01
I0523 08:26:30.141062 34819 solver.cpp:239] Iteration 76780 (2.91432 iter/s, 3.43133s/10 iters), loss = 7.63923
I0523 08:26:30.141111 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63923 (* 1 = 7.63923 loss)
I0523 08:26:30.851199 34819 sgd_solver.cpp:112] Iteration 76780, lr = 0.01
I0523 08:26:35.545692 34819 solver.cpp:239] Iteration 76790 (1.85036 iter/s, 5.40434s/10 iters), loss = 7.26747
I0523 08:26:35.545735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26747 (* 1 = 7.26747 loss)
I0523 08:26:36.360883 34819 sgd_solver.cpp:112] Iteration 76790, lr = 0.01
I0523 08:26:42.032444 34819 solver.cpp:239] Iteration 76800 (1.54168 iter/s, 6.48644s/10 iters), loss = 7.91157
I0523 08:26:42.032495 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91157 (* 1 = 7.91157 loss)
I0523 08:26:42.089136 34819 sgd_solver.cpp:112] Iteration 76800, lr = 0.01
I0523 08:26:45.249518 34819 solver.cpp:239] Iteration 76810 (3.1086 iter/s, 3.21688s/10 iters), loss = 8.06175
I0523 08:26:45.249560 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06175 (* 1 = 8.06175 loss)
I0523 08:26:45.332933 34819 sgd_solver.cpp:112] Iteration 76810, lr = 0.01
I0523 08:26:48.794091 34819 solver.cpp:239] Iteration 76820 (2.82137 iter/s, 3.54438s/10 iters), loss = 7.20012
I0523 08:26:48.794147 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20012 (* 1 = 7.20012 loss)
I0523 08:26:48.863651 34819 sgd_solver.cpp:112] Iteration 76820, lr = 0.01
I0523 08:26:53.926754 34819 solver.cpp:239] Iteration 76830 (1.94841 iter/s, 5.1324s/10 iters), loss = 7.4757
I0523 08:26:53.926952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4757 (* 1 = 7.4757 loss)
I0523 08:26:54.747643 34819 sgd_solver.cpp:112] Iteration 76830, lr = 0.01
I0523 08:27:00.275918 34819 solver.cpp:239] Iteration 76840 (1.57512 iter/s, 6.34872s/10 iters), loss = 8.17122
I0523 08:27:00.275964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17122 (* 1 = 8.17122 loss)
I0523 08:27:00.337232 34819 sgd_solver.cpp:112] Iteration 76840, lr = 0.01
I0523 08:27:04.303869 34819 solver.cpp:239] Iteration 76850 (2.48279 iter/s, 4.02773s/10 iters), loss = 8.4382
I0523 08:27:04.303913 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.4382 (* 1 = 8.4382 loss)
I0523 08:27:05.141353 34819 sgd_solver.cpp:112] Iteration 76850, lr = 0.01
I0523 08:27:08.368166 34819 solver.cpp:239] Iteration 76860 (2.46059 iter/s, 4.06407s/10 iters), loss = 6.84853
I0523 08:27:08.368211 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.84853 (* 1 = 6.84853 loss)
I0523 08:27:08.445569 34819 sgd_solver.cpp:112] Iteration 76860, lr = 0.01
I0523 08:27:13.483803 34819 solver.cpp:239] Iteration 76870 (1.95489 iter/s, 5.11538s/10 iters), loss = 7.45866
I0523 08:27:13.483845 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.45866 (* 1 = 7.45866 loss)
I0523 08:27:13.563773 34819 sgd_solver.cpp:112] Iteration 76870, lr = 0.01
I0523 08:27:16.955024 34819 solver.cpp:239] Iteration 76880 (2.88099 iter/s, 3.47103s/10 iters), loss = 7.68048
I0523 08:27:16.955080 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68048 (* 1 = 7.68048 loss)
I0523 08:27:17.046785 34819 sgd_solver.cpp:112] Iteration 76880, lr = 0.01
I0523 08:27:20.635061 34819 solver.cpp:239] Iteration 76890 (2.72082 iter/s, 3.67536s/10 iters), loss = 8.07937
I0523 08:27:20.635134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07937 (* 1 = 8.07937 loss)
I0523 08:27:20.696923 34819 sgd_solver.cpp:112] Iteration 76890, lr = 0.01
I0523 08:27:24.837782 34819 solver.cpp:239] Iteration 76900 (2.37955 iter/s, 4.20247s/10 iters), loss = 7.83154
I0523 08:27:24.837985 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83154 (* 1 = 7.83154 loss)
I0523 08:27:25.713258 34819 sgd_solver.cpp:112] Iteration 76900, lr = 0.01
I0523 08:27:31.944977 34819 solver.cpp:239] Iteration 76910 (1.40712 iter/s, 7.1067s/10 iters), loss = 7.68914
I0523 08:27:31.945024 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68914 (* 1 = 7.68914 loss)
I0523 08:27:32.029785 34819 sgd_solver.cpp:112] Iteration 76910, lr = 0.01
I0523 08:27:35.222627 34819 solver.cpp:239] Iteration 76920 (3.05115 iter/s, 3.27745s/10 iters), loss = 7.98493
I0523 08:27:35.222671 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98493 (* 1 = 7.98493 loss)
I0523 08:27:36.054945 34819 sgd_solver.cpp:112] Iteration 76920, lr = 0.01
I0523 08:27:41.436230 34819 solver.cpp:239] Iteration 76930 (1.60945 iter/s, 6.2133s/10 iters), loss = 7.85183
I0523 08:27:41.436273 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85183 (* 1 = 7.85183 loss)
I0523 08:27:42.260118 34819 sgd_solver.cpp:112] Iteration 76930, lr = 0.01
I0523 08:27:47.798570 34819 solver.cpp:239] Iteration 76940 (1.57183 iter/s, 6.36202s/10 iters), loss = 8.46164
I0523 08:27:47.798621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.46164 (* 1 = 8.46164 loss)
I0523 08:27:47.865723 34819 sgd_solver.cpp:112] Iteration 76940, lr = 0.01
I0523 08:27:50.898910 34819 solver.cpp:239] Iteration 76950 (3.22566 iter/s, 3.10014s/10 iters), loss = 6.91446
I0523 08:27:50.898963 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.91446 (* 1 = 6.91446 loss)
I0523 08:27:51.480494 34819 sgd_solver.cpp:112] Iteration 76950, lr = 0.01
I0523 08:27:56.156183 34819 solver.cpp:239] Iteration 76960 (1.90223 iter/s, 5.25699s/10 iters), loss = 7.87108
I0523 08:27:56.156342 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87108 (* 1 = 7.87108 loss)
I0523 08:27:56.233585 34819 sgd_solver.cpp:112] Iteration 76960, lr = 0.01
I0523 08:27:59.990864 34819 solver.cpp:239] Iteration 76970 (2.60801 iter/s, 3.83435s/10 iters), loss = 7.78613
I0523 08:27:59.990924 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78613 (* 1 = 7.78613 loss)
I0523 08:28:00.831727 34819 sgd_solver.cpp:112] Iteration 76970, lr = 0.01
I0523 08:28:04.860594 34819 solver.cpp:239] Iteration 76980 (2.05361 iter/s, 4.86947s/10 iters), loss = 7.53009
I0523 08:28:04.860651 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53009 (* 1 = 7.53009 loss)
I0523 08:28:04.935554 34819 sgd_solver.cpp:112] Iteration 76980, lr = 0.01
I0523 08:28:07.852064 34819 solver.cpp:239] Iteration 76990 (3.34306 iter/s, 2.99127s/10 iters), loss = 7.99855
I0523 08:28:07.852114 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99855 (* 1 = 7.99855 loss)
I0523 08:28:07.910482 34819 sgd_solver.cpp:112] Iteration 76990, lr = 0.01
I0523 08:28:11.319602 34819 solver.cpp:239] Iteration 77000 (2.88407 iter/s, 3.46732s/10 iters), loss = 8.94719
I0523 08:28:11.319656 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.94719 (* 1 = 8.94719 loss)
I0523 08:28:11.390203 34819 sgd_solver.cpp:112] Iteration 77000, lr = 0.01
I0523 08:28:16.448894 34819 solver.cpp:239] Iteration 77010 (1.94969 iter/s, 5.12902s/10 iters), loss = 7.06337
I0523 08:28:16.448952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.06337 (* 1 = 7.06337 loss)
I0523 08:28:16.521309 34819 sgd_solver.cpp:112] Iteration 77010, lr = 0.01
I0523 08:28:22.110510 34819 solver.cpp:239] Iteration 77020 (1.76637 iter/s, 5.66133s/10 iters), loss = 8.6858
I0523 08:28:22.110569 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6858 (* 1 = 8.6858 loss)
I0523 08:28:22.926040 34819 sgd_solver.cpp:112] Iteration 77020, lr = 0.01
I0523 08:28:27.537040 34819 solver.cpp:239] Iteration 77030 (1.84289 iter/s, 5.42625s/10 iters), loss = 7.71656
I0523 08:28:27.537261 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71656 (* 1 = 7.71656 loss)
I0523 08:28:28.377764 34819 sgd_solver.cpp:112] Iteration 77030, lr = 0.01
I0523 08:28:32.202201 34819 solver.cpp:239] Iteration 77040 (2.14374 iter/s, 4.66475s/10 iters), loss = 8.63248
I0523 08:28:32.202255 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.63248 (* 1 = 8.63248 loss)
I0523 08:28:33.019948 34819 sgd_solver.cpp:112] Iteration 77040, lr = 0.01
I0523 08:28:37.276437 34819 solver.cpp:239] Iteration 77050 (1.97084 iter/s, 5.07397s/10 iters), loss = 7.74859
I0523 08:28:37.276482 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74859 (* 1 = 7.74859 loss)
I0523 08:28:37.948829 34819 sgd_solver.cpp:112] Iteration 77050, lr = 0.01
I0523 08:28:43.442358 34819 solver.cpp:239] Iteration 77060 (1.6219 iter/s, 6.16561s/10 iters), loss = 8.30785
I0523 08:28:43.442410 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30785 (* 1 = 8.30785 loss)
I0523 08:28:43.494505 34819 sgd_solver.cpp:112] Iteration 77060, lr = 0.01
I0523 08:28:47.702400 34819 solver.cpp:239] Iteration 77070 (2.34753 iter/s, 4.2598s/10 iters), loss = 7.95974
I0523 08:28:47.702462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95974 (* 1 = 7.95974 loss)
I0523 08:28:48.524469 34819 sgd_solver.cpp:112] Iteration 77070, lr = 0.01
I0523 08:28:53.583320 34819 solver.cpp:239] Iteration 77080 (1.7005 iter/s, 5.88062s/10 iters), loss = 7.41138
I0523 08:28:53.583374 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.41138 (* 1 = 7.41138 loss)
I0523 08:28:53.654938 34819 sgd_solver.cpp:112] Iteration 77080, lr = 0.01
I0523 08:29:00.049041 34819 solver.cpp:239] Iteration 77090 (1.5467 iter/s, 6.4654s/10 iters), loss = 7.28126
I0523 08:29:00.049253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28126 (* 1 = 7.28126 loss)
I0523 08:29:00.741367 34819 sgd_solver.cpp:112] Iteration 77090, lr = 0.01
I0523 08:29:03.986117 34819 solver.cpp:239] Iteration 77100 (2.54021 iter/s, 3.93669s/10 iters), loss = 7.22002
I0523 08:29:03.986184 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22002 (* 1 = 7.22002 loss)
I0523 08:29:04.046900 34819 sgd_solver.cpp:112] Iteration 77100, lr = 0.01
I0523 08:29:09.865545 34819 solver.cpp:239] Iteration 77110 (1.70094 iter/s, 5.8791s/10 iters), loss = 7.46657
I0523 08:29:09.865598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.46657 (* 1 = 7.46657 loss)
I0523 08:29:10.693544 34819 sgd_solver.cpp:112] Iteration 77110, lr = 0.01
I0523 08:29:15.581835 34819 solver.cpp:239] Iteration 77120 (1.74948 iter/s, 5.716s/10 iters), loss = 8.6061
I0523 08:29:15.581907 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.6061 (* 1 = 8.6061 loss)
I0523 08:29:16.441746 34819 sgd_solver.cpp:112] Iteration 77120, lr = 0.01
I0523 08:29:19.978942 34819 solver.cpp:239] Iteration 77130 (2.27436 iter/s, 4.39685s/10 iters), loss = 6.78626
I0523 08:29:19.978986 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.78626 (* 1 = 6.78626 loss)
I0523 08:29:20.034214 34819 sgd_solver.cpp:112] Iteration 77130, lr = 0.01
I0523 08:29:25.581809 34819 solver.cpp:239] Iteration 77140 (1.7849 iter/s, 5.60256s/10 iters), loss = 7.25863
I0523 08:29:25.581866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.25863 (* 1 = 7.25863 loss)
I0523 08:29:25.639235 34819 sgd_solver.cpp:112] Iteration 77140, lr = 0.01
I0523 08:29:32.335965 34819 solver.cpp:239] Iteration 77150 (1.48065 iter/s, 6.75381s/10 iters), loss = 7.50559
I0523 08:29:32.336136 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50559 (* 1 = 7.50559 loss)
I0523 08:29:32.392284 34819 sgd_solver.cpp:112] Iteration 77150, lr = 0.01
I0523 08:29:37.443112 34819 solver.cpp:239] Iteration 77160 (1.95917 iter/s, 5.1042s/10 iters), loss = 7.5548
I0523 08:29:37.443158 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5548 (* 1 = 7.5548 loss)
I0523 08:29:37.497733 34819 sgd_solver.cpp:112] Iteration 77160, lr = 0.01
I0523 08:29:43.692505 34819 solver.cpp:239] Iteration 77170 (1.60023 iter/s, 6.24909s/10 iters), loss = 7.83924
I0523 08:29:43.692557 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83924 (* 1 = 7.83924 loss)
I0523 08:29:43.767729 34819 sgd_solver.cpp:112] Iteration 77170, lr = 0.01
I0523 08:29:50.212425 34819 solver.cpp:239] Iteration 77180 (1.53384 iter/s, 6.51959s/10 iters), loss = 7.27455
I0523 08:29:50.212492 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.27455 (* 1 = 7.27455 loss)
I0523 08:29:50.287442 34819 sgd_solver.cpp:112] Iteration 77180, lr = 0.01
I0523 08:29:56.690201 34819 solver.cpp:239] Iteration 77190 (1.54382 iter/s, 6.47743s/10 iters), loss = 8.24583
I0523 08:29:56.690266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24583 (* 1 = 8.24583 loss)
I0523 08:29:56.746922 34819 sgd_solver.cpp:112] Iteration 77190, lr = 0.01
I0523 08:30:03.431993 34819 solver.cpp:239] Iteration 77200 (1.48336 iter/s, 6.74145s/10 iters), loss = 8.14089
I0523 08:30:03.432150 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14089 (* 1 = 8.14089 loss)
I0523 08:30:04.278187 34819 sgd_solver.cpp:112] Iteration 77200, lr = 0.01
I0523 08:30:09.125392 34819 solver.cpp:239] Iteration 77210 (1.75654 iter/s, 5.69301s/10 iters), loss = 7.26487
I0523 08:30:09.125442 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26487 (* 1 = 7.26487 loss)
I0523 08:30:09.181267 34819 sgd_solver.cpp:112] Iteration 77210, lr = 0.01
I0523 08:30:13.936307 34819 solver.cpp:239] Iteration 77220 (2.07873 iter/s, 4.81064s/10 iters), loss = 7.77222
I0523 08:30:13.936364 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77222 (* 1 = 7.77222 loss)
I0523 08:30:14.336684 34819 sgd_solver.cpp:112] Iteration 77220, lr = 0.01
I0523 08:30:19.617002 34819 solver.cpp:239] Iteration 77230 (1.76044 iter/s, 5.6804s/10 iters), loss = 8.52703
I0523 08:30:19.617055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.52703 (* 1 = 8.52703 loss)
I0523 08:30:20.318675 34819 sgd_solver.cpp:112] Iteration 77230, lr = 0.01
I0523 08:30:26.575533 34819 solver.cpp:239] Iteration 77240 (1.43715 iter/s, 6.9582s/10 iters), loss = 7.84853
I0523 08:30:26.575592 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.84853 (* 1 = 7.84853 loss)
I0523 08:30:27.380445 34819 sgd_solver.cpp:112] Iteration 77240, lr = 0.01
I0523 08:30:34.669427 34819 solver.cpp:239] Iteration 77250 (1.23556 iter/s, 8.09351s/10 iters), loss = 7.79956
I0523 08:30:34.669687 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79956 (* 1 = 7.79956 loss)
I0523 08:30:35.383083 34819 sgd_solver.cpp:112] Iteration 77250, lr = 0.01
I0523 08:30:39.598042 34819 solver.cpp:239] Iteration 77260 (2.02915 iter/s, 4.92818s/10 iters), loss = 6.81381
I0523 08:30:39.598095 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.81381 (* 1 = 6.81381 loss)
I0523 08:30:39.659796 34819 sgd_solver.cpp:112] Iteration 77260, lr = 0.01
I0523 08:30:43.758783 34819 solver.cpp:239] Iteration 77270 (2.40355 iter/s, 4.16051s/10 iters), loss = 8.00796
I0523 08:30:43.758833 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00796 (* 1 = 8.00796 loss)
I0523 08:30:44.520540 34819 sgd_solver.cpp:112] Iteration 77270, lr = 0.01
I0523 08:30:47.941520 34819 solver.cpp:239] Iteration 77280 (2.39091 iter/s, 4.18251s/10 iters), loss = 7.39744
I0523 08:30:47.941570 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39744 (* 1 = 7.39744 loss)
I0523 08:30:48.517911 34819 sgd_solver.cpp:112] Iteration 77280, lr = 0.01
I0523 08:30:53.001416 34819 solver.cpp:239] Iteration 77290 (1.97643 iter/s, 5.05964s/10 iters), loss = 8.09636
I0523 08:30:53.001469 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09636 (* 1 = 8.09636 loss)
I0523 08:30:53.702955 34819 sgd_solver.cpp:112] Iteration 77290, lr = 0.01
I0523 08:30:57.918784 34819 solver.cpp:239] Iteration 77300 (2.03372 iter/s, 4.9171s/10 iters), loss = 7.71811
I0523 08:30:57.918839 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71811 (* 1 = 7.71811 loss)
I0523 08:30:57.979611 34819 sgd_solver.cpp:112] Iteration 77300, lr = 0.01
I0523 08:31:02.257983 34819 solver.cpp:239] Iteration 77310 (2.30471 iter/s, 4.33894s/10 iters), loss = 7.20329
I0523 08:31:02.258034 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20329 (* 1 = 7.20329 loss)
I0523 08:31:02.489630 34819 sgd_solver.cpp:112] Iteration 77310, lr = 0.01
I0523 08:31:06.711161 34819 solver.cpp:239] Iteration 77320 (2.24571 iter/s, 4.45294s/10 iters), loss = 7.16176
I0523 08:31:06.711352 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.16176 (* 1 = 7.16176 loss)
I0523 08:31:07.501474 34819 sgd_solver.cpp:112] Iteration 77320, lr = 0.01
I0523 08:31:11.590912 34819 solver.cpp:239] Iteration 77330 (2.04944 iter/s, 4.87937s/10 iters), loss = 7.61803
I0523 08:31:11.590957 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61803 (* 1 = 7.61803 loss)
I0523 08:31:11.649297 34819 sgd_solver.cpp:112] Iteration 77330, lr = 0.01
I0523 08:31:18.222832 34819 solver.cpp:239] Iteration 77340 (1.50793 iter/s, 6.6316s/10 iters), loss = 8.80421
I0523 08:31:18.222887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.80421 (* 1 = 8.80421 loss)
I0523 08:31:18.292829 34819 sgd_solver.cpp:112] Iteration 77340, lr = 0.01
I0523 08:31:22.476685 34819 solver.cpp:239] Iteration 77350 (2.35094 iter/s, 4.25361s/10 iters), loss = 7.05522
I0523 08:31:22.476744 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.05522 (* 1 = 7.05522 loss)
I0523 08:31:22.544654 34819 sgd_solver.cpp:112] Iteration 77350, lr = 0.01
I0523 08:31:26.877985 34819 solver.cpp:239] Iteration 77360 (2.27218 iter/s, 4.40105s/10 iters), loss = 7.98298
I0523 08:31:26.878047 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.98298 (* 1 = 7.98298 loss)
I0523 08:31:26.940170 34819 sgd_solver.cpp:112] Iteration 77360, lr = 0.01
I0523 08:31:32.615737 34819 solver.cpp:239] Iteration 77370 (1.74293 iter/s, 5.73746s/10 iters), loss = 8.09864
I0523 08:31:32.615780 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09864 (* 1 = 8.09864 loss)
I0523 08:31:32.675293 34819 sgd_solver.cpp:112] Iteration 77370, lr = 0.01
I0523 08:31:38.540117 34819 solver.cpp:239] Iteration 77380 (1.68802 iter/s, 5.9241s/10 iters), loss = 6.48726
I0523 08:31:38.540347 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.48726 (* 1 = 6.48726 loss)
I0523 08:31:39.368271 34819 sgd_solver.cpp:112] Iteration 77380, lr = 0.01
I0523 08:31:45.107380 34819 solver.cpp:239] Iteration 77390 (1.52282 iter/s, 6.56678s/10 iters), loss = 6.912
I0523 08:31:45.107437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.912 (* 1 = 6.912 loss)
I0523 08:31:45.170770 34819 sgd_solver.cpp:112] Iteration 77390, lr = 0.01
I0523 08:31:49.106629 34819 solver.cpp:239] Iteration 77400 (2.50062 iter/s, 3.99901s/10 iters), loss = 6.82128
I0523 08:31:49.106675 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.82128 (* 1 = 6.82128 loss)
I0523 08:31:49.888998 34819 sgd_solver.cpp:112] Iteration 77400, lr = 0.01
I0523 08:31:53.962113 34819 solver.cpp:239] Iteration 77410 (2.05964 iter/s, 4.85523s/10 iters), loss = 7.5048
I0523 08:31:53.962169 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5048 (* 1 = 7.5048 loss)
I0523 08:31:54.764077 34819 sgd_solver.cpp:112] Iteration 77410, lr = 0.01
I0523 08:31:59.464448 34819 solver.cpp:239] Iteration 77420 (1.81751 iter/s, 5.50204s/10 iters), loss = 7.4589
I0523 08:31:59.464489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4589 (* 1 = 7.4589 loss)
I0523 08:31:59.519248 34819 sgd_solver.cpp:112] Iteration 77420, lr = 0.01
I0523 08:32:03.769968 34819 solver.cpp:239] Iteration 77430 (2.32273 iter/s, 4.30528s/10 iters), loss = 7.79564
I0523 08:32:03.770030 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79564 (* 1 = 7.79564 loss)
I0523 08:32:04.582073 34819 sgd_solver.cpp:112] Iteration 77430, lr = 0.01
I0523 08:32:10.040567 34819 solver.cpp:239] Iteration 77440 (1.59483 iter/s, 6.27027s/10 iters), loss = 7.85785
I0523 08:32:10.040807 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85785 (* 1 = 7.85785 loss)
I0523 08:32:10.097543 34819 sgd_solver.cpp:112] Iteration 77440, lr = 0.01
I0523 08:32:15.109462 34819 solver.cpp:239] Iteration 77450 (1.97299 iter/s, 5.06846s/10 iters), loss = 7.40635
I0523 08:32:15.109508 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40635 (* 1 = 7.40635 loss)
I0523 08:32:15.179527 34819 sgd_solver.cpp:112] Iteration 77450, lr = 0.01
I0523 08:32:18.468190 34819 solver.cpp:239] Iteration 77460 (2.97749 iter/s, 3.35854s/10 iters), loss = 7.34402
I0523 08:32:18.468235 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.34402 (* 1 = 7.34402 loss)
I0523 08:32:18.521905 34819 sgd_solver.cpp:112] Iteration 77460, lr = 0.01
I0523 08:32:22.622836 34819 solver.cpp:239] Iteration 77470 (2.40707 iter/s, 4.15443s/10 iters), loss = 6.71098
I0523 08:32:22.622877 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.71098 (* 1 = 6.71098 loss)
I0523 08:32:23.485889 34819 sgd_solver.cpp:112] Iteration 77470, lr = 0.01
I0523 08:32:29.539782 34819 solver.cpp:239] Iteration 77480 (1.44579 iter/s, 6.91663s/10 iters), loss = 7.59146
I0523 08:32:29.539824 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59146 (* 1 = 7.59146 loss)
I0523 08:32:29.610939 34819 sgd_solver.cpp:112] Iteration 77480, lr = 0.01
I0523 08:32:33.562497 34819 solver.cpp:239] Iteration 77490 (2.48601 iter/s, 4.0225s/10 iters), loss = 8.54941
I0523 08:32:33.562548 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.54941 (* 1 = 8.54941 loss)
I0523 08:32:33.617967 34819 sgd_solver.cpp:112] Iteration 77490, lr = 0.01
I0523 08:32:38.854020 34819 solver.cpp:239] Iteration 77500 (1.88991 iter/s, 5.29125s/10 iters), loss = 7.11197
I0523 08:32:38.854074 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.11197 (* 1 = 7.11197 loss)
I0523 08:32:38.929957 34819 sgd_solver.cpp:112] Iteration 77500, lr = 0.01
I0523 08:32:42.979377 34819 solver.cpp:239] Iteration 77510 (2.42418 iter/s, 4.12511s/10 iters), loss = 8.42114
I0523 08:32:42.979553 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42114 (* 1 = 8.42114 loss)
I0523 08:32:43.042045 34819 sgd_solver.cpp:112] Iteration 77510, lr = 0.01
I0523 08:32:47.854185 34819 solver.cpp:239] Iteration 77520 (2.05152 iter/s, 4.87443s/10 iters), loss = 8.60042
I0523 08:32:47.854241 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60042 (* 1 = 8.60042 loss)
I0523 08:32:48.716012 34819 sgd_solver.cpp:112] Iteration 77520, lr = 0.01
I0523 08:32:55.364807 34819 solver.cpp:239] Iteration 77530 (1.33151 iter/s, 7.51026s/10 iters), loss = 7.11477
I0523 08:32:55.364866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.11477 (* 1 = 7.11477 loss)
I0523 08:32:55.432360 34819 sgd_solver.cpp:112] Iteration 77530, lr = 0.01
I0523 08:33:00.283138 34819 solver.cpp:239] Iteration 77540 (2.03333 iter/s, 4.91805s/10 iters), loss = 7.92111
I0523 08:33:00.283197 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92111 (* 1 = 7.92111 loss)
I0523 08:33:00.349315 34819 sgd_solver.cpp:112] Iteration 77540, lr = 0.01
I0523 08:33:06.033112 34819 solver.cpp:239] Iteration 77550 (1.73923 iter/s, 5.74966s/10 iters), loss = 7.2512
I0523 08:33:06.033164 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2512 (* 1 = 7.2512 loss)
I0523 08:33:06.105788 34819 sgd_solver.cpp:112] Iteration 77550, lr = 0.01
I0523 08:33:08.673319 34819 solver.cpp:239] Iteration 77560 (3.78783 iter/s, 2.64004s/10 iters), loss = 7.13332
I0523 08:33:08.673372 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13332 (* 1 = 7.13332 loss)
I0523 08:33:08.734637 34819 sgd_solver.cpp:112] Iteration 77560, lr = 0.01
I0523 08:33:13.635224 34819 solver.cpp:239] Iteration 77570 (2.01546 iter/s, 4.96164s/10 iters), loss = 7.68227
I0523 08:33:13.635385 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68227 (* 1 = 7.68227 loss)
I0523 08:33:13.894775 34819 sgd_solver.cpp:112] Iteration 77570, lr = 0.01
I0523 08:33:20.751951 34819 solver.cpp:239] Iteration 77580 (1.40523 iter/s, 7.11627s/10 iters), loss = 7.8246
I0523 08:33:20.752005 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.8246 (* 1 = 7.8246 loss)
I0523 08:33:20.809376 34819 sgd_solver.cpp:112] Iteration 77580, lr = 0.01
I0523 08:33:26.017103 34819 solver.cpp:239] Iteration 77590 (1.89938 iter/s, 5.26488s/10 iters), loss = 7.35478
I0523 08:33:26.017159 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35478 (* 1 = 7.35478 loss)
I0523 08:33:26.247865 34819 sgd_solver.cpp:112] Iteration 77590, lr = 0.01
I0523 08:33:30.294487 34819 solver.cpp:239] Iteration 77600 (2.33801 iter/s, 4.27714s/10 iters), loss = 8.03251
I0523 08:33:30.294539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03251 (* 1 = 8.03251 loss)
I0523 08:33:31.128682 34819 sgd_solver.cpp:112] Iteration 77600, lr = 0.01
I0523 08:33:36.007258 34819 solver.cpp:239] Iteration 77610 (1.75055 iter/s, 5.71248s/10 iters), loss = 7.2153
I0523 08:33:36.007302 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2153 (* 1 = 7.2153 loss)
I0523 08:33:36.833505 34819 sgd_solver.cpp:112] Iteration 77610, lr = 0.01
I0523 08:33:42.691205 34819 solver.cpp:239] Iteration 77620 (1.49619 iter/s, 6.68362s/10 iters), loss = 8.02805
I0523 08:33:42.691267 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02805 (* 1 = 8.02805 loss)
I0523 08:33:42.760586 34819 sgd_solver.cpp:112] Iteration 77620, lr = 0.01
I0523 08:33:47.791668 34819 solver.cpp:239] Iteration 77630 (1.96071 iter/s, 5.10019s/10 iters), loss = 8.31981
I0523 08:33:47.791801 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31981 (* 1 = 8.31981 loss)
I0523 08:33:48.457792 34819 sgd_solver.cpp:112] Iteration 77630, lr = 0.01
I0523 08:33:53.321784 34819 solver.cpp:239] Iteration 77640 (1.8084 iter/s, 5.52976s/10 iters), loss = 8.58044
I0523 08:33:53.321830 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58044 (* 1 = 8.58044 loss)
I0523 08:33:54.142508 34819 sgd_solver.cpp:112] Iteration 77640, lr = 0.01
I0523 08:33:58.682953 34819 solver.cpp:239] Iteration 77650 (1.86536 iter/s, 5.3609s/10 iters), loss = 7.7585
I0523 08:33:58.683008 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7585 (* 1 = 7.7585 loss)
I0523 08:33:58.756036 34819 sgd_solver.cpp:112] Iteration 77650, lr = 0.01
I0523 08:34:01.450362 34819 solver.cpp:239] Iteration 77660 (3.61373 iter/s, 2.76722s/10 iters), loss = 7.24718
I0523 08:34:01.450403 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.24718 (* 1 = 7.24718 loss)
I0523 08:34:01.531823 34819 sgd_solver.cpp:112] Iteration 77660, lr = 0.01
I0523 08:34:04.144246 34819 solver.cpp:239] Iteration 77670 (3.71236 iter/s, 2.69371s/10 iters), loss = 7.76646
I0523 08:34:04.144299 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76646 (* 1 = 7.76646 loss)
I0523 08:34:04.853338 34819 sgd_solver.cpp:112] Iteration 77670, lr = 0.01
I0523 08:34:08.233191 34819 solver.cpp:239] Iteration 77680 (2.44575 iter/s, 4.08872s/10 iters), loss = 8.51392
I0523 08:34:08.233233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51392 (* 1 = 8.51392 loss)
I0523 08:34:08.293980 34819 sgd_solver.cpp:112] Iteration 77680, lr = 0.01
I0523 08:34:12.514569 34819 solver.cpp:239] Iteration 77690 (2.33582 iter/s, 4.28116s/10 iters), loss = 7.93206
I0523 08:34:12.514621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93206 (* 1 = 7.93206 loss)
I0523 08:34:12.589476 34819 sgd_solver.cpp:112] Iteration 77690, lr = 0.01
I0523 08:34:17.082381 34819 solver.cpp:239] Iteration 77700 (2.18935 iter/s, 4.56756s/10 iters), loss = 8.56302
I0523 08:34:17.082432 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56302 (* 1 = 8.56302 loss)
I0523 08:34:17.140607 34819 sgd_solver.cpp:112] Iteration 77700, lr = 0.01
I0523 08:34:20.548607 34819 solver.cpp:239] Iteration 77710 (2.88515 iter/s, 3.46602s/10 iters), loss = 7.99413
I0523 08:34:20.548890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99413 (* 1 = 7.99413 loss)
I0523 08:34:20.641594 34819 sgd_solver.cpp:112] Iteration 77710, lr = 0.01
I0523 08:34:24.226007 34819 solver.cpp:239] Iteration 77720 (2.71963 iter/s, 3.67698s/10 iters), loss = 7.76834
I0523 08:34:24.226058 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76834 (* 1 = 7.76834 loss)
I0523 08:34:24.294826 34819 sgd_solver.cpp:112] Iteration 77720, lr = 0.01
I0523 08:34:29.574070 34819 solver.cpp:239] Iteration 77730 (1.87147 iter/s, 5.34339s/10 iters), loss = 7.91951
I0523 08:34:29.574120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.91951 (* 1 = 7.91951 loss)
I0523 08:34:29.633538 34819 sgd_solver.cpp:112] Iteration 77730, lr = 0.01
I0523 08:34:35.345924 34819 solver.cpp:239] Iteration 77740 (1.73263 iter/s, 5.77156s/10 iters), loss = 7.59964
I0523 08:34:35.345990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59964 (* 1 = 7.59964 loss)
I0523 08:34:36.147354 34819 sgd_solver.cpp:112] Iteration 77740, lr = 0.01
I0523 08:34:40.998046 34819 solver.cpp:239] Iteration 77750 (1.76934 iter/s, 5.65182s/10 iters), loss = 8.65223
I0523 08:34:40.998111 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65223 (* 1 = 8.65223 loss)
I0523 08:34:41.064391 34819 sgd_solver.cpp:112] Iteration 77750, lr = 0.01
I0523 08:34:44.415626 34819 solver.cpp:239] Iteration 77760 (2.92623 iter/s, 3.41737s/10 iters), loss = 8.21394
I0523 08:34:44.415678 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21394 (* 1 = 8.21394 loss)
I0523 08:34:45.133610 34819 sgd_solver.cpp:112] Iteration 77760, lr = 0.01
I0523 08:34:49.215697 34819 solver.cpp:239] Iteration 77770 (2.08342 iter/s, 4.79979s/10 iters), loss = 7.65928
I0523 08:34:49.215739 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65928 (* 1 = 7.65928 loss)
I0523 08:34:49.289487 34819 sgd_solver.cpp:112] Iteration 77770, lr = 0.01
I0523 08:34:54.335031 34819 solver.cpp:239] Iteration 77780 (1.95349 iter/s, 5.11906s/10 iters), loss = 7.73147
I0523 08:34:54.335250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73147 (* 1 = 7.73147 loss)
I0523 08:34:55.057394 34819 sgd_solver.cpp:112] Iteration 77780, lr = 0.01
I0523 08:35:00.873231 34819 solver.cpp:239] Iteration 77790 (1.52958 iter/s, 6.53773s/10 iters), loss = 7.03562
I0523 08:35:00.873297 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.03562 (* 1 = 7.03562 loss)
I0523 08:35:01.752028 34819 sgd_solver.cpp:112] Iteration 77790, lr = 0.01
I0523 08:35:07.426784 34819 solver.cpp:239] Iteration 77800 (1.52597 iter/s, 6.55322s/10 iters), loss = 7.61822
I0523 08:35:07.426832 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61822 (* 1 = 7.61822 loss)
I0523 08:35:07.483639 34819 sgd_solver.cpp:112] Iteration 77800, lr = 0.01
I0523 08:35:12.533658 34819 solver.cpp:239] Iteration 77810 (1.95824 iter/s, 5.10662s/10 iters), loss = 7.49754
I0523 08:35:12.533716 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.49754 (* 1 = 7.49754 loss)
I0523 08:35:12.606739 34819 sgd_solver.cpp:112] Iteration 77810, lr = 0.01
I0523 08:35:17.026752 34819 solver.cpp:239] Iteration 77820 (2.22577 iter/s, 4.49283s/10 iters), loss = 7.95928
I0523 08:35:17.026808 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.95928 (* 1 = 7.95928 loss)
I0523 08:35:17.110471 34819 sgd_solver.cpp:112] Iteration 77820, lr = 0.01
I0523 08:35:22.105485 34819 solver.cpp:239] Iteration 77830 (1.9691 iter/s, 5.07847s/10 iters), loss = 7.6628
I0523 08:35:22.105528 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6628 (* 1 = 7.6628 loss)
I0523 08:35:22.153405 34819 sgd_solver.cpp:112] Iteration 77830, lr = 0.01
I0523 08:35:26.289392 34819 solver.cpp:239] Iteration 77840 (2.39024 iter/s, 4.18367s/10 iters), loss = 8.09677
I0523 08:35:26.289618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09677 (* 1 = 8.09677 loss)
I0523 08:35:27.170753 34819 sgd_solver.cpp:112] Iteration 77840, lr = 0.01
I0523 08:35:30.138980 34819 solver.cpp:239] Iteration 77850 (2.59793 iter/s, 3.84922s/10 iters), loss = 7.20232
I0523 08:35:30.139053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20232 (* 1 = 7.20232 loss)
I0523 08:35:30.211469 34819 sgd_solver.cpp:112] Iteration 77850, lr = 0.01
I0523 08:35:34.650795 34819 solver.cpp:239] Iteration 77860 (2.21654 iter/s, 4.51154s/10 iters), loss = 9.08236
I0523 08:35:34.650851 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.08236 (* 1 = 9.08236 loss)
I0523 08:35:34.754623 34819 sgd_solver.cpp:112] Iteration 77860, lr = 0.01
I0523 08:35:39.350286 34819 solver.cpp:239] Iteration 77870 (2.12801 iter/s, 4.69923s/10 iters), loss = 8.23482
I0523 08:35:39.350337 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23482 (* 1 = 8.23482 loss)
I0523 08:35:40.200448 34819 sgd_solver.cpp:112] Iteration 77870, lr = 0.01
I0523 08:35:45.730110 34819 solver.cpp:239] Iteration 77880 (1.56752 iter/s, 6.37951s/10 iters), loss = 8.08334
I0523 08:35:45.730154 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08334 (* 1 = 8.08334 loss)
I0523 08:35:46.596801 34819 sgd_solver.cpp:112] Iteration 77880, lr = 0.01
I0523 08:35:50.495371 34819 solver.cpp:239] Iteration 77890 (2.09863 iter/s, 4.76501s/10 iters), loss = 7.82411
I0523 08:35:50.495417 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82411 (* 1 = 7.82411 loss)
I0523 08:35:50.561023 34819 sgd_solver.cpp:112] Iteration 77890, lr = 0.01
I0523 08:35:56.957468 34819 solver.cpp:239] Iteration 77900 (1.54756 iter/s, 6.46179s/10 iters), loss = 7.94605
I0523 08:35:56.957649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94605 (* 1 = 7.94605 loss)
I0523 08:35:57.026933 34819 sgd_solver.cpp:112] Iteration 77900, lr = 0.01
I0523 08:36:01.846063 34819 solver.cpp:239] Iteration 77910 (2.04573 iter/s, 4.88823s/10 iters), loss = 7.61489
I0523 08:36:01.846105 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61489 (* 1 = 7.61489 loss)
I0523 08:36:02.695886 34819 sgd_solver.cpp:112] Iteration 77910, lr = 0.01
I0523 08:36:06.904378 34819 solver.cpp:239] Iteration 77920 (1.97705 iter/s, 5.05804s/10 iters), loss = 7.50281
I0523 08:36:06.904450 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50281 (* 1 = 7.50281 loss)
I0523 08:36:07.684737 34819 sgd_solver.cpp:112] Iteration 77920, lr = 0.01
I0523 08:36:13.033547 34819 solver.cpp:239] Iteration 77930 (1.63163 iter/s, 6.12884s/10 iters), loss = 8.48495
I0523 08:36:13.033610 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.48495 (* 1 = 8.48495 loss)
I0523 08:36:13.115314 34819 sgd_solver.cpp:112] Iteration 77930, lr = 0.01
I0523 08:36:19.592129 34819 solver.cpp:239] Iteration 77940 (1.5248 iter/s, 6.55824s/10 iters), loss = 8.29643
I0523 08:36:19.592183 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29643 (* 1 = 8.29643 loss)
I0523 08:36:19.662355 34819 sgd_solver.cpp:112] Iteration 77940, lr = 0.01
I0523 08:36:24.620520 34819 solver.cpp:239] Iteration 77950 (1.98881 iter/s, 5.02812s/10 iters), loss = 7.90345
I0523 08:36:24.620579 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.90345 (* 1 = 7.90345 loss)
I0523 08:36:24.680681 34819 sgd_solver.cpp:112] Iteration 77950, lr = 0.01
I0523 08:36:30.096621 34819 solver.cpp:239] Iteration 77960 (1.82623 iter/s, 5.47577s/10 iters), loss = 7.67
I0523 08:36:30.096755 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67 (* 1 = 7.67 loss)
I0523 08:36:30.367072 34819 sgd_solver.cpp:112] Iteration 77960, lr = 0.01
I0523 08:36:35.886804 34819 solver.cpp:239] Iteration 77970 (1.72717 iter/s, 5.7898s/10 iters), loss = 8.26617
I0523 08:36:35.886857 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26617 (* 1 = 8.26617 loss)
I0523 08:36:35.955921 34819 sgd_solver.cpp:112] Iteration 77970, lr = 0.01
I0523 08:36:40.132537 34819 solver.cpp:239] Iteration 77980 (2.35544 iter/s, 4.2455s/10 iters), loss = 7.53299
I0523 08:36:40.132591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53299 (* 1 = 7.53299 loss)
I0523 08:36:40.763183 34819 sgd_solver.cpp:112] Iteration 77980, lr = 0.01
I0523 08:36:45.559973 34819 solver.cpp:239] Iteration 77990 (1.84258 iter/s, 5.42716s/10 iters), loss = 7.75886
I0523 08:36:45.560017 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75886 (* 1 = 7.75886 loss)
I0523 08:36:46.306802 34819 sgd_solver.cpp:112] Iteration 77990, lr = 0.01
I0523 08:36:49.505396 34819 solver.cpp:239] Iteration 78000 (2.53472 iter/s, 3.9452s/10 iters), loss = 6.30375
I0523 08:36:49.505440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.30375 (* 1 = 6.30375 loss)
I0523 08:36:49.693869 34819 sgd_solver.cpp:112] Iteration 78000, lr = 0.01
I0523 08:36:53.094409 34819 solver.cpp:239] Iteration 78010 (2.78643 iter/s, 3.58882s/10 iters), loss = 8.0615
I0523 08:36:53.094452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0615 (* 1 = 8.0615 loss)
I0523 08:36:53.971527 34819 sgd_solver.cpp:112] Iteration 78010, lr = 0.01
I0523 08:36:58.308315 34819 solver.cpp:239] Iteration 78020 (1.91805 iter/s, 5.21363s/10 iters), loss = 7.70468
I0523 08:36:58.308365 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70468 (* 1 = 7.70468 loss)
I0523 08:36:58.373883 34819 sgd_solver.cpp:112] Iteration 78020, lr = 0.01
I0523 08:37:05.282654 34819 solver.cpp:239] Iteration 78030 (1.4339 iter/s, 6.97399s/10 iters), loss = 7.89664
I0523 08:37:05.282841 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89664 (* 1 = 7.89664 loss)
I0523 08:37:05.337231 34819 sgd_solver.cpp:112] Iteration 78030, lr = 0.01
I0523 08:37:07.979168 34819 solver.cpp:239] Iteration 78040 (3.7089 iter/s, 2.69622s/10 iters), loss = 7.52182
I0523 08:37:07.979229 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52182 (* 1 = 7.52182 loss)
I0523 08:37:08.782965 34819 sgd_solver.cpp:112] Iteration 78040, lr = 0.01
I0523 08:37:13.126265 34819 solver.cpp:239] Iteration 78050 (1.94295 iter/s, 5.14681s/10 iters), loss = 7.56124
I0523 08:37:13.126317 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56124 (* 1 = 7.56124 loss)
I0523 08:37:13.947480 34819 sgd_solver.cpp:112] Iteration 78050, lr = 0.01
I0523 08:37:17.594065 34819 solver.cpp:239] Iteration 78060 (2.23836 iter/s, 4.46755s/10 iters), loss = 7.43004
I0523 08:37:17.594120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.43004 (* 1 = 7.43004 loss)
I0523 08:37:17.666838 34819 sgd_solver.cpp:112] Iteration 78060, lr = 0.01
I0523 08:37:21.219811 34819 solver.cpp:239] Iteration 78070 (2.75821 iter/s, 3.62554s/10 iters), loss = 7.12962
I0523 08:37:21.219854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.12962 (* 1 = 7.12962 loss)
I0523 08:37:22.049432 34819 sgd_solver.cpp:112] Iteration 78070, lr = 0.01
I0523 08:37:26.039810 34819 solver.cpp:239] Iteration 78080 (2.07479 iter/s, 4.81976s/10 iters), loss = 7.72423
I0523 08:37:26.039852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72423 (* 1 = 7.72423 loss)
I0523 08:37:26.109437 34819 sgd_solver.cpp:112] Iteration 78080, lr = 0.01
I0523 08:37:31.516712 34819 solver.cpp:239] Iteration 78090 (1.82594 iter/s, 5.47664s/10 iters), loss = 7.99567
I0523 08:37:31.516758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99567 (* 1 = 7.99567 loss)
I0523 08:37:31.588802 34819 sgd_solver.cpp:112] Iteration 78090, lr = 0.01
I0523 08:37:36.555603 34819 solver.cpp:239] Iteration 78100 (1.98466 iter/s, 5.03864s/10 iters), loss = 6.62716
I0523 08:37:36.555757 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.62716 (* 1 = 6.62716 loss)
I0523 08:37:36.613929 34819 sgd_solver.cpp:112] Iteration 78100, lr = 0.01
I0523 08:37:40.845682 34819 solver.cpp:239] Iteration 78110 (2.33115 iter/s, 4.28972s/10 iters), loss = 8.42384
I0523 08:37:40.845773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42384 (* 1 = 8.42384 loss)
I0523 08:37:41.699084 34819 sgd_solver.cpp:112] Iteration 78110, lr = 0.01
I0523 08:37:46.640758 34819 solver.cpp:239] Iteration 78120 (1.7257 iter/s, 5.79475s/10 iters), loss = 7.02866
I0523 08:37:46.640805 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.02866 (* 1 = 7.02866 loss)
I0523 08:37:46.695830 34819 sgd_solver.cpp:112] Iteration 78120, lr = 0.01
I0523 08:37:50.621572 34819 solver.cpp:239] Iteration 78130 (2.51219 iter/s, 3.98058s/10 iters), loss = 8.21981
I0523 08:37:50.621626 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21981 (* 1 = 8.21981 loss)
I0523 08:37:50.695838 34819 sgd_solver.cpp:112] Iteration 78130, lr = 0.01
I0523 08:37:55.803186 34819 solver.cpp:239] Iteration 78140 (1.93 iter/s, 5.18135s/10 iters), loss = 6.54959
I0523 08:37:55.803239 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.54959 (* 1 = 6.54959 loss)
I0523 08:37:55.878157 34819 sgd_solver.cpp:112] Iteration 78140, lr = 0.01
I0523 08:38:02.628535 34819 solver.cpp:239] Iteration 78150 (1.4652 iter/s, 6.82501s/10 iters), loss = 6.8628
I0523 08:38:02.628573 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.8628 (* 1 = 6.8628 loss)
I0523 08:38:02.686977 34819 sgd_solver.cpp:112] Iteration 78150, lr = 0.01
I0523 08:38:06.573906 34819 solver.cpp:239] Iteration 78160 (2.53475 iter/s, 3.94516s/10 iters), loss = 7.53965
I0523 08:38:06.574127 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53965 (* 1 = 7.53965 loss)
I0523 08:38:07.340230 34819 sgd_solver.cpp:112] Iteration 78160, lr = 0.01
I0523 08:38:11.391211 34819 solver.cpp:239] Iteration 78170 (2.07603 iter/s, 4.8169s/10 iters), loss = 7.18772
I0523 08:38:11.391263 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.18772 (* 1 = 7.18772 loss)
I0523 08:38:12.210460 34819 sgd_solver.cpp:112] Iteration 78170, lr = 0.01
I0523 08:38:17.379575 34819 solver.cpp:239] Iteration 78180 (1.66999 iter/s, 5.98805s/10 iters), loss = 7.55685
I0523 08:38:17.379645 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55685 (* 1 = 7.55685 loss)
I0523 08:38:17.446022 34819 sgd_solver.cpp:112] Iteration 78180, lr = 0.01
I0523 08:38:22.888622 34819 solver.cpp:239] Iteration 78190 (1.8153 iter/s, 5.50875s/10 iters), loss = 7.96241
I0523 08:38:22.888664 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96241 (* 1 = 7.96241 loss)
I0523 08:38:23.703287 34819 sgd_solver.cpp:112] Iteration 78190, lr = 0.01
I0523 08:38:29.287523 34819 solver.cpp:239] Iteration 78200 (1.56284 iter/s, 6.39859s/10 iters), loss = 7.86805
I0523 08:38:29.287575 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86805 (* 1 = 7.86805 loss)
I0523 08:38:30.123565 34819 sgd_solver.cpp:112] Iteration 78200, lr = 0.01
I0523 08:38:35.638422 34819 solver.cpp:239] Iteration 78210 (1.57466 iter/s, 6.35059s/10 iters), loss = 8.89713
I0523 08:38:35.638473 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.89713 (* 1 = 8.89713 loss)
I0523 08:38:36.507103 34819 sgd_solver.cpp:112] Iteration 78210, lr = 0.01
I0523 08:38:40.081881 34819 solver.cpp:239] Iteration 78220 (2.25062 iter/s, 4.44322s/10 iters), loss = 7.10081
I0523 08:38:40.082109 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.10081 (* 1 = 7.10081 loss)
I0523 08:38:40.157515 34819 sgd_solver.cpp:112] Iteration 78220, lr = 0.01
I0523 08:38:44.612581 34819 solver.cpp:239] Iteration 78230 (2.20735 iter/s, 4.53031s/10 iters), loss = 8.42895
I0523 08:38:44.612623 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.42895 (* 1 = 8.42895 loss)
I0523 08:38:44.698729 34819 sgd_solver.cpp:112] Iteration 78230, lr = 0.01
I0523 08:38:49.431031 34819 solver.cpp:239] Iteration 78240 (2.07547 iter/s, 4.81819s/10 iters), loss = 8.28512
I0523 08:38:49.431090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.28512 (* 1 = 8.28512 loss)
I0523 08:38:50.233901 34819 sgd_solver.cpp:112] Iteration 78240, lr = 0.01
I0523 08:38:54.306418 34819 solver.cpp:239] Iteration 78250 (2.05123 iter/s, 4.87513s/10 iters), loss = 7.4125
I0523 08:38:54.306462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4125 (* 1 = 7.4125 loss)
I0523 08:38:54.959072 34819 sgd_solver.cpp:112] Iteration 78250, lr = 0.01
I0523 08:39:01.682484 34819 solver.cpp:239] Iteration 78260 (1.3558 iter/s, 7.37571s/10 iters), loss = 7.77586
I0523 08:39:01.682538 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77586 (* 1 = 7.77586 loss)
I0523 08:39:01.743852 34819 sgd_solver.cpp:112] Iteration 78260, lr = 0.01
I0523 08:39:06.561565 34819 solver.cpp:239] Iteration 78270 (2.04968 iter/s, 4.87882s/10 iters), loss = 7.52564
I0523 08:39:06.561614 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52564 (* 1 = 7.52564 loss)
I0523 08:39:07.385540 34819 sgd_solver.cpp:112] Iteration 78270, lr = 0.01
I0523 08:39:11.908161 34819 solver.cpp:239] Iteration 78280 (1.87044 iter/s, 5.34633s/10 iters), loss = 7.66439
I0523 08:39:11.908391 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66439 (* 1 = 7.66439 loss)
I0523 08:39:11.959187 34819 sgd_solver.cpp:112] Iteration 78280, lr = 0.01
I0523 08:39:16.335769 34819 solver.cpp:239] Iteration 78290 (2.25876 iter/s, 4.42721s/10 iters), loss = 7.4039
I0523 08:39:16.335839 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4039 (* 1 = 7.4039 loss)
I0523 08:39:17.078876 34819 sgd_solver.cpp:112] Iteration 78290, lr = 0.01
I0523 08:39:21.256958 34819 solver.cpp:239] Iteration 78300 (2.03215 iter/s, 4.92089s/10 iters), loss = 7.05032
I0523 08:39:21.257020 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.05032 (* 1 = 7.05032 loss)
I0523 08:39:22.114807 34819 sgd_solver.cpp:112] Iteration 78300, lr = 0.01
I0523 08:39:26.257097 34819 solver.cpp:239] Iteration 78310 (2.00006 iter/s, 4.99985s/10 iters), loss = 7.87349
I0523 08:39:26.257148 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87349 (* 1 = 7.87349 loss)
I0523 08:39:26.345686 34819 sgd_solver.cpp:112] Iteration 78310, lr = 0.01
I0523 08:39:31.689944 34819 solver.cpp:239] Iteration 78320 (1.84075 iter/s, 5.43256s/10 iters), loss = 7.22491
I0523 08:39:31.689990 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22491 (* 1 = 7.22491 loss)
I0523 08:39:32.326169 34819 sgd_solver.cpp:112] Iteration 78320, lr = 0.01
I0523 08:39:36.486739 34819 solver.cpp:239] Iteration 78330 (2.08485 iter/s, 4.79652s/10 iters), loss = 7.189
I0523 08:39:36.486793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.189 (* 1 = 7.189 loss)
I0523 08:39:36.548823 34819 sgd_solver.cpp:112] Iteration 78330, lr = 0.01
I0523 08:39:42.715369 34819 solver.cpp:239] Iteration 78340 (1.60557 iter/s, 6.22831s/10 iters), loss = 8.21923
I0523 08:39:42.715512 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.21923 (* 1 = 8.21923 loss)
I0523 08:39:42.753794 34819 sgd_solver.cpp:112] Iteration 78340, lr = 0.01
I0523 08:39:43.942447 34819 solver.cpp:239] Iteration 78350 (8.15076 iter/s, 1.22688s/10 iters), loss = 7.13876
I0523 08:39:43.942489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.13876 (* 1 = 7.13876 loss)
I0523 08:39:44.610965 34819 sgd_solver.cpp:112] Iteration 78350, lr = 0.01
I0523 08:39:49.554538 34819 solver.cpp:239] Iteration 78360 (1.78196 iter/s, 5.61181s/10 iters), loss = 7.26268
I0523 08:39:49.554615 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26268 (* 1 = 7.26268 loss)
I0523 08:39:49.614665 34819 sgd_solver.cpp:112] Iteration 78360, lr = 0.01
I0523 08:39:54.283383 34819 solver.cpp:239] Iteration 78370 (2.11481 iter/s, 4.72856s/10 iters), loss = 8.07645
I0523 08:39:54.283440 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.07645 (* 1 = 8.07645 loss)
I0523 08:39:54.355144 34819 sgd_solver.cpp:112] Iteration 78370, lr = 0.01
I0523 08:39:59.491809 34819 solver.cpp:239] Iteration 78380 (1.92007 iter/s, 5.20814s/10 iters), loss = 6.80537
I0523 08:39:59.491860 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.80537 (* 1 = 6.80537 loss)
I0523 08:40:00.344575 34819 sgd_solver.cpp:112] Iteration 78380, lr = 0.01
I0523 08:40:05.234144 34819 solver.cpp:239] Iteration 78390 (1.74154 iter/s, 5.74204s/10 iters), loss = 8.62847
I0523 08:40:05.234195 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62847 (* 1 = 8.62847 loss)
I0523 08:40:05.820204 34819 sgd_solver.cpp:112] Iteration 78390, lr = 0.01
I0523 08:40:09.603811 34819 solver.cpp:239] Iteration 78400 (2.28863 iter/s, 4.36943s/10 iters), loss = 6.98443
I0523 08:40:09.603854 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.98443 (* 1 = 6.98443 loss)
I0523 08:40:09.660166 34819 sgd_solver.cpp:112] Iteration 78400, lr = 0.01
I0523 08:40:12.282403 34819 solver.cpp:239] Iteration 78410 (3.73355 iter/s, 2.67842s/10 iters), loss = 7.35313
I0523 08:40:12.282452 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35313 (* 1 = 7.35313 loss)
I0523 08:40:13.058363 34819 sgd_solver.cpp:112] Iteration 78410, lr = 0.01
I0523 08:40:17.402242 34819 solver.cpp:239] Iteration 78420 (1.95329 iter/s, 5.11955s/10 iters), loss = 7.74417
I0523 08:40:17.402304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74417 (* 1 = 7.74417 loss)
I0523 08:40:18.216459 34819 sgd_solver.cpp:112] Iteration 78420, lr = 0.01
I0523 08:40:23.230324 34819 solver.cpp:239] Iteration 78430 (1.71592 iter/s, 5.82778s/10 iters), loss = 7.52163
I0523 08:40:23.230386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52163 (* 1 = 7.52163 loss)
I0523 08:40:23.297575 34819 sgd_solver.cpp:112] Iteration 78430, lr = 0.01
I0523 08:40:27.853621 34819 solver.cpp:239] Iteration 78440 (2.16308 iter/s, 4.62304s/10 iters), loss = 7.35792
I0523 08:40:27.853674 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.35792 (* 1 = 7.35792 loss)
I0523 08:40:27.926774 34819 sgd_solver.cpp:112] Iteration 78440, lr = 0.01
I0523 08:40:34.748247 34819 solver.cpp:239] Iteration 78450 (1.45048 iter/s, 6.89428s/10 iters), loss = 7.66596
I0523 08:40:34.748304 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66596 (* 1 = 7.66596 loss)
I0523 08:40:34.819443 34819 sgd_solver.cpp:112] Iteration 78450, lr = 0.01
I0523 08:40:42.121999 34819 solver.cpp:239] Iteration 78460 (1.35623 iter/s, 7.37339s/10 iters), loss = 6.93248
I0523 08:40:42.122040 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.93248 (* 1 = 6.93248 loss)
I0523 08:40:42.186147 34819 sgd_solver.cpp:112] Iteration 78460, lr = 0.01
I0523 08:40:47.693503 34819 solver.cpp:239] Iteration 78470 (1.79494 iter/s, 5.57122s/10 iters), loss = 7.94047
I0523 08:40:47.693644 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94047 (* 1 = 7.94047 loss)
I0523 08:40:47.754266 34819 sgd_solver.cpp:112] Iteration 78470, lr = 0.01
I0523 08:40:53.045249 34819 solver.cpp:239] Iteration 78480 (1.86868 iter/s, 5.35138s/10 iters), loss = 7.71263
I0523 08:40:53.045294 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71263 (* 1 = 7.71263 loss)
I0523 08:40:53.771132 34819 sgd_solver.cpp:112] Iteration 78480, lr = 0.01
I0523 08:40:59.182857 34819 solver.cpp:239] Iteration 78490 (1.62938 iter/s, 6.13731s/10 iters), loss = 8.27294
I0523 08:40:59.182914 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27294 (* 1 = 8.27294 loss)
I0523 08:40:59.566891 34819 sgd_solver.cpp:112] Iteration 78490, lr = 0.01
I0523 08:41:03.571682 34819 solver.cpp:239] Iteration 78500 (2.27864 iter/s, 4.38859s/10 iters), loss = 6.68204
I0523 08:41:03.571736 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.68204 (* 1 = 6.68204 loss)
I0523 08:41:03.641528 34819 sgd_solver.cpp:112] Iteration 78500, lr = 0.01
I0523 08:41:06.828230 34819 solver.cpp:239] Iteration 78510 (3.07093 iter/s, 3.25634s/10 iters), loss = 7.96037
I0523 08:41:06.828285 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.96037 (* 1 = 7.96037 loss)
I0523 08:41:06.891923 34819 sgd_solver.cpp:112] Iteration 78510, lr = 0.01
I0523 08:41:10.108608 34819 solver.cpp:239] Iteration 78520 (3.04862 iter/s, 3.28017s/10 iters), loss = 7.28995
I0523 08:41:10.108676 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28995 (* 1 = 7.28995 loss)
I0523 08:41:10.171913 34819 sgd_solver.cpp:112] Iteration 78520, lr = 0.01
I0523 08:41:13.999670 34819 solver.cpp:239] Iteration 78530 (2.57015 iter/s, 3.89082s/10 iters), loss = 7.87423
I0523 08:41:13.999727 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87423 (* 1 = 7.87423 loss)
I0523 08:41:14.068163 34819 sgd_solver.cpp:112] Iteration 78530, lr = 0.01
I0523 08:41:19.565157 34819 solver.cpp:239] Iteration 78540 (1.79688 iter/s, 5.5652s/10 iters), loss = 6.92314
I0523 08:41:19.565359 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.92314 (* 1 = 6.92314 loss)
I0523 08:41:20.413591 34819 sgd_solver.cpp:112] Iteration 78540, lr = 0.01
I0523 08:41:25.922559 34819 solver.cpp:239] Iteration 78550 (1.57309 iter/s, 6.35693s/10 iters), loss = 7.55536
I0523 08:41:25.922624 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55536 (* 1 = 7.55536 loss)
I0523 08:41:26.671326 34819 sgd_solver.cpp:112] Iteration 78550, lr = 0.01
I0523 08:41:29.261718 34819 solver.cpp:239] Iteration 78560 (2.99496 iter/s, 3.33894s/10 iters), loss = 8.68693
I0523 08:41:29.261771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.68693 (* 1 = 8.68693 loss)
I0523 08:41:29.850291 34819 sgd_solver.cpp:112] Iteration 78560, lr = 0.01
I0523 08:41:33.316452 34819 solver.cpp:239] Iteration 78570 (2.46639 iter/s, 4.05451s/10 iters), loss = 8.05109
I0523 08:41:33.316501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05109 (* 1 = 8.05109 loss)
I0523 08:41:34.135377 34819 sgd_solver.cpp:112] Iteration 78570, lr = 0.01
I0523 08:41:37.668789 34819 solver.cpp:239] Iteration 78580 (2.29775 iter/s, 4.35209s/10 iters), loss = 6.85332
I0523 08:41:37.668838 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.85332 (* 1 = 6.85332 loss)
I0523 08:41:38.241601 34819 sgd_solver.cpp:112] Iteration 78580, lr = 0.01
I0523 08:41:41.971413 34819 solver.cpp:239] Iteration 78590 (2.32429 iter/s, 4.30239s/10 iters), loss = 7.16533
I0523 08:41:41.971464 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.16533 (* 1 = 7.16533 loss)
I0523 08:41:42.045639 34819 sgd_solver.cpp:112] Iteration 78590, lr = 0.01
I0523 08:41:49.083802 34819 solver.cpp:239] Iteration 78600 (1.40607 iter/s, 7.11204s/10 iters), loss = 8.33936
I0523 08:41:49.083858 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.33936 (* 1 = 8.33936 loss)
I0523 08:41:49.958895 34819 sgd_solver.cpp:112] Iteration 78600, lr = 0.01
I0523 08:41:56.313916 34819 solver.cpp:239] Iteration 78610 (1.38317 iter/s, 7.22977s/10 iters), loss = 6.74776
I0523 08:41:56.313982 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.74776 (* 1 = 6.74776 loss)
I0523 08:41:57.089519 34819 sgd_solver.cpp:112] Iteration 78610, lr = 0.01
I0523 08:42:01.924371 34819 solver.cpp:239] Iteration 78620 (1.78248 iter/s, 5.61015s/10 iters), loss = 8.06428
I0523 08:42:01.924427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06428 (* 1 = 8.06428 loss)
I0523 08:42:02.771101 34819 sgd_solver.cpp:112] Iteration 78620, lr = 0.01
I0523 08:42:08.062736 34819 solver.cpp:239] Iteration 78630 (1.62919 iter/s, 6.13803s/10 iters), loss = 9.3098
I0523 08:42:08.062784 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.3098 (* 1 = 9.3098 loss)
I0523 08:42:08.127364 34819 sgd_solver.cpp:112] Iteration 78630, lr = 0.01
I0523 08:42:15.284291 34819 solver.cpp:239] Iteration 78640 (1.38481 iter/s, 7.22121s/10 iters), loss = 7.83369
I0523 08:42:15.284340 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83369 (* 1 = 7.83369 loss)
I0523 08:42:15.358564 34819 sgd_solver.cpp:112] Iteration 78640, lr = 0.01
I0523 08:42:20.880281 34819 solver.cpp:239] Iteration 78650 (1.78708 iter/s, 5.59571s/10 iters), loss = 7.55182
I0523 08:42:20.880437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.55182 (* 1 = 7.55182 loss)
I0523 08:42:21.694928 34819 sgd_solver.cpp:112] Iteration 78650, lr = 0.01
I0523 08:42:25.310273 34819 solver.cpp:239] Iteration 78660 (2.25751 iter/s, 4.42966s/10 iters), loss = 7.2375
I0523 08:42:25.310315 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.2375 (* 1 = 7.2375 loss)
I0523 08:42:25.374300 34819 sgd_solver.cpp:112] Iteration 78660, lr = 0.01
I0523 08:42:29.300315 34819 solver.cpp:239] Iteration 78670 (2.50638 iter/s, 3.98982s/10 iters), loss = 7.65409
I0523 08:42:29.300356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65409 (* 1 = 7.65409 loss)
I0523 08:42:29.367276 34819 sgd_solver.cpp:112] Iteration 78670, lr = 0.01
I0523 08:42:34.059757 34819 solver.cpp:239] Iteration 78680 (2.10121 iter/s, 4.75916s/10 iters), loss = 7.63085
I0523 08:42:34.059818 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63085 (* 1 = 7.63085 loss)
I0523 08:42:34.883437 34819 sgd_solver.cpp:112] Iteration 78680, lr = 0.01
I0523 08:42:39.078294 34819 solver.cpp:239] Iteration 78690 (1.99272 iter/s, 5.01826s/10 iters), loss = 7.50991
I0523 08:42:39.078336 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50991 (* 1 = 7.50991 loss)
I0523 08:42:39.496109 34819 sgd_solver.cpp:112] Iteration 78690, lr = 0.01
I0523 08:42:43.009012 34819 solver.cpp:239] Iteration 78700 (2.5442 iter/s, 3.9305s/10 iters), loss = 6.95444
I0523 08:42:43.009055 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.95444 (* 1 = 6.95444 loss)
I0523 08:42:43.086290 34819 sgd_solver.cpp:112] Iteration 78700, lr = 0.01
I0523 08:42:47.107697 34819 solver.cpp:239] Iteration 78710 (2.43995 iter/s, 4.09845s/10 iters), loss = 8.64098
I0523 08:42:47.107749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64098 (* 1 = 8.64098 loss)
I0523 08:42:47.171435 34819 sgd_solver.cpp:112] Iteration 78710, lr = 0.01
I0523 08:42:51.559828 34819 solver.cpp:239] Iteration 78720 (2.24624 iter/s, 4.45188s/10 iters), loss = 7.24285
I0523 08:42:51.559898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.24285 (* 1 = 7.24285 loss)
I0523 08:42:51.630897 34819 sgd_solver.cpp:112] Iteration 78720, lr = 0.01
I0523 08:42:54.195518 34819 solver.cpp:239] Iteration 78730 (3.79434 iter/s, 2.6355s/10 iters), loss = 7.5035
I0523 08:42:54.195561 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5035 (* 1 = 7.5035 loss)
I0523 08:42:55.051429 34819 sgd_solver.cpp:112] Iteration 78730, lr = 0.01
I0523 08:42:58.195693 34819 solver.cpp:239] Iteration 78740 (2.50004 iter/s, 3.99994s/10 iters), loss = 7.74199
I0523 08:42:58.195747 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.74199 (* 1 = 7.74199 loss)
I0523 08:42:58.266364 34819 sgd_solver.cpp:112] Iteration 78740, lr = 0.01
I0523 08:43:03.441701 34819 solver.cpp:239] Iteration 78750 (1.90632 iter/s, 5.24572s/10 iters), loss = 8.55256
I0523 08:43:03.441745 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.55256 (* 1 = 8.55256 loss)
I0523 08:43:03.501377 34819 sgd_solver.cpp:112] Iteration 78750, lr = 0.01
I0523 08:43:11.028002 34819 solver.cpp:239] Iteration 78760 (1.31823 iter/s, 7.58595s/10 iters), loss = 7.69145
I0523 08:43:11.028044 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69145 (* 1 = 7.69145 loss)
I0523 08:43:11.903569 34819 sgd_solver.cpp:112] Iteration 78760, lr = 0.01
I0523 08:43:18.575002 34819 solver.cpp:239] Iteration 78770 (1.32509 iter/s, 7.54665s/10 iters), loss = 7.40605
I0523 08:43:18.575042 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40605 (* 1 = 7.40605 loss)
I0523 08:43:19.437458 34819 sgd_solver.cpp:112] Iteration 78770, lr = 0.01
I0523 08:43:24.744107 34819 solver.cpp:239] Iteration 78780 (1.62106 iter/s, 6.16881s/10 iters), loss = 8.32718
I0523 08:43:24.744735 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32718 (* 1 = 8.32718 loss)
I0523 08:43:24.825623 34819 sgd_solver.cpp:112] Iteration 78780, lr = 0.01
I0523 08:43:28.094100 34819 solver.cpp:239] Iteration 78790 (2.98578 iter/s, 3.34921s/10 iters), loss = 8.17519
I0523 08:43:28.094141 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17519 (* 1 = 8.17519 loss)
I0523 08:43:28.884552 34819 sgd_solver.cpp:112] Iteration 78790, lr = 0.01
I0523 08:43:33.789700 34819 solver.cpp:239] Iteration 78800 (1.75583 iter/s, 5.69531s/10 iters), loss = 7.58723
I0523 08:43:33.789746 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58723 (* 1 = 7.58723 loss)
I0523 08:43:34.583467 34819 sgd_solver.cpp:112] Iteration 78800, lr = 0.01
I0523 08:43:40.587401 34819 solver.cpp:239] Iteration 78810 (1.47115 iter/s, 6.79738s/10 iters), loss = 7.92581
I0523 08:43:40.587441 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92581 (* 1 = 7.92581 loss)
I0523 08:43:40.660629 34819 sgd_solver.cpp:112] Iteration 78810, lr = 0.01
I0523 08:43:44.173661 34819 solver.cpp:239] Iteration 78820 (2.78857 iter/s, 3.58606s/10 iters), loss = 7.58858
I0523 08:43:44.173702 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58858 (* 1 = 7.58858 loss)
I0523 08:43:44.962889 34819 sgd_solver.cpp:112] Iteration 78820, lr = 0.01
I0523 08:43:50.474102 34819 solver.cpp:239] Iteration 78830 (1.58727 iter/s, 6.30013s/10 iters), loss = 6.73877
I0523 08:43:50.474153 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.73877 (* 1 = 6.73877 loss)
I0523 08:43:51.328894 34819 sgd_solver.cpp:112] Iteration 78830, lr = 0.01
I0523 08:43:55.639684 34819 solver.cpp:239] Iteration 78840 (1.93599 iter/s, 5.16531s/10 iters), loss = 7.10664
I0523 08:43:55.639811 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.10664 (* 1 = 7.10664 loss)
I0523 08:43:56.425127 34819 sgd_solver.cpp:112] Iteration 78840, lr = 0.01
I0523 08:44:02.784495 34819 solver.cpp:239] Iteration 78850 (1.3997 iter/s, 7.14439s/10 iters), loss = 8.78191
I0523 08:44:02.784545 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.78191 (* 1 = 8.78191 loss)
I0523 08:44:03.429800 34819 sgd_solver.cpp:112] Iteration 78850, lr = 0.01
I0523 08:44:08.189837 34819 solver.cpp:239] Iteration 78860 (1.85012 iter/s, 5.40506s/10 iters), loss = 7.54249
I0523 08:44:08.189889 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.54249 (* 1 = 7.54249 loss)
I0523 08:44:09.061532 34819 sgd_solver.cpp:112] Iteration 78860, lr = 0.01
I0523 08:44:12.320102 34819 solver.cpp:239] Iteration 78870 (2.42129 iter/s, 4.13003s/10 iters), loss = 7.4821
I0523 08:44:12.320143 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.4821 (* 1 = 7.4821 loss)
I0523 08:44:12.387542 34819 sgd_solver.cpp:112] Iteration 78870, lr = 0.01
I0523 08:44:15.490550 34819 solver.cpp:239] Iteration 78880 (3.15433 iter/s, 3.17025s/10 iters), loss = 7.71575
I0523 08:44:15.490617 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71575 (* 1 = 7.71575 loss)
I0523 08:44:16.296041 34819 sgd_solver.cpp:112] Iteration 78880, lr = 0.01
I0523 08:44:21.043269 34819 solver.cpp:239] Iteration 78890 (1.80101 iter/s, 5.55243s/10 iters), loss = 8.25216
I0523 08:44:21.043313 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25216 (* 1 = 8.25216 loss)
I0523 08:44:21.856487 34819 sgd_solver.cpp:112] Iteration 78890, lr = 0.01
I0523 08:44:25.800242 34819 solver.cpp:239] Iteration 78900 (2.10229 iter/s, 4.75673s/10 iters), loss = 7.18042
I0523 08:44:25.800356 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.18042 (* 1 = 7.18042 loss)
I0523 08:44:25.872138 34819 sgd_solver.cpp:112] Iteration 78900, lr = 0.01
I0523 08:44:30.001024 34819 solver.cpp:239] Iteration 78910 (2.38068 iter/s, 4.20048s/10 iters), loss = 7.83032
I0523 08:44:30.001076 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83032 (* 1 = 7.83032 loss)
I0523 08:44:30.065104 34819 sgd_solver.cpp:112] Iteration 78910, lr = 0.01
I0523 08:44:34.302912 34819 solver.cpp:239] Iteration 78920 (2.32469 iter/s, 4.30165s/10 iters), loss = 7.77455
I0523 08:44:34.302964 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.77455 (* 1 = 7.77455 loss)
I0523 08:44:35.128365 34819 sgd_solver.cpp:112] Iteration 78920, lr = 0.01
I0523 08:44:39.295078 34819 solver.cpp:239] Iteration 78930 (2.00324 iter/s, 4.99191s/10 iters), loss = 6.25615
I0523 08:44:39.295137 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.25615 (* 1 = 6.25615 loss)
I0523 08:44:40.125855 34819 sgd_solver.cpp:112] Iteration 78930, lr = 0.01
I0523 08:44:42.699748 34819 solver.cpp:239] Iteration 78940 (2.93732 iter/s, 3.40446s/10 iters), loss = 8.87702
I0523 08:44:42.699802 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.87702 (* 1 = 8.87702 loss)
I0523 08:44:43.513949 34819 sgd_solver.cpp:112] Iteration 78940, lr = 0.01
I0523 08:44:46.637869 34819 solver.cpp:239] Iteration 78950 (2.53943 iter/s, 3.93789s/10 iters), loss = 7.64654
I0523 08:44:46.637933 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64654 (* 1 = 7.64654 loss)
I0523 08:44:46.704586 34819 sgd_solver.cpp:112] Iteration 78950, lr = 0.01
I0523 08:44:50.787695 34819 solver.cpp:239] Iteration 78960 (2.40988 iter/s, 4.14958s/10 iters), loss = 7.28427
I0523 08:44:50.787748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28427 (* 1 = 7.28427 loss)
I0523 08:44:51.647663 34819 sgd_solver.cpp:112] Iteration 78960, lr = 0.01
I0523 08:44:55.649785 34819 solver.cpp:239] Iteration 78970 (2.05684 iter/s, 4.86183s/10 iters), loss = 7.67678
I0523 08:44:55.649837 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67678 (* 1 = 7.67678 loss)
I0523 08:44:55.710777 34819 sgd_solver.cpp:112] Iteration 78970, lr = 0.01
I0523 08:44:59.579916 34819 solver.cpp:239] Iteration 78980 (2.54458 iter/s, 3.92991s/10 iters), loss = 7.39059
I0523 08:44:59.580205 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39059 (* 1 = 7.39059 loss)
I0523 08:45:00.295867 34819 sgd_solver.cpp:112] Iteration 78980, lr = 0.01
I0523 08:45:04.735234 34819 solver.cpp:239] Iteration 78990 (1.93992 iter/s, 5.15486s/10 iters), loss = 8.15077
I0523 08:45:04.735281 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15077 (* 1 = 8.15077 loss)
I0523 08:45:04.803673 34819 sgd_solver.cpp:112] Iteration 78990, lr = 0.01
I0523 08:45:09.853837 34819 solver.cpp:239] Iteration 79000 (1.95376 iter/s, 5.11834s/10 iters), loss = 8.16101
I0523 08:45:09.853898 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.16101 (* 1 = 8.16101 loss)
I0523 08:45:10.007669 34819 sgd_solver.cpp:112] Iteration 79000, lr = 0.01
I0523 08:45:14.152715 34819 solver.cpp:239] Iteration 79010 (2.32633 iter/s, 4.29862s/10 iters), loss = 8.2957
I0523 08:45:14.152783 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2957 (* 1 = 8.2957 loss)
I0523 08:45:14.228135 34819 sgd_solver.cpp:112] Iteration 79010, lr = 0.01
I0523 08:45:18.170976 34819 solver.cpp:239] Iteration 79020 (2.48879 iter/s, 4.01802s/10 iters), loss = 7.39976
I0523 08:45:18.171032 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.39976 (* 1 = 7.39976 loss)
I0523 08:45:19.008647 34819 sgd_solver.cpp:112] Iteration 79020, lr = 0.01
I0523 08:45:23.069275 34819 solver.cpp:239] Iteration 79030 (2.04164 iter/s, 4.89803s/10 iters), loss = 7.71935
I0523 08:45:23.069319 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71935 (* 1 = 7.71935 loss)
I0523 08:45:23.146870 34819 sgd_solver.cpp:112] Iteration 79030, lr = 0.01
I0523 08:45:26.440923 34819 solver.cpp:239] Iteration 79040 (2.96609 iter/s, 3.37144s/10 iters), loss = 7.04884
I0523 08:45:26.440982 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.04884 (* 1 = 7.04884 loss)
I0523 08:45:27.059101 34819 sgd_solver.cpp:112] Iteration 79040, lr = 0.01
I0523 08:45:31.251727 34819 solver.cpp:239] Iteration 79050 (2.07877 iter/s, 4.81055s/10 iters), loss = 7.38864
I0523 08:45:31.251904 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38864 (* 1 = 7.38864 loss)
I0523 08:45:31.329965 34819 sgd_solver.cpp:112] Iteration 79050, lr = 0.01
I0523 08:45:36.007184 34819 solver.cpp:239] Iteration 79060 (2.103 iter/s, 4.7551s/10 iters), loss = 8.23877
I0523 08:45:36.007228 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.23877 (* 1 = 8.23877 loss)
I0523 08:45:36.061300 34819 sgd_solver.cpp:112] Iteration 79060, lr = 0.01
I0523 08:45:41.002831 34819 solver.cpp:239] Iteration 79070 (2.00185 iter/s, 4.99538s/10 iters), loss = 8.71827
I0523 08:45:41.002887 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.71827 (* 1 = 8.71827 loss)
I0523 08:45:41.639238 34819 sgd_solver.cpp:112] Iteration 79070, lr = 0.01
I0523 08:45:45.276422 34819 solver.cpp:239] Iteration 79080 (2.34009 iter/s, 4.27334s/10 iters), loss = 7.20868
I0523 08:45:45.276489 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20868 (* 1 = 7.20868 loss)
I0523 08:45:46.079097 34819 sgd_solver.cpp:112] Iteration 79080, lr = 0.01
I0523 08:45:50.355340 34819 solver.cpp:239] Iteration 79090 (1.96904 iter/s, 5.07862s/10 iters), loss = 7.38573
I0523 08:45:50.355396 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.38573 (* 1 = 7.38573 loss)
I0523 08:45:51.014623 34819 sgd_solver.cpp:112] Iteration 79090, lr = 0.01
I0523 08:45:55.546633 34819 solver.cpp:239] Iteration 79100 (1.9264 iter/s, 5.19102s/10 iters), loss = 8.56749
I0523 08:45:55.546730 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.56749 (* 1 = 8.56749 loss)
I0523 08:45:55.609223 34819 sgd_solver.cpp:112] Iteration 79100, lr = 0.01
I0523 08:46:01.157824 34819 solver.cpp:239] Iteration 79110 (1.78225 iter/s, 5.61089s/10 iters), loss = 7.65374
I0523 08:46:01.157866 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65374 (* 1 = 7.65374 loss)
I0523 08:46:01.900998 34819 sgd_solver.cpp:112] Iteration 79110, lr = 0.01
I0523 08:46:05.897851 34819 solver.cpp:239] Iteration 79120 (2.1098 iter/s, 4.73978s/10 iters), loss = 7.40286
I0523 08:46:05.897912 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40286 (* 1 = 7.40286 loss)
I0523 08:46:05.960985 34819 sgd_solver.cpp:112] Iteration 79120, lr = 0.01
I0523 08:46:08.790635 34819 solver.cpp:239] Iteration 79130 (3.4571 iter/s, 2.8926s/10 iters), loss = 7.61435
I0523 08:46:08.790690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.61435 (* 1 = 7.61435 loss)
I0523 08:46:09.443316 34819 sgd_solver.cpp:112] Iteration 79130, lr = 0.01
I0523 08:46:15.031725 34819 solver.cpp:239] Iteration 79140 (1.60237 iter/s, 6.24077s/10 iters), loss = 8.82019
I0523 08:46:15.031770 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.82019 (* 1 = 8.82019 loss)
I0523 08:46:15.099922 34819 sgd_solver.cpp:112] Iteration 79140, lr = 0.01
I0523 08:46:22.766793 34819 solver.cpp:239] Iteration 79150 (1.29288 iter/s, 7.73469s/10 iters), loss = 8.38819
I0523 08:46:22.766852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.38819 (* 1 = 8.38819 loss)
I0523 08:46:22.832465 34819 sgd_solver.cpp:112] Iteration 79150, lr = 0.01
I0523 08:46:26.882138 34819 solver.cpp:239] Iteration 79160 (2.43007 iter/s, 4.1151s/10 iters), loss = 8.99479
I0523 08:46:26.882182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.99479 (* 1 = 8.99479 loss)
I0523 08:46:27.002774 34819 sgd_solver.cpp:112] Iteration 79160, lr = 0.01
I0523 08:46:31.769716 34819 solver.cpp:239] Iteration 79170 (2.04611 iter/s, 4.88733s/10 iters), loss = 7.21491
I0523 08:46:31.769771 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.21491 (* 1 = 7.21491 loss)
I0523 08:46:32.592175 34819 sgd_solver.cpp:112] Iteration 79170, lr = 0.01
I0523 08:46:36.047755 34819 solver.cpp:239] Iteration 79180 (2.33765 iter/s, 4.2778s/10 iters), loss = 8.03194
I0523 08:46:36.047809 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03194 (* 1 = 8.03194 loss)
I0523 08:46:36.111392 34819 sgd_solver.cpp:112] Iteration 79180, lr = 0.01
I0523 08:46:39.801452 34819 solver.cpp:239] Iteration 79190 (2.6642 iter/s, 3.75348s/10 iters), loss = 7.25239
I0523 08:46:39.801508 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.25239 (* 1 = 7.25239 loss)
I0523 08:46:39.875123 34819 sgd_solver.cpp:112] Iteration 79190, lr = 0.01
I0523 08:46:43.618785 34819 solver.cpp:239] Iteration 79200 (2.61979 iter/s, 3.81711s/10 iters), loss = 6.81682
I0523 08:46:43.618849 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.81682 (* 1 = 6.81682 loss)
I0523 08:46:43.682301 34819 sgd_solver.cpp:112] Iteration 79200, lr = 0.01
I0523 08:46:46.958431 34819 solver.cpp:239] Iteration 79210 (2.99454 iter/s, 3.33941s/10 iters), loss = 7.07897
I0523 08:46:46.958499 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.07897 (* 1 = 7.07897 loss)
I0523 08:46:47.785229 34819 sgd_solver.cpp:112] Iteration 79210, lr = 0.01
I0523 08:46:51.678119 34819 solver.cpp:239] Iteration 79220 (2.11891 iter/s, 4.71941s/10 iters), loss = 6.98765
I0523 08:46:51.678182 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.98765 (* 1 = 6.98765 loss)
I0523 08:46:51.757447 34819 sgd_solver.cpp:112] Iteration 79220, lr = 0.01
I0523 08:46:56.835211 34819 solver.cpp:239] Iteration 79230 (1.93919 iter/s, 5.1568s/10 iters), loss = 7.69655
I0523 08:46:56.835253 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.69655 (* 1 = 7.69655 loss)
I0523 08:46:56.895714 34819 sgd_solver.cpp:112] Iteration 79230, lr = 0.01
I0523 08:47:01.935371 34819 solver.cpp:239] Iteration 79240 (1.96082 iter/s, 5.0999s/10 iters), loss = 7.50611
I0523 08:47:01.935418 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50611 (* 1 = 7.50611 loss)
I0523 08:47:02.007714 34819 sgd_solver.cpp:112] Iteration 79240, lr = 0.01
I0523 08:47:05.879539 34819 solver.cpp:239] Iteration 79250 (2.53553 iter/s, 3.94395s/10 iters), loss = 7.12319
I0523 08:47:05.879803 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.12319 (* 1 = 7.12319 loss)
I0523 08:47:05.937950 34819 sgd_solver.cpp:112] Iteration 79250, lr = 0.01
I0523 08:47:10.004920 34819 solver.cpp:239] Iteration 79260 (2.42426 iter/s, 4.12497s/10 iters), loss = 7.7402
I0523 08:47:10.004962 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7402 (* 1 = 7.7402 loss)
I0523 08:47:10.851924 34819 sgd_solver.cpp:112] Iteration 79260, lr = 0.01
I0523 08:47:15.070253 34819 solver.cpp:239] Iteration 79270 (1.9743 iter/s, 5.06508s/10 iters), loss = 7.7372
I0523 08:47:15.070298 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7372 (* 1 = 7.7372 loss)
I0523 08:47:15.465512 34819 sgd_solver.cpp:112] Iteration 79270, lr = 0.01
I0523 08:47:20.502581 34819 solver.cpp:239] Iteration 79280 (1.84093 iter/s, 5.43205s/10 iters), loss = 7.82112
I0523 08:47:20.502645 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.82112 (* 1 = 7.82112 loss)
I0523 08:47:21.273926 34819 sgd_solver.cpp:112] Iteration 79280, lr = 0.01
I0523 08:47:26.226327 34819 solver.cpp:239] Iteration 79290 (1.7472 iter/s, 5.72344s/10 iters), loss = 7.93772
I0523 08:47:26.226384 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93772 (* 1 = 7.93772 loss)
I0523 08:47:26.302390 34819 sgd_solver.cpp:112] Iteration 79290, lr = 0.01
I0523 08:47:31.643497 34819 solver.cpp:239] Iteration 79300 (1.84608 iter/s, 5.41687s/10 iters), loss = 7.00033
I0523 08:47:31.643551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.00033 (* 1 = 7.00033 loss)
I0523 08:47:32.496150 34819 sgd_solver.cpp:112] Iteration 79300, lr = 0.01
I0523 08:47:36.834990 34819 solver.cpp:239] Iteration 79310 (1.92633 iter/s, 5.19122s/10 iters), loss = 8.19046
I0523 08:47:36.835211 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.19046 (* 1 = 8.19046 loss)
I0523 08:47:36.917315 34819 sgd_solver.cpp:112] Iteration 79310, lr = 0.01
I0523 08:47:42.409965 34819 solver.cpp:239] Iteration 79320 (1.79387 iter/s, 5.57454s/10 iters), loss = 6.79007
I0523 08:47:42.410022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.79007 (* 1 = 6.79007 loss)
I0523 08:47:43.099654 34819 sgd_solver.cpp:112] Iteration 79320, lr = 0.01
I0523 08:47:47.363126 34819 solver.cpp:239] Iteration 79330 (2.01903 iter/s, 4.95288s/10 iters), loss = 7.47567
I0523 08:47:47.363191 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.47567 (* 1 = 7.47567 loss)
I0523 08:47:47.715272 34819 sgd_solver.cpp:112] Iteration 79330, lr = 0.01
I0523 08:47:51.945456 34819 solver.cpp:239] Iteration 79340 (2.18242 iter/s, 4.58207s/10 iters), loss = 8.04984
I0523 08:47:51.945498 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.04984 (* 1 = 8.04984 loss)
I0523 08:47:52.470072 34819 sgd_solver.cpp:112] Iteration 79340, lr = 0.01
I0523 08:47:58.191087 34819 solver.cpp:239] Iteration 79350 (1.6012 iter/s, 6.24532s/10 iters), loss = 7.70898
I0523 08:47:58.191135 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70898 (* 1 = 7.70898 loss)
I0523 08:47:58.263111 34819 sgd_solver.cpp:112] Iteration 79350, lr = 0.01
I0523 08:48:03.934767 34819 solver.cpp:239] Iteration 79360 (1.74114 iter/s, 5.74338s/10 iters), loss = 7.88258
I0523 08:48:03.934820 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88258 (* 1 = 7.88258 loss)
I0523 08:48:04.001837 34819 sgd_solver.cpp:112] Iteration 79360, lr = 0.01
I0523 08:48:08.398507 34819 solver.cpp:239] Iteration 79370 (2.24039 iter/s, 4.4635s/10 iters), loss = 8.20375
I0523 08:48:08.398713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.20375 (* 1 = 8.20375 loss)
I0523 08:48:09.222944 34819 sgd_solver.cpp:112] Iteration 79370, lr = 0.01
I0523 08:48:13.326071 34819 solver.cpp:239] Iteration 79380 (2.02956 iter/s, 4.92717s/10 iters), loss = 7.20752
I0523 08:48:13.326123 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.20752 (* 1 = 7.20752 loss)
I0523 08:48:13.397310 34819 sgd_solver.cpp:112] Iteration 79380, lr = 0.01
I0523 08:48:17.452726 34819 solver.cpp:239] Iteration 79390 (2.42341 iter/s, 4.12643s/10 iters), loss = 6.91965
I0523 08:48:17.452774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.91965 (* 1 = 6.91965 loss)
I0523 08:48:17.519121 34819 sgd_solver.cpp:112] Iteration 79390, lr = 0.01
I0523 08:48:22.262521 34819 solver.cpp:239] Iteration 79400 (2.0792 iter/s, 4.80954s/10 iters), loss = 7.59087
I0523 08:48:22.262564 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.59087 (* 1 = 7.59087 loss)
I0523 08:48:23.079461 34819 sgd_solver.cpp:112] Iteration 79400, lr = 0.01
I0523 08:48:28.815392 34819 solver.cpp:239] Iteration 79410 (1.52612 iter/s, 6.55256s/10 iters), loss = 7.63076
I0523 08:48:28.815457 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63076 (* 1 = 7.63076 loss)
I0523 08:48:29.656066 34819 sgd_solver.cpp:112] Iteration 79410, lr = 0.01
I0523 08:48:32.941812 34819 solver.cpp:239] Iteration 79420 (2.42355 iter/s, 4.12619s/10 iters), loss = 7.83558
I0523 08:48:32.941859 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83558 (* 1 = 7.83558 loss)
I0523 08:48:33.761175 34819 sgd_solver.cpp:112] Iteration 79420, lr = 0.01
I0523 08:48:37.875716 34819 solver.cpp:239] Iteration 79430 (2.0269 iter/s, 4.93364s/10 iters), loss = 8.17604
I0523 08:48:37.875758 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.17604 (* 1 = 8.17604 loss)
I0523 08:48:37.930547 34819 sgd_solver.cpp:112] Iteration 79430, lr = 0.01
I0523 08:48:43.231885 34819 solver.cpp:239] Iteration 79440 (1.8671 iter/s, 5.3559s/10 iters), loss = 7.94238
I0523 08:48:43.232071 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94238 (* 1 = 7.94238 loss)
I0523 08:48:43.287230 34819 sgd_solver.cpp:112] Iteration 79440, lr = 0.01
I0523 08:48:48.920490 34819 solver.cpp:239] Iteration 79450 (1.75802 iter/s, 5.68822s/10 iters), loss = 7.76508
I0523 08:48:48.920542 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76508 (* 1 = 7.76508 loss)
I0523 08:48:49.765475 34819 sgd_solver.cpp:112] Iteration 79450, lr = 0.01
I0523 08:48:51.863329 34819 solver.cpp:239] Iteration 79460 (3.39829 iter/s, 2.94266s/10 iters), loss = 8.15566
I0523 08:48:51.863379 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15566 (* 1 = 8.15566 loss)
I0523 08:48:51.933135 34819 sgd_solver.cpp:112] Iteration 79460, lr = 0.01
I0523 08:48:56.755928 34819 solver.cpp:239] Iteration 79470 (2.04401 iter/s, 4.89234s/10 iters), loss = 7.85707
I0523 08:48:56.755980 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85707 (* 1 = 7.85707 loss)
I0523 08:48:56.818722 34819 sgd_solver.cpp:112] Iteration 79470, lr = 0.01
I0523 08:49:01.434422 34819 solver.cpp:239] Iteration 79480 (2.13756 iter/s, 4.67823s/10 iters), loss = 7.64513
I0523 08:49:01.434480 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64513 (* 1 = 7.64513 loss)
I0523 08:49:01.500540 34819 sgd_solver.cpp:112] Iteration 79480, lr = 0.01
I0523 08:49:07.507406 34819 solver.cpp:239] Iteration 79490 (1.64672 iter/s, 6.07268s/10 iters), loss = 7.05559
I0523 08:49:07.507462 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.05559 (* 1 = 7.05559 loss)
I0523 08:49:07.578692 34819 sgd_solver.cpp:112] Iteration 79490, lr = 0.01
I0523 08:49:12.524085 34819 solver.cpp:239] Iteration 79500 (1.99345 iter/s, 5.01642s/10 iters), loss = 7.71374
I0523 08:49:12.524125 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.71374 (* 1 = 7.71374 loss)
I0523 08:49:12.586521 34819 sgd_solver.cpp:112] Iteration 79500, lr = 0.01
I0523 08:49:16.587311 34819 solver.cpp:239] Iteration 79510 (2.46124 iter/s, 4.06299s/10 iters), loss = 8.40135
I0523 08:49:16.587486 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.40135 (* 1 = 8.40135 loss)
I0523 08:49:17.426779 34819 sgd_solver.cpp:112] Iteration 79510, lr = 0.01
I0523 08:49:21.596899 34819 solver.cpp:239] Iteration 79520 (1.99632 iter/s, 5.00921s/10 iters), loss = 7.33627
I0523 08:49:21.596946 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.33627 (* 1 = 7.33627 loss)
I0523 08:49:22.470880 34819 sgd_solver.cpp:112] Iteration 79520, lr = 0.01
I0523 08:49:26.408386 34819 solver.cpp:239] Iteration 79530 (2.07945 iter/s, 4.80896s/10 iters), loss = 7.79764
I0523 08:49:26.408435 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79764 (* 1 = 7.79764 loss)
I0523 08:49:27.186674 34819 sgd_solver.cpp:112] Iteration 79530, lr = 0.01
I0523 08:49:29.874267 34819 solver.cpp:239] Iteration 79540 (2.88546 iter/s, 3.46565s/10 iters), loss = 7.78876
I0523 08:49:29.874323 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.78876 (* 1 = 7.78876 loss)
I0523 08:49:29.936290 34819 sgd_solver.cpp:112] Iteration 79540, lr = 0.01
I0523 08:49:33.990370 34819 solver.cpp:239] Iteration 79550 (2.42962 iter/s, 4.11587s/10 iters), loss = 7.86917
I0523 08:49:33.990427 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.86917 (* 1 = 7.86917 loss)
I0523 08:49:34.049890 34819 sgd_solver.cpp:112] Iteration 79550, lr = 0.01
I0523 08:49:37.403868 34819 solver.cpp:239] Iteration 79560 (2.92973 iter/s, 3.41329s/10 iters), loss = 7.94363
I0523 08:49:37.403921 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94363 (* 1 = 7.94363 loss)
I0523 08:49:38.262792 34819 sgd_solver.cpp:112] Iteration 79560, lr = 0.01
I0523 08:49:43.424163 34819 solver.cpp:239] Iteration 79570 (1.66113 iter/s, 6.02s/10 iters), loss = 8.00939
I0523 08:49:43.424216 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00939 (* 1 = 8.00939 loss)
I0523 08:49:43.478644 34819 sgd_solver.cpp:112] Iteration 79570, lr = 0.01
I0523 08:49:48.222949 34819 solver.cpp:239] Iteration 79580 (2.08397 iter/s, 4.79853s/10 iters), loss = 7.75218
I0523 08:49:48.223134 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75218 (* 1 = 7.75218 loss)
I0523 08:49:48.288791 34819 sgd_solver.cpp:112] Iteration 79580, lr = 0.01
I0523 08:49:52.777573 34819 solver.cpp:239] Iteration 79590 (2.19574 iter/s, 4.55428s/10 iters), loss = 7.94756
I0523 08:49:52.777618 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.94756 (* 1 = 7.94756 loss)
I0523 08:49:52.850709 34819 sgd_solver.cpp:112] Iteration 79590, lr = 0.01
I0523 08:49:55.926558 34819 solver.cpp:239] Iteration 79600 (3.17582 iter/s, 3.14879s/10 iters), loss = 6.60467
I0523 08:49:55.926607 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.60467 (* 1 = 6.60467 loss)
I0523 08:49:56.741317 34819 sgd_solver.cpp:112] Iteration 79600, lr = 0.01
I0523 08:50:02.046367 34819 solver.cpp:239] Iteration 79610 (1.63412 iter/s, 6.11951s/10 iters), loss = 7.53243
I0523 08:50:02.046422 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.53243 (* 1 = 7.53243 loss)
I0523 08:50:02.485116 34819 sgd_solver.cpp:112] Iteration 79610, lr = 0.01
I0523 08:50:06.587649 34819 solver.cpp:239] Iteration 79620 (2.20214 iter/s, 4.54104s/10 iters), loss = 7.5521
I0523 08:50:06.587692 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5521 (* 1 = 7.5521 loss)
I0523 08:50:06.667675 34819 sgd_solver.cpp:112] Iteration 79620, lr = 0.01
I0523 08:50:09.990154 34819 solver.cpp:239] Iteration 79630 (2.93917 iter/s, 3.40232s/10 iters), loss = 8.13078
I0523 08:50:09.990197 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.13078 (* 1 = 8.13078 loss)
I0523 08:50:10.824728 34819 sgd_solver.cpp:112] Iteration 79630, lr = 0.01
I0523 08:50:16.236430 34819 solver.cpp:239] Iteration 79640 (1.60103 iter/s, 6.24596s/10 iters), loss = 7.26071
I0523 08:50:16.236488 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26071 (* 1 = 7.26071 loss)
I0523 08:50:16.874857 34819 sgd_solver.cpp:112] Iteration 79640, lr = 0.01
I0523 08:50:21.820360 34819 solver.cpp:239] Iteration 79650 (1.79095 iter/s, 5.58364s/10 iters), loss = 7.89637
I0523 08:50:21.820523 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.89637 (* 1 = 7.89637 loss)
I0523 08:50:22.614737 34819 sgd_solver.cpp:112] Iteration 79650, lr = 0.01
I0523 08:50:24.380827 34819 solver.cpp:239] Iteration 79660 (3.90596 iter/s, 2.56019s/10 iters), loss = 8.27973
I0523 08:50:24.380883 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27973 (* 1 = 8.27973 loss)
I0523 08:50:24.449421 34819 sgd_solver.cpp:112] Iteration 79660, lr = 0.01
I0523 08:50:28.979038 34819 solver.cpp:239] Iteration 79670 (2.17699 iter/s, 4.59351s/10 iters), loss = 7.23394
I0523 08:50:28.979096 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.23394 (* 1 = 7.23394 loss)
I0523 08:50:29.244010 34819 sgd_solver.cpp:112] Iteration 79670, lr = 0.01
I0523 08:50:33.358589 34819 solver.cpp:239] Iteration 79680 (2.28347 iter/s, 4.3793s/10 iters), loss = 7.80463
I0523 08:50:33.358639 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80463 (* 1 = 7.80463 loss)
I0523 08:50:33.416899 34819 sgd_solver.cpp:112] Iteration 79680, lr = 0.01
I0523 08:50:38.699977 34819 solver.cpp:239] Iteration 79690 (1.87227 iter/s, 5.34112s/10 iters), loss = 8.27962
I0523 08:50:38.700022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.27962 (* 1 = 8.27962 loss)
I0523 08:50:38.903725 34819 sgd_solver.cpp:112] Iteration 79690, lr = 0.01
I0523 08:50:42.284451 34819 solver.cpp:239] Iteration 79700 (2.78997 iter/s, 3.58427s/10 iters), loss = 7.66097
I0523 08:50:42.284507 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66097 (* 1 = 7.66097 loss)
I0523 08:50:43.147444 34819 sgd_solver.cpp:112] Iteration 79700, lr = 0.01
I0523 08:50:50.160004 34819 solver.cpp:239] Iteration 79710 (1.26981 iter/s, 7.87517s/10 iters), loss = 7.65181
I0523 08:50:50.160053 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.65181 (* 1 = 7.65181 loss)
I0523 08:50:51.036767 34819 sgd_solver.cpp:112] Iteration 79710, lr = 0.01
I0523 08:50:56.186465 34819 solver.cpp:239] Iteration 79720 (1.65943 iter/s, 6.02617s/10 iters), loss = 8.29612
I0523 08:50:56.186612 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.29612 (* 1 = 8.29612 loss)
I0523 08:50:56.241437 34819 sgd_solver.cpp:112] Iteration 79720, lr = 0.01
I0523 08:51:01.447692 34819 solver.cpp:239] Iteration 79730 (1.90084 iter/s, 5.26084s/10 iters), loss = 8.03129
I0523 08:51:01.447748 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.03129 (* 1 = 8.03129 loss)
I0523 08:51:02.313300 34819 sgd_solver.cpp:112] Iteration 79730, lr = 0.01
I0523 08:51:07.672845 34819 solver.cpp:239] Iteration 79740 (1.60646 iter/s, 6.22485s/10 iters), loss = 7.44797
I0523 08:51:07.672890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44797 (* 1 = 7.44797 loss)
I0523 08:51:07.734818 34819 sgd_solver.cpp:112] Iteration 79740, lr = 0.01
I0523 08:51:12.529976 34819 solver.cpp:239] Iteration 79750 (2.05894 iter/s, 4.85687s/10 iters), loss = 8.15118
I0523 08:51:12.530038 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.15118 (* 1 = 8.15118 loss)
I0523 08:51:12.593729 34819 sgd_solver.cpp:112] Iteration 79750, lr = 0.01
I0523 08:51:17.580690 34819 solver.cpp:239] Iteration 79760 (1.98003 iter/s, 5.05043s/10 iters), loss = 8.34314
I0523 08:51:17.580754 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34314 (* 1 = 8.34314 loss)
I0523 08:51:17.644899 34819 sgd_solver.cpp:112] Iteration 79760, lr = 0.01
I0523 08:51:21.599727 34819 solver.cpp:239] Iteration 79770 (2.4883 iter/s, 4.01881s/10 iters), loss = 7.40952
I0523 08:51:21.599766 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40952 (* 1 = 7.40952 loss)
I0523 08:51:22.250509 34819 sgd_solver.cpp:112] Iteration 79770, lr = 0.01
I0523 08:51:26.458393 34819 solver.cpp:239] Iteration 79780 (2.0583 iter/s, 4.85839s/10 iters), loss = 7.80334
I0523 08:51:26.458598 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80334 (* 1 = 7.80334 loss)
I0523 08:51:27.287775 34819 sgd_solver.cpp:112] Iteration 79780, lr = 0.01
I0523 08:51:30.495982 34819 solver.cpp:239] Iteration 79790 (2.47695 iter/s, 4.03722s/10 iters), loss = 6.60105
I0523 08:51:30.496032 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.60105 (* 1 = 6.60105 loss)
I0523 08:51:31.191980 34819 sgd_solver.cpp:112] Iteration 79790, lr = 0.01
I0523 08:51:36.833734 34819 solver.cpp:239] Iteration 79800 (1.57793 iter/s, 6.33744s/10 iters), loss = 7.45844
I0523 08:51:36.833793 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.45844 (* 1 = 7.45844 loss)
I0523 08:51:36.921636 34819 sgd_solver.cpp:112] Iteration 79800, lr = 0.01
I0523 08:51:40.468220 34819 solver.cpp:239] Iteration 79810 (2.75159 iter/s, 3.63426s/10 iters), loss = 7.58351
I0523 08:51:40.468272 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.58351 (* 1 = 7.58351 loss)
I0523 08:51:41.215553 34819 sgd_solver.cpp:112] Iteration 79810, lr = 0.01
I0523 08:51:46.875129 34819 solver.cpp:239] Iteration 79820 (1.56089 iter/s, 6.4066s/10 iters), loss = 8.53717
I0523 08:51:46.875170 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.53717 (* 1 = 8.53717 loss)
I0523 08:51:46.937633 34819 sgd_solver.cpp:112] Iteration 79820, lr = 0.01
I0523 08:51:53.191542 34819 solver.cpp:239] Iteration 79830 (1.58326 iter/s, 6.3161s/10 iters), loss = 7.80285
I0523 08:51:53.191601 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.80285 (* 1 = 7.80285 loss)
I0523 08:51:53.261693 34819 sgd_solver.cpp:112] Iteration 79830, lr = 0.01
I0523 08:51:56.697403 34819 solver.cpp:239] Iteration 79840 (2.85254 iter/s, 3.50565s/10 iters), loss = 7.29385
I0523 08:51:56.697522 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29385 (* 1 = 7.29385 loss)
I0523 08:51:57.412766 34819 sgd_solver.cpp:112] Iteration 79840, lr = 0.01
I0523 08:52:02.781661 34819 solver.cpp:239] Iteration 79850 (1.64368 iter/s, 6.08389s/10 iters), loss = 7.36959
I0523 08:52:02.781713 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.36959 (* 1 = 7.36959 loss)
I0523 08:52:02.852269 34819 sgd_solver.cpp:112] Iteration 79850, lr = 0.01
I0523 08:52:07.147286 34819 solver.cpp:239] Iteration 79860 (2.29075 iter/s, 4.36539s/10 iters), loss = 7.79857
I0523 08:52:07.147346 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79857 (* 1 = 7.79857 loss)
I0523 08:52:07.209280 34819 sgd_solver.cpp:112] Iteration 79860, lr = 0.01
I0523 08:52:11.070469 34819 solver.cpp:239] Iteration 79870 (2.5491 iter/s, 3.92295s/10 iters), loss = 8.35969
I0523 08:52:11.070518 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.35969 (* 1 = 8.35969 loss)
I0523 08:52:11.148972 34819 sgd_solver.cpp:112] Iteration 79870, lr = 0.01
I0523 08:52:15.802636 34819 solver.cpp:239] Iteration 79880 (2.11331 iter/s, 4.73192s/10 iters), loss = 6.9689
I0523 08:52:15.802691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.9689 (* 1 = 6.9689 loss)
I0523 08:52:16.439622 34819 sgd_solver.cpp:112] Iteration 79880, lr = 0.01
I0523 08:52:22.712038 34819 solver.cpp:239] Iteration 79890 (1.44737 iter/s, 6.90907s/10 iters), loss = 7.22053
I0523 08:52:22.712090 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.22053 (* 1 = 7.22053 loss)
I0523 08:52:23.467414 34819 sgd_solver.cpp:112] Iteration 79890, lr = 0.01
I0523 08:52:27.598381 34819 solver.cpp:239] Iteration 79900 (2.04662 iter/s, 4.88609s/10 iters), loss = 7.99906
I0523 08:52:27.598502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99906 (* 1 = 7.99906 loss)
I0523 08:52:27.653520 34819 sgd_solver.cpp:112] Iteration 79900, lr = 0.01
I0523 08:52:32.494946 34819 solver.cpp:239] Iteration 79910 (2.04239 iter/s, 4.89623s/10 iters), loss = 7.56312
I0523 08:52:32.495002 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56312 (* 1 = 7.56312 loss)
I0523 08:52:33.357483 34819 sgd_solver.cpp:112] Iteration 79910, lr = 0.01
I0523 08:52:38.708562 34819 solver.cpp:239] Iteration 79920 (1.60945 iter/s, 6.21329s/10 iters), loss = 7.7186
I0523 08:52:38.708621 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.7186 (* 1 = 7.7186 loss)
I0523 08:52:39.441512 34819 sgd_solver.cpp:112] Iteration 79920, lr = 0.01
I0523 08:52:42.886519 34819 solver.cpp:239] Iteration 79930 (2.39365 iter/s, 4.17771s/10 iters), loss = 6.81612
I0523 08:52:42.886576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.81612 (* 1 = 6.81612 loss)
I0523 08:52:43.626920 34819 sgd_solver.cpp:112] Iteration 79930, lr = 0.01
I0523 08:52:49.294786 34819 solver.cpp:239] Iteration 79940 (1.56056 iter/s, 6.40795s/10 iters), loss = 8.05726
I0523 08:52:49.294840 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05726 (* 1 = 8.05726 loss)
I0523 08:52:49.354257 34819 sgd_solver.cpp:112] Iteration 79940, lr = 0.01
I0523 08:52:55.105855 34819 solver.cpp:239] Iteration 79950 (1.72094 iter/s, 5.81077s/10 iters), loss = 7.9558
I0523 08:52:55.105909 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.9558 (* 1 = 7.9558 loss)
I0523 08:52:55.178313 34819 sgd_solver.cpp:112] Iteration 79950, lr = 0.01
I0523 08:52:58.609627 34819 solver.cpp:239] Iteration 79960 (2.85423 iter/s, 3.50357s/10 iters), loss = 7.07362
I0523 08:52:58.609799 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.07362 (* 1 = 7.07362 loss)
I0523 08:52:58.676997 34819 sgd_solver.cpp:112] Iteration 79960, lr = 0.01
I0523 08:53:01.402482 34819 solver.cpp:239] Iteration 79970 (3.58093 iter/s, 2.79257s/10 iters), loss = 7.31597
I0523 08:53:01.402525 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.31597 (* 1 = 7.31597 loss)
I0523 08:53:02.258328 34819 sgd_solver.cpp:112] Iteration 79970, lr = 0.01
I0523 08:53:04.709435 34819 solver.cpp:239] Iteration 79980 (3.02411 iter/s, 3.30676s/10 iters), loss = 8.93865
I0523 08:53:04.709497 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.93865 (* 1 = 8.93865 loss)
I0523 08:53:04.779788 34819 sgd_solver.cpp:112] Iteration 79980, lr = 0.01
I0523 08:53:08.391957 34819 solver.cpp:239] Iteration 79990 (2.7157 iter/s, 3.6823s/10 iters), loss = 7.40494
I0523 08:53:08.392011 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.40494 (* 1 = 7.40494 loss)
I0523 08:53:09.184020 34819 sgd_solver.cpp:112] Iteration 79990, lr = 0.01
I0523 08:53:13.808990 34819 solver.cpp:468] Snapshotting to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_80000.caffemodel
I0523 08:53:24.738283 34819 sgd_solver.cpp:280] Snapshotting solver state to binary proto file ../asset/snapshot/AMlmdbCdata/AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn/2018-05-22_AMlmdbCdata-b0.35s30_fc_0.35_112x96_b+FaceAdd+encode_faceNet-20-light2s4-bn_zkx_iter_80000.solverstate
I0523 08:53:24.963640 34819 solver.cpp:239] Iteration 80000 (0.603464 iter/s, 16.571s/10 iters), loss = 8.09443
I0523 08:53:24.963690 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.09443 (* 1 = 8.09443 loss)
I0523 08:53:25.034338 34819 sgd_solver.cpp:112] Iteration 80000, lr = 0.01
I0523 08:53:29.964401 34819 solver.cpp:239] Iteration 80010 (2.00002 iter/s, 4.99995s/10 iters), loss = 7.70409
I0523 08:53:29.964591 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.70409 (* 1 = 7.70409 loss)
I0523 08:53:30.041615 34819 sgd_solver.cpp:112] Iteration 80010, lr = 0.01
I0523 08:53:33.559880 34819 solver.cpp:239] Iteration 80020 (2.78154 iter/s, 3.59513s/10 iters), loss = 7.64914
I0523 08:53:33.559942 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64914 (* 1 = 7.64914 loss)
I0523 08:53:33.633148 34819 sgd_solver.cpp:112] Iteration 80020, lr = 0.01
I0523 08:53:37.962757 34819 solver.cpp:239] Iteration 80030 (2.27137 iter/s, 4.40263s/10 iters), loss = 8.36433
I0523 08:53:37.962800 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.36433 (* 1 = 8.36433 loss)
I0523 08:53:38.547017 34819 sgd_solver.cpp:112] Iteration 80030, lr = 0.01
I0523 08:53:43.340236 34819 solver.cpp:239] Iteration 80040 (1.8597 iter/s, 5.3772s/10 iters), loss = 8.0522
I0523 08:53:43.340286 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.0522 (* 1 = 8.0522 loss)
I0523 08:53:44.123399 34819 sgd_solver.cpp:112] Iteration 80040, lr = 0.01
I0523 08:53:48.310621 34819 solver.cpp:239] Iteration 80050 (2.01203 iter/s, 4.97011s/10 iters), loss = 8.08991
I0523 08:53:48.310678 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08991 (* 1 = 8.08991 loss)
I0523 08:53:48.950212 34819 sgd_solver.cpp:112] Iteration 80050, lr = 0.01
I0523 08:53:53.495059 34819 solver.cpp:239] Iteration 80060 (1.92895 iter/s, 5.18417s/10 iters), loss = 7.25274
I0523 08:53:53.495102 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.25274 (* 1 = 7.25274 loss)
I0523 08:53:53.558727 34819 sgd_solver.cpp:112] Iteration 80060, lr = 0.01
I0523 08:53:57.699065 34819 solver.cpp:239] Iteration 80070 (2.37881 iter/s, 4.20379s/10 iters), loss = 8.00802
I0523 08:53:57.699120 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00802 (* 1 = 8.00802 loss)
I0523 08:53:57.939815 34819 sgd_solver.cpp:112] Iteration 80070, lr = 0.01
I0523 08:54:01.522795 34819 solver.cpp:239] Iteration 80080 (2.61539 iter/s, 3.82352s/10 iters), loss = 8.43561
I0523 08:54:01.522886 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.43561 (* 1 = 8.43561 loss)
I0523 08:54:01.580315 34819 sgd_solver.cpp:112] Iteration 80080, lr = 0.01
I0523 08:54:05.524982 34819 solver.cpp:239] Iteration 80090 (2.50023 iter/s, 3.99963s/10 iters), loss = 7.51355
I0523 08:54:05.525030 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.51355 (* 1 = 7.51355 loss)
I0523 08:54:06.353094 34819 sgd_solver.cpp:112] Iteration 80090, lr = 0.01
I0523 08:54:11.843312 34819 solver.cpp:239] Iteration 80100 (1.58278 iter/s, 6.31801s/10 iters), loss = 7.12422
I0523 08:54:11.843369 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.12422 (* 1 = 7.12422 loss)
I0523 08:54:12.674895 34819 sgd_solver.cpp:112] Iteration 80100, lr = 0.01
I0523 08:54:18.369393 34819 solver.cpp:239] Iteration 80110 (1.53239 iter/s, 6.52575s/10 iters), loss = 7.73503
I0523 08:54:18.369446 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73503 (* 1 = 7.73503 loss)
I0523 08:54:18.446913 34819 sgd_solver.cpp:112] Iteration 80110, lr = 0.01
I0523 08:54:21.639787 34819 solver.cpp:239] Iteration 80120 (3.05793 iter/s, 3.27019s/10 iters), loss = 8.65339
I0523 08:54:21.639839 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.65339 (* 1 = 8.65339 loss)
I0523 08:54:21.708884 34819 sgd_solver.cpp:112] Iteration 80120, lr = 0.01
I0523 08:54:25.729203 34819 solver.cpp:239] Iteration 80130 (2.44547 iter/s, 4.08919s/10 iters), loss = 8.49292
I0523 08:54:25.729249 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.49292 (* 1 = 8.49292 loss)
I0523 08:54:26.539808 34819 sgd_solver.cpp:112] Iteration 80130, lr = 0.01
I0523 08:54:32.092676 34819 solver.cpp:239] Iteration 80140 (1.57155 iter/s, 6.36315s/10 iters), loss = 8.14071
I0523 08:54:32.092890 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14071 (* 1 = 8.14071 loss)
I0523 08:54:32.144820 34819 sgd_solver.cpp:112] Iteration 80140, lr = 0.01
I0523 08:54:35.578594 34819 solver.cpp:239] Iteration 80150 (2.86898 iter/s, 3.48556s/10 iters), loss = 8.45337
I0523 08:54:35.578649 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.45337 (* 1 = 8.45337 loss)
I0523 08:54:35.631779 34819 sgd_solver.cpp:112] Iteration 80150, lr = 0.01
I0523 08:54:41.015694 34819 solver.cpp:239] Iteration 80160 (1.83931 iter/s, 5.43682s/10 iters), loss = 7.66184
I0523 08:54:41.015740 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.66184 (* 1 = 7.66184 loss)
I0523 08:54:41.086369 34819 sgd_solver.cpp:112] Iteration 80160, lr = 0.01
I0523 08:54:45.314601 34819 solver.cpp:239] Iteration 80170 (2.3263 iter/s, 4.29867s/10 iters), loss = 8.26812
I0523 08:54:45.314666 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.26812 (* 1 = 8.26812 loss)
I0523 08:54:46.072592 34819 sgd_solver.cpp:112] Iteration 80170, lr = 0.01
I0523 08:54:49.436965 34819 solver.cpp:239] Iteration 80180 (2.42593 iter/s, 4.12212s/10 iters), loss = 7.99784
I0523 08:54:49.437032 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99784 (* 1 = 7.99784 loss)
I0523 08:54:50.286558 34819 sgd_solver.cpp:112] Iteration 80180, lr = 0.01
I0523 08:54:54.748716 34819 solver.cpp:239] Iteration 80190 (1.88274 iter/s, 5.31142s/10 iters), loss = 7.6182
I0523 08:54:54.748782 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.6182 (* 1 = 7.6182 loss)
I0523 08:54:54.848671 34819 sgd_solver.cpp:112] Iteration 80190, lr = 0.01
I0523 08:54:58.096006 34819 solver.cpp:239] Iteration 80200 (2.98768 iter/s, 3.34708s/10 iters), loss = 7.26559
I0523 08:54:58.096052 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.26559 (* 1 = 7.26559 loss)
I0523 08:54:58.158218 34819 sgd_solver.cpp:112] Iteration 80200, lr = 0.01
I0523 08:55:03.858258 34819 solver.cpp:239] Iteration 80210 (1.73552 iter/s, 5.76195s/10 iters), loss = 7.50436
I0523 08:55:03.858454 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.50436 (* 1 = 7.50436 loss)
I0523 08:55:04.719456 34819 sgd_solver.cpp:112] Iteration 80210, lr = 0.01
I0523 08:55:11.701081 34819 solver.cpp:239] Iteration 80220 (1.27513 iter/s, 7.84232s/10 iters), loss = 8.02561
I0523 08:55:11.701155 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02561 (* 1 = 8.02561 loss)
I0523 08:55:12.505995 34819 sgd_solver.cpp:112] Iteration 80220, lr = 0.01
I0523 08:55:16.663511 34819 solver.cpp:239] Iteration 80230 (2.01526 iter/s, 4.96214s/10 iters), loss = 8.24924
I0523 08:55:16.663566 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.24924 (* 1 = 8.24924 loss)
I0523 08:55:16.745309 34819 sgd_solver.cpp:112] Iteration 80230, lr = 0.01
I0523 08:55:22.738333 34819 solver.cpp:239] Iteration 80240 (1.64622 iter/s, 6.0745s/10 iters), loss = 7.63706
I0523 08:55:22.738386 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63706 (* 1 = 7.63706 loss)
I0523 08:55:23.358575 34819 sgd_solver.cpp:112] Iteration 80240, lr = 0.01
I0523 08:55:29.442608 34819 solver.cpp:239] Iteration 80250 (1.49166 iter/s, 6.70394s/10 iters), loss = 8.39056
I0523 08:55:29.442662 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.39056 (* 1 = 8.39056 loss)
I0523 08:55:30.243002 34819 sgd_solver.cpp:112] Iteration 80250, lr = 0.01
I0523 08:55:35.720563 34819 solver.cpp:239] Iteration 80260 (1.59295 iter/s, 6.27765s/10 iters), loss = 7.44659
I0523 08:55:35.720700 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.44659 (* 1 = 7.44659 loss)
I0523 08:55:36.608300 34819 sgd_solver.cpp:112] Iteration 80260, lr = 0.01
I0523 08:55:41.606577 34819 solver.cpp:239] Iteration 80270 (1.69905 iter/s, 5.88563s/10 iters), loss = 8.30214
I0523 08:55:41.606619 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.30214 (* 1 = 8.30214 loss)
I0523 08:55:42.290261 34819 sgd_solver.cpp:112] Iteration 80270, lr = 0.01
I0523 08:55:48.369472 34819 solver.cpp:239] Iteration 80280 (1.47873 iter/s, 6.76258s/10 iters), loss = 7.76813
I0523 08:55:48.369516 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76813 (* 1 = 7.76813 loss)
I0523 08:55:48.442641 34819 sgd_solver.cpp:112] Iteration 80280, lr = 0.01
I0523 08:55:54.136179 34819 solver.cpp:239] Iteration 80290 (1.73418 iter/s, 5.76642s/10 iters), loss = 6.74593
I0523 08:55:54.136234 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.74593 (* 1 = 6.74593 loss)
I0523 08:55:54.204449 34819 sgd_solver.cpp:112] Iteration 80290, lr = 0.01
I0523 08:56:01.451289 34819 solver.cpp:239] Iteration 80300 (1.3671 iter/s, 7.31475s/10 iters), loss = 7.29789
I0523 08:56:01.451335 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29789 (* 1 = 7.29789 loss)
I0523 08:56:01.525162 34819 sgd_solver.cpp:112] Iteration 80300, lr = 0.01
I0523 08:56:06.441778 34819 solver.cpp:239] Iteration 80310 (2.00547 iter/s, 4.98637s/10 iters), loss = 7.63968
I0523 08:56:06.441953 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63968 (* 1 = 7.63968 loss)
I0523 08:56:07.224369 34819 sgd_solver.cpp:112] Iteration 80310, lr = 0.01
I0523 08:56:12.318732 34819 solver.cpp:239] Iteration 80320 (1.70169 iter/s, 5.87652s/10 iters), loss = 7.57858
I0523 08:56:12.318781 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57858 (* 1 = 7.57858 loss)
I0523 08:56:12.876276 34819 sgd_solver.cpp:112] Iteration 80320, lr = 0.01
I0523 08:56:17.808688 34819 solver.cpp:239] Iteration 80330 (1.8216 iter/s, 5.48968s/10 iters), loss = 7.79321
I0523 08:56:17.808749 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79321 (* 1 = 7.79321 loss)
I0523 08:56:18.246552 34819 sgd_solver.cpp:112] Iteration 80330, lr = 0.01
I0523 08:56:23.757483 34819 solver.cpp:239] Iteration 80340 (1.6811 iter/s, 5.94849s/10 iters), loss = 8.62168
I0523 08:56:23.757534 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.62168 (* 1 = 8.62168 loss)
I0523 08:56:23.825445 34819 sgd_solver.cpp:112] Iteration 80340, lr = 0.01
I0523 08:56:27.871855 34819 solver.cpp:239] Iteration 80350 (2.43064 iter/s, 4.11414s/10 iters), loss = 7.76492
I0523 08:56:27.871917 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.76492 (* 1 = 7.76492 loss)
I0523 08:56:27.944643 34819 sgd_solver.cpp:112] Iteration 80350, lr = 0.01
I0523 08:56:32.666281 34819 solver.cpp:239] Iteration 80360 (2.08588 iter/s, 4.79414s/10 iters), loss = 7.73664
I0523 08:56:32.666373 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.73664 (* 1 = 7.73664 loss)
I0523 08:56:33.506592 34819 sgd_solver.cpp:112] Iteration 80360, lr = 0.01
I0523 08:56:39.366032 34819 solver.cpp:239] Iteration 80370 (1.49267 iter/s, 6.69939s/10 iters), loss = 7.93445
I0523 08:56:39.366250 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93445 (* 1 = 7.93445 loss)
I0523 08:56:40.180186 34819 sgd_solver.cpp:112] Iteration 80370, lr = 0.01
I0523 08:56:46.419486 34819 solver.cpp:239] Iteration 80380 (1.41784 iter/s, 7.05297s/10 iters), loss = 7.62146
I0523 08:56:46.419543 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62146 (* 1 = 7.62146 loss)
I0523 08:56:46.500432 34819 sgd_solver.cpp:112] Iteration 80380, lr = 0.01
I0523 08:56:50.811414 34819 solver.cpp:239] Iteration 80390 (2.27703 iter/s, 4.39168s/10 iters), loss = 7.83878
I0523 08:56:50.811460 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83878 (* 1 = 7.83878 loss)
I0523 08:56:51.519047 34819 sgd_solver.cpp:112] Iteration 80390, lr = 0.01
I0523 08:56:57.292387 34819 solver.cpp:239] Iteration 80400 (1.54306 iter/s, 6.48065s/10 iters), loss = 7.56462
I0523 08:56:57.292443 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56462 (* 1 = 7.56462 loss)
I0523 08:56:57.359966 34819 sgd_solver.cpp:112] Iteration 80400, lr = 0.01
I0523 08:57:00.807476 34819 solver.cpp:239] Iteration 80410 (2.84705 iter/s, 3.51241s/10 iters), loss = 8.57473
I0523 08:57:00.807533 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.57473 (* 1 = 8.57473 loss)
I0523 08:57:01.212692 34819 sgd_solver.cpp:112] Iteration 80410, lr = 0.01
I0523 08:57:05.981799 34819 solver.cpp:239] Iteration 80420 (1.93272 iter/s, 5.17405s/10 iters), loss = 7.62485
I0523 08:57:05.981853 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.62485 (* 1 = 7.62485 loss)
I0523 08:57:06.798436 34819 sgd_solver.cpp:112] Iteration 80420, lr = 0.01
I0523 08:57:13.113638 34819 solver.cpp:239] Iteration 80430 (1.40223 iter/s, 7.13149s/10 iters), loss = 8.05103
I0523 08:57:13.113819 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.05103 (* 1 = 8.05103 loss)
I0523 08:57:13.179213 34819 sgd_solver.cpp:112] Iteration 80430, lr = 0.01
I0523 08:57:15.489328 34819 solver.cpp:239] Iteration 80440 (4.20981 iter/s, 2.3754s/10 iters), loss = 8.01045
I0523 08:57:15.489369 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.01045 (* 1 = 8.01045 loss)
I0523 08:57:15.547036 34819 sgd_solver.cpp:112] Iteration 80440, lr = 0.01
I0523 08:57:18.995538 34819 solver.cpp:239] Iteration 80450 (2.85226 iter/s, 3.50599s/10 iters), loss = 8.00457
I0523 08:57:18.995592 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.00457 (* 1 = 8.00457 loss)
I0523 08:57:19.056035 34819 sgd_solver.cpp:112] Iteration 80450, lr = 0.01
I0523 08:57:22.487390 34819 solver.cpp:239] Iteration 80460 (2.86398 iter/s, 3.49165s/10 iters), loss = 6.49287
I0523 08:57:22.487438 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.49287 (* 1 = 6.49287 loss)
I0523 08:57:22.542909 34819 sgd_solver.cpp:112] Iteration 80460, lr = 0.01
I0523 08:57:28.072098 34819 solver.cpp:239] Iteration 80470 (1.7907 iter/s, 5.58442s/10 iters), loss = 7.01021
I0523 08:57:28.072142 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.01021 (* 1 = 7.01021 loss)
I0523 08:57:28.129443 34819 sgd_solver.cpp:112] Iteration 80470, lr = 0.01
I0523 08:57:32.175823 34819 solver.cpp:239] Iteration 80480 (2.43695 iter/s, 4.1035s/10 iters), loss = 8.25096
I0523 08:57:32.175865 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.25096 (* 1 = 8.25096 loss)
I0523 08:57:33.066015 34819 sgd_solver.cpp:112] Iteration 80480, lr = 0.01
I0523 08:57:37.038092 34819 solver.cpp:239] Iteration 80490 (2.05676 iter/s, 4.86202s/10 iters), loss = 7.72201
I0523 08:57:37.038144 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72201 (* 1 = 7.72201 loss)
I0523 08:57:37.792532 34819 sgd_solver.cpp:112] Iteration 80490, lr = 0.01
I0523 08:57:41.689646 34819 solver.cpp:239] Iteration 80500 (2.14994 iter/s, 4.6513s/10 iters), loss = 7.29221
I0523 08:57:41.689688 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.29221 (* 1 = 7.29221 loss)
I0523 08:57:41.759555 34819 sgd_solver.cpp:112] Iteration 80500, lr = 0.01
I0523 08:57:47.133219 34819 solver.cpp:239] Iteration 80510 (1.83713 iter/s, 5.44327s/10 iters), loss = 8.06595
I0523 08:57:47.133451 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.06595 (* 1 = 8.06595 loss)
I0523 08:57:47.578192 34819 sgd_solver.cpp:112] Iteration 80510, lr = 0.01
I0523 08:57:50.946781 34819 solver.cpp:239] Iteration 80520 (2.62247 iter/s, 3.81319s/10 iters), loss = 8.02701
I0523 08:57:50.946825 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.02701 (* 1 = 8.02701 loss)
I0523 08:57:51.765905 34819 sgd_solver.cpp:112] Iteration 80520, lr = 0.01
I0523 08:57:56.741173 34819 solver.cpp:239] Iteration 80530 (1.72589 iter/s, 5.7941s/10 iters), loss = 7.92782
I0523 08:57:56.741233 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.92782 (* 1 = 7.92782 loss)
I0523 08:57:57.448015 34819 sgd_solver.cpp:112] Iteration 80530, lr = 0.01
I0523 08:58:02.072893 34819 solver.cpp:239] Iteration 80540 (1.87567 iter/s, 5.33144s/10 iters), loss = 8.34468
I0523 08:58:02.072937 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.34468 (* 1 = 8.34468 loss)
I0523 08:58:02.784097 34819 sgd_solver.cpp:112] Iteration 80540, lr = 0.01
I0523 08:58:07.072808 34819 solver.cpp:239] Iteration 80550 (2.00014 iter/s, 4.99965s/10 iters), loss = 7.63882
I0523 08:58:07.072852 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.63882 (* 1 = 7.63882 loss)
I0523 08:58:07.155485 34819 sgd_solver.cpp:112] Iteration 80550, lr = 0.01
I0523 08:58:13.410457 34819 solver.cpp:239] Iteration 80560 (1.57795 iter/s, 6.33734s/10 iters), loss = 8.14961
I0523 08:58:13.410502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.14961 (* 1 = 8.14961 loss)
I0523 08:58:13.469766 34819 sgd_solver.cpp:112] Iteration 80560, lr = 0.01
I0523 08:58:16.582659 34819 solver.cpp:239] Iteration 80570 (3.15257 iter/s, 3.17201s/10 iters), loss = 7.3574
I0523 08:58:16.582720 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.3574 (* 1 = 7.3574 loss)
I0523 08:58:17.415810 34819 sgd_solver.cpp:112] Iteration 80570, lr = 0.01
I0523 08:58:22.093895 34819 solver.cpp:239] Iteration 80580 (1.81457 iter/s, 5.51093s/10 iters), loss = 8.58126
I0523 08:58:22.093952 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.58126 (* 1 = 8.58126 loss)
I0523 08:58:22.178170 34819 sgd_solver.cpp:112] Iteration 80580, lr = 0.01
I0523 08:58:26.698617 34819 solver.cpp:239] Iteration 80590 (2.1718 iter/s, 4.60447s/10 iters), loss = 6.99366
I0523 08:58:26.698668 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.99366 (* 1 = 6.99366 loss)
I0523 08:58:26.771507 34819 sgd_solver.cpp:112] Iteration 80590, lr = 0.01
I0523 08:58:31.823463 34819 solver.cpp:239] Iteration 80600 (1.95139 iter/s, 5.12455s/10 iters), loss = 7.17749
I0523 08:58:31.823540 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.17749 (* 1 = 7.17749 loss)
I0523 08:58:32.083736 34819 sgd_solver.cpp:112] Iteration 80600, lr = 0.01
I0523 08:58:35.359232 34819 solver.cpp:239] Iteration 80610 (2.82844 iter/s, 3.53551s/10 iters), loss = 8.51495
I0523 08:58:35.359302 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.51495 (* 1 = 8.51495 loss)
I0523 08:58:36.244452 34819 sgd_solver.cpp:112] Iteration 80610, lr = 0.01
I0523 08:58:43.414301 34819 solver.cpp:239] Iteration 80620 (1.24152 iter/s, 8.05466s/10 iters), loss = 7.57364
I0523 08:58:43.414367 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.57364 (* 1 = 7.57364 loss)
I0523 08:58:44.161783 34819 sgd_solver.cpp:112] Iteration 80620, lr = 0.01
I0523 08:58:47.263916 34819 solver.cpp:239] Iteration 80630 (2.59782 iter/s, 3.84938s/10 iters), loss = 7.64972
I0523 08:58:47.263972 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.64972 (* 1 = 7.64972 loss)
I0523 08:58:47.318953 34819 sgd_solver.cpp:112] Iteration 80630, lr = 0.01
I0523 08:58:52.366143 34819 solver.cpp:239] Iteration 80640 (1.96003 iter/s, 5.10196s/10 iters), loss = 7.88455
I0523 08:58:52.366266 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88455 (* 1 = 7.88455 loss)
I0523 08:58:52.427726 34819 sgd_solver.cpp:112] Iteration 80640, lr = 0.01
I0523 08:58:55.519729 34819 solver.cpp:239] Iteration 80650 (3.17125 iter/s, 3.15333s/10 iters), loss = 7.56163
I0523 08:58:55.519773 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.56163 (* 1 = 7.56163 loss)
I0523 08:58:55.587522 34819 sgd_solver.cpp:112] Iteration 80650, lr = 0.01
I0523 08:59:00.102974 34819 solver.cpp:239] Iteration 80660 (2.18198 iter/s, 4.583s/10 iters), loss = 7.99354
I0523 08:59:00.103022 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.99354 (* 1 = 7.99354 loss)
I0523 08:59:00.738690 34819 sgd_solver.cpp:112] Iteration 80660, lr = 0.01
I0523 08:59:06.019826 34819 solver.cpp:239] Iteration 80670 (1.69018 iter/s, 5.91654s/10 iters), loss = 8.31244
I0523 08:59:06.019884 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.31244 (* 1 = 8.31244 loss)
I0523 08:59:06.084842 34819 sgd_solver.cpp:112] Iteration 80670, lr = 0.01
I0523 08:59:09.524976 34819 solver.cpp:239] Iteration 80680 (2.85311 iter/s, 3.50494s/10 iters), loss = 6.94904
I0523 08:59:09.525023 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.94904 (* 1 = 6.94904 loss)
I0523 08:59:09.573987 34819 sgd_solver.cpp:112] Iteration 80680, lr = 0.01
I0523 08:59:15.027087 34819 solver.cpp:239] Iteration 80690 (1.81757 iter/s, 5.50184s/10 iters), loss = 8.12348
I0523 08:59:15.027132 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12348 (* 1 = 8.12348 loss)
I0523 08:59:15.835188 34819 sgd_solver.cpp:112] Iteration 80690, lr = 0.01
I0523 08:59:20.136492 34819 solver.cpp:239] Iteration 80700 (1.95753 iter/s, 5.10848s/10 iters), loss = 6.91436
I0523 08:59:20.136539 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.91436 (* 1 = 6.91436 loss)
I0523 08:59:20.240196 34819 sgd_solver.cpp:112] Iteration 80700, lr = 0.01
I0523 08:59:24.868916 34819 solver.cpp:239] Iteration 80710 (2.1132 iter/s, 4.73215s/10 iters), loss = 7.87253
I0523 08:59:24.869057 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.87253 (* 1 = 7.87253 loss)
I0523 08:59:24.925226 34819 sgd_solver.cpp:112] Iteration 80710, lr = 0.01
I0523 08:59:31.378661 34819 solver.cpp:239] Iteration 80720 (1.53626 iter/s, 6.50933s/10 iters), loss = 7.93247
I0523 08:59:31.378726 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.93247 (* 1 = 7.93247 loss)
I0523 08:59:32.120026 34819 sgd_solver.cpp:112] Iteration 80720, lr = 0.01
I0523 08:59:36.933928 34819 solver.cpp:239] Iteration 80730 (1.80019 iter/s, 5.55497s/10 iters), loss = 7.75445
I0523 08:59:36.933979 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.75445 (* 1 = 7.75445 loss)
I0523 08:59:37.731487 34819 sgd_solver.cpp:112] Iteration 80730, lr = 0.01
I0523 08:59:41.840275 34819 solver.cpp:239] Iteration 80740 (2.03828 iter/s, 4.90609s/10 iters), loss = 8.7186
I0523 08:59:41.840322 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.7186 (* 1 = 8.7186 loss)
I0523 08:59:42.453713 34819 sgd_solver.cpp:112] Iteration 80740, lr = 0.01
I0523 08:59:47.524169 34819 solver.cpp:239] Iteration 80750 (1.75944 iter/s, 5.68361s/10 iters), loss = 7.83102
I0523 08:59:47.524215 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.83102 (* 1 = 7.83102 loss)
I0523 08:59:48.303452 34819 sgd_solver.cpp:112] Iteration 80750, lr = 0.01
I0523 08:59:51.702448 34819 solver.cpp:239] Iteration 80760 (2.39347 iter/s, 4.17804s/10 iters), loss = 7.85805
I0523 08:59:51.702502 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.85805 (* 1 = 7.85805 loss)
I0523 08:59:51.753717 34819 sgd_solver.cpp:112] Iteration 80760, lr = 0.01
I0523 08:59:54.805650 34819 solver.cpp:239] Iteration 80770 (3.22268 iter/s, 3.10301s/10 iters), loss = 7.03382
I0523 08:59:54.805701 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.03382 (* 1 = 7.03382 loss)
I0523 08:59:55.578981 34819 sgd_solver.cpp:112] Iteration 80770, lr = 0.01
I0523 09:00:00.042925 34819 solver.cpp:239] Iteration 80780 (1.90949 iter/s, 5.237s/10 iters), loss = 7.06794
I0523 09:00:00.042974 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.06794 (* 1 = 7.06794 loss)
I0523 09:00:00.099123 34819 sgd_solver.cpp:112] Iteration 80780, lr = 0.01
I0523 09:00:04.271078 34819 solver.cpp:239] Iteration 80790 (2.36523 iter/s, 4.22792s/10 iters), loss = 7.25056
I0523 09:00:04.271119 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.25056 (* 1 = 7.25056 loss)
I0523 09:00:04.327757 34819 sgd_solver.cpp:112] Iteration 80790, lr = 0.01
I0523 09:00:08.026382 34819 solver.cpp:239] Iteration 80800 (2.66305 iter/s, 3.7551s/10 iters), loss = 7.79281
I0523 09:00:08.026437 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.79281 (* 1 = 7.79281 loss)
I0523 09:00:08.767226 34819 sgd_solver.cpp:112] Iteration 80800, lr = 0.01
I0523 09:00:13.015547 34819 solver.cpp:239] Iteration 80810 (2.00445 iter/s, 4.98891s/10 iters), loss = 8.08399
I0523 09:00:13.015594 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.08399 (* 1 = 8.08399 loss)
I0523 09:00:13.091316 34819 sgd_solver.cpp:112] Iteration 80810, lr = 0.01
I0523 09:00:15.969774 34819 solver.cpp:239] Iteration 80820 (3.3852 iter/s, 2.95403s/10 iters), loss = 8.60633
I0523 09:00:15.969835 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.60633 (* 1 = 8.60633 loss)
I0523 09:00:16.050788 34819 sgd_solver.cpp:112] Iteration 80820, lr = 0.01
I0523 09:00:21.807988 34819 solver.cpp:239] Iteration 80830 (1.71294 iter/s, 5.83791s/10 iters), loss = 8.2802
I0523 09:00:21.808049 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.2802 (* 1 = 8.2802 loss)
I0523 09:00:22.666713 34819 sgd_solver.cpp:112] Iteration 80830, lr = 0.01
I0523 09:00:28.340683 34819 solver.cpp:239] Iteration 80840 (1.53084 iter/s, 6.53236s/10 iters), loss = 8.10427
I0523 09:00:28.340929 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10427 (* 1 = 8.10427 loss)
I0523 09:00:29.041741 34819 sgd_solver.cpp:112] Iteration 80840, lr = 0.01
I0523 09:00:34.434625 34819 solver.cpp:239] Iteration 80850 (1.6411 iter/s, 6.09346s/10 iters), loss = 6.48157
I0523 09:00:34.434680 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.48157 (* 1 = 6.48157 loss)
I0523 09:00:34.497473 34819 sgd_solver.cpp:112] Iteration 80850, lr = 0.01
I0523 09:00:39.731798 34819 solver.cpp:239] Iteration 80860 (1.88791 iter/s, 5.29688s/10 iters), loss = 7.31475
I0523 09:00:39.731871 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.31475 (* 1 = 7.31475 loss)
I0523 09:00:39.804575 34819 sgd_solver.cpp:112] Iteration 80860, lr = 0.01
I0523 09:00:45.513674 34819 solver.cpp:239] Iteration 80870 (1.72964 iter/s, 5.78156s/10 iters), loss = 8.12694
I0523 09:00:45.513732 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.12694 (* 1 = 8.12694 loss)
I0523 09:00:45.584478 34819 sgd_solver.cpp:112] Iteration 80870, lr = 0.01
I0523 09:00:50.973286 34819 solver.cpp:239] Iteration 80880 (1.83173 iter/s, 5.45933s/10 iters), loss = 7.02556
I0523 09:00:50.973328 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.02556 (* 1 = 7.02556 loss)
I0523 09:00:51.033705 34819 sgd_solver.cpp:112] Iteration 80880, lr = 0.01
I0523 09:00:55.937466 34819 solver.cpp:239] Iteration 80890 (2.01453 iter/s, 4.96393s/10 iters), loss = 7.72366
I0523 09:00:55.937511 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.72366 (* 1 = 7.72366 loss)
I0523 09:00:56.706068 34819 sgd_solver.cpp:112] Iteration 80890, lr = 0.01
I0523 09:01:00.782625 34819 solver.cpp:239] Iteration 80900 (2.06403 iter/s, 4.8449s/10 iters), loss = 6.95803
I0523 09:01:00.782774 34819 solver.cpp:258]     Train net output #0: softmax_loss = 6.95803 (* 1 = 6.95803 loss)
I0523 09:01:01.042812 34819 sgd_solver.cpp:112] Iteration 80900, lr = 0.01
I0523 09:01:05.220499 34819 solver.cpp:239] Iteration 80910 (2.2535 iter/s, 4.43754s/10 iters), loss = 7.67207
I0523 09:01:05.220551 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.67207 (* 1 = 7.67207 loss)
I0523 09:01:06.032968 34819 sgd_solver.cpp:112] Iteration 80910, lr = 0.01
I0523 09:01:09.310216 34819 solver.cpp:239] Iteration 80920 (2.44529 iter/s, 4.08949s/10 iters), loss = 7.1382
I0523 09:01:09.310271 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.1382 (* 1 = 7.1382 loss)
I0523 09:01:09.375501 34819 sgd_solver.cpp:112] Iteration 80920, lr = 0.01
I0523 09:01:14.162621 34819 solver.cpp:239] Iteration 80930 (2.06095 iter/s, 4.85212s/10 iters), loss = 7.00272
I0523 09:01:14.162691 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.00272 (* 1 = 7.00272 loss)
I0523 09:01:15.022927 34819 sgd_solver.cpp:112] Iteration 80930, lr = 0.01
I0523 09:01:21.538141 34819 solver.cpp:239] Iteration 80940 (1.3559 iter/s, 7.37516s/10 iters), loss = 8.64822
I0523 09:01:21.538185 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.64822 (* 1 = 8.64822 loss)
I0523 09:01:21.596369 34819 sgd_solver.cpp:112] Iteration 80940, lr = 0.01
I0523 09:01:26.197500 34819 solver.cpp:239] Iteration 80950 (2.14633 iter/s, 4.65912s/10 iters), loss = 8.10421
I0523 09:01:26.197552 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.10421 (* 1 = 8.10421 loss)
I0523 09:01:26.280252 34819 sgd_solver.cpp:112] Iteration 80950, lr = 0.01
I0523 09:01:29.425405 34819 solver.cpp:239] Iteration 80960 (3.09817 iter/s, 3.22771s/10 iters), loss = 7.88425
I0523 09:01:29.425460 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.88425 (* 1 = 7.88425 loss)
I0523 09:01:29.504020 34819 sgd_solver.cpp:112] Iteration 80960, lr = 0.01
I0523 09:01:33.818413 34819 solver.cpp:239] Iteration 80970 (2.27648 iter/s, 4.39276s/10 iters), loss = 9.11488
I0523 09:01:33.818576 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.11488 (* 1 = 9.11488 loss)
I0523 09:01:33.890612 34819 sgd_solver.cpp:112] Iteration 80970, lr = 0.01
I0523 09:01:37.670449 34819 solver.cpp:239] Iteration 80980 (2.59625 iter/s, 3.85171s/10 iters), loss = 7.52505
I0523 09:01:37.670501 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.52505 (* 1 = 7.52505 loss)
I0523 09:01:37.734539 34819 sgd_solver.cpp:112] Iteration 80980, lr = 0.01
I0523 09:01:40.944255 34819 solver.cpp:239] Iteration 80990 (3.05473 iter/s, 3.27361s/10 iters), loss = 8.32524
I0523 09:01:40.944305 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.32524 (* 1 = 8.32524 loss)
I0523 09:01:41.027920 34819 sgd_solver.cpp:112] Iteration 80990, lr = 0.01
I0523 09:01:44.662209 34819 solver.cpp:239] Iteration 81000 (2.68981 iter/s, 3.71773s/10 iters), loss = 7.17355
I0523 09:01:44.662279 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.17355 (* 1 = 7.17355 loss)
I0523 09:01:44.735764 34819 sgd_solver.cpp:112] Iteration 81000, lr = 0.01
I0523 09:01:49.524044 34819 solver.cpp:239] Iteration 81010 (2.05695 iter/s, 4.86156s/10 iters), loss = 8.47738
I0523 09:01:49.524091 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.47738 (* 1 = 8.47738 loss)
I0523 09:01:49.592623 34819 sgd_solver.cpp:112] Iteration 81010, lr = 0.01
I0523 09:01:54.567904 34819 solver.cpp:239] Iteration 81020 (1.98271 iter/s, 5.0436s/10 iters), loss = 9.29046
I0523 09:01:54.567950 34819 solver.cpp:258]     Train net output #0: softmax_loss = 9.29046 (* 1 = 9.29046 loss)
I0523 09:01:55.302618 34819 sgd_solver.cpp:112] Iteration 81020, lr = 0.01
I0523 09:02:00.750077 34819 solver.cpp:239] Iteration 81030 (1.61764 iter/s, 6.18184s/10 iters), loss = 7.5413
I0523 09:02:00.750149 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.5413 (* 1 = 7.5413 loss)
I0523 09:02:01.545496 34819 sgd_solver.cpp:112] Iteration 81030, lr = 0.01
I0523 09:02:06.581868 34819 solver.cpp:239] Iteration 81040 (1.71483 iter/s, 5.83148s/10 iters), loss = 7.28595
I0523 09:02:06.582026 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.28595 (* 1 = 7.28595 loss)
I0523 09:02:07.410425 34819 sgd_solver.cpp:112] Iteration 81040, lr = 0.01
I0523 09:02:11.848949 34819 solver.cpp:239] Iteration 81050 (1.89872 iter/s, 5.2667s/10 iters), loss = 8.1625
I0523 09:02:11.849004 34819 solver.cpp:258]     Train net output #0: softmax_loss = 8.1625 (* 1 = 8.1625 loss)
I0523 09:02:11.921373 34819 sgd_solver.cpp:112] Iteration 81050, lr = 0.01
I0523 09:02:15.295960 34819 solver.cpp:239] Iteration 81060 (2.90123 iter/s, 3.44681s/10 iters), loss = 7.0604
I0523 09:02:15.296015 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.0604 (* 1 = 7.0604 loss)
I0523 09:02:15.365151 34819 sgd_solver.cpp:112] Iteration 81060, lr = 0.01
I0523 09:02:17.542534 34872 data_layer.cpp:73] Restarting data prefetching from start.
I0523 09:02:18.721698 34819 solver.cpp:239] Iteration 81070 (2.91926 iter/s, 3.42552s/10 iters), loss = 7.68188
I0523 09:02:18.721750 34819 solver.cpp:258]     Train net output #0: softmax_loss = 7.68188 (* 1 = 7.68188 loss)
I0523 09:02:18.797358 34819 sgd_solver.cpp:112] Iteration 81070, lr = 0.01
*** Aborted at 1527037340 (unix time) try "date -d @1527037340" if you are using GNU date ***
PC: @     0x7f2da7597f1c __lll_lock_wait
*** SIGTERM (@0x3e90000441d) received by PID 34819 (TID 0x7f2db8b3b780) from PID 17437; stack trace: ***
    @     0x7f2db66edcb0 (unknown)
    @     0x7f2da7597f1c __lll_lock_wait
    @     0x7f2da7593664 _L_lock_952
    @     0x7f2da75934c6 __GI___pthread_mutex_lock
    @     0x7f2d7fe68cbd (unknown)
    @     0x7f2d7ffc0ba0 (unknown)
    @     0x7f2daab0b5f1 (unknown)
    @     0x7f2daab25e6d (unknown)
    @     0x7f2daa7f2d1f (unknown)
    @     0x7f2daa7988be (unknown)
    @     0x7f2daa72c7c9 (unknown)
    @     0x7f2db7de9cf7 caffe::CuDNNConvolutionLayer<>::Forward_gpu()
    @     0x7f2db7d8a1d3 caffe::Net<>::ForwardFromTo()
    @     0x7f2db7d8a587 caffe::Net<>::Forward()
    @     0x7f2db7c2fcc7 caffe::Solver<>::Step()
    @     0x7f2db7c304bf caffe::Solver<>::Solve()
    @     0x7f2db7d6c4e6 caffe::NCCL<>::Run()
    @           0x40c1e3 train()
    @           0x40982c main
    @     0x7f2db66d8f45 (unknown)
    @           0x40a111 (unknown)
